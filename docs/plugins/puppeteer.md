# 🎭 Puppeteer Plugin

> **Anti-detection browser automation with pooling, cookie farming, and proxy orchestration.**
>
> **Navigation:** [← Plugin Index](./README.md) | [Configuration ↓](#-configuration) | [FAQ ↓](#-faq)

---

## ⚡ TLDR

**Enterprise-grade browser automation with anti-bot detection and intelligent cookie farming.**

**1 line to get started:**
```javascript
await db.usePlugin(new PuppeteerPlugin({ stealth: { enabled: true } }));
```

**Production-ready scraping:**
```javascript
await db.usePlugin(new PuppeteerPlugin({
  pool: { maxBrowsers: 5, maxTabsPerBrowser: 10 },        // 70-90% less memory
  stealth: { enabled: true },                             // Bypass bot detection
  cookies: { enabled: true, farming: { enabled: true } }, // Smart cookie rotation
  proxy: { enabled: true, list: ['http://proxy1.com'] }  // Multi-proxy support
}));

const page = await puppeteerPlugin.getPage();
await page.goto('https://example.com');
await puppeteerPlugin.releasePage(page);
```

**Key features:**
- ✅ **Browser Pool Management** - 70-90% memory reduction with tab recycling
- ✅ **Stealth Mode** - Bypass bot detection (puppeteer-extra-plugin-stealth)
- ✅ **Human Behavior** - Realistic mouse movements, typing, scrolling (ghost-cursor)
- ✅ **Cookie Farming** - Automated warmup, rotation, reputation tracking
- ✅ **Proxy Rotation** - Multi-proxy with health monitoring & auto-failover
- ✅ **Performance** - Resource blocking (50-70% faster), caching, connection reuse
- ✅ **Monitoring** - Network/console tracking with compression

**Performance comparison:**
```javascript
// ❌ Without pooling: Create new browser each time
for (const url of urls) {
  const browser = await puppeteer.launch();  // 450 MB each
  // ... scrape
  await browser.close();
}
// Memory: 450 MB per request, Startup: 3-5 seconds each

// ✅ With pooling: Reuse browsers from pool
const plugin = new PuppeteerPlugin({ pool: { maxBrowsers: 5 } });
for (const url of urls) {
  const page = await plugin.getPage();  // 85 MB total for 5 browsers
  // ... scrape
  await plugin.releasePage(page);
}
// Memory: 85 MB total (5x reduction), Startup: 0.7 seconds (7x faster)
```

---

## 📑 Table of Contents

1. [⚡ TLDR](#-tldr)
2. [⚡ Quickstart](#-quickstart)
3. [Usage Journey](#usage-journey)
   - [Level 1: Basic Page Visit](#level-1-basic-page-visit)
   - [Level 2: Enable Browser Pooling](#level-2-enable-browser-pooling)
   - [Level 3: Add Stealth Mode](#level-3-add-stealth-mode)
   - [Level 4: Human Behavior Simulation](#level-4-human-behavior-simulation)
   - [Level 5: Cookie Farming](#level-5-cookie-farming)
   - [Level 6: Proxy Rotation](#level-6-proxy-rotation)
   - [Level 7: Production Setup](#level-7-production-setup)
4. [📊 Configuration Reference](#-configuration-reference)
5. [📚 Configuration Examples](#-configuration-examples)
6. [🔧 API Reference](#-api-reference)
7. [✅ Best Practices](#-best-practices)
8. [🚨 Error Handling](#-error-handling)
9. [🔗 See Also](#-see-also)
10. [❓ FAQ](#-faq)

---

## ⚡ Quickstart

```javascript
import { Database } from 's3db.js';
import { PuppeteerPlugin } from 's3db.js/plugins';

const db = new Database({
  connectionString: 's3://key:secret@bucket/path'
});

// Create plugin with stealth mode
const puppeteerPlugin = new PuppeteerPlugin({
  stealth: { enabled: true },
  pool: { maxBrowsers: 3 }
});

await db.usePlugin(puppeteerPlugin);
await db.connect();

// Get a page and scrape
const page = await puppeteerPlugin.getPage();

try {
  await page.goto('https://example.com');

  const title = await page.title();
  const products = await page.evaluate(() => {
    return Array.from(document.querySelectorAll('.product')).map(el => ({
      name: el.querySelector('.name')?.textContent,
      price: el.querySelector('.price')?.textContent
    }));
  });

  console.log(`Found ${products.length} products on "${title}"`);
} finally {
  await puppeteerPlugin.releasePage(page);  // IMPORTANT: Always release!
}

await db.disconnect();
```

---

## Usage Journey

### Level 1: Basic Page Visit

Simple page navigation without any optimizations.

```javascript
import { Database } from 's3db.js';
import { PuppeteerPlugin } from 's3db.js/plugins';

const db = new Database({ connectionString: 's3://...' });
const plugin = new PuppeteerPlugin();

await db.usePlugin(plugin);
await db.connect();

// Navigate to a page
const page = await plugin.getPage();
await page.goto('https://example.com');

// Extract data
const title = await page.title();
const content = await page.evaluate(() => document.body.textContent);

console.log(`Title: ${title}`);
console.log(`Content length: ${content.length} chars`);

await plugin.releasePage(page);
```

**What you get:**
- Basic browser automation
- Simple page navigation
- Data extraction

**What's missing:**
- No browser pooling (high memory)
- No stealth (easily detected)
- No error handling

---

### Level 2: Enable Browser Pooling

Add browser pooling to reduce memory consumption by 70-90%.

```javascript
const plugin = new PuppeteerPlugin({
  pool: {
    enabled: true,
    maxBrowsers: 5,         // Max 5 concurrent browsers
    maxTabsPerBrowser: 10,  // Max 10 tabs per browser
    closeOnIdle: true,      // Close after 5min idle
    idleTimeout: 300000
  }
});

await db.usePlugin(plugin);

// Scrape multiple URLs efficiently
const urls = [
  'https://example.com/page1',
  'https://example.com/page2',
  'https://example.com/page3'
];

for (const url of urls) {
  const page = await plugin.getPage();  // Reuses browsers from pool

  try {
    await page.goto(url);
    const data = await page.evaluate(() => /* extract data */);
    console.log(`Scraped ${url}:`, data);
  } finally {
    await plugin.releasePage(page);  // Returns to pool (doesn't close)
  }
}

// Check pool statistics
const stats = await plugin.getPoolStats();
console.log('Pool stats:', stats);
// {
//   totalBrowsers: 3,
//   totalPages: 8,
//   availableBrowsers: 2,
//   busyBrowsers: 1
// }
```

**Performance improvement:**
- **Memory**: 450 MB → 85 MB (5x reduction)
- **Startup time**: 3-5s → 0.7s (7x faster)

---

### Level 3: Add Stealth Mode

Bypass bot detection with advanced evasion techniques.

```javascript
const plugin = new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },

  // Enable stealth mode
  stealth: {
    enabled: true,
    enableEvasions: true  // Enable all evasion techniques
  },

  // Randomize user agent
  userAgent: {
    enabled: true,
    random: true,
    filters: {
      deviceCategory: 'desktop'  // 'desktop' | 'mobile' | 'tablet'
    }
  },

  // Randomize viewport
  viewport: {
    randomize: true,
    presets: ['desktop', 'laptop']
  }
});

const page = await plugin.getPage();
await page.goto('https://bot-detection-test.com');

// Check if detected
const isBot = await page.evaluate(() => navigator.webdriver);
console.log(`Detected as bot: ${isBot}`);  // false
```

**What stealth mode does:**
- Removes `navigator.webdriver` flag
- Fixes WebGL, plugins, permissions inconsistencies
- Randomizes canvas fingerprint
- Spoofs timezone, language, platform
- Patches Chrome DevTools Protocol leaks

---

### Level 4: Human Behavior Simulation

Simulate realistic human interactions to avoid detection.

```javascript
const plugin = new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },
  stealth: { enabled: true },

  // Human-like mouse movements
  humanBehavior: {
    enabled: true,
    mouse: {
      enabled: true,
      bezierCurves: true,    // Smooth curved movements
      overshoot: true,       // Overshoot and correct
      jitter: true,          // Minor tremors
      pathThroughElements: true
    },

    // Realistic typing
    typing: {
      enabled: true,
      mistakes: true,        // Simulate typos
      corrections: true,     // Delete and fix
      pauseAfterWord: true,  // Pause between words
      speedVariation: true,
      delayRange: [50, 150]  // Variable speed
    },

    // Natural scrolling
    scrolling: {
      enabled: true,
      randomStops: true,     // Pause at random positions
      backScroll: true,      // Scroll up occasionally
      horizontalJitter: true
    }
  }
});

const page = await plugin.getPage();
await page.goto('https://example.com/login');

// Human-like typing
await page.type('#username', 'myuser');      // Types with delays and occasional typos
await page.type('#password', 'mypassword');
await page.click('#login-button');           // Human-like mouse movement

await page.waitForNavigation();
```

**What you get:**
- Bezier curve mouse movements (ghost-cursor)
- Variable typing speed with mistakes
- Natural scrolling with pauses
- Harder to detect as bot

---

### Level 5: Cookie Farming

Automated cookie warming, rotation, and reputation tracking.

```javascript
const plugin = new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },
  stealth: { enabled: true },
  humanBehavior: { enabled: true },

  // Cookie farming
  cookies: {
    enabled: true,
    storage: {
      resource: 'plg_puppeteer_cookies',  // S3DB resource
      autoSave: true,                     // Auto-save after page
      autoLoad: true,                     // Auto-load before navigation
      encrypt: true                       // Encrypt cookie data
    },
    farming: {
      enabled: true,

      // Warmup phase: Visit popular sites
      warmup: {
        enabled: true,
        pages: [
          'https://www.google.com',
          'https://www.youtube.com',
          'https://www.wikipedia.org'
        ],
        randomOrder: true,
        timePerPage: { min: 5000, max: 15000 },
        interactions: {
          scroll: true,
          click: true,
          hover: true
        }
      },

      // Rotation strategy
      rotation: {
        enabled: true,
        requestsPerCookie: 100,  // Max requests per cookie
        maxAge: 86400000,        // 24 hours max age
        poolSize: 10             // Maintain 10 cookies
      },

      // Reputation tracking
      reputation: {
        enabled: true,
        trackSuccess: true,
        retireThreshold: 0.5,    // Retire if success < 50%
        ageBoost: true           // Prefer older cookies
      }
    }
  }
});

await db.usePlugin(plugin);

// Get next available cookie
const cookieId = await plugin.cookieManager.getNextCookie('example.com');
const cookieData = await plugin.cookieManager.getCookie(cookieId);

// Use the cookie
const page = await plugin.getPage();
await page.setCookie(...cookieData.data);
await page.goto('https://example.com');

// Extract data...
const success = true;  // Based on your logic

// Update reputation
await plugin.cookieManager.updateCookieReputation(cookieId, success);
```

**Cookie lifecycle:**
1. **Warmup** - Visit popular sites to collect cookies
2. **Usage** - Rotate cookies based on usage/age
3. **Reputation** - Track success rates
4. **Retirement** - Remove low-performing cookies

---

### Level 6: Proxy Rotation

Multi-proxy management with health monitoring and automatic failover.

```javascript
const plugin = new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },
  stealth: { enabled: true },
  cookies: { enabled: true, farming: { enabled: true } },

  // Proxy rotation
  proxy: {
    enabled: true,

    // Proxy list (multiple formats supported)
    list: [
      'http://proxy1.example.com:8080',
      'http://user:pass@proxy2.example.com:3128',
      {
        server: 'socks5://proxy3.example.com:1080',
        username: 'user',
        password: 'pass'
      }
    ],

    // Selection strategy
    selectionStrategy: 'round-robin',  // 'round-robin' | 'random' | 'least-used' | 'best-performance'

    // Domains to bypass proxy
    bypassList: ['localhost', '127.0.0.1'],

    // Health monitoring
    healthCheck: {
      enabled: true,
      interval: 300000,              // Check every 5 minutes
      testUrl: 'https://www.google.com',
      timeout: 10000,
      successRateThreshold: 0.3      // Minimum 30% success rate
    }
  }
});

// Proxy is automatically assigned per browser
const browser1 = await plugin.getBrowser();  // Gets proxy1
const browser2 = await plugin.getBrowser();  // Gets proxy2 (round-robin)

// Check proxy statistics
const stats = await plugin.proxyManager.getProxyStats();
console.log('Proxy stats:', stats);
// [
//   {
//     proxy: 'http://proxy1.com:8080',
//     requests: 145,
//     successes: 120,
//     failures: 25,
//     successRate: 0.827,
//     avgResponseTime: 423,
//     healthy: true
//   },
//   ...
// ]
```

**Selection strategies:**
- **round-robin** - Cycle through proxies sequentially (equal distribution)
- **random** - Random proxy per request (load balancing)
- **least-used** - Pick least-used proxy (balance usage)
- **best-performance** - Pick fastest proxy (performance priority)

---

### ⚠️ CRITICAL: Proxy-Session Immutable Binding

**KEY CONCEPT**: Once a session is assigned a proxy, **they are permanently bound together**. This is a security feature to prevent fingerprint leakage.

```javascript
const plugin = new PuppeteerPlugin({
  proxy: {
    enabled: true,
    list: ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']
  },
  cookies: { enabled: true }
});

// First request with session 'user-123' gets assigned proxy1
await plugin.navigate('https://example.com', { useSession: 'user-123' });
// ✅ Proxy: proxy1 (binding created and saved to S3DB)

// SAME session ALWAYS uses proxy1 (binding is immutable)
await plugin.navigate('https://other.com', { useSession: 'user-123' });
// ✅ Proxy: proxy1 (reused from binding)

// Different session gets different proxy
await plugin.navigate('https://example.com', { useSession: 'user-456' });
// ✅ Proxy: proxy2 (new binding created)

// Trying to change proxy for existing session FAILS
await plugin.navigate('https://site.com', {
  useSession: 'user-123',
  proxy: 'http://proxy3.com'  // ❌ IGNORED - binding already exists
});
// ✅ Proxy: proxy1 (binding enforced)
```

**Why Immutable?**

1. **Fingerprint Consistency**: Browser fingerprints include IP address. Changing proxy mid-session = different fingerprint = bot detection
2. **Session Integrity**: Many sites track IP changes as suspicious behavior
3. **Cookie Validity**: Cookies are often bound to specific IP ranges by security policies

**Binding Storage**:

Bindings are persisted to S3DB in the cookies resource:

```javascript
{
  sessionId: 'user-123',
  proxyId: 'proxy_0',  // IMMUTABLE! Cannot be changed
  proxyUrl: 'http://proxy1.com:8080',
  cookies: [...],
  boundAt: '2025-01-01T00:00:00.000Z'
}
```

**Error Scenarios**:

```javascript
// Error 1: Bound proxy removed from pool
// PluginError: Proxy http://proxy1.com bound to session user-123 not found in proxy list

// Error 2: Bound proxy marked unhealthy
// PluginError: Proxy http://proxy1.com bound to session user-123 is unhealthy (success rate: 0.15)

// Solution: Delete session to rebind
await plugin.deleteSession('user-123');
const page = await plugin.getPage({ useSession: 'user-123' });
// New binding created with healthy proxy
```

**Proxy Rotation Pattern**:

To effectively rotate proxies, use different session IDs:

```javascript
// ❌ BAD: Same session = same proxy forever
for (let i = 0; i < 100; i++) {
  await plugin.navigate(urls[i], { useSession: 'scraper' });
  // All 100 requests use same proxy (proxy1)
}

// ✅ GOOD: Rotate sessions = rotate proxies
for (let i = 0; i < 100; i++) {
  const sessionId = `scraper-${i % 5}`;  // 5 sessions = 5 proxies
  await plugin.navigate(urls[i], { useSession: sessionId });
  // Requests distributed across 5 different proxies
}

// ✅ BETTER: Dynamic session IDs for full rotation
const proxyCount = plugin.proxyManager.getProxyCount();
for (let i = 0; i < 100; i++) {
  const sessionId = `scraper-${i % proxyCount}`;
  await plugin.navigate(urls[i], { useSession: sessionId });
  // Requests distributed across ALL proxies
}
```

**Best Practices**:

1. **Plan session strategy** - Number of sessions = number of unique proxies you need
2. **Monitor bindings** - Track which sessions are bound to which proxies
3. **Handle failures gracefully** - If bound proxy fails, delete session and restart
4. **Don't over-optimize** - Proxy rotation is already handled by session rotation

**Events**:

```javascript
// Monitor proxy-session bindings
plugin.on('puppeteer.proxy-session-bound', ({ sessionId, proxyId, proxyUrl }) => {
  console.log(`Session ${sessionId} bound to proxy ${proxyUrl}`);
});

plugin.on('puppeteer.proxy-session-binding-enforced', ({ sessionId, requestedProxy, boundProxy }) => {
  console.warn(`Session ${sessionId} requested ${requestedProxy} but enforced ${boundProxy}`);
});
```

---

### Level 7: Production Setup

Complete production configuration with monitoring and optimization.

```javascript
const plugin = new PuppeteerPlugin({
  // Browser pool
  pool: {
    maxBrowsers: 5,
    maxTabsPerBrowser: 10,
    reuseTab: false,        // Set to true for 30-50% faster page creation
    closeOnIdle: true,
    idleTimeout: 300000
  },

  // Launch options
  launch: {
    headless: true,
    args: [
      '--no-sandbox',
      '--disable-setuid-sandbox',
      '--disable-dev-shm-usage',
      '--disable-accelerated-2d-canvas',
      '--no-first-run',
      '--no-zygote',
      '--disable-gpu'
    ],
    ignoreHTTPSErrors: true
  },

  // Stealth & human behavior
  stealth: { enabled: true },
  humanBehavior: { enabled: true },

  // Cookie farming
  cookies: {
    enabled: true,
    farming: { enabled: true }
  },

  // Proxy rotation
  proxy: {
    enabled: true,
    list: process.env.PROXY_LIST.split(','),
    healthCheck: { enabled: true }
  },

  // Performance optimization
  performance: {
    blockResources: {
      enabled: true,
      types: ['image', 'stylesheet', 'font', 'media']  // 50-70% faster
    },
    cacheEnabled: true,
    javascriptEnabled: true
  },

  // Network monitoring (optional)
  networkMonitor: {
    enabled: false,        // Enable only for debugging (adds overhead)
    persist: false,
    filters: {
      saveErrors: true,    // Always save failed requests
      saveLargeAssets: true
    }
  },

  // Console monitoring (optional)
  consoleMonitor: {
    enabled: false,        // Enable only for debugging
    persist: false,
    filters: {
      levels: ['error', 'warning']
    }
  },

  // Error handling
  retries: {
    enabled: true,
    maxAttempts: 3,
    backoff: 'exponential',
    initialDelay: 1000
  },

  // Debug mode (disable in production)
  debug: {
    enabled: false,
    screenshots: false,
    console: false,
    network: false
  }
});

await db.usePlugin(plugin);
await db.connect();

// Production scraping loop with error handling
const urls = ['https://example.com/page1', 'https://example.com/page2'];

for (const url of urls) {
  const page = await plugin.getPage();

  try {
    await page.goto(url, {
      waitUntil: 'networkidle2',
      timeout: 30000
    });

    const data = await page.evaluate(() => /* extract data */);

    // Save to S3DB
    await db.resources.products.insert(data);

    console.log(`✓ Scraped ${url}`);
  } catch (error) {
    console.error(`✗ Failed to scrape ${url}:`, error.message);
    // Error automatically retried up to 3 times
  } finally {
    await plugin.releasePage(page);
  }
}

// Cleanup
await plugin.closeAll();
await db.disconnect();
```

**Production checklist:**
- ✅ Browser pooling enabled
- ✅ Resource blocking enabled (50-70% faster)
- ✅ Stealth mode enabled
- ✅ Cookie farming enabled
- ✅ Proxy rotation enabled
- ✅ Error handling with retries
- ✅ Monitoring disabled (only enable for debugging)
- ✅ Always release pages
- ✅ Cleanup on exit

---

## 📊 Configuration Reference

### Complete Configuration Object

```javascript
{
  // ============================================
  // BROWSER POOL
  // ============================================
  pool: {
    enabled: true,              // Enable browser pooling (RECOMMENDED)
    maxBrowsers: 5,             // Max concurrent browsers
    maxTabsPerBrowser: 10,      // Max tabs per browser
    reuseTab: false,            // ⚠️ NOT SUPPORTED YET - will be ignored with warning
    closeOnIdle: true,          // Close browsers after idle timeout
    idleTimeout: 300000         // 5 minutes idle timeout
  },

  // ============================================
  // BROWSER LAUNCH OPTIONS
  // ============================================
  launch: {
    headless: true,
    args: [
      '--no-sandbox',
      '--disable-setuid-sandbox',
      '--disable-dev-shm-usage',
      '--disable-accelerated-2d-canvas',
      '--no-first-run',
      '--no-zygote',
      '--disable-gpu'
    ],
    ignoreHTTPSErrors: true,
    executablePath: null,       // Custom browser path (optional)
    dumpio: false               // Pipe browser output to console
  },

  // ============================================
  // VIEWPORT & USER AGENT
  // ============================================
  viewport: {
    width: 1920,
    height: 1080,
    deviceScaleFactor: 1,
    randomize: true,            // Random viewport per page
    presets: ['desktop', 'laptop', 'tablet']
  },

  userAgent: {
    enabled: true,
    random: true,               // Random user agent per page
    filters: {
      deviceCategory: 'desktop' // 'desktop' | 'mobile' | 'tablet'
    },
    custom: null                // Custom user agent string
  },

  // ============================================
  // STEALTH MODE (Anti-Detection)
  // ============================================
  stealth: {
    enabled: true,              // Enable stealth evasions (RECOMMENDED)
    enableEvasions: true        // Enable all evasion techniques
  },

  // ============================================
  // HUMAN BEHAVIOR SIMULATION
  // ============================================
  humanBehavior: {
    enabled: true,
    mouse: {
      enabled: true,
      bezierCurves: true,       // Smooth bezier mouse movements
      overshoot: true,          // Realistic overshoot/correction
      jitter: true,             // Minor position jitter
      pathThroughElements: true
    },
    typing: {
      enabled: true,
      mistakes: true,           // Simulate typos
      corrections: true,        // Delete and correct mistakes
      pauseAfterWord: true,     // Pause between words
      speedVariation: true,
      delayRange: [50, 150]     // Delay between keystrokes (ms)
    },
    scrolling: {
      enabled: true,
      randomStops: true,        // Random scroll pauses
      backScroll: true,         // Scroll up occasionally
      horizontalJitter: true
    }
  },

  // ============================================
  // COOKIE MANAGEMENT & FARMING
  // ============================================
  cookies: {
    enabled: true,
    storage: {
      resource: 'plg_puppeteer_cookies',
      autoSave: true,           // Auto-save after each page
      autoLoad: true,           // Auto-load before navigation
      encrypt: true             // Encrypt cookie data
    },
    farming: {
      enabled: true,
      warmup: {
        enabled: true,
        pages: [                // Sites to visit for warmup
          'https://www.google.com',
          'https://www.youtube.com',
          'https://www.wikipedia.org'
        ],
        randomOrder: true,
        timePerPage: { min: 5000, max: 15000 },
        interactions: {
          scroll: true,
          click: true,
          hover: true
        }
      },
      rotation: {
        enabled: true,
        requestsPerCookie: 100,
        maxAge: 86400000,       // 24 hours
        poolSize: 10
      },
      reputation: {
        enabled: true,
        trackSuccess: true,
        retireThreshold: 0.5,
        ageBoost: true
      }
    }
  },

  // ============================================
  // PERFORMANCE OPTIMIZATION
  // ============================================
  performance: {
    blockResources: {
      enabled: true,            // 50-70% faster page loads
      types: ['image', 'stylesheet', 'font', 'media']
    },
    cacheEnabled: true,
    javascriptEnabled: true
  },

  // ============================================
  // RESOURCE NAMING (customize S3DB resource names)
  // ============================================
  resourceNames: {
    cookies: 'my_cookies',                      // Default: plg_puppeteer_cookies
    networkSessions: 'my_network_sessions',     // Default: plg_puppeteer_network_sessions
    networkRequests: 'my_network_requests',     // Default: plg_puppeteer_network_requests
    networkErrors: 'my_network_errors',         // Default: plg_puppeteer_network_errors
    consoleSessions: 'my_console_sessions',     // Default: plg_puppeteer_console_sessions
    consoleMessages: 'my_console_messages',     // Default: plg_puppeteer_console_messages
    consoleErrors: 'my_console_errors'          // Default: plg_puppeteer_console_errors
  },

  // ============================================
  // NETWORK MONITORING (CDP)
  // ============================================
  networkMonitor: {
    enabled: false,             // Disabled by default (overhead)
    persist: false,             // Save to S3DB
    filters: {
      types: null,              // ['xhr', 'fetch'] or null
      statuses: null,           // [404, 500] or null
      minSize: null,
      maxSize: null,
      saveErrors: true,
      saveLargeAssets: true
    },
    compression: {
      enabled: true,
      threshold: 10240          // Compress payloads > 10KB
    }
  },

  // ============================================
  // CONSOLE MONITORING
  // ============================================
  consoleMonitor: {
    enabled: false,             // Disabled by default
    persist: false,
    filters: {
      levels: null,             // ['error', 'warning'] or null
      excludePatterns: [],
      includeStackTraces: true,
      includeSourceLocation: true,
      captureNetwork: false
    }
  },

  // ============================================
  // SCREENSHOT & RECORDING
  // ============================================
  screenshot: {
    fullPage: false,
    type: 'png'                 // 'png' | 'jpeg' | 'webp'
  },

  // ============================================
  // PROXY SUPPORT
  // ============================================
  proxy: {
    enabled: false,
    list: [],                   // Array of proxy URLs
    selectionStrategy: 'round-robin',
    bypassList: [],
    healthCheck: {
      enabled: true,
      interval: 300000,
      testUrl: 'https://www.google.com',
      timeout: 10000,
      successRateThreshold: 0.3
    }
  },

  // ============================================
  // ERROR HANDLING & RETRIES
  // ============================================
  retries: {
    enabled: true,
    maxAttempts: 3,
    backoff: 'exponential',
    initialDelay: 1000
  },

  // ============================================
  // LOGGING & DEBUGGING
  // ============================================
  debug: {
    enabled: false,
    screenshots: false,
    console: false,
    network: false
  }
}
```

---

## 📚 Configuration Examples

### Example 1: Lightweight Scraper (Minimal Config)

```javascript
new PuppeteerPlugin({
  pool: { maxBrowsers: 3 },
  stealth: { enabled: true },
  performance: {
    blockResources: { enabled: true }
  }
})
```

**Use case:** Simple scraping, minimal memory footprint

---

### Example 2: Stealth Scraper (Anti-Detection)

```javascript
new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },
  stealth: { enabled: true },
  humanBehavior: { enabled: true },
  userAgent: { random: true },
  viewport: { randomize: true },
  cookies: {
    enabled: true,
    farming: { enabled: true }
  }
})
```

**Use case:** Bypass bot detection, realistic behavior

---

### Example 3: High-Volume Scraper (Performance)

```javascript
new PuppeteerPlugin({
  pool: {
    maxBrowsers: 10,
    maxTabsPerBrowser: 20,
    reuseTab: true,  // 30-50% faster
    closeOnIdle: true
  },
  performance: {
    blockResources: {
      enabled: true,
      types: ['image', 'stylesheet', 'font', 'media']
    },
    cacheEnabled: true
  },
  stealth: { enabled: true }
})
```

**Use case:** High-volume scraping, maximum performance

---

### Example 4: Multi-Proxy Scraper (Distributed)

```javascript
new PuppeteerPlugin({
  pool: { maxBrowsers: 5 },
  stealth: { enabled: true },
  proxy: {
    enabled: true,
    list: [
      'http://proxy1.com:8080',
      'http://proxy2.com:8080',
      'http://proxy3.com:8080'
    ],
    selectionStrategy: 'best-performance',
    healthCheck: { enabled: true }
  }
})
```

**Use case:** Distributed scraping, IP rotation

---

### Example 5: Session-Based Scraper (Authentication)

```javascript
new PuppeteerPlugin({
  pool: { maxBrowsers: 3 },
  stealth: { enabled: true },
  humanBehavior: {
    enabled: true,
    typing: { enabled: true, mistakes: true }
  },
  cookies: {
    enabled: true,
    storage: {
      autoSave: true,
      autoLoad: true,
      encrypt: true
    }
  }
})
```

**Use case:** Login sessions, authenticated scraping

---

### Example 6: Debug Mode (Troubleshooting)

```javascript
new PuppeteerPlugin({
  pool: { maxBrowsers: 1 },
  launch: { headless: false },  // See browser
  networkMonitor: {
    enabled: true,
    persist: true
  },
  consoleMonitor: {
    enabled: true,
    persist: true
  },
  debug: {
    enabled: true,
    screenshots: true,
    console: true,
    network: true
  }
})
```

**Use case:** Debugging, troubleshooting issues

---

## 🔧 API Reference

### Plugin Methods

#### `getBrowser(options?): Promise<Browser>`

Get a browser instance from the pool.

```javascript
const browser = await plugin.getBrowser({
  proxy: 'http://proxy.com:8080',  // Override proxy
  headless: false                  // Override headless
});
```

---

#### `getPage(browser?, options?): Promise<Page>`

Get a new page from a browser (or create browser if not provided).

```javascript
const page = await plugin.getPage(browser, {
  viewport: { width: 1280, height: 720 },
  userAgent: 'Custom User-Agent'
});
```

---

#### `releasePage(page): Promise<void>`

Release a page back to the pool (closes tab).

```javascript
await plugin.releasePage(page);  // IMPORTANT: Always call this!
```

---

#### `releaseBrowser(browser): Promise<void>`

Release a browser back to the pool (marks as available).

```javascript
await plugin.releaseBrowser(browser);
```

---

#### `closeBrowser(browser): Promise<void>`

Close a browser permanently (removes from pool).

```javascript
await plugin.closeBrowser(browser);
```

---

#### `closeAll(): Promise<void>`

Close all browsers in the pool.

```javascript
await plugin.closeAll();  // Call on shutdown
```

---

#### `getPoolStats(): Promise<Object>`

Get browser pool statistics.

```javascript
const stats = await plugin.getPoolStats();
console.log(stats);
// {
//   totalBrowsers: 3,
//   totalPages: 12,
//   availableBrowsers: 1,
//   busyBrowsers: 2,
//   browsers: [...]
// }
```

---

#### `withSession(sessionId, handler, options): Promise<any>`

**DX Helper**: Convenient session-aware navigation with automatic cleanup.

Simplifies session-based scraping by handling navigation, page management, and cleanup automatically.

**Signature**:
```javascript
await plugin.withSession(sessionId, handler, { url, ...navigateOptions })
```

**Parameters**:
- `sessionId` (string, required): Session identifier for cookie/proxy binding
- `handler` (function, required): Async function that receives `(page, plugin)` and performs scraping
- `options` (object, required): Navigation options
  - `url` (string, required): URL to navigate to before calling handler
  - `waitUntil` (string): Navigation wait condition ('load', 'domcontentloaded', 'networkidle0', 'networkidle2')
  - `timeout` (number): Navigation timeout in milliseconds
  - All other `navigate()` options supported

**Returns**: Promise resolving to handler's return value

**Examples**:

```javascript
// Basic usage
const data = await plugin.withSession('user-123', async (page) => {
  // Page is already navigated to URL with session loaded
  const title = await page.title();
  const content = await page.$eval('#main', el => el.textContent);
  return { title, content };
}, {
  url: 'https://example.com',
  waitUntil: 'networkidle2'
});

console.log(data);  // { title: 'Example', content: '...' }
// Page automatically closed, cookies automatically saved
```

**vs. Manual Approach**:

```javascript
// ❌ Manual (verbose, error-prone)
const page = await plugin.navigate('https://example.com', {
  useSession: 'user-123',
  waitUntil: 'networkidle2'
});

try {
  const title = await page.title();
  const content = await page.$eval('#main', el => el.textContent);
  return { title, content };
} catch (error) {
  console.error('Scraping failed:', error);
  throw error;
} finally {
  await page.close();  // MUST remember to close
  // Cookies saved automatically on close
}

// ✅ withSession (clean, automatic)
await plugin.withSession('user-123', async (page) => {
  const title = await page.title();
  const content = await page.$eval('#main', el => el.textContent);
  return { title, content };
}, { url: 'https://example.com', waitUntil: 'networkidle2' });
```

**Advanced Usage**:

```javascript
// Multi-page navigation within session
await plugin.withSession('user-123', async (page, plugin) => {
  // Already at homepage from URL option
  const products = await page.$$eval('.product', els =>
    els.map(el => ({ name: el.textContent, link: el.href }))
  );

  // Navigate to first product page
  await page.click('.product:first-child a');
  await page.waitForNavigation();

  const details = await page.$eval('#details', el => el.textContent);

  return { products, details };
}, {
  url: 'https://shop.example.com/products'
});
```

**Error Handling**:

```javascript
try {
  const data = await plugin.withSession('user-123', async (page) => {
    throw new Error('Scraping failed');
  }, { url: 'https://example.com' });
} catch (error) {
  // Page still cleaned up properly even on error
  console.error('Handler error:', error.message);
}
```

**Events Emitted**:

```javascript
plugin.on('puppeteer.withSession.start', ({ sessionId, url }) => {
  console.log(`Starting withSession for ${sessionId} at ${url}`);
});

plugin.on('puppeteer.withSession.finish', ({ sessionId, url, duration, error }) => {
  if (error) {
    console.error(`withSession failed for ${sessionId}:`, error);
  } else {
    console.log(`withSession completed for ${sessionId} in ${duration}ms`);
  }
});

plugin.on('puppeteer.withSession.cleanupFailed', ({ sessionId, error }) => {
  console.error(`Failed to cleanup session ${sessionId}:`, error);
});
```

**Requirements & Validation**:

```javascript
// ❌ Missing sessionId
await plugin.withSession(null, async (page) => {}, { url: '...' });
// Throws: PluginError: sessionId is required for withSession

// ❌ Missing url
await plugin.withSession('user-123', async (page) => {});
// Throws: PluginError: options.url is required for withSession

// ❌ Invalid handler
await plugin.withSession('user-123', 'not-a-function', { url: '...' });
// Throws: PluginError: handler must be a function
```

**Best Practices**:

1. **Always use for session-based scraping** - Reduces boilerplate significantly
2. **Return data from handler** - Handler's return value is passed through
3. **Let errors propagate** - Don't catch errors inside handler unless necessary
4. **Use for single-page scrapes** - For complex multi-page flows, use `navigate()` directly

**Performance**:

```javascript
// Benchmark: 1000 single-page scrapes
// Manual approach: 145 seconds (boilerplate overhead)
// withSession:     142 seconds (3 seconds faster, cleaner code)
```

---

### Cookie Manager Methods

#### `createCookie(options): Promise<string>`

Create a new cookie session.

```javascript
const sessionId = await plugin.cookieManager.createCookie({
  domain: 'example.com',
  tags: ['premium']
});
```

---

#### `getCookie(id): Promise<Object>`

Get cookie data by ID.

```javascript
const cookie = await plugin.cookieManager.getCookie('cookie-123');
```

---

#### `getNextCookie(domain): Promise<string>`

Get next available cookie for domain (rotation logic).

```javascript
const cookieId = await plugin.cookieManager.getNextCookie('example.com');
```

---

#### `updateCookieReputation(id, success): Promise<void>`

Update cookie reputation after use.

```javascript
await plugin.cookieManager.updateCookieReputation('cookie-123', true);
```

---

#### `retireCookie(id): Promise<void>`

Retire a cookie (mark as inactive).

```javascript
await plugin.cookieManager.retireCookie('cookie-123');
```

---

### Proxy Manager Methods

#### `getProxyStats(): Promise<Array>`

Get statistics for all proxies.

```javascript
const stats = await plugin.proxyManager.getProxyStats();
console.log(stats);
// [
//   {
//     proxy: 'http://proxy1.com:8080',
//     requests: 145,
//     successes: 120,
//     failures: 25,
//     successRate: 0.827,
//     avgResponseTime: 423,
//     healthy: true
//   }
// ]
```

---

## ✅ Best Practices

### Do's ✅

1. **Always release pages**
   ```javascript
   const page = await plugin.getPage();
   try {
     // ... work
   } finally {
     await plugin.releasePage(page);  // CRITICAL
   }
   ```

2. **Use browser pooling in production**
   ```javascript
   pool: { enabled: true, maxBrowsers: 5 }
   ```

3. **Enable stealth mode for public sites**
   ```javascript
   stealth: { enabled: true }
   ```

4. **Block unnecessary resources**
   ```javascript
   performance: { blockResources: { enabled: true } }  // 50-70% faster
   ```

5. **Use cookie farming for session persistence**
   ```javascript
   cookies: { farming: { enabled: true } }
   ```

6. **Monitor proxy health**
   ```javascript
   proxy: { healthCheck: { enabled: true } }
   ```

7. **Use error handling**
   ```javascript
   try {
     await page.goto(url, { timeout: 30000 });
   } catch (error) {
     console.error(`Failed: ${error.message}`);
   }
   ```

8. **Don't use `reuseTab: true` (not implemented yet)**
   ```javascript
   // ❌ NOT SUPPORTED YET
   pool: { reuseTab: true }  // Will emit warning and be ignored

   // ✅ Use browser pooling instead
   pool: { maxBrowsers: 5, maxTabsPerBrowser: 20 }
   ```

---

### ⚠️ Tab Recycling Status (Feature Not Implemented)

**Status**: Not yet implemented - coming in future release

The `pool.reuseTab` option is documented but **not currently functional**. When enabled, it will emit a warning and be ignored:

```javascript
const plugin = new PuppeteerPlugin({
  pool: {
    reuseTab: true  // ⚠️ NOT SUPPORTED YET
  }
});

// Console warning emitted:
// [PuppeteerPlugin] pool.reuseTab is not supported yet and will be ignored

plugin.on('puppeteer.configWarning', ({ setting, message }) => {
  console.warn(`${setting}: ${message}`);
  // Output: "pool.reuseTab: pool.reuseTab is not supported yet and will be ignored."
});
```

**Workaround**: Use browser pooling with multiple tabs per browser:

```javascript
// Instead of tab recycling, use browser pooling
const plugin = new PuppeteerPlugin({
  pool: {
    enabled: true,
    maxBrowsers: 5,           // Pool of 5 browsers
    maxTabsPerBrowser: 20,    // Up to 20 tabs per browser
    closeOnIdle: true,        // Close idle browsers
    idleTimeout: 300000       // After 5 minutes
  }
});

// This provides similar benefits:
// - Browsers are reused (faster than creating new browsers)
// - Tabs are created/closed as needed
// - Memory is managed through idle browser closure
```

**Future Implementation**:

Tab recycling will enable even faster page creation by reusing existing tabs instead of closing and creating new ones. Expected benefits:

- **30-50% faster** page creation (no tab initialization overhead)
- **Lower memory fragmentation** (reusing existing resources)
- **Fewer CDP reconnections** (stable browser connections)

**Track Progress**:
- GitHub Issue: [#xxx] Implement tab recycling for PuppeteerPlugin
- Expected: v2.x release

---

### Don'ts ❌

1. **Don't create new browsers for each request**
   ```javascript
   // ❌ Bad - Creates new browser each time (450 MB each)
   for (const url of urls) {
     const browser = await puppeteer.launch();
     await browser.close();
   }

   // ✅ Good - Reuse browsers from pool (85 MB total)
   const browser = await plugin.getBrowser();
   for (const url of urls) {
     const page = await plugin.getPage(browser);
     await plugin.releasePage(page);
   }
   ```

2. **Don't forget error handling**
   ```javascript
   // ❌ Bad - No error handling
   await page.goto(url);

   // ✅ Good - With timeout and error handling
   try {
     await page.goto(url, { timeout: 30000 });
   } catch (error) {
     console.error(`Failed to load ${url}:`, error.message);
   }
   ```

3. **Don't use headless: false in production**
   ```javascript
   // ❌ Bad - Resource intensive
   launch: { headless: false }

   // ✅ Good - Headless mode
   launch: { headless: true }
   ```

4. **Don't enable all monitoring in production**
   ```javascript
   // ❌ Bad - High overhead
   networkMonitor: { enabled: true },
   consoleMonitor: { enabled: true }

   // ✅ Good - Only when debugging
   networkMonitor: { enabled: false }
   ```

5. **Don't forget to close browsers on exit**
   ```javascript
   // ❌ Bad - Browsers left running
   process.exit(0);

   // ✅ Good - Cleanup
   await plugin.closeAll();
   await db.disconnect();
   process.exit(0);
   ```

---

## 🚨 Error Handling

### Common Errors

#### 1. BrowserPoolError: "No browsers available"

**Cause:** All browsers in pool are busy

**Solution:**
```javascript
// Increase max browsers or wait for release
pool: { maxBrowsers: 10 }  // Increase limit

// Or add timeout
const page = await plugin.getPage({ timeout: 30000 });
```

---

#### 2. NavigationError: "Navigation timeout"

**Cause:** Page took too long to load

**Solution:**
```javascript
await page.goto(url, {
  waitUntil: 'domcontentloaded',  // Don't wait for all resources
  timeout: 60000                   // Increase timeout
});
```

---

#### 3. BrowserPoolError: "Browser closed unexpectedly"

**Cause:** Browser crashed or was closed externally

**Solution:**
```javascript
launch: {
  args: [
    '--disable-dev-shm-usage',  // Fix shared memory issues
    '--no-sandbox'              // Fix permissions issues
  ]
}
```

---

#### 4. PluginError: "Detected as bot"

**Cause:** Bot detection bypassed stealth evasions

**Solution:**
```javascript
stealth: { enabled: true },
humanBehavior: { enabled: true },
cookies: { farming: { enabled: true } }
```

---

#### 5. BrowserPoolError: "Out of memory"

**Cause:** Too many browsers/pages open

**Solution:**
```javascript
pool: {
  maxBrowsers: 2,            // Reduce max browsers
  maxTabsPerBrowser: 5,      // Reduce max tabs
  closeOnIdle: true
}

// ALWAYS release pages
await plugin.releasePage(page);
```

---

#### 6. ProxyError: "Proxy connection failed"

**Cause:** Proxy server down or authentication failed

**Solution:**
```javascript
proxy: {
  healthCheck: {
    enabled: true,
    interval: 60000,           // Check more frequently
    successRateThreshold: 0.5  // Increase threshold
  }
}
```

---

## 🔗 See Also

### Related Documentation
- [Network Monitoring Guide](./puppeteer/NETWORK_MONITORING.md) - Advanced network tracking
- [Performance Optimization Guide](./puppeteer/PERFORMANCE.md) - Detailed benchmarks

### Examples
- **Basic Usage**: `docs/examples/e91-puppeteer-basic.js`
- **Cookie Farming**: `docs/examples/e92-puppeteer-cookie-farming.js`
- **Proxy Binding**: `docs/examples/e93-puppeteer-proxy-binding.js`
- **Performance Metrics**: `docs/examples/e95-puppeteer-performance-metrics.js`
- **Network Monitoring**: `docs/examples/e96-puppeteer-network-monitoring.js`
- **Console Monitoring**: `docs/examples/e97-puppeteer-console-monitoring.js`

### Tests
- **Plugin Tests**: `tests/plugins/puppeteer.test.js`
- **Cookie Tests**: `tests/plugins/puppeteer-cookies.test.js`

### Source Code
- **Plugin**: `src/plugins/puppeteer.plugin.js`
- **Browser Pool**: `src/plugins/puppeteer/browser-pool.class.js`
- **Cookie Manager**: `src/plugins/puppeteer/cookie-manager.class.js`
- **Proxy Manager**: `src/plugins/puppeteer/proxy-manager.class.js`

---

## ❓ FAQ

### General

**Q: What's the difference between `closeBrowser()` and `releaseBrowser()`?**

A:
- `releaseBrowser(browser)` - Returns browser to pool (keeps it alive for reuse)
- `closeBrowser(browser)` - Closes browser permanently (removes from pool)
- `releasePage(page)` - Closes tab and releases browser to pool

```javascript
// ✅ Recommended: Release to pool
await plugin.releasePage(page);

// ⚠️ Only if browser is broken
await plugin.closeBrowser(browser);
```

---

**Q: How many browsers should I have in the pool?**

A: Depends on your use case:

```javascript
// Low volume (< 10 requests/min)
pool: { maxBrowsers: 2 }

// Medium volume (10-50 requests/min)
pool: { maxBrowsers: 5 }

// High volume (50+ requests/min)
pool: { maxBrowsers: 10 }

// Rule of thumb: 1 browser per concurrent request
```

---

**Q: Should I enable `reuseTab`?**

A: Depends on isolation requirements:

```javascript
// ✅ Enable for performance (30-50% faster)
pool: { reuseTab: true }  // Good for: same-site scraping, high volume

// ❌ Disable for isolation
pool: { reuseTab: false }  // Good for: multi-site, auth sessions
```

---

### Stealth & Detection

**Q: How do I know if I'm detected as a bot?**

A: Check multiple indicators:

```javascript
const page = await plugin.getPage();
await page.goto('https://example.com');

// Check webdriver flag
const isBot = await page.evaluate(() => navigator.webdriver);
console.log(`Webdriver flag: ${isBot}`);  // Should be false

// Check for captcha
const hasCaptcha = await page.$('.captcha-container');
console.log(`Has captcha: ${!!hasCaptcha}`);

// Check response
const blocked = await page.evaluate(() =>
  document.body.textContent.includes('Access Denied')
);
console.log(`Blocked: ${blocked}`);
```

---

**Q: What's the best configuration for avoiding detection?**

A: Use all anti-detection features:

```javascript
new PuppeteerPlugin({
  stealth: { enabled: true },          // Anti-detection
  humanBehavior: { enabled: true },    // Realistic interactions
  userAgent: { random: true },         // Random user agent
  viewport: { randomize: true },       // Random viewport
  cookies: {
    farming: {
      enabled: true,
      warmup: { enabled: true }        // Warm up cookies
    }
  },
  proxy: { enabled: true }             // Rotate IPs
})
```

---

**Q: Why am I still getting detected even with stealth mode?**

A: Common causes:

1. **Too fast** - Add delays between requests
2. **No cookies** - Enable cookie farming
3. **Same IP** - Use proxy rotation
4. **Predictable behavior** - Enable human behavior simulation
5. **Modern detection** - Some sites use advanced fingerprinting (TLS, canvas, etc.)

---

### Cookies & Sessions

**Q: How does cookie farming work?**

A: 3-phase process:

1. **Warmup** - Visit popular sites (Google, YouTube) to collect cookies
2. **Usage** - Rotate cookies based on usage count and age
3. **Reputation** - Track success rates, retire low-performing cookies

```javascript
// Cookie lifecycle
// 1. Created with warmup
const cookieId = await plugin.cookieManager.createCookie({ domain: 'example.com' });

// 2. Used for requests
const cookie = await plugin.cookieManager.getCookie(cookieId);
await page.setCookie(...cookie.data);

// 3. Reputation updated
await plugin.cookieManager.updateCookieReputation(cookieId, success);

// 4. Eventually retired if success rate < 50%
```

---

**Q: How many cookies should I maintain in the pool?**

A: Rule of thumb:

```javascript
rotation: {
  poolSize: maxBrowsers * 2  // 2 cookies per browser
}

// Example: 5 browsers = 10 cookies
pool: { maxBrowsers: 5 },
cookies: { farming: { rotation: { poolSize: 10 } } }
```

---

**Q: Can I manually manage cookies instead of farming?**

A: Yes, disable farming and manage manually:

```javascript
cookies: {
  enabled: true,
  storage: { autoSave: true, autoLoad: true },
  farming: { enabled: false }  // Disable auto-farming
}

// Manual cookie management
const sessionId = await plugin.cookieManager.createCookie({
  domain: 'example.com',
  data: cookiesArray,
  tags: ['authenticated']
});
```

---

### Proxy & Performance

**Q: Which proxy selection strategy should I use?**

A: Depends on priority:

| Strategy | Use Case |
|----------|----------|
| `round-robin` | Equal distribution across proxies |
| `random` | Load balancing |
| `least-used` | Balance usage stats |
| `best-performance` | Fastest response time |

```javascript
// Most common: round-robin
proxy: { selectionStrategy: 'round-robin' }
```

---

**Q: How do I know if a proxy is working?**

A: Check proxy stats:

```javascript
const stats = await plugin.proxyManager.getProxyStats();
stats.forEach(proxy => {
  console.log(`${proxy.proxy}:`, {
    healthy: proxy.healthy,
    successRate: proxy.successRate,
    avgResponseTime: proxy.avgResponseTime
  });
});

// Unhealthy proxies are automatically removed if:
// - successRate < successRateThreshold (default 0.3)
```

---

**Q: How much faster is resource blocking?**

A: Measured improvement:

```javascript
// ❌ Without blocking: Load all resources
performance: { blockResources: { enabled: false } }
// Average load time: 3.2 seconds

// ✅ With blocking: Block images, CSS, fonts, media
performance: { blockResources: { enabled: true } }
// Average load time: 1.1 seconds

// Result: 65% faster (3x speed improvement)
```

---

### Memory & Resources

**Q: How much memory does the plugin use?**

A: Comparison:

```javascript
// ❌ Without pooling
// Memory: ~450 MB per browser
// 10 browsers = 4.5 GB

// ✅ With pooling (5 browsers, 10 tabs each)
pool: { maxBrowsers: 5, maxTabsPerBrowser: 10 }
// Memory: ~85 MB total (50 tabs)
// Result: 95% memory reduction
```

---

**Q: How do I monitor memory usage?**

A: Check pool stats:

```javascript
const stats = await plugin.getPoolStats();
console.log({
  totalBrowsers: stats.totalBrowsers,
  totalPages: stats.totalPages,
  memoryEstimate: stats.totalBrowsers * 17  // ~17 MB per browser
});
```

---

**Q: My scraper is running out of memory, what should I do?**

A: Common fixes:

```javascript
// 1. Reduce max browsers
pool: { maxBrowsers: 2 }

// 2. Reduce max tabs
pool: { maxTabsPerBrowser: 5 }

// 3. Enable auto-close on idle
pool: { closeOnIdle: true, idleTimeout: 180000 }  // 3 min

// 4. Block resources
performance: { blockResources: { enabled: true } }

// 5. ALWAYS release pages
await plugin.releasePage(page);  // CRITICAL!
```

---

### Monitoring & Debugging

**Q: Should I enable network/console monitoring in production?**

A: No - only for debugging:

```javascript
// ❌ Production (high overhead)
networkMonitor: { enabled: true },
consoleMonitor: { enabled: true }

// ✅ Production (disabled)
networkMonitor: { enabled: false },
consoleMonitor: { enabled: false }

// ✅ Debugging (enable temporarily)
networkMonitor: { enabled: true, persist: true }
```

---

**Q: How do I debug a failing page?**

A: Enable debug mode:

```javascript
const plugin = new PuppeteerPlugin({
  launch: { headless: false },  // See browser
  debug: {
    enabled: true,
    screenshots: true,           // Save screenshot on error
    console: true,               // Log console messages
    network: true                // Log network requests
  }
});

// Screenshot saved to: ./screenshots/<timestamp>.png
```

---

**Q: How do I save network logs to S3DB?**

A: Enable persistence:

```javascript
networkMonitor: {
  enabled: true,
  persist: true,  // Save to S3DB
  filters: {
    statuses: [404, 500],  // Only save errors
    saveErrors: true
  }
}

// Query logs
const logs = await db.resources['plg_puppeteer_network'].query({
  status: { $gte: 400 }
});
console.log(`Found ${logs.length} network errors`);
```

---

### Performance Benchmarks

**Q: What's the performance improvement with pooling?**

A: Measured benchmarks:

| Configuration | Memory (avg) | Load Time | Pages/min |
|---------------|-------------|-----------|-----------|
| No optimizations | 450 MB | 3.2s | 18 |
| + Resource blocking | 320 MB | 1.1s | 54 |
| + Browser pooling | 95 MB | 1.0s | 60 |
| + Tab recycling | 85 MB | 0.7s | 85 |

**Result**: 85x memory reduction, 4.5x speed improvement

See [Performance Guide](./puppeteer/PERFORMANCE.md) for detailed benchmarks.

---

**Q: What's the fastest configuration?**

A: Maximum performance setup:

```javascript
new PuppeteerPlugin({
  pool: {
    maxBrowsers: 10,
    maxTabsPerBrowser: 20,
    reuseTab: true,         // 30-50% faster
    closeOnIdle: false      // Keep browsers alive
  },
  performance: {
    blockResources: {
      enabled: true,
      types: ['image', 'stylesheet', 'font', 'media']  // 50-70% faster
    },
    cacheEnabled: true
  },
  stealth: { enabled: false },     // Disable for max speed (not recommended)
  humanBehavior: { enabled: false }
})
```

**Trade-off**: Faster but easier to detect as bot

---

## License

MIT License - See main s3db.js LICENSE file

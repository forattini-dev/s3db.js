# Base62 Encoding Benchmark Results

## Summary

- **Date**: 2025-01-15
- **Hardware**: Node.js v20.x
- **Iterations**: 1,000,000 operations (sequential), 100,000 operations (large numbers)
- **Runs**: 5 runs per test (average reported)
- **Conclusion**: Base62 is **5-5.37x faster** than Base36 for large and random numbers, but **2-3x slower** for small sequential numbers. **Superior compression** in all scenarios (32-41% vs 32-34%).

## Results

### Performance Comparison

| Operation | Base36 (k ops/s) | Base62 (k ops/s) | Base62 vs Base36 |
|-----------|------------------|------------------|------------------|
| encode (0..1e6) | 60,742 | 24,607 | **2.47x slower** |
| decode (0..1e6) | 31,856 | 8,599 | **3.70x slower** |
| encode (random 1e6) | 2,186 | 10,936 | **5.00x faster** ‚úÖ |
| decode (random 1e6) | 2,058 | 2,967 | **1.44x faster** ‚úÖ |
| encode (large 1e5) | 1,669 | 8,956 | **5.37x faster** ‚úÖ |
| decode (large 1e5) | 1,599 | 2,485 | **1.55x faster** ‚úÖ |

### Compression Analysis

| Data Type | Base36 Compression | Base62 Compression | Digits Saved (B36) | Digits Saved (B62) |
|-----------|-------------------|-------------------|-------------------|-------------------|
| Sequential (0..999) | 32.04% | **32.94%** | 0.93 | 0.95 |
| Random Large | 33.46% | **41.62%** ‚úÖ | 3.98 | 4.95 |
| Very Large | 32.43% | **40.71%** ‚úÖ | 4.18 | 5.24 |

### Compression Examples

| Number | Base10 | Base36 | Base62 | B36 Saved | B62 Saved |
|--------|--------|--------|--------|-----------|-----------|
| 10,000 | 10000 | 7ps | 2Bi | 2 (40.00%) | 2 (40.00%) |
| 123,456,789 | 123456789 | 21i3v9 | 8m0Kx | 3 (33.33%) | **4 (44.44%)** ‚úÖ |
| 999,999,999,999 | 999999999999 | cre66i9r | hBxM5A3 | 4 (33.33%) | **5 (41.67%)** ‚úÖ |

## Analysis

### When to Use Base62

‚úÖ **USE Base62 when:**
- Large numbers (> 1 million)
- Random numbers/IDs
- Maximum compression is priority
- Unix timestamps (large numbers)
- UUIDs converted to numbers

‚ùå **AVOID Base62 when:**
- Small sequential numbers (0-999999)
- Encode/decode performance is critical for small numbers
- Numbers are predominantly < 1 million

### Trade-offs

**Base62 Advantages:**
- üéØ **Better compression**: +8-9% on large numbers (41% vs 33%)
- ‚ö° **Much faster**: 5-5.37x for large numbers
- üìä **More efficient**: Larger alphabet (62 vs 36) = fewer characters

**Base62 Disadvantages:**
- üêå **Slower on small numbers**: 2-3x slower for 0-1M
- üßÆ **Lookup overhead**: More complex algorithm for small values

### Recommendations for S3DB.js

Based on these results, S3DB.js uses Base62 for:

1. **Timestamps** (`src/concerns/advanced-metadata-encoding.js`):
   - Unix timestamps are large numbers (1.7+ billion)
   - **Expected speedup**: 5x encode, 1.5x decode
   - **Expected compression**: 40% vs 33%

2. **Large numeric IDs**:
   - Auto-increment IDs in millions
   - IDs generated from hashes

3. **Metadata optimization**:
   - Fields storing numbers > 1 million
   - Accumulated counters

**NOT used for:**
- Small numbers (< 1M)
- Versions (v0, v1, v2...)
- Array indices

## How to Run

```bash
node docs/benchmarks/base62.bench.js
```

## History

- **2025-01-15**: Initial benchmark with performance data
- **2025-10-11**: Moved to docs/benchmarks/ with centralization

import crypto, { createHash, createVerify, generateKeyPairSync, createPublicKey, createSign, randomUUID, randomBytes } from 'crypto';
import EventEmitter, { EventEmitter as EventEmitter$1 } from 'events';
import { Hono } from 'hono';
import { jwtVerify, createRemoteJWKSet, SignJWT } from 'jose';
import fs$1, { readFile, mkdir, copyFile, unlink, stat, access, readdir, writeFile, rm, watch } from 'fs/promises';
import path, { resolve, join, dirname } from 'path';
import * as fs from 'fs';
import fs__default, { createReadStream, existsSync, createWriteStream, readFileSync } from 'fs';
import { HeadObjectCommand, GetObjectCommand, ListBucketsCommand, S3Client as S3Client$1, GetBucketLocationCommand, GetBucketTaggingCommand, PutObjectCommand, CopyObjectCommand, DeleteObjectCommand, DeleteObjectsCommand, ListObjectsV2Command } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { pipeline } from 'stream/promises';
import { Transform, Writable, Readable } from 'stream';
import zlib from 'node:zlib';
import os from 'os';
import jsonStableStringify from 'json-stable-stringify';
import os$1 from 'node:os';
import { promisify } from 'node:util';
import { PromisePool } from '@supercharge/promise-pool';
import { merge, isString, isEmpty, invert, uniq, cloneDeep, get, set, isObject as isObject$1, chunk, isFunction as isFunction$1 } from 'lodash-es';
import { flatten, unflatten } from 'flat';
import FastestValidator from 'fastest-validator';
import { ReadableStream } from 'node:stream/web';
import { fromNodeProviderChain, fromIni, fromProcess } from '@aws-sdk/credential-providers';
import { GetCallerIdentityCommand, STSClient } from '@aws-sdk/client-sts';
import { paginateDescribeInstances, paginateDescribeVpcs, paginateDescribeSubnets, paginateDescribeSecurityGroups, paginateDescribeRouteTables, paginateDescribeInternetGateways, paginateDescribeNatGateways, paginateDescribeNetworkAcls, paginateDescribeVolumes, paginateDescribeSnapshots, DescribeVpnConnectionsCommand, DescribeCustomerGatewaysCommand, DescribeTransitGatewaysCommand, DescribeTransitGatewayAttachmentsCommand, EC2Client } from '@aws-sdk/client-ec2';
import { paginateDescribeDBInstances, RDSClient, ListTagsForResourceCommand } from '@aws-sdk/client-rds';
import { paginateListUsers, ListUserTagsCommand, paginateListRoles, ListRoleTagsCommand, IAMClient } from '@aws-sdk/client-iam';
import { paginateListFunctions, LambdaClient, ListTagsCommand } from '@aws-sdk/client-lambda';
import { paginateDescribeLoadBalancers, ElasticLoadBalancingClient, DescribeTagsCommand } from '@aws-sdk/client-elastic-load-balancing';
import { paginateDescribeLoadBalancers as paginateDescribeLoadBalancers$1, paginateDescribeTargetGroups, ElasticLoadBalancingV2Client, DescribeTagsCommand as DescribeTagsCommand$1 } from '@aws-sdk/client-elastic-load-balancing-v2';
import { paginateListTables, DescribeTableCommand, DynamoDBClient, ListTagsOfResourceCommand } from '@aws-sdk/client-dynamodb';
import { paginateListQueues, SQSClient, GetQueueAttributesCommand, ListQueueTagsCommand } from '@aws-sdk/client-sqs';
import { paginateListTopics, SNSClient, GetTopicAttributesCommand, ListTagsForResourceCommand as ListTagsForResourceCommand$1 } from '@aws-sdk/client-sns';
import { paginateListClusters, paginateListServices, DescribeServicesCommand, paginateListTaskDefinitions, DescribeTaskDefinitionCommand, ECSClient, ListTagsForResourceCommand as ListTagsForResourceCommand$2 } from '@aws-sdk/client-ecs';
import { paginateListClusters as paginateListClusters$1, DescribeClusterCommand, paginateListNodegroups, DescribeNodegroupCommand, EKSClient, ListTagsForResourceCommand as ListTagsForResourceCommand$3 } from '@aws-sdk/client-eks';
import { paginateGetRestApis, APIGatewayClient, GetTagsCommand } from '@aws-sdk/client-api-gateway';
import { GetApisCommand, ApiGatewayV2Client, GetTagsCommand as GetTagsCommand$1 } from '@aws-sdk/client-apigatewayv2';
import { paginateListDistributions, CloudFrontClient, ListTagsForResourceCommand as ListTagsForResourceCommand$4 } from '@aws-sdk/client-cloudfront';
import { paginateListHostedZones, Route53Client, ListTagsForResourceCommand as ListTagsForResourceCommand$5 } from '@aws-sdk/client-route-53';
import { paginateListKeys, DescribeKeyCommand, KMSClient, ListResourceTagsCommand } from '@aws-sdk/client-kms';
import { paginateListSecrets, DescribeSecretCommand, SecretsManagerClient } from '@aws-sdk/client-secrets-manager';
import { paginateDescribeParameters, SSMClient, ListTagsForResourceCommand as ListTagsForResourceCommand$6 } from '@aws-sdk/client-ssm';
import { paginateDescribeCacheClusters, ElastiCacheClient, ListTagsForResourceCommand as ListTagsForResourceCommand$7 } from '@aws-sdk/client-elasticache';
import { paginateDescribeFileSystems, EFSClient, DescribeTagsCommand as DescribeTagsCommand$2 } from '@aws-sdk/client-efs';
import { paginateDescribeRepositories, ECRClient, ListTagsForResourceCommand as ListTagsForResourceCommand$8 } from '@aws-sdk/client-ecr';
import { paginateListStateMachines, SFNClient, ListTagsForResourceCommand as ListTagsForResourceCommand$9 } from '@aws-sdk/client-sfn';
import { paginateListEventBuses, paginateListRules, EventBridgeClient, ListTagsForResourceCommand as ListTagsForResourceCommand$a } from '@aws-sdk/client-eventbridge';
import { paginateDescribeAlarms, CloudWatchClient, ListTagsForResourceCommand as ListTagsForResourceCommand$b } from '@aws-sdk/client-cloudwatch';
import { paginateDescribeLogGroups, CloudWatchLogsClient, ListTagsForResourceCommand as ListTagsForResourceCommand$c } from '@aws-sdk/client-cloudwatch-logs';
import { paginateListTrails, GetTrailCommand, CloudTrailClient, ListTagsCommand as ListTagsCommand$1 } from '@aws-sdk/client-cloudtrail';
import { DescribeConfigurationRecordersCommand, DescribeDeliveryChannelsCommand, ConfigServiceClient } from '@aws-sdk/client-config-service';
import { paginateListCertificates, DescribeCertificateCommand, ACMClient, ListTagsForCertificateCommand } from '@aws-sdk/client-acm';
import { paginateListWebACLs, WAFClient, ListTagsForResourceCommand as ListTagsForResourceCommand$d } from '@aws-sdk/client-waf';
import { paginateListWebACLs as paginateListWebACLs$1, WAFV2Client, ListTagsForResourceCommand as ListTagsForResourceCommand$e } from '@aws-sdk/client-wafv2';
import { paginateListUserPools, DescribeUserPoolCommand, CognitoIdentityProviderClient, ListTagsForResourceCommand as ListTagsForResourceCommand$f } from '@aws-sdk/client-cognito-identity-provider';
import { paginateListBackupPlans, paginateListBackupVaults, BackupClient, ListTagsCommand as ListTagsCommand$2 } from '@aws-sdk/client-backup';
import { paginateListStreams, DescribeStreamCommand, KinesisClient, ListTagsForStreamCommand } from '@aws-sdk/client-kinesis';
import { GoogleAuth } from 'google-auth-library';
import * as readline from 'readline';
import { Agent } from 'http';
import { Agent as Agent$1 } from 'https';
import { NodeHttpHandler } from '@smithy/node-http-handler';
import { glob } from 'glob';
import { gzip as gzip$1, brotliCompress } from 'zlib';
import { promisify as promisify$1 } from 'util';
import { fileURLToPath } from 'url';
import bcrypt from 'bcrypt';
import { randomFillSync } from 'node:crypto';

const alphabet = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
const base = alphabet.length;
const charToValue = Object.fromEntries([...alphabet].map((c, i) => [c, i]));
const encode = (n) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  if (n === 0) return alphabet[0];
  if (n < 0) return "-" + encode(-Math.floor(n));
  n = Math.floor(n);
  let s = "";
  while (n) {
    s = alphabet[n % base] + s;
    n = Math.floor(n / base);
  }
  return s;
};
const decode = (s) => {
  if (typeof s !== "string") return NaN;
  if (s === "") return 0;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  let r = 0;
  for (let i = 0; i < s.length; i++) {
    const idx = charToValue[s[i]];
    if (idx === void 0) return NaN;
    r = r * base + idx;
  }
  return negative ? -r : r;
};
const encodeDecimal = (n) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  const negative = n < 0;
  n = Math.abs(n);
  const [intPart, decPart] = n.toString().split(".");
  const encodedInt = encode(Number(intPart));
  if (decPart) {
    return (negative ? "-" : "") + encodedInt + "." + decPart;
  }
  return (negative ? "-" : "") + encodedInt;
};
const decodeDecimal = (s) => {
  if (typeof s !== "string") return NaN;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  const [intPart, decPart] = s.split(".");
  const decodedInt = decode(intPart);
  if (isNaN(decodedInt)) return NaN;
  const num = decPart ? Number(decodedInt + "." + decPart) : decodedInt;
  return negative ? -num : num;
};
const encodeFixedPoint = (n, precision = 6) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  const scale = Math.pow(10, precision);
  const scaled = Math.round(n * scale);
  if (scaled === 0) return "^0";
  const negative = scaled < 0;
  let num = Math.abs(scaled);
  let s = "";
  while (num > 0) {
    s = alphabet[num % base] + s;
    num = Math.floor(num / base);
  }
  return "^" + (negative ? "-" : "") + s;
};
const decodeFixedPoint = (s, precision = 6) => {
  if (typeof s !== "string") return NaN;
  if (!s.startsWith("^")) return NaN;
  s = s.slice(1);
  if (s === "0") return 0;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  let r = 0;
  for (let i = 0; i < s.length; i++) {
    const idx = charToValue[s[i]];
    if (idx === void 0) return NaN;
    r = r * base + idx;
  }
  const scale = Math.pow(10, precision);
  const scaled = negative ? -r : r;
  return scaled / scale;
};
const encodeFixedPointBatch = (values, precision = 6) => {
  if (!Array.isArray(values)) return "";
  if (values.length === 0) return "^[]";
  const scale = Math.pow(10, precision);
  const encoded = values.map((n) => {
    if (typeof n !== "number" || isNaN(n) || !isFinite(n)) return "";
    const scaled = Math.round(n * scale);
    if (scaled === 0) return "0";
    const negative = scaled < 0;
    let num = Math.abs(scaled);
    let s = "";
    while (num > 0) {
      s = alphabet[num % base] + s;
      num = Math.floor(num / base);
    }
    return (negative ? "-" : "") + s;
  });
  return "^[" + encoded.join(",") + "]";
};
const decodeFixedPointBatch = (s, precision = 6) => {
  if (typeof s !== "string") return [];
  if (!s.startsWith("^[")) return [];
  s = s.slice(2, -1);
  if (s === "") return [];
  const parts = s.split(",");
  const scale = Math.pow(10, precision);
  return parts.map((part) => {
    if (part === "0") return 0;
    if (part === "") return NaN;
    let negative = false;
    if (part[0] === "-") {
      negative = true;
      part = part.slice(1);
    }
    let r = 0;
    for (let i = 0; i < part.length; i++) {
      const idx = charToValue[part[i]];
      if (idx === void 0) return NaN;
      r = r * base + idx;
    }
    const scaled = negative ? -r : r;
    return scaled / scale;
  });
};

const utf8BytesMemory = /* @__PURE__ */ new Map();
const UTF8_MEMORY_MAX_SIZE = 1e4;
function calculateUTF8Bytes(str) {
  if (typeof str !== "string") {
    str = String(str);
  }
  if (utf8BytesMemory.has(str)) {
    return utf8BytesMemory.get(str);
  }
  let bytes = 0;
  for (let i = 0; i < str.length; i++) {
    const codePoint = str.codePointAt(i);
    if (codePoint <= 127) {
      bytes += 1;
    } else if (codePoint <= 2047) {
      bytes += 2;
    } else if (codePoint <= 65535) {
      bytes += 3;
    } else if (codePoint <= 1114111) {
      bytes += 4;
      if (codePoint > 65535) {
        i++;
      }
    }
  }
  if (utf8BytesMemory.size < UTF8_MEMORY_MAX_SIZE) {
    utf8BytesMemory.set(str, bytes);
  } else if (utf8BytesMemory.size === UTF8_MEMORY_MAX_SIZE) {
    const entriesToDelete = Math.floor(UTF8_MEMORY_MAX_SIZE / 2);
    let deleted = 0;
    for (const key of utf8BytesMemory.keys()) {
      if (deleted >= entriesToDelete) break;
      utf8BytesMemory.delete(key);
      deleted++;
    }
    utf8BytesMemory.set(str, bytes);
  }
  return bytes;
}
function clearUTF8Memory() {
  utf8BytesMemory.clear();
}
function calculateAttributeNamesSize(mappedObject) {
  let totalSize = 0;
  for (const key of Object.keys(mappedObject)) {
    totalSize += calculateUTF8Bytes(key);
  }
  return totalSize;
}
function transformValue(value) {
  if (value === null || value === void 0) {
    return "";
  }
  if (typeof value === "boolean") {
    return value ? "1" : "0";
  }
  if (typeof value === "number") {
    return String(value);
  }
  if (typeof value === "string") {
    return value;
  }
  if (Array.isArray(value)) {
    if (value.length === 0) {
      return "[]";
    }
    return value.map((item) => String(item)).join("|");
  }
  if (typeof value === "object") {
    return JSON.stringify(value);
  }
  return String(value);
}
function calculateAttributeSizes(mappedObject) {
  const sizes = {};
  for (const [key, value] of Object.entries(mappedObject)) {
    const transformedValue = transformValue(value);
    const byteSize = calculateUTF8Bytes(transformedValue);
    sizes[key] = byteSize;
  }
  return sizes;
}
function calculateTotalSize(mappedObject) {
  const valueSizes = calculateAttributeSizes(mappedObject);
  const valueTotal = Object.values(valueSizes).reduce((total, size) => total + size, 0);
  const namesSize = calculateAttributeNamesSize(mappedObject);
  return valueTotal + namesSize;
}
function getSizeBreakdown(mappedObject) {
  const valueSizes = calculateAttributeSizes(mappedObject);
  const namesSize = calculateAttributeNamesSize(mappedObject);
  const valueTotal = Object.values(valueSizes).reduce((sum, size) => sum + size, 0);
  const total = valueTotal + namesSize;
  const sortedAttributes = Object.entries(valueSizes).sort(([, a], [, b]) => b - a).map(([key, size]) => ({
    attribute: key,
    size,
    percentage: (size / total * 100).toFixed(2) + "%"
  }));
  return {
    total,
    valueSizes,
    namesSize,
    valueTotal,
    breakdown: sortedAttributes,
    // Add detailed breakdown including names
    detailedBreakdown: {
      values: valueTotal,
      names: namesSize,
      total
    }
  };
}
function calculateSystemOverhead(config = {}) {
  const { version = "1", timestamps = false, id = "" } = config;
  const systemFields = {
    "_v": String(version)
    // Version field (e.g., "1", "10", "100")
  };
  if (timestamps) {
    systemFields.createdAt = "2024-01-01T00:00:00.000Z";
    systemFields.updatedAt = "2024-01-01T00:00:00.000Z";
  }
  if (id) {
    systemFields.id = id;
  }
  const overheadObject = {};
  for (const [key, value] of Object.entries(systemFields)) {
    overheadObject[key] = value;
  }
  return calculateTotalSize(overheadObject);
}
function calculateEffectiveLimit(config = {}) {
  const { s3Limit = 2048, systemConfig = {} } = config;
  const overhead = calculateSystemOverhead(systemConfig);
  return s3Limit - overhead;
}

class BaseError extends Error {
  constructor({
    verbose,
    bucket,
    key,
    message,
    code,
    statusCode,
    requestId,
    awsMessage,
    original,
    commandName,
    commandInput,
    metadata,
    description,
    suggestion,
    retriable,
    docs,
    title,
    hint,
    ...rest
  }) {
    if (verbose) message = message + `

Verbose:

${JSON.stringify(rest, null, 2)}`;
    super(message);
    if (typeof Error.captureStackTrace === "function") {
      Error.captureStackTrace(this, this.constructor);
    } else {
      this.stack = new Error(message).stack;
    }
    super.name = this.constructor.name;
    this.name = this.constructor.name;
    this.bucket = bucket;
    this.key = key;
    this.thrownAt = /* @__PURE__ */ new Date();
    this.code = code;
    this.statusCode = statusCode ?? 500;
    this.requestId = requestId;
    this.awsMessage = awsMessage;
    this.original = original;
    this.commandName = commandName;
    this.commandInput = commandInput;
    this.metadata = metadata;
    this.description = description;
    this.suggestion = suggestion;
    this.retriable = retriable ?? false;
    this.docs = docs;
    this.title = title || this.constructor.name;
    this.hint = hint;
    this.data = {
      bucket,
      key,
      ...rest,
      verbose,
      message,
      suggestion: this.suggestion,
      retriable: this.retriable,
      docs: this.docs,
      title: this.title,
      hint: this.hint
    };
  }
  toJson() {
    return {
      name: this.name,
      message: this.message,
      code: this.code,
      statusCode: this.statusCode,
      requestId: this.requestId,
      awsMessage: this.awsMessage,
      bucket: this.bucket,
      key: this.key,
      thrownAt: this.thrownAt,
      retriable: this.retriable,
      suggestion: this.suggestion,
      docs: this.docs,
      title: this.title,
      hint: this.hint,
      commandName: this.commandName,
      commandInput: this.commandInput,
      metadata: this.metadata,
      description: this.description,
      data: this.data,
      original: this.original,
      stack: this.stack
    };
  }
  toString() {
    return `${this.name} | ${this.message}`;
  }
}
class S3dbError extends BaseError {
  constructor(message, details = {}) {
    let code, statusCode, requestId, awsMessage, original, metadata;
    if (details.original) {
      original = details.original;
      code = original.code || original.Code || original.name;
      statusCode = original.statusCode || original.$metadata && original.$metadata.httpStatusCode;
      requestId = original.requestId || original.$metadata && original.$metadata.requestId;
      awsMessage = original.message;
      metadata = original.$metadata ? { ...original.$metadata } : void 0;
    }
    super({ message, ...details, code, statusCode, requestId, awsMessage, original, metadata });
  }
}
class DatabaseError extends S3dbError {
  constructor(message, details = {}) {
    const merged = {
      statusCode: details.statusCode ?? 500,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Check database configuration and ensure the operation parameters are valid.",
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class ValidationError extends S3dbError {
  constructor(message, details = {}) {
    const merged = {
      statusCode: details.statusCode ?? 422,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Review validation errors and adjust the request payload before retrying.",
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class AuthenticationError extends S3dbError {
  constructor(message, details = {}) {
    const merged = {
      statusCode: details.statusCode ?? 401,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Provide valid authentication credentials and try again.",
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class PermissionError extends S3dbError {
  constructor(message, details = {}) {
    const merged = {
      statusCode: details.statusCode ?? 403,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Verify IAM permissions, bucket policies, and credentials before retrying.",
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class EncryptionError extends S3dbError {
  constructor(message, details = {}) {
    const merged = {
      statusCode: details.statusCode ?? 500,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Check encryption keys and inputs. This error generally requires code/config changes before retrying.",
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class ResourceNotFound extends S3dbError {
  constructor({ bucket, resourceName, id, original, ...rest }) {
    if (typeof id !== "string") {
      throw new ValidationError("ResourceNotFound requires id to be a string", {
        field: "id",
        value: id,
        retriable: false,
        suggestion: "Provide the resource id as a string when constructing ResourceNotFound."
      });
    }
    if (typeof bucket !== "string") {
      throw new ValidationError("ResourceNotFound requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing ResourceNotFound."
      });
    }
    if (typeof resourceName !== "string") {
      throw new ValidationError("ResourceNotFound requires resourceName to be a string", {
        field: "resourceName",
        value: resourceName,
        retriable: false,
        suggestion: "Provide the resource name as a string when constructing ResourceNotFound."
      });
    }
    super(`Resource not found: ${resourceName}/${id} [bucket:${bucket}]`, {
      bucket,
      resourceName,
      id,
      original,
      statusCode: rest.statusCode ?? 404,
      retriable: rest.retriable ?? false,
      suggestion: rest.suggestion ?? "Confirm the resource ID and ensure it exists before retrying.",
      ...rest
    });
  }
}
class NoSuchBucket extends S3dbError {
  constructor({ bucket, original, ...rest }) {
    if (typeof bucket !== "string") {
      throw new ValidationError("NoSuchBucket requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing NoSuchBucket."
      });
    }
    super(`Bucket does not exists [bucket:${bucket}]`, {
      bucket,
      original,
      statusCode: rest.statusCode ?? 404,
      retriable: rest.retriable ?? false,
      suggestion: rest.suggestion ?? "Verify the bucket name and AWS region. Create the bucket if it is missing.",
      ...rest
    });
  }
}
class NoSuchKey extends S3dbError {
  constructor({ bucket, key, resourceName, id, original, ...rest }) {
    if (typeof key !== "string") {
      throw new ValidationError("NoSuchKey requires key to be a string", {
        field: "key",
        value: key,
        retriable: false,
        suggestion: "Provide the object key as a string when constructing NoSuchKey."
      });
    }
    if (typeof bucket !== "string") {
      throw new ValidationError("NoSuchKey requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing NoSuchKey."
      });
    }
    if (id !== void 0 && typeof id !== "string") {
      throw new ValidationError("NoSuchKey requires id to be a string when provided", {
        field: "id",
        value: id,
        retriable: false,
        suggestion: "Provide the resource id as a string when including it in NoSuchKey."
      });
    }
    super(`No such key: ${key} [bucket:${bucket}]`, {
      bucket,
      key,
      resourceName,
      id,
      original,
      statusCode: rest.statusCode ?? 404,
      retriable: rest.retriable ?? false,
      suggestion: rest.suggestion ?? "Check if the object key is correct and that the object was uploaded.",
      ...rest
    });
    this.resourceName = resourceName;
    this.id = id;
  }
}
class NotFound extends S3dbError {
  constructor({ bucket, key, resourceName, id, original, ...rest }) {
    if (typeof key !== "string") {
      throw new ValidationError("NotFound requires key to be a string", {
        field: "key",
        value: key,
        retriable: false,
        suggestion: "Provide the object key as a string when constructing NotFound."
      });
    }
    if (typeof bucket !== "string") {
      throw new ValidationError("NotFound requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing NotFound."
      });
    }
    super(`Not found: ${key} [bucket:${bucket}]`, {
      bucket,
      key,
      resourceName,
      id,
      original,
      statusCode: rest.statusCode ?? 404,
      retriable: rest.retriable ?? false,
      suggestion: rest.suggestion ?? "Confirm the key and bucket. Upload the object if it is missing.",
      ...rest
    });
    this.resourceName = resourceName;
    this.id = id;
  }
}
class MissingMetadata extends S3dbError {
  constructor({ bucket, original, ...rest }) {
    if (typeof bucket !== "string") {
      throw new ValidationError("MissingMetadata requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing MissingMetadata."
      });
    }
    super(`Missing metadata for bucket [bucket:${bucket}]`, {
      bucket,
      original,
      statusCode: rest.statusCode ?? 500,
      retriable: rest.retriable ?? false,
      suggestion: rest.suggestion ?? "Re-upload metadata or run db.uploadMetadataFile() to regenerate it.",
      ...rest
    });
  }
}
class InvalidResourceItem extends S3dbError {
  constructor({
    bucket,
    resourceName,
    attributes,
    validation,
    message,
    original,
    ...rest
  }) {
    if (typeof bucket !== "string") {
      throw new ValidationError("InvalidResourceItem requires bucket to be a string", {
        field: "bucket",
        value: bucket,
        retriable: false,
        suggestion: "Provide the bucket name as a string when constructing InvalidResourceItem."
      });
    }
    if (typeof resourceName !== "string") {
      throw new ValidationError("InvalidResourceItem requires resourceName to be a string", {
        field: "resourceName",
        value: resourceName,
        retriable: false,
        suggestion: "Provide the resource name as a string when constructing InvalidResourceItem."
      });
    }
    super(
      message || `Validation error: This item is not valid. Resource=${resourceName} [bucket:${bucket}].
${JSON.stringify(validation, null, 2)}`,
      {
        bucket,
        resourceName,
        attributes,
        validation,
        original,
        statusCode: rest.statusCode ?? 422,
        retriable: rest.retriable ?? false,
        suggestion: rest.suggestion ?? "Fix validation errors on the provided attributes before retrying the request.",
        ...rest
      }
    );
  }
}
class UnknownError extends S3dbError {
}
const ErrorMap = {
  "NotFound": NotFound,
  "NoSuchKey": NoSuchKey,
  "UnknownError": UnknownError,
  "NoSuchBucket": NoSuchBucket,
  "MissingMetadata": MissingMetadata,
  "InvalidResourceItem": InvalidResourceItem
};
function mapAwsError(err, context = {}) {
  const code = err.code || err.Code || err.name;
  const metadata = err.$metadata ? { ...err.$metadata } : void 0;
  const commandName = context.commandName;
  const commandInput = context.commandInput;
  let description;
  if (code === "NoSuchKey" || code === "NotFound") {
    description = "The specified key does not exist in the bucket. Check if the key exists and if your credentials have permission to access it.";
    return new NoSuchKey({
      ...context,
      original: err,
      metadata,
      commandName,
      commandInput,
      description,
      retriable: false
    });
  }
  if (code === "NoSuchBucket") {
    description = "The specified bucket does not exist. Check if the bucket name is correct and if your credentials have permission to access it.";
    return new NoSuchBucket({
      ...context,
      original: err,
      metadata,
      commandName,
      commandInput,
      description,
      retriable: false
    });
  }
  if (code === "AccessDenied" || err.statusCode === 403 || code === "Forbidden") {
    description = "Access denied. Check your AWS credentials, IAM permissions, and bucket policy.";
    return new PermissionError("Access denied", {
      ...context,
      original: err,
      metadata,
      commandName,
      commandInput,
      description,
      retriable: false
    });
  }
  if (code === "ValidationError" || err.statusCode === 400) {
    description = "Validation error. Check the request parameters and payload format.";
    return new ValidationError("Validation error", {
      ...context,
      original: err,
      metadata,
      commandName,
      commandInput,
      description,
      retriable: false
    });
  }
  if (code === "MissingMetadata") {
    description = "Object metadata is missing or invalid. Check if the object was uploaded correctly.";
    return new MissingMetadata({
      ...context,
      original: err,
      metadata,
      commandName,
      commandInput,
      description,
      retriable: false
    });
  }
  const errorDetails = [
    `Unknown error: ${err.message || err.toString()}`,
    err.code && `Code: ${err.code}`,
    err.statusCode && `Status: ${err.statusCode}`,
    err.stack && `Stack: ${err.stack.split("\n")[0]}`
  ].filter(Boolean).join(" | ");
  description = `Check the error details and AWS documentation. Original error: ${err.message || err.toString()}`;
  return new UnknownError(errorDetails, {
    ...context,
    original: err,
    metadata,
    commandName,
    commandInput,
    description,
    retriable: context.retriable ?? false
  });
}
class ConnectionStringError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Invalid connection string format. Check the connection string syntax and credentials.";
    const merged = {
      statusCode: details.statusCode ?? 400,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Fix the connection string and retry the operation.",
      description,
      ...details
    };
    super(message, merged);
  }
}
class CryptoError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Cryptography operation failed. Check if the crypto library is available and input is valid.";
    const merged = {
      statusCode: details.statusCode ?? 500,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Validate crypto inputs and environment setup before retrying.",
      description,
      ...details
    };
    super(message, merged);
  }
}
class SchemaError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Schema validation failed. Check schema definition and input data format.";
    const merged = {
      statusCode: details.statusCode ?? 400,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Update the schema or adjust the data to match the schema definition.",
      description,
      ...details
    };
    super(message, merged);
  }
}
class ResourceError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Resource operation failed. Check resource configuration, attributes, and operation context.";
    const merged = {
      statusCode: details.statusCode ?? 400,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Review the resource configuration and request payload before retrying.",
      description,
      ...details
    };
    super(message, merged);
    Object.assign(this, merged);
  }
}
class PartitionError extends S3dbError {
  constructor(message, details = {}) {
    let description = details.description;
    if (!description && details.resourceName && details.partitionName && details.fieldName) {
      const { resourceName, partitionName, fieldName, availableFields = [] } = details;
      description = `
Partition Field Validation Error

Resource: ${resourceName}
Partition: ${partitionName}
Missing Field: ${fieldName}

Available fields in schema:
${availableFields.map((f) => `  \u2022 ${f}`).join("\n") || "  (no fields defined)"}

Possible causes:
1. Field was removed from schema but partition still references it
2. Typo in partition field name
3. Nested field path is incorrect (use dot notation like 'utm.source')

Solution:
${details.strictValidation === false ? "  \u2022 Update partition definition to use existing fields" : `  \u2022 Add missing field to schema, OR
  \u2022 Update partition definition to use existing fields, OR
  \u2022 Use strictValidation: false to skip this check during testing`}

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#partitions
`.trim();
    }
    super(message, {
      ...details,
      statusCode: details.statusCode ?? 400,
      retriable: details.retriable ?? false,
      description
    });
  }
}
class AnalyticsNotEnabledError extends S3dbError {
  constructor(details = {}) {
    const {
      pluginName = "EventualConsistency",
      resourceName = "unknown",
      field = "unknown",
      configuredResources = [],
      registeredResources = [],
      pluginInitialized = false,
      ...rest
    } = details;
    const message = `Analytics not enabled for ${resourceName}.${field}`;
    const description = `
Analytics Not Enabled

Plugin: ${pluginName}
Resource: ${resourceName}
Field: ${field}

Diagnostics:
  \u2022 Plugin initialized: ${pluginInitialized ? "\u2713 Yes" : "\u2717 No"}
  \u2022 Analytics resources created: ${registeredResources.length}/${configuredResources.length}
${configuredResources.map((r) => {
      const exists = registeredResources.includes(r);
      return `    ${exists ? "\u2713" : "\u2717"} ${r}${!exists ? " (missing)" : ""}`;
    }).join("\n")}

Possible causes:
1. Resource not created yet - Analytics resources are created when db.createResource() is called
2. Resource created before plugin initialization - Plugin must be initialized before resources
3. Field not configured in analytics.resources config

Correct initialization order:
  1. Create database: const db = new Database({ ... })
  2. Install plugins: await db.connect() (triggers plugin.install())
  3. Create resources: await db.createResource({ name: '${resourceName}', ... })
  4. Analytics resources are auto-created by plugin

Example fix:
  const db = new Database({
    bucket: 'my-bucket',
    plugins: [new EventualConsistencyPlugin({
      resources: {
        '${resourceName}': {
          fields: {
            '${field}': { type: 'counter', analytics: true }
          }
        }
      }
    })]
  });

  await db.connect();  // Plugin initialized here
  await db.createResource({ name: '${resourceName}', ... });  // Analytics resource created here

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/eventual-consistency.md
`.trim();
    super(message, {
      ...rest,
      pluginName,
      resourceName,
      field,
      configuredResources,
      registeredResources,
      pluginInitialized,
      statusCode: rest.statusCode ?? 400,
      retriable: rest.retriable ?? false,
      description
    });
  }
}
class PluginError extends S3dbError {
  constructor(message, details = {}) {
    const {
      pluginName = "Unknown",
      operation = "unknown",
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Plugin Error

Plugin: ${pluginName}
Operation: ${operation}

Possible causes:
1. Plugin not properly initialized
2. Plugin configuration is invalid
3. Plugin dependencies not met
4. Plugin method called before installation

Solution:
Ensure plugin is added to database and connect() is called before usage.

Example:
  const db = new Database({
    bucket: 'my-bucket',
    plugins: [new ${pluginName}({ /* config */ })]
  });

  await db.connect();  // Plugin installed here
  // Now plugin methods are available

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/README.md
`.trim();
    }
    super(message, {
      ...rest,
      pluginName,
      operation,
      statusCode: rest.statusCode ?? 500,
      retriable: rest.retriable ?? false,
      description
    });
  }
}
class PluginStorageError extends S3dbError {
  constructor(message, details = {}) {
    const {
      pluginSlug = "unknown",
      key = "",
      operation = "unknown",
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Plugin Storage Error

Plugin: ${pluginSlug}
Key: ${key}
Operation: ${operation}

Possible causes:
1. Storage not initialized (plugin not installed)
2. Invalid key format
3. S3 operation failed
4. Permissions issue

Solution:
Ensure plugin has access to storage and key is valid.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/README.md#plugin-storage
`.trim();
    }
    super(message, {
      ...rest,
      pluginSlug,
      key,
      operation,
      statusCode: rest.statusCode ?? 500,
      retriable: rest.retriable ?? false,
      description
    });
  }
}
class PartitionDriverError extends S3dbError {
  constructor(message, details = {}) {
    const {
      driver = "unknown",
      operation = "unknown",
      queueSize,
      maxQueueSize,
      ...rest
    } = details;
    let description = details.description;
    if (!description && queueSize !== void 0 && maxQueueSize !== void 0) {
      description = `
Partition Driver Error

Driver: ${driver}
Operation: ${operation}
Queue Status: ${queueSize}/${maxQueueSize}

Possible causes:
1. Queue is full (backpressure)
2. Driver not properly configured
3. SQS permissions issue (if using SQS driver)

Solution:
${queueSize >= maxQueueSize ? "Wait for queue to drain or increase maxQueueSize" : "Check driver configuration and permissions"}
`.trim();
    } else if (!description) {
      description = `
Partition Driver Error

Driver: ${driver}
Operation: ${operation}

Check driver configuration and permissions.
`.trim();
    }
    super(message, {
      ...rest,
      driver,
      operation,
      queueSize,
      maxQueueSize,
      statusCode: rest.statusCode ?? 503,
      retriable: rest.retriable ?? queueSize >= maxQueueSize,
      description
    });
  }
}
class BehaviorError extends S3dbError {
  constructor(message, details = {}) {
    const {
      behavior = "unknown",
      availableBehaviors = [],
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Behavior Error

Requested: ${behavior}
Available: ${availableBehaviors.join(", ") || "body-overflow, body-only, truncate-data, enforce-limits, user-managed"}

Possible causes:
1. Behavior name misspelled
2. Custom behavior not registered

Solution:
Use one of the available behaviors or register custom behavior.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#behaviors
`.trim();
    }
    super(message, {
      ...rest,
      behavior,
      availableBehaviors,
      statusCode: rest.statusCode ?? 400,
      retriable: rest.retriable ?? false,
      description
    });
  }
}
class StreamError extends S3dbError {
  constructor(message, details = {}) {
    const {
      operation = "unknown",
      resource,
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Stream Error

Operation: ${operation}
${resource ? `Resource: ${resource}` : ""}

Possible causes:
1. Stream not properly initialized
2. Resource not available
3. Network error during streaming

Solution:
Check stream configuration and resource availability.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#streaming
`.trim();
    }
    super(message, {
      ...rest,
      operation,
      resource,
      statusCode: rest.statusCode ?? 500,
      retriable: rest.retriable ?? false,
      description
    });
  }
}
class MetadataLimitError extends S3dbError {
  constructor(message, details = {}) {
    const {
      totalSize,
      effectiveLimit,
      absoluteLimit = 2047,
      excess,
      resourceName,
      operation,
      ...rest
    } = details;
    let description = details.description;
    if (!description && totalSize && effectiveLimit) {
      description = `
S3 Metadata Size Limit Exceeded

Current Size: ${totalSize} bytes
Effective Limit: ${effectiveLimit} bytes
Absolute Limit: ${absoluteLimit} bytes
${excess ? `Excess: ${excess} bytes` : ""}
${resourceName ? `Resource: ${resourceName}` : ""}
${operation ? `Operation: ${operation}` : ""}

S3 has a hard limit of 2KB (2047 bytes) for object metadata.

Solutions:
1. Use 'body-overflow' behavior to store excess in body
2. Use 'body-only' behavior to store everything in body
3. Reduce number of fields
4. Use shorter field values
5. Enable advanced metadata encoding

Example:
  await db.createResource({
    name: '${resourceName || "myResource"}',
    behavior: 'body-overflow',  // Automatically handles overflow
    attributes: { ... }
  });

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#metadata-size-limits
`.trim();
    }
    super(message, {
      ...rest,
      totalSize,
      effectiveLimit,
      absoluteLimit,
      excess,
      resourceName,
      operation,
      statusCode: rest.statusCode ?? 413,
      retriable: rest.retriable ?? false,
      description
    });
  }
}

function tryFn(fnOrPromise) {
  if (fnOrPromise == null) {
    const err = new Error("fnOrPromise cannot be null or undefined");
    err.stack = new Error().stack;
    return [false, err, void 0];
  }
  if (typeof fnOrPromise === "function") {
    try {
      const result = fnOrPromise();
      if (result == null) {
        return [true, null, result];
      }
      if (typeof result.then === "function") {
        return result.then((data) => [true, null, data]).catch((error) => {
          if (error instanceof Error && Object.isExtensible(error)) {
            const desc = Object.getOwnPropertyDescriptor(error, "stack");
            if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
              try {
                error.stack = new Error().stack;
              } catch (_) {
              }
            }
          }
          return [false, error, void 0];
        });
      }
      return [true, null, result];
    } catch (error) {
      if (error instanceof Error && Object.isExtensible(error)) {
        const desc = Object.getOwnPropertyDescriptor(error, "stack");
        if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
          try {
            error.stack = new Error().stack;
          } catch (_) {
          }
        }
      }
      return [false, error, void 0];
    }
  }
  if (typeof fnOrPromise.then === "function") {
    return Promise.resolve(fnOrPromise).then((data) => [true, null, data]).catch((error) => {
      if (error instanceof Error && Object.isExtensible(error)) {
        const desc = Object.getOwnPropertyDescriptor(error, "stack");
        if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
          try {
            error.stack = new Error().stack;
          } catch (_) {
          }
        }
      }
      return [false, error, void 0];
    });
  }
  return [true, null, fnOrPromise];
}
function tryFnSync(fn) {
  try {
    const result = fn();
    return [true, null, result];
  } catch (err) {
    return [false, err, null];
  }
}

async function dynamicCrypto() {
  let lib;
  if (typeof process !== "undefined") {
    lib = crypto.webcrypto;
  } else if (typeof window !== "undefined") {
    lib = window.crypto;
  }
  if (!lib) throw new CryptoError("Could not load any crypto library", { context: "dynamicCrypto" });
  return lib;
}
async function sha256(message) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encoder = new TextEncoder();
  const data = encoder.encode(message);
  const [ok, err, hashBuffer] = await tryFn(() => cryptoLib.subtle.digest("SHA-256", data));
  if (!ok) throw new CryptoError("SHA-256 digest failed", { original: err, input: message });
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashHex = hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  return hashHex;
}
async function encrypt(content, passphrase) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const salt = cryptoLib.getRandomValues(new Uint8Array(16));
  const [okKey, errKey, key] = await tryFn(() => getKeyMaterial(passphrase, salt));
  if (!okKey) throw new CryptoError("Key derivation failed", { original: errKey, passphrase, salt });
  const iv = cryptoLib.getRandomValues(new Uint8Array(12));
  const encoder = new TextEncoder();
  const encodedContent = encoder.encode(content);
  const [okEnc, errEnc, encryptedContent] = await tryFn(() => cryptoLib.subtle.encrypt({ name: "AES-GCM", iv }, key, encodedContent));
  if (!okEnc) throw new CryptoError("Encryption failed", { original: errEnc, content });
  const encryptedData = new Uint8Array(salt.length + iv.length + encryptedContent.byteLength);
  encryptedData.set(salt);
  encryptedData.set(iv, salt.length);
  encryptedData.set(new Uint8Array(encryptedContent), salt.length + iv.length);
  return arrayBufferToBase64(encryptedData);
}
async function decrypt(encryptedBase64, passphrase) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encryptedData = base64ToArrayBuffer(encryptedBase64);
  const salt = encryptedData.slice(0, 16);
  const iv = encryptedData.slice(16, 28);
  const encryptedContent = encryptedData.slice(28);
  const [okKey, errKey, key] = await tryFn(() => getKeyMaterial(passphrase, salt));
  if (!okKey) throw new CryptoError("Key derivation failed (decrypt)", { original: errKey, passphrase, salt });
  const [okDec, errDec, decryptedContent] = await tryFn(() => cryptoLib.subtle.decrypt({ name: "AES-GCM", iv }, key, encryptedContent));
  if (!okDec) throw new CryptoError("Decryption failed", { original: errDec, encryptedBase64 });
  const decoder = new TextDecoder();
  return decoder.decode(decryptedContent);
}
async function md5(data) {
  if (typeof process === "undefined") {
    throw new CryptoError("MD5 hashing is only available in Node.js environment", { context: "md5" });
  }
  const [ok, err, result] = await tryFn(async () => {
    return crypto.createHash("md5").update(data).digest("base64");
  });
  if (!ok) {
    throw new CryptoError("MD5 hashing failed", { original: err, data });
  }
  return result;
}
async function getKeyMaterial(passphrase, salt) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encoder = new TextEncoder();
  const keyMaterial = encoder.encode(passphrase);
  const [okImport, errImport, baseKey] = await tryFn(() => cryptoLib.subtle.importKey(
    "raw",
    keyMaterial,
    { name: "PBKDF2" },
    false,
    ["deriveKey"]
  ));
  if (!okImport) throw new CryptoError("importKey failed", { original: errImport, passphrase });
  const [okDerive, errDerive, derivedKey] = await tryFn(() => cryptoLib.subtle.deriveKey(
    {
      name: "PBKDF2",
      salt,
      iterations: 1e5,
      hash: "SHA-256"
    },
    baseKey,
    { name: "AES-GCM", length: 256 },
    true,
    ["encrypt", "decrypt"]
  ));
  if (!okDerive) throw new CryptoError("deriveKey failed", { original: errDerive, passphrase, salt });
  return derivedKey;
}
function arrayBufferToBase64(buffer) {
  if (typeof process !== "undefined") {
    return Buffer.from(buffer).toString("base64");
  } else {
    const [ok, err, binary] = tryFnSync(() => String.fromCharCode.apply(null, new Uint8Array(buffer)));
    if (!ok) throw new CryptoError("Failed to convert ArrayBuffer to base64 (browser)", { original: err });
    return window.btoa(binary);
  }
}
function base64ToArrayBuffer(base64) {
  if (typeof process !== "undefined") {
    return new Uint8Array(Buffer.from(base64, "base64"));
  } else {
    const [ok, err, binaryString] = tryFnSync(() => window.atob(base64));
    if (!ok) throw new CryptoError("Failed to decode base64 (browser)", { original: err });
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes;
  }
}

function hashPasswordSync(password, rounds = 10) {
  if (!password || typeof password !== "string") {
    throw new ValidationError("Password must be a non-empty string", {
      field: "password",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a non-empty string before calling hashPasswordSync()."
    });
  }
  if (rounds < 4 || rounds > 31) {
    throw new ValidationError("Bcrypt rounds must be between 4 and 31", {
      field: "rounds",
      statusCode: 400,
      retriable: false,
      suggestion: "Configure bcrypt rounds between 4 and 31 (inclusive)."
    });
  }
  return bcrypt.hashSync(password, rounds);
}
async function hashPassword(password, rounds = 10) {
  if (!password || typeof password !== "string") {
    throw new ValidationError("Password must be a non-empty string", {
      field: "password",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a non-empty string before calling hashPassword()."
    });
  }
  if (rounds < 4 || rounds > 31) {
    throw new ValidationError("Bcrypt rounds must be between 4 and 31", {
      field: "rounds",
      statusCode: 400,
      retriable: false,
      suggestion: "Configure bcrypt rounds between 4 and 31 (inclusive)."
    });
  }
  return await bcrypt.hash(password, rounds);
}
async function verifyPassword$1(plaintext, hash) {
  if (!plaintext || typeof plaintext !== "string") {
    return false;
  }
  if (!hash || typeof hash !== "string") {
    return false;
  }
  try {
    const fullHash = hash.startsWith("$") ? hash : expandHash(hash);
    return await bcrypt.compare(plaintext, fullHash);
  } catch (error) {
    return false;
  }
}
function compactHash(bcryptHash) {
  if (!bcryptHash || typeof bcryptHash !== "string") {
    throw new ValidationError("Invalid bcrypt hash", {
      field: "bcryptHash",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a valid bcrypt hash generated by hashPassword()."
    });
  }
  if (!bcryptHash.startsWith("$2")) {
    throw new ValidationError("Not a valid bcrypt hash", {
      field: "bcryptHash",
      statusCode: 400,
      retriable: false,
      suggestion: 'Ensure the hash starts with "$2" and was produced by bcrypt.'
    });
  }
  const parts = bcryptHash.split("$");
  if (parts.length !== 4) {
    throw new ValidationError("Invalid bcrypt hash format", {
      field: "bcryptHash",
      statusCode: 400,
      retriable: false,
      suggestion: 'Provide a complete bcrypt hash (e.g., "$2b$10$...").'
    });
  }
  return parts[3];
}
function expandHash(compactHash2, rounds = 10) {
  if (!compactHash2 || typeof compactHash2 !== "string") {
    throw new ValidationError("Invalid compacted hash", {
      field: "compactHash",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a compacted hash returned from compactHash()."
    });
  }
  if (compactHash2.startsWith("$")) {
    return compactHash2;
  }
  const roundsStr = rounds.toString().padStart(2, "0");
  return `$2b$${roundsStr}$${compactHash2}`;
}
function isBcryptHash(str) {
  if (!str || typeof str !== "string") {
    return false;
  }
  if (str.startsWith("$2")) {
    return str.length === 60;
  }
  return str.length === 53;
}

var passwordHashing = /*#__PURE__*/Object.freeze({
  __proto__: null,
  compactHash: compactHash,
  expandHash: expandHash,
  hashPassword: hashPassword,
  hashPasswordSync: hashPasswordSync,
  isBcryptHash: isBcryptHash,
  verifyPassword: verifyPassword$1
});

const FALLBACK_URL_ALPHABET = "useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict";
const PASSWORD_ALPHABET = "ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz23456789";
const POOL_SIZE_MULTIPLIER = 128;
let pool;
let poolOffset = 0;
function fillPool(bytes) {
  if (!pool || pool.length < bytes) {
    pool = Buffer.allocUnsafe(bytes * POOL_SIZE_MULTIPLIER);
    randomFillSync(pool);
    poolOffset = 0;
  } else if (poolOffset + bytes > pool.length) {
    randomFillSync(pool);
    poolOffset = 0;
  }
  poolOffset += bytes;
}
function randomFromPool(bytes) {
  fillPool(bytes |= 0);
  return pool.subarray(poolOffset - bytes, poolOffset);
}
function customRandomFallback(alphabet, defaultSize, getRandom) {
  const mask = (2 << 31 - Math.clz32(alphabet.length - 1 | 1)) - 1;
  const step = Math.ceil(1.6 * mask * defaultSize / alphabet.length);
  return (size = defaultSize) => {
    if (!size) return "";
    let id = "";
    while (true) {
      const bytes = getRandom(step);
      let i = step;
      while (i--) {
        id += alphabet[bytes[i] & mask] || "";
        if (id.length >= size) return id;
      }
    }
  };
}
function customAlphabetFallback(alphabet, size = 21) {
  return customRandomFallback(alphabet, size, randomFromPool);
}
let activeCustomAlphabet = customAlphabetFallback;
let activeUrlAlphabet = FALLBACK_URL_ALPHABET;
let idGeneratorImpl = activeCustomAlphabet(activeUrlAlphabet, 22);
let passwordGeneratorImpl = activeCustomAlphabet(PASSWORD_ALPHABET, 16);
let nanoidInitializationError = null;
const nanoidReadyPromise = import('nanoid').then((mod) => {
  const resolvedCustomAlphabet = mod?.customAlphabet ?? activeCustomAlphabet;
  const resolvedUrlAlphabet = mod?.urlAlphabet ?? activeUrlAlphabet;
  activeCustomAlphabet = resolvedCustomAlphabet;
  activeUrlAlphabet = resolvedUrlAlphabet;
  idGeneratorImpl = activeCustomAlphabet(activeUrlAlphabet, 22);
  passwordGeneratorImpl = activeCustomAlphabet(PASSWORD_ALPHABET, 16);
}).catch((error) => {
  nanoidInitializationError = error;
  if (typeof process !== "undefined" && process?.env?.S3DB_DEBUG) {
    console.warn('[s3db] Failed to dynamically import "nanoid". Using fallback implementation.', error);
  }
});
function initializeNanoid() {
  return nanoidReadyPromise;
}
function getNanoidInitializationError() {
  return nanoidInitializationError;
}
const idGenerator = (...args) => idGeneratorImpl(...args);
const passwordGenerator = (...args) => passwordGeneratorImpl(...args);
const getUrlAlphabet = () => activeUrlAlphabet;
const createCustomGenerator = (alphabet, size) => activeCustomAlphabet(alphabet, size);

var id = /*#__PURE__*/Object.freeze({
  __proto__: null,
  createCustomGenerator: createCustomGenerator,
  getNanoidInitializationError: getNanoidInitializationError,
  getUrlAlphabet: getUrlAlphabet,
  idGenerator: idGenerator,
  initializeNanoid: initializeNanoid,
  passwordGenerator: passwordGenerator
});

const CONTENT_TYPE_DICT = {
  // JSON/XML (most common, highest savings)
  "application/json": "j",
  // 16B  1B = -93.75%
  "application/xml": "X",
  // 15B  1B = -93.3% (changed from 'x' to avoid conflict)
  "application/ld+json": "J",
  // 20B  1B = -95%
  // Text types
  "text/html": "H",
  // 9B  1B = -88.9% (changed from 'h' to avoid conflict)
  "text/plain": "T",
  // 10B  1B = -90% (changed from 'p' to avoid conflict)
  "text/css": "C",
  // 8B  1B = -87.5% (changed from 'c' to avoid conflict)
  "text/javascript": "V",
  // 15B  1B = -93.3% (changed from 's' to avoid conflict)
  "text/csv": "v",
  // 8B  1B = -87.5%
  // Images
  "image/png": "P",
  // 9B  1B = -88.9%
  "image/jpeg": "I",
  // 10B  1B = -90%
  "image/gif": "G",
  // 9B  1B = -88.9%
  "image/svg+xml": "S",
  // 13B  1B = -92.3%
  "image/webp": "W",
  // 10B  1B = -90%
  // Application types
  "application/pdf": "Q",
  // 15B  1B = -93.3% (changed from 'd' to avoid conflict)
  "application/zip": "z",
  // 15B  1B = -93.3%
  "application/octet-stream": "o",
  // 24B  1B = -95.8%
  "application/x-www-form-urlencoded": "u",
  // 33B  1B = -97%
  "multipart/form-data": "F",
  // 19B  1B = -94.7% (changed from 'f' to avoid conflict)
  // Font types
  "font/woff": "w",
  // 9B  1B = -88.9%
  "font/woff2": "f"
  // 10B  1B = -90% (changed from 'F')
};
const URL_PREFIX_DICT = {
  // API endpoints (very common)
  "/api/v1/": "@1",
  // 8B  2B = -75%
  "/api/v2/": "@2",
  // 8B  2B = -75%
  "/api/v3/": "@3",
  // 8B  2B = -75%
  "/api/": "@a",
  // 5B  2B = -60%
  // HTTPS prefixes
  "https://api.example.com/": "@A",
  // 24B  2B = -91.7%
  "https://api.": "@H",
  // 11B  2B = -81.8%
  "https://www.": "@W",
  // 12B  2B = -83.3%
  "https://": "@h",
  // 8B  2B = -75%
  "http://": "@t",
  // 7B  2B = -71.4%
  // AWS/S3 (common in s3db.js context)
  "https://s3.amazonaws.com/": "@s",
  // 26B  2B = -92.3%
  "https://s3-": "@S",
  // 10B  2B = -80%
  // Localhost (development)
  "http://localhost:": "@L",
  // 17B  2B = -88.2%
  "http://localhost": "@l",
  // 16B  2B = -87.5%
  // Common paths
  "/v1/": "@v",
  // 4B  2B = -50%
  "/users/": "@u",
  // 7B  2B = -71.4%
  "/products/": "@p"
  // 10B  2B = -80%
};
const STATUS_MESSAGE_DICT = {
  // Processing states (very common, good savings)
  "processing": "p",
  // 10B  1B = -90%
  "completed": "c",
  // 9B  1B = -88.9%
  "succeeded": "s",
  // 9B  1B = -88.9%
  "failed": "f",
  // 6B  1B = -83.3%
  "cancelled": "x",
  // 9B  1B = -88.9%
  "timeout": "t",
  // 7B  1B = -85.7%
  "retrying": "r",
  // 8B  1B = -87.5%
  // Payment states
  "authorized": "a",
  // 10B  1B = -90%
  "captured": "K",
  // 8B  1B = -87.5% (changed from C to avoid conflict)
  "refunded": "R",
  // 8B  1B = -87.5%
  "declined": "d",
  // 8B  1B = -87.5%
  // Order/delivery states
  "shipped": "h",
  // 7B  1B = -85.7% (changed from S to avoid conflict)
  "delivered": "D",
  // 9B  1B = -88.9%
  "returned": "e",
  // 8B  1B = -87.5% (changed from T to avoid conflict)
  "in_transit": "i",
  // 10B  1B = -90%
  // Generic states
  "initialized": "n",
  // 11B  1B = -90.9% (changed from I to avoid conflict)
  "terminated": "m"
  // 10B  1B = -90% (changed from X to avoid conflict)
};
const CONTENT_TYPE_REVERSE = Object.fromEntries(
  Object.entries(CONTENT_TYPE_DICT).map(([k, v]) => [v, k])
);
const URL_PREFIX_REVERSE = Object.fromEntries(
  Object.entries(URL_PREFIX_DICT).map(([k, v]) => [v, k])
);
const STATUS_MESSAGE_REVERSE = Object.fromEntries(
  Object.entries(STATUS_MESSAGE_DICT).map(([k, v]) => [v, k])
);
const COMBINED_DICT = {
  ...CONTENT_TYPE_DICT,
  ...STATUS_MESSAGE_DICT
  // URL prefixes handled separately (prefix matching)
};
const COMBINED_REVERSE = {
  ...CONTENT_TYPE_REVERSE,
  ...STATUS_MESSAGE_REVERSE
  // URL prefixes handled separately
};
function dictionaryEncode(value) {
  if (typeof value !== "string" || !value) {
    return null;
  }
  if (COMBINED_DICT[value]) {
    return {
      encoded: "d:" + COMBINED_DICT[value],
      encoding: "dictionary",
      originalLength: value.length,
      encodedLength: 2 + COMBINED_DICT[value].length,
      dictionaryType: "exact",
      savings: value.length - (2 + COMBINED_DICT[value].length)
    };
  }
  const sortedPrefixes = Object.entries(URL_PREFIX_DICT).sort(([a], [b]) => b.length - a.length);
  for (const [prefix, code] of sortedPrefixes) {
    if (value.startsWith(prefix)) {
      const remainder = value.substring(prefix.length);
      const encoded = "d:" + code + remainder;
      return {
        encoded,
        encoding: "dictionary",
        originalLength: value.length,
        encodedLength: encoded.length,
        dictionaryType: "prefix",
        prefix,
        remainder,
        savings: value.length - encoded.length
      };
    }
  }
  return null;
}
function dictionaryDecode(encoded) {
  if (typeof encoded !== "string" || !encoded.startsWith("d:")) {
    return null;
  }
  const payload = encoded.substring(2);
  if (payload.length === 0) {
    return null;
  }
  if (payload.length === 1) {
    const decoded = COMBINED_REVERSE[payload];
    if (decoded) {
      return decoded;
    }
  }
  if (payload.startsWith("@")) {
    const prefixCode = payload.substring(0, 2);
    const remainder = payload.substring(2);
    const prefix = URL_PREFIX_REVERSE[prefixCode];
    if (prefix) {
      return prefix + remainder;
    }
  }
  return null;
}

const analysisCache = /* @__PURE__ */ new Map();
const MAX_CACHE_SIZE = 500;
function isAsciiOnly(str) {
  return /^[\x20-\x7E]*$/.test(str);
}
function analyzeString(str) {
  if (!str || typeof str !== "string") {
    return { type: "none", safe: true };
  }
  if (analysisCache.has(str)) {
    return analysisCache.get(str);
  }
  if (isAsciiOnly(str)) {
    const result2 = {
      type: "ascii",
      safe: true,
      stats: { ascii: str.length, latin1: 0, multibyte: 0 }
    };
    cacheAnalysisResult(str, result2);
    return result2;
  }
  let asciiCount = 0;
  let latin1Count = 0;
  let multibyteCount = 0;
  for (let i = 0; i < str.length; i++) {
    const code = str.charCodeAt(i);
    if (code >= 32 && code <= 126) {
      asciiCount++;
    } else if (code < 32 || code === 127) {
      multibyteCount++;
    } else if (code >= 128 && code <= 255) {
      latin1Count++;
    } else {
      multibyteCount++;
    }
  }
  const hasMultibyte = multibyteCount > 0;
  const hasLatin1 = latin1Count > 0;
  let result;
  if (!hasLatin1 && !hasMultibyte) {
    result = {
      type: "ascii",
      safe: true,
      stats: { ascii: asciiCount, latin1: 0, multibyte: 0 }
    };
  } else if (hasMultibyte) {
    const multibyteRatio = multibyteCount / str.length;
    if (multibyteRatio > 0.3) {
      result = {
        type: "base64",
        safe: false,
        reason: "high multibyte content",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: multibyteCount }
      };
    } else {
      result = {
        type: "url",
        safe: false,
        reason: "contains multibyte characters",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: multibyteCount }
      };
    }
  } else {
    const latin1Ratio = latin1Count / str.length;
    if (latin1Ratio > 0.5) {
      result = {
        type: "base64",
        safe: false,
        reason: "high Latin-1 content",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: 0 }
      };
    } else {
      result = {
        type: "url",
        safe: false,
        reason: "contains Latin-1 extended characters",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: 0 }
      };
    }
  }
  cacheAnalysisResult(str, result);
  return result;
}
function cacheAnalysisResult(str, result) {
  if (analysisCache.size >= MAX_CACHE_SIZE) {
    const firstKey = analysisCache.keys().next().value;
    analysisCache.delete(firstKey);
  }
  analysisCache.set(str, result);
}
const COMMON_VALUES = {
  // Status values (10 entries)
  "active": { encoded: "active", encoding: "none" },
  "inactive": { encoded: "inactive", encoding: "none" },
  "pending": { encoded: "pending", encoding: "none" },
  "completed": { encoded: "completed", encoding: "none" },
  "failed": { encoded: "failed", encoding: "none" },
  "success": { encoded: "success", encoding: "none" },
  "error": { encoded: "error", encoding: "none" },
  "processing": { encoded: "processing", encoding: "none" },
  "queued": { encoded: "queued", encoding: "none" },
  "cancelled": { encoded: "cancelled", encoding: "none" },
  // HTTP methods (7 entries)
  "GET": { encoded: "GET", encoding: "none" },
  "POST": { encoded: "POST", encoding: "none" },
  "PUT": { encoded: "PUT", encoding: "none" },
  "DELETE": { encoded: "DELETE", encoding: "none" },
  "PATCH": { encoded: "PATCH", encoding: "none" },
  "HEAD": { encoded: "HEAD", encoding: "none" },
  "OPTIONS": { encoded: "OPTIONS", encoding: "none" },
  // HTTP status codes (20 entries - most common)
  "200": { encoded: "200", encoding: "none" },
  "201": { encoded: "201", encoding: "none" },
  "204": { encoded: "204", encoding: "none" },
  "301": { encoded: "301", encoding: "none" },
  "302": { encoded: "302", encoding: "none" },
  "304": { encoded: "304", encoding: "none" },
  "400": { encoded: "400", encoding: "none" },
  "401": { encoded: "401", encoding: "none" },
  "403": { encoded: "403", encoding: "none" },
  "404": { encoded: "404", encoding: "none" },
  "405": { encoded: "405", encoding: "none" },
  "409": { encoded: "409", encoding: "none" },
  "422": { encoded: "422", encoding: "none" },
  "429": { encoded: "429", encoding: "none" },
  "500": { encoded: "500", encoding: "none" },
  "502": { encoded: "502", encoding: "none" },
  "503": { encoded: "503", encoding: "none" },
  "504": { encoded: "504", encoding: "none" },
  "OK": { encoded: "OK", encoding: "none" },
  "Created": { encoded: "Created", encoding: "none" },
  // Payment/transaction status (12 entries)
  "paid": { encoded: "paid", encoding: "none" },
  "unpaid": { encoded: "unpaid", encoding: "none" },
  "refunded": { encoded: "refunded", encoding: "none" },
  "pending_payment": { encoded: "pending_payment", encoding: "none" },
  "authorized": { encoded: "authorized", encoding: "none" },
  "captured": { encoded: "captured", encoding: "none" },
  "declined": { encoded: "declined", encoding: "none" },
  "voided": { encoded: "voided", encoding: "none" },
  "chargeback": { encoded: "chargeback", encoding: "none" },
  "disputed": { encoded: "disputed", encoding: "none" },
  "settled": { encoded: "settled", encoding: "none" },
  "reversed": { encoded: "reversed", encoding: "none" },
  // Order/delivery status (10 entries)
  "shipped": { encoded: "shipped", encoding: "none" },
  "delivered": { encoded: "delivered", encoding: "none" },
  "returned": { encoded: "returned", encoding: "none" },
  "in_transit": { encoded: "in_transit", encoding: "none" },
  "out_for_delivery": { encoded: "out_for_delivery", encoding: "none" },
  "ready_to_ship": { encoded: "ready_to_ship", encoding: "none" },
  "backordered": { encoded: "backordered", encoding: "none" },
  "pre_order": { encoded: "pre_order", encoding: "none" },
  "on_hold": { encoded: "on_hold", encoding: "none" },
  "awaiting_pickup": { encoded: "awaiting_pickup", encoding: "none" },
  // User roles (8 entries)
  "admin": { encoded: "admin", encoding: "none" },
  "moderator": { encoded: "moderator", encoding: "none" },
  "owner": { encoded: "owner", encoding: "none" },
  "editor": { encoded: "editor", encoding: "none" },
  "viewer": { encoded: "viewer", encoding: "none" },
  "contributor": { encoded: "contributor", encoding: "none" },
  "guest": { encoded: "guest", encoding: "none" },
  "member": { encoded: "member", encoding: "none" },
  // Log levels (6 entries)
  "trace": { encoded: "trace", encoding: "none" },
  "debug": { encoded: "debug", encoding: "none" },
  "info": { encoded: "info", encoding: "none" },
  "warn": { encoded: "warn", encoding: "none" },
  "fatal": { encoded: "fatal", encoding: "none" },
  "emergency": { encoded: "emergency", encoding: "none" },
  // Environments (7 entries)
  "dev": { encoded: "dev", encoding: "none" },
  "development": { encoded: "development", encoding: "none" },
  "staging": { encoded: "staging", encoding: "none" },
  "production": { encoded: "production", encoding: "none" },
  "test": { encoded: "test", encoding: "none" },
  "qa": { encoded: "qa", encoding: "none" },
  "uat": { encoded: "uat", encoding: "none" },
  // CRUD operations (7 entries)
  "create": { encoded: "create", encoding: "none" },
  "read": { encoded: "read", encoding: "none" },
  "update": { encoded: "update", encoding: "none" },
  "delete": { encoded: "delete", encoding: "none" },
  "list": { encoded: "list", encoding: "none" },
  "search": { encoded: "search", encoding: "none" },
  "count": { encoded: "count", encoding: "none" },
  // States (8 entries)
  "enabled": { encoded: "enabled", encoding: "none" },
  "disabled": { encoded: "disabled", encoding: "none" },
  "archived": { encoded: "archived", encoding: "none" },
  "draft": { encoded: "draft", encoding: "none" },
  "published": { encoded: "published", encoding: "none" },
  "scheduled": { encoded: "scheduled", encoding: "none" },
  "expired": { encoded: "expired", encoding: "none" },
  "locked": { encoded: "locked", encoding: "none" },
  // Priorities (5 entries)
  "low": { encoded: "low", encoding: "none" },
  "medium": { encoded: "medium", encoding: "none" },
  "high": { encoded: "high", encoding: "none" },
  "urgent": { encoded: "urgent", encoding: "none" },
  "critical": { encoded: "critical", encoding: "none" },
  // Boolean variants (8 entries)
  "true": { encoded: "true", encoding: "none" },
  "false": { encoded: "false", encoding: "none" },
  "yes": { encoded: "yes", encoding: "none" },
  "no": { encoded: "no", encoding: "none" },
  "on": { encoded: "on", encoding: "none" },
  "off": { encoded: "off", encoding: "none" },
  "1": { encoded: "1", encoding: "none" },
  "0": { encoded: "0", encoding: "none" },
  // Common null-like values (4 entries)
  "null": { encoded: "null", encoding: "special" },
  "undefined": { encoded: "undefined", encoding: "special" },
  "none": { encoded: "none", encoding: "none" },
  "N/A": { encoded: "N/A", encoding: "none" }
};
function metadataEncode(value) {
  if (value === null) {
    return { encoded: "null", encoding: "special" };
  }
  if (value === void 0) {
    return { encoded: "undefined", encoding: "special" };
  }
  const stringValue = String(value);
  if (stringValue.startsWith("d:") || stringValue.startsWith("u:") || stringValue.startsWith("b:")) {
    return {
      encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
      encoding: "base64",
      reason: "force-encoded to prevent decoding ambiguity"
    };
  }
  const dictResult = dictionaryEncode(stringValue);
  if (dictResult && dictResult.savings > 0) {
    return {
      encoded: dictResult.encoded,
      encoding: "dictionary",
      dictionaryType: dictResult.dictionaryType,
      savings: dictResult.savings,
      compressionRatio: (dictResult.encodedLength / dictResult.originalLength).toFixed(3)
    };
  }
  if (COMMON_VALUES[stringValue]) {
    return COMMON_VALUES[stringValue];
  }
  const analysis = analyzeString(stringValue);
  switch (analysis.type) {
    case "none":
    case "ascii":
      return {
        encoded: stringValue,
        encoding: "none",
        analysis
      };
    case "url":
      return {
        encoded: "u:" + encodeURIComponent(stringValue),
        encoding: "url",
        analysis
      };
    case "base64":
      return {
        encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
        encoding: "base64",
        analysis
      };
    default:
      return {
        encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
        encoding: "base64",
        analysis
      };
  }
}
function metadataDecode(value) {
  if (value === "null") {
    return null;
  }
  if (value === "undefined") {
    return void 0;
  }
  if (value === null || value === void 0 || typeof value !== "string") {
    return value;
  }
  if (value.startsWith("d:")) {
    const decoded = dictionaryDecode(value);
    if (decoded !== null) {
      return decoded;
    }
  }
  if (value.length >= 2) {
    const firstChar = value.charCodeAt(0);
    const secondChar = value.charCodeAt(1);
    if (secondChar === 58) {
      if (firstChar === 117) {
        if (value.length === 2) return value;
        try {
          return decodeURIComponent(value.substring(2));
        } catch (err) {
          return value;
        }
      }
      if (firstChar === 98) {
        if (value.length === 2) return value;
        try {
          const decoded = Buffer.from(value.substring(2), "base64").toString("utf8");
          return decoded;
        } catch (err) {
          return value;
        }
      }
    }
  }
  return value;
}

const S3_METADATA_LIMIT = 2047;
class PluginStorage {
  /**
   * @param {Object} client - S3db Client instance
   * @param {string} pluginSlug - Plugin identifier (kebab-case)
   */
  constructor(client, pluginSlug) {
    if (!client) {
      throw new PluginStorageError("PluginStorage requires a client instance", {
        operation: "constructor",
        pluginSlug,
        suggestion: "Pass a valid S3db Client instance when creating PluginStorage"
      });
    }
    if (!pluginSlug) {
      throw new PluginStorageError("PluginStorage requires a pluginSlug", {
        operation: "constructor",
        suggestion: 'Provide a plugin slug (e.g., "eventual-consistency", "cache", "audit")'
      });
    }
    this.client = client;
    this.pluginSlug = pluginSlug;
  }
  /**
   * Generate hierarchical plugin-scoped key
   *
   * @param {string} resourceName - Resource name (optional, for resource-scoped data)
   * @param {...string} parts - Additional path parts
   * @returns {string} S3 key
   *
   * @example
   * // Resource-scoped: resource=wallets/plugin=eventual-consistency/balance/transactions/id=txn1
   * getPluginKey('wallets', 'balance', 'transactions', 'id=txn1')
   *
   * // Global plugin data: plugin=eventual-consistency/config
   * getPluginKey(null, 'config')
   */
  getPluginKey(resourceName, ...parts) {
    if (resourceName) {
      return `resource=${resourceName}/plugin=${this.pluginSlug}/${parts.join("/")}`;
    }
    return `plugin=${this.pluginSlug}/${parts.join("/")}`;
  }
  /**
   * Save data with metadata encoding, behavior support, and optional TTL
   *
   * @param {string} key - S3 key
   * @param {Object} data - Data to save
   * @param {Object} options - Options
   * @param {number} options.ttl - Time-to-live in seconds (optional)
   * @param {string} options.behavior - 'body-overflow' | 'body-only' | 'enforce-limits'
   * @param {string} options.contentType - Content type (default: application/json)
   * @returns {Promise<Object>} Underlying client response (includes ETag when available)
   */
  async set(key, data, options = {}) {
    const {
      ttl,
      behavior = "body-overflow",
      contentType = "application/json",
      ifMatch,
      ifNoneMatch
    } = options;
    const dataToSave = { ...data };
    if (ttl && typeof ttl === "number" && ttl > 0) {
      dataToSave._expiresAt = Date.now() + ttl * 1e3;
    }
    const { metadata, body } = this._applyBehavior(dataToSave, behavior);
    const putParams = {
      key,
      metadata,
      contentType
    };
    if (body !== null) {
      putParams.body = JSON.stringify(body);
    }
    if (ifMatch !== void 0) {
      putParams.ifMatch = ifMatch;
    }
    if (ifNoneMatch !== void 0) {
      putParams.ifNoneMatch = ifNoneMatch;
    }
    const [ok, err, response] = await tryFn(() => this.client.putObject(putParams));
    if (!ok) {
      throw new PluginStorageError(`Failed to save plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "set",
        behavior,
        ttl,
        original: err,
        suggestion: "Check S3 permissions and key format"
      });
    }
    return response;
  }
  /**
   * Batch set multiple items
   *
   * @param {Array<{key: string, data: Object, options?: Object}>} items - Items to save
   * @returns {Promise<Array<{ok: boolean, key: string, error?: Error}>>} Results
   */
  async batchSet(items) {
    const results = [];
    for (const item of items) {
      try {
        await this.set(item.key, item.data, item.options || {});
        results.push({ ok: true, key: item.key });
      } catch (error) {
        results.push({ ok: false, key: item.key, error });
      }
    }
    return results;
  }
  /**
   * Get data with automatic metadata decoding and TTL check
   *
   * @param {string} key - S3 key
   * @returns {Promise<Object|null>} Data or null if not found/expired
   */
  async get(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      if (err.name === "NoSuchKey" || err.Code === "NoSuchKey") {
        return null;
      }
      throw new PluginStorageError(`Failed to retrieve plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "get",
        original: err,
        suggestion: "Check if the key exists and S3 permissions are correct"
      });
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, parseErr, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        throw new PluginStorageError(`Failed to parse JSON body`, {
          pluginSlug: this.pluginSlug,
          key,
          operation: "get",
          original: parseErr,
          suggestion: "Body content may be corrupted. Check S3 object integrity"
        });
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (expiresAt) {
      if (Date.now() > expiresAt) {
        await this.delete(key);
        return null;
      }
      delete data._expiresat;
      delete data._expiresAt;
    }
    return data;
  }
  /**
   * Parse metadata values back to their original types
   * @private
   */
  _parseMetadataValues(metadata) {
    const parsed = {};
    for (const [key, value] of Object.entries(metadata)) {
      if (typeof value === "string") {
        if (value.startsWith("{") && value.endsWith("}") || value.startsWith("[") && value.endsWith("]")) {
          const [ok, err, result] = tryFn(() => JSON.parse(value));
          if (ok) {
            parsed[key] = result;
            continue;
          }
        }
        if (!isNaN(value) && value.trim() !== "") {
          parsed[key] = Number(value);
          continue;
        }
        if (value === "true") {
          parsed[key] = true;
          continue;
        }
        if (value === "false") {
          parsed[key] = false;
          continue;
        }
      }
      parsed[key] = value;
    }
    return parsed;
  }
  /**
   * List all keys with plugin prefix
   *
   * @param {string} prefix - Additional prefix (optional)
   * @param {Object} options - List options
   * @param {number} options.limit - Max number of results
   * @returns {Promise<Array<string>>} List of keys
   */
  async list(prefix = "", options = {}) {
    const { limit } = options;
    const fullPrefix = prefix ? `plugin=${this.pluginSlug}/${prefix}` : `plugin=${this.pluginSlug}/`;
    const [ok, err, result] = await tryFn(
      () => this.client.listObjects({ prefix: fullPrefix, maxKeys: limit })
    );
    if (!ok) {
      throw new PluginStorageError(`Failed to list plugin data`, {
        pluginSlug: this.pluginSlug,
        operation: "list",
        prefix,
        fullPrefix,
        limit,
        original: err,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    const keys = result.Contents?.map((item) => item.Key) || [];
    return this._removeKeyPrefix(keys);
  }
  /**
   * List keys for a specific resource
   *
   * @param {string} resourceName - Resource name
   * @param {string} subPrefix - Additional prefix within resource (optional)
   * @param {Object} options - List options
   * @returns {Promise<Array<string>>} List of keys
   */
  async listForResource(resourceName, subPrefix = "", options = {}) {
    const { limit } = options;
    const fullPrefix = subPrefix ? `resource=${resourceName}/plugin=${this.pluginSlug}/${subPrefix}` : `resource=${resourceName}/plugin=${this.pluginSlug}/`;
    const [ok, err, result] = await tryFn(
      () => this.client.listObjects({ prefix: fullPrefix, maxKeys: limit })
    );
    if (!ok) {
      throw new PluginStorageError(`Failed to list resource data`, {
        pluginSlug: this.pluginSlug,
        operation: "listForResource",
        resourceName,
        subPrefix,
        fullPrefix,
        limit,
        original: err,
        suggestion: "Check resource name and S3 permissions"
      });
    }
    const keys = result.Contents?.map((item) => item.Key) || [];
    return this._removeKeyPrefix(keys);
  }
  /**
   * Remove client keyPrefix from keys
   * @private
   */
  _removeKeyPrefix(keys) {
    const keyPrefix = this.client.config.keyPrefix;
    if (!keyPrefix) return keys;
    return keys.map((key) => key.replace(keyPrefix, "")).map((key) => key.startsWith("/") ? key.replace("/", "") : key);
  }
  /**
   * Check if a key exists (not expired)
   *
   * @param {string} key - S3 key
   * @returns {Promise<boolean>} True if exists and not expired
   */
  async has(key) {
    const data = await this.get(key);
    return data !== null;
  }
  /**
   * Check if a key is expired
   *
   * @param {string} key - S3 key
   * @returns {Promise<boolean>} True if expired or not found
   */
  async isExpired(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      return true;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, err2, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        return true;
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (!expiresAt) {
      return false;
    }
    return Date.now() > expiresAt;
  }
  /**
   * Get remaining TTL in seconds
   *
   * @param {string} key - S3 key
   * @returns {Promise<number|null>} Remaining seconds or null if no TTL/not found
   */
  async getTTL(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      return null;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, err2, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        return null;
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (!expiresAt) {
      return null;
    }
    const remaining = Math.max(0, expiresAt - Date.now());
    return Math.floor(remaining / 1e3);
  }
  /**
   * Extend TTL by adding additional seconds
   *
   * @param {string} key - S3 key
   * @param {number} additionalSeconds - Seconds to add to current TTL
   * @returns {Promise<boolean>} True if extended, false if not found or no TTL
   */
  async touch(key, additionalSeconds) {
    const [ok, err, response] = await tryFn(() => this.client.headObject(key));
    if (!ok) {
      return false;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    const expiresAt = parsedMetadata._expiresat || parsedMetadata._expiresAt;
    if (!expiresAt) {
      return false;
    }
    parsedMetadata._expiresAt = expiresAt + additionalSeconds * 1e3;
    delete parsedMetadata._expiresat;
    const encodedMetadata = {};
    for (const [metaKey, metaValue] of Object.entries(parsedMetadata)) {
      const { encoded } = metadataEncode(metaValue);
      encodedMetadata[metaKey] = encoded;
    }
    const [copyOk] = await tryFn(() => this.client.copyObject({
      from: key,
      to: key,
      metadata: encodedMetadata,
      metadataDirective: "REPLACE",
      contentType: response.ContentType || "application/json"
    }));
    return copyOk;
  }
  /**
   * Delete a single object
   *
   * @param {string} key - S3 key
   * @returns {Promise<void>}
   */
  async delete(key) {
    const [ok, err] = await tryFn(() => this.client.deleteObject(key));
    if (!ok) {
      throw new PluginStorageError(`Failed to delete plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "delete",
        original: err,
        suggestion: "Check S3 delete permissions"
      });
    }
  }
  /**
   * Delete all plugin data (for uninstall)
   *
   * @param {string} resourceName - Resource name (optional, if null deletes all plugin data)
   * @returns {Promise<number>} Number of objects deleted
   */
  async deleteAll(resourceName = null) {
    let deleted = 0;
    if (resourceName) {
      const keys = await this.listForResource(resourceName);
      for (const key of keys) {
        await this.delete(key);
        deleted++;
      }
    } else {
      const allKeys = await this.client.getAllKeys({});
      const pluginKeys = allKeys.filter(
        (key) => key.includes(`plugin=${this.pluginSlug}/`)
      );
      for (const key of pluginKeys) {
        await this.delete(key);
        deleted++;
      }
    }
    return deleted;
  }
  /**
   * Batch put operations
   *
   * @param {Array<{key: string, data: Object, options?: Object}>} items - Items to save
   * @returns {Promise<Array<{key: string, ok: boolean, error?: Error}>>} Results
   */
  async batchPut(items) {
    const results = [];
    for (const item of items) {
      const [ok, err] = await tryFn(
        () => this.put(item.key, item.data, item.options)
      );
      results.push({
        key: item.key,
        ok,
        error: err
      });
    }
    return results;
  }
  /**
   * Batch get operations
   *
   * @param {Array<string>} keys - Keys to fetch
   * @returns {Promise<Array<{key: string, ok: boolean, data?: Object, error?: Error}>>} Results
   */
  async batchGet(keys) {
    const results = [];
    for (const key of keys) {
      const [ok, err, data] = await tryFn(() => this.get(key));
      results.push({
        key,
        ok,
        data,
        error: err
      });
    }
    return results;
  }
  /**
   * Acquire a distributed lock with TTL and retry logic
   *
   * @param {string} lockName - Lock identifier
   * @param {Object} options - Lock options
   * @param {number} options.ttl - Lock TTL in seconds (default: 30)
   * @param {number} options.timeout - Max wait time in ms (default: 0, no wait)
   * @param {string} options.workerId - Worker identifier (default: 'unknown')
   * @returns {Promise<Object|null>} Lock object or null if couldn't acquire
   */
  async acquireLock(lockName, options = {}) {
    const {
      ttl = 30,
      timeout = 0,
      workerId = "unknown",
      retryDelay = 100,
      maxRetryDelay = 1e3
    } = options;
    const key = this.getPluginKey(null, "locks", lockName);
    const token = idGenerator();
    const startTime = Date.now();
    let attempt = 0;
    while (true) {
      const payload = {
        workerId,
        token,
        acquiredAt: Date.now()
      };
      const [ok, err, putResponse] = await tryFn(() => this.set(key, payload, {
        ttl,
        behavior: "body-only",
        ifNoneMatch: "*"
      }));
      if (ok) {
        return {
          name: lockName,
          key,
          token,
          workerId,
          expiresAt: Date.now() + ttl * 1e3,
          etag: putResponse?.ETag || null
        };
      }
      const originalError = err?.original || err;
      const errorCode = originalError?.code || originalError?.Code || originalError?.name;
      const statusCode = originalError?.statusCode || originalError?.$metadata?.httpStatusCode;
      const isPreconditionFailure = errorCode === "PreconditionFailed" || statusCode === 412;
      if (!isPreconditionFailure) {
        throw err;
      }
      if (timeout && Date.now() - startTime >= timeout) {
        return null;
      }
      const current = await this.get(key);
      if (!current) {
        continue;
      }
      attempt += 1;
      const delay = this._computeBackoff(attempt, retryDelay, maxRetryDelay);
      await this._sleep(delay);
    }
  }
  /**
   * Release a distributed lock
   *
   * @param {Object|string} lock - Lock object returned by acquireLock or lock name
   * @param {string} [token] - Lock token (required when passing lock name)
   * @returns {Promise<void>}
   */
  async releaseLock(lock, token) {
    if (!lock) return;
    let lockName;
    let key;
    let expectedToken = token;
    if (typeof lock === "object") {
      lockName = lock.name || lock.lockName;
      key = lock.key || (lockName ? this.getPluginKey(null, "locks", lockName) : null);
      expectedToken = lock.token ?? token;
      if (!expectedToken && lock.token !== void 0) {
        throw new PluginStorageError("Lock token missing on lock object", {
          pluginSlug: this.pluginSlug,
          operation: "releaseLock",
          lockName
        });
      }
    } else if (typeof lock === "string") {
      lockName = lock;
      key = this.getPluginKey(null, "locks", lockName);
      expectedToken = token;
      if (!expectedToken) {
        throw new PluginStorageError("releaseLock(lockName) now requires the lock token", {
          pluginSlug: this.pluginSlug,
          operation: "releaseLock",
          lockName,
          suggestion: "Pass the original lock object or provide the token explicitly"
        });
      }
    } else {
      throw new PluginStorageError("releaseLock expects a lock object or lock name", {
        pluginSlug: this.pluginSlug,
        operation: "releaseLock"
      });
    }
    if (!key) {
      throw new PluginStorageError("Invalid lock key", {
        pluginSlug: this.pluginSlug,
        operation: "releaseLock"
      });
    }
    const current = await this.get(key);
    if (!current) {
      return;
    }
    if (current.token !== void 0) {
      if (!expectedToken) {
        throw new PluginStorageError("releaseLock detected a stored token but none was provided", {
          pluginSlug: this.pluginSlug,
          operation: "releaseLock",
          lockName,
          suggestion: "Always release using the lock object returned by acquireLock"
        });
      }
      if (current.token !== expectedToken) {
        return;
      }
    }
    await this.delete(key);
  }
  /**
   * Acquire a lock, execute a callback, and release automatically.
   *
   * @param {string} lockName - Lock identifier
   * @param {Object} options - Options forwarded to acquireLock
   * @param {Function} callback - Async function to execute while holding the lock
   * @returns {Promise<*>} Callback result, or null when lock not acquired
   */
  async withLock(lockName, options, callback) {
    if (typeof callback !== "function") {
      throw new PluginStorageError("withLock requires a callback function", {
        pluginSlug: this.pluginSlug,
        operation: "withLock",
        lockName,
        suggestion: "Pass an async function as the third argument"
      });
    }
    const lock = await this.acquireLock(lockName, options);
    if (!lock) {
      return null;
    }
    try {
      return await callback(lock);
    } finally {
      await tryFn(() => this.releaseLock(lock));
    }
  }
  /**
   * Check if a lock is currently held
   *
   * @param {string} lockName - Lock identifier
   * @returns {Promise<boolean>} True if locked
   */
  async isLocked(lockName) {
    const key = this.getPluginKey(null, "locks", lockName);
    const lock = await this.get(key);
    return lock !== null;
  }
  _computeBackoff(attempt, baseDelay, maxDelay) {
    const exponential = Math.min(baseDelay * Math.pow(2, Math.max(attempt - 1, 0)), maxDelay);
    const jitter = Math.floor(Math.random() * Math.max(baseDelay / 2, 1));
    return exponential + jitter;
  }
  _sleep(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  /**
   * Increment a counter value
   *
   * Optimization: Uses HEAD + COPY for existing counters to avoid body transfer.
   * Falls back to GET + PUT for non-existent counters or those with additional data.
   *
   * @param {string} key - S3 key
   * @param {number} amount - Amount to increment (default: 1)
   * @param {Object} options - Options (e.g., ttl)
   * @returns {Promise<number>} New value
   */
  async increment(key, amount = 1, options = {}) {
    const [headOk, headErr, headResponse] = await tryFn(() => this.client.headObject(key));
    if (headOk && headResponse.Metadata) {
      const metadata = headResponse.Metadata || {};
      const parsedMetadata = this._parseMetadataValues(metadata);
      const currentValue = parsedMetadata.value || 0;
      const newValue = currentValue + amount;
      parsedMetadata.value = newValue;
      if (options.ttl) {
        parsedMetadata._expiresAt = Date.now() + options.ttl * 1e3;
      }
      const encodedMetadata = {};
      for (const [metaKey, metaValue] of Object.entries(parsedMetadata)) {
        const { encoded } = metadataEncode(metaValue);
        encodedMetadata[metaKey] = encoded;
      }
      const [copyOk] = await tryFn(() => this.client.copyObject({
        from: key,
        to: key,
        metadata: encodedMetadata,
        metadataDirective: "REPLACE",
        contentType: headResponse.ContentType || "application/json"
      }));
      if (copyOk) {
        return newValue;
      }
    }
    const data = await this.get(key);
    const value = (data?.value || 0) + amount;
    await this.set(key, { value }, options);
    return value;
  }
  /**
   * Decrement a counter value
   *
   * @param {string} key - S3 key
   * @param {number} amount - Amount to decrement (default: 1)
   * @param {Object} options - Options (e.g., ttl)
   * @returns {Promise<number>} New value
   */
  async decrement(key, amount = 1, options = {}) {
    return this.increment(key, -amount, options);
  }
  /**
   * Apply behavior to split data between metadata and body
   *
   * @private
   * @param {Object} data - Data to split
   * @param {string} behavior - Behavior strategy
   * @returns {{metadata: Object, body: Object|null}}
   */
  _applyBehavior(data, behavior) {
    const effectiveLimit = calculateEffectiveLimit({ s3Limit: S3_METADATA_LIMIT });
    let metadata = {};
    let body = null;
    switch (behavior) {
      case "body-overflow": {
        const entries = Object.entries(data);
        const sorted = entries.map(([key, value]) => {
          const jsonValue = typeof value === "object" ? JSON.stringify(value) : value;
          const { encoded } = metadataEncode(jsonValue);
          const keySize = calculateUTF8Bytes(key);
          const valueSize = calculateUTF8Bytes(encoded);
          return { key, value, jsonValue, encoded, size: keySize + valueSize };
        }).sort((a, b) => a.size - b.size);
        let currentSize = 0;
        for (const item of sorted) {
          if (currentSize + item.size <= effectiveLimit) {
            metadata[item.key] = item.jsonValue;
            currentSize += item.size;
          } else {
            if (body === null) body = {};
            body[item.key] = item.value;
          }
        }
        break;
      }
      case "body-only": {
        body = data;
        break;
      }
      case "enforce-limits": {
        let currentSize = 0;
        for (const [key, value] of Object.entries(data)) {
          const jsonValue = typeof value === "object" ? JSON.stringify(value) : value;
          const { encoded } = metadataEncode(jsonValue);
          const keySize = calculateUTF8Bytes(key);
          const valueSize = calculateUTF8Bytes(encoded);
          currentSize += keySize + valueSize;
          if (currentSize > effectiveLimit) {
            throw new MetadataLimitError(`Data exceeds metadata limit with enforce-limits behavior`, {
              totalSize: currentSize,
              effectiveLimit,
              absoluteLimit: S3_METADATA_LIMIT,
              excess: currentSize - effectiveLimit,
              operation: "PluginStorage.set",
              pluginSlug: this.pluginSlug,
              suggestion: "Use 'body-overflow' or 'body-only' behavior to handle large data"
            });
          }
          metadata[key] = jsonValue;
        }
        break;
      }
      default:
        throw new BehaviorError(`Unknown behavior: ${behavior}`, {
          behavior,
          availableBehaviors: ["body-overflow", "body-only", "enforce-limits"],
          operation: "PluginStorage._applyBehavior",
          pluginSlug: this.pluginSlug,
          suggestion: "Use 'body-overflow', 'body-only', or 'enforce-limits'"
        });
    }
    return { metadata, body };
  }
}

class Plugin extends EventEmitter {
  constructor(options = {}) {
    super();
    this.name = this.constructor.name;
    this.options = options;
    this.hooks = /* @__PURE__ */ new Map();
    this.baseSlug = options.slug || this._generateSlug();
    this.slug = this.baseSlug;
    this._storage = null;
    this.instanceName = null;
    this.namespace = null;
    this._namespaceExplicit = false;
    if (options.namespace || options.instanceId) {
      this.setNamespace(options.namespace || options.instanceId, { explicit: true });
    }
  }
  /**
   * Generate kebab-case slug from class name
   * @private
   * @returns {string}
   */
  _generateSlug() {
    return this.name.replace(/Plugin$/, "").replace(/([a-z])([A-Z])/g, "$1-$2").toLowerCase();
  }
  /**
   * Normalize namespace into kebab-case
   * @private
   */
  _normalizeNamespace(value) {
    if (value === null || value === void 0) return null;
    const text = String(value).trim();
    if (!text) return null;
    return text.toLowerCase().replace(/[^a-z0-9]+/g, "-").replace(/^-+/, "").replace(/-+$/, "") || null;
  }
  /**
   * Update plugin namespace (affects storage slug & helpers)
   * @param {string|null} value
   * @param {Object} options
   * @param {boolean} options.explicit - Whether namespace was set explicitly by the user
   */
  setNamespace(value, { explicit = false } = {}) {
    const normalized = this._normalizeNamespace(value);
    if (!normalized) {
      if (explicit) {
        this.namespace = null;
        this.slug = this.baseSlug;
        this._namespaceExplicit = true;
        this._storage = null;
        if (typeof this.onNamespaceChanged === "function") {
          this.onNamespaceChanged(this.namespace);
        }
      }
      return;
    }
    if (this.namespace === normalized && (explicit === false || this._namespaceExplicit)) {
      return;
    }
    this.namespace = normalized;
    if (explicit) {
      this._namespaceExplicit = true;
    }
    this.slug = `${this.baseSlug}--${normalized}`;
    this._storage = null;
    if (typeof this.onNamespaceChanged === "function") {
      this.onNamespaceChanged(this.namespace);
    }
  }
  /**
   * Set instance name (called by Database when registering the plugin)
   * Automatically derives namespace when not explicitly provided.
   */
  setInstanceName(name) {
    if (!name) return;
    this.instanceName = name;
    if (!this._namespaceExplicit) {
      const normalized = this._normalizeNamespace(name);
      if (normalized && normalized !== this.baseSlug) {
        this.setNamespace(normalized);
      }
    }
  }
  /**
   * Hook for subclasses to react to namespace changes
   * @param {string|null} namespace
   */
  // eslint-disable-next-line no-unused-vars
  onNamespaceChanged(namespace) {
  }
  /**
   * Get PluginStorage instance (lazy-loaded)
   * @returns {PluginStorage}
   */
  getStorage() {
    if (!this._storage) {
      if (!this.database || !this.database.client) {
        throw new PluginError("Plugin storage unavailable until plugin is installed", {
          pluginName: this.name,
          operation: "getStorage",
          statusCode: 400,
          retriable: false,
          suggestion: "Call db.installPlugin(new Plugin()) or ensure db.connect() completed before accessing storage."
        });
      }
      this._storage = new PluginStorage(this.database.client, this.slug);
    }
    return this._storage;
  }
  /**
   * Install plugin
   * @param {Database} database - Database instance
   */
  async install(database) {
    this.database = database;
    this.beforeInstall();
    await this.onInstall();
    this.afterInstall();
  }
  async start() {
    this.beforeStart();
    await this.onStart();
    this.afterStart();
  }
  async stop() {
    this.beforeStop();
    await this.onStop();
    this.afterStop();
  }
  /**
   * Uninstall plugin and cleanup all data
   * @param {Object} options - Uninstall options
   * @param {boolean} options.purgeData - Delete all plugin data from S3 (default: false)
   */
  async uninstall(options = {}) {
    const { purgeData = false } = options;
    this.beforeUninstall();
    await this.onUninstall(options);
    if (purgeData && this._storage) {
      const deleted = await this._storage.deleteAll();
      this.emit("plugin.dataPurged", { deleted });
    }
    this.afterUninstall();
  }
  // Override these methods in subclasses
  async onInstall() {
  }
  async onStart() {
  }
  async onStop() {
  }
  async onUninstall(options) {
  }
  // Hook management methods
  addHook(resource, event, handler) {
    if (!this.hooks.has(resource)) {
      this.hooks.set(resource, /* @__PURE__ */ new Map());
    }
    const resourceHooks = this.hooks.get(resource);
    if (!resourceHooks.has(event)) {
      resourceHooks.set(event, []);
    }
    resourceHooks.get(event).push(handler);
  }
  removeHook(resource, event, handler) {
    const resourceHooks = this.hooks.get(resource);
    if (resourceHooks && resourceHooks.has(event)) {
      const handlers = resourceHooks.get(event);
      const index = handlers.indexOf(handler);
      if (index > -1) {
        handlers.splice(index, 1);
      }
    }
  }
  // Enhanced resource method wrapping that supports multiple plugins
  wrapResourceMethod(resource, methodName, wrapper) {
    const originalMethod = resource[methodName];
    if (!resource._pluginWrappers) {
      resource._pluginWrappers = /* @__PURE__ */ new Map();
    }
    if (!resource._pluginWrappers.has(methodName)) {
      resource._pluginWrappers.set(methodName, []);
    }
    resource._pluginWrappers.get(methodName).push(wrapper);
    if (!resource[`_wrapped_${methodName}`]) {
      resource[`_wrapped_${methodName}`] = originalMethod;
      const isJestMock = originalMethod && originalMethod._isMockFunction;
      resource[methodName] = async function(...args) {
        let result = await resource[`_wrapped_${methodName}`](...args);
        for (const wrapper2 of resource._pluginWrappers.get(methodName)) {
          result = await wrapper2.call(this, result, args, methodName);
        }
        return result;
      };
      if (isJestMock) {
        Object.setPrototypeOf(resource[methodName], Object.getPrototypeOf(originalMethod));
        Object.assign(resource[methodName], originalMethod);
      }
    }
  }
  /**
   * Add a middleware to intercept a resource method (Koa/Express style).
   * Middleware signature: async (next, ...args) => { ... }
   * - Chame next(...args) para continuar a cadeia.
   * - Retorne sem chamar next para interromper.
   * - Pode modificar argumentos/resultados.
   */
  addMiddleware(resource, methodName, middleware) {
    if (typeof resource[methodName] !== "function") {
      throw new PluginError(`Cannot add middleware to "${methodName}"`, {
        pluginName: this.name,
        operation: "addMiddleware",
        statusCode: 400,
        retriable: false,
        suggestion: "Ensure the resource exposes the method before registering middleware.",
        resourceName: resource.name || "unknown",
        methodName
      });
    }
    if (!resource._pluginMiddlewares) {
      resource._pluginMiddlewares = {};
    }
    if (!resource._pluginMiddlewares[methodName]) {
      resource._pluginMiddlewares[methodName] = [];
      const originalMethod = resource[methodName].bind(resource);
      resource[methodName] = async function(...args) {
        let idx = -1;
        const next = async (...nextArgs) => {
          idx++;
          if (idx < resource._pluginMiddlewares[methodName].length) {
            return await resource._pluginMiddlewares[methodName][idx].call(this, next, ...nextArgs);
          } else {
            return await originalMethod(...nextArgs);
          }
        };
        return await next(...args);
      };
    }
    resource._pluginMiddlewares[methodName].push(middleware);
  }
  // Partition-aware helper methods
  getPartitionValues(data, resource) {
    if (!resource.config?.partitions) return {};
    const partitionValues = {};
    for (const [partitionName, partitionDef] of Object.entries(resource.config.partitions)) {
      if (partitionDef.fields) {
        partitionValues[partitionName] = {};
        for (const [fieldName, rule] of Object.entries(partitionDef.fields)) {
          const value = this.getNestedFieldValue(data, fieldName);
          if (value !== null && value !== void 0) {
            partitionValues[partitionName][fieldName] = resource.applyPartitionRule(value, rule);
          }
        }
      } else {
        partitionValues[partitionName] = {};
      }
    }
    return partitionValues;
  }
  getNestedFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data[fieldPath] ?? null;
    }
    const keys = fieldPath.split(".");
    let value = data;
    for (const key of keys) {
      if (value && typeof value === "object" && key in value) {
        value = value[key];
      } else {
        return null;
      }
    }
    return value ?? null;
  }
  // Event emission methods
  beforeInstall() {
    this.emit("plugin.beforeInstall", /* @__PURE__ */ new Date());
  }
  afterInstall() {
    this.emit("plugin.afterInstall", /* @__PURE__ */ new Date());
  }
  beforeStart() {
    this.emit("plugin.beforeStart", /* @__PURE__ */ new Date());
  }
  afterStart() {
    this.emit("plugin.afterStart", /* @__PURE__ */ new Date());
  }
  beforeStop() {
    this.emit("plugin.beforeStop", /* @__PURE__ */ new Date());
  }
  afterStop() {
    this.emit("plugin.afterStop", /* @__PURE__ */ new Date());
  }
  beforeUninstall() {
    this.emit("plugin.beforeUninstall", /* @__PURE__ */ new Date());
  }
  afterUninstall() {
    this.emit("plugin.afterUninstall", /* @__PURE__ */ new Date());
  }
}

const PluginObject = {
  setup(database) {
  },
  start() {
  },
  stop() {
  }
};

const PLUGIN_DEPENDENCIES = {
  "postgresql-replicator": {
    name: "PostgreSQL Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "pg": {
        version: "^8.0.0",
        description: "PostgreSQL client for Node.js",
        installCommand: "pnpm add pg",
        npmUrl: "https://www.npmjs.com/package/pg"
      }
    }
  },
  "bigquery-replicator": {
    name: "BigQuery Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "@google-cloud/bigquery": {
        version: "^7.0.0",
        description: "Google Cloud BigQuery SDK",
        installCommand: "pnpm add @google-cloud/bigquery",
        npmUrl: "https://www.npmjs.com/package/@google-cloud/bigquery"
      }
    }
  },
  "sqs-replicator": {
    name: "SQS Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "@aws-sdk/client-sqs": {
        version: "^3.0.0",
        description: "AWS SDK for SQS",
        installCommand: "pnpm add @aws-sdk/client-sqs",
        npmUrl: "https://www.npmjs.com/package/@aws-sdk/client-sqs"
      }
    }
  },
  "sqs-consumer": {
    name: "SQS Queue Consumer",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue-consumer.md",
    dependencies: {
      "@aws-sdk/client-sqs": {
        version: "^3.0.0",
        description: "AWS SDK for SQS",
        installCommand: "pnpm add @aws-sdk/client-sqs",
        npmUrl: "https://www.npmjs.com/package/@aws-sdk/client-sqs"
      }
    }
  },
  "rabbitmq-consumer": {
    name: "RabbitMQ Queue Consumer",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue-consumer.md",
    dependencies: {
      "amqplib": {
        version: "^0.10.0",
        description: "AMQP 0-9-1 library for RabbitMQ",
        installCommand: "pnpm add amqplib",
        npmUrl: "https://www.npmjs.com/package/amqplib"
      }
    }
  },
  "tfstate-plugin": {
    name: "Tfstate Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/tfstate.md",
    dependencies: {
      "node-cron": {
        version: "^4.0.0",
        description: "Cron job scheduler for auto-sync functionality",
        installCommand: "pnpm add node-cron",
        npmUrl: "https://www.npmjs.com/package/node-cron"
      }
    }
  },
  "api-plugin": {
    name: "API Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/api.md",
    dependencies: {
      "hono": {
        version: "^4.0.0",
        description: "Ultra-light HTTP server framework",
        installCommand: "pnpm add hono",
        npmUrl: "https://www.npmjs.com/package/hono"
      },
      "@hono/node-server": {
        version: "^1.0.0",
        description: "Node.js adapter for Hono",
        installCommand: "pnpm add @hono/node-server",
        npmUrl: "https://www.npmjs.com/package/@hono/node-server"
      },
      "@hono/swagger-ui": {
        version: "^0.4.0",
        description: "Swagger UI integration for Hono",
        installCommand: "pnpm add @hono/swagger-ui",
        npmUrl: "https://www.npmjs.com/package/@hono/swagger-ui"
      },
      "jose": {
        version: "^5.0.0 || ^6.0.0",
        description: "Universal JOSE and JWE implementation (for OAuth2 token validation)",
        installCommand: "pnpm add jose",
        npmUrl: "https://www.npmjs.com/package/jose"
      }
    }
  },
  "identity-plugin": {
    name: "Identity Provider Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/identity.md",
    dependencies: {
      "hono": {
        version: "^4.0.0",
        description: "Ultra-light HTTP server framework",
        installCommand: "pnpm add hono",
        npmUrl: "https://www.npmjs.com/package/hono"
      },
      "@hono/node-server": {
        version: "^1.0.0",
        description: "Node.js adapter for Hono",
        installCommand: "pnpm add @hono/node-server",
        npmUrl: "https://www.npmjs.com/package/@hono/node-server"
      },
      "jose": {
        version: "^5.0.0 || ^6.0.0",
        description: "Universal JOSE and JWE implementation (for RSA key generation and JWT signing)",
        installCommand: "pnpm add jose",
        npmUrl: "https://www.npmjs.com/package/jose"
      },
      "bcrypt": {
        version: "^5.1.0 || ^6.0.0",
        description: "Secure password hashing library",
        installCommand: "pnpm add bcrypt",
        npmUrl: "https://www.npmjs.com/package/bcrypt"
      },
      "nodemailer": {
        version: "^6.9.0 || ^7.0.0",
        description: "Email sending library for password reset and verification",
        installCommand: "pnpm add nodemailer",
        npmUrl: "https://www.npmjs.com/package/nodemailer"
      }
    }
  },
  "cloud-inventory-plugin": {
    name: "Cloud Inventory Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/cloud-inventory.md",
    dependencies: {
      "node-cron": {
        version: "^4.0.0",
        description: "Cron scheduler for automated discovery",
        installCommand: "pnpm add -D node-cron",
        npmUrl: "https://www.npmjs.com/package/node-cron"
      }
    }
  },
  "ml-plugin": {
    name: "ML Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/ml-plugin.md",
    dependencies: {
      "@tensorflow/tfjs-node": {
        version: "^4.0.0",
        description: "TensorFlow.js for Node.js with native bindings",
        installCommand: "pnpm add @tensorflow/tfjs-node",
        npmUrl: "https://www.npmjs.com/package/@tensorflow/tfjs-node"
      }
    }
  },
  "puppeteer": {
    name: "Puppeteer Suite",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/puppeteer/README.md",
    dependencies: {
      "puppeteer-extra": {
        version: "^3.3.4",
        description: "Headless Chrome automation toolkit",
        installCommand: "pnpm add puppeteer-extra",
        npmUrl: "https://www.npmjs.com/package/puppeteer-extra"
      },
      "puppeteer-extra-plugin-stealth": {
        version: "^2.11.2",
        description: "Stealth plugin to evade bot detection",
        installCommand: "pnpm add puppeteer-extra-plugin-stealth",
        npmUrl: "https://www.npmjs.com/package/puppeteer-extra-plugin-stealth"
      },
      "user-agents": {
        version: "^2.0.0",
        description: "Randomized user agent generator",
        installCommand: "pnpm add user-agents",
        npmUrl: "https://www.npmjs.com/package/user-agents"
      },
      "ghost-cursor": {
        version: "^1.4.1",
        description: "Human-like mouse movement generator",
        installCommand: "pnpm add ghost-cursor",
        npmUrl: "https://www.npmjs.com/package/ghost-cursor"
      }
    }
  },
  "puppeteer-extra": {
    name: "puppeteer-extra",
    docsUrl: "https://github.com/berstend/puppeteer-extra",
    dependencies: {}
  },
  "puppeteer-extra-plugin-stealth": {
    name: "puppeteer-extra-plugin-stealth",
    docsUrl: "https://github.com/berstend/puppeteer-extra/tree/master/packages/puppeteer-extra-plugin-stealth",
    dependencies: {}
  },
  "user-agents": {
    name: "user-agents",
    docsUrl: "https://github.com/intoli/user-agents",
    dependencies: {}
  },
  "ghost-cursor": {
    name: "ghost-cursor",
    docsUrl: "https://github.com/Xetera/ghost-cursor",
    dependencies: {}
  }
};
function isVersionCompatible(actual, required) {
  if (!actual || !required) return false;
  if (required.includes("||")) {
    const ranges = required.split("||").map((r) => r.trim());
    return ranges.some((range) => isVersionCompatible(actual, range));
  }
  const cleanRequired = required.replace(/^[\^~]/, "");
  const actualMajor = parseInt(actual.split(".")[0], 10);
  const requiredMajor = parseInt(cleanRequired.split(".")[0], 10);
  if (required.startsWith("^")) {
    return actualMajor === requiredMajor;
  }
  if (required.startsWith("~")) {
    const actualMinor = parseInt(actual.split(".")[1] || "0", 10);
    const requiredMinor = parseInt(cleanRequired.split(".")[1] || "0", 10);
    return actualMajor === requiredMajor && actualMinor >= requiredMinor;
  }
  return actualMajor >= requiredMajor;
}
async function tryLoadPackage(packageName) {
  try {
    const pkg = await import(packageName);
    let version = null;
    try {
      const pkgJson = await import(`${packageName}/package.json`, { assert: { type: 'json' } });
      version = pkgJson.default?.version || pkgJson.version || null;
    } catch (e) {
      version = "unknown";
    }
    return { installed: true, version, error: null };
  } catch (error) {
    return { installed: false, version: null, error };
  }
}
async function requirePluginDependency(pluginId, options = {}) {
  const {
    throwOnError = true,
    checkVersions = true
  } = options;
  const pluginDef = PLUGIN_DEPENDENCIES[pluginId];
  if (!pluginDef) {
    const error = new Error(
      `Unknown plugin identifier: ${pluginId}. Available plugins: ${Object.keys(PLUGIN_DEPENDENCIES).join(", ")}`
    );
    if (throwOnError) throw error;
    return { valid: false, missing: [], incompatible: [], messages: [error.message] };
  }
  if (process?.env?.S3DB_SKIP_PLUGIN_DEP_CHECK === "1") {
    return { valid: true, missing: [], incompatible: [], messages: [] };
  }
  const missing = [];
  const incompatible = [];
  const messages = [];
  for (const [pkgName, pkgInfo] of Object.entries(pluginDef.dependencies)) {
    const { installed, version, error } = await tryLoadPackage(pkgName);
    if (!installed) {
      missing.push(pkgName);
      messages.push(
        `\u274C Missing dependency: ${pkgName}
   Description: ${pkgInfo.description}
   Required: ${pkgInfo.version}
   Install: ${pkgInfo.installCommand}`
      );
      continue;
    }
    if (checkVersions && version && version !== "unknown") {
      const compatible = isVersionCompatible(version, pkgInfo.version);
      if (!compatible) {
        incompatible.push(pkgName);
        messages.push(
          `\u26A0\uFE0F  Incompatible version: ${pkgName}
   Installed: ${version}
   Required: ${pkgInfo.version}
   Update: ${pkgInfo.installCommand}`
        );
      } else {
        messages.push(
          `\u2705 ${pkgName}@${version} (compatible with ${pkgInfo.version})`
        );
      }
    } else {
      messages.push(
        `\u2705 ${pkgName}@${version || "unknown"} (installed)`
      );
    }
  }
  const valid = missing.length === 0 && incompatible.length === 0;
  if (!valid && throwOnError) {
    const depCount = Object.keys(pluginDef.dependencies).length;
    const missingCount = missing.length;
    const incompatCount = incompatible.length;
    const errorMsg = [
      "",
      "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557",
      `\u2551  \u274C ${pluginDef.name} - Missing Dependencies  \u2551`,
      "\u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D",
      "",
      `\u{1F4E6} Plugin: ${pluginId}`,
      `\u{1F4CA} Status: ${depCount - missingCount - incompatCount}/${depCount} dependencies satisfied`,
      "",
      "\u{1F50D} Dependency Status:",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
      ...messages,
      "",
      "\u{1F680} Quick Fix - Install Missing Dependencies:",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
      "",
      "  Option 1: Install individually",
      ...Object.entries(pluginDef.dependencies).filter(([pkg]) => missing.includes(pkg) || incompatible.includes(pkg)).map(([pkg, info]) => `    ${info.installCommand}`),
      "",
      "  Option 2: Install all at once",
      `    pnpm add ${Object.keys(pluginDef.dependencies).join(" ")}`,
      "",
      "\u{1F4DA} Documentation:",
      `    ${pluginDef.docsUrl}`,
      "",
      "\u{1F4A1} Troubleshooting:",
      "  \u2022 If packages are installed but not detected, try:",
      "    1. Delete node_modules and reinstall: rm -rf node_modules && pnpm install",
      "    2. Check Node.js version: node --version (requires Node 18+)",
      "    3. Verify pnpm version: pnpm --version (requires pnpm 8+)",
      "",
      "  \u2022 Still having issues? Check:",
      "    - Package.json has correct dependencies listed",
      "    - No conflicting versions in pnpm-lock.yaml",
      "    - File permissions (especially in node_modules/)",
      "",
      "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
      ""
    ].join("\n");
    const error = new Error(errorMsg);
    error.pluginId = pluginId;
    error.pluginName = pluginDef.name;
    error.missing = missing;
    error.incompatible = incompatible;
    error.docsUrl = pluginDef.docsUrl;
    throw error;
  }
  return { valid, missing, incompatible, messages };
}

function success$1(data, options = {}) {
  const { status = 200, meta = {} } = options;
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      ...meta
    },
    _status: status
  };
}
function error$1(error2, options = {}) {
  const { status = 500, code = "INTERNAL_ERROR", details = {} } = options;
  const errorMessage = error2 instanceof Error ? error2.message : error2;
  const errorStack = error2 instanceof Error && process.env.NODE_ENV !== "production" ? error2.stack : void 0;
  return {
    success: false,
    error: {
      message: errorMessage,
      code,
      details,
      stack: errorStack
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: status
  };
}
function list(items, pagination = {}) {
  const { total, page, pageSize, pageCount } = pagination;
  return {
    success: true,
    data: items,
    pagination: {
      total: total || items.length,
      page: page || 1,
      pageSize: pageSize || items.length,
      pageCount: pageCount || 1
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: 200
  };
}
function created(data, location) {
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      location
    },
    _status: 201
  };
}
function noContent() {
  return {
    success: true,
    data: null,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: 204
  };
}
function validationError(errors) {
  return error$1("Validation failed", {
    status: 400,
    code: "VALIDATION_ERROR",
    details: { errors }
  });
}
function notFound(resource, id) {
  return error$1(`${resource} with id '${id}' not found`, {
    status: 404,
    code: "NOT_FOUND",
    details: { resource, id }
  });
}
function unauthorized(message = "Unauthorized") {
  return error$1(message, {
    status: 401,
    code: "UNAUTHORIZED"
  });
}

const errorStatusMap$1 = {
  "ValidationError": 400,
  "InvalidResourceItem": 400,
  "ResourceNotFound": 404,
  "NoSuchKey": 404,
  "NoSuchBucket": 404,
  "PartitionError": 400,
  "CryptoError": 500,
  "SchemaError": 400,
  "QueueError": 500,
  "ResourceError": 500
};
function getStatusFromError$1(err) {
  if (err.name && errorStatusMap$1[err.name]) {
    return errorStatusMap$1[err.name];
  }
  if (err.constructor && err.constructor.name && errorStatusMap$1[err.constructor.name]) {
    return errorStatusMap$1[err.constructor.name];
  }
  if (err.message) {
    if (err.message.includes("not found") || err.message.includes("does not exist")) {
      return 404;
    }
    if (err.message.includes("validation") || err.message.includes("invalid")) {
      return 400;
    }
    if (err.message.includes("unauthorized") || err.message.includes("authentication")) {
      return 401;
    }
    if (err.message.includes("forbidden") || err.message.includes("permission")) {
      return 403;
    }
  }
  return 500;
}
function errorHandler$1(err, c) {
  const status = getStatusFromError$1(err);
  const code = err.name || "INTERNAL_ERROR";
  const details = {};
  if (err.resource) details.resource = err.resource;
  if (err.bucket) details.bucket = err.bucket;
  if (err.key) details.key = err.key;
  if (err.operation) details.operation = err.operation;
  if (err.suggestion) details.suggestion = err.suggestion;
  if (err.availableResources) details.availableResources = err.availableResources;
  const response = error$1(err, {
    status,
    code,
    details
  });
  if (status >= 500) {
    console.error("[API Plugin] Error:", {
      message: err.message,
      code,
      status,
      stack: err.stack,
      details
    });
  } else if (status >= 400 && status < 500 && c.get("verbose")) {
    console.warn("[API Plugin] Client error:", {
      message: err.message,
      code,
      status,
      details
    });
  }
  return c.json(response, response._status);
}
function asyncHandler(fn) {
  return async (c) => {
    try {
      return await fn(c);
    } catch (err) {
      return errorHandler$1(err, c);
    }
  };
}

function checkGuard(ctxOrUser, guard, recordOrContext = null) {
  if (!guard) {
    return true;
  }
  const isRouteContext = ctxOrUser && typeof ctxOrUser === "object" && ("user" in ctxOrUser || "_currentResource" in ctxOrUser);
  const ctx = isRouteContext ? ctxOrUser : null;
  const user = isRouteContext ? ctxOrUser.user : ctxOrUser;
  const record = isRouteContext ? recordOrContext : null;
  const legacyContext = isRouteContext ? {} : recordOrContext || {};
  if (!user && guard !== true) {
    return false;
  }
  if (typeof guard === "boolean") {
    return guard;
  }
  if (typeof guard === "function") {
    try {
      if (ctx) {
        const guardLength = guard.length;
        if (guardLength >= 2 && record !== null) {
          return guard(ctx, record);
        } else {
          return guard(ctx);
        }
      } else {
        return guard(user, legacyContext);
      }
    } catch (err) {
      console.error("[Guards] Error executing guard function:", err);
      return false;
    }
  }
  if (typeof guard === "string") {
    return hasScope(user, guard);
  }
  if (Array.isArray(guard)) {
    return guard.some((scope) => hasScope(user, scope));
  }
  if (typeof guard === "object") {
    if (guard.role) {
      if (Array.isArray(guard.role)) {
        if (!guard.role.includes(user.role)) {
          return false;
        }
      } else if (user.role !== guard.role) {
        return false;
      }
    }
    if (guard.scopes) {
      const requiredScopes = Array.isArray(guard.scopes) ? guard.scopes : [guard.scopes];
      if (!requiredScopes.every((scope) => hasScope(user, scope))) {
        return false;
      }
    }
    if (guard.check && typeof guard.check === "function") {
      try {
        if (ctx) {
          return guard.check(ctx, record);
        } else {
          return guard.check(user, legacyContext);
        }
      } catch (err) {
        console.error("[Guards] Error executing guard.check function:", err);
        return false;
      }
    }
    return true;
  }
  return false;
}
function hasScope(user, scope) {
  if (!user || !user.scopes) {
    return false;
  }
  if (!Array.isArray(user.scopes)) {
    return false;
  }
  if (user.scopes.includes(scope)) {
    return true;
  }
  const wildcards = user.scopes.filter((s) => s.endsWith(":*"));
  for (const wildcard of wildcards) {
    const prefix = wildcard.slice(0, -2);
    if (scope.startsWith(prefix + ":")) {
      return true;
    }
  }
  if (user.scopes.includes("*")) {
    return true;
  }
  return false;
}
function getOperationGuard(guards, operation) {
  if (!guards) {
    return null;
  }
  if (typeof guards === "function" || typeof guards === "string" || Array.isArray(guards)) {
    return guards;
  }
  if (typeof guards === "object") {
    if (guards[operation] !== void 0) {
      return guards[operation];
    }
    if (guards.all !== void 0) {
      return guards.all;
    }
    const aliases = {
      list: "read",
      get: "read",
      create: "write",
      update: "write",
      delete: "write"
    };
    if (aliases[operation] && guards[aliases[operation]] !== void 0) {
      return guards[aliases[operation]];
    }
  }
  return null;
}
function guardMiddleware(guards, operation, options = {}) {
  return async (c, next) => {
    const { RouteContext } = await Promise.resolve().then(function () { return routeContext; });
    const legacyContext = c.get("customRouteContext") || {};
    const { database, resource, plugins = {} } = { ...legacyContext, ...options };
    const ctx = new RouteContext(c, database, resource, plugins);
    const guard = getOperationGuard(guards, operation);
    const authorized = checkGuard(ctx, guard, null);
    if (!authorized) {
      return c.json({
        success: false,
        error: {
          message: "Forbidden: Insufficient permissions",
          code: "FORBIDDEN",
          details: {
            operation,
            user: ctx.user ? { id: ctx.user.id, role: ctx.user.role } : null
          }
        },
        _status: 403
      }, 403);
    }
    if (ctx.hasPartitionFilters()) {
      c.set("partitionFilters", ctx.getPartitionFilters());
    }
    await next();
  };
}

function parseCustomRoute(routeDef) {
  let def = routeDef.trim();
  const isAsync = def.startsWith("async ");
  if (isAsync) {
    def = def.substring(6).trim();
  }
  const parts = def.split(/\s+/);
  if (parts.length < 2) {
    throw new Error(`Invalid route definition: "${routeDef}". Expected format: "METHOD /path" or "async METHOD /path"`);
  }
  const method = parts[0].toUpperCase();
  const path = parts.slice(1).join(" ").trim();
  const validMethods = ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"];
  if (!validMethods.includes(method)) {
    throw new Error(`Invalid HTTP method: "${method}". Must be one of: ${validMethods.join(", ")}`);
  }
  if (!path.startsWith("/")) {
    throw new Error(`Invalid route path: "${path}". Path must start with "/"`);
  }
  return { method, path, isAsync };
}
function createResourceRoutes(resource, version, config = {}, Hono) {
  const app = new Hono();
  const {
    methods = ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"],
    customMiddleware = [],
    enableValidation = true,
    versionPrefix = "",
    // Empty string by default (calculated in server.js)
    events = null
    // Event emitter for lifecycle hooks
  } = config;
  const resourceName = resource.name;
  const basePath = versionPrefix ? `/${versionPrefix}/${resourceName}` : `/${resourceName}`;
  const guards = resource.config?.guards || null;
  customMiddleware.forEach((middleware) => {
    app.use("*", middleware);
  });
  if (resource.config?.api && typeof resource.config.api === "object") {
    for (const [routeDef, handler] of Object.entries(resource.config.api)) {
      try {
        const { method, path } = parseCustomRoute(routeDef);
        if (typeof handler !== "function") {
          throw new Error(`Handler for route "${routeDef}" must be a function`);
        }
        app.on(method, path, asyncHandler(async (c) => {
          const result = await handler(c, { resource, database: resource.database });
          if (result && result.constructor && result.constructor.name === "Response") {
            return result;
          }
          if (result !== void 0 && result !== null) {
            return c.json(success$1(result));
          }
          return c.json(noContent(), 204);
        }));
        if (config.verbose || resource.database?.verbose) {
          console.log(`[API Plugin] Registered custom route for ${resourceName}: ${method} ${path}`);
        }
      } catch (error) {
        console.error(`[API Plugin] Error registering custom route "${routeDef}" for ${resourceName}:`, error.message);
        throw error;
      }
    }
  }
  if (methods.includes("GET")) {
    app.get("/", guardMiddleware(guards, "list"), asyncHandler(async (c) => {
      const query = c.req.query();
      const limit = parseInt(query.limit) || 100;
      const offset = parseInt(query.offset) || 0;
      const partition = query.partition;
      const partitionValues = query.partitionValues ? JSON.parse(query.partitionValues) : void 0;
      const reservedKeys = ["limit", "offset", "partition", "partitionValues", "sort"];
      const filters = {};
      for (const [key, value] of Object.entries(query)) {
        if (!reservedKeys.includes(key)) {
          try {
            filters[key] = JSON.parse(value);
          } catch {
            filters[key] = value;
          }
        }
      }
      const guardPartitionFilters = c.get("partitionFilters") || [];
      let items;
      let total;
      if (guardPartitionFilters.length > 0) {
        const { partitionName, partitionFields } = guardPartitionFilters[0];
        items = await resource.listPartition(partitionName, partitionFields, { limit, offset });
        total = items.length;
      } else if (Object.keys(filters).length > 0) {
        items = await resource.query(filters, { limit, offset });
        total = items.length;
      } else if (partition && partitionValues) {
        items = await resource.listPartition({
          partition,
          partitionValues,
          limit,
          offset
        });
        total = items.length;
      } else {
        items = await resource.list({ limit, offset });
        total = items.length;
      }
      const response = list(items, {
        total,
        page: Math.floor(offset / limit) + 1,
        pageSize: limit,
        pageCount: Math.ceil(total / limit)
      });
      c.header("X-Total-Count", total.toString());
      c.header("X-Page-Count", Math.ceil(total / limit).toString());
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("GET")) {
    app.get("/:id", guardMiddleware(guards, "get"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const query = c.req.query();
      const partition = query.partition;
      const partitionValues = query.partitionValues ? JSON.parse(query.partitionValues) : void 0;
      let item;
      if (partition && partitionValues) {
        item = await resource.getFromPartition({
          id,
          partitionName: partition,
          partitionValues
        });
      } else {
        item = await resource.get(id);
      }
      if (!item) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const response = success$1(item);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("POST")) {
    app.post("/", guardMiddleware(guards, "create"), asyncHandler(async (c) => {
      const data = await c.req.json();
      const item = await resource.insert(data);
      if (events) {
        events.emitResourceEvent("created", {
          resource: resourceName,
          id: item.id,
          data: item,
          user: c.get("user")
        });
      }
      const location = `${basePath}/${item.id}`;
      const response = created(item, location);
      c.header("Location", location);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("PUT")) {
    app.put("/:id", guardMiddleware(guards, "update"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const data = await c.req.json();
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const updated = await resource.update(id, data);
      if (events) {
        events.emitResourceEvent("updated", {
          resource: resourceName,
          id: updated.id,
          data: updated,
          previous: existing,
          user: c.get("user")
        });
      }
      const response = success$1(updated);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("PATCH")) {
    app.patch("/:id", guardMiddleware(guards, "update"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const data = await c.req.json();
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const merged = { ...existing, ...data, id };
      const updated = await resource.update(id, merged);
      if (events) {
        events.emitResourceEvent("updated", {
          resource: resourceName,
          id: updated.id,
          data: updated,
          previous: existing,
          partial: true,
          user: c.get("user")
        });
      }
      const response = success$1(updated);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("DELETE")) {
    app.delete("/:id", guardMiddleware(guards, "delete"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      await resource.delete(id);
      if (events) {
        events.emitResourceEvent("deleted", {
          resource: resourceName,
          id,
          previous: existing,
          user: c.get("user")
        });
      }
      const response = noContent();
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("HEAD")) {
    app.on("HEAD", "/", asyncHandler(async (c) => {
      const total = await resource.count();
      const version2 = resource.config?.currentVersion || resource.version || "v1";
      c.header("X-Total-Count", total.toString());
      c.header("X-Resource-Version", version2);
      c.header("X-Schema-Fields", Object.keys(resource.config?.attributes || {}).length.toString());
      return c.body(null, 200);
    }));
    app.on("HEAD", "/:id", asyncHandler(async (c) => {
      const id = c.req.param("id");
      const item = await resource.get(id);
      if (!item) {
        return c.body(null, 404);
      }
      if (item.updatedAt) {
        c.header("Last-Modified", new Date(item.updatedAt).toUTCString());
      }
      return c.body(null, 200);
    }));
  }
  if (methods.includes("OPTIONS")) {
    app.options("/", asyncHandler(async (c) => {
      c.header("Allow", methods.join(", "));
      const total = await resource.count();
      const schema = resource.config?.attributes || {};
      const version2 = resource.config?.currentVersion || resource.version || "v1";
      const metadata = {
        resource: resourceName,
        version: version2,
        totalRecords: total,
        allowedMethods: methods,
        schema: Object.entries(schema).map(([name, def]) => ({
          name,
          type: typeof def === "string" ? def.split("|")[0] : def.type,
          rules: typeof def === "string" ? def.split("|").slice(1) : []
        })),
        endpoints: {
          list: `/${version2}/${resourceName}`,
          get: `/${version2}/${resourceName}/:id`,
          create: `/${version2}/${resourceName}`,
          update: `/${version2}/${resourceName}/:id`,
          delete: `/${version2}/${resourceName}/:id`
        },
        queryParameters: {
          limit: "number (1-1000, default: 100)",
          offset: "number (min: 0, default: 0)",
          partition: "string (partition name)",
          partitionValues: "JSON string",
          "[any field]": "any (filter by field value)"
        }
      };
      return c.json(metadata);
    }));
    app.options("/:id", (c) => {
      c.header("Allow", methods.filter((m) => m !== "POST").join(", "));
      return c.body(null, 204);
    });
  }
  return app;
}
function createRelationalRoutes(sourceResource, relationName, relationConfig, version, Hono) {
  const app = new Hono();
  const resourceName = sourceResource.name;
  const relatedResourceName = relationConfig.resource;
  app.get("/", asyncHandler(async (c) => {
    const pathParts = c.req.path.split("/");
    const relationNameIndex = pathParts.lastIndexOf(relationName);
    const id = pathParts[relationNameIndex - 1];
    const query = c.req.query();
    const source = await sourceResource.get(id);
    if (!source) {
      const response = notFound(resourceName, id);
      return c.json(response, response._status);
    }
    const result = await sourceResource.get(id, {
      include: [relationName]
    });
    const relatedData = result[relationName];
    if (!relatedData) {
      if (relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany") {
        const response = list([], {
          total: 0,
          page: 1,
          pageSize: 100,
          pageCount: 0
        });
        return c.json(response, response._status);
      } else {
        const response = notFound(relatedResourceName, "related resource");
        return c.json(response, response._status);
      }
    }
    if (relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany") {
      const items = Array.isArray(relatedData) ? relatedData : [relatedData];
      const limit = parseInt(query.limit) || 100;
      const offset = parseInt(query.offset) || 0;
      const paginatedItems = items.slice(offset, offset + limit);
      const response = list(paginatedItems, {
        total: items.length,
        page: Math.floor(offset / limit) + 1,
        pageSize: limit,
        pageCount: Math.ceil(items.length / limit)
      });
      c.header("X-Total-Count", items.length.toString());
      c.header("X-Page-Count", Math.ceil(items.length / limit).toString());
      return c.json(response, response._status);
    } else {
      const response = success$1(relatedData);
      return c.json(response, response._status);
    }
  }));
  return app;
}

function createToken(payload, secret, expiresIn = "7d") {
  const match = expiresIn.match(/^(\d+)([smhd])$/);
  if (!match) {
    throw new Error("Invalid expiresIn format. Use: 60s, 30m, 24h, 7d");
  }
  const [, value, unit] = match;
  const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
  const expiresInSeconds = parseInt(value) * multipliers[unit];
  const header = { alg: "HS256", typ: "JWT" };
  const now = Math.floor(Date.now() / 1e3);
  const data = {
    ...payload,
    iat: now,
    exp: now + expiresInSeconds
  };
  const encodedHeader = Buffer.from(JSON.stringify(header)).toString("base64url");
  const encodedPayload = Buffer.from(JSON.stringify(data)).toString("base64url");
  const signature = createHash("sha256").update(`${encodedHeader}.${encodedPayload}.${secret}`).digest("base64url");
  return `${encodedHeader}.${encodedPayload}.${signature}`;
}
function verifyToken(token, secret) {
  try {
    const [encodedHeader, encodedPayload, signature] = token.split(".");
    if (!encodedHeader || !encodedPayload || !signature) {
      return null;
    }
    const expectedSignature = createHash("sha256").update(`${encodedHeader}.${encodedPayload}.${secret}`).digest("base64url");
    if (signature !== expectedSignature) {
      return null;
    }
    const payload = JSON.parse(Buffer.from(encodedPayload, "base64url").toString());
    const now = Math.floor(Date.now() / 1e3);
    if (payload.exp && payload.exp < now) {
      return null;
    }
    return payload;
  } catch (err) {
    return null;
  }
}
function jwtAuth(options = {}) {
  const { secret, usersResource, optional = false } = options;
  if (!secret) {
    throw new Error("JWT secret is required");
  }
  return async (c, next) => {
    const authHeader = c.req.header("authorization");
    if (!authHeader) {
      if (optional) {
        return await next();
      }
      const response = unauthorized("No authorization header provided");
      return c.json(response, response._status);
    }
    const match = authHeader.match(/^Bearer\s+(.+)$/i);
    if (!match) {
      const response = unauthorized("Invalid authorization header format. Use: Bearer <token>");
      return c.json(response, response._status);
    }
    const token = match[1];
    const payload = verifyToken(token, secret);
    if (!payload) {
      const response = unauthorized("Invalid or expired token");
      return c.json(response, response._status);
    }
    if (usersResource && payload.userId) {
      try {
        const user = await usersResource.get(payload.userId);
        if (!user) {
          const response = unauthorized("User not found");
          return c.json(response, response._status);
        }
        if (!user.active) {
          const response = unauthorized("User account is inactive");
          return c.json(response, response._status);
        }
        c.set("user", user);
        c.set("authMethod", "jwt");
      } catch (err) {
        console.error("[JWT Auth] Error loading user:", err);
        const response = unauthorized("Authentication error");
        return c.json(response, response._status);
      }
    } else {
      c.set("user", payload);
      c.set("authMethod", "jwt");
    }
    await next();
  };
}

function generateApiKey(length = 32) {
  const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
  let apiKey = "";
  for (let i = 0; i < length; i++) {
    apiKey += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return apiKey;
}
function apiKeyAuth(options = {}) {
  const {
    headerName = "X-API-Key",
    usersResource,
    optional = false
  } = options;
  if (!usersResource) {
    throw new Error("usersResource is required for API key authentication");
  }
  return async (c, next) => {
    const apiKey = c.req.header(headerName);
    if (!apiKey) {
      if (optional) {
        return await next();
      }
      const response = unauthorized(`Missing ${headerName} header`);
      return c.json(response, response._status);
    }
    try {
      const users = await usersResource.query({ apiKey });
      if (!users || users.length === 0) {
        const response = unauthorized("Invalid API key");
        return c.json(response, response._status);
      }
      const user = users[0];
      if (!user.active) {
        const response = unauthorized("User account is inactive");
        return c.json(response, response._status);
      }
      c.set("user", user);
      c.set("authMethod", "apiKey");
      await next();
    } catch (err) {
      console.error("[API Key Auth] Error validating key:", err);
      const response = unauthorized("Authentication error");
      return c.json(response, response._status);
    }
  };
}

function createAuthRoutes(authResource, config = {}) {
  const app = new Hono();
  const {
    driver,
    // 'jwt' or 'basic'
    usernameField = "email",
    // Field name for username (default: 'email')
    passwordField = "password",
    // Field name for password (default: 'password')
    jwtSecret,
    jwtExpiresIn = "7d",
    passphrase = "secret",
    registration = {},
    loginThrottle = {}
  } = config;
  const registrationConfig = {
    enabled: registration.enabled === true,
    allowedFields: Array.isArray(registration.allowedFields) ? registration.allowedFields : [],
    defaultRole: registration.defaultRole || "user"
  };
  const schemaAttributes = authResource.schema?.attributes || {};
  const passwordAttribute = schemaAttributes?.[passwordField];
  const isPasswordType = typeof passwordAttribute === "string" ? passwordAttribute.includes("password") : passwordAttribute?.type === "password";
  const allowedRegistrationFields = /* @__PURE__ */ new Set([usernameField, passwordField]);
  for (const field of registrationConfig.allowedFields) {
    if (typeof field === "string" && field && field !== passwordField) {
      allowedRegistrationFields.add(field);
    }
  }
  const blockedRegistrationFields = /* @__PURE__ */ new Set([
    "role",
    "active",
    "apiKey",
    "jwtSecret",
    "scopes",
    "createdAt",
    "updatedAt",
    "metadata",
    "id"
  ]);
  const loginThrottleConfig = {
    enabled: loginThrottle?.enabled !== false,
    maxAttempts: loginThrottle?.maxAttempts ?? 5,
    windowMs: loginThrottle?.windowMs ?? 6e4,
    blockDurationMs: loginThrottle?.blockDurationMs ?? 3e5,
    maxEntries: loginThrottle?.maxEntries ?? 1e4
  };
  const loginAttempts = /* @__PURE__ */ new Map();
  const getClientIp = (c) => {
    const forwarded = c.req.header("x-forwarded-for");
    if (forwarded) {
      return forwarded.split(",")[0].trim();
    }
    const cfConnecting = c.req.header("cf-connecting-ip");
    if (cfConnecting) {
      return cfConnecting;
    }
    return c.req.raw?.socket?.remoteAddress || "unknown";
  };
  const cleanupLoginAttempts = () => {
    if (loginAttempts.size <= loginThrottleConfig.maxEntries) {
      return;
    }
    const oldestKey = loginAttempts.keys().next().value;
    if (oldestKey) {
      loginAttempts.delete(oldestKey);
    }
  };
  const getThrottleRecord = (key, now) => {
    if (!loginThrottleConfig.enabled) return null;
    let record = loginAttempts.get(key);
    if (record && record.blockedUntil && now > record.blockedUntil) {
      loginAttempts.delete(key);
      record = null;
    }
    if (!record || now - record.firstAttemptAt > loginThrottleConfig.windowMs) {
      record = { attempts: 0, firstAttemptAt: now, blockedUntil: null };
      loginAttempts.set(key, record);
      cleanupLoginAttempts();
    }
    return record;
  };
  const registerFailedAttempt = (record, now) => {
    if (!loginThrottleConfig.enabled || !record) {
      return { blocked: false };
    }
    record.attempts += 1;
    record.lastAttemptAt = now;
    if (record.attempts >= loginThrottleConfig.maxAttempts) {
      record.blockedUntil = now + loginThrottleConfig.blockDurationMs;
      const retryAfter = Math.ceil((record.blockedUntil - now) / 1e3);
      return { blocked: true, retryAfter };
    }
    return { blocked: false };
  };
  const buildPublicUser = (user) => {
    const publicUser = { id: user.id };
    const identifier = user[usernameField] ?? user.email ?? user.username;
    if (identifier !== void 0) {
      publicUser[usernameField] = identifier;
    }
    for (const field of allowedRegistrationFields) {
      if (field === usernameField || field === passwordField) continue;
      if (user[field] !== void 0) {
        publicUser[field] = user[field];
      }
    }
    if (schemaAttributes.role !== void 0 && user.role !== void 0) {
      publicUser.role = user.role;
    }
    if (schemaAttributes.active !== void 0 && user.active !== void 0) {
      publicUser.active = user.active;
    }
    return publicUser;
  };
  if (registrationConfig.enabled) {
    app.post("/register", asyncHandler(async (c) => {
      const data = await c.req.json();
      const username = data[usernameField];
      const password = data[passwordField];
      if (!username || !password) {
        const response2 = validationError([
          { field: usernameField, message: `${usernameField} is required` },
          { field: passwordField, message: `${passwordField} is required` }
        ]);
        return c.json(response2, response2._status);
      }
      if (password.length < 8) {
        const response2 = validationError([
          { field: passwordField, message: "Password must be at least 8 characters" }
        ]);
        return c.json(response2, response2._status);
      }
      const queryFilter = { [usernameField]: username };
      const existing = await authResource.query(queryFilter);
      if (existing && existing.length > 0) {
        const response2 = error$1(`${usernameField} already exists`, {
          status: 409,
          code: "CONFLICT"
        });
        return c.json(response2, response2._status);
      }
      const { id, ...dataWithoutId } = data;
      const userData = {};
      for (const [key, value] of Object.entries(dataWithoutId)) {
        if (!allowedRegistrationFields.has(key)) continue;
        if (blockedRegistrationFields.has(key)) continue;
        if (key === usernameField || key === passwordField) continue;
        userData[key] = value;
      }
      userData[usernameField] = username;
      if (isPasswordType) {
        userData[passwordField] = password;
      } else {
        userData[passwordField] = await hashPassword(password);
      }
      if (schemaAttributes.role !== void 0) {
        userData.role = registrationConfig.defaultRole;
      }
      if (schemaAttributes.active !== void 0) {
        userData.active = true;
      }
      const user = await authResource.insert(userData);
      let token = null;
      if (driver === "jwt" && jwtSecret) {
        token = createToken(
          {
            userId: user.id,
            [usernameField]: user[usernameField],
            role: user.role
          },
          jwtSecret,
          jwtExpiresIn
        );
      }
      const response = created({
        user: buildPublicUser(user),
        ...token && { token }
        // Only include token if JWT driver
      }, `/auth/users/${user.id}`);
      return c.json(response, response._status);
    }));
  }
  if (driver === "jwt") {
    app.post("/login", asyncHandler(async (c) => {
      const data = await c.req.json();
      const username = data[usernameField];
      const password = data[passwordField];
      if (!username || !password) {
        const response2 = unauthorized(`${usernameField} and ${passwordField} are required`);
        return c.json(response2, response2._status);
      }
      const queryFilter = { [usernameField]: username };
      const users = await authResource.query(queryFilter);
      if (!users || users.length === 0) {
        const now2 = Date.now();
        let throttleRecord2 = null;
        let throttleKey2 = null;
        if (loginThrottleConfig.enabled) {
          const ip = getClientIp(c);
          throttleKey2 = `${ip}:${username}`;
          throttleRecord2 = getThrottleRecord(throttleKey2, now2);
          const throttleResult = registerFailedAttempt(throttleRecord2, now2);
          if (throttleResult.blocked) {
            c.header("Retry-After", throttleResult.retryAfter.toString());
            const response3 = error$1("Too many login attempts. Try again later.", {
              status: 429,
              code: "TOO_MANY_ATTEMPTS",
              details: { retryAfter: throttleResult.retryAfter }
            });
            return c.json(response3, response3._status);
          }
        }
        const response2 = unauthorized("Invalid credentials");
        return c.json(response2, response2._status);
      }
      const user = users[0];
      if (user.active !== void 0 && !user.active) {
        const response2 = unauthorized("User account is inactive");
        return c.json(response2, response2._status);
      }
      const now = Date.now();
      let throttleRecord = null;
      let throttleKey = null;
      if (loginThrottleConfig.enabled) {
        const ip = getClientIp(c);
        throttleKey = `${ip}:${username}`;
        throttleRecord = getThrottleRecord(throttleKey, now);
        if (throttleRecord && throttleRecord.blockedUntil && now < throttleRecord.blockedUntil) {
          const retryAfter = Math.ceil((throttleRecord.blockedUntil - now) / 1e3);
          c.header("Retry-After", retryAfter.toString());
          const response2 = error$1("Too many login attempts. Try again later.", {
            status: 429,
            code: "TOO_MANY_ATTEMPTS",
            details: { retryAfter }
          });
          return c.json(response2, response2._status);
        }
      }
      let isValid = false;
      const storedPassword = user[passwordField];
      if (!storedPassword) {
        const response2 = unauthorized("Invalid credentials");
        return c.json(response2, response2._status);
      }
      const isBcryptHash = storedPassword.startsWith("$") || storedPassword.length === 53 && !storedPassword.includes(":");
      if (isBcryptHash) {
        const { verifyPassword } = await Promise.resolve().then(function () { return passwordHashing; });
        isValid = await verifyPassword(password, storedPassword);
      } else {
        isValid = storedPassword === password;
      }
      if (!isValid) {
        const throttleResult = registerFailedAttempt(throttleRecord, now);
        if (throttleResult.blocked) {
          c.header("Retry-After", throttleResult.retryAfter.toString());
          const response3 = error$1("Too many login attempts. Try again later.", {
            status: 429,
            code: "TOO_MANY_ATTEMPTS",
            details: { retryAfter: throttleResult.retryAfter }
          });
          return c.json(response3, response3._status);
        }
        const response2 = unauthorized("Invalid credentials");
        return c.json(response2, response2._status);
      }
      if (user.lastLoginAt !== void 0) {
        await authResource.update(user.id, {
          lastLoginAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
      let token = null;
      if (jwtSecret) {
        token = createToken(
          {
            userId: user.id,
            [usernameField]: user[usernameField],
            role: user.role
          },
          jwtSecret,
          jwtExpiresIn
        );
      }
      if (loginThrottleConfig.enabled && throttleKey) {
        loginAttempts.delete(throttleKey);
      }
      const response = success$1({
        user: buildPublicUser(user),
        token,
        expiresIn: jwtExpiresIn
      });
      return c.json(response, response._status);
    }));
  }
  if (jwtSecret) {
    app.post("/token/refresh", asyncHandler(async (c) => {
      const user = c.get("user");
      if (!user) {
        const response2 = unauthorized("Authentication required");
        return c.json(response2, response2._status);
      }
      const token = createToken(
        { userId: user.id, username: user.username, role: user.role },
        jwtSecret,
        jwtExpiresIn
      );
      const response = success$1({
        token,
        expiresIn: jwtExpiresIn
      });
      return c.json(response, response._status);
    }));
  }
  app.get("/me", asyncHandler(async (c) => {
    const user = c.get("user");
    if (!user) {
      const response2 = unauthorized("Authentication required");
      return c.json(response2, response2._status);
    }
    const response = success$1(buildPublicUser(user));
    return c.json(response, response._status);
  }));
  app.post("/api-key/regenerate", asyncHandler(async (c) => {
    const user = c.get("user");
    if (!user) {
      const response2 = unauthorized("Authentication required");
      return c.json(response2, response2._status);
    }
    const newApiKey = generateApiKey();
    await authResource.update(user.id, {
      apiKey: newApiKey
    });
    const response = success$1({
      apiKey: newApiKey,
      message: "API key regenerated successfully"
    });
    return c.json(response, response._status);
  }));
  return app;
}

class RouteContext {
  /**
   * Create RouteContext
   * @param {Object} honoContext - Hono context (c)
   * @param {Object} database - s3db.js Database instance
   * @param {Object} resource - Current resource (for resource-level routes)
   * @param {Object} plugins - Plugin instances
   */
  constructor(honoContext, database, resource = null, plugins = {}) {
    this.c = honoContext;
    this.db = database;
    this.database = database;
    this._currentResource = resource;
    this.plugins = plugins;
    this.resources = this._createResourcesProxy();
    this.validator = this._createValidator();
    this.resource = resource;
  }
  /**
   * Create Proxy for easy resource access
   * @private
   */
  _createResourcesProxy() {
    return new Proxy({}, {
      get: (target, prop) => {
        if (this.database.resources[prop]) {
          return this.database.resources[prop];
        }
        const available = Object.keys(this.database.resources);
        throw new Error(
          `Resource "${prop}" not found. Available resources: ${available.join(", ")}`
        );
      },
      // List available resources (for debugging)
      ownKeys: () => {
        return Object.keys(this.database.resources);
      },
      // Make resources enumerable
      getOwnPropertyDescriptor: (target, prop) => {
        if (this.database.resources[prop]) {
          return {
            enumerable: true,
            configurable: true
          };
        }
        return void 0;
      }
    });
  }
  /**
   * Create validator helper
   * @private
   */
  _createValidator() {
    const ctx = this;
    return {
      /**
       * Validate data against resource schema
       * @param {string|Object} resourceOrData - Resource name or data object
       * @param {Object} data - Data to validate (if first param is resource name)
       * @returns {Object} { valid: boolean, errors?: Array }
       */
      validate(resourceOrData, data = null) {
        let resource;
        let dataToValidate;
        if (typeof resourceOrData === "object" && data === null) {
          if (!ctx._currentResource) {
            throw new Error('validator.validate(data) requires a current resource. Use validator.validate("resourceName", data) instead.');
          }
          resource = ctx._currentResource;
          dataToValidate = resourceOrData;
        } else if (typeof resourceOrData === "string" && data !== null) {
          resource = ctx.resources[resourceOrData];
          dataToValidate = data;
        } else {
          throw new Error('Invalid arguments. Use validator.validate(data) or validator.validate("resourceName", data)');
        }
        const validation = resource.schema.validate(dataToValidate);
        if (validation === true) {
          return { valid: true };
        } else {
          return {
            valid: false,
            errors: Array.isArray(validation) ? validation : [validation]
          };
        }
      },
      /**
       * Validate and throw if invalid
       * @param {string|Object} resourceOrData - Resource name or data object
       * @param {Object} data - Data to validate
       * @throws {Error} Validation error with details
       */
      validateOrThrow(resourceOrData, data = null) {
        const result = this.validate(resourceOrData, data);
        if (!result.valid) {
          const error = new Error("Validation failed");
          error.code = "VALIDATION_ERROR";
          error.errors = result.errors;
          error.status = 400;
          throw error;
        }
      },
      /**
       * Validate request body against resource schema
       * @param {string} resourceName - Resource name (optional if current resource exists)
       * @returns {Promise<Object>} { valid: boolean, data?: Object, errors?: Array }
       */
      async validateBody(resourceName = null) {
        const body = await ctx.c.req.json();
        if (resourceName) {
          const result = this.validate(resourceName, body);
          return { ...result, data: body };
        } else {
          const result = this.validate(body);
          return { ...result, data: body };
        }
      }
    };
  }
  // ============================================
  // Request Helpers (proxy to Hono context)
  // ============================================
  /**
   * Get path parameter
   * @param {string} name - Parameter name
   * @returns {string} Parameter value
   */
  param(name) {
    return this.c.req.param(name);
  }
  /**
   * Get all path parameters
   * @returns {Object} All parameters
   */
  params() {
    return this.c.req.param();
  }
  /**
   * Get query parameter
   * @param {string} name - Query parameter name
   * @returns {string|undefined} Query value
   */
  query(name) {
    return this.c.req.query(name);
  }
  /**
   * Get all query parameters
   * @returns {Object} All query parameters
   */
  queries() {
    return this.c.req.query();
  }
  /**
   * Get request header
   * @param {string} name - Header name
   * @returns {string|undefined} Header value
   */
  header(name) {
    return this.c.req.header(name);
  }
  /**
   * Parse JSON body
   * @returns {Promise<Object>} Parsed body
   */
  async body() {
    return await this.c.req.json();
  }
  /**
   * Get request body as text
   * @returns {Promise<string>} Body text
   */
  async text() {
    return await this.c.req.text();
  }
  /**
   * Get request body as FormData
   * @returns {Promise<FormData>} FormData
   */
  async formData() {
    return await this.c.req.formData();
  }
  // ============================================
  // Response Helpers (shortcuts)
  // ============================================
  /**
   * Send JSON response
   * @param {Object} data - Response data
   * @param {number} status - HTTP status code
   * @returns {Response} Hono response
   */
  json(data, status = 200) {
    return this.c.json(data, status);
  }
  /**
   * Send success response
   * @param {Object} data - Response data
   * @param {number} status - HTTP status code
   * @returns {Response} Success response
   */
  success(data, status = 200) {
    return this.c.json({
      success: true,
      data
    }, status);
  }
  /**
   * Send error response
   * @param {string} message - Error message
   * @param {number} status - HTTP status code
   * @returns {Response} Error response
   */
  error(message, status = 400) {
    return this.c.json({
      success: false,
      error: {
        message,
        code: "ERROR",
        status
      }
    }, status);
  }
  /**
   * Send 404 Not Found
   * @param {string} message - Optional message
   * @returns {Response} 404 response
   */
  notFound(message = "Not found") {
    return this.c.json({
      success: false,
      error: {
        message,
        code: "NOT_FOUND",
        status: 404
      }
    }, 404);
  }
  /**
   * Send 401 Unauthorized
   * @param {string} message - Optional message
   * @returns {Response} 401 response
   */
  unauthorized(message = "Unauthorized") {
    return this.c.json({
      success: false,
      error: {
        message,
        code: "UNAUTHORIZED",
        status: 401
      }
    }, 401);
  }
  /**
   * Send 403 Forbidden
   * @param {string} message - Optional message
   * @returns {Response} 403 response
   */
  forbidden(message = "Forbidden") {
    return this.c.json({
      success: false,
      error: {
        message,
        code: "FORBIDDEN",
        status: 403
      }
    }, 403);
  }
  /**
   * Send HTML response
   * @param {string} html - HTML content
   * @param {number} status - HTTP status code
   * @returns {Response} HTML response
   */
  html(html, status = 200) {
    return this.c.html(html, status);
  }
  /**
   * Redirect to URL
   * @param {string} url - Target URL
   * @param {number} status - HTTP status code (default 302)
   * @returns {Response} Redirect response
   */
  redirect(url, status = 302) {
    return this.c.redirect(url, status);
  }
  /**
   * Render template (if template engine is configured)
   * @param {string|JSX.Element} template - Template name or JSX element
   * @param {Object} data - Data to pass to template
   * @param {Object} options - Render options
   * @returns {Promise<Response>} Rendered HTML response
   */
  async render(template, data = {}, options = {}) {
    if (!this.c.render) {
      throw new Error(
        'Template engine not configured. Use ApiPlugin with templates: { engine: "ejs" | "pug" | "jsx" }'
      );
    }
    return await this.c.render(template, data, options);
  }
  // ============================================
  // Context Helpers
  // ============================================
  /**
   * Get authenticated user (if auth is enabled)
   * @returns {Object|null} User object
   */
  get user() {
    return this.c.get("user") || null;
  }
  /**
   * Get session (if session tracking enabled)
   * @returns {Object|null} Session object
   */
  get session() {
    return this.c.get("session") || null;
  }
  /**
   * Get session ID (if session tracking enabled)
   * @returns {string|null} Session ID
   */
  get sessionId() {
    return this.c.get("sessionId") || null;
  }
  /**
   * Get request ID (if request ID tracking enabled)
   * @returns {string|null} Request ID
   */
  get requestId() {
    return this.c.get("requestId") || null;
  }
  /**
   * Check if user is authenticated
   * @returns {boolean} True if authenticated
   */
  get isAuthenticated() {
    return !!this.user;
  }
  /**
   * Check if user has scope
   * @param {string} scope - Scope to check
   * @returns {boolean} True if user has scope
   */
  hasScope(scope) {
    return this.user?.scopes?.includes(scope) || false;
  }
  /**
   * Check if user has any of the scopes
   * @param {Array<string>} scopes - Scopes to check
   * @returns {boolean} True if user has any scope
   */
  hasAnyScope(...scopes) {
    return scopes.some((scope) => this.hasScope(scope));
  }
  /**
   * Check if user has all scopes
   * @param {Array<string>} scopes - Scopes to check
   * @returns {boolean} True if user has all scopes
   */
  hasAllScopes(...scopes) {
    return scopes.every((scope) => this.hasScope(scope));
  }
  /**
   * Require authentication (throw if not authenticated)
   * @throws {Error} If not authenticated
   */
  requireAuth() {
    if (!this.isAuthenticated) {
      throw Object.assign(
        new Error("Authentication required"),
        { status: 401, code: "UNAUTHORIZED" }
      );
    }
  }
  /**
   * Require scope (throw if not authorized)
   * @param {string} scope - Required scope
   * @throws {Error} If scope missing
   */
  requireScope(scope) {
    this.requireAuth();
    if (!this.hasScope(scope)) {
      throw Object.assign(
        new Error(`Scope required: ${scope}`),
        { status: 403, code: "FORBIDDEN" }
      );
    }
  }
  // ============================================
  // Partition Helpers (for Guards)
  // ============================================
  /**
   * Set partition filter for current query (used by guards for tenant isolation)
   * @param {string} partitionName - Partition name (e.g., 'byUserId')
   * @param {Object} partitionFields - Partition field values (e.g., { userId: 'user123' })
   * @returns {void}
   *
   * @example
   * // In guard:
   * users.guard = {
   *   list: (ctx) => {
   *     if (ctx.user.scopes?.includes('preset:admin')) {
   *       return true; // Admin sees everything
   *     }
   *
   *     // Regular user sees only their data (O(1) via partition)
   *     ctx.setPartition('byUserId', { userId: ctx.user.id });
   *     return true;
   *   }
   * };
   */
  setPartition(partitionName, partitionFields) {
    if (!this._partitionFilters) {
      this._partitionFilters = [];
    }
    this._partitionFilters.push({ partitionName, partitionFields });
  }
  /**
   * Get partition filters set by guards
   * @returns {Array} Partition filters
   * @internal
   */
  getPartitionFilters() {
    return this._partitionFilters || [];
  }
  /**
   * Clear partition filters
   * @returns {void}
   * @internal
   */
  clearPartitionFilters() {
    this._partitionFilters = [];
  }
  /**
   * Check if partition filters are set
   * @returns {boolean} True if partition filters exist
   */
  hasPartitionFilters() {
    return this._partitionFilters && this._partitionFilters.length > 0;
  }
}
function withContext(handler, options = {}) {
  return async (c) => {
    const legacyContext = c.get("customRouteContext") || {};
    const { database, resource, plugins = {} } = legacyContext;
    const currentResource = options.resource || resource || null;
    const ctx = new RouteContext(c, database, currentResource, plugins);
    return await handler(c, ctx);
  };
}

var routeContext = /*#__PURE__*/Object.freeze({
  __proto__: null,
  RouteContext: RouteContext,
  withContext: withContext
});

function parseRouteKey(key) {
  const match = key.match(/^(GET|POST|PUT|PATCH|DELETE|HEAD|OPTIONS)\s+(.+)$/i);
  if (!match) {
    throw new Error(`Invalid route key format: "${key}". Expected format: "METHOD /path"`);
  }
  return {
    method: match[1].toUpperCase(),
    path: match[2]
  };
}
function mountCustomRoutes(app, routes, context = {}, verbose = false, options = {}) {
  if (!routes || typeof routes !== "object") {
    return;
  }
  const { autoWrap = true } = options;
  for (const [key, handler] of Object.entries(routes)) {
    try {
      const { method, path } = parseRouteKey(key);
      const wrappedHandler = asyncHandler(async (c) => {
        c.set("customRouteContext", context);
        if (autoWrap && handler.length === 2) {
          return await withContext(handler, { resource: context.resource })(c);
        } else {
          return await handler(c);
        }
      });
      app.on(method, path, wrappedHandler);
      if (verbose) {
        const contextType = autoWrap && handler.length === 2 ? "(enhanced)" : "(legacy)";
        console.log(`[Custom Routes] Mounted ${method} ${path} ${contextType}`);
      }
    } catch (err) {
      console.error(`[Custom Routes] Error mounting route "${key}":`, err.message);
    }
  }
}

function success(data, options = {}) {
  const { status = 200, meta = {} } = options;
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      ...meta
    },
    _status: status
  };
}
function error(error2, options = {}) {
  const { status = 500, code = "INTERNAL_ERROR", details = {} } = options;
  const errorMessage = error2 instanceof Error ? error2.message : error2;
  const errorStack = error2 instanceof Error && process.env.NODE_ENV !== "production" ? error2.stack : void 0;
  return {
    success: false,
    error: {
      message: errorMessage,
      code,
      details,
      stack: errorStack
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: status
  };
}
function payloadTooLarge(size, limit) {
  return error("Request payload too large", {
    status: 413,
    code: "PAYLOAD_TOO_LARGE",
    details: {
      receivedSize: size,
      maxSize: limit,
      receivedMB: (size / 1024 / 1024).toFixed(2),
      maxMB: (limit / 1024 / 1024).toFixed(2)
    }
  });
}

const errorStatusMap = {
  "ValidationError": 400,
  "InvalidResourceItem": 400,
  "ResourceNotFound": 404,
  "NoSuchKey": 404,
  "NoSuchBucket": 404,
  "PartitionError": 400,
  "CryptoError": 500,
  "SchemaError": 400,
  "QueueError": 500,
  "ResourceError": 500
};
function getStatusFromError(err) {
  if (err.name && errorStatusMap[err.name]) {
    return errorStatusMap[err.name];
  }
  if (err.constructor && err.constructor.name && errorStatusMap[err.constructor.name]) {
    return errorStatusMap[err.constructor.name];
  }
  if (err.message) {
    if (err.message.includes("not found") || err.message.includes("does not exist")) {
      return 404;
    }
    if (err.message.includes("validation") || err.message.includes("invalid")) {
      return 400;
    }
    if (err.message.includes("unauthorized") || err.message.includes("authentication")) {
      return 401;
    }
    if (err.message.includes("forbidden") || err.message.includes("permission")) {
      return 403;
    }
  }
  return 500;
}
function errorHandler(err, c) {
  const status = getStatusFromError(err);
  const code = err.name || "INTERNAL_ERROR";
  const details = {};
  if (err.resource) details.resource = err.resource;
  if (err.bucket) details.bucket = err.bucket;
  if (err.key) details.key = err.key;
  if (err.operation) details.operation = err.operation;
  if (err.suggestion) details.suggestion = err.suggestion;
  if (err.availableResources) details.availableResources = err.availableResources;
  const response = error(err, {
    status,
    code,
    details
  });
  if (status >= 500) {
    console.error("[API Plugin] Error:", {
      message: err.message,
      code,
      status,
      stack: err.stack,
      details
    });
  } else if (status >= 400 && status < 500 && c.get("verbose")) {
    console.warn("[API Plugin] Client error:", {
      message: err.message,
      code,
      status,
      details
    });
  }
  return c.json(response, response._status);
}

function mapFieldTypeToOpenAPI(fieldType) {
  const type = fieldType.split("|")[0].trim();
  const typeMap = {
    "string": { type: "string" },
    "number": { type: "number" },
    "integer": { type: "integer" },
    "boolean": { type: "boolean" },
    "array": { type: "array", items: { type: "string" } },
    "object": { type: "object" },
    "json": { type: "object" },
    "secret": { type: "string", format: "password" },
    "email": { type: "string", format: "email" },
    "url": { type: "string", format: "uri" },
    "date": { type: "string", format: "date" },
    "datetime": { type: "string", format: "date-time" },
    "ip4": { type: "string", format: "ipv4", description: "IPv4 address" },
    "ip6": { type: "string", format: "ipv6", description: "IPv6 address" },
    "embedding": { type: "array", items: { type: "number" }, description: "Vector embedding" }
  };
  if (type.startsWith("embedding:")) {
    const length = parseInt(type.split(":")[1]);
    return {
      type: "array",
      items: { type: "number" },
      minItems: length,
      maxItems: length,
      description: `Vector embedding (${length} dimensions)`
    };
  }
  return typeMap[type] || { type: "string" };
}
function extractValidationRules(fieldDef) {
  const rules = {};
  const parts = fieldDef.split("|");
  for (const part of parts) {
    const [rule, value] = part.split(":").map((s) => s.trim());
    switch (rule) {
      case "required":
        rules.required = true;
        break;
      case "min":
        rules.minimum = parseFloat(value);
        break;
      case "max":
        rules.maximum = parseFloat(value);
        break;
      case "minlength":
        rules.minLength = parseInt(value);
        break;
      case "maxlength":
        rules.maxLength = parseInt(value);
        break;
      case "pattern":
        rules.pattern = value;
        break;
      case "enum":
        rules.enum = value.split(",").map((v) => v.trim());
        break;
      case "default":
        rules.default = value;
        break;
    }
  }
  return rules;
}
function generateResourceSchema(resource) {
  const properties = {};
  const required = [];
  const allAttributes = resource.$schema.attributes || {};
  const pluginAttrNames = resource.$schema._pluginAttributes ? Object.values(resource.$schema._pluginAttributes).flat() : [];
  const attributes = Object.fromEntries(
    Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
  );
  const resourceDescription = resource.$schema.description;
  const attributeDescriptions = typeof resourceDescription === "object" ? resourceDescription.attributes || {} : {};
  properties.id = {
    type: "string",
    description: "Unique identifier for the resource",
    example: "2_gDTpeU6EI0e8B92n_R3Y",
    readOnly: true
  };
  for (const [fieldName, fieldDef] of Object.entries(attributes)) {
    if (typeof fieldDef === "object" && fieldDef.type) {
      const baseType = mapFieldTypeToOpenAPI(fieldDef.type);
      properties[fieldName] = {
        ...baseType,
        description: fieldDef.description || attributeDescriptions[fieldName] || void 0
      };
      if (fieldDef.required) {
        required.push(fieldName);
      }
      if (fieldDef.type === "object" && fieldDef.props) {
        properties[fieldName].properties = {};
        for (const [propName, propDef] of Object.entries(fieldDef.props)) {
          const propType = typeof propDef === "string" ? propDef : propDef.type;
          properties[fieldName].properties[propName] = mapFieldTypeToOpenAPI(propType);
        }
      }
      if (fieldDef.type === "array" && fieldDef.items) {
        properties[fieldName].items = mapFieldTypeToOpenAPI(fieldDef.items);
      }
    } else if (typeof fieldDef === "string") {
      const baseType = mapFieldTypeToOpenAPI(fieldDef);
      const rules = extractValidationRules(fieldDef);
      properties[fieldName] = {
        ...baseType,
        ...rules,
        description: attributeDescriptions[fieldName] || void 0
      };
      if (rules.required) {
        required.push(fieldName);
        delete properties[fieldName].required;
      }
    }
  }
  return {
    type: "object",
    properties,
    required: required.length > 0 ? required : void 0
  };
}
function generateResourcePaths(resource, version, config = {}) {
  const resourceName = resource.name;
  let versionPrefixConfig = config.versionPrefix !== void 0 ? config.versionPrefix : false;
  let prefix = "";
  if (versionPrefixConfig === true) {
    prefix = version;
  } else if (versionPrefixConfig === false) {
    prefix = "";
  } else if (typeof versionPrefixConfig === "string") {
    prefix = versionPrefixConfig;
  }
  const basePath = prefix ? `/${prefix}/${resourceName}` : `/${resourceName}`;
  const schema = generateResourceSchema(resource);
  const methods = config.methods || ["GET", "POST", "PUT", "PATCH", "DELETE"];
  const authMethods = config.auth || [];
  const requiresAuth = authMethods && authMethods.length > 0;
  const paths = {};
  const security = [];
  if (requiresAuth) {
    if (authMethods.includes("jwt")) security.push({ bearerAuth: [] });
    if (authMethods.includes("apiKey")) security.push({ apiKeyAuth: [] });
    if (authMethods.includes("basic")) security.push({ basicAuth: [] });
  }
  const partitions = resource.$schema.partitions || {};
  const partitionNames = Object.keys(partitions);
  const hasPartitions = partitionNames.length > 0;
  let partitionDescription = "Partition name for filtering";
  let partitionValuesDescription = "Partition values as JSON string";
  let partitionExample = void 0;
  let partitionValuesExample = void 0;
  if (hasPartitions) {
    const partitionDocs = partitionNames.map((name) => {
      const partition = partitions[name];
      const fields = Object.keys(partition.fields || {});
      const fieldTypes = Object.entries(partition.fields || {}).map(([field, type]) => `${field}: ${type}`).join(", ");
      return `- **${name}**: Filters by ${fields.join(", ")} (${fieldTypes})`;
    }).join("\n");
    partitionDescription = `Available partitions:
${partitionDocs}`;
    const examplePartition = partitionNames[0];
    const exampleFields = partitions[examplePartition]?.fields || {};
    Object.entries(exampleFields).map(([field, type]) => `"${field}": <${type} value>`).join(", ");
    partitionValuesDescription = `Partition field values as JSON string. Must match the structure of the selected partition.

Example for "${examplePartition}" partition: \`{"${Object.keys(exampleFields)[0]}": "value"}\``;
    partitionExample = examplePartition;
    const firstField = Object.keys(exampleFields)[0];
    const firstFieldType = exampleFields[firstField];
    let exampleValue = "example";
    if (firstFieldType === "number" || firstFieldType === "integer") {
      exampleValue = 123;
    } else if (firstFieldType === "boolean") {
      exampleValue = true;
    }
    partitionValuesExample = JSON.stringify({ [firstField]: exampleValue });
  }
  const attributeQueryParams = [];
  if (hasPartitions) {
    const partitionFieldsSet = /* @__PURE__ */ new Set();
    for (const [partitionName, partition] of Object.entries(partitions)) {
      const fields = partition.fields || {};
      for (const fieldName of Object.keys(fields)) {
        partitionFieldsSet.add(fieldName);
      }
    }
    const allAttributes = resource.config?.attributes || resource.attributes || {};
    const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
    const attributes = Object.fromEntries(
      Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
    );
    for (const fieldName of partitionFieldsSet) {
      const fieldDef = attributes[fieldName];
      if (!fieldDef) continue;
      let fieldType;
      if (typeof fieldDef === "object" && fieldDef.type) {
        fieldType = fieldDef.type;
      } else if (typeof fieldDef === "string") {
        fieldType = fieldDef.split("|")[0].trim();
      } else {
        fieldType = "string";
      }
      const openAPIType = mapFieldTypeToOpenAPI(fieldType);
      attributeQueryParams.push({
        name: fieldName,
        in: "query",
        description: `Filter by ${fieldName} field (indexed via partitions for efficient querying). Value will be parsed as JSON if possible, otherwise treated as string.`,
        required: false,
        schema: openAPIType
      });
    }
  }
  if (methods.includes("GET")) {
    paths[basePath] = {
      get: {
        tags: [resourceName],
        summary: `List ${resourceName}`,
        description: `Retrieve a paginated list of ${resourceName}. Supports filtering by passing any resource field as a query parameter (e.g., ?status=active&year=2024). Values are parsed as JSON if possible, otherwise treated as strings.

**Pagination**: Use \`limit\` and \`offset\` to paginate results. For example:
- First page (10 items): \`?limit=10&offset=0\`
- Second page: \`?limit=10&offset=10\`
- Third page: \`?limit=10&offset=20\`

The response includes pagination metadata in the \`pagination\` object with total count and page information.${hasPartitions ? "\n\n**Partitioning**: This resource supports partitioned queries for optimized filtering. Use the `partition` and `partitionValues` parameters together." : ""}`,
        parameters: [
          {
            name: "limit",
            in: "query",
            description: "Maximum number of items to return per page (page size)",
            schema: { type: "integer", default: 100, minimum: 1, maximum: 1e3 },
            example: 10
          },
          {
            name: "offset",
            in: "query",
            description: "Number of items to skip before starting to return results. Use for pagination: offset = (page - 1) * limit",
            schema: { type: "integer", default: 0, minimum: 0 },
            example: 0
          },
          ...hasPartitions ? [
            {
              name: "partition",
              in: "query",
              description: partitionDescription,
              schema: {
                type: "string",
                enum: partitionNames
              },
              example: partitionExample
            },
            {
              name: "partitionValues",
              in: "query",
              description: partitionValuesDescription,
              schema: { type: "string" },
              example: partitionValuesExample
            }
          ] : [],
          ...attributeQueryParams
        ],
        responses: {
          200: {
            description: "Successful response",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "array",
                      items: schema
                    },
                    pagination: {
                      type: "object",
                      description: "Pagination metadata for the current request",
                      properties: {
                        total: {
                          type: "integer",
                          description: "Total number of items available",
                          example: 150
                        },
                        page: {
                          type: "integer",
                          description: "Current page number (1-indexed)",
                          example: 1
                        },
                        pageSize: {
                          type: "integer",
                          description: "Number of items per page (same as limit parameter)",
                          example: 10
                        },
                        pageCount: {
                          type: "integer",
                          description: "Total number of pages available",
                          example: 15
                        }
                      }
                    }
                  }
                }
              }
            },
            headers: {
              "X-Total-Count": {
                description: "Total number of records",
                schema: { type: "integer" }
              },
              "X-Page-Count": {
                description: "Total number of pages",
                schema: { type: "integer" }
              }
            }
          }
        },
        security: security.length > 0 ? security : void 0
      }
    };
  }
  if (methods.includes("GET")) {
    paths[`${basePath}/{id}`] = {
      get: {
        tags: [resourceName],
        summary: `Get ${resourceName} by ID`,
        description: `Retrieve a single ${resourceName} by its ID${hasPartitions ? ". Optionally specify a partition for more efficient retrieval." : ""}`,
        parameters: [
          {
            name: "id",
            in: "path",
            required: true,
            description: `${resourceName} ID`,
            schema: { type: "string" }
          },
          ...hasPartitions ? [
            {
              name: "partition",
              in: "query",
              description: partitionDescription,
              schema: {
                type: "string",
                enum: partitionNames
              },
              example: partitionExample
            },
            {
              name: "partitionValues",
              in: "query",
              description: partitionValuesDescription,
              schema: { type: "string" },
              example: partitionValuesExample
            }
          ] : []
        ],
        responses: {
          200: {
            description: "Successful response",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: schema
                  }
                }
              }
            }
          },
          404: {
            description: "Resource not found",
            content: {
              "application/json": {
                schema: { $ref: "#/components/schemas/Error" }
              }
            }
          }
        },
        security: security.length > 0 ? security : void 0
      }
    };
  }
  if (methods.includes("POST")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].post = {
      tags: [resourceName],
      summary: `Create ${resourceName}`,
      description: `Create a new ${resourceName}`,
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema
          }
        }
      },
      responses: {
        201: {
          description: "Resource created successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          },
          headers: {
            Location: {
              description: "URL of the created resource",
              schema: { type: "string" }
            }
          }
        },
        400: {
          description: "Validation error",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/ValidationError" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("PUT")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].put = {
      tags: [resourceName],
      summary: `Update ${resourceName} (full)`,
      description: `Fully update a ${resourceName}`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema
          }
        }
      },
      responses: {
        200: {
          description: "Resource updated successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          }
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("PATCH")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].patch = {
      tags: [resourceName],
      summary: `Update ${resourceName} (partial)`,
      description: `Partially update a ${resourceName}`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema: {
              ...schema,
              required: void 0
              // Partial updates don't require all fields
            }
          }
        }
      },
      responses: {
        200: {
          description: "Resource updated successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          }
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("DELETE")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].delete = {
      tags: [resourceName],
      summary: `Delete ${resourceName}`,
      description: `Delete a ${resourceName} by ID`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        204: {
          description: "Resource deleted successfully"
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("HEAD")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].head = {
      tags: [resourceName],
      summary: `Get ${resourceName} statistics`,
      description: `Get statistics about ${resourceName} collection without retrieving data. Returns statistics in response headers.`,
      responses: {
        200: {
          description: "Statistics retrieved successfully",
          headers: {
            "X-Total-Count": {
              description: "Total number of records",
              schema: { type: "integer" }
            },
            "X-Resource-Version": {
              description: "Current resource version",
              schema: { type: "string" }
            },
            "X-Schema-Fields": {
              description: "Number of schema fields",
              schema: { type: "integer" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].head = {
      tags: [resourceName],
      summary: `Check if ${resourceName} exists`,
      description: `Check if a ${resourceName} exists without retrieving its data`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        200: {
          description: "Resource exists",
          headers: {
            "Last-Modified": {
              description: "Last modification date",
              schema: { type: "string", format: "date-time" }
            }
          }
        },
        404: {
          description: "Resource not found"
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("OPTIONS")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].options = {
      tags: [resourceName],
      summary: `Get ${resourceName} metadata`,
      description: `Get complete metadata about ${resourceName} resource including schema, allowed methods, endpoints, and query parameters`,
      responses: {
        200: {
          description: "Metadata retrieved successfully",
          headers: {
            "Allow": {
              description: "Allowed HTTP methods",
              schema: { type: "string", example: "GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS" }
            }
          },
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  resource: { type: "string" },
                  version: { type: "string" },
                  totalRecords: { type: "integer" },
                  allowedMethods: {
                    type: "array",
                    items: { type: "string" }
                  },
                  schema: {
                    type: "array",
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string" },
                        type: { type: "string" },
                        rules: { type: "array", items: { type: "string" } }
                      }
                    }
                  },
                  endpoints: {
                    type: "object",
                    properties: {
                      list: { type: "string" },
                      get: { type: "string" },
                      create: { type: "string" },
                      update: { type: "string" },
                      delete: { type: "string" }
                    }
                  },
                  queryParameters: { type: "object" }
                }
              }
            }
          }
        }
      }
    };
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].options = {
      tags: [resourceName],
      summary: `Get allowed methods for ${resourceName} item`,
      description: `Get allowed HTTP methods for individual ${resourceName} operations`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        204: {
          description: "Methods retrieved successfully",
          headers: {
            "Allow": {
              description: "Allowed HTTP methods",
              schema: { type: "string", example: "GET, PUT, PATCH, DELETE, HEAD, OPTIONS" }
            }
          }
        }
      }
    };
  }
  return paths;
}
function generateRelationalPaths(resource, relationName, relationConfig, version, relatedSchema, versionPrefix = "") {
  const resourceName = resource.name;
  const basePath = versionPrefix ? `/${versionPrefix}/${resourceName}/{id}/${relationName}` : `/${resourceName}/{id}/${relationName}`;
  relationConfig.resource;
  const isToMany = relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany";
  const paths = {};
  paths[basePath] = {
    get: {
      tags: [resourceName],
      summary: `Get ${relationName} of ${resourceName}`,
      description: `Retrieve ${relationName} (${relationConfig.type}) associated with this ${resourceName}. This endpoint uses the RelationPlugin to efficiently load related data` + (relationConfig.partitionHint ? ` via the '${relationConfig.partitionHint}' partition.` : "."),
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          description: `${resourceName} ID`,
          schema: { type: "string" }
        },
        ...isToMany ? [
          {
            name: "limit",
            in: "query",
            description: "Maximum number of items to return",
            schema: { type: "integer", default: 100, minimum: 1, maximum: 1e3 }
          },
          {
            name: "offset",
            in: "query",
            description: "Number of items to skip",
            schema: { type: "integer", default: 0, minimum: 0 }
          }
        ] : []
      ],
      responses: {
        200: {
          description: "Successful response",
          content: {
            "application/json": {
              schema: isToMany ? {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "array",
                    items: relatedSchema
                  },
                  pagination: {
                    type: "object",
                    properties: {
                      total: { type: "integer" },
                      page: { type: "integer" },
                      pageSize: { type: "integer" },
                      pageCount: { type: "integer" }
                    }
                  }
                }
              } : {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: relatedSchema
                }
              }
            }
          },
          ...isToMany ? {
            headers: {
              "X-Total-Count": {
                description: "Total number of related records",
                schema: { type: "integer" }
              },
              "X-Page-Count": {
                description: "Total number of pages",
                schema: { type: "integer" }
              }
            }
          } : {}
        },
        404: {
          description: `${resourceName} not found` + (isToMany ? "" : " or no related resource exists"),
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      }
    }
  };
  return paths;
}
function generateOpenAPISpec(database, config = {}) {
  const {
    title = "s3db.js API",
    version = "1.0.0",
    description = "Auto-generated REST API documentation for s3db.js resources",
    serverUrl = "http://localhost:3000",
    auth = {},
    resources: resourceConfigs = {},
    versionPrefix: globalVersionPrefix
  } = config;
  const resourcesTableRows = [];
  for (const [name, resource] of Object.entries(database.resources)) {
    const rawConfig = resourceConfigs[name];
    if (rawConfig?.enabled === false) {
      continue;
    }
    if (name.startsWith("plg_") && !rawConfig) {
      continue;
    }
    const version2 = resource.config?.currentVersion || resource.version || "v1";
    const resourceDescription = resource.config?.description;
    const descText = typeof resourceDescription === "object" ? resourceDescription.resource : resourceDescription || "No description";
    const resourceConfig = rawConfig && typeof rawConfig === "object" ? rawConfig : {};
    let versionPrefixConfig;
    if (resourceConfig.versionPrefix !== void 0) {
      versionPrefixConfig = resourceConfig.versionPrefix;
    } else if (resource.config && resource.config.versionPrefix !== void 0) {
      versionPrefixConfig = resource.config.versionPrefix;
    } else if (globalVersionPrefix !== void 0) {
      versionPrefixConfig = globalVersionPrefix;
    } else {
      versionPrefixConfig = false;
    }
    let prefix = "";
    if (versionPrefixConfig === true) {
      prefix = version2;
    } else if (versionPrefixConfig === false) {
      prefix = "";
    } else if (typeof versionPrefixConfig === "string") {
      prefix = versionPrefixConfig;
    }
    const basePath = prefix ? `/${prefix}/${name}` : `/${name}`;
    resourcesTableRows.push(`| ${name} | ${descText} | \`${basePath}\` |`);
  }
  const enhancedDescription = `${description}

## Available Resources

| Resource | Description | Base Path |
|----------|-------------|-----------|
${resourcesTableRows.join("\n")}

---

For detailed information about each endpoint, see the sections below.`;
  const spec = {
    openapi: "3.1.0",
    info: {
      title,
      version,
      description: enhancedDescription,
      contact: {
        name: "s3db.js",
        url: "https://github.com/forattini-dev/s3db.js"
      }
    },
    servers: [
      {
        url: serverUrl,
        description: "API Server"
      }
    ],
    paths: {},
    components: {
      schemas: {
        Error: {
          type: "object",
          properties: {
            success: { type: "boolean", example: false },
            error: {
              type: "object",
              properties: {
                message: { type: "string" },
                code: { type: "string" },
                details: { type: "object" }
              }
            }
          }
        },
        ValidationError: {
          type: "object",
          properties: {
            success: { type: "boolean", example: false },
            error: {
              type: "object",
              properties: {
                message: { type: "string", example: "Validation failed" },
                code: { type: "string", example: "VALIDATION_ERROR" },
                details: {
                  type: "object",
                  properties: {
                    errors: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          field: { type: "string" },
                          message: { type: "string" },
                          expected: { type: "string" },
                          actual: {}
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      },
      securitySchemes: {}
    },
    tags: []
  };
  if (auth.jwt?.enabled) {
    spec.components.securitySchemes.bearerAuth = {
      type: "http",
      scheme: "bearer",
      bearerFormat: "JWT",
      description: "JWT authentication"
    };
  }
  if (auth.apiKey?.enabled) {
    spec.components.securitySchemes.apiKeyAuth = {
      type: "apiKey",
      in: "header",
      name: auth.apiKey.headerName || "X-API-Key",
      description: "API Key authentication"
    };
  }
  if (auth.basic?.enabled) {
    spec.components.securitySchemes.basicAuth = {
      type: "http",
      scheme: "basic",
      description: "HTTP Basic authentication"
    };
  }
  const resources = database.resources;
  const relationsPlugin = database.plugins?.relation || database.plugins?.RelationPlugin || null;
  for (const [name, resource] of Object.entries(resources)) {
    const rawConfig = resourceConfigs[name];
    if (rawConfig?.enabled === false) {
      continue;
    }
    if (name.startsWith("plg_") && !rawConfig) {
      continue;
    }
    const resourceConfig = rawConfig && typeof rawConfig === "object" ? { ...rawConfig } : {
      methods: ["GET", "POST", "PUT", "PATCH", "DELETE"],
      auth: false
    };
    const version2 = resource.config?.currentVersion || resource.version || "v1";
    let versionPrefixConfig;
    if (resourceConfig.versionPrefix !== void 0) {
      versionPrefixConfig = resourceConfig.versionPrefix;
    } else if (resource.config && resource.config.versionPrefix !== void 0) {
      versionPrefixConfig = resource.config.versionPrefix;
    } else if (globalVersionPrefix !== void 0) {
      versionPrefixConfig = globalVersionPrefix;
    } else {
      versionPrefixConfig = false;
    }
    let prefix = "";
    if (versionPrefixConfig === true) {
      prefix = version2;
    } else if (versionPrefixConfig === false) {
      prefix = "";
    } else if (typeof versionPrefixConfig === "string") {
      prefix = versionPrefixConfig;
    }
    const paths = generateResourcePaths(resource, version2, {
      ...resourceConfig,
      versionPrefix: versionPrefixConfig
    });
    Object.assign(spec.paths, paths);
    const resourceDescription = resource.config?.description;
    const tagDescription = typeof resourceDescription === "object" ? resourceDescription.resource : resourceDescription || `Operations for ${name} resource`;
    spec.tags.push({
      name,
      description: tagDescription
    });
    spec.components.schemas[name] = generateResourceSchema(resource);
    if (relationsPlugin && relationsPlugin.relations && relationsPlugin.relations[name]) {
      const relationsDef = relationsPlugin.relations[name];
      for (const [relationName, relationConfig] of Object.entries(relationsDef)) {
        if (relationConfig.type === "belongsTo") {
          continue;
        }
        const exposeRelation = resourceConfig?.relations?.[relationName]?.expose !== false;
        if (!exposeRelation) {
          continue;
        }
        const relatedResource = database.resources[relationConfig.resource];
        if (!relatedResource) {
          continue;
        }
        const relatedSchema = generateResourceSchema(relatedResource);
        const relationalPaths = generateRelationalPaths(
          resource,
          relationName,
          relationConfig,
          version2,
          relatedSchema,
          prefix
        );
        Object.assign(spec.paths, relationalPaths);
      }
    }
  }
  if (auth.jwt?.enabled || auth.apiKey?.enabled || auth.basic?.enabled) {
    spec.paths["/auth/login"] = {
      post: {
        tags: ["Authentication"],
        summary: "Login",
        description: "Authenticate with username and password",
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  username: { type: "string" },
                  password: { type: "string", format: "password" }
                },
                required: ["username", "password"]
              }
            }
          }
        },
        responses: {
          200: {
            description: "Login successful",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "object",
                      properties: {
                        token: { type: "string" },
                        user: { type: "object" }
                      }
                    }
                  }
                }
              }
            }
          },
          401: {
            description: "Invalid credentials",
            content: {
              "application/json": {
                schema: { $ref: "#/components/schemas/Error" }
              }
            }
          }
        }
      }
    };
    spec.paths["/auth/register"] = {
      post: {
        tags: ["Authentication"],
        summary: "Register",
        description: "Register a new user",
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  username: { type: "string", minLength: 3 },
                  password: { type: "string", format: "password", minLength: 8 },
                  email: { type: "string", format: "email" }
                },
                required: ["username", "password"]
              }
            }
          }
        },
        responses: {
          201: {
            description: "User registered successfully",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "object",
                      properties: {
                        token: { type: "string" },
                        user: { type: "object" }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    };
    spec.tags.push({
      name: "Authentication",
      description: "Authentication endpoints"
    });
  }
  spec.paths["/health"] = {
    get: {
      tags: ["Health"],
      summary: "Generic Health Check",
      description: "Generic health check endpoint that includes references to liveness and readiness probes",
      responses: {
        200: {
          description: "API is healthy",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "ok" },
                      uptime: { type: "number", description: "Process uptime in seconds" },
                      timestamp: { type: "string", format: "date-time" },
                      checks: {
                        type: "object",
                        properties: {
                          liveness: { type: "string", example: "/health/live" },
                          readiness: { type: "string", example: "/health/ready" }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.paths["/health/live"] = {
    get: {
      tags: ["Health"],
      summary: "Liveness Probe",
      description: "Kubernetes liveness probe - checks if the application is alive. If this fails, Kubernetes will restart the pod.",
      responses: {
        200: {
          description: "Application is alive",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "alive" },
                      timestamp: { type: "string", format: "date-time" }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.paths["/health/ready"] = {
    get: {
      tags: ["Health"],
      summary: "Readiness Probe",
      description: "Kubernetes readiness probe - checks if the application is ready to receive traffic. If this fails, Kubernetes will remove the pod from service endpoints.",
      responses: {
        200: {
          description: "Application is ready to receive traffic",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "ready" },
                      database: {
                        type: "object",
                        properties: {
                          connected: { type: "boolean", example: true },
                          resources: { type: "integer", example: 5 }
                        }
                      },
                      timestamp: { type: "string", format: "date-time" }
                    }
                  }
                }
              }
            }
          }
        },
        503: {
          description: "Application is not ready",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: false },
                  error: {
                    type: "object",
                    properties: {
                      message: { type: "string", example: "Service not ready" },
                      code: { type: "string", example: "NOT_READY" },
                      details: {
                        type: "object",
                        properties: {
                          database: {
                            type: "object",
                            properties: {
                              connected: { type: "boolean", example: false },
                              resources: { type: "integer", example: 0 }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.tags.push({
    name: "Health",
    description: "Health check endpoints for monitoring and Kubernetes probes"
  });
  const metricsPlugin = database.plugins?.metrics || database.plugins?.MetricsPlugin;
  if (metricsPlugin && metricsPlugin.config?.prometheus?.enabled) {
    const metricsPath = metricsPlugin.config.prometheus.path || "/metrics";
    const isIntegrated = metricsPlugin.config.prometheus.mode !== "standalone";
    if (isIntegrated) {
      spec.paths[metricsPath] = {
        get: {
          tags: ["Monitoring"],
          summary: "Prometheus Metrics",
          description: "Exposes application metrics in Prometheus text-based exposition format for monitoring and observability. Metrics include operation counts, durations, errors, uptime, and resource statistics.",
          responses: {
            200: {
              description: "Metrics in Prometheus format",
              content: {
                "text/plain": {
                  schema: {
                    type: "string",
                    example: '# HELP s3db_operations_total Total number of operations by type and resource\n# TYPE s3db_operations_total counter\ns3db_operations_total{operation="insert",resource="cars"} 1523\ns3db_operations_total{operation="update",resource="cars"} 342\n\n# HELP s3db_operation_duration_seconds Average operation duration in seconds\n# TYPE s3db_operation_duration_seconds gauge\ns3db_operation_duration_seconds{operation="insert",resource="cars"} 0.045\n\n# HELP s3db_operation_errors_total Total number of operation errors\n# TYPE s3db_operation_errors_total counter\ns3db_operation_errors_total{operation="insert",resource="cars"} 12\n'
                  }
                }
              }
            }
          }
        }
      };
      spec.tags.push({
        name: "Monitoring",
        description: "Monitoring and observability endpoints (Prometheus)"
      });
    }
  }
  return spec;
}

function parseBasicAuth(authHeader) {
  if (!authHeader) {
    return null;
  }
  const match = authHeader.match(/^Basic\s+(.+)$/i);
  if (!match) {
    return null;
  }
  try {
    const decoded = Buffer.from(match[1], "base64").toString("utf-8");
    const [username, ...passwordParts] = decoded.split(":");
    const password = passwordParts.join(":");
    if (!username || !password) {
      return null;
    }
    return { username, password };
  } catch (err) {
    return null;
  }
}
function basicAuth(options = {}) {
  const {
    realm = "API Access",
    authResource,
    usernameField = "email",
    passwordField = "password",
    passphrase = "secret",
    optional = false,
    adminUser = null
  } = options;
  if (!authResource) {
    throw new Error("authResource is required for Basic authentication");
  }
  return async (c, next) => {
    const authHeader = c.req.header("authorization");
    if (!authHeader) {
      if (optional) {
        return await next();
      }
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Basic authentication required");
      return c.json(response, response._status);
    }
    const credentials = parseBasicAuth(authHeader);
    if (!credentials) {
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Invalid Basic authentication format");
      return c.json(response, response._status);
    }
    const { username, password } = credentials;
    if (adminUser && adminUser.enabled === true) {
      if (username === adminUser.username && password === adminUser.password) {
        c.set("user", {
          id: "root",
          username: adminUser.username,
          email: adminUser.username,
          scopes: adminUser.scopes || ["admin"],
          authMethod: "basic-admin"
        });
        c.set("authMethod", "basic");
        await next();
        return;
      }
    }
    try {
      const queryFilter = { [usernameField]: username };
      const users = await authResource.query(queryFilter);
      if (!users || users.length === 0) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("Invalid credentials");
        return c.json(response, response._status);
      }
      const user = users[0];
      if (user.active !== void 0 && !user.active) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("User account is inactive");
        return c.json(response, response._status);
      }
      const storedPassword = user[passwordField];
      const isValid = storedPassword === password;
      if (!isValid) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("Invalid credentials");
        return c.json(response, response._status);
      }
      c.set("user", user);
      c.set("authMethod", "basic");
      await next();
    } catch (err) {
      console.error("[Basic Auth] Error validating credentials:", err);
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Authentication error");
      return c.json(response, response._status);
    }
  };
}

const jwksCache = /* @__PURE__ */ new Map();
function createOAuth2Handler(config, usersResource) {
  const {
    issuer,
    jwksUri,
    audience = null,
    algorithms = ["RS256", "ES256"],
    cacheTTL = 36e5,
    // 1 hour
    clockTolerance = 60,
    // 60 seconds tolerance for exp/nbf
    validateScopes = true,
    fetchUserInfo = true
  } = config;
  if (!issuer) {
    throw new Error("[OAuth2 Auth] Missing required config: issuer");
  }
  const finalJwksUri = jwksUri || `${issuer}/.well-known/jwks.json`;
  const getJWKS = () => {
    const cacheKey = finalJwksUri;
    if (jwksCache.has(cacheKey)) {
      const cached = jwksCache.get(cacheKey);
      if (Date.now() - cached.timestamp < cacheTTL) {
        return cached.jwks;
      }
    }
    const jwks = createRemoteJWKSet(new URL(finalJwksUri), {
      cooldownDuration: 3e4,
      // 30 seconds cooldown between fetches
      cacheMaxAge: cacheTTL
    });
    jwksCache.set(cacheKey, {
      jwks,
      timestamp: Date.now()
    });
    return jwks;
  };
  return async (c) => {
    const authHeader = c.req.header("authorization") || c.req.header("Authorization");
    if (!authHeader || !authHeader.startsWith("Bearer ")) {
      return null;
    }
    const token = authHeader.substring(7);
    try {
      const jwks = getJWKS();
      const verifyOptions = {
        issuer,
        algorithms,
        clockTolerance
      };
      if (audience) {
        verifyOptions.audience = audience;
      }
      const { payload } = await jwtVerify(token, jwks, verifyOptions);
      const userId = payload.sub;
      const email = payload.email || null;
      const username = payload.preferred_username || payload.username || email;
      const scopes = payload.scope ? payload.scope.split(" ") : payload.scopes || [];
      const role = payload.role || "user";
      let user = null;
      if (fetchUserInfo && userId && usersResource) {
        try {
          user = await usersResource.get(userId).catch(() => null);
          if (!user && email) {
            const users = await usersResource.query({ email }, { limit: 1 });
            user = users[0] || null;
          }
        } catch (err) {
        }
      }
      if (user) {
        return {
          ...user,
          scopes: user.scopes || scopes,
          // Prefer database scopes
          role: user.role || role,
          tokenClaims: payload
          // Include full token claims
        };
      }
      return {
        id: userId,
        username: username || userId,
        email,
        role,
        scopes,
        active: true,
        tokenClaims: payload,
        isVirtual: true
        // Flag to indicate user is not in local database
      };
    } catch (err) {
      if (config.verbose) {
        console.error("[OAuth2 Auth] Token verification failed:", err.message);
      }
      return null;
    }
  };
}

function createAuthMiddleware(options = {}) {
  const {
    methods = [],
    jwt: jwtConfig = {},
    apiKey: apiKeyConfig = {},
    basic: basicConfig = {},
    oauth2: oauth2Config = {},
    oidc: oidcMiddleware = null,
    usersResource,
    optional = false,
    strategy = "any",
    priorities = {}
  } = options;
  if (methods.length === 0) {
    return async (c, next) => await next();
  }
  const middlewares = [];
  if (methods.includes("jwt") && jwtConfig.secret) {
    middlewares.push({
      name: "jwt",
      middleware: jwtAuth({
        secret: jwtConfig.secret,
        usersResource,
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("apiKey") && usersResource) {
    middlewares.push({
      name: "apiKey",
      middleware: apiKeyAuth({
        headerName: apiKeyConfig.headerName || "X-API-Key",
        usersResource,
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("basic") && usersResource) {
    middlewares.push({
      name: "basic",
      middleware: basicAuth({
        realm: basicConfig.realm || "API Access",
        passphrase: basicConfig.passphrase || "secret",
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("oauth2") && oauth2Config.issuer) {
    const oauth2Handler = createOAuth2Handler(oauth2Config, usersResource);
    middlewares.push({
      name: "oauth2",
      middleware: async (c, next) => {
        const user = await oauth2Handler(c);
        if (user) {
          c.set("user", user);
          return await next();
        }
      }
    });
  }
  if (oidcMiddleware) {
    middlewares.push({
      name: "oidc",
      middleware: oidcMiddleware
    });
  }
  if (strategy === "priority" && Object.keys(priorities).length > 0) {
    middlewares.sort((a, b) => {
      const priorityA = priorities[a.name] || 999;
      const priorityB = priorities[b.name] || 999;
      return priorityA - priorityB;
    });
  }
  return async (c, next) => {
    for (const { name, middleware } of middlewares) {
      let authSuccess = false;
      const tempNext = async () => {
        authSuccess = true;
      };
      await middleware(c, tempNext);
      if (authSuccess && c.get("user")) {
        return await next();
      }
    }
    if (optional) {
      return await next();
    }
    const response = unauthorized(
      `Authentication required. Supported methods: ${methods.join(", ")}`
    );
    return c.json(response, response._status);
  };
}

class RateLimitStore {
  constructor(options = {}) {
    this.store = /* @__PURE__ */ new Map();
    this.cleanupInterval = options.cleanupInterval || 6e4;
    this.windowMs = options.windowMs || 9e5;
    this.cleanupTimer = setInterval(() => this.cleanup(), this.cleanupInterval);
  }
  /**
   * Record an attempt
   * @param {string} key - Rate limit key
   * @returns {number} Current attempt count in window
   */
  record(key) {
    const now = Date.now();
    const cutoff = now - this.windowMs;
    if (!this.store.has(key)) {
      this.store.set(key, { attempts: [] });
    }
    const entry = this.store.get(key);
    entry.attempts = entry.attempts.filter((timestamp) => timestamp > cutoff);
    entry.attempts.push(now);
    return entry.attempts.length;
  }
  /**
   * Get current attempt count
   * @param {string} key - Rate limit key
   * @returns {number} Current attempt count in window
   */
  getCount(key) {
    if (!this.store.has(key)) {
      return 0;
    }
    const now = Date.now();
    const cutoff = now - this.windowMs;
    const entry = this.store.get(key);
    entry.attempts = entry.attempts.filter((timestamp) => timestamp > cutoff);
    return entry.attempts.length;
  }
  /**
   * Reset rate limit for key
   * @param {string} key - Rate limit key
   */
  reset(key) {
    this.store.delete(key);
  }
  /**
   * Get time until next allowed attempt
   * @param {string} key - Rate limit key
   * @returns {number} Milliseconds until next attempt allowed
   */
  getRetryAfter(key) {
    if (!this.store.has(key)) {
      return 0;
    }
    const entry = this.store.get(key);
    if (entry.attempts.length === 0) {
      return 0;
    }
    const oldestAttempt = entry.attempts[0];
    const expiresAt = oldestAttempt + this.windowMs;
    const now = Date.now();
    return Math.max(0, expiresAt - now);
  }
  /**
   * Cleanup expired entries
   * @private
   */
  cleanup() {
    const now = Date.now();
    const cutoff = now - this.windowMs;
    for (const [key, entry] of this.store.entries()) {
      entry.attempts = entry.attempts.filter((timestamp) => timestamp > cutoff);
      if (entry.attempts.length === 0) {
        this.store.delete(key);
      }
    }
  }
  /**
   * Stop cleanup timer
   */
  stop() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
  }
  /**
   * Get statistics
   * @returns {Object} Store statistics
   */
  getStats() {
    return {
      totalKeys: this.store.size,
      totalAttempts: Array.from(this.store.values()).reduce(
        (sum, entry) => sum + entry.attempts.length,
        0
      )
    };
  }
}
function createDriverRateLimiter(config = {}) {
  const {
    windowMs = 9e5,
    // 15 minutes
    maxAttempts = 5,
    keyPrefix = "ratelimit",
    keyGenerator = null,
    skipSuccessfulRequests = false,
    handler = null,
    enabled = true
  } = config;
  if (!enabled) {
    return async (c, next) => await next();
  }
  const store = new RateLimitStore({ windowMs });
  return async (c, next) => {
    let key;
    if (keyGenerator && typeof keyGenerator === "function") {
      key = await keyGenerator(c);
    } else {
      const ip = c.req.header("x-forwarded-for") || c.req.header("x-real-ip") || "unknown";
      key = `${keyPrefix}:${ip}`;
    }
    const currentCount = store.getCount(key);
    if (currentCount >= maxAttempts) {
      const retryAfter = store.getRetryAfter(key);
      const retryAfterSeconds = Math.ceil(retryAfter / 1e3);
      c.header("Retry-After", String(retryAfterSeconds));
      c.header("X-RateLimit-Limit", String(maxAttempts));
      c.header("X-RateLimit-Remaining", "0");
      c.header("X-RateLimit-Reset", String(Date.now() + retryAfter));
      if (handler && typeof handler === "function") {
        return handler(c, { retryAfter: retryAfterSeconds });
      }
      return c.json({
        error: "Too Many Requests",
        message: `Rate limit exceeded. Try again in ${retryAfterSeconds} seconds.`,
        retryAfter: retryAfterSeconds
      }, 429);
    }
    if (!skipSuccessfulRequests) {
      store.record(key);
    }
    const previousUser = c.get("user");
    await next();
    if (skipSuccessfulRequests) {
      const currentUser = c.get("user");
      if (!currentUser && !previousUser) {
        store.record(key);
      }
    }
    const remaining = Math.max(0, maxAttempts - store.getCount(key));
    c.header("X-RateLimit-Limit", String(maxAttempts));
    c.header("X-RateLimit-Remaining", String(remaining));
  };
}
function createAuthDriverRateLimiter(driver, config = {}) {
  const defaults = {
    oidc: {
      windowMs: 9e5,
      // 15 minutes
      maxAttempts: 5,
      keyPrefix: "auth:oidc",
      skipSuccessfulRequests: true
    },
    jwt: {
      windowMs: 3e5,
      // 5 minutes
      maxAttempts: 20,
      keyPrefix: "auth:jwt",
      skipSuccessfulRequests: false
    },
    basic: {
      windowMs: 9e5,
      // 15 minutes
      maxAttempts: 10,
      keyPrefix: "auth:basic",
      skipSuccessfulRequests: true
    },
    apikey: {
      windowMs: 6e4,
      // 1 minute
      maxAttempts: 100,
      keyPrefix: "auth:apikey",
      skipSuccessfulRequests: false
    }
  };
  const driverDefaults = defaults[driver] || defaults.basic;
  const finalConfig = { ...driverDefaults, ...config };
  return createDriverRateLimiter(finalConfig);
}

async function getOrCreateUser(usersResource, claims, config) {
  const {
    autoCreateUser = true,
    userIdClaim = "sub",
    fallbackIdClaims = ["email", "preferred_username"],
    lookupFields = ["email", "preferred_username"]
  } = config;
  const candidateIds = [];
  if (userIdClaim && claims[userIdClaim]) {
    candidateIds.push(String(claims[userIdClaim]));
  }
  for (const field of fallbackIdClaims) {
    if (!field || field === userIdClaim) continue;
    const value = claims[field];
    if (value) {
      candidateIds.push(String(value));
    }
  }
  let user = null;
  for (const candidate of candidateIds) {
    try {
      user = await usersResource.get(candidate);
      break;
    } catch (_) {
    }
  }
  if (!user) {
    const fields = Array.isArray(lookupFields) ? lookupFields : [lookupFields];
    for (const field of fields) {
      if (!field) continue;
      const value = claims[field];
      if (!value) continue;
      const results = await usersResource.query({ [field]: value }, { limit: 1 });
      if (results.length > 0) {
        user = results[0];
        break;
      }
    }
  }
  const now = (/* @__PURE__ */ new Date()).toISOString();
  if (user) {
    const updates = {
      lastLoginAt: now,
      metadata: {
        ...user.metadata,
        oidc: {
          sub: claims.sub,
          provider: config.issuer,
          lastSync: now,
          claims: {
            name: claims.name,
            email: claims.email,
            picture: claims.picture
          }
        }
      }
    };
    if (claims.name && claims.name !== user.name) {
      updates.name = claims.name;
    }
    if (config.beforeUpdateUser && typeof config.beforeUpdateUser === "function") {
      try {
        const enrichedData = await config.beforeUpdateUser({
          user,
          updates,
          claims,
          usersResource
        });
        if (enrichedData && typeof enrichedData === "object") {
          Object.assign(updates, enrichedData);
          if (enrichedData.metadata) {
            updates.metadata = {
              ...updates.metadata,
              ...enrichedData.metadata
            };
          }
        }
      } catch (hookErr) {
        console.error("[OIDC] beforeUpdateUser hook failed:", hookErr);
      }
    }
    user = await usersResource.update(userId, updates);
    return { user, created: false };
  }
  if (!autoCreateUser) {
    return { user: null, created: false };
  }
  const newUserId = candidateIds[0];
  if (!newUserId) {
    throw new Error("Cannot determine user ID from OIDC claims");
  }
  const newUser = {
    id: newUserId,
    email: claims.email || newUserId,
    username: claims.preferred_username || claims.email || newUserId,
    name: claims.name || claims.email || newUserId,
    picture: claims.picture || null,
    role: config.defaultRole || "user",
    scopes: config.defaultScopes || ["openid", "profile", "email"],
    active: true,
    apiKey: null,
    // Will be generated on first API usage if needed
    lastLoginAt: now,
    metadata: {
      oidc: {
        sub: claims.sub,
        provider: config.issuer,
        createdAt: now,
        claims: {
          name: claims.name,
          email: claims.email,
          picture: claims.picture
        }
      },
      costCenterId: config.defaultCostCenter || null,
      teamId: config.defaultTeam || null
    }
  };
  if (config.beforeCreateUser && typeof config.beforeCreateUser === "function") {
    try {
      const enrichedData = await config.beforeCreateUser({
        user: newUser,
        claims,
        usersResource
      });
      if (enrichedData && typeof enrichedData === "object") {
        Object.assign(newUser, enrichedData);
        if (enrichedData.metadata) {
          newUser.metadata = {
            ...newUser.metadata,
            ...enrichedData.metadata
          };
        }
      }
    } catch (hookErr) {
      console.error("[OIDC] beforeCreateUser hook failed:", hookErr);
    }
  }
  user = await usersResource.insert(newUser);
  return { user, created: true };
}
async function refreshAccessToken(tokenEndpoint, refreshToken, clientId, clientSecret) {
  const response = await fetch(tokenEndpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/x-www-form-urlencoded",
      "Authorization": `Basic ${Buffer.from(`${clientId}:${clientSecret}`).toString("base64")}`
    },
    body: new URLSearchParams({
      grant_type: "refresh_token",
      refresh_token: refreshToken
    })
  });
  if (!response.ok) {
    throw new Error(`Token refresh failed: ${response.status}`);
  }
  return await response.json();
}
function createOIDCHandler(config, app, usersResource, events = null) {
  const finalConfig = {
    scopes: ["openid", "profile", "email", "offline_access"],
    cookieName: "oidc_session",
    cookieMaxAge: 6048e5,
    // 7 days (same as absolute duration)
    rollingDuration: 864e5,
    // 24 hours
    absoluteDuration: 6048e5,
    // 7 days
    loginPath: "/auth/login",
    callbackPath: "/auth/callback",
    logoutPath: "/auth/logout",
    postLoginRedirect: "/",
    postLogoutRedirect: "/",
    idpLogout: true,
    autoCreateUser: true,
    userIdClaim: "sub",
    fallbackIdClaims: ["email", "preferred_username"],
    lookupFields: ["email", "preferred_username"],
    autoRefreshTokens: true,
    refreshThreshold: 3e5,
    // 5 minutes before expiry
    cookieSecure: process.env.NODE_ENV === "production",
    cookieSameSite: "Lax",
    defaultRole: "user",
    defaultScopes: ["openid", "profile", "email"],
    rateLimit: config.rateLimit !== void 0 ? config.rateLimit : {
      enabled: true,
      windowMs: 9e5,
      // 15 minutes
      maxAttempts: 5,
      skipSuccessfulRequests: true
    },
    ...config
  };
  const {
    issuer,
    clientId,
    clientSecret,
    redirectUri,
    scopes,
    cookieSecret,
    cookieName,
    cookieMaxAge,
    rollingDuration,
    absoluteDuration,
    loginPath,
    callbackPath,
    logoutPath,
    postLoginRedirect,
    postLogoutRedirect,
    idpLogout,
    autoCreateUser,
    autoRefreshTokens,
    refreshThreshold,
    cookieSecure,
    cookieSameSite
  } = finalConfig;
  const authorizationEndpoint = `${issuer}/oauth/authorize`;
  const tokenEndpoint = `${issuer}/oauth/token`;
  const logoutEndpoint = `${issuer}/oauth2/v2.0/logout`;
  async function encodeSession(data) {
    const secret = new TextEncoder().encode(cookieSecret);
    const jwt = await new SignJWT(data).setProtectedHeader({ alg: "HS256" }).setIssuedAt().setExpirationTime(`${Math.floor(cookieMaxAge / 1e3)}s`).sign(secret);
    return jwt;
  }
  async function decodeSession(jwt) {
    try {
      const secret = new TextEncoder().encode(cookieSecret);
      const { payload } = await jwtVerify(jwt, secret);
      return payload;
    } catch (err) {
      return null;
    }
  }
  function validateSessionDuration(session) {
    const now = Date.now();
    if (session.issued_at + absoluteDuration < now) {
      return { valid: false, reason: "absolute_expired" };
    }
    if (session.last_activity + rollingDuration < now) {
      return { valid: false, reason: "rolling_expired" };
    }
    return { valid: true };
  }
  function generateState() {
    return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
  }
  function decodeIdToken(idToken) {
    try {
      const parts = idToken.split(".");
      if (parts.length !== 3) return null;
      const payload = Buffer.from(parts[1], "base64").toString("utf-8");
      return JSON.parse(payload);
    } catch (err) {
      return null;
    }
  }
  let rateLimiter = null;
  if (finalConfig.rateLimit?.enabled) {
    rateLimiter = createAuthDriverRateLimiter("oidc", finalConfig.rateLimit);
  }
  app.get(loginPath, async (c) => {
    const state = generateState();
    const stateJWT = await encodeSession({ state, type: "csrf", expires: Date.now() + 6e5 });
    c.header("Set-Cookie", `${cookieName}_state=${stateJWT}; Path=/; HttpOnly; Max-Age=600; SameSite=Lax`);
    const params = new URLSearchParams({
      response_type: "code",
      client_id: clientId,
      redirect_uri: redirectUri,
      scope: scopes.join(" "),
      state
    });
    return c.redirect(`${authorizationEndpoint}?${params.toString()}`, 302);
  });
  const callbackHandler = async (c) => {
    const code = c.req.query("code");
    const state = c.req.query("state");
    const stateCookie = c.req.cookie(`${cookieName}_state`);
    if (!stateCookie) {
      return c.json({ error: "Missing state cookie (CSRF protection)" }, 400);
    }
    const stateData = await decodeSession(stateCookie);
    if (!stateData || stateData.state !== state) {
      return c.json({ error: "Invalid state (CSRF protection)" }, 400);
    }
    c.header("Set-Cookie", `${cookieName}_state=; Path=/; HttpOnly; Max-Age=0`);
    if (!code) {
      return c.json({ error: "Missing authorization code" }, 400);
    }
    try {
      const tokenResponse = await fetch(tokenEndpoint, {
        method: "POST",
        headers: {
          "Content-Type": "application/x-www-form-urlencoded",
          "Authorization": `Basic ${Buffer.from(`${clientId}:${clientSecret}`).toString("base64")}`
        },
        body: new URLSearchParams({
          grant_type: "authorization_code",
          code,
          redirect_uri: redirectUri
        })
      });
      if (!tokenResponse.ok) {
        const error = await tokenResponse.text();
        console.error("[OIDC] Token exchange failed:", error);
        return c.json({ error: "Failed to exchange code for tokens" }, 500);
      }
      const tokens = await tokenResponse.json();
      const idTokenClaims = decodeIdToken(tokens.id_token);
      if (!idTokenClaims) {
        return c.json({ error: "Failed to decode id_token" }, 500);
      }
      let user = null;
      let userCreated = false;
      if (usersResource) {
        try {
          const result = await getOrCreateUser(usersResource, idTokenClaims, finalConfig);
          user = result.user;
          userCreated = result.created;
          if (!user) {
            return c.json({
              error: "User not provisioned",
              message: "User does not exist in configured auth resource"
            }, 403);
          }
          if (events) {
            if (userCreated) {
              events.emitUserEvent("created", {
                user: { id: user.id, email: user.email, name: user.name },
                source: "oidc",
                provider: finalConfig.issuer
              });
            }
            events.emitUserEvent("login", {
              user: { id: user.id, email: user.email, name: user.name },
              source: "oidc",
              provider: finalConfig.issuer,
              newUser: userCreated
            });
          }
          if (finalConfig.onUserAuthenticated && typeof finalConfig.onUserAuthenticated === "function") {
            try {
              await finalConfig.onUserAuthenticated({
                user,
                created: userCreated,
                claims: idTokenClaims,
                tokens: {
                  access_token: tokens.access_token,
                  id_token: tokens.id_token,
                  refresh_token: tokens.refresh_token
                },
                context: c
                //  Pass Hono context for cookie/header manipulation
              });
            } catch (hookErr) {
              console.error("[OIDC] onUserAuthenticated hook failed:", hookErr);
            }
          }
        } catch (err) {
          console.error("[OIDC] Failed to create/update user:", err);
        }
      }
      const now = Date.now();
      const sessionData = {
        access_token: tokens.access_token,
        id_token: tokens.id_token,
        refresh_token: tokens.refresh_token,
        expires_at: now + tokens.expires_in * 1e3,
        issued_at: now,
        last_activity: now,
        // User data (avoid DB lookup on every request)
        user: user ? {
          id: user.id,
          email: user.email,
          username: user.username,
          name: user.name,
          picture: user.picture,
          role: user.role,
          scopes: user.scopes,
          active: user.active,
          metadata: {
            costCenterId: user.metadata?.costCenterId,
            teamId: user.metadata?.teamId
          }
        } : {
          id: idTokenClaims.sub,
          email: idTokenClaims.email,
          username: idTokenClaims.preferred_username || idTokenClaims.email,
          name: idTokenClaims.name,
          picture: idTokenClaims.picture,
          role: "user",
          scopes,
          active: true,
          isVirtual: true
        }
      };
      const sessionJWT = await encodeSession(sessionData);
      const cookieOptions = [
        `${cookieName}=${sessionJWT}`,
        "Path=/",
        "HttpOnly",
        `Max-Age=${Math.floor(cookieMaxAge / 1e3)}`,
        `SameSite=${cookieSameSite}`
      ];
      if (cookieSecure) {
        cookieOptions.push("Secure");
      }
      c.header("Set-Cookie", cookieOptions.join("; "));
      return c.redirect(postLoginRedirect, 302);
    } catch (err) {
      console.error("[OIDC] Error during token exchange:", err);
      return c.json({ error: "Authentication failed" }, 500);
    }
  };
  if (rateLimiter) {
    app.get(callbackPath, rateLimiter, callbackHandler);
  } else {
    app.get(callbackPath, callbackHandler);
  }
  app.get(logoutPath, async (c) => {
    const sessionCookie = c.req.cookie(cookieName);
    let idToken = null;
    if (sessionCookie) {
      const session = await decodeSession(sessionCookie);
      idToken = session?.id_token;
    }
    c.header("Set-Cookie", `${cookieName}=; Path=/; HttpOnly; Max-Age=0`);
    if (idpLogout && idToken) {
      const params = new URLSearchParams({
        id_token_hint: idToken,
        post_logout_redirect_uri: `${postLogoutRedirect}`
      });
      return c.redirect(`${logoutEndpoint}?${params.toString()}`, 302);
    }
    return c.redirect(postLogoutRedirect, 302);
  });
  function matchPath(path, pattern) {
    if (pattern === path) return true;
    const regexPattern = pattern.replace(/\*\*/g, "___GLOBSTAR___").replace(/\*/g, "[^/]*").replace(/___GLOBSTAR___/g, ".*").replace(/\//g, "\\/") + "$";
    const regex = new RegExp("^" + regexPattern);
    return regex.test(path);
  }
  const middleware = async (c, next) => {
    const protectedPaths = finalConfig.protectedPaths || [];
    const currentPath = c.req.path;
    if (protectedPaths.length > 0) {
      const isProtected = protectedPaths.some((pattern) => matchPath(currentPath, pattern));
      if (!isProtected) {
        return await next();
      }
    }
    const sessionCookie = c.req.cookie(cookieName);
    if (!sessionCookie) {
      if (protectedPaths.length > 0) {
        const acceptHeader = c.req.header("accept") || "";
        const acceptsHtml = acceptHeader.includes("text/html");
        if (acceptsHtml) {
          const returnTo = encodeURIComponent(currentPath);
          return c.redirect(`${loginPath}?returnTo=${returnTo}`, 302);
        } else {
          const response = unauthorized("Authentication required");
          return c.json(response, response._status);
        }
      }
      return await next();
    }
    const session = await decodeSession(sessionCookie);
    if (!session || !session.access_token) {
      return await next();
    }
    const validation = validateSessionDuration(session);
    if (!validation.valid) {
      c.header("Set-Cookie", `${cookieName}=; Path=/; HttpOnly; Max-Age=0`);
      return await next();
    }
    if (autoRefreshTokens && session.refresh_token && session.expires_at) {
      const timeUntilExpiry = session.expires_at - Date.now();
      if (timeUntilExpiry < refreshThreshold) {
        try {
          const newTokens = await refreshAccessToken(
            tokenEndpoint,
            session.refresh_token,
            clientId,
            clientSecret
          );
          session.access_token = newTokens.access_token;
          session.expires_at = Date.now() + newTokens.expires_in * 1e3;
          if (newTokens.refresh_token) {
            session.refresh_token = newTokens.refresh_token;
          }
        } catch (err) {
          console.error("[OIDC] Token refresh failed:", err);
        }
      }
    }
    session.last_activity = Date.now();
    if (session.user.active !== void 0 && !session.user.active) {
      c.header("Set-Cookie", `${cookieName}=; Path=/; HttpOnly; Max-Age=0`);
      const acceptHeader = c.req.header("accept") || "";
      const acceptsHtml = acceptHeader.includes("text/html");
      if (acceptsHtml) {
        return c.redirect(`${loginPath}?error=account_inactive`, 302);
      } else {
        const response = unauthorized("User account is inactive");
        return c.json(response, response._status);
      }
    }
    c.set("user", {
      ...session.user,
      authMethod: "oidc",
      session: {
        access_token: session.access_token,
        refresh_token: session.refresh_token,
        expires_at: session.expires_at
      }
    });
    const newSessionJWT = await encodeSession(session);
    const cookieOptions = [
      `${cookieName}=${newSessionJWT}`,
      "Path=/",
      "HttpOnly",
      `Max-Age=${Math.floor(cookieMaxAge / 1e3)}`,
      `SameSite=${cookieSameSite}`
    ];
    if (cookieSecure) {
      cookieOptions.push("Secure");
    }
    c.header("Set-Cookie", cookieOptions.join("; "));
    return await next();
  };
  return {
    middleware,
    routes: {
      [loginPath]: "Login (redirect to SSO)",
      [callbackPath]: "OAuth2 callback",
      [logoutPath]: "Logout (local + IdP)"
    },
    config: finalConfig
  };
}

function patternToRegex$1(pattern) {
  let escaped = pattern.replace(/[.+?^${}()|[\]\\]/g, "\\$&");
  escaped = escaped.replace(/\*\*/g, "__DOUBLE_STAR__");
  escaped = escaped.replace(/\*/g, "([^/]+)");
  escaped = escaped.replace(/__DOUBLE_STAR__/g, "(.*)");
  return new RegExp(`^${escaped}$`);
}
function matchPath$1(pattern, path) {
  const regex = patternToRegex$1(pattern);
  return regex.test(path);
}
function calculateSpecificity$1(pattern) {
  const segments = pattern.split("/").filter((s) => s !== "");
  let score = 0;
  for (const segment of segments) {
    if (segment === "**") {
      score += 10;
    } else if (segment === "*") {
      score += 100;
    } else {
      score += 1e3;
    }
  }
  return score;
}
function findBestMatch(rules, path) {
  if (!rules || rules.length === 0) {
    return null;
  }
  const matches = rules.map((rule) => ({
    rule,
    specificity: calculateSpecificity$1(rule.pattern)
  })).filter(({ rule }) => matchPath$1(rule.pattern, path)).sort((a, b) => b.specificity - a.specificity);
  return matches.length > 0 ? matches[0].rule : null;
}
function validatePathAuth(pathAuth) {
  if (!Array.isArray(pathAuth)) {
    throw new Error("pathAuth must be an array of rules");
  }
  for (const [index, rule] of pathAuth.entries()) {
    if (!rule.pattern || typeof rule.pattern !== "string") {
      throw new Error(`pathAuth[${index}]: pattern is required and must be a string`);
    }
    if (!rule.pattern.startsWith("/")) {
      throw new Error(`pathAuth[${index}]: pattern must start with / (got: ${rule.pattern})`);
    }
    if (rule.drivers !== void 0 && !Array.isArray(rule.drivers)) {
      throw new Error(`pathAuth[${index}]: drivers must be an array (got: ${typeof rule.drivers})`);
    }
    if (rule.required !== void 0 && typeof rule.required !== "boolean") {
      throw new Error(`pathAuth[${index}]: required must be a boolean (got: ${typeof rule.required})`);
    }
    const validDrivers = ["jwt", "apiKey", "basic", "oauth2", "oidc"];
    if (rule.drivers) {
      for (const driver of rule.drivers) {
        if (!validDrivers.includes(driver)) {
          throw new Error(
            `pathAuth[${index}]: invalid driver '${driver}'. Valid drivers: ${validDrivers.join(", ")}`
          );
        }
      }
    }
  }
}

const MIME_TYPES = {
  // Text
  "txt": "text/plain",
  "html": "text/html",
  "htm": "text/html",
  "css": "text/css",
  "js": "text/javascript",
  "mjs": "text/javascript",
  "json": "application/json",
  "xml": "application/xml",
  "csv": "text/csv",
  "md": "text/markdown",
  // Images
  "jpg": "image/jpeg",
  "jpeg": "image/jpeg",
  "png": "image/png",
  "gif": "image/gif",
  "webp": "image/webp",
  "svg": "image/svg+xml",
  "ico": "image/x-icon",
  "bmp": "image/bmp",
  "tiff": "image/tiff",
  "tif": "image/tiff",
  // Audio
  "mp3": "audio/mpeg",
  "wav": "audio/wav",
  "ogg": "audio/ogg",
  "flac": "audio/flac",
  "m4a": "audio/mp4",
  // Video
  "mp4": "video/mp4",
  "webm": "video/webm",
  "ogv": "video/ogg",
  "avi": "video/x-msvideo",
  "mov": "video/quicktime",
  "mkv": "video/x-matroska",
  // Documents
  "pdf": "application/pdf",
  "doc": "application/msword",
  "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
  "xls": "application/vnd.ms-excel",
  "xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
  "ppt": "application/vnd.ms-powerpoint",
  "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
  // Archives
  "zip": "application/zip",
  "tar": "application/x-tar",
  "gz": "application/gzip",
  "bz2": "application/x-bzip2",
  "7z": "application/x-7z-compressed",
  "rar": "application/vnd.rar",
  // Fonts
  "ttf": "font/ttf",
  "otf": "font/otf",
  "woff": "font/woff",
  "woff2": "font/woff2",
  "eot": "application/vnd.ms-fontobject",
  // Application
  "wasm": "application/wasm",
  "bin": "application/octet-stream"
};
function getMimeType(filename) {
  if (!filename || typeof filename !== "string") {
    return "application/octet-stream";
  }
  const ext = filename.split(".").pop().toLowerCase();
  return MIME_TYPES[ext] || "application/octet-stream";
}
function getCharset(mimeType) {
  if (!mimeType) return null;
  if (mimeType.startsWith("text/")) return "utf-8";
  if (mimeType.includes("javascript")) return "utf-8";
  if (mimeType.includes("json")) return "utf-8";
  if (mimeType.includes("xml")) return "utf-8";
  return null;
}
function getContentType(filename) {
  const mimeType = getMimeType(filename);
  const charset = getCharset(mimeType);
  return charset ? `${mimeType}; charset=${charset}` : mimeType;
}

function createFilesystemHandler(config = {}) {
  const {
    root,
    index = ["index.html"],
    fallback = false,
    maxAge = 0,
    dotfiles = "ignore",
    etag = true,
    cors = false
  } = config;
  if (!root) {
    throw new Error('Filesystem static handler requires "root" directory');
  }
  const absoluteRoot = path.resolve(root);
  let fallbackFile = null;
  if (fallback === true) {
    fallbackFile = index[0];
  } else if (typeof fallback === "string") {
    fallbackFile = fallback;
  }
  return async (c) => {
    try {
      let requestPath = c.req.path.replace(/^\//, "");
      const safePath = path.normalize(requestPath).replace(/^(\.\.(\/|\\|$))+/, "");
      const fullPath = path.join(absoluteRoot, safePath);
      if (!fullPath.startsWith(absoluteRoot)) {
        return c.json({ success: false, error: { message: "Forbidden" } }, 403);
      }
      let stats;
      let useFallback = false;
      try {
        stats = await fs$1.stat(fullPath);
      } catch (err) {
        if (err.code === "ENOENT" && fallbackFile) {
          useFallback = true;
        } else if (err.code === "ENOENT") {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        } else {
          throw err;
        }
      }
      let filePath = fullPath;
      if (useFallback) {
        filePath = path.join(absoluteRoot, fallbackFile);
        try {
          stats = await fs$1.stat(filePath);
        } catch (err) {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
      }
      if (!useFallback && stats.isDirectory()) {
        let indexFound = false;
        for (const indexFile of index) {
          const indexPath = path.join(fullPath, indexFile);
          try {
            const indexStats = await fs$1.stat(indexPath);
            if (indexStats.isFile()) {
              filePath = indexPath;
              stats = indexStats;
              indexFound = true;
              break;
            }
          } catch (err) {
          }
        }
        if (!indexFound) {
          if (fallbackFile) {
            filePath = path.join(absoluteRoot, fallbackFile);
            try {
              stats = await fs$1.stat(filePath);
            } catch (err) {
              return c.json({ success: false, error: { message: "Forbidden" } }, 403);
            }
          } else {
            return c.json({ success: false, error: { message: "Forbidden" } }, 403);
          }
        }
      }
      const filename = path.basename(filePath);
      if (filename.startsWith(".")) {
        if (dotfiles === "deny") {
          return c.json({ success: false, error: { message: "Forbidden" } }, 403);
        } else if (dotfiles === "ignore") {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
      }
      const etagValue = etag ? `"${crypto.createHash("md5").update(`${stats.mtime.getTime()}-${stats.size}`).digest("hex")}"` : null;
      if (etagValue) {
        const ifNoneMatch = c.req.header("If-None-Match");
        if (ifNoneMatch === etagValue) {
          return c.body(null, 304, {
            "ETag": etagValue,
            "Cache-Control": maxAge > 0 ? `public, max-age=${Math.floor(maxAge / 1e3)}` : "no-cache"
          });
        }
      }
      const contentType = getContentType(filename);
      const headers = {
        "Content-Type": contentType,
        "Content-Length": stats.size.toString(),
        "Last-Modified": stats.mtime.toUTCString()
      };
      if (etagValue) {
        headers["ETag"] = etagValue;
      }
      if (maxAge > 0) {
        headers["Cache-Control"] = `public, max-age=${Math.floor(maxAge / 1e3)}`;
      } else {
        headers["Cache-Control"] = "no-cache";
      }
      if (cors) {
        headers["Access-Control-Allow-Origin"] = "*";
        headers["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
      }
      const rangeHeader = c.req.header("Range");
      if (rangeHeader) {
        const parts = rangeHeader.replace(/bytes=/, "").split("-");
        const start = parseInt(parts[0], 10);
        const end = parts[1] ? parseInt(parts[1], 10) : stats.size - 1;
        if (start >= stats.size || end >= stats.size) {
          return c.body(null, 416, {
            "Content-Range": `bytes */${stats.size}`
          });
        }
        const chunkSize = end - start + 1;
        const stream2 = createReadStream(filePath, { start, end });
        headers["Content-Range"] = `bytes ${start}-${end}/${stats.size}`;
        headers["Content-Length"] = chunkSize.toString();
        headers["Accept-Ranges"] = "bytes";
        return c.body(stream2, 206, headers);
      }
      if (c.req.method === "HEAD") {
        return c.body(null, 200, headers);
      }
      const stream = createReadStream(filePath);
      return c.body(stream, 200, headers);
    } catch (err) {
      console.error("[Static Filesystem] Error:", err);
      return c.json({ success: false, error: { message: "Internal Server Error" } }, 500);
    }
  };
}
function validateFilesystemConfig(config) {
  if (!config.root || typeof config.root !== "string") {
    throw new Error('Filesystem static config requires "root" directory (string)');
  }
  if (config.index !== void 0 && !Array.isArray(config.index)) {
    throw new Error('Filesystem static "index" must be an array');
  }
  if (config.fallback !== void 0 && typeof config.fallback !== "string" && typeof config.fallback !== "boolean") {
    throw new Error('Filesystem static "fallback" must be a string (filename) or boolean');
  }
  if (config.maxAge !== void 0 && typeof config.maxAge !== "number") {
    throw new Error('Filesystem static "maxAge" must be a number');
  }
  if (config.dotfiles !== void 0 && !["ignore", "allow", "deny"].includes(config.dotfiles)) {
    throw new Error('Filesystem static "dotfiles" must be "ignore", "allow", or "deny"');
  }
  if (config.etag !== void 0 && typeof config.etag !== "boolean") {
    throw new Error('Filesystem static "etag" must be a boolean');
  }
  if (config.cors !== void 0 && typeof config.cors !== "boolean") {
    throw new Error('Filesystem static "cors" must be a boolean');
  }
}

function createS3Handler(config = {}) {
  const {
    s3Client,
    bucket,
    prefix = "",
    streaming = true,
    signedUrlExpiry = 300,
    maxAge = 0,
    cacheControl,
    contentDisposition = "inline",
    etag = true,
    cors = false
  } = config;
  if (!s3Client) {
    throw new Error('S3 static handler requires "s3Client"');
  }
  if (!bucket) {
    throw new Error('S3 static handler requires "bucket" name');
  }
  return async (c) => {
    try {
      let requestPath = c.req.path.replace(/^\//, "");
      const key = prefix ? `${prefix}${requestPath}` : requestPath;
      if (key.includes("..") || key.includes("//")) {
        return c.json({ success: false, error: { message: "Forbidden" } }, 403);
      }
      let metadata;
      try {
        const headCommand = new HeadObjectCommand({ Bucket: bucket, Key: key });
        metadata = await s3Client.send(headCommand);
      } catch (err) {
        if (err.name === "NotFound" || err.$metadata?.httpStatusCode === 404) {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
        throw err;
      }
      if (etag && metadata.ETag) {
        const ifNoneMatch = c.req.header("If-None-Match");
        if (ifNoneMatch === metadata.ETag) {
          const headers2 = {
            "ETag": metadata.ETag,
            "Cache-Control": cacheControl || (maxAge > 0 ? `public, max-age=${Math.floor(maxAge / 1e3)}` : "no-cache")
          };
          if (cors) {
            headers2["Access-Control-Allow-Origin"] = "*";
            headers2["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
          }
          return c.body(null, 304, headers2);
        }
      }
      if (!streaming) {
        const getCommand2 = new GetObjectCommand({ Bucket: bucket, Key: key });
        const signedUrl = await getSignedUrl(s3Client, getCommand2, { expiresIn: signedUrlExpiry });
        return c.redirect(signedUrl, 302);
      }
      const contentType = metadata.ContentType || getContentType(key);
      const headers = {
        "Content-Type": contentType,
        "Content-Length": metadata.ContentLength?.toString() || "0",
        "Last-Modified": metadata.LastModified?.toUTCString() || (/* @__PURE__ */ new Date()).toUTCString()
      };
      if (metadata.ETag && etag) {
        headers["ETag"] = metadata.ETag;
      }
      if (cacheControl) {
        headers["Cache-Control"] = cacheControl;
      } else if (maxAge > 0) {
        headers["Cache-Control"] = `public, max-age=${Math.floor(maxAge / 1e3)}`;
      } else {
        headers["Cache-Control"] = "no-cache";
      }
      if (contentDisposition) {
        const filename = key.split("/").pop();
        headers["Content-Disposition"] = `${contentDisposition}; filename="${filename}"`;
      }
      if (cors) {
        headers["Access-Control-Allow-Origin"] = "*";
        headers["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
      }
      const rangeHeader = c.req.header("Range");
      let getCommand;
      if (rangeHeader) {
        const parts = rangeHeader.replace(/bytes=/, "").split("-");
        const start = parseInt(parts[0], 10);
        const end = parts[1] ? parseInt(parts[1], 10) : metadata.ContentLength - 1;
        if (start >= metadata.ContentLength || end >= metadata.ContentLength) {
          return c.body(null, 416, {
            "Content-Range": `bytes */${metadata.ContentLength}`
          });
        }
        const range = `bytes=${start}-${end}`;
        getCommand = new GetObjectCommand({ Bucket: bucket, Key: key, Range: range });
        const chunkSize = end - start + 1;
        headers["Content-Range"] = `bytes ${start}-${end}/${metadata.ContentLength}`;
        headers["Content-Length"] = chunkSize.toString();
        headers["Accept-Ranges"] = "bytes";
        const response2 = await s3Client.send(getCommand);
        return c.body(response2.Body, 206, headers);
      }
      if (c.req.method === "HEAD") {
        return c.body(null, 200, headers);
      }
      getCommand = new GetObjectCommand({ Bucket: bucket, Key: key });
      const response = await s3Client.send(getCommand);
      return c.body(response.Body, 200, headers);
    } catch (err) {
      console.error("[Static S3] Error:", err);
      return c.json({ success: false, error: { message: "Internal Server Error" } }, 500);
    }
  };
}
function validateS3Config(config) {
  if (!config.bucket || typeof config.bucket !== "string") {
    throw new Error('S3 static config requires "bucket" name (string)');
  }
  if (config.prefix !== void 0 && typeof config.prefix !== "string") {
    throw new Error('S3 static "prefix" must be a string');
  }
  if (config.streaming !== void 0 && typeof config.streaming !== "boolean") {
    throw new Error('S3 static "streaming" must be a boolean');
  }
  if (config.signedUrlExpiry !== void 0 && typeof config.signedUrlExpiry !== "number") {
    throw new Error('S3 static "signedUrlExpiry" must be a number');
  }
  if (config.maxAge !== void 0 && typeof config.maxAge !== "number") {
    throw new Error('S3 static "maxAge" must be a number');
  }
  if (config.cacheControl !== void 0 && typeof config.cacheControl !== "string") {
    throw new Error('S3 static "cacheControl" must be a string');
  }
  if (config.contentDisposition !== void 0 && typeof config.contentDisposition !== "string") {
    throw new Error('S3 static "contentDisposition" must be a string');
  }
  if (config.etag !== void 0 && typeof config.etag !== "boolean") {
    throw new Error('S3 static "etag" must be a boolean');
  }
  if (config.cors !== void 0 && typeof config.cors !== "boolean") {
    throw new Error('S3 static "cors" must be a boolean');
  }
}

async function loadEJS() {
  try {
    const ejs = await import('ejs');
    return ejs.default || ejs;
  } catch (err) {
    throw new Error(
      "EJS template engine not installed. Install with: npm install ejs\nEJS is a peer dependency to keep the core package lightweight."
    );
  }
}
async function loadPug() {
  try {
    const pug = await import('pug');
    return pug.default || pug;
  } catch (err) {
    throw new Error(
      "Pug template engine not installed. Install with: npm install pug\nPug is a peer dependency to keep the core package lightweight."
    );
  }
}
function setupTemplateEngine(options = {}) {
  const {
    engine = "jsx",
    templatesDir = "./views",
    layout = null,
    engineOptions = {},
    customRenderer = null
  } = options;
  const templatesPath = resolve(templatesDir);
  return async (c, next) => {
    c.render = async (template, data = {}, renderOptions = {}) => {
      if (typeof template === "object" && template !== null) {
        return c.html(template);
      }
      if (engine === "pug") {
        const pug = await loadPug();
        const templateFile = template.endsWith(".pug") ? template : `${template}.pug`;
        const templatePath = join(templatesPath, templateFile);
        if (!existsSync(templatePath)) {
          throw new Error(`Template not found: ${templatePath}`);
        }
        const renderData = {
          ...data,
          // Add helpers that Pug templates might expect
          _url: c.req.url,
          _path: c.req.path,
          _method: c.req.method
        };
        const html = pug.renderFile(templatePath, {
          ...renderData,
          ...engineOptions,
          ...renderOptions
        });
        return c.html(html);
      }
      if (engine === "ejs") {
        const ejs = await loadEJS();
        const templateFile = template.endsWith(".ejs") ? template : `${template}.ejs`;
        const templatePath = join(templatesPath, templateFile);
        if (!existsSync(templatePath)) {
          throw new Error(`Template not found: ${templatePath}`);
        }
        const templateContent = await readFile(templatePath, "utf-8");
        const renderData = {
          ...data,
          // Add helpers that EJS templates might expect
          _url: c.req.url,
          _path: c.req.path,
          _method: c.req.method
        };
        const html = ejs.render(templateContent, renderData, {
          filename: templatePath,
          // For includes to work
          ...engineOptions,
          ...renderOptions
        });
        if (layout || renderOptions.layout) {
          const layoutName = renderOptions.layout || layout;
          const layoutFile = layoutName.endsWith(".ejs") ? layoutName : `${layoutName}.ejs`;
          const layoutPath = join(templatesPath, layoutFile);
          if (!existsSync(layoutPath)) {
            throw new Error(`Layout not found: ${layoutPath}`);
          }
          const layoutContent = await readFile(layoutPath, "utf-8");
          const wrappedHtml = ejs.render(layoutContent, {
            ...renderData,
            body: html
            // Content goes into <%- body %>
          }, {
            filename: layoutPath,
            ...engineOptions
          });
          return c.html(wrappedHtml);
        }
        return c.html(html);
      }
      if (engine === "custom" && customRenderer) {
        return customRenderer(c, template, data, renderOptions);
      }
      throw new Error(`Unsupported template engine: ${engine}`);
    };
    await next();
  };
}

function calculateSpecificity(pattern) {
  let score = 0;
  if (!pattern.includes("*") && !pattern.includes(":")) {
    score += 1e4;
  }
  const segments = pattern.split("/").filter((s) => s.length > 0);
  score += segments.length * 100;
  const singleWildcards = (pattern.match(/(?<!\*)\*(?!\*)/g) || []).length;
  const doubleWildcards = (pattern.match(/\*\*/g) || []).length;
  score -= singleWildcards * 10;
  score -= doubleWildcards * 50;
  const params = (pattern.match(/:[^/]+/g) || []).length;
  score -= params * 5;
  return score;
}
function patternToRegex(pattern) {
  let regexPattern = pattern.replace(/[.+?^${}()|[\]\\]/g, "\\$&");
  regexPattern = regexPattern.replace(/:([^/]+)/g, "([^/]+)");
  regexPattern = regexPattern.replace(/\*\*/g, "___GLOBSTAR___").replace(/\*/g, "[^/]*").replace(/___GLOBSTAR___/g, ".*");
  if (pattern.endsWith("/**")) {
    regexPattern = regexPattern.replace(/\/\.\*$/, "(?:/.*)?");
  }
  regexPattern = "^" + regexPattern + "$";
  return new RegExp(regexPattern);
}
function matchPath(path, pattern) {
  if (path === pattern) return true;
  const regex = patternToRegex(pattern);
  return regex.test(path);
}
function findAuthRule(path, rules = []) {
  if (!rules || rules.length === 0) {
    return null;
  }
  const matches = rules.map((rule) => ({
    ...rule,
    specificity: calculateSpecificity(rule.path)
  })).filter((rule) => matchPath(path, rule.path)).sort((a, b) => b.specificity - a.specificity);
  return matches.length > 0 ? matches[0] : null;
}
function createPathBasedAuthMiddleware(options = {}) {
  const {
    rules = [],
    authMiddlewares = {},
    unauthorizedHandler = null,
    events = null
  } = options;
  return async (c, next) => {
    const currentPath = c.req.path;
    const rule = findAuthRule(currentPath, rules);
    if (!rule) {
      return await next();
    }
    if (!rule.required) {
      return await next();
    }
    if (rule.methods.length === 0 && rule.required) {
      console.error(`[Path Auth] Invalid rule: path "${rule.path}" requires auth but has no methods`);
      if (unauthorizedHandler) {
        return unauthorizedHandler(c, "Configuration error");
      }
      return c.json({ error: "Configuration error" }, 500);
    }
    const allowedMiddlewares = rule.methods.map((methodName) => ({
      name: methodName,
      middleware: authMiddlewares[methodName]
    })).filter((m) => m.middleware);
    if (allowedMiddlewares.length === 0) {
      console.error(`[Path Auth] No middlewares found for methods: ${rule.methods.join(", ")}`);
      if (unauthorizedHandler) {
        return unauthorizedHandler(c, "No auth methods available");
      }
      return c.json({ error: "No auth methods available" }, 500);
    }
    const strategy = rule.strategy || "any";
    const priorities = rule.priorities || {};
    if (strategy === "priority" && Object.keys(priorities).length > 0) {
      allowedMiddlewares.sort((a, b) => {
        const priorityA = priorities[a.name] || 999;
        const priorityB = priorities[b.name] || 999;
        return priorityA - priorityB;
      });
    }
    for (const { name, middleware } of allowedMiddlewares) {
      let authSuccess = false;
      const tempNext = async () => {
        authSuccess = true;
      };
      await middleware(c, tempNext);
      if (authSuccess && c.get("user")) {
        if (events) {
          events.emitAuthEvent("success", {
            method: name,
            user: c.get("user"),
            path: currentPath,
            rule: rule.path
          });
        }
        return await next();
      }
    }
    if (events) {
      events.emitAuthEvent("failure", {
        path: currentPath,
        rule: rule.path,
        allowedMethods: rule.methods,
        ip: c.req.header("x-forwarded-for") || c.req.header("x-real-ip")
      });
    }
    const acceptHeader = c.req.header("accept") || "";
    const acceptsHtml = acceptHeader.includes("text/html");
    const unauthorizedBehavior = rule.unauthorizedBehavior || "auto";
    if (unauthorizedBehavior === "auto") {
      if (acceptsHtml) {
        const returnTo = encodeURIComponent(c.req.path);
        return c.redirect(`/auth/login?returnTo=${returnTo}`);
      } else {
        return c.json({
          error: "Unauthorized",
          message: `Authentication required. Allowed methods: ${rule.methods.join(", ")}`
        }, 401);
      }
    }
    if (typeof unauthorizedBehavior === "object") {
      if (acceptsHtml && unauthorizedBehavior.html === "redirect") {
        const returnTo = encodeURIComponent(c.req.path);
        const loginPath = unauthorizedBehavior.loginPath || "/auth/login";
        return c.redirect(`${loginPath}?returnTo=${returnTo}`);
      }
      if (!acceptsHtml && unauthorizedBehavior.json) {
        return c.json(
          unauthorizedBehavior.json,
          unauthorizedBehavior.json.status || 401
        );
      }
    }
    if (unauthorizedHandler) {
      return unauthorizedHandler(c, `Authentication required. Allowed methods: ${rule.methods.join(", ")}`);
    }
    return c.json({
      error: "Unauthorized",
      message: `Authentication required. Allowed methods: ${rule.methods.join(", ")}`
    }, 401);
  };
}

function createRequestIdMiddleware(config = {}) {
  const {
    headerName = "X-Request-ID",
    generator = () => idGenerator(),
    includeInResponse = true,
    includeInLogs = true
    // Reserved for future use
  } = config;
  return async (c, next) => {
    let requestId = c.req.header(headerName);
    if (!requestId) {
      requestId = generator();
    }
    c.set("requestId", requestId);
    await next();
    if (includeInResponse) {
      c.header(headerName, requestId);
    }
  };
}

function createSecurityHeadersMiddleware(config = {}) {
  const defaults = {
    csp: "default-src 'self'",
    hsts: { maxAge: 31536e3, includeSubDomains: true, preload: false },
    xFrameOptions: "DENY",
    xContentTypeOptions: "nosniff",
    referrerPolicy: "strict-origin-when-cross-origin",
    xssProtection: "1; mode=block",
    permissionsPolicy: "geolocation=(), microphone=(), camera=()"
  };
  const settings = {
    ...defaults,
    ...config.headers || {}
  };
  if (config.headers?.hsts && typeof config.headers.hsts === "object") {
    settings.hsts = {
      ...defaults.hsts,
      ...config.headers.hsts
    };
  }
  return async (c, next) => {
    if (settings.csp) {
      c.header("Content-Security-Policy", settings.csp);
    }
    if (settings.hsts) {
      const hsts = settings.hsts;
      let hstsValue = `max-age=${hsts.maxAge}`;
      if (hsts.includeSubDomains) {
        hstsValue += "; includeSubDomains";
      }
      if (hsts.preload) {
        hstsValue += "; preload";
      }
      c.header("Strict-Transport-Security", hstsValue);
    }
    if (settings.xFrameOptions) {
      c.header("X-Frame-Options", settings.xFrameOptions);
    }
    if (settings.xContentTypeOptions) {
      c.header("X-Content-Type-Options", settings.xContentTypeOptions);
    }
    if (settings.referrerPolicy) {
      c.header("Referrer-Policy", settings.referrerPolicy);
    }
    if (settings.xssProtection) {
      c.header("X-XSS-Protection", settings.xssProtection);
    }
    if (settings.permissionsPolicy) {
      c.header("Permissions-Policy", settings.permissionsPolicy);
    }
    await next();
  };
}

function createSessionTrackingMiddleware(config = {}, db) {
  const {
    enabled = false,
    resource = null,
    cookieName = "session_id",
    cookieMaxAge = 2592e6,
    // 30 days
    cookieSecure = process.env.NODE_ENV === "production",
    cookieSameSite = "Strict",
    updateOnRequest = true,
    passphrase = null,
    enrichSession = null
  } = config;
  if (!enabled) {
    return async (c, next) => await next();
  }
  if (!passphrase) {
    throw new Error("sessionTracking.passphrase is required when sessionTracking.enabled = true");
  }
  const sessionsResource = resource && db ? db.resources[resource] : null;
  return async (c, next) => {
    let session = null;
    let sessionId = null;
    let isNewSession = false;
    const sessionCookie = c.req.cookie(cookieName);
    if (sessionCookie) {
      try {
        sessionId = await decrypt(sessionCookie, passphrase);
        if (sessionsResource) {
          const exists = await sessionsResource.exists(sessionId);
          if (exists) {
            session = await sessionsResource.get(sessionId);
          }
        } else {
          session = { id: sessionId };
        }
      } catch (err) {
        console.error("[SessionTracking] Failed to decrypt cookie:", err.message);
      }
    }
    if (!session) {
      isNewSession = true;
      sessionId = idGenerator();
      const sessionData = {
        id: sessionId,
        userAgent: c.req.header("user-agent") || null,
        ip: c.req.header("x-forwarded-for") || c.req.header("x-real-ip") || null,
        referer: c.req.header("referer") || null,
        createdAt: (/* @__PURE__ */ new Date()).toISOString(),
        lastSeenAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      if (enrichSession && typeof enrichSession === "function") {
        try {
          const enriched = await enrichSession({ session: sessionData, context: c });
          if (enriched && typeof enriched === "object") {
            Object.assign(sessionData, enriched);
          }
        } catch (enrichErr) {
          console.error("[SessionTracking] enrichSession failed:", enrichErr.message);
        }
      }
      if (sessionsResource) {
        try {
          session = await sessionsResource.insert(sessionData);
        } catch (insertErr) {
          console.error("[SessionTracking] Failed to insert session:", insertErr.message);
          session = sessionData;
        }
      } else {
        session = sessionData;
      }
    } else if (updateOnRequest && !isNewSession && sessionsResource) {
      const updates = {
        lastSeenAt: (/* @__PURE__ */ new Date()).toISOString(),
        lastUserAgent: c.req.header("user-agent") || null,
        lastIp: c.req.header("x-forwarded-for") || c.req.header("x-real-ip") || null
      };
      sessionsResource.update(sessionId, updates).catch((updateErr) => {
        console.error("[SessionTracking] Failed to update session:", updateErr.message);
      });
      Object.assign(session, updates);
    }
    try {
      const encryptedSessionId = await encrypt(sessionId, passphrase);
      c.header(
        "Set-Cookie",
        `${cookieName}=${encryptedSessionId}; Max-Age=${Math.floor(cookieMaxAge / 1e3)}; Path=/; HttpOnly; ` + (cookieSecure ? "Secure; " : "") + `SameSite=${cookieSameSite}`
      );
    } catch (encryptErr) {
      console.error("[SessionTracking] Failed to encrypt session ID:", encryptErr.message);
    }
    c.set("sessionId", sessionId);
    c.set("session", session);
    await next();
  };
}

function createFailbanMiddleware(config = {}) {
  const {
    plugin,
    events = null,
    handler = null
  } = config;
  if (!plugin || !plugin.options.enabled) {
    return async (c, next) => await next();
  }
  return async (c, next) => {
    const ip = c.req.header("x-forwarded-for")?.split(",")[0]?.trim() || c.req.header("x-real-ip") || "unknown";
    if (plugin.isBlacklisted(ip)) {
      c.header("X-Ban-Status", "blacklisted");
      c.header("X-Ban-Reason", "IP is permanently blacklisted");
      if (handler) {
        return handler(c, { ip, reason: "blacklisted", permanent: true });
      }
      return c.json({
        error: "Forbidden",
        message: "Your IP address has been permanently blocked",
        ip
      }, 403);
    }
    const countryBlock = plugin.checkCountryBlock(ip);
    if (countryBlock) {
      c.header("X-Ban-Status", "country_blocked");
      c.header("X-Ban-Reason", countryBlock.reason);
      c.header("X-Country-Code", countryBlock.country);
      if (events) {
        events.emit("security:country_blocked", {
          ip,
          country: countryBlock.country,
          reason: countryBlock.reason,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
      if (handler) {
        return handler(c, countryBlock);
      }
      return c.json({
        error: "Forbidden",
        message: "Access from your country is not allowed",
        country: countryBlock.country,
        ip
      }, 403);
    }
    if (plugin.isBanned(ip)) {
      const ban = await plugin.getBan(ip);
      if (ban) {
        const expiresAt = new Date(ban.expiresAt);
        const retryAfter = Math.ceil((expiresAt.getTime() - Date.now()) / 1e3);
        c.header("Retry-After", String(retryAfter));
        c.header("X-Ban-Status", "banned");
        c.header("X-Ban-Reason", ban.reason);
        c.header("X-Ban-Expires", ban.expiresAt);
        if (handler) {
          return handler(c, { ip, ban, retryAfter });
        }
        return c.json({
          error: "Forbidden",
          message: "Your IP address has been temporarily banned due to security violations",
          reason: ban.reason,
          expiresAt: ban.expiresAt,
          retryAfter
        }, 403);
      }
    }
    await next();
  };
}
function setupFailbanViolationListener(config = {}) {
  const { plugin, events } = config;
  if (!plugin || !plugin.options.enabled || !events) {
    return;
  }
  events.on("auth:failure", (data) => {
    const ip = data.ip || "unknown";
    plugin.recordViolation(ip, "auth_failure", {
      path: data.path,
      allowedMethods: data.allowedMethods
    });
  });
  events.on("request:error", (data) => {
    const ip = data.ip || "unknown";
    if (data.status && data.status >= 400 && data.status < 500) {
      plugin.recordViolation(ip, "request_error", {
        path: data.path,
        error: data.error,
        userAgent: data.userAgent
      });
    }
  });
  if (plugin.options.verbose) {
    console.log("[Failban] Violation listeners configured");
  }
}
function createFailbanAdminRoutes(Hono, plugin) {
  const app = new Hono();
  app.get("/bans", async (c) => {
    try {
      const bans = await plugin.listBans();
      return c.json({
        success: true,
        data: bans,
        meta: { count: bans.length }
      });
    } catch (err) {
      return c.json({
        success: false,
        error: err.message
      }, 500);
    }
  });
  app.get("/bans/:ip", async (c) => {
    const ip = c.req.param("ip");
    try {
      const ban = await plugin.getBan(ip);
      if (!ban) {
        return c.json({
          success: false,
          error: "Ban not found"
        }, 404);
      }
      return c.json({
        success: true,
        data: ban
      });
    } catch (err) {
      return c.json({
        success: false,
        error: err.message
      }, 500);
    }
  });
  app.post("/bans", async (c) => {
    try {
      const { ip, reason, duration } = await c.req.json();
      if (!ip) {
        return c.json({
          success: false,
          error: "IP address is required"
        }, 400);
      }
      const originalDuration = plugin.options.banDuration;
      if (duration) {
        plugin.options.banDuration = duration;
      }
      await plugin.ban(ip, reason || "Manual ban by admin");
      if (duration) {
        plugin.options.banDuration = originalDuration;
      }
      return c.json({
        success: true,
        message: `IP ${ip} has been banned`
      });
    } catch (err) {
      return c.json({
        success: false,
        error: err.message
      }, 500);
    }
  });
  app.delete("/bans/:ip", async (c) => {
    const ip = c.req.param("ip");
    try {
      const result = await plugin.unban(ip);
      if (!result) {
        return c.json({
          success: false,
          error: "Failed to unban IP"
        }, 500);
      }
      return c.json({
        success: true,
        message: `IP ${ip} has been unbanned`
      });
    } catch (err) {
      return c.json({
        success: false,
        error: err.message
      }, 500);
    }
  });
  app.get("/stats", async (c) => {
    try {
      const stats = await plugin.getStats();
      return c.json({
        success: true,
        data: stats
      });
    } catch (err) {
      return c.json({
        success: false,
        error: err.message
      }, 500);
    }
  });
  return app;
}

const PREFIX = "plg_";
function normalizeNamespace(namespace) {
  if (!namespace) return null;
  const text = String(namespace).trim().toLowerCase();
  if (!text) return null;
  const normalized = text.replace(/[^a-z0-9]+/g, "_").replace(/^_+/, "").replace(/_+$/, "");
  return normalized || null;
}
function applyNamespace(name, namespace) {
  const ensured = ensurePlgPrefix(name);
  if (!namespace) {
    return ensured;
  }
  const withoutPrefix = ensured.slice(PREFIX.length);
  if (withoutPrefix.startsWith(`${namespace}_`)) {
    return ensured;
  }
  return `${PREFIX}${namespace}_${withoutPrefix}`;
}
function sanitizeName(name) {
  if (!name || typeof name !== "string") {
    throw new Error("[resource-names] Resource name must be a non-empty string");
  }
  return name.trim();
}
function ensurePlgPrefix(name) {
  const sanitized = sanitizeName(name);
  if (sanitized.startsWith(PREFIX)) {
    return sanitized;
  }
  return `${PREFIX}${sanitized.replace(/^\_+/, "")}`;
}
function resolveResourceName(pluginKey, { defaultName, override, suffix } = {}, options = {}) {
  const namespace = normalizeNamespace(options.namespace);
  const applyOverrideNamespace = options.applyNamespaceToOverrides === true;
  if (!defaultName && !override && !suffix) {
    throw new Error(`[resource-names] Missing name parameters for plugin "${pluginKey}"`);
  }
  if (override) {
    const ensured2 = ensurePlgPrefix(override);
    return applyOverrideNamespace ? applyNamespace(ensured2, namespace) : ensured2;
  }
  if (defaultName) {
    const ensured2 = defaultName.startsWith(PREFIX) ? defaultName : ensurePlgPrefix(defaultName);
    return applyNamespace(ensured2, namespace);
  }
  if (!suffix) {
    throw new Error(`[resource-names] Cannot derive resource name for plugin "${pluginKey}" without suffix`);
  }
  const ensured = ensurePlgPrefix(`${pluginKey}_${suffix}`);
  return applyNamespace(ensured, namespace);
}
function resolveResourceNames(pluginKey, descriptors = {}, options = {}) {
  const result = {};
  for (const [key, descriptor] of Object.entries(descriptors)) {
    if (typeof descriptor === "string") {
      result[key] = resolveResourceName(pluginKey, { defaultName: descriptor }, options);
      continue;
    }
    result[key] = resolveResourceName(pluginKey, descriptor, options);
  }
  return result;
}

class FailbanManager {
  constructor(options = {}) {
    this.namespace = options.namespace || null;
    const resourceOverrides = options.resourceNames || options.resources || {};
    this._resourceDescriptors = {
      bans: {
        defaultName: "plg_api_failban_bans",
        override: resourceOverrides.bans
      },
      violations: {
        defaultName: "plg_api_failban_violations",
        override: resourceOverrides.violations
      }
    };
    this.resourceNames = this._resolveResourceNames();
    this.options = {
      enabled: options.enabled !== false,
      database: options.database,
      maxViolations: options.maxViolations || 3,
      violationWindow: options.violationWindow || 36e5,
      banDuration: options.banDuration || 864e5,
      whitelist: options.whitelist || ["127.0.0.1", "::1"],
      blacklist: options.blacklist || [],
      persistViolations: options.persistViolations !== false,
      verbose: options.verbose || false,
      geo: {
        enabled: options.geo?.enabled || false,
        databasePath: options.geo?.databasePath || null,
        allowedCountries: options.geo?.allowedCountries || [],
        blockedCountries: options.geo?.blockedCountries || [],
        blockUnknown: options.geo?.blockUnknown || false,
        cacheResults: options.geo?.cacheResults !== false
      },
      resources: this.resourceNames
    };
    this.database = options.database;
    this.bansResource = null;
    this.violationsResource = null;
    this.memoryCache = /* @__PURE__ */ new Map();
    this.geoCache = /* @__PURE__ */ new Map();
    this.geoReader = null;
    this.cleanupTimer = null;
  }
  _resolveResourceNames() {
    return resolveResourceNames("api_failban", this._resourceDescriptors, {
      namespace: this.namespace
    });
  }
  setNamespace(namespace) {
    this.namespace = namespace;
    this.resourceNames = this._resolveResourceNames();
    this.options.resources = this.resourceNames;
  }
  /**
   * Initialize failban manager
   */
  async initialize() {
    if (!this.options.enabled) {
      if (this.options.verbose) {
        console.log("[Failban] Disabled, skipping initialization");
      }
      return;
    }
    if (!this.database) {
      throw new Error("[Failban] Database instance is required");
    }
    if (this.options.geo.enabled) {
      await this._initializeGeoIP();
    }
    this.bansResource = await this._createBansResource();
    if (this.options.persistViolations) {
      this.violationsResource = await this._createViolationsResource();
    }
    await this._loadBansIntoCache();
    this._setupCleanupTimer();
    if (this.options.verbose) {
      console.log("[Failban] Initialized");
      console.log(`[Failban] Max violations: ${this.options.maxViolations}`);
      console.log(`[Failban] Violation window: ${this.options.violationWindow}ms`);
      console.log(`[Failban] Ban duration: ${this.options.banDuration}ms`);
      console.log(`[Failban] Whitelist: ${this.options.whitelist.join(", ")}`);
      if (this.options.geo.enabled) {
        console.log(`[Failban] GeoIP enabled`);
        console.log(`[Failban] Allowed countries: ${this.options.geo.allowedCountries.join(", ") || "none"}`);
        console.log(`[Failban] Blocked countries: ${this.options.geo.blockedCountries.join(", ") || "none"}`);
        console.log(`[Failban] Block unknown: ${this.options.geo.blockUnknown}`);
      }
    }
  }
  /**
   * Create bans resource with TTL support
   * @private
   */
  async _createBansResource() {
    const resourceName = this.resourceNames.bans;
    try {
      return await this.database.getResource(resourceName);
    } catch (err) {
    }
    const [created, createErr, resource] = await tryFn(() => this.database.createResource({
      name: resourceName,
      attributes: {
        ip: "string|required",
        reason: "string",
        violations: "number",
        bannedAt: "string",
        expiresAt: "string|required",
        metadata: {
          userAgent: "string",
          path: "string",
          lastViolation: "string"
        }
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        byExpiry: {
          fields: { expiresAtCohort: "string" }
        }
      }
    }));
    if (!created) {
      const existing = this.database.resources?.[resourceName];
      if (existing) {
        return existing;
      }
      throw createErr;
    }
    const ttlPlugin = this.database.plugins?.ttl || this.database.plugins?.TTLPlugin;
    if (ttlPlugin) {
      ttlPlugin.options.resources = ttlPlugin.options.resources || {};
      ttlPlugin.options.resources[resourceName] = {
        enabled: true,
        field: "expiresAt"
      };
      if (this.options.verbose) {
        console.log(`[Failban] TTL configured for bans resource (${resourceName})`);
      }
    } else {
      console.warn("[Failban] TTLPlugin not found - bans will not auto-expire from DB");
    }
    return resource;
  }
  /**
   * Create violations tracking resource
   * @private
   */
  async _createViolationsResource() {
    const resourceName = this.resourceNames.violations;
    try {
      return await this.database.getResource(resourceName);
    } catch (err) {
    }
    const [created, createErr, resource] = await tryFn(() => this.database.createResource({
      name: resourceName,
      attributes: {
        ip: "string|required",
        timestamp: "string|required",
        type: "string",
        path: "string",
        userAgent: "string"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        byIp: {
          fields: { ip: "string" }
        }
      }
    }));
    if (!created) {
      const existing = this.database.resources?.[resourceName];
      if (existing) {
        return existing;
      }
      throw createErr;
    }
    return resource;
  }
  /**
   * Load existing bans into memory cache
   * @private
   */
  async _loadBansIntoCache() {
    try {
      const bans = await this.bansResource.list({ limit: 1e3 });
      const now = Date.now();
      for (const ban of bans) {
        const expiresAt = new Date(ban.expiresAt).getTime();
        if (expiresAt > now) {
          this.memoryCache.set(ban.ip, {
            expiresAt,
            reason: ban.reason,
            violations: ban.violations
          });
        }
      }
      if (this.options.verbose) {
        console.log(`[Failban] Loaded ${this.memoryCache.size} active bans into cache`);
      }
    } catch (err) {
      console.error("[Failban] Failed to load bans:", err.message);
    }
  }
  /**
   * Setup cleanup timer for memory cache
   * @private
   */
  _setupCleanupTimer() {
    this.cleanupTimer = setInterval(() => {
      const now = Date.now();
      let cleaned = 0;
      for (const [ip, ban] of this.memoryCache.entries()) {
        if (ban.expiresAt <= now) {
          this.memoryCache.delete(ip);
          cleaned++;
          this.database.emit?.("security:unbanned", {
            ip,
            reason: "expired",
            bannedFor: ban.reason
          });
        }
      }
      if (this.options.verbose && cleaned > 0) {
        console.log(`[Failban] Cleaned ${cleaned} expired bans from cache`);
      }
    }, 6e4);
  }
  /**
   * Initialize GeoIP reader
   * @private
   */
  async _initializeGeoIP() {
    if (!this.options.geo.databasePath) {
      console.warn("[Failban] GeoIP enabled but no databasePath provided");
      return;
    }
    try {
      const Reader = await requirePluginDependency(
        "@maxmind/geoip2-node",
        "ApiPlugin (Failban)",
        "GeoIP country blocking"
      );
      this.geoReader = await Reader.open(this.options.geo.databasePath);
      if (this.options.verbose) {
        console.log(`[Failban] GeoIP database loaded from ${this.options.geo.databasePath}`);
      }
    } catch (err) {
      console.error("[Failban] Failed to initialize GeoIP:", err.message);
      console.warn("[Failban] GeoIP features will be disabled");
      this.options.geo.enabled = false;
    }
  }
  /**
   * Get country code for IP address
   */
  getCountryCode(ip) {
    if (!this.options.geo.enabled || !this.geoReader) {
      return null;
    }
    if (this.options.geo.cacheResults && this.geoCache.has(ip)) {
      return this.geoCache.get(ip);
    }
    try {
      const response = this.geoReader.country(ip);
      const countryCode = response?.country?.isoCode || null;
      if (this.options.geo.cacheResults) {
        this.geoCache.set(ip, countryCode);
        if (this.geoCache.size > 1e4) {
          const firstKey = this.geoCache.keys().next().value;
          this.geoCache.delete(firstKey);
        }
      }
      return countryCode;
    } catch (err) {
      if (this.options.verbose) {
        console.log(`[Failban] GeoIP lookup failed for ${ip}: ${err.message}`);
      }
      return null;
    }
  }
  /**
   * Check if country is blocked
   */
  isCountryBlocked(countryCode) {
    if (!this.options.geo.enabled) {
      return false;
    }
    if (!countryCode) {
      return this.options.geo.blockUnknown;
    }
    const upperCode = countryCode.toUpperCase();
    if (this.options.geo.blockedCountries.length > 0) {
      if (this.options.geo.blockedCountries.includes(upperCode)) {
        return true;
      }
    }
    if (this.options.geo.allowedCountries.length > 0) {
      return !this.options.geo.allowedCountries.includes(upperCode);
    }
    return false;
  }
  /**
   * Check if IP is blocked by country restrictions
   */
  checkCountryBlock(ip) {
    if (!this.options.geo.enabled) {
      return null;
    }
    if (this.isWhitelisted(ip)) {
      return null;
    }
    const countryCode = this.getCountryCode(ip);
    if (this.isCountryBlocked(countryCode)) {
      return {
        blocked: true,
        reason: "country_restricted",
        country: countryCode || "unknown",
        ip
      };
    }
    return null;
  }
  /**
   * Check if IP is in whitelist
   */
  isWhitelisted(ip) {
    return this.options.whitelist.includes(ip);
  }
  /**
   * Check if IP is in blacklist
   */
  isBlacklisted(ip) {
    return this.options.blacklist.includes(ip);
  }
  /**
   * Check if IP is currently banned
   */
  isBanned(ip) {
    if (!this.options.enabled) return false;
    if (this.isWhitelisted(ip)) return false;
    if (this.isBlacklisted(ip)) return true;
    const cachedBan = this.memoryCache.get(ip);
    if (cachedBan) {
      if (cachedBan.expiresAt > Date.now()) {
        return true;
      } else {
        this.memoryCache.delete(ip);
        return false;
      }
    }
    return false;
  }
  /**
   * Get ban details for IP
   */
  async getBan(ip) {
    if (!this.options.enabled) return null;
    if (this.isBlacklisted(ip)) {
      return {
        ip,
        reason: "blacklisted",
        permanent: true
      };
    }
    try {
      const ban = await this.bansResource.get(ip);
      if (!ban) return null;
      if (new Date(ban.expiresAt).getTime() <= Date.now()) {
        return null;
      }
      return ban;
    } catch (err) {
      return null;
    }
  }
  /**
   * Record a violation
   */
  async recordViolation(ip, type = "rate_limit", metadata = {}) {
    if (!this.options.enabled) return;
    if (this.isWhitelisted(ip)) return;
    const now = (/* @__PURE__ */ new Date()).toISOString();
    this.database.emit?.("security:violation", {
      ip,
      type,
      timestamp: now,
      ...metadata
    });
    if (this.violationsResource) {
      try {
        await this.violationsResource.insert({
          id: `${ip}_${Date.now()}`,
          ip,
          timestamp: now,
          type,
          path: metadata.path,
          userAgent: metadata.userAgent
        });
      } catch (err) {
        console.error("[Failban] Failed to persist violation:", err.message);
      }
    }
    await this._checkAndBan(ip, type, metadata);
  }
  /**
   * Check violation count and ban if threshold exceeded
   * @private
   */
  async _checkAndBan(ip, type, metadata) {
    if (this.isBanned(ip)) return;
    const cutoff = new Date(Date.now() - this.options.violationWindow).toISOString();
    let violationCount = 0;
    if (this.violationsResource) {
      try {
        const violations = await this.violationsResource.query({
          ip,
          timestamp: { $gte: cutoff }
        });
        violationCount = violations.length;
      } catch (err) {
        console.error("[Failban] Failed to count violations:", err.message);
        return;
      }
    }
    if (violationCount >= this.options.maxViolations) {
      await this.ban(ip, `${violationCount} ${type} violations`, metadata);
    }
  }
  /**
   * Ban an IP
   */
  async ban(ip, reason, metadata = {}) {
    if (!this.options.enabled) return;
    if (this.isWhitelisted(ip)) {
      console.warn(`[Failban] Cannot ban whitelisted IP: ${ip}`);
      return;
    }
    const now = /* @__PURE__ */ new Date();
    const expiresAt = new Date(now.getTime() + this.options.banDuration);
    const banRecord = {
      id: ip,
      ip,
      reason,
      violations: metadata.violationCount || this.options.maxViolations,
      bannedAt: now.toISOString(),
      expiresAt: expiresAt.toISOString(),
      metadata: {
        userAgent: metadata.userAgent,
        path: metadata.path,
        lastViolation: now.toISOString()
      }
    };
    try {
      await this.bansResource.insert(banRecord);
      this.memoryCache.set(ip, {
        expiresAt: expiresAt.getTime(),
        reason,
        violations: banRecord.violations
      });
      this.database.emit?.("security:banned", {
        ip,
        reason,
        expiresAt: expiresAt.toISOString(),
        duration: this.options.banDuration
      });
      if (this.options.verbose) {
        console.log(`[Failban] Banned ${ip} for ${reason} until ${expiresAt.toISOString()}`);
      }
    } catch (err) {
      console.error("[Failban] Failed to ban IP:", err.message);
    }
  }
  /**
   * Unban an IP
   */
  async unban(ip) {
    if (!this.options.enabled) return;
    try {
      await this.bansResource.delete(ip);
      this.memoryCache.delete(ip);
      this.database.emit?.("security:unbanned", {
        ip,
        reason: "manual",
        unbannedAt: (/* @__PURE__ */ new Date()).toISOString()
      });
      if (this.options.verbose) {
        console.log(`[Failban] Unbanned ${ip}`);
      }
      return true;
    } catch (err) {
      console.error("[Failban] Failed to unban IP:", err.message);
      return false;
    }
  }
  /**
   * List all active bans
   */
  async listBans() {
    if (!this.options.enabled) return [];
    try {
      const bans = await this.bansResource.list({ limit: 1e3 });
      const now = Date.now();
      return bans.filter((ban) => new Date(ban.expiresAt).getTime() > now);
    } catch (err) {
      console.error("[Failban] Failed to list bans:", err.message);
      return [];
    }
  }
  /**
   * Get statistics
   */
  async getStats() {
    const activeBans = await this.listBans();
    let totalViolations = 0;
    if (this.violationsResource) {
      try {
        const violations = await this.violationsResource.list({ limit: 1e4 });
        totalViolations = violations.length;
      } catch (err) {
        console.error("[Failban] Failed to count violations:", err.message);
      }
    }
    return {
      enabled: this.options.enabled,
      activeBans: activeBans.length,
      cachedBans: this.memoryCache.size,
      totalViolations,
      whitelistedIPs: this.options.whitelist.length,
      blacklistedIPs: this.options.blacklist.length,
      geo: {
        enabled: this.options.geo.enabled,
        allowedCountries: this.options.geo.allowedCountries.length,
        blockedCountries: this.options.geo.blockedCountries.length,
        blockUnknown: this.options.geo.blockUnknown
      },
      config: {
        maxViolations: this.options.maxViolations,
        violationWindow: this.options.violationWindow,
        banDuration: this.options.banDuration
      }
    };
  }
  /**
   * Cleanup
   */
  async cleanup() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
    this.memoryCache.clear();
    this.geoCache.clear();
    if (this.geoReader) {
      this.geoReader = null;
    }
    if (this.options.verbose) {
      console.log("[Failban] Cleaned up");
    }
  }
}

var failbanManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  FailbanManager: FailbanManager
});

class ApiEventEmitter extends EventEmitter$1 {
  constructor(options = {}) {
    super();
    this.options = {
      enabled: options.enabled !== false,
      // Enabled by default
      verbose: options.verbose || false,
      maxListeners: options.maxListeners || 10
    };
    this.setMaxListeners(this.options.maxListeners);
  }
  /**
   * Emit event with wildcard support
   * @param {string} event - Event name
   * @param {Object} data - Event data
   */
  emit(event, data = {}) {
    if (!this.options.enabled) {
      return false;
    }
    if (this.options.verbose) {
      console.log(`[API Events] ${event}`, data);
    }
    super.emit(event, { event, ...data, timestamp: (/* @__PURE__ */ new Date()).toISOString() });
    if (event.includes(":")) {
      const [prefix] = event.split(":");
      const wildcardEvent = `${prefix}:*`;
      super.emit(wildcardEvent, { event, ...data, timestamp: (/* @__PURE__ */ new Date()).toISOString() });
    }
    return true;
  }
  /**
   * Helper to emit user events
   * @param {string} action - created, login, updated, deleted
   * @param {Object} data - Event data
   */
  emitUserEvent(action, data) {
    this.emit(`user:${action}`, data);
  }
  /**
   * Helper to emit auth events
   * @param {string} action - success, failure
   * @param {Object} data - Event data
   */
  emitAuthEvent(action, data) {
    this.emit(`auth:${action}`, data);
  }
  /**
   * Helper to emit resource events
   * @param {string} action - created, updated, deleted
   * @param {Object} data - Event data
   */
  emitResourceEvent(action, data) {
    this.emit(`resource:${action}`, data);
  }
  /**
   * Helper to emit request events
   * @param {string} action - start, end, error
   * @param {Object} data - Event data
   */
  emitRequestEvent(action, data) {
    this.emit(`request:${action}`, data);
  }
  /**
   * Get event statistics
   * @returns {Object} Event statistics
   */
  getStats() {
    const stats = {
      enabled: this.options.enabled,
      maxListeners: this.options.maxListeners,
      listeners: {}
    };
    for (const event of this.eventNames()) {
      stats.listeners[event] = this.listenerCount(event);
    }
    return stats;
  }
}

class MetricsCollector {
  constructor(options = {}) {
    this.options = {
      enabled: options.enabled !== false,
      // Enabled by default
      verbose: options.verbose || false,
      maxPathsTracked: options.maxPathsTracked || 100,
      // Limit memory usage
      resetInterval: options.resetInterval || 3e5
      // Reset every 5 minutes
    };
    this.metrics = this._createEmptyMetrics();
    this.startTime = Date.now();
    if (this.options.resetInterval > 0) {
      this.resetTimer = setInterval(() => {
        if (this.options.verbose) {
          console.log("[Metrics] Auto-resetting metrics");
        }
        this.reset();
      }, this.options.resetInterval);
    }
  }
  /**
   * Create empty metrics structure
   * @private
   */
  _createEmptyMetrics() {
    return {
      requests: {
        total: 0,
        byMethod: {},
        byStatus: {},
        byPath: {},
        durations: []
      },
      auth: {
        success: 0,
        failure: 0,
        byMethod: {}
      },
      resources: {
        created: 0,
        updated: 0,
        deleted: 0,
        byResource: {}
      },
      users: {
        logins: 0,
        newUsers: 0
      },
      errors: {
        total: 0,
        byType: {}
      }
    };
  }
  /**
   * Record request metrics
   * @param {Object} data - Request data
   */
  recordRequest({ method, path, status, duration }) {
    if (!this.options.enabled) return;
    const metrics = this.metrics.requests;
    metrics.total++;
    metrics.byMethod[method] = (metrics.byMethod[method] || 0) + 1;
    const statusGroup = `${Math.floor(status / 100)}xx`;
    metrics.byStatus[statusGroup] = (metrics.byStatus[statusGroup] || 0) + 1;
    if (Object.keys(metrics.byPath).length < this.options.maxPathsTracked || metrics.byPath[path]) {
      if (!metrics.byPath[path]) {
        metrics.byPath[path] = { count: 0, totalDuration: 0, errors: 0 };
      }
      metrics.byPath[path].count++;
      metrics.byPath[path].totalDuration += duration;
      if (status >= 400) {
        metrics.byPath[path].errors++;
      }
    }
    metrics.durations.push(duration);
    if (metrics.durations.length > 1e3) {
      metrics.durations.shift();
    }
    if (this.options.verbose) {
      console.log(`[Metrics] Request: ${method} ${path} ${status} (${duration}ms)`);
    }
  }
  /**
   * Record auth metrics
   * @param {Object} data - Auth data
   */
  recordAuth({ success, method }) {
    if (!this.options.enabled) return;
    const metrics = this.metrics.auth;
    if (success) {
      metrics.success++;
    } else {
      metrics.failure++;
    }
    if (!metrics.byMethod[method]) {
      metrics.byMethod[method] = { success: 0, failure: 0 };
    }
    if (success) {
      metrics.byMethod[method].success++;
    } else {
      metrics.byMethod[method].failure++;
    }
    if (this.options.verbose) {
      console.log(`[Metrics] Auth: ${method} ${success ? "success" : "failure"}`);
    }
  }
  /**
   * Record resource operation metrics
   * @param {Object} data - Resource operation data
   */
  recordResourceOperation({ action, resource }) {
    if (!this.options.enabled) return;
    const metrics = this.metrics.resources;
    if (action === "created") metrics.created++;
    else if (action === "updated") metrics.updated++;
    else if (action === "deleted") metrics.deleted++;
    if (!metrics.byResource[resource]) {
      metrics.byResource[resource] = { created: 0, updated: 0, deleted: 0 };
    }
    metrics.byResource[resource][action]++;
    if (this.options.verbose) {
      console.log(`[Metrics] Resource: ${resource} ${action}`);
    }
  }
  /**
   * Record user event metrics
   * @param {Object} data - User event data
   */
  recordUserEvent({ action }) {
    if (!this.options.enabled) return;
    const metrics = this.metrics.users;
    if (action === "login") {
      metrics.logins++;
    } else if (action === "created") {
      metrics.newUsers++;
    }
    if (this.options.verbose) {
      console.log(`[Metrics] User: ${action}`);
    }
  }
  /**
   * Record error metrics
   * @param {Object} data - Error data
   */
  recordError({ error, type = "unknown" }) {
    if (!this.options.enabled) return;
    const metrics = this.metrics.errors;
    metrics.total++;
    metrics.byType[type] = (metrics.byType[type] || 0) + 1;
    if (this.options.verbose) {
      console.log(`[Metrics] Error: ${type} - ${error}`);
    }
  }
  /**
   * Calculate percentile from sorted array
   * @private
   */
  _percentile(arr, p) {
    if (arr.length === 0) return 0;
    const sorted = [...arr].sort((a, b) => a - b);
    const index = Math.ceil(p / 100 * sorted.length) - 1;
    return sorted[Math.max(0, index)];
  }
  /**
   * Get metrics summary
   * @returns {Object} Metrics summary
   */
  getSummary() {
    const uptime = Date.now() - this.startTime;
    return {
      uptime: {
        milliseconds: uptime,
        seconds: Math.floor(uptime / 1e3),
        formatted: this._formatDuration(uptime)
      },
      requests: {
        total: this.metrics.requests.total,
        rps: (this.metrics.requests.total / (uptime / 1e3)).toFixed(2),
        byMethod: this.metrics.requests.byMethod,
        byStatus: this.metrics.requests.byStatus,
        topPaths: this._getTopPaths(),
        duration: {
          p50: this._percentile(this.metrics.requests.durations, 50),
          p95: this._percentile(this.metrics.requests.durations, 95),
          p99: this._percentile(this.metrics.requests.durations, 99),
          avg: this.metrics.requests.durations.length > 0 ? (this.metrics.requests.durations.reduce((a, b) => a + b, 0) / this.metrics.requests.durations.length).toFixed(2) : 0
        }
      },
      auth: {
        total: this.metrics.auth.success + this.metrics.auth.failure,
        success: this.metrics.auth.success,
        failure: this.metrics.auth.failure,
        successRate: this._calculateRate(this.metrics.auth.success, this.metrics.auth.success + this.metrics.auth.failure),
        byMethod: this.metrics.auth.byMethod
      },
      resources: {
        total: this.metrics.resources.created + this.metrics.resources.updated + this.metrics.resources.deleted,
        created: this.metrics.resources.created,
        updated: this.metrics.resources.updated,
        deleted: this.metrics.resources.deleted,
        byResource: this.metrics.resources.byResource
      },
      users: this.metrics.users,
      errors: {
        total: this.metrics.errors.total,
        rate: this._calculateRate(this.metrics.errors.total, this.metrics.requests.total),
        byType: this.metrics.errors.byType
      }
    };
  }
  /**
   * Get top paths by request count
   * @private
   */
  _getTopPaths(limit = 10) {
    return Object.entries(this.metrics.requests.byPath).map(([path, data]) => ({
      path,
      count: data.count,
      avgDuration: (data.totalDuration / data.count).toFixed(2),
      errors: data.errors,
      errorRate: this._calculateRate(data.errors, data.count)
    })).sort((a, b) => b.count - a.count).slice(0, limit);
  }
  /**
   * Calculate rate as percentage
   * @private
   */
  _calculateRate(numerator, denominator) {
    if (denominator === 0) return "0.00%";
    return (numerator / denominator * 100).toFixed(2) + "%";
  }
  /**
   * Format duration in human-readable form
   * @private
   */
  _formatDuration(ms) {
    const seconds = Math.floor(ms / 1e3);
    const minutes = Math.floor(seconds / 60);
    const hours = Math.floor(minutes / 60);
    const days = Math.floor(hours / 24);
    if (days > 0) return `${days}d ${hours % 24}h ${minutes % 60}m`;
    if (hours > 0) return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
    if (minutes > 0) return `${minutes}m ${seconds % 60}s`;
    return `${seconds}s`;
  }
  /**
   * Reset metrics
   */
  reset() {
    this.metrics = this._createEmptyMetrics();
    this.startTime = Date.now();
  }
  /**
   * Stop metrics collection and cleanup
   */
  stop() {
    if (this.resetTimer) {
      clearInterval(this.resetTimer);
      this.resetTimer = null;
    }
  }
}

class ApiServer {
  /**
   * Create API server
   * @param {Object} options - Server options
   * @param {number} options.port - Server port
   * @param {string} options.host - Server host
   * @param {Object} options.database - s3db.js database instance
   * @param {Object} options.resources - Resource configuration
   * @param {Array} options.middlewares - Global middlewares
   */
  constructor(options = {}) {
    this.options = {
      port: options.port || 3e3,
      host: options.host || "0.0.0.0",
      database: options.database,
      resources: options.resources || {},
      routes: options.routes || {},
      // Plugin-level custom routes
      templates: options.templates || { enabled: false, engine: "jsx" },
      // Template engine config
      middlewares: options.middlewares || [],
      requestId: options.requestId || { enabled: false },
      // Request ID tracking config
      cors: options.cors || { enabled: false },
      // CORS configuration
      security: options.security || { enabled: false },
      // Security headers config
      sessionTracking: options.sessionTracking || { enabled: false },
      // Session tracking config
      events: options.events || { enabled: false },
      // Event hooks config
      metrics: options.metrics || { enabled: false },
      // Metrics collection config
      failban: options.failban || { enabled: false },
      // Failban (fail2ban-style) config
      verbose: options.verbose || false,
      auth: options.auth || {},
      static: options.static || [],
      // Static file serving config
      docsEnabled: options.docsEnabled !== false,
      // Enable /docs by default
      docsUI: options.docsUI || "redoc",
      // 'swagger' or 'redoc'
      maxBodySize: options.maxBodySize || 10 * 1024 * 1024,
      // 10MB default
      rootHandler: options.rootHandler,
      // Custom handler for root path, if not provided redirects to /docs
      versionPrefix: options.versionPrefix,
      // Global version prefix config
      namespace: options.namespace || null,
      apiInfo: {
        title: options.apiTitle || "s3db.js API",
        version: options.apiVersion || "1.0.0",
        description: options.apiDescription || "Auto-generated REST API for s3db.js resources"
      }
    };
    this.app = null;
    this.server = null;
    this.isRunning = false;
    this.openAPISpec = null;
    this.initialized = false;
    this.inFlightRequests = /* @__PURE__ */ new Set();
    this.acceptingRequests = true;
    this.events = new ApiEventEmitter({
      enabled: this.options.events?.enabled !== false,
      verbose: this.options.events?.verbose || this.options.verbose,
      maxListeners: this.options.events?.maxListeners
    });
    this.metrics = new MetricsCollector({
      enabled: this.options.metrics?.enabled !== false,
      verbose: this.options.metrics?.verbose || this.options.verbose,
      maxPathsTracked: this.options.metrics?.maxPathsTracked,
      resetInterval: this.options.metrics?.resetInterval
    });
    if (this.options.metrics?.enabled && this.options.events?.enabled !== false) {
      this._setupMetricsEventListeners();
    }
    this.failban = null;
    if (this.options.failban?.enabled) {
      this.failban = new FailbanManager({
        database: this.options.database,
        namespace: this.options.namespace,
        enabled: true,
        maxViolations: this.options.failban.maxViolations || 3,
        violationWindow: this.options.failban.violationWindow || 36e5,
        banDuration: this.options.failban.banDuration || 864e5,
        whitelist: this.options.failban.whitelist || ["127.0.0.1", "::1"],
        blacklist: this.options.failban.blacklist || [],
        persistViolations: this.options.failban.persistViolations !== false,
        verbose: this.options.failban.verbose || this.options.verbose,
        geo: this.options.failban.geo || {}
      });
    }
    this.relationsPlugin = this.options.database?.plugins?.relation || this.options.database?.plugins?.RelationPlugin || null;
  }
  /**
   * Setup metrics event listeners
   * @private
   */
  _setupMetricsEventListeners() {
    this.events.on("request:end", (data) => {
      this.metrics.recordRequest({
        method: data.method,
        path: data.path,
        status: data.status,
        duration: data.duration
      });
    });
    this.events.on("request:error", (data) => {
      this.metrics.recordError({
        error: data.error,
        type: "request"
      });
    });
    this.events.on("auth:success", (data) => {
      this.metrics.recordAuth({
        success: true,
        method: data.method
      });
    });
    this.events.on("auth:failure", (data) => {
      this.metrics.recordAuth({
        success: false,
        method: data.allowedMethods?.[0] || "unknown"
      });
    });
    this.events.on("resource:created", (data) => {
      this.metrics.recordResourceOperation({
        action: "created",
        resource: data.resource
      });
    });
    this.events.on("resource:updated", (data) => {
      this.metrics.recordResourceOperation({
        action: "updated",
        resource: data.resource
      });
    });
    this.events.on("resource:deleted", (data) => {
      this.metrics.recordResourceOperation({
        action: "deleted",
        resource: data.resource
      });
    });
    this.events.on("user:created", (data) => {
      this.metrics.recordUserEvent({
        action: "created"
      });
    });
    this.events.on("user:login", (data) => {
      this.metrics.recordUserEvent({
        action: "login"
      });
    });
    if (this.options.verbose) {
      console.log("[API Server] Metrics event listeners configured");
    }
  }
  /**
   * Setup request tracking middleware for graceful shutdown
   * @private
   */
  _setupRequestTracking() {
    this.app.use("*", async (c, next) => {
      if (!this.acceptingRequests) {
        return c.json({ error: "Server is shutting down" }, 503);
      }
      const requestId = Symbol("request");
      this.inFlightRequests.add(requestId);
      const startTime = Date.now();
      const requestInfo = {
        requestId: c.get("requestId") || requestId.toString(),
        method: c.req.method,
        path: c.req.path,
        userAgent: c.req.header("user-agent"),
        ip: c.req.header("x-forwarded-for") || c.req.header("x-real-ip")
      };
      this.events.emitRequestEvent("start", requestInfo);
      try {
        await next();
        this.events.emitRequestEvent("end", {
          ...requestInfo,
          duration: Date.now() - startTime,
          status: c.res.status
        });
      } catch (err) {
        this.events.emitRequestEvent("error", {
          ...requestInfo,
          duration: Date.now() - startTime,
          error: err.message,
          stack: err.stack
        });
        throw err;
      } finally {
        this.inFlightRequests.delete(requestId);
      }
    });
  }
  /**
   * Stop accepting new requests
   * @returns {void}
   */
  stopAcceptingRequests() {
    this.acceptingRequests = false;
    if (this.options.verbose) {
      console.log("[API Server] Stopped accepting new requests");
    }
  }
  /**
   * Wait for all in-flight requests to finish
   * @param {Object} options - Options
   * @param {number} options.timeout - Max time to wait in ms (default: 30000)
   * @returns {Promise<boolean>} True if all requests finished, false if timeout
   */
  async waitForRequestsToFinish({ timeout = 3e4 } = {}) {
    const startTime = Date.now();
    while (this.inFlightRequests.size > 0) {
      const elapsed = Date.now() - startTime;
      if (elapsed >= timeout) {
        if (this.options.verbose) {
          console.warn(`[API Server] Timeout waiting for ${this.inFlightRequests.size} in-flight requests`);
        }
        return false;
      }
      if (this.options.verbose) {
        console.log(`[API Server] Waiting for ${this.inFlightRequests.size} in-flight requests...`);
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
    if (this.options.verbose) {
      console.log("[API Server] All requests finished");
    }
    return true;
  }
  /**
   * Graceful shutdown
   * @param {Object} options - Shutdown options
   * @param {number} options.timeout - Max time to wait for requests (default: 30000)
   * @returns {Promise<void>}
   */
  async shutdown({ timeout = 3e4 } = {}) {
    if (!this.isRunning) {
      console.warn("[API Server] Server is not running");
      return;
    }
    console.log("[API Server] Initiating graceful shutdown...");
    this.stopAcceptingRequests();
    const allFinished = await this.waitForRequestsToFinish({ timeout });
    if (!allFinished) {
      console.warn("[API Server] Some requests did not finish in time");
    }
    if (this.server) {
      await new Promise((resolve, reject) => {
        this.server.close((err) => {
          if (err) reject(err);
          else resolve();
        });
      });
    }
    this.isRunning = false;
    console.log("[API Server] Shutdown complete");
  }
  /**
   * Setup all routes
   * @private
   */
  _setupRoutes() {
    this._setupRequestTracking();
    if (this.failban) {
      const failbanMiddleware = createFailbanMiddleware({
        plugin: this.failban,
        events: this.events
      });
      this.app.use("*", failbanMiddleware);
      setupFailbanViolationListener({
        plugin: this.failban,
        events: this.events
      });
      if (this.options.verbose) {
        console.log("[API Server] Failban protection enabled");
      }
    }
    if (this.options.requestId?.enabled) {
      const requestIdMiddleware = createRequestIdMiddleware(this.options.requestId);
      this.app.use("*", requestIdMiddleware);
      if (this.options.verbose) {
        console.log(`[API Server] Request ID tracking enabled (header: ${this.options.requestId.headerName || "X-Request-ID"})`);
      }
    }
    if (this.options.cors?.enabled) {
      const corsConfig = this.options.cors;
      this.app.use("*", this.cors({
        origin: corsConfig.origin || "*",
        allowMethods: corsConfig.allowMethods || ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
        allowHeaders: corsConfig.allowHeaders || ["Content-Type", "Authorization", "X-Request-ID"],
        exposeHeaders: corsConfig.exposeHeaders || ["X-Request-ID"],
        credentials: corsConfig.credentials || false,
        maxAge: corsConfig.maxAge || 86400
        // 24 hours cache by default
      }));
      if (this.options.verbose) {
        console.log(`[API Server] CORS enabled (maxAge: ${corsConfig.maxAge || 86400}s, origin: ${corsConfig.origin || "*"})`);
      }
    }
    if (this.options.security?.enabled) {
      const securityMiddleware = createSecurityHeadersMiddleware(this.options.security);
      this.app.use("*", securityMiddleware);
      if (this.options.verbose) {
        console.log("[API Server] Security headers enabled");
      }
    }
    if (this.options.sessionTracking?.enabled) {
      const sessionMiddleware = createSessionTrackingMiddleware(
        this.options.sessionTracking,
        this.options.database
      );
      this.app.use("*", sessionMiddleware);
      if (this.options.verbose) {
        const resource = this.options.sessionTracking.resource ? ` (resource: ${this.options.sessionTracking.resource})` : " (in-memory)";
        console.log(`[API Server] Session tracking enabled${resource}`);
      }
    }
    this.options.middlewares.forEach((middleware) => {
      this.app.use("*", middleware);
    });
    if (this.options.templates?.enabled) {
      const templateMiddleware = setupTemplateEngine(this.options.templates);
      this.app.use("*", templateMiddleware);
      if (this.options.verbose) {
        console.log(`[API Server] Template engine enabled: ${this.options.templates.engine}`);
      }
    }
    this.app.use("*", async (c, next) => {
      const method = c.req.method;
      if (["POST", "PUT", "PATCH"].includes(method)) {
        const contentLength = c.req.header("content-length");
        if (contentLength) {
          const size = parseInt(contentLength);
          if (size > this.options.maxBodySize) {
            const response = payloadTooLarge(size, this.options.maxBodySize);
            c.header("Connection", "close");
            return c.json(response, response._status);
          }
        }
      }
      await next();
    });
    this.app.get("/health/live", (c) => {
      const response = success({
        status: "alive",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/ready", async (c) => {
      const checks = {};
      let isHealthy = true;
      const healthConfig = this.options.health || {};
      const customChecks = healthConfig.readiness?.checks || [];
      try {
        const startTime = Date.now();
        const isDbReady = this.options.database && this.options.database.connected && Object.keys(this.options.database.resources).length > 0;
        const latency = Date.now() - startTime;
        if (isDbReady) {
          checks.s3db = {
            status: "healthy",
            latency_ms: latency,
            resources: Object.keys(this.options.database.resources).length
          };
        } else {
          checks.s3db = {
            status: "unhealthy",
            connected: this.options.database?.connected || false,
            resources: Object.keys(this.options.database?.resources || {}).length
          };
          isHealthy = false;
        }
      } catch (err) {
        checks.s3db = {
          status: "unhealthy",
          error: err.message
        };
        isHealthy = false;
      }
      for (const check of customChecks) {
        try {
          const startTime = Date.now();
          const timeout = check.timeout || 5e3;
          const result = await Promise.race([
            check.check(),
            new Promise(
              (_, reject) => setTimeout(() => reject(new Error("Timeout")), timeout)
            )
          ]);
          const latency = Date.now() - startTime;
          checks[check.name] = {
            status: result.healthy ? "healthy" : "unhealthy",
            latency_ms: latency,
            ...result
          };
          if (!result.healthy && !check.optional) {
            isHealthy = false;
          }
        } catch (err) {
          checks[check.name] = {
            status: "unhealthy",
            error: err.message
          };
          if (!check.optional) {
            isHealthy = false;
          }
        }
      }
      const status = isHealthy ? 200 : 503;
      return c.json({
        status: isHealthy ? "healthy" : "unhealthy",
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        uptime: process.uptime(),
        checks
      }, status);
    });
    this.app.get("/health", (c) => {
      const response = success({
        status: "ok",
        uptime: process.uptime(),
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        checks: {
          liveness: "/health/live",
          readiness: "/health/ready"
        }
      });
      return c.json(response);
    });
    if (this.options.metrics?.enabled) {
      this.app.get("/metrics", (c) => {
        const summary = this.metrics.getSummary();
        const response = success(summary);
        return c.json(response);
      });
      if (this.options.verbose) {
        console.log("[API Server] Metrics endpoint enabled at /metrics");
      }
    }
    if (this.failban) {
      const failbanAdminRoutes = createFailbanAdminRoutes(this.Hono, this.failban);
      this.app.route("/admin/security", failbanAdminRoutes);
      if (this.options.verbose) {
        console.log("[API Server] Failban admin endpoints enabled at /admin/security");
      }
    }
    this.app.get("/", (c) => {
      if (this.options.rootHandler) {
        return this.options.rootHandler(c);
      }
      return c.redirect("/docs", 302);
    });
    this._setupStaticRoutes();
    if (this.options.docsEnabled) {
      this.app.get("/openapi.json", (c) => {
        if (!this.openAPISpec) {
          this.openAPISpec = this._generateOpenAPISpec();
        }
        return c.json(this.openAPISpec);
      });
      if (this.options.docsUI === "swagger") {
        this.app.get("/docs", this.swaggerUI({
          url: "/openapi.json"
        }));
      } else {
        this.app.get("/docs", (c) => {
          return c.html(`<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${this.options.apiInfo.title} - API Documentation</title>
  <style>
    body {
      margin: 0;
      padding: 0;
    }
  </style>
</head>
<body>
  <redoc spec-url="/openapi.json"></redoc>
  <script src="https://cdn.redoc.ly/redoc/v2.5.1/bundles/redoc.standalone.js"><\/script>
</body>
</html>`);
        });
      }
    }
    this._setupResourceRoutes();
    const hasJwtDriver = Array.isArray(this.options.auth?.drivers) ? this.options.auth.drivers.some((d) => d.driver === "jwt") : false;
    if (this.options.auth?.driver || hasJwtDriver) {
      this._setupAuthRoutes();
    }
    const oidcDriver = this.options.auth?.drivers?.find((d) => d.driver === "oidc");
    if (oidcDriver) {
      this._setupOIDCRoutes(oidcDriver.config);
    }
    if (this.relationsPlugin) {
      this._setupRelationalRoutes();
    }
    this._setupPluginRoutes();
    this.app.onError((err, c) => {
      return errorHandler(err, c);
    });
    this.app.notFound((c) => {
      const response = error("Route not found", {
        status: 404,
        code: "NOT_FOUND",
        details: {
          path: c.req.path,
          method: c.req.method
        }
      });
      return c.json(response, 404);
    });
  }
  /**
   * Setup routes for all resources
   * @private
   */
  _setupResourceRoutes() {
    const { database, resources: resourceConfigs = {} } = this.options;
    const resources = database.resources;
    const authMiddleware = this._createAuthMiddleware();
    for (const [name, resource] of Object.entries(resources)) {
      const resourceConfig = resourceConfigs[name];
      const isPluginResource = name.startsWith("plg_");
      if (isPluginResource && !resourceConfig) {
        if (this.options.verbose) {
          console.log(`[API Plugin] Skipping internal resource '${name}' (not included in config.resources)`);
        }
        continue;
      }
      if (resourceConfig?.enabled === false) {
        if (this.options.verbose) {
          console.log(`[API Plugin] Resource '${name}' disabled via config.resources`);
        }
        continue;
      }
      const version = resource.config?.currentVersion || resource.version || "v1";
      let versionPrefixConfig;
      if (resourceConfig && resourceConfig.versionPrefix !== void 0) {
        versionPrefixConfig = resourceConfig.versionPrefix;
      } else if (resource.config && resource.config.versionPrefix !== void 0) {
        versionPrefixConfig = resource.config.versionPrefix;
      } else if (this.options.versionPrefix !== void 0) {
        versionPrefixConfig = this.options.versionPrefix;
      } else {
        versionPrefixConfig = false;
      }
      let prefix = "";
      if (versionPrefixConfig === true) {
        prefix = version;
      } else if (versionPrefixConfig === false) {
        prefix = "";
      } else if (typeof versionPrefixConfig === "string") {
        prefix = versionPrefixConfig;
      }
      const middlewares = [];
      const authDisabled = resourceConfig?.auth === false;
      if (authMiddleware && !authDisabled) {
        middlewares.push(authMiddleware);
      }
      const extraMiddleware = resourceConfig?.customMiddleware;
      if (extraMiddleware) {
        const toRegister = Array.isArray(extraMiddleware) ? extraMiddleware : [extraMiddleware];
        for (const middleware of toRegister) {
          if (typeof middleware === "function") {
            middlewares.push(middleware);
          } else if (this.options.verbose) {
            console.warn(`[API Plugin] Ignoring non-function middleware for resource '${name}'`);
          }
        }
      }
      let methods = resourceConfig?.methods || resource.config?.methods;
      if (!Array.isArray(methods) || methods.length === 0) {
        methods = ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"];
      } else {
        methods = methods.filter(Boolean).map((method) => typeof method === "string" ? method.toUpperCase() : method);
      }
      const enableValidation = resourceConfig?.validation !== void 0 ? resourceConfig.validation !== false : resource.config?.validation !== false;
      const resourceApp = createResourceRoutes(resource, version, {
        methods,
        customMiddleware: middlewares,
        enableValidation,
        versionPrefix: prefix,
        events: this.events
      }, this.Hono);
      const mountPath = prefix ? `/${prefix}/${name}` : `/${name}`;
      this.app.route(mountPath, resourceApp);
      if (this.options.verbose) {
        console.log(`[API Plugin] Mounted routes for resource '${name}' at ${mountPath}`);
      }
      if (resource.config?.routes) {
        const routeContext = {
          resource,
          database,
          resourceName: name,
          version
        };
        mountCustomRoutes(resourceApp, resource.config.routes, routeContext, this.options.verbose);
      }
    }
  }
  /**
   * Setup authentication routes (when auth drivers are configured)
   * @private
   */
  _setupAuthRoutes() {
    const { database, auth } = this.options;
    const { drivers, resource: resourceName, usernameField, passwordField } = auth;
    const identityPlugin = database?.plugins?.identity || database?.plugins?.Identity;
    if (identityPlugin) {
      if (this.options.verbose) {
        console.warn("[API Plugin] IdentityPlugin detected. Skipping built-in auth routes.");
      }
      return;
    }
    const jwtDriver = drivers.find((d) => d.driver === "jwt");
    if (!jwtDriver) {
      return;
    }
    const authResource = database.resources[resourceName];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${resourceName}' not found. Skipping auth routes.`);
      return;
    }
    const driverConfig = jwtDriver.config || {};
    const registrationConfig = {
      enabled: driverConfig.allowRegistration === true || driverConfig.registration?.enabled === true || auth.registration?.enabled === true,
      allowedFields: Array.isArray(driverConfig.registration?.allowedFields) ? driverConfig.registration.allowedFields : Array.isArray(auth.registration?.allowedFields) ? auth.registration.allowedFields : [],
      defaultRole: driverConfig.registration?.defaultRole ?? auth.registration?.defaultRole ?? "user"
    };
    const driverLoginThrottle = driverConfig.loginThrottle || {};
    const loginThrottleConfig = {
      enabled: driverLoginThrottle.enabled ?? auth.loginThrottle?.enabled ?? true,
      maxAttempts: driverLoginThrottle.maxAttempts || auth.loginThrottle?.maxAttempts || 5,
      windowMs: driverLoginThrottle.windowMs || auth.loginThrottle?.windowMs || 6e4,
      blockDurationMs: driverLoginThrottle.blockDurationMs || auth.loginThrottle?.blockDurationMs || 3e5,
      maxEntries: driverLoginThrottle.maxEntries || auth.loginThrottle?.maxEntries || 1e4
    };
    const authConfig = {
      driver: "jwt",
      usernameField,
      passwordField,
      jwtSecret: driverConfig.jwtSecret || driverConfig.secret,
      jwtExpiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d",
      passphrase: driverConfig.passphrase || "secret",
      allowRegistration: registrationConfig.enabled,
      registration: registrationConfig,
      loginThrottle: loginThrottleConfig
    };
    const authApp = createAuthRoutes(authResource, authConfig);
    this.app.route("/auth", authApp);
    if (this.options.verbose) {
      console.log("[API Plugin] Mounted auth routes (driver: jwt) at /auth");
    }
  }
  /**
   * Setup OIDC routes (when oidc driver is configured)
   * @private
   * @param {Object} config - OIDC driver configuration
   */
  _setupOIDCRoutes(config) {
    const { database, auth } = this.options;
    const authResource = database.resources[auth.resource];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${auth.resource}' not found for OIDC`);
      return;
    }
    const oidcHandler = createOIDCHandler(config, this.app, authResource, this.events);
    this.oidcMiddleware = oidcHandler.middleware;
    if (this.options.verbose) {
      console.log("[API Plugin] Mounted OIDC routes:");
      for (const [path, description] of Object.entries(oidcHandler.routes)) {
        console.log(`[API Plugin]   ${path} - ${description}`);
      }
    }
  }
  /**
   * Create authentication middleware based on configured drivers
   * @private
   * @returns {Function|null} Hono middleware or null
   */
  _createAuthMiddleware() {
    const { database, auth } = this.options;
    const { drivers, resource: defaultResourceName, pathAuth, pathRules } = auth;
    if (!drivers || drivers.length === 0) {
      return null;
    }
    const authResource = database.resources[defaultResourceName];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${defaultResourceName}' not found for middleware`);
      return null;
    }
    if (pathRules && pathRules.length > 0) {
      return this._createPathRulesAuthMiddleware(authResource, drivers, pathRules);
    }
    if (pathAuth) {
      try {
        validatePathAuth(pathAuth);
      } catch (err) {
        console.error(`[API Plugin] Invalid pathAuth configuration: ${err.message}`);
        throw err;
      }
    }
    const extractDriverConfigs = (driverNames) => {
      const configs = {
        jwt: {},
        apiKey: {},
        basic: {},
        oauth2: {}
      };
      for (const driverDef of drivers) {
        const driverName = driverDef.driver;
        const driverConfig = driverDef.config || {};
        if (driverNames && !driverNames.includes(driverName)) {
          continue;
        }
        if (driverName === "oauth2-server" || driverName === "oidc") {
          continue;
        }
        if (driverName === "jwt") {
          configs.jwt = {
            secret: driverConfig.jwtSecret || driverConfig.secret,
            expiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d"
          };
        } else if (driverName === "apiKey") {
          configs.apiKey = {
            headerName: driverConfig.headerName || "X-API-Key"
          };
        } else if (driverName === "basic") {
          configs.basic = {
            realm: driverConfig.realm || "API Access",
            passphrase: driverConfig.passphrase || "secret"
          };
        } else if (driverName === "oauth2") {
          configs.oauth2 = driverConfig;
        }
      }
      return configs;
    };
    if (pathAuth) {
      return async (c, next) => {
        const requestPath = c.req.path;
        const matchedRule = findBestMatch(pathAuth, requestPath);
        if (this.options.verbose) {
          if (matchedRule) {
            console.log(`[API Plugin] Path ${requestPath} matched rule: ${matchedRule.pattern}`);
          } else {
            console.log(`[API Plugin] Path ${requestPath} no pathAuth rule matched (using global auth)`);
          }
        }
        if (!matchedRule) {
          const methods2 = drivers.map((d) => d.driver).filter((d) => d !== "oauth2-server" && d !== "oidc");
          const driverConfigs3 = extractDriverConfigs(null);
          const globalAuth = createAuthMiddleware({
            methods: methods2,
            jwt: driverConfigs3.jwt,
            apiKey: driverConfigs3.apiKey,
            basic: driverConfigs3.basic,
            oauth2: driverConfigs3.oauth2,
            oidc: this.oidcMiddleware || null,
            usersResource: authResource,
            optional: true
          });
          return await globalAuth(c, next);
        }
        if (!matchedRule.required) {
          return await next();
        }
        const ruleMethods = matchedRule.drivers || [];
        const driverConfigs2 = extractDriverConfigs(ruleMethods);
        const ruleAuth = createAuthMiddleware({
          methods: ruleMethods,
          jwt: driverConfigs2.jwt,
          apiKey: driverConfigs2.apiKey,
          basic: driverConfigs2.basic,
          oauth2: driverConfigs2.oauth2,
          oidc: this.oidcMiddleware || null,
          usersResource: authResource,
          optional: false
          // Auth is required for this path
        });
        return await ruleAuth(c, next);
      };
    }
    const methods = [];
    const driverConfigs = {
      jwt: {},
      apiKey: {},
      basic: {},
      oauth2: {}
    };
    for (const driverDef of drivers) {
      const driverName = driverDef.driver;
      const driverConfig = driverDef.config || {};
      if (driverName === "oauth2-server" || driverName === "oidc") {
        continue;
      }
      if (!methods.includes(driverName)) {
        methods.push(driverName);
      }
      if (driverName === "jwt") {
        driverConfigs.jwt = {
          secret: driverConfig.jwtSecret || driverConfig.secret,
          expiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d"
        };
      } else if (driverName === "apiKey") {
        driverConfigs.apiKey = {
          headerName: driverConfig.headerName || "X-API-Key"
        };
      } else if (driverName === "basic") {
        driverConfigs.basic = {
          realm: driverConfig.realm || "API Access",
          passphrase: driverConfig.passphrase || "secret"
        };
      } else if (driverName === "oauth2") {
        driverConfigs.oauth2 = driverConfig;
      }
    }
    return createAuthMiddleware({
      methods,
      jwt: driverConfigs.jwt,
      apiKey: driverConfigs.apiKey,
      basic: driverConfigs.basic,
      oauth2: driverConfigs.oauth2,
      oidc: this.oidcMiddleware || null,
      // OIDC middleware (if configured)
      usersResource: authResource,
      optional: true
      // Let guards handle authorization
    });
  }
  /**
   * Create path-based auth middleware using pathRules
   * @private
   * @param {Object} authResource - Users resource for authentication
   * @param {Array} drivers - Auth driver configurations
   * @param {Array} pathRules - Path-based auth rules
   * @returns {Function} Hono middleware
   */
  _createPathRulesAuthMiddleware(authResource, drivers, pathRules) {
    const authMiddlewares = {};
    for (const driverDef of drivers) {
      const driverType = driverDef.type || driverDef.driver;
      const driverConfig = driverDef.config || driverDef;
      if (driverType === "oauth2-server") {
        continue;
      }
      if (driverType === "oidc") {
        if (this.oidcMiddleware) {
          authMiddlewares.oidc = this.oidcMiddleware;
        }
        continue;
      }
      if (driverType === "jwt") {
        authMiddlewares.jwt = jwtAuth({
          secret: driverConfig.jwtSecret || driverConfig.secret,
          expiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d",
          usersResource: authResource,
          optional: true
        });
      }
      if (driverType === "apiKey") {
        authMiddlewares.apiKey = apiKeyAuth({
          headerName: driverConfig.headerName || "X-API-Key",
          usersResource: authResource,
          optional: true
        });
      }
      if (driverType === "basic") {
        authMiddlewares.basic = basicAuth({
          authResource,
          usernameField: driverConfig.usernameField || "email",
          passwordField: driverConfig.passwordField || "password",
          passphrase: driverConfig.passphrase || "secret",
          adminUser: driverConfig.adminUser || null,
          optional: true
        });
      }
      if (driverType === "oauth2") {
        const oauth2Handler = createOAuth2Handler(driverConfig, authResource);
        authMiddlewares.oauth2 = async (c, next) => {
          const user = await oauth2Handler(c);
          if (user) {
            c.set("user", user);
            return await next();
          }
        };
      }
    }
    if (this.options.verbose) {
      console.log(`[API Server] Path-based auth with ${pathRules.length} rules`);
      console.log(`[API Server] Available auth methods: ${Object.keys(authMiddlewares).join(", ")}`);
    }
    return createPathBasedAuthMiddleware({
      rules: pathRules,
      authMiddlewares,
      unauthorizedHandler: (c, message) => {
        const acceptHeader = c.req.header("accept") || "";
        const acceptsHtml = acceptHeader.includes("text/html");
        if (acceptsHtml) {
          if (authMiddlewares.oidc) {
            return c.redirect("/auth/login", 302);
          }
        }
        return c.json({
          error: "Unauthorized",
          message
        }, 401);
      },
      events: this.events
    });
  }
  /**
   * Setup relational routes (when RelationPlugin is active)
   * @private
   */
  _setupRelationalRoutes() {
    if (!this.relationsPlugin || !this.relationsPlugin.relations) {
      return;
    }
    const { database } = this.options;
    const relations = this.relationsPlugin.relations;
    if (this.options.verbose) {
      console.log("[API Plugin] Setting up relational routes...");
    }
    for (const [resourceName, relationsDef] of Object.entries(relations)) {
      const resource = database.resources[resourceName];
      if (!resource) {
        if (this.options.verbose) {
          console.warn(`[API Plugin] Resource '${resourceName}' not found for relational routes`);
        }
        continue;
      }
      if (resourceName.startsWith("plg_") && !this.options.resources[resourceName]) {
        continue;
      }
      const version = resource.config?.currentVersion || resource.version || "v1";
      for (const [relationName, relationConfig] of Object.entries(relationsDef)) {
        if (relationConfig.type === "belongsTo") {
          continue;
        }
        const resourceConfig = this.options.resources[resourceName];
        const exposeRelation = resourceConfig?.relations?.[relationName]?.expose !== false;
        if (!exposeRelation) {
          continue;
        }
        const relationalApp = createRelationalRoutes(
          resource,
          relationName,
          relationConfig,
          version,
          this.Hono
        );
        this.app.route(`/${version}/${resourceName}/:id/${relationName}`, relationalApp);
        if (this.options.verbose) {
          console.log(
            `[API Plugin] Mounted relational route: /${version}/${resourceName}/:id/${relationName} (${relationConfig.type} -> ${relationConfig.resource})`
          );
        }
      }
    }
  }
  /**
   * Setup plugin-level custom routes
   * @private
   */
  _setupPluginRoutes() {
    const { routes, database } = this.options;
    if (!routes || Object.keys(routes).length === 0) {
      return;
    }
    const context = {
      database,
      plugins: database?.plugins || {}
    };
    mountCustomRoutes(this.app, routes, context, this.options.verbose);
    if (this.options.verbose) {
      console.log(`[API Plugin] Mounted ${Object.keys(routes).length} plugin-level custom routes`);
    }
  }
  /**
   * Setup static file serving routes
   * @private
   */
  _setupStaticRoutes() {
    const { static: staticConfigs, database } = this.options;
    if (!staticConfigs || staticConfigs.length === 0) {
      return;
    }
    if (!Array.isArray(staticConfigs)) {
      throw new Error("Static config must be an array of mount points");
    }
    for (const [index, config] of staticConfigs.entries()) {
      try {
        if (!config.driver) {
          throw new Error(`static[${index}]: "driver" is required (filesystem or s3)`);
        }
        if (!config.path) {
          throw new Error(`static[${index}]: "path" is required (mount path)`);
        }
        if (!config.path.startsWith("/")) {
          throw new Error(`static[${index}]: "path" must start with / (got: ${config.path})`);
        }
        const driverConfig = config.config || {};
        let handler;
        if (config.driver === "filesystem") {
          validateFilesystemConfig({ ...config, ...driverConfig });
          handler = createFilesystemHandler({
            root: config.root,
            index: driverConfig.index,
            fallback: driverConfig.fallback,
            maxAge: driverConfig.maxAge,
            dotfiles: driverConfig.dotfiles,
            etag: driverConfig.etag,
            cors: driverConfig.cors
          });
        } else if (config.driver === "s3") {
          validateS3Config({ ...config, ...driverConfig });
          const s3Client = database?.client?.client;
          if (!s3Client) {
            throw new Error(`static[${index}]: S3 driver requires database with S3 client`);
          }
          handler = createS3Handler({
            s3Client,
            bucket: config.bucket,
            prefix: config.prefix,
            streaming: driverConfig.streaming,
            signedUrlExpiry: driverConfig.signedUrlExpiry,
            maxAge: driverConfig.maxAge,
            cacheControl: driverConfig.cacheControl,
            contentDisposition: driverConfig.contentDisposition,
            etag: driverConfig.etag,
            cors: driverConfig.cors
          });
        } else {
          throw new Error(
            `static[${index}]: invalid driver "${config.driver}". Valid drivers: filesystem, s3`
          );
        }
        const mountPath = config.path === "/" ? "/*" : `${config.path}/*`;
        this.app.get(mountPath, handler);
        this.app.head(mountPath, handler);
        if (this.options.verbose) {
          console.log(
            `[API Plugin] Mounted static files (${config.driver}) at ${config.path}` + (config.driver === "filesystem" ? ` -> ${config.root}` : ` -> s3://${config.bucket}/${config.prefix || ""}`)
          );
        }
      } catch (err) {
        console.error(`[API Plugin] Failed to setup static files for index ${index}:`, err.message);
        throw err;
      }
    }
  }
  /**
   * Start the server
   * @returns {Promise<void>}
   */
  async start() {
    if (this.isRunning) {
      console.warn("[API Plugin] Server is already running");
      return;
    }
    if (!this.initialized) {
      const { Hono } = await import('hono');
      const { serve } = await import('@hono/node-server');
      const { swaggerUI } = await import('@hono/swagger-ui');
      const { cors } = await Promise.resolve().then(function () { return index; });
      this.Hono = Hono;
      this.serve = serve;
      this.swaggerUI = swaggerUI;
      this.cors = cors;
      this.app = new Hono();
      if (this.failban) {
        await this.failban.initialize();
      }
      this._setupRoutes();
      this.initialized = true;
    }
    const { port, host } = this.options;
    return new Promise((resolve, reject) => {
      try {
        this.server = this.serve({
          fetch: this.app.fetch,
          port,
          hostname: host
        }, (info) => {
          this.isRunning = true;
          console.log(`[API Plugin] Server listening on http://${info.address}:${info.port}`);
          const shutdownHandler = async (signal) => {
            console.log(`[API Server] Received ${signal}, initiating graceful shutdown...`);
            try {
              await this.shutdown({ timeout: 3e4 });
              process.exit(0);
            } catch (err) {
              console.error("[API Server] Error during shutdown:", err);
              process.exit(1);
            }
          };
          process.once("SIGTERM", () => shutdownHandler("SIGTERM"));
          process.once("SIGINT", () => shutdownHandler("SIGINT"));
          resolve();
        });
      } catch (err) {
        reject(err);
      }
    });
  }
  /**
   * Stop the server
   * @returns {Promise<void>}
   */
  async stop() {
    if (!this.isRunning) {
      console.warn("[API Plugin] Server is not running");
      return;
    }
    if (this.server && typeof this.server.close === "function") {
      await new Promise((resolve) => {
        this.server.close(() => {
          this.isRunning = false;
          console.log("[API Plugin] Server stopped");
          resolve();
        });
      });
    } else {
      this.isRunning = false;
      console.log("[API Plugin] Server stopped");
    }
    if (this.metrics) {
      this.metrics.stop();
    }
    if (this.failban) {
      await this.failban.cleanup();
    }
  }
  /**
   * Get server info
   * @returns {Object} Server information
   */
  getInfo() {
    return {
      isRunning: this.isRunning,
      port: this.options.port,
      host: this.options.host,
      resources: Object.keys(this.options.database.resources).length
    };
  }
  /**
   * Get Hono app instance
   * @returns {Hono} Hono app
   */
  getApp() {
    return this.app;
  }
  /**
   * Generate OpenAPI specification
   * @private
   * @returns {Object} OpenAPI spec
  */
  _generateOpenAPISpec() {
    const { port, host, database, resources, auth, apiInfo, versionPrefix } = this.options;
    return generateOpenAPISpec(database, {
      title: apiInfo.title,
      version: apiInfo.version,
      description: apiInfo.description,
      serverUrl: `http://${host === "0.0.0.0" ? "localhost" : host}:${port}`,
      auth,
      resources,
      versionPrefix
    });
  }
}

const AUTH_DRIVER_KEYS = ["jwt", "apiKey", "basic", "oidc", "oauth2"];
function normalizeAuthConfig(authOptions = {}) {
  if (!authOptions) {
    return {
      drivers: [],
      pathRules: [],
      pathAuth: void 0,
      strategy: "any",
      priorities: {},
      resource: "users",
      usernameField: "email",
      passwordField: "password",
      driver: null
    };
  }
  const normalized = {
    drivers: [],
    pathRules: Array.isArray(authOptions.pathRules) ? authOptions.pathRules : [],
    pathAuth: authOptions.pathAuth,
    strategy: authOptions.strategy || "any",
    priorities: authOptions.priorities || {},
    resource: authOptions.resource,
    usernameField: authOptions.usernameField || "email",
    passwordField: authOptions.passwordField || "password",
    createResource: authOptions.createResource !== false
  };
  const seen = /* @__PURE__ */ new Set();
  const addDriver = (name, driverConfig = {}) => {
    if (!name) return;
    const driverName = String(name).trim();
    if (!driverName || seen.has(driverName)) return;
    seen.add(driverName);
    normalized.drivers.push({
      driver: driverName,
      config: driverConfig || {}
    });
  };
  if (Array.isArray(authOptions.drivers)) {
    for (const entry of authOptions.drivers) {
      if (typeof entry === "string") {
        addDriver(entry, {});
      } else if (entry && typeof entry === "object") {
        addDriver(entry.driver, entry.config || {});
      }
    }
  }
  if (authOptions.driver) {
    if (typeof authOptions.driver === "string") {
      addDriver(authOptions.driver, authOptions.config || {});
    } else if (typeof authOptions.driver === "object") {
      addDriver(authOptions.driver.driver, authOptions.driver.config || authOptions.config || {});
    }
  }
  for (const driverName of AUTH_DRIVER_KEYS) {
    if (authOptions[driverName] === void 0) continue;
    const value = authOptions[driverName];
    if (!value || value.enabled === false) continue;
    const config = typeof value === "object" ? { ...value } : {};
    if (config.enabled !== void 0) {
      delete config.enabled;
    }
    addDriver(driverName, config);
  }
  normalized.driver = normalized.drivers.length > 0 ? normalized.drivers[0].driver : null;
  return normalized;
}
class ApiPlugin extends Plugin {
  /**
   * Create API Plugin instance
   * @param {Object} options - Plugin configuration
   */
  constructor(options = {}) {
    super(options);
    const resourceNamesOption = options.resourceNames || {};
    this._usersResourceDescriptor = {
      defaultName: "plg_api_users",
      override: resourceNamesOption.authUsers || options.auth?.resource
    };
    const normalizedAuth = normalizeAuthConfig(options.auth);
    normalizedAuth.registration = {
      enabled: options.auth?.registration?.enabled === true,
      allowedFields: Array.isArray(options.auth?.registration?.allowedFields) ? options.auth.registration.allowedFields : [],
      defaultRole: options.auth?.registration?.defaultRole || "user"
    };
    normalizedAuth.loginThrottle = {
      enabled: options.auth?.loginThrottle?.enabled !== false,
      maxAttempts: options.auth?.loginThrottle?.maxAttempts || 5,
      windowMs: options.auth?.loginThrottle?.windowMs || 6e4,
      blockDurationMs: options.auth?.loginThrottle?.blockDurationMs || 3e5,
      maxEntries: options.auth?.loginThrottle?.maxEntries || 1e4
    };
    this.usersResourceName = this._resolveUsersResourceName();
    normalizedAuth.resource = this.usersResourceName;
    normalizedAuth.createResource = options.auth?.createResource !== false;
    this.config = {
      // Server configuration
      port: options.port || 3e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      // Version prefix configuration (global default)
      // Can be: true (use resource version), false (no prefix - DEFAULT), or string (custom prefix like 'api/v1')
      versionPrefix: options.versionPrefix !== void 0 ? options.versionPrefix : false,
      docs: {
        enabled: options.docs?.enabled !== false && options.docsEnabled !== false,
        // Enable by default
        ui: options.docs?.ui || "redoc",
        // 'swagger' or 'redoc' (redoc is prettier!)
        title: options.docs?.title || options.apiTitle || "s3db.js API",
        version: options.docs?.version || options.apiVersion || "1.0.0",
        description: options.docs?.description || options.apiDescription || "Auto-generated REST API for s3db.js resources"
      },
      // Authentication configuration (multiple drivers)
      auth: normalizedAuth,
      // Custom routes (plugin-level)
      routes: options.routes || {},
      // Template engine configuration
      templates: {
        enabled: options.templates?.enabled || false,
        engine: options.templates?.engine || "jsx",
        // 'jsx' (default), 'ejs', 'custom'
        templatesDir: options.templates?.templatesDir || "./views",
        layout: options.templates?.layout || null,
        engineOptions: options.templates?.engineOptions || {},
        customRenderer: options.templates?.customRenderer || null
      },
      // CORS configuration
      cors: {
        enabled: options.cors?.enabled || false,
        origin: options.cors?.origin || "*",
        methods: options.cors?.methods || ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
        allowedHeaders: options.cors?.allowedHeaders || ["Content-Type", "Authorization", "X-API-Key"],
        exposedHeaders: options.cors?.exposedHeaders || ["X-Total-Count", "X-Page-Count"],
        credentials: options.cors?.credentials !== false,
        maxAge: options.cors?.maxAge || 86400
      },
      // Rate limiting configuration
      rateLimit: {
        enabled: options.rateLimit?.enabled || false,
        windowMs: options.rateLimit?.windowMs || 6e4,
        // 1 minute
        maxRequests: options.rateLimit?.maxRequests || 100,
        keyGenerator: options.rateLimit?.keyGenerator || null,
        maxUniqueKeys: options.rateLimit?.maxUniqueKeys || 1e3
      },
      // Logging configuration
      logging: {
        enabled: options.logging?.enabled || false,
        format: options.logging?.format || ":method :path :status :response-time ms",
        verbose: options.logging?.verbose || false
      },
      // Compression configuration
      compression: {
        enabled: options.compression?.enabled || false,
        threshold: options.compression?.threshold || 1024,
        // 1KB
        level: options.compression?.level || 6
      },
      // Validation configuration
      validation: {
        enabled: options.validation?.enabled !== false,
        validateOnInsert: options.validation?.validateOnInsert !== false,
        validateOnUpdate: options.validation?.validateOnUpdate !== false,
        returnValidationErrors: options.validation?.returnValidationErrors !== false
      },
      // Security Headers (Helmet-like configuration)
      security: {
        enabled: options.security?.enabled !== false,
        // Enabled by default
        // Content Security Policy (CSP)
        contentSecurityPolicy: options.security?.contentSecurityPolicy !== false ? {
          enabled: options.security?.contentSecurityPolicy?.enabled !== false,
          directives: options.security?.contentSecurityPolicy?.directives || options.csp?.directives || {
            "default-src": ["'self'"],
            "script-src": ["'self'", "'unsafe-inline'", "https://cdn.redoc.ly/redoc/v2.5.1/"],
            "style-src": ["'self'", "'unsafe-inline'", "https://cdn.redoc.ly/redoc/v2.5.1/", "https://fonts.googleapis.com"],
            "font-src": ["'self'", "https://fonts.gstatic.com"],
            "img-src": ["'self'", "data:", "https:"],
            "connect-src": ["'self'"]
          },
          reportOnly: options.security?.contentSecurityPolicy?.reportOnly || options.csp?.reportOnly || false,
          reportUri: options.security?.contentSecurityPolicy?.reportUri || options.csp?.reportUri || null
        } : false,
        // X-Frame-Options (clickjacking protection)
        frameguard: options.security?.frameguard !== false ? {
          action: options.security?.frameguard?.action || "deny"
          // 'deny' or 'sameorigin'
        } : false,
        // X-Content-Type-Options (MIME sniffing protection)
        noSniff: options.security?.noSniff !== false,
        // Enabled by default
        // Strict-Transport-Security (HSTS - force HTTPS)
        hsts: options.security?.hsts !== false ? {
          maxAge: options.security?.hsts?.maxAge || 15552e3,
          // 180 days (Helmet default)
          includeSubDomains: options.security?.hsts?.includeSubDomains !== false,
          preload: options.security?.hsts?.preload || false
        } : false,
        // Referrer-Policy (privacy)
        referrerPolicy: options.security?.referrerPolicy !== false ? {
          policy: options.security?.referrerPolicy?.policy || "no-referrer"
        } : false,
        // X-DNS-Prefetch-Control (DNS leak protection)
        dnsPrefetchControl: options.security?.dnsPrefetchControl !== false ? {
          allow: options.security?.dnsPrefetchControl?.allow || false
        } : false,
        // X-Download-Options (IE8+ download security)
        ieNoOpen: options.security?.ieNoOpen !== false,
        // Enabled by default
        // X-Permitted-Cross-Domain-Policies (Flash/PDF security)
        permittedCrossDomainPolicies: options.security?.permittedCrossDomainPolicies !== false ? {
          policy: options.security?.permittedCrossDomainPolicies?.policy || "none"
        } : false,
        // X-XSS-Protection (legacy XSS filter)
        xssFilter: options.security?.xssFilter !== false ? {
          mode: options.security?.xssFilter?.mode || "block"
        } : false,
        // Permissions-Policy (modern feature policy)
        permissionsPolicy: options.security?.permissionsPolicy !== false ? {
          features: options.security?.permissionsPolicy?.features || {
            geolocation: [],
            microphone: [],
            camera: [],
            payment: [],
            usb: [],
            magnetometer: [],
            gyroscope: [],
            accelerometer: []
          }
        } : false
      },
      // Legacy CSP config (backward compatibility)
      csp: {
        enabled: options.csp?.enabled || false,
        directives: options.csp?.directives || {},
        reportOnly: options.csp?.reportOnly || false,
        reportUri: options.csp?.reportUri || null
      },
      // Custom global middlewares
      middlewares: options.middlewares || []
    };
    this.config.resources = this._normalizeResourcesConfig(options.resources);
    this.server = null;
    this.usersResource = null;
  }
  /**
   * Normalize resources config so array/string inputs become object map
   * @private
   * @param {Object|Array<string|Object>} resources
   * @returns {Object<string, Object>}
   */
  _normalizeResourcesConfig(resources) {
    if (!resources) {
      return {};
    }
    const normalized = {};
    const verbose = this.options?.verbose;
    const addResourceConfig = (name, config = {}) => {
      if (typeof name !== "string" || !name.trim()) {
        if (verbose) {
          console.warn("[API Plugin] Ignoring resource config with invalid name:", name);
        }
        return;
      }
      normalized[name] = { ...config };
    };
    if (Array.isArray(resources)) {
      for (const entry of resources) {
        if (typeof entry === "string") {
          addResourceConfig(entry);
        } else if (entry && typeof entry === "object" && typeof entry.name === "string") {
          const { name, ...config } = entry;
          addResourceConfig(name, config);
        } else {
          if (verbose) {
            console.warn("[API Plugin] Ignoring invalid resource config entry (expected string or object with name):", entry);
          }
        }
      }
      return normalized;
    }
    if (typeof resources === "object") {
      for (const [name, config] of Object.entries(resources)) {
        if (config === false) {
          addResourceConfig(name, { enabled: false });
        } else if (config === true || config === void 0 || config === null) {
          addResourceConfig(name);
        } else if (typeof config === "object") {
          addResourceConfig(name, config);
        } else {
          if (verbose) {
            console.warn("[API Plugin] Coercing resource config to empty object for", name);
          }
          addResourceConfig(name);
        }
      }
      return normalized;
    }
    if (verbose) {
      console.warn("[API Plugin] Invalid resources configuration. Expected object or array, received:", typeof resources);
    }
    return {};
  }
  /**
   * Validate plugin dependencies
   * @private
   */
  async _validateDependencies() {
    await requirePluginDependency("api-plugin", {
      throwOnError: true,
      checkVersions: true
    });
  }
  /**
   * Install plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[API Plugin] Installing...");
    }
    try {
      await this._validateDependencies();
    } catch (err) {
      console.error("[API Plugin] Dependency validation failed:", err.message);
      throw err;
    }
    const authEnabled = this.config.auth.drivers.length > 0;
    if (authEnabled) {
      await this._createUsersResource();
    }
    await this._setupMiddlewares();
    if (this.config.verbose) {
      console.log("[API Plugin] Installed successfully");
    }
  }
  /**
   * Create users resource for authentication
   * @private
   */
  async _createUsersResource() {
    const existingResource = this._findExistingUsersResource();
    if (!this.config.auth.createResource) {
      if (!existingResource) {
        throw new Error(
          `[API Plugin] Auth resource "${this.usersResourceName}" not found and auth.createResource is false`
        );
      }
      this.usersResource = existingResource;
      this.config.auth.resource = existingResource.name;
      if (this.config.verbose) {
        console.log(`[API Plugin] Using existing ${existingResource.name} resource for authentication`);
      }
      return;
    }
    if (existingResource) {
      this.usersResource = existingResource;
      this.config.auth.resource = existingResource.name;
      if (this.config.verbose) {
        console.log(`[API Plugin] Reusing existing ${existingResource.name} resource for authentication`);
      }
      return;
    }
    const [ok, err, resource] = await tryFn(
      () => this.database.createResource({
        name: this.usersResourceName,
        attributes: {
          id: "string|required",
          username: "string|required|minlength:3",
          email: "string|required|email",
          password: "secret|required|minlength:8",
          apiKey: "string|optional",
          jwtSecret: "string|optional",
          role: "string|default:user",
          scopes: "array|items:string|optional",
          active: "boolean|default:true",
          createdAt: "string|optional",
          lastLoginAt: "string|optional",
          metadata: "json|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "ApiPlugin"
      })
    );
    if (!ok) {
      throw err;
    }
    this.usersResource = resource;
    this.config.auth.resource = resource.name;
    if (this.config.verbose) {
      console.log(`[API Plugin] Created ${this.usersResourceName} resource for authentication`);
    }
  }
  _findExistingUsersResource() {
    const candidates = /* @__PURE__ */ new Set([this.usersResourceName]);
    const identityPlugin = this.database?.plugins?.identity || this.database?.plugins?.Identity;
    if (identityPlugin) {
      const identityNames = [
        identityPlugin.usersResource?.name,
        identityPlugin.config?.resources?.users?.mergedConfig?.name,
        identityPlugin.config?.resources?.users?.userConfig?.name
      ].filter(Boolean);
      for (const name of identityNames) {
        candidates.add(name);
      }
    }
    for (const name of candidates) {
      if (!name) continue;
      const resource = this.database.resources?.[name];
      if (resource) {
        return resource;
      }
    }
    return null;
  }
  /**
   * Setup middlewares
   * @private
   */
  async _setupMiddlewares() {
    const middlewares = [];
    middlewares.push(async (c, next) => {
      c.set("requestId", idGenerator());
      c.set("verbose", this.config.verbose);
      await next();
    });
    if (this.config.security.enabled) {
      const securityMiddleware = await this._createSecurityMiddleware();
      middlewares.push(securityMiddleware);
    }
    if (this.config.cors.enabled) {
      const corsMiddleware = await this._createCorsMiddleware();
      middlewares.push(corsMiddleware);
    }
    if (this.config.csp.enabled && !this.config.security.contentSecurityPolicy) {
      const cspMiddleware = await this._createCSPMiddleware();
      middlewares.push(cspMiddleware);
    }
    if (this.config.rateLimit.enabled) {
      const rateLimitMiddleware = await this._createRateLimitMiddleware();
      middlewares.push(rateLimitMiddleware);
    }
    if (this.config.logging.enabled) {
      const loggingMiddleware = await this._createLoggingMiddleware();
      middlewares.push(loggingMiddleware);
    }
    if (this.config.compression.enabled) {
      const compressionMiddleware = await this._createCompressionMiddleware();
      middlewares.push(compressionMiddleware);
    }
    middlewares.push(...this.config.middlewares);
    this.compiledMiddlewares = middlewares;
  }
  /**
   * Create CORS middleware
   * @private
   *
   * Handles Cross-Origin Resource Sharing (CORS) headers and preflight requests.
   * Supports wildcard origins, credential-based requests, and OPTIONS preflight.
   */
  async _createCorsMiddleware() {
    return async (c, next) => {
      const { origin, methods, allowedHeaders, exposedHeaders, credentials, maxAge } = this.config.cors;
      c.header("Access-Control-Allow-Origin", origin);
      c.header("Access-Control-Allow-Methods", methods.join(", "));
      c.header("Access-Control-Allow-Headers", allowedHeaders.join(", "));
      c.header("Access-Control-Expose-Headers", exposedHeaders.join(", "));
      if (credentials) {
        c.header("Access-Control-Allow-Credentials", "true");
      }
      c.header("Access-Control-Max-Age", maxAge.toString());
      if (c.req.method === "OPTIONS") {
        return c.body(null, 204);
      }
      await next();
    };
  }
  /**
   * Create CSP middleware
   * @private
   */
  async _createCSPMiddleware() {
    return async (c, next) => {
      const { directives, reportOnly, reportUri } = this.config.csp;
      const cspParts = [];
      for (const [directive, values] of Object.entries(directives)) {
        if (Array.isArray(values) && values.length > 0) {
          cspParts.push(`${directive} ${values.join(" ")}`);
        } else if (typeof values === "string") {
          cspParts.push(`${directive} ${values}`);
        }
      }
      if (reportUri) {
        cspParts.push(`report-uri ${reportUri}`);
      }
      const cspValue = cspParts.join("; ");
      const headerName = reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
      c.header(headerName, cspValue);
      await next();
    };
  }
  /**
   * Create rate limiting middleware
   * @private
   *
   * Implements sliding window rate limiting with configurable window size and max requests.
   * Returns 429 status code with Retry-After header when limit is exceeded.
   * Uses IP address or custom key generator to track request counts.
   */
  async _createRateLimitMiddleware() {
    const requests = /* @__PURE__ */ new Map();
    const { windowMs, maxRequests, keyGenerator, maxUniqueKeys } = this.config.rateLimit;
    const getClientIp = (c) => {
      const forwarded = c.req.header("x-forwarded-for");
      if (forwarded) {
        return forwarded.split(",")[0].trim();
      }
      const cfConnecting = c.req.header("cf-connecting-ip");
      if (cfConnecting) {
        return cfConnecting;
      }
      return c.req.raw?.socket?.remoteAddress || "unknown";
    };
    return async (c, next) => {
      const key = keyGenerator ? keyGenerator(c) : getClientIp(c) || "unknown";
      let record = requests.get(key);
      if (record && Date.now() > record.resetAt) {
        requests.delete(key);
        record = null;
      }
      if (!record) {
        record = { count: 0, resetAt: Date.now() + windowMs };
        requests.set(key, record);
        if (requests.size > maxUniqueKeys) {
          const oldestKey = requests.keys().next().value;
          if (oldestKey) {
            requests.delete(oldestKey);
          }
        }
      }
      if (record.count >= maxRequests) {
        const retryAfter = Math.ceil((record.resetAt - Date.now()) / 1e3);
        c.header("Retry-After", retryAfter.toString());
        c.header("X-RateLimit-Limit", maxRequests.toString());
        c.header("X-RateLimit-Remaining", "0");
        c.header("X-RateLimit-Reset", record.resetAt.toString());
        return c.json({
          success: false,
          error: {
            message: "Rate limit exceeded",
            code: "RATE_LIMIT_EXCEEDED",
            details: { retryAfter }
          }
        }, 429);
      }
      record.count++;
      c.header("X-RateLimit-Limit", maxRequests.toString());
      c.header("X-RateLimit-Remaining", (maxRequests - record.count).toString());
      c.header("X-RateLimit-Reset", record.resetAt.toString());
      await next();
    };
  }
  /**
   * Create logging middleware with customizable format
   * @private
   *
   * Supported tokens:
   * - :method - HTTP method (GET, POST, etc)
   * - :path - Request path
   * - :status - HTTP status code
   * - :response-time - Response time in milliseconds
   * - :user - Username or 'anonymous'
   * - :requestId - Request ID (UUID)
   *
   * Example format: ':method :path :status :response-time ms - :user'
   * Output: 'GET /api/v1/cars 200 45ms - john'
   */
  async _createLoggingMiddleware() {
    const { format } = this.config.logging;
    return async (c, next) => {
      const start = Date.now();
      const method = c.req.method;
      const path = c.req.path;
      const requestId = c.get("requestId");
      await next();
      const duration = Date.now() - start;
      const status = c.res.status;
      const user = c.get("user")?.username || c.get("user")?.email || "anonymous";
      let logMessage = format.replace(":method", method).replace(":path", path).replace(":status", status).replace(":response-time", duration).replace(":user", user).replace(":requestId", requestId);
      console.log(`[API Plugin] ${logMessage}`);
    };
  }
  /**
   * Create compression middleware (using Node.js zlib)
   * @private
   */
  async _createCompressionMiddleware() {
    const { gzip, brotliCompress } = await import('zlib');
    const { promisify } = await import('util');
    const gzipAsync = promisify(gzip);
    const brotliAsync = promisify(brotliCompress);
    const { threshold, level } = this.config.compression;
    const skipContentTypes = [
      "image/",
      "video/",
      "audio/",
      "application/zip",
      "application/gzip",
      "application/x-gzip",
      "application/x-bzip2"
    ];
    return async (c, next) => {
      await next();
      if (!c.res || !c.res.body) {
        return;
      }
      if (c.res.headers.has("content-encoding") || c.res.bodyUsed) {
        return;
      }
      const contentType = c.res.headers.get("content-type") || "";
      const isTextLike = contentType.startsWith("text/") || contentType.includes("json");
      if (skipContentTypes.some((type) => contentType.startsWith(type)) || !isTextLike) {
        return;
      }
      const acceptEncoding = c.req.header("accept-encoding") || "";
      const supportsBrotli = acceptEncoding.includes("br");
      const supportsGzip = acceptEncoding.includes("gzip");
      if (!supportsBrotli && !supportsGzip) {
        return;
      }
      let body;
      try {
        const text = await c.res.text();
        body = Buffer.from(text, "utf-8");
      } catch (err) {
        return;
      }
      if (body.length < threshold) {
        return;
      }
      let compressed;
      let encoding;
      try {
        if (supportsBrotli) {
          compressed = await brotliAsync(body);
          encoding = "br";
        } else {
          compressed = await gzipAsync(body, { level });
          encoding = "gzip";
        }
        if (compressed.length >= body.length) {
          return;
        }
        const headers = new Headers(c.res.headers);
        headers.set("Content-Encoding", encoding);
        headers.set("Content-Length", compressed.length.toString());
        headers.set("Vary", "Accept-Encoding");
        c.res = new Response(compressed, {
          status: c.res.status,
          statusText: c.res.statusText,
          headers
        });
      } catch (err) {
        if (this.config.verbose) {
          console.error("[API Plugin] Compression error:", err.message);
        }
      }
    };
  }
  /**
   * Create security headers middleware (Helmet-like)
   * @private
   */
  async _createSecurityMiddleware() {
    const { security } = this.config;
    return async (c, next) => {
      if (security.noSniff) {
        c.header("X-Content-Type-Options", "nosniff");
      }
      if (security.frameguard) {
        const action = security.frameguard.action.toUpperCase();
        if (action === "DENY") {
          c.header("X-Frame-Options", "DENY");
        } else if (action === "SAMEORIGIN") {
          c.header("X-Frame-Options", "SAMEORIGIN");
        }
      }
      if (security.hsts) {
        const parts = [`max-age=${security.hsts.maxAge}`];
        if (security.hsts.includeSubDomains) {
          parts.push("includeSubDomains");
        }
        if (security.hsts.preload) {
          parts.push("preload");
        }
        c.header("Strict-Transport-Security", parts.join("; "));
      }
      if (security.referrerPolicy) {
        c.header("Referrer-Policy", security.referrerPolicy.policy);
      }
      if (security.dnsPrefetchControl) {
        const value = security.dnsPrefetchControl.allow ? "on" : "off";
        c.header("X-DNS-Prefetch-Control", value);
      }
      if (security.ieNoOpen) {
        c.header("X-Download-Options", "noopen");
      }
      if (security.permittedCrossDomainPolicies) {
        c.header("X-Permitted-Cross-Domain-Policies", security.permittedCrossDomainPolicies.policy);
      }
      if (security.xssFilter) {
        const mode = security.xssFilter.mode;
        c.header("X-XSS-Protection", mode === "block" ? "1; mode=block" : "0");
      }
      if (security.permissionsPolicy && security.permissionsPolicy.features) {
        const features = security.permissionsPolicy.features;
        const policies = [];
        for (const [feature, allowList] of Object.entries(features)) {
          if (Array.isArray(allowList)) {
            const value = allowList.length === 0 ? `${feature}=()` : `${feature}=(${allowList.join(" ")})`;
            policies.push(value);
          }
        }
        if (policies.length > 0) {
          c.header("Permissions-Policy", policies.join(", "));
        }
      }
      const cspConfig = this.config.csp.enabled ? this.config.csp : security.contentSecurityPolicy;
      if (cspConfig && cspConfig.enabled !== false && cspConfig.directives) {
        const cspParts = [];
        for (const [directive, values] of Object.entries(cspConfig.directives)) {
          if (Array.isArray(values) && values.length > 0) {
            cspParts.push(`${directive} ${values.join(" ")}`);
          } else if (typeof values === "string") {
            cspParts.push(`${directive} ${values}`);
          }
        }
        if (cspConfig.reportUri) {
          cspParts.push(`report-uri ${cspConfig.reportUri}`);
        }
        if (cspParts.length > 0) {
          const cspValue = cspParts.join("; ");
          const headerName = cspConfig.reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
          c.header(headerName, cspValue);
        }
      }
      await next();
    };
  }
  /**
   * Start plugin
   */
  async onStart() {
    if (this.config.verbose) {
      console.log("[API Plugin] Starting server...");
    }
    this.server = new ApiServer({
      port: this.config.port,
      host: this.config.host,
      database: this.database,
      namespace: this.namespace,
      versionPrefix: this.config.versionPrefix,
      resources: this.config.resources,
      routes: this.config.routes,
      templates: this.config.templates,
      middlewares: this.compiledMiddlewares,
      verbose: this.config.verbose,
      auth: this.config.auth,
      docsEnabled: this.config.docs.enabled,
      docsUI: this.config.docs.ui,
      apiTitle: this.config.docs.title,
      apiVersion: this.config.docs.version,
      apiDescription: this.config.docs.description
    });
    await this.server.start();
    this.emit("plugin.started", {
      port: this.config.port,
      host: this.config.host
    });
  }
  /**
   * Stop plugin
   */
  async onStop() {
    if (this.config.verbose) {
      console.log("[API Plugin] Stopping server...");
    }
    if (this.server) {
      await this.server.stop();
    }
    this.server = null;
  }
  _resolveUsersResourceName() {
    return resolveResourceName("api", this._usersResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.usersResourceName = this._resolveUsersResourceName();
    if (this.config?.auth) {
      this.config.auth.resource = this.usersResourceName;
    }
    if (this.server?.failban) {
      this.server.failban.setNamespace(this.namespace);
    }
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    const { purgeData = false } = options;
    await this.onStop();
    if (purgeData && this.usersResource) {
      const [ok] = await tryFn(() => this.database.deleteResource(this.usersResourceName));
      if (ok && this.config.verbose) {
        console.log(`[API Plugin] Deleted ${this.usersResourceName} resource`);
      }
    }
    if (this.config.verbose) {
      console.log("[API Plugin] Uninstalled successfully");
    }
  }
  /**
   * Get server information
   * @returns {Object} Server info
   */
  getServerInfo() {
    return this.server ? this.server.getInfo() : { isRunning: false };
  }
  /**
   * Get Hono app instance (for advanced usage)
   * @returns {Hono|null} Hono app
   */
  getApp() {
    return this.server ? this.server.getApp() : null;
  }
}

function generateKeyPair(modulusLength = 2048) {
  const { publicKey, privateKey } = generateKeyPairSync("rsa", {
    modulusLength,
    publicKeyEncoding: {
      type: "spki",
      format: "pem"
    },
    privateKeyEncoding: {
      type: "pkcs8",
      format: "pem"
    }
  });
  const kid = createHash("sha256").update(publicKey).digest("hex").substring(0, 16);
  return {
    publicKey,
    privateKey,
    kid,
    algorithm: "RS256",
    use: "sig",
    createdAt: (/* @__PURE__ */ new Date()).toISOString()
  };
}
function pemToJwk(publicKeyPem, kid) {
  const keyObject = createPublicKey(publicKeyPem);
  const exported = keyObject.export({ format: "jwk" });
  return {
    kty: "RSA",
    use: "sig",
    alg: "RS256",
    kid,
    n: exported.n,
    // modulus
    e: exported.e
    // exponent
  };
}
function createRS256Token(payload, privateKey, kid, expiresIn = "15m") {
  const match = expiresIn.match(/^(\d+)([smhd])$/);
  if (!match) {
    throw new Error("Invalid expiresIn format. Use: 60s, 30m, 24h, 7d");
  }
  const [, value, unit] = match;
  const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
  const expiresInSeconds = parseInt(value) * multipliers[unit];
  const header = {
    alg: "RS256",
    typ: "JWT",
    kid
  };
  const now = Math.floor(Date.now() / 1e3);
  const data = {
    ...payload,
    iat: now,
    exp: now + expiresInSeconds
  };
  const encodedHeader = Buffer.from(JSON.stringify(header)).toString("base64url");
  const encodedPayload = Buffer.from(JSON.stringify(data)).toString("base64url");
  const sign = createSign("RSA-SHA256");
  sign.update(`${encodedHeader}.${encodedPayload}`);
  sign.end();
  const signature = sign.sign(privateKey, "base64url");
  return `${encodedHeader}.${encodedPayload}.${signature}`;
}
function verifyRS256Token(token, publicKey) {
  try {
    const parts = token.split(".");
    if (parts.length !== 3) {
      return null;
    }
    const [encodedHeader, encodedPayload, signature] = parts;
    const verify = createVerify("RSA-SHA256");
    verify.update(`${encodedHeader}.${encodedPayload}`);
    verify.end();
    const isValid = verify.verify(publicKey, signature, "base64url");
    if (!isValid) {
      return null;
    }
    const header = JSON.parse(Buffer.from(encodedHeader, "base64url").toString());
    const payload = JSON.parse(Buffer.from(encodedPayload, "base64url").toString());
    if (header.alg !== "RS256") {
      return null;
    }
    const now = Math.floor(Date.now() / 1e3);
    if (payload.exp && payload.exp < now) {
      return null;
    }
    return {
      header,
      payload
    };
  } catch (err) {
    return null;
  }
}
function getKidFromToken(token) {
  try {
    const [encodedHeader] = token.split(".");
    const header = JSON.parse(Buffer.from(encodedHeader, "base64url").toString());
    return header.kid || null;
  } catch (err) {
    return null;
  }
}
class KeyManager {
  constructor(keyResource) {
    this.keyResource = keyResource;
    this.keysByPurpose = /* @__PURE__ */ new Map();
    this.currentKeys = /* @__PURE__ */ new Map();
    this.keysByKid = /* @__PURE__ */ new Map();
  }
  /**
   * Initialize key manager - load or generate keys
   */
  async initialize() {
    const existingKeys = await this.keyResource.list();
    if (existingKeys.length > 0) {
      for (const keyRecord of existingKeys) {
        this._storeKeyRecord({
          ...keyRecord,
          purpose: keyRecord.purpose || "oauth"
        });
      }
    }
    if (!this.currentKeys.get("oauth")) {
      await this.rotateKey("oauth");
    }
  }
  /**
   * Rotate keys - generate new key pair
   */
  async rotateKey(purpose = "oauth") {
    const normalizedPurpose = this._normalizePurpose(purpose);
    const keyPair = generateKeyPair();
    const oldKeys = await this.keyResource.query({ active: true, purpose: normalizedPurpose });
    for (const oldKey of oldKeys) {
      await this.keyResource.update(oldKey.id, { active: false });
      const stored = this.keysByKid.get(oldKey.kid);
      if (stored) {
        stored.active = false;
      }
    }
    const keyRecord = await this.keyResource.insert({
      kid: keyPair.kid,
      publicKey: keyPair.publicKey,
      privateKey: keyPair.privateKey,
      algorithm: keyPair.algorithm,
      use: keyPair.use,
      active: true,
      createdAt: keyPair.createdAt,
      purpose: normalizedPurpose
    });
    this._storeKeyRecord(keyRecord);
    return keyRecord;
  }
  /**
   * Get current active key
   */
  getCurrentKey(purpose = "oauth") {
    return this.currentKeys.get(this._normalizePurpose(purpose)) || null;
  }
  /**
   * Get key by kid
   */
  getKey(kid) {
    return this.keysByKid.get(kid) || null;
  }
  /**
   * Ensure a purpose has an active key
   * @param {string} purpose
   * @returns {Promise<Object>}
   */
  async ensurePurpose(purpose = "oauth") {
    const normalizedPurpose = this._normalizePurpose(purpose);
    const current = this.currentKeys.get(normalizedPurpose);
    if (current) {
      return current;
    }
    const [active] = await this.keyResource.query({ purpose: normalizedPurpose, active: true });
    if (active) {
      this._storeKeyRecord({
        ...active,
        purpose: active.purpose || normalizedPurpose
      });
      return this.currentKeys.get(normalizedPurpose);
    }
    return await this.rotateKey(normalizedPurpose);
  }
  /**
   * Get all public keys in JWKS format
   */
  async getJWKS() {
    const keys = Array.from(this.keysByKid.values()).filter((key) => key.active).map((key) => ({
      kty: "RSA",
      use: "sig",
      alg: "RS256",
      kid: key.kid,
      ...pemToJwk(key.publicKey, key.kid)
    }));
    return { keys };
  }
  /**
   * Create JWT with current active key
   */
  createToken(payload, expiresIn = "15m", purpose = "oauth") {
    const normalizedPurpose = this._normalizePurpose(purpose);
    const activeKey = this.currentKeys.get(normalizedPurpose);
    if (!activeKey) {
      throw new Error(`No active key available for purpose "${normalizedPurpose}"`);
    }
    return createRS256Token(
      payload,
      activeKey.privateKey,
      activeKey.kid,
      expiresIn
    );
  }
  /**
   * Verify JWT token
   */
  async verifyToken(token) {
    const kid = getKidFromToken(token);
    if (!kid) {
      return null;
    }
    const key = this.getKey(kid);
    if (!key) {
      return null;
    }
    return verifyRS256Token(token, key.publicKey);
  }
  /**
   * Normalize purpose name
   * @param {string} purpose
   * @returns {string}
   * @private
   */
  _normalizePurpose(purpose) {
    return typeof purpose === "string" && purpose.trim().length > 0 ? purpose.trim() : "oauth";
  }
  /**
   * Store key record in caches
   * @param {Object} record
   * @private
   */
  _storeKeyRecord(record) {
    const purpose = this._normalizePurpose(record.purpose);
    const entry = {
      publicKey: record.publicKey,
      privateKey: record.privateKey,
      kid: record.kid,
      createdAt: record.createdAt,
      active: record.active,
      purpose,
      id: record.id
    };
    if (!this.keysByPurpose.has(purpose)) {
      this.keysByPurpose.set(purpose, /* @__PURE__ */ new Map());
    }
    this.keysByPurpose.get(purpose).set(entry.kid, entry);
    this.keysByKid.set(entry.kid, entry);
    if (entry.active) {
      this.currentKeys.set(purpose, entry);
    }
  }
}

var rsaKeys = /*#__PURE__*/Object.freeze({
  __proto__: null,
  KeyManager: KeyManager,
  createRS256Token: createRS256Token,
  generateKeyPair: generateKeyPair,
  getKidFromToken: getKidFromToken,
  pemToJwk: pemToJwk,
  verifyRS256Token: verifyRS256Token
});

function generateDiscoveryDocument(options = {}) {
  const {
    issuer,
    grantTypes = ["authorization_code", "client_credentials", "refresh_token"],
    responseTypes = ["code", "token", "id_token", "code id_token", "code token", "id_token token", "code id_token token"],
    scopes = ["openid", "profile", "email", "offline_access"]
  } = options;
  if (!issuer) {
    throw new PluginError("Issuer URL is required for OIDC discovery", {
      pluginName: "IdentityPlugin",
      operation: "generateDiscoveryDocument",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide options.issuer when generating the discovery document."
    });
  }
  const baseUrl = issuer.replace(/\/$/, "");
  return {
    issuer: baseUrl,
    authorization_endpoint: `${baseUrl}/oauth/authorize`,
    token_endpoint: `${baseUrl}/oauth/token`,
    userinfo_endpoint: `${baseUrl}/oauth/userinfo`,
    jwks_uri: `${baseUrl}/.well-known/jwks.json`,
    registration_endpoint: `${baseUrl}/oauth/register`,
    introspection_endpoint: `${baseUrl}/oauth/introspect`,
    revocation_endpoint: `${baseUrl}/oauth/revoke`,
    end_session_endpoint: `${baseUrl}/logout`,
    // Supported features
    scopes_supported: scopes,
    response_types_supported: responseTypes,
    response_modes_supported: ["query", "fragment", "form_post"],
    grant_types_supported: grantTypes,
    subject_types_supported: ["public"],
    id_token_signing_alg_values_supported: ["RS256"],
    token_endpoint_auth_methods_supported: [
      "client_secret_basic",
      "client_secret_post",
      "none"
    ],
    // Claims
    claims_supported: [
      "sub",
      "iss",
      "aud",
      "exp",
      "iat",
      "auth_time",
      "nonce",
      "email",
      "email_verified",
      "name",
      "given_name",
      "family_name",
      "picture",
      "locale"
    ],
    // Code challenge methods (PKCE)
    code_challenge_methods_supported: ["plain", "S256"],
    // UI locales
    ui_locales_supported: ["en", "pt-BR"],
    // Service documentation
    service_documentation: `${baseUrl}/docs`,
    // Additional metadata
    claim_types_supported: ["normal"],
    claims_parameter_supported: false,
    request_parameter_supported: false,
    request_uri_parameter_supported: false,
    require_request_uri_registration: false,
    // Discovery document version
    version: "1.0"
  };
}
function validateClaims(payload, options = {}) {
  const {
    issuer,
    audience,
    clockTolerance = 60
  } = options;
  const now = Math.floor(Date.now() / 1e3);
  if (!payload.sub) {
    return { valid: false, error: "Missing required claim: sub" };
  }
  if (!payload.iat) {
    return { valid: false, error: "Missing required claim: iat" };
  }
  if (!payload.exp) {
    return { valid: false, error: "Missing required claim: exp" };
  }
  if (issuer && payload.iss !== issuer) {
    return {
      valid: false,
      error: `Invalid issuer. Expected: ${issuer}, Got: ${payload.iss}`
    };
  }
  if (audience) {
    const audiences = Array.isArray(payload.aud) ? payload.aud : [payload.aud];
    if (!audiences.includes(audience)) {
      return {
        valid: false,
        error: `Invalid audience. Expected: ${audience}, Got: ${audiences.join(", ")}`
      };
    }
  }
  if (payload.exp < now - clockTolerance) {
    return { valid: false, error: "Token has expired" };
  }
  if (payload.nbf && payload.nbf > now + clockTolerance) {
    return { valid: false, error: "Token not yet valid (nbf)" };
  }
  if (payload.iat > now + clockTolerance) {
    return { valid: false, error: "Token issued in the future" };
  }
  return { valid: true, error: null };
}
function extractUserClaims(user, scopes = []) {
  const claims = {
    sub: user.id
    // Subject - user ID
  };
  if (scopes.includes("email") && user.email) {
    claims.email = user.email;
    claims.email_verified = user.emailVerified || false;
  }
  if (scopes.includes("profile")) {
    if (user.name) claims.name = user.name;
    if (user.givenName) claims.given_name = user.givenName;
    if (user.familyName) claims.family_name = user.familyName;
    if (user.picture) claims.picture = user.picture;
    if (user.locale) claims.locale = user.locale;
    if (user.zoneinfo) claims.zoneinfo = user.zoneinfo;
    if (user.birthdate) claims.birthdate = user.birthdate;
    if (user.gender) claims.gender = user.gender;
  }
  return claims;
}
function parseScopes(scopeString) {
  if (!scopeString || typeof scopeString !== "string") {
    return [];
  }
  return scopeString.trim().split(/\s+/).filter((s) => s.length > 0);
}
function validateScopes(requestedScopes, supportedScopes) {
  if (!Array.isArray(requestedScopes)) {
    requestedScopes = parseScopes(requestedScopes);
  }
  const invalidScopes = requestedScopes.filter((scope) => !supportedScopes.includes(scope));
  if (invalidScopes.length > 0) {
    return {
      valid: false,
      error: `Unsupported scopes: ${invalidScopes.join(", ")}`,
      scopes: []
    };
  }
  return {
    valid: true,
    error: null,
    scopes: requestedScopes
  };
}
function generateAuthCode(length = 32) {
  const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~";
  let code = "";
  for (let i = 0; i < length; i++) {
    code += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return code;
}
function generateClientId() {
  return crypto.randomUUID();
}
function generateClientSecret(length = 64) {
  return crypto.randomBytes(length / 2).toString("hex");
}

const DEFAULT_PASSWORD_POLICY = {
  minLength: 8,
  maxLength: 128,
  requireUppercase: true,
  requireLowercase: true,
  requireNumbers: true,
  requireSymbols: false
};
async function verifyPassword(plaintext, storedHash) {
  return await verifyPassword$1(plaintext, storedHash);
}
function validatePassword(password, policy = DEFAULT_PASSWORD_POLICY) {
  const errors = [];
  if (!password || typeof password !== "string") {
    return { valid: false, errors: ["Password must be a string"] };
  }
  const rules = { ...DEFAULT_PASSWORD_POLICY, ...policy };
  if (password.length < rules.minLength) {
    errors.push(`Password must be at least ${rules.minLength} characters long`);
  }
  if (password.length > rules.maxLength) {
    errors.push(`Password must not exceed ${rules.maxLength} characters`);
  }
  if (rules.requireUppercase && !/[A-Z]/.test(password)) {
    errors.push("Password must contain at least one uppercase letter");
  }
  if (rules.requireLowercase && !/[a-z]/.test(password)) {
    errors.push("Password must contain at least one lowercase letter");
  }
  if (rules.requireNumbers && !/[0-9]/.test(password)) {
    errors.push("Password must contain at least one number");
  }
  if (rules.requireSymbols && !/[!@#$%^&*()_+\-=\[\]{};':"\\|,.<>\/?]/.test(password)) {
    errors.push("Password must contain at least one symbol");
  }
  return {
    valid: errors.length === 0,
    errors
  };
}

class OAuth2Server {
  constructor(options = {}) {
    const {
      issuer,
      keyResource,
      userResource,
      clientResource,
      authCodeResource,
      supportedScopes = ["openid", "profile", "email", "offline_access"],
      supportedGrantTypes = ["authorization_code", "client_credentials", "refresh_token"],
      supportedResponseTypes = ["code", "token", "id_token"],
      accessTokenExpiry = "15m",
      idTokenExpiry = "15m",
      refreshTokenExpiry = "7d",
      authCodeExpiry = "10m"
    } = options;
    if (!issuer) {
      throw new PluginError("Issuer URL is required for OAuth2Server", {
        pluginName: "IdentityPlugin",
        operation: "OAuth2Server.constructor",
        statusCode: 400,
        retriable: false,
        suggestion: 'Pass { issuer: "https://auth.example.com" } when initializing OAuth2Server.'
      });
    }
    if (!keyResource) {
      throw new PluginError("keyResource is required for OAuth2Server", {
        pluginName: "IdentityPlugin",
        operation: "OAuth2Server.constructor",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide a keyResource (S3DB resource) to store signing keys."
      });
    }
    if (!userResource) {
      throw new PluginError("userResource is required for OAuth2Server", {
        pluginName: "IdentityPlugin",
        operation: "OAuth2Server.constructor",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide a userResource to look up user accounts during token exchange."
      });
    }
    this.issuer = issuer.replace(/\/$/, "");
    this.keyResource = keyResource;
    this.userResource = userResource;
    this.clientResource = clientResource;
    this.authCodeResource = authCodeResource;
    this.supportedScopes = supportedScopes;
    this.supportedGrantTypes = supportedGrantTypes;
    this.supportedResponseTypes = supportedResponseTypes;
    this.accessTokenExpiry = accessTokenExpiry;
    this.idTokenExpiry = idTokenExpiry;
    this.refreshTokenExpiry = refreshTokenExpiry;
    this.authCodeExpiry = authCodeExpiry;
    this.keyManager = new KeyManager(keyResource);
  }
  /**
   * Initialize OAuth2 server - load keys
   */
  async initialize() {
    await this.keyManager.initialize();
  }
  /**
   * OIDC Discovery endpoint handler
   * GET /.well-known/openid-configuration
   */
  async discoveryHandler(req, res) {
    try {
      const document = generateDiscoveryDocument({
        issuer: this.issuer,
        grantTypes: this.supportedGrantTypes,
        responseTypes: this.supportedResponseTypes,
        scopes: this.supportedScopes
      });
      return res.status(200).json(document);
    } catch (error) {
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * JWKS endpoint handler
   * GET /.well-known/jwks.json
   */
  async jwksHandler(req, res) {
    try {
      const jwks = await this.keyManager.getJWKS();
      return res.status(200).json(jwks);
    } catch (error) {
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token endpoint handler
   * POST /auth/token
   *
   * Supports:
   * - client_credentials grant
   * - authorization_code grant (if authCodeResource provided)
   * - refresh_token grant (if authCodeResource provided)
   */
  async tokenHandler(req, res) {
    try {
      const { grant_type, scope, client_id, client_secret } = req.body;
      if (!grant_type) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "grant_type is required"
        });
      }
      if (!this.supportedGrantTypes.includes(grant_type)) {
        return res.status(400).json({
          error: "unsupported_grant_type",
          error_description: `Grant type ${grant_type} is not supported`
        });
      }
      if (!client_id) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "client_id is required"
        });
      }
      if (this.clientResource) {
        const client = await this.authenticateClient(client_id, client_secret);
        if (!client) {
          return res.status(401).json({
            error: "invalid_client",
            error_description: "Client authentication failed"
          });
        }
      }
      switch (grant_type) {
        case "client_credentials":
          return await this.handleClientCredentials(req, res, { client_id, scope });
        case "authorization_code":
          return await this.handleAuthorizationCode(req, res);
        case "refresh_token":
          return await this.handleRefreshToken(req, res);
        default:
          return res.status(400).json({
            error: "unsupported_grant_type",
            error_description: `Grant type ${grant_type} is not supported`
          });
      }
    } catch (error) {
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Client Credentials flow handler
   */
  async handleClientCredentials(req, res, { client_id, scope }) {
    const scopes = parseScopes(scope);
    const scopeValidation = validateScopes(scopes, this.supportedScopes);
    if (!scopeValidation.valid) {
      return res.status(400).json({
        error: "invalid_scope",
        error_description: scopeValidation.error
      });
    }
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: client_id,
      aud: this.issuer,
      scope: scopeValidation.scopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    return res.status(200).json({
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry),
      scope: scopeValidation.scopes.join(" ")
    });
  }
  /**
   * Authorization Code flow handler
   */
  async handleAuthorizationCode(req, res) {
    if (!this.authCodeResource) {
      return res.status(400).json({
        error: "unsupported_grant_type",
        error_description: "Authorization code flow requires authCodeResource"
      });
    }
    const { code, redirect_uri, code_verifier } = req.body;
    if (!code) {
      return res.status(400).json({
        error: "invalid_request",
        error_description: "code is required"
      });
    }
    const authCodes = await this.authCodeResource.query({ code });
    if (authCodes.length === 0) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Invalid authorization code"
      });
    }
    const authCode = authCodes[0];
    const expiresAtMs = this.parseAuthCodeExpiry(authCode.expiresAt);
    if (!Number.isFinite(expiresAtMs)) {
      await this.authCodeResource.remove(authCode.id);
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Authorization code is invalid"
      });
    }
    if (expiresAtMs <= Date.now()) {
      await this.authCodeResource.remove(authCode.id);
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Authorization code has expired"
      });
    }
    if (authCode.redirectUri !== redirect_uri) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "redirect_uri mismatch"
      });
    }
    if (authCode.codeChallenge) {
      if (!code_verifier) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "code_verifier is required"
        });
      }
      const isValid = await this.validatePKCE(
        code_verifier,
        authCode.codeChallenge,
        authCode.codeChallengeMethod
      );
      if (!isValid) {
        return res.status(400).json({
          error: "invalid_grant",
          error_description: "Invalid code_verifier"
        });
      }
    }
    const user = await this.userResource.get(authCode.userId);
    if (!user) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "User not found"
      });
    }
    const scopes = parseScopes(authCode.scope);
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: user.id,
      aud: authCode.audience || this.issuer,
      scope: scopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    const response = {
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry)
    };
    if (scopes.includes("openid")) {
      const userClaims = extractUserClaims(user, scopes);
      const idToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: authCode.clientId,
        nonce: authCode.nonce,
        ...userClaims
      }, this.idTokenExpiry);
      response.id_token = idToken;
    }
    if (scopes.includes("offline_access")) {
      const refreshToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: this.issuer,
        scope: scopes.join(" "),
        token_type: "refresh_token"
      }, this.refreshTokenExpiry);
      response.refresh_token = refreshToken;
    }
    await this.authCodeResource.remove(authCode.id);
    return res.status(200).json(response);
  }
  /**
   * Refresh Token flow handler
   */
  async handleRefreshToken(req, res) {
    const { refresh_token, scope } = req.body;
    if (!refresh_token) {
      return res.status(400).json({
        error: "invalid_request",
        error_description: "refresh_token is required"
      });
    }
    const verified = await this.keyManager.verifyToken(refresh_token);
    if (!verified) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Invalid refresh token"
      });
    }
    const { payload } = verified;
    if (payload.token_type !== "refresh_token") {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Token is not a refresh token"
      });
    }
    const claimValidation = validateClaims(payload, {
      issuer: this.issuer,
      clockTolerance: 60
    });
    if (!claimValidation.valid) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: claimValidation.error
      });
    }
    const requestedScopes = scope ? parseScopes(scope) : parseScopes(payload.scope);
    const originalScopes = parseScopes(payload.scope);
    const invalidScopes = requestedScopes.filter((s) => !originalScopes.includes(s));
    if (invalidScopes.length > 0) {
      return res.status(400).json({
        error: "invalid_scope",
        error_description: `Cannot request scopes not in original grant: ${invalidScopes.join(", ")}`
      });
    }
    const user = await this.userResource.get(payload.sub);
    if (!user) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "User not found"
      });
    }
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: user.id,
      aud: payload.aud,
      scope: requestedScopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    const response = {
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry)
    };
    if (requestedScopes.includes("openid")) {
      const userClaims = extractUserClaims(user, requestedScopes);
      const idToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: payload.aud,
        ...userClaims
      }, this.idTokenExpiry);
      response.id_token = idToken;
    }
    return res.status(200).json(response);
  }
  /**
   * UserInfo endpoint handler
   * GET /auth/userinfo
   */
  async userinfoHandler(req, res) {
    try {
      const authHeader = req.headers.authorization;
      if (!authHeader || !authHeader.startsWith("Bearer ")) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: "Missing or invalid Authorization header"
        });
      }
      const token = authHeader.substring(7);
      const verified = await this.keyManager.verifyToken(token);
      if (!verified) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: "Invalid access token"
        });
      }
      const { payload } = verified;
      const claimValidation = validateClaims(payload, {
        issuer: this.issuer,
        clockTolerance: 60
      });
      if (!claimValidation.valid) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: claimValidation.error
        });
      }
      const user = await this.userResource.get(payload.sub);
      if (!user) {
        return res.status(404).json({
          error: "not_found",
          error_description: "User not found"
        });
      }
      const scopes = parseScopes(payload.scope);
      const userClaims = extractUserClaims(user, scopes);
      return res.status(200).json({
        sub: user.id,
        ...userClaims
      });
    } catch (error) {
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token Introspection endpoint handler (RFC 7662)
   * POST /auth/introspect
   */
  async introspectHandler(req, res) {
    try {
      const { token, token_type_hint } = req.body;
      if (!token) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "token is required"
        });
      }
      const verified = await this.keyManager.verifyToken(token);
      if (!verified) {
        return res.status(200).json({ active: false });
      }
      const { payload } = verified;
      const claimValidation = validateClaims(payload, {
        issuer: this.issuer,
        clockTolerance: 60
      });
      if (!claimValidation.valid) {
        return res.status(200).json({ active: false });
      }
      return res.status(200).json({
        active: true,
        scope: payload.scope,
        client_id: payload.aud,
        username: payload.sub,
        token_type: payload.token_type || "access_token",
        exp: payload.exp,
        iat: payload.iat,
        sub: payload.sub,
        iss: payload.iss,
        aud: payload.aud
      });
    } catch (error) {
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Authenticate client with credentials
   */
  async authenticateClient(clientId, clientSecret) {
    if (!this.clientResource) {
      return null;
    }
    try {
      const clients = await this.clientResource.query({ clientId });
      if (clients.length === 0) {
        return null;
      }
      const client = clients[0];
      if (client.clientSecret !== clientSecret) {
        return null;
      }
      return client;
    } catch (error) {
      return null;
    }
  }
  /**
   * Validate PKCE code verifier
   */
  async validatePKCE(codeVerifier, codeChallenge, codeChallengeMethod = "plain") {
    if (codeChallengeMethod === "plain") {
      return codeVerifier === codeChallenge;
    }
    if (codeChallengeMethod === "S256") {
      const crypto = await import('crypto');
      const hash = crypto.createHash("sha256").update(codeVerifier).digest("base64url");
      return hash === codeChallenge;
    }
    return false;
  }
  /**
   * Parse expiry string to seconds
   */
  parseExpiryToSeconds(expiresIn) {
    const match = expiresIn.match(/^(\d+)([smhd])$/);
    if (!match) {
      throw new PluginError("Invalid expiresIn format", {
        pluginName: "IdentityPlugin",
        operation: "parseExpiryToSeconds",
        statusCode: 400,
        retriable: false,
        suggestion: 'Use a duration string such as "15m", "24h", or "30s".'
      });
    }
    const [, value, unit] = match;
    const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
    return parseInt(value) * multipliers[unit];
  }
  /**
   * Authorization endpoint handler (GET /oauth/authorize)
   * Implements OAuth2 authorization code flow
   *
   * Query params:
   * - response_type: 'code' (required)
   * - client_id: Client identifier (required)
   * - redirect_uri: Callback URL (required)
   * - scope: Requested scopes (optional)
   * - state: CSRF protection (recommended)
   * - code_challenge: PKCE challenge (optional)
   * - code_challenge_method: PKCE method (optional, default: plain)
   */
  async authorizeHandler(req, res) {
    try {
      const {
        response_type,
        client_id,
        redirect_uri,
        scope,
        state,
        code_challenge,
        code_challenge_method = "plain"
      } = req.query || {};
      if (!response_type || !client_id || !redirect_uri) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "response_type, client_id, and redirect_uri are required"
        });
      }
      if (!this.supportedResponseTypes.includes(response_type)) {
        return res.status(400).json({
          error: "unsupported_response_type",
          error_description: `Response type ${response_type} is not supported`
        });
      }
      if (this.clientResource) {
        const clients = await this.clientResource.query({ clientId: client_id });
        if (clients.length === 0) {
          return res.status(400).json({
            error: "invalid_client",
            error_description: "Client not found"
          });
        }
        const client = clients[0];
        if (!client.redirectUris.includes(redirect_uri)) {
          return res.status(400).json({
            error: "invalid_request",
            error_description: "Invalid redirect_uri"
          });
        }
        if (scope) {
          const requestedScopes = scope.split(" ");
          const invalidScopes = requestedScopes.filter(
            (s) => !client.allowedScopes.includes(s)
          );
          if (invalidScopes.length > 0) {
            return res.status(400).json({
              error: "invalid_scope",
              error_description: `Invalid scopes: ${invalidScopes.join(", ")}`
            });
          }
        }
      }
      const html = `
<!DOCTYPE html>
<html>
<head>
  <title>Authorization - ${this.issuer}</title>
  <style>
    body { font-family: system-ui; max-width: 400px; margin: 100px auto; padding: 20px; }
    form { background: #f5f5f5; padding: 20px; border-radius: 8px; }
    input { width: 100%; padding: 10px; margin: 10px 0; box-sizing: border-box; }
    button { width: 100%; padding: 12px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
    button:hover { background: #0056b3; }
    .info { background: #e7f3ff; padding: 10px; border-radius: 4px; margin-bottom: 20px; }
  </style>
</head>
<body>
  <div class="info">
    <strong>Application requesting access:</strong><br>
    Client ID: ${client_id}<br>
    Scopes: ${scope || "none"}<br>
    Redirect: ${redirect_uri}
  </div>
  <form method="POST" action="/oauth/authorize">
    <input type="hidden" name="response_type" value="${response_type}">
    <input type="hidden" name="client_id" value="${client_id}">
    <input type="hidden" name="redirect_uri" value="${redirect_uri}">
    <input type="hidden" name="scope" value="${scope || ""}">
    <input type="hidden" name="state" value="${state || ""}">
    <input type="hidden" name="code_challenge" value="${code_challenge || ""}">
    <input type="hidden" name="code_challenge_method" value="${code_challenge_method}">

    <input type="email" name="username" placeholder="Email" required>
    <input type="password" name="password" placeholder="Password" required>
    <button type="submit">Authorize</button>
  </form>
</body>
</html>`;
      return res.status(200).header("Content-Type", "text/html").send(html);
    } catch (error) {
      console.error("[OAuth2Server] Authorization error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Authorization endpoint handler (POST /oauth/authorize)
   * Processes user authentication and generates authorization code
   */
  async authorizePostHandler(req, res) {
    try {
      const {
        response_type,
        client_id,
        redirect_uri,
        scope,
        state,
        code_challenge,
        code_challenge_method = "plain",
        username,
        password
      } = req.body || {};
      const users = await this.userResource.query({ email: username });
      if (users.length === 0) {
        return res.status(401).json({
          error: "access_denied",
          error_description: "Invalid credentials"
        });
      }
      const user = users[0];
      const [okVerify, errVerify, isValid] = await tryFn(
        () => verifyPassword(password, user.password)
      );
      if (!okVerify) {
        console.error("[OAuth2Server] Password verification error:", errVerify);
        return res.status(500).json({
          error: "server_error",
          error_description: "Authentication failed"
        });
      }
      if (!isValid) {
        return res.status(401).json({
          error: "access_denied",
          error_description: "Invalid credentials"
        });
      }
      const code = generateAuthCode();
      const expiresAt = new Date(Date.now() + this.parseExpiryToSeconds(this.authCodeExpiry) * 1e3).toISOString();
      if (this.authCodeResource) {
        await this.authCodeResource.insert({
          code,
          clientId: client_id,
          userId: user.id,
          redirectUri: redirect_uri,
          scope: scope || "",
          expiresAt,
          used: false,
          codeChallenge: code_challenge || null,
          codeChallengeMethod: code_challenge_method
        });
      }
      const url = new URL(redirect_uri);
      url.searchParams.set("code", code);
      if (state) {
        url.searchParams.set("state", state);
      }
      return res.redirect(url.toString());
    } catch (error) {
      console.error("[OAuth2Server] Authorization POST error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Client Registration endpoint handler (POST /oauth/register)
   * Implements RFC 7591 - OAuth 2.0 Dynamic Client Registration
   *
   * Request body:
   * - redirect_uris: Array of redirect URIs (required)
   * - token_endpoint_auth_method: 'client_secret_basic' | 'client_secret_post'
   * - grant_types: Array of grant types (optional)
   * - response_types: Array of response types (optional)
   * - client_name: Human-readable name (optional)
   * - client_uri: URL of client homepage (optional)
   * - logo_uri: URL of client logo (optional)
   * - scope: Space-separated scopes (optional)
   * - contacts: Array of contact emails (optional)
   * - tos_uri: Terms of service URL (optional)
   * - policy_uri: Privacy policy URL (optional)
   */
  async registerClientHandler(req, res) {
    try {
      const {
        redirect_uris,
        token_endpoint_auth_method = "client_secret_basic",
        grant_types,
        response_types,
        client_name,
        client_uri,
        logo_uri,
        scope,
        contacts,
        tos_uri,
        policy_uri
      } = req.body || {};
      if (!redirect_uris || !Array.isArray(redirect_uris) || redirect_uris.length === 0) {
        return res.status(400).json({
          error: "invalid_redirect_uri",
          error_description: "redirect_uris is required and must be a non-empty array"
        });
      }
      for (const uri of redirect_uris) {
        try {
          new URL(uri);
        } catch {
          return res.status(400).json({
            error: "invalid_redirect_uri",
            error_description: `Invalid redirect URI: ${uri}`
          });
        }
      }
      const clientId = generateClientId();
      const clientSecret = generateClientSecret();
      const clientData = {
        clientId,
        clientSecret,
        name: client_name || `Client ${clientId}`,
        redirectUris: redirect_uris,
        allowedScopes: scope ? scope.split(" ") : this.supportedScopes,
        grantTypes: grant_types || ["authorization_code", "refresh_token"],
        responseTypes: response_types || ["code"],
        tokenEndpointAuthMethod: token_endpoint_auth_method,
        active: true
      };
      if (client_uri) clientData.clientUri = client_uri;
      if (logo_uri) clientData.logoUri = logo_uri;
      if (contacts) clientData.contacts = contacts;
      if (tos_uri) clientData.tosUri = tos_uri;
      if (policy_uri) clientData.policyUri = policy_uri;
      if (!this.clientResource) {
        return res.status(500).json({
          error: "server_error",
          error_description: "Client registration not available"
        });
      }
      const client = await this.clientResource.insert(clientData);
      return res.status(201).json({
        client_id: clientId,
        client_secret: clientSecret,
        client_id_issued_at: Math.floor(Date.now() / 1e3),
        client_secret_expires_at: 0,
        // 0 = never expires
        redirect_uris,
        token_endpoint_auth_method,
        grant_types: clientData.grantTypes,
        response_types: clientData.responseTypes,
        client_name: clientData.name,
        client_uri,
        logo_uri,
        scope: clientData.allowedScopes.join(" "),
        contacts,
        tos_uri,
        policy_uri
      });
    } catch (error) {
      console.error("[OAuth2Server] Client registration error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token Revocation endpoint handler (POST /oauth/revoke)
   * Implements RFC 7009 - OAuth 2.0 Token Revocation
   *
   * Request body:
   * - token: Token to revoke (required)
   * - token_type_hint: 'access_token' | 'refresh_token' (optional)
   */
  async revokeHandler(req, res) {
    try {
      const { token, token_type_hint } = req.body || {};
      if (!token) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "token is required"
        });
      }
      const { publicKey, privateKey, kid } = await this.keyManager.getCurrentKey();
      const { verifyRS256Token } = await Promise.resolve().then(function () { return rsaKeys; });
      const [valid, payload] = verifyRS256Token(token, publicKey);
      if (!valid) {
        return res.status(200).send();
      }
      return res.status(200).send();
    } catch (error) {
      console.error("[OAuth2Server] Token revocation error:", error);
      return res.status(200).send();
    }
  }
  /**
   * Rotate signing keys
   */
  async rotateKeys() {
    return await this.keyManager.rotateKey();
  }
  /**
   * Normalize authorization code expiry representation
   * @param {string|number} value
   * @returns {number} Expiry timestamp in milliseconds or NaN
   */
  parseAuthCodeExpiry(value) {
    if (typeof value === "number") {
      return value > 1e12 ? value : value * 1e3;
    }
    if (typeof value === "string") {
      const parsed = Date.parse(value);
      return Number.isNaN(parsed) ? NaN : parsed;
    }
    return NaN;
  }
}

class RateLimiter {
  /**
   * @param {Object} options
   * @param {number} options.windowMs - Window size in milliseconds
   * @param {number} options.max - Maximum number of hits allowed per window
   */
  constructor(options = {}) {
    this.windowMs = options.windowMs ?? 6e4;
    this.max = options.max ?? 10;
    this.buckets = /* @__PURE__ */ new Map();
  }
  /**
   * Consume a token for the given key
   * @param {string} key - Identifier (usually IP address)
   * @returns {{allowed: boolean, remaining: number, retryAfter: number}}
   */
  consume(key) {
    if (!this.enabled()) {
      return { allowed: true, remaining: Infinity, retryAfter: 0 };
    }
    const now = Date.now();
    const bucket = this.buckets.get(key);
    if (!bucket || bucket.expiresAt <= now) {
      const expiresAt = now + this.windowMs;
      this.buckets.set(key, { count: 1, expiresAt });
      this._prune(now);
      return {
        allowed: true,
        remaining: Math.max(this.max - 1, 0),
        retryAfter: 0
      };
    }
    if (bucket.count < this.max) {
      bucket.count += 1;
      this._prune(now);
      return {
        allowed: true,
        remaining: Math.max(this.max - bucket.count, 0),
        retryAfter: 0
      };
    }
    const retryAfterMs = bucket.expiresAt - now;
    return {
      allowed: false,
      remaining: 0,
      retryAfter: Math.max(Math.ceil(retryAfterMs / 1e3), 1)
    };
  }
  /**
   * Whether the limiter is active
   * @returns {boolean}
   */
  enabled() {
    return this.max > 0 && this.windowMs > 0;
  }
  /**
   * Periodically remove expired buckets
   * @private
   */
  _prune(now) {
    if (this.buckets.size > 5e3) {
      for (const [key, bucket] of this.buckets.entries()) {
        if (bucket.expiresAt <= now) {
          this.buckets.delete(key);
        }
      }
    }
  }
}
function createJsonRateLimitMiddleware(limiter, getKey) {
  return async (c, next) => {
    const key = getKey(c);
    const result = limiter.consume(key);
    if (result.allowed) {
      return await next();
    }
    c.header("Retry-After", String(result.retryAfter));
    return c.json({
      error: "too_many_requests",
      error_description: `Too many requests. Try again in ${result.retryAfter} seconds.`
    }, 429);
  };
}
function createRedirectRateLimitMiddleware(limiter, getKey, buildRedirectUrl) {
  return async (c, next) => {
    const key = getKey(c);
    const result = limiter.consume(key);
    if (result.allowed) {
      return await next();
    }
    const url = buildRedirectUrl(result.retryAfter);
    return c.redirect(url, 302);
  };
}

const BASE_USER_ATTRIBUTES$1 = {
  // Authentication
  email: "string|required|email",
  password: "password|required",
  emailVerified: "boolean|default:false",
  // Profile
  name: "string|optional",
  givenName: "string|optional",
  familyName: "string|optional",
  nickname: "string|optional",
  picture: "string|optional",
  locale: "string|optional",
  // Authorization
  scopes: "array|items:string|optional",
  roles: "array|items:string|optional",
  // Multi-tenancy
  tenantId: "string|optional",
  // Tenant the user belongs to
  // Status
  active: "boolean|default:true",
  // Account Lockout (Brute Force Protection)
  failedLoginAttempts: "number|default:0",
  // Count of failed login attempts
  lockedUntil: "string|optional",
  // ISO timestamp when account unlocks
  lastFailedLogin: "string|optional",
  // ISO timestamp of last failed attempt
  // Metadata
  metadata: "object|optional"
};
const BASE_TENANT_ATTRIBUTES$1 = {
  // Identity
  name: "string|required",
  slug: "string|required",
  // URL-friendly identifier
  // Settings
  settings: "object|optional",
  // Status
  active: "boolean|default:true",
  // Metadata
  metadata: "object|optional"
};
const BASE_CLIENT_ATTRIBUTES$1 = {
  // OAuth2 Identity
  clientId: "string|required",
  clientSecret: "secret|required",
  // Client Info
  name: "string|required",
  description: "string|optional",
  // OAuth2 Configuration
  redirectUris: "array|items:string|required",
  allowedScopes: "array|items:string|optional",
  grantTypes: 'array|items:string|default:["authorization_code","refresh_token"]',
  responseTypes: "array|items:string|optional",
  // Multi-tenancy
  tenantId: "string|optional",
  // Tenant the client belongs to
  // Security
  tokenEndpointAuthMethod: "string|default:client_secret_post",
  requirePkce: "boolean|default:false",
  // Status
  active: "boolean|default:true",
  // Metadata
  metadata: "object|optional"
};
function deepMerge(target, source) {
  const output = { ...target };
  for (const key in source) {
    if (source[key] && typeof source[key] === "object" && !Array.isArray(source[key])) {
      if (target[key] && typeof target[key] === "object" && !Array.isArray(target[key])) {
        output[key] = deepMerge(target[key], source[key]);
      } else {
        output[key] = source[key];
      }
    } else {
      output[key] = source[key];
    }
  }
  return output;
}
function validateExtraAttributes(baseAttributes, userAttributes, resourceType) {
  const errors = [];
  if (!userAttributes || typeof userAttributes !== "object") {
    return { valid: true, errors: [] };
  }
  for (const fieldName of Object.keys(userAttributes)) {
    if (baseAttributes[fieldName]) {
      errors.push(
        `Cannot override base attribute '${fieldName}' in ${resourceType} resource. Base attributes are managed by IdentityPlugin.`
      );
    }
  }
  for (const [fieldName, fieldSchema] of Object.entries(userAttributes)) {
    const isOptional = typeof fieldSchema === "string" && fieldSchema.includes("optional");
    const hasDefault = typeof fieldSchema === "string" && fieldSchema.includes("default:");
    if (isOptional && !hasDefault) {
      errors.push(
        `Extra attribute '${fieldName}' in ${resourceType} resource is optional but has no default value. Add "|default:value" to the schema or make it required.`
      );
    }
  }
  return {
    valid: errors.length === 0,
    errors
  };
}
function mergeResourceConfig$1(baseConfig, userConfig = {}, resourceType) {
  if (userConfig.attributes) {
    const validation = validateExtraAttributes(
      baseConfig.attributes,
      userConfig.attributes,
      resourceType
    );
    if (!validation.valid) {
      const errorMsg = [
        `Invalid extra attributes for ${resourceType} resource:`,
        ...validation.errors.map((err) => `  - ${err}`)
      ].join("\n");
      throw new Error(errorMsg);
    }
  }
  const merged = deepMerge(userConfig, baseConfig);
  if (userConfig.attributes || baseConfig.attributes) {
    merged.attributes = {
      ...userConfig.attributes || {},
      // User extras first
      ...baseConfig.attributes || {}
      // Base overrides (protection)
    };
  }
  return merged;
}
function validateResourcesConfig$1(resourcesConfig) {
  const errors = [];
  if (!resourcesConfig || typeof resourcesConfig !== "object") {
    errors.push('IdentityPlugin requires "resources" configuration object');
    return { valid: false, errors };
  }
  if (!resourcesConfig.users) {
    errors.push(
      'IdentityPlugin requires "resources.users" configuration.\nExample: resources: { users: { name: "users", attributes: {...}, hooks: {...} } }'
    );
  } else {
    if (!resourcesConfig.users.name || typeof resourcesConfig.users.name !== "string") {
      errors.push("resources.users.name is required and must be a string");
    }
  }
  if (!resourcesConfig.tenants) {
    errors.push(
      'IdentityPlugin requires "resources.tenants" configuration.\nExample: resources: { tenants: { name: "tenants", attributes: {...}, partitions: {...} } }'
    );
  } else {
    if (!resourcesConfig.tenants.name || typeof resourcesConfig.tenants.name !== "string") {
      errors.push("resources.tenants.name is required and must be a string");
    }
  }
  if (!resourcesConfig.clients) {
    errors.push(
      'IdentityPlugin requires "resources.clients" configuration.\nExample: resources: { clients: { name: "oauth_clients", attributes: {...}, behavior: "..." } }'
    );
  } else {
    if (!resourcesConfig.clients.name || typeof resourcesConfig.clients.name !== "string") {
      errors.push("resources.clients.name is required and must be a string");
    }
  }
  return {
    valid: errors.length === 0,
    errors
  };
}

function prepareResourceConfigs(resourcesOptions = {}) {
  const resourcesValidation = validateResourcesConfig$1(resourcesOptions);
  if (!resourcesValidation.valid) {
    throw new Error(
      "IdentityPlugin configuration error:\n" + resourcesValidation.errors.join("\n")
    );
  }
  mergeResourceConfig$1(
    { attributes: BASE_USER_ATTRIBUTES$1 },
    resourcesOptions.users,
    "users"
  );
  mergeResourceConfig$1(
    { attributes: BASE_TENANT_ATTRIBUTES$1 },
    resourcesOptions.tenants,
    "tenants"
  );
  mergeResourceConfig$1(
    { attributes: BASE_CLIENT_ATTRIBUTES$1 },
    resourcesOptions.clients,
    "clients"
  );
  return {
    users: {
      userConfig: resourcesOptions.users,
      mergedConfig: null
    },
    tenants: {
      userConfig: resourcesOptions.tenants,
      mergedConfig: null
    },
    clients: {
      userConfig: resourcesOptions.clients,
      mergedConfig: null
    }
  };
}

class IdentityPlugin extends Plugin {
  /**
   * Create Identity Provider Plugin instance
   * @param {Object} options - Plugin configuration
   */
  constructor(options = {}) {
    super(options);
    this._internalResourceOverrides = options.resourceNames || options.internalResources || {};
    this._internalResourceDescriptors = {
      oauthKeys: {
        defaultName: "plg_identity_oauth_keys",
        override: this._internalResourceOverrides.oauthKeys
      },
      authCodes: {
        defaultName: "plg_identity_auth_codes",
        override: this._internalResourceOverrides.authCodes
      },
      sessions: {
        defaultName: "plg_identity_sessions",
        override: this._internalResourceOverrides.sessions
      },
      passwordResetTokens: {
        defaultName: "plg_identity_password_reset_tokens",
        override: this._internalResourceOverrides.passwordResetTokens
      },
      mfaDevices: {
        defaultName: "plg_identity_mfa_devices",
        override: this._internalResourceOverrides.mfaDevices
      }
    };
    this.internalResourceNames = this._resolveInternalResourceNames();
    const normalizedResources = prepareResourceConfigs(options.resources);
    this.config = {
      // Server configuration
      port: options.port || 4e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      // OAuth2/OIDC configuration
      issuer: options.issuer || `http://localhost:${options.port || 4e3}`,
      supportedScopes: options.supportedScopes || ["openid", "profile", "email", "offline_access"],
      supportedGrantTypes: options.supportedGrantTypes || ["authorization_code", "client_credentials", "refresh_token"],
      supportedResponseTypes: options.supportedResponseTypes || ["code", "token", "id_token"],
      // Token expiration
      accessTokenExpiry: options.accessTokenExpiry || "15m",
      idTokenExpiry: options.idTokenExpiry || "15m",
      refreshTokenExpiry: options.refreshTokenExpiry || "7d",
      authCodeExpiry: options.authCodeExpiry || "10m",
      // Resource configuration (REQUIRED)
      resources: normalizedResources,
      resourceNames: this.internalResourceNames,
      // CORS configuration
      cors: {
        enabled: options.cors?.enabled !== false,
        // Enabled by default for identity servers
        origin: options.cors?.origin || "*",
        methods: options.cors?.methods || ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
        allowedHeaders: options.cors?.allowedHeaders || ["Content-Type", "Authorization", "X-API-Key"],
        credentials: options.cors?.credentials !== false,
        maxAge: options.cors?.maxAge || 86400
      },
      // Security headers
      security: {
        enabled: options.security?.enabled !== false,
        contentSecurityPolicy: {
          enabled: true,
          directives: {
            "default-src": ["'self'"],
            "script-src": ["'self'", "'unsafe-inline'"],
            "style-src": ["'self'", "'unsafe-inline'", "https://unpkg.com"],
            "img-src": ["'self'", "data:", "https:"],
            "font-src": ["'self'", "https://unpkg.com"],
            ...options.security?.contentSecurityPolicy?.directives
          },
          reportOnly: options.security?.contentSecurityPolicy?.reportOnly || false,
          reportUri: options.security?.contentSecurityPolicy?.reportUri || null
        }
      },
      // Logging
      logging: {
        enabled: options.logging?.enabled || false,
        format: options.logging?.format || ":method :path :status :response-time ms"
      },
      // Session Management
      session: {
        sessionExpiry: options.session?.sessionExpiry || "24h",
        cookieName: options.session?.cookieName || "s3db_session",
        cookiePath: options.session?.cookiePath || "/",
        cookieHttpOnly: options.session?.cookieHttpOnly !== false,
        cookieSecure: options.session?.cookieSecure || false,
        // Set true in production with HTTPS
        cookieSameSite: options.session?.cookieSameSite || "Lax",
        cleanupInterval: options.session?.cleanupInterval || 36e5,
        // 1 hour
        enableCleanup: options.session?.enableCleanup !== false
      },
      // Password Policy
      passwordPolicy: {
        minLength: options.passwordPolicy?.minLength || 8,
        maxLength: options.passwordPolicy?.maxLength || 128,
        requireUppercase: options.passwordPolicy?.requireUppercase !== false,
        requireLowercase: options.passwordPolicy?.requireLowercase !== false,
        requireNumbers: options.passwordPolicy?.requireNumbers !== false,
        requireSymbols: options.passwordPolicy?.requireSymbols || false,
        bcryptRounds: options.passwordPolicy?.bcryptRounds || 10
      },
      // Registration Configuration
      registration: {
        enabled: options.registration?.enabled !== false,
        // Enabled by default
        requireEmailVerification: options.registration?.requireEmailVerification !== false,
        // Required by default
        allowedDomains: options.registration?.allowedDomains || null,
        // null = allow all domains
        blockedDomains: options.registration?.blockedDomains || [],
        // Block specific domains
        customMessage: options.registration?.customMessage || null
        // Custom message when disabled
      },
      // UI Configuration (white-label customization)
      ui: {
        // Branding
        title: options.ui?.title || "S3DB Identity",
        companyName: options.ui?.companyName || "S3DB",
        legalName: options.ui?.legalName || options.ui?.companyName || "S3DB Corp",
        tagline: options.ui?.tagline || "Secure Identity & Access Management",
        welcomeMessage: options.ui?.welcomeMessage || "Welcome back!",
        logoUrl: options.ui?.logoUrl || null,
        logo: options.ui?.logo || null,
        // Deprecated, use logoUrl
        favicon: options.ui?.favicon || null,
        // Colors (11 options)
        primaryColor: options.ui?.primaryColor || "#007bff",
        secondaryColor: options.ui?.secondaryColor || "#6c757d",
        successColor: options.ui?.successColor || "#28a745",
        dangerColor: options.ui?.dangerColor || "#dc3545",
        warningColor: options.ui?.warningColor || "#ffc107",
        infoColor: options.ui?.infoColor || "#17a2b8",
        textColor: options.ui?.textColor || "#212529",
        textMuted: options.ui?.textMuted || "#6c757d",
        backgroundColor: options.ui?.backgroundColor || "#ffffff",
        backgroundLight: options.ui?.backgroundLight || "#f8f9fa",
        borderColor: options.ui?.borderColor || "#dee2e6",
        // Typography
        fontFamily: options.ui?.fontFamily || '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif',
        fontSize: options.ui?.fontSize || "16px",
        // Layout
        borderRadius: options.ui?.borderRadius || "0.375rem",
        boxShadow: options.ui?.boxShadow || "0 0.125rem 0.25rem rgba(0, 0, 0, 0.075)",
        // Company Info
        footerText: options.ui?.footerText || null,
        supportEmail: options.ui?.supportEmail || null,
        privacyUrl: options.ui?.privacyUrl || "/privacy",
        termsUrl: options.ui?.termsUrl || "/terms",
        // Social Links
        socialLinks: options.ui?.socialLinks || null,
        // Custom CSS
        customCSS: options.ui?.customCSS || null,
        // Custom Pages (override default pages)
        customPages: options.ui?.customPages || {},
        // Base URL
        baseUrl: options.ui?.baseUrl || `http://localhost:${options.port || 4e3}`
      },
      // Email Configuration (SMTP)
      email: {
        enabled: options.email?.enabled !== false,
        from: options.email?.from || "noreply@s3db.identity",
        replyTo: options.email?.replyTo || null,
        smtp: {
          host: options.email?.smtp?.host || "localhost",
          port: options.email?.smtp?.port || 587,
          secure: options.email?.smtp?.secure || false,
          auth: {
            user: options.email?.smtp?.auth?.user || "",
            pass: options.email?.smtp?.auth?.pass || ""
          },
          tls: {
            rejectUnauthorized: options.email?.smtp?.tls?.rejectUnauthorized !== false
          }
        },
        templates: {
          baseUrl: options.email?.templates?.baseUrl || options.ui?.baseUrl || `http://localhost:${options.port || 4e3}`,
          brandName: options.email?.templates?.brandName || options.ui?.title || "S3DB Identity",
          brandLogo: options.email?.templates?.brandLogo || options.ui?.logo || null,
          brandColor: options.email?.templates?.brandColor || options.ui?.primaryColor || "#007bff",
          supportEmail: options.email?.templates?.supportEmail || options.email?.replyTo || null,
          customFooter: options.email?.templates?.customFooter || null
        }
      },
      // MFA Configuration (Multi-Factor Authentication)
      mfa: {
        enabled: options.mfa?.enabled || false,
        // Enable MFA/TOTP
        required: options.mfa?.required || false,
        // Require MFA for all users
        issuer: options.mfa?.issuer || options.ui?.title || "S3DB Identity",
        // TOTP issuer name
        algorithm: options.mfa?.algorithm || "SHA1",
        // SHA1, SHA256, SHA512
        digits: options.mfa?.digits || 6,
        // 6 or 8 digits
        period: options.mfa?.period || 30,
        // 30 seconds
        window: options.mfa?.window || 1,
        // Time window tolerance
        backupCodesCount: options.mfa?.backupCodesCount || 10,
        // Number of backup codes
        backupCodeLength: options.mfa?.backupCodeLength || 8
        // Backup code length
      },
      // Audit Configuration (Compliance & Security Logging)
      audit: {
        enabled: options.audit?.enabled !== false,
        // Enable audit logging
        includeData: options.audit?.includeData !== false,
        // Store before/after data
        includePartitions: options.audit?.includePartitions !== false,
        // Track partition info
        maxDataSize: options.audit?.maxDataSize || 1e4,
        // Max bytes for data field
        resources: options.audit?.resources || ["users", "plg_oauth_clients"],
        // Resources to audit
        events: options.audit?.events || [
          // Custom events to audit
          "login",
          "logout",
          "login_failed",
          "account_locked",
          "account_unlocked",
          "ip_banned",
          "ip_unbanned",
          "password_reset_requested",
          "password_changed",
          "email_verified",
          "user_created",
          "user_deleted",
          "mfa_enrolled",
          "mfa_disabled",
          "mfa_verified",
          "mfa_failed"
        ]
      },
      // Account Lockout Configuration (Per-User Brute Force Protection)
      accountLockout: {
        enabled: options.accountLockout?.enabled !== false,
        // Enable account lockout
        maxAttempts: options.accountLockout?.maxAttempts || 5,
        // Max failed attempts before lockout
        lockoutDuration: options.accountLockout?.lockoutDuration || 9e5,
        // Lockout duration (15 min)
        resetOnSuccess: options.accountLockout?.resetOnSuccess !== false
        // Reset counter on successful login
      },
      // Failban Configuration (IP-Based Brute Force Protection)
      failban: {
        enabled: options.failban?.enabled !== false,
        // Enable failban protection
        maxViolations: options.failban?.maxViolations || 5,
        // Max failed attempts before ban
        violationWindow: options.failban?.violationWindow || 3e5,
        // Time window for violations (5 min)
        banDuration: options.failban?.banDuration || 9e5,
        // Ban duration (15 min)
        whitelist: options.failban?.whitelist || ["127.0.0.1", "::1"],
        // IPs to never ban
        blacklist: options.failban?.blacklist || [],
        // IPs to always ban
        persistViolations: options.failban?.persistViolations !== false,
        // Persist violations to DB
        endpoints: {
          login: options.failban?.endpoints?.login !== false,
          // Protect /oauth/authorize POST
          token: options.failban?.endpoints?.token !== false,
          // Protect /oauth/token
          register: options.failban?.endpoints?.register !== false
          // Protect /register
        },
        geo: {
          enabled: options.failban?.geo?.enabled || false,
          // Enable GeoIP blocking
          databasePath: options.failban?.geo?.databasePath || null,
          // Path to GeoLite2-Country.mmdb
          allowedCountries: options.failban?.geo?.allowedCountries || [],
          // Whitelist countries (ISO codes)
          blockedCountries: options.failban?.geo?.blockedCountries || [],
          // Blacklist countries (ISO codes)
          blockUnknown: options.failban?.geo?.blockUnknown || false
          // Block IPs with unknown country
        }
      },
      // Rate Limiting Configuration
      rateLimit: {
        enabled: options.rateLimit?.enabled !== false,
        login: {
          windowMs: options.rateLimit?.login?.windowMs || 6e4,
          max: options.rateLimit?.login?.max ?? 10
        },
        token: {
          windowMs: options.rateLimit?.token?.windowMs || 6e4,
          max: options.rateLimit?.token?.max ?? 60
        },
        authorize: {
          windowMs: options.rateLimit?.authorize?.windowMs || 6e4,
          max: options.rateLimit?.authorize?.max ?? 30
        }
      },
      // Features (MVP - Phase 1)
      features: {
        // Endpoints (can be disabled individually)
        discovery: options.features?.discovery !== false,
        // GET /.well-known/openid-configuration
        jwks: options.features?.jwks !== false,
        // GET /.well-known/jwks.json
        token: options.features?.token !== false,
        // POST /oauth/token
        authorize: options.features?.authorize !== false,
        // GET/POST /oauth/authorize
        userinfo: options.features?.userinfo !== false,
        // GET /oauth/userinfo
        introspection: options.features?.introspection !== false,
        // POST /oauth/introspect
        revocation: options.features?.revocation !== false,
        // POST /oauth/revoke
        registration: options.features?.registration !== false,
        // POST /oauth/register (RFC 7591)
        // Authorization Code Flow UI
        builtInLoginUI: options.features?.builtInLoginUI !== false,
        // HTML login form
        customLoginHandler: options.features?.customLoginHandler || null,
        // Custom UI handler
        // PKCE (Proof Key for Code Exchange - RFC 7636)
        pkce: {
          enabled: options.features?.pkce?.enabled !== false,
          // PKCE support
          required: options.features?.pkce?.required || false,
          // Force PKCE for public clients
          methods: options.features?.pkce?.methods || ["S256", "plain"]
          // Supported methods
        },
        // Refresh tokens
        refreshTokens: options.features?.refreshTokens !== false,
        // Enable refresh tokens
        refreshTokenRotation: options.features?.refreshTokenRotation || false,
        // Rotate on each use
        revokeOldRefreshTokens: options.features?.revokeOldRefreshTokens !== false
        // Revoke old tokens after rotation
        // Future features (Phase 2 - commented for reference)
        // admin: { enabled: false, apiKey: null, endpoints: {...} },
        // consent: { enabled: false, skipForTrustedClients: true },
        // mfa: { enabled: false, methods: ['totp', 'sms', 'email'] },
        // emailVerification: { enabled: false, required: false },
        // passwordPolicy: { enabled: false, minLength: 8, ... },
        // webhooks: { enabled: false, endpoints: [], events: [] }
      }
    };
    this.server = null;
    this.oauth2Server = null;
    this.sessionManager = null;
    this.emailService = null;
    this.failbanManager = null;
    this.auditPlugin = null;
    this.mfaManager = null;
    this.oauth2KeysResource = null;
    this.oauth2AuthCodesResource = null;
    this.sessionsResource = null;
    this.passwordResetTokensResource = null;
    this.mfaDevicesResource = null;
    this.usersResource = null;
    this.tenantsResource = null;
    this.clientsResource = null;
    this.rateLimiters = this._createRateLimiters();
  }
  _resolveInternalResourceNames() {
    return resolveResourceNames("identity", this._internalResourceDescriptors, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.internalResourceNames = this._resolveInternalResourceNames();
    if (this.config) {
      this.config.resourceNames = this.internalResourceNames;
    }
  }
  /**
   * Validate plugin dependencies
   * @private
   */
  async _validateDependencies() {
    await requirePluginDependency("identity-plugin", {
      throwOnError: true,
      checkVersions: true
    });
  }
  /**
   * Initialize rate limiters for sensitive endpoints
   * @private
   * @returns {Object<string, RateLimiter>}
   */
  _createRateLimiters() {
    if (!this.config.rateLimit.enabled) {
      return {};
    }
    const limiters = {};
    const { login, token, authorize } = this.config.rateLimit;
    if (login?.max > 0 && login?.windowMs > 0) {
      limiters.login = new RateLimiter(login);
    }
    if (token?.max > 0 && token?.windowMs > 0) {
      limiters.token = new RateLimiter(token);
    }
    if (authorize?.max > 0 && authorize?.windowMs > 0) {
      limiters.authorize = new RateLimiter(authorize);
    }
    return limiters;
  }
  /**
   * Install plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Installing...");
    }
    try {
      await this._validateDependencies();
    } catch (err) {
      console.error("[Identity Plugin] Dependency validation failed:", err.message);
      throw err;
    }
    await this._createUserManagedResources();
    await this._createOAuth2Resources();
    await this._initializeOAuth2Server();
    await this._initializeSessionManager();
    await this._initializeEmailService();
    await this._initializeFailbanManager();
    await this._initializeAuditPlugin();
    await this._initializeMFAManager();
    if (this.config.verbose) {
      console.log("[Identity Plugin] Installed successfully");
    }
  }
  /**
   * Create OAuth2 resources for authorization server
   * @private
   */
  async _createOAuth2Resources() {
    const names = this.internalResourceNames;
    const [okKeys, errKeys, keysResource] = await tryFn(
      () => this.database.createResource({
        name: names.oauthKeys,
        attributes: {
          kid: "string|required",
          publicKey: "string|required",
          privateKey: "secret|required",
          algorithm: "string|default:RS256",
          use: "string|default:sig",
          active: "boolean|default:true",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okKeys) {
      this.oauth2KeysResource = keysResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${names.oauthKeys} resource`);
      }
    } else if (this.database.resources[names.oauthKeys]) {
      this.oauth2KeysResource = this.database.resources[names.oauthKeys];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${names.oauthKeys} resource`);
      }
    } else {
      throw errKeys;
    }
    const [okCodes, errCodes, codesResource] = await tryFn(
      () => this.database.createResource({
        name: names.authCodes,
        attributes: {
          code: "string|required",
          clientId: "string|required",
          userId: "string|required",
          redirectUri: "string|required",
          scope: "string|optional",
          expiresAt: "string|required",
          used: "boolean|default:false",
          codeChallenge: "string|optional",
          // PKCE support
          codeChallengeMethod: "string|optional",
          // PKCE support
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okCodes) {
      this.oauth2AuthCodesResource = codesResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${names.authCodes} resource`);
      }
    } else if (this.database.resources[names.authCodes]) {
      this.oauth2AuthCodesResource = this.database.resources[names.authCodes];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${names.authCodes} resource`);
      }
    } else {
      throw errCodes;
    }
    const [okSessions, errSessions, sessionsResource] = await tryFn(
      () => this.database.createResource({
        name: names.sessions,
        attributes: {
          userId: "string|required",
          expiresAt: "string|required",
          ipAddress: "ip4|optional",
          userAgent: "string|optional",
          metadata: "object|optional",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okSessions) {
      this.sessionsResource = sessionsResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${names.sessions} resource`);
      }
    } else if (this.database.resources[names.sessions]) {
      this.sessionsResource = this.database.resources[names.sessions];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${names.sessions} resource`);
      }
    } else {
      throw errSessions;
    }
    const [okResetTokens, errResetTokens, resetTokensResource] = await tryFn(
      () => this.database.createResource({
        name: names.passwordResetTokens,
        attributes: {
          userId: "string|required",
          token: "string|required",
          expiresAt: "string|required",
          used: "boolean|default:false",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okResetTokens) {
      this.passwordResetTokensResource = resetTokensResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${names.passwordResetTokens} resource`);
      }
    } else if (this.database.resources[names.passwordResetTokens]) {
      this.passwordResetTokensResource = this.database.resources[names.passwordResetTokens];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${names.passwordResetTokens} resource`);
      }
    } else {
      throw errResetTokens;
    }
    if (this.config.mfa.enabled) {
      const [okMFA, errMFA, mfaResource] = await tryFn(
        () => this.database.createResource({
          name: names.mfaDevices,
          attributes: {
            userId: "string|required",
            type: "string|required",
            // 'totp', 'sms', 'email'
            secret: "secret|required",
            // TOTP secret (encrypted by S3DB)
            verified: "boolean|default:false",
            backupCodes: "array|items:string",
            // Hashed backup codes
            enrolledAt: "string",
            lastUsedAt: "string|optional",
            deviceName: "string|optional",
            // User-friendly name
            metadata: "object|optional"
          },
          behavior: "body-overflow",
          timestamps: true,
          partitions: {
            byUser: {
              fields: { userId: "string" }
            }
          },
          createdBy: "IdentityPlugin"
        })
      );
      if (okMFA) {
        this.mfaDevicesResource = mfaResource;
        if (this.config.verbose) {
          console.log(`[Identity Plugin] Created ${names.mfaDevices} resource`);
        }
      } else if (this.database.resources[names.mfaDevices]) {
        this.mfaDevicesResource = this.database.resources[names.mfaDevices];
        if (this.config.verbose) {
          console.log(`[Identity Plugin] Using existing ${names.mfaDevices} resource`);
        }
      } else {
        console.warn(`[Identity Plugin] MFA enabled but failed to create ${names.mfaDevices} resource:`, errMFA?.message);
      }
    }
  }
  /**
   * Create user-managed resources (users, tenants, clients) with merged config
   * @private
   */
  async _createUserManagedResources() {
    const usersConfig = this.config.resources.users;
    const usersBaseConfig = {
      attributes: BASE_USER_ATTRIBUTES,
      behavior: "body-overflow",
      timestamps: true
    };
    const usersMergedConfig = mergeResourceConfig(
      usersBaseConfig,
      usersConfig.userConfig,
      "users"
    );
    usersConfig.mergedConfig = usersMergedConfig;
    const [okUsers, errUsers, usersResource] = await tryFn(
      () => this.database.createResource(usersMergedConfig)
    );
    if (okUsers) {
      this.usersResource = usersResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${usersMergedConfig.name} resource with merged config`);
      }
    } else if (this.database.resources[usersMergedConfig.name]) {
      this.usersResource = this.database.resources[usersMergedConfig.name];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${usersMergedConfig.name} resource`);
      }
    } else {
      throw errUsers;
    }
    const tenantsConfig = this.config.resources.tenants;
    const tenantsBaseConfig = {
      attributes: BASE_TENANT_ATTRIBUTES,
      behavior: "body-overflow",
      timestamps: true
    };
    const tenantsMergedConfig = mergeResourceConfig(
      tenantsBaseConfig,
      tenantsConfig.userConfig,
      "tenants"
    );
    tenantsConfig.mergedConfig = tenantsMergedConfig;
    const [okTenants, errTenants, tenantsResource] = await tryFn(
      () => this.database.createResource(tenantsMergedConfig)
    );
    if (okTenants) {
      this.tenantsResource = tenantsResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${tenantsMergedConfig.name} resource with merged config`);
      }
    } else if (this.database.resources[tenantsMergedConfig.name]) {
      this.tenantsResource = this.database.resources[tenantsMergedConfig.name];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${tenantsMergedConfig.name} resource`);
      }
    } else {
      throw errTenants;
    }
    const clientsConfig = this.config.resources.clients;
    const clientsBaseConfig = {
      attributes: BASE_CLIENT_ATTRIBUTES,
      behavior: "body-overflow",
      timestamps: true
    };
    const clientsMergedConfig = mergeResourceConfig(
      clientsBaseConfig,
      clientsConfig.userConfig,
      "clients"
    );
    clientsConfig.mergedConfig = clientsMergedConfig;
    const [okClients, errClients, clientsResource] = await tryFn(
      () => this.database.createResource(clientsMergedConfig)
    );
    if (okClients) {
      this.clientsResource = clientsResource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${clientsMergedConfig.name} resource with merged config`);
      }
    } else if (this.database.resources[clientsMergedConfig.name]) {
      this.clientsResource = this.database.resources[clientsMergedConfig.name];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${clientsMergedConfig.name} resource`);
      }
    } else {
      throw errClients;
    }
  }
  /**
   * Initialize OAuth2 Server instance
   * @private
   */
  async _initializeOAuth2Server() {
    this.oauth2Server = new OAuth2Server({
      issuer: this.config.issuer,
      keyResource: this.oauth2KeysResource,
      userResource: this.usersResource,
      clientResource: this.clientsResource,
      authCodeResource: this.oauth2AuthCodesResource,
      supportedScopes: this.config.supportedScopes,
      supportedGrantTypes: this.config.supportedGrantTypes,
      supportedResponseTypes: this.config.supportedResponseTypes,
      accessTokenExpiry: this.config.accessTokenExpiry,
      idTokenExpiry: this.config.idTokenExpiry,
      refreshTokenExpiry: this.config.refreshTokenExpiry,
      authCodeExpiry: this.config.authCodeExpiry
    });
    await this.oauth2Server.initialize();
    if (this.config.verbose) {
      console.log("[Identity Plugin] OAuth2 Server initialized");
      console.log(`[Identity Plugin] Issuer: ${this.config.issuer}`);
      console.log(`[Identity Plugin] Supported scopes: ${this.config.supportedScopes.join(", ")}`);
      console.log(`[Identity Plugin] Supported grant types: ${this.config.supportedGrantTypes.join(", ")}`);
    }
  }
  /**
   * Initialize Session Manager
   * @private
   */
  async _initializeSessionManager() {
    const { SessionManager } = await Promise.resolve().then(function () { return sessionManager; });
    this.sessionManager = new SessionManager({
      sessionResource: this.sessionsResource,
      config: this.config.session
    });
    if (this.config.verbose) {
      console.log("[Identity Plugin] Session Manager initialized");
      console.log(`[Identity Plugin] Session expiry: ${this.config.session.sessionExpiry}`);
      console.log(`[Identity Plugin] Cookie name: ${this.config.session.cookieName}`);
    }
  }
  /**
   * Initialize email service
   * @private
   */
  async _initializeEmailService() {
    const { EmailService } = await Promise.resolve().then(function () { return emailService; });
    this.emailService = new EmailService({
      enabled: this.config.email.enabled,
      from: this.config.email.from,
      replyTo: this.config.email.replyTo,
      smtp: this.config.email.smtp,
      templates: this.config.email.templates,
      verbose: this.config.verbose
    });
    if (this.config.verbose) {
      console.log("[Identity Plugin] Email Service initialized");
      console.log(`[Identity Plugin] Email enabled: ${this.config.email.enabled}`);
      if (this.config.email.enabled) {
        console.log(`[Identity Plugin] SMTP host: ${this.config.email.smtp.host}:${this.config.email.smtp.port}`);
        console.log(`[Identity Plugin] From address: ${this.config.email.from}`);
      }
    }
  }
  /**
   * Initialize failban manager
   * @private
   */
  async _initializeFailbanManager() {
    if (!this.config.failban.enabled) {
      if (this.config.verbose) {
        console.log("[Identity Plugin] Failban disabled");
      }
      return;
    }
    const { FailbanManager } = await Promise.resolve().then(function () { return failbanManager; });
    this.failbanManager = new FailbanManager({
      database: this.database,
      enabled: this.config.failban.enabled,
      maxViolations: this.config.failban.maxViolations,
      violationWindow: this.config.failban.violationWindow,
      banDuration: this.config.failban.banDuration,
      whitelist: this.config.failban.whitelist,
      blacklist: this.config.failban.blacklist,
      persistViolations: this.config.failban.persistViolations,
      verbose: this.config.verbose,
      geo: this.config.failban.geo
    });
    await this.failbanManager.initialize();
    if (this.config.verbose) {
      console.log("[Identity Plugin] Failban Manager initialized");
      console.log(`[Identity Plugin] Max violations: ${this.config.failban.maxViolations}`);
      console.log(`[Identity Plugin] Violation window: ${this.config.failban.violationWindow}ms`);
      console.log(`[Identity Plugin] Ban duration: ${this.config.failban.banDuration}ms`);
      console.log(`[Identity Plugin] Protected endpoints: login=${this.config.failban.endpoints.login}, token=${this.config.failban.endpoints.token}, register=${this.config.failban.endpoints.register}`);
      if (this.config.failban.geo.enabled) {
        console.log(`[Identity Plugin] GeoIP enabled`);
        console.log(`[Identity Plugin] Allowed countries: ${this.config.failban.geo.allowedCountries.join(", ") || "all"}`);
        console.log(`[Identity Plugin] Blocked countries: ${this.config.failban.geo.blockedCountries.join(", ") || "none"}`);
      }
    }
  }
  /**
   * Initialize audit plugin
   * @private
   */
  async _initializeAuditPlugin() {
    if (!this.config.audit.enabled) {
      if (this.config.verbose) {
        console.log("[Identity Plugin] Audit logging disabled");
      }
      return;
    }
    const { AuditPlugin } = await Promise.resolve().then(function () { return audit_plugin; });
    this.auditPlugin = new AuditPlugin({
      includeData: this.config.audit.includeData,
      includePartitions: this.config.audit.includePartitions,
      maxDataSize: this.config.audit.maxDataSize,
      resources: this.config.audit.resources
    });
    await this.database.usePlugin(this.auditPlugin);
    if (this.config.verbose) {
      console.log("[Identity Plugin] Audit Plugin initialized");
      console.log(`[Identity Plugin] Auditing resources: ${this.config.audit.resources.join(", ")}`);
      console.log(`[Identity Plugin] Include data: ${this.config.audit.includeData}`);
      console.log(`[Identity Plugin] Max data size: ${this.config.audit.maxDataSize} bytes`);
    }
  }
  /**
   * Log custom audit event
   * @param {string} event - Event name
   * @param {Object} data - Event data
   * @private
   */
  async _logAuditEvent(event, data = {}) {
    if (!this.config.audit.enabled || !this.auditPlugin) {
      return;
    }
    if (!this.config.audit.events.includes(event)) {
      return;
    }
    try {
      await this.auditPlugin.logCustomEvent(event, data);
      if (this.config.verbose) {
        console.log(`[Audit] ${event}:`, JSON.stringify(data));
      }
    } catch (error) {
      console.error(`[Audit] Failed to log event ${event}:`, error.message);
    }
  }
  /**
   * Initialize MFA Manager (Multi-Factor Authentication)
   * @private
   */
  async _initializeMFAManager() {
    if (!this.config.mfa.enabled) {
      if (this.config.verbose) {
        console.log("[Identity Plugin] MFA disabled");
      }
      return;
    }
    const { MFAManager } = await Promise.resolve().then(function () { return mfaManager; });
    this.mfaManager = new MFAManager({
      issuer: this.config.mfa.issuer,
      algorithm: this.config.mfa.algorithm,
      digits: this.config.mfa.digits,
      period: this.config.mfa.period,
      window: this.config.mfa.window,
      backupCodesCount: this.config.mfa.backupCodesCount,
      backupCodeLength: this.config.mfa.backupCodeLength
    });
    await this.mfaManager.initialize();
    if (this.config.verbose) {
      console.log("[Identity Plugin] MFA Manager initialized");
      console.log(`[Identity Plugin] Issuer: ${this.config.mfa.issuer}`);
      console.log(`[Identity Plugin] Algorithm: ${this.config.mfa.algorithm}`);
      console.log(`[Identity Plugin] Digits: ${this.config.mfa.digits}`);
      console.log(`[Identity Plugin] Period: ${this.config.mfa.period}s`);
      console.log(`[Identity Plugin] Required: ${this.config.mfa.required}`);
    }
  }
  /**
   * Start plugin
   */
  async onStart() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Starting server...");
    }
    const { IdentityServer } = await Promise.resolve().then(function () { return server; });
    this.server = new IdentityServer({
      port: this.config.port,
      host: this.config.host,
      verbose: this.config.verbose,
      issuer: this.config.issuer,
      oauth2Server: this.oauth2Server,
      sessionManager: this.sessionManager,
      usersResource: this.usersResource,
      identityPlugin: this,
      failbanManager: this.failbanManager,
      failbanConfig: this.config.failban,
      accountLockoutConfig: this.config.accountLockout,
      cors: this.config.cors,
      security: this.config.security,
      logging: this.config.logging
    });
    await this.server.start();
    this.emit("plugin.started", {
      port: this.config.port,
      host: this.config.host,
      issuer: this.config.issuer
    });
  }
  /**
   * Stop plugin
   */
  async onStop() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Stopping server...");
    }
    if (this.server) {
      await this.server.stop();
      this.server = null;
    }
    if (this.sessionManager) {
      this.sessionManager.stopCleanup();
    }
    if (this.emailService) {
      await this.emailService.close();
    }
    if (this.failbanManager) {
      await this.failbanManager.cleanup();
    }
    this.emit("plugin.stopped");
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    const { purgeData = false } = options;
    await this.onStop();
    if (purgeData) {
      const resourcesToDelete = /* @__PURE__ */ new Set([
        this.internalResourceNames.oauthKeys,
        this.internalResourceNames.authCodes,
        this.internalResourceNames.sessions,
        this.internalResourceNames.passwordResetTokens,
        this.internalResourceNames.mfaDevices,
        "plg_oauth_clients"
      ]);
      for (const resourceName of resourcesToDelete) {
        const [ok] = await tryFn(() => this.database.deleteResource(resourceName));
        if (ok && this.config.verbose) {
          console.log(`[Identity Plugin] Deleted ${resourceName} resource`);
        }
      }
    }
    if (this.config.verbose) {
      console.log("[Identity Plugin] Uninstalled successfully");
    }
  }
  /**
   * Get server information
   * @returns {Object} Server info
   */
  getServerInfo() {
    return this.server ? this.server.getInfo() : { isRunning: false };
  }
  /**
   * Get OAuth2 Server instance (for advanced usage)
   * @returns {OAuth2Server|null}
   */
  getOAuth2Server() {
    return this.oauth2Server;
  }
}

class AuditPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    const resourceNames = options.resourceNames || {};
    this.auditResource = null;
    this._auditResourceDescriptor = {
      defaultName: "plg_audits",
      override: resourceNames.audit || options.resourceName
    };
    this.auditResourceName = this._resolveAuditResourceName();
    this.config = {
      includeData: options.includeData !== false,
      includePartitions: options.includePartitions !== false,
      maxDataSize: options.maxDataSize || 1e4,
      ...options
    };
  }
  _resolveAuditResourceName() {
    return resolveResourceName("audit", this._auditResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.auditResourceName = this._resolveAuditResourceName();
  }
  async onInstall() {
    const [ok, err, auditResource] = await tryFn(() => this.database.createResource({
      name: this.auditResourceName,
      attributes: {
        id: "string|required",
        resourceName: "string|required",
        operation: "string|required",
        recordId: "string|required",
        userId: "string|optional",
        timestamp: "string|required",
        createdAt: "string|required",
        // YYYY-MM-DD for partitioning
        oldData: "string|optional",
        newData: "string|optional",
        partition: "string|optional",
        partitionValues: "string|optional",
        metadata: "string|optional"
      },
      partitions: {
        byDate: { fields: { createdAt: "string|maxlength:10" } },
        byResource: { fields: { resourceName: "string" } }
      },
      behavior: "body-overflow"
    }));
    this.auditResource = ok ? auditResource : this.database.resources[this.auditResourceName] || null;
    if (!ok && !this.auditResource) return;
    this.database.addHook("afterCreateResource", (context) => {
      if (context.resource.name !== this.auditResourceName) {
        this.setupResourceAuditing(context.resource);
      }
    });
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name !== this.auditResourceName) {
        this.setupResourceAuditing(resource);
      }
    }
  }
  async onStart() {
  }
  async onStop() {
  }
  setupResourceAuditing(resource) {
    resource.on("inserted", async (data) => {
      const partitionValues = this.config.includePartitions ? this.getPartitionValues(data, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "insert",
        recordId: data.id || "auto-generated",
        oldData: null,
        newData: this.config.includeData ? JSON.stringify(this.truncateData(data)) : null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    resource.on("updated", async (data) => {
      let oldData = data.$before;
      if (this.config.includeData && !oldData) {
        const [ok, err, fetched] = await tryFn(() => resource.get(data.id));
        if (ok) oldData = fetched;
      }
      const partitionValues = this.config.includePartitions ? this.getPartitionValues(data, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "update",
        recordId: data.id,
        oldData: oldData && this.config.includeData ? JSON.stringify(this.truncateData(oldData)) : null,
        newData: this.config.includeData ? JSON.stringify(this.truncateData(data)) : null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    resource.on("deleted", async (data) => {
      let oldData = data;
      if (this.config.includeData && !oldData) {
        const [ok, err, fetched] = await tryFn(() => resource.get(data.id));
        if (ok) oldData = fetched;
      }
      const partitionValues = oldData && this.config.includePartitions ? this.getPartitionValues(oldData, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "delete",
        recordId: data.id,
        oldData: oldData && this.config.includeData ? JSON.stringify(this.truncateData(oldData)) : null,
        newData: null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    const originalDeleteMany = resource.deleteMany.bind(resource);
    const plugin = this;
    resource.deleteMany = async function(ids) {
      const objectsToDelete = [];
      for (const id of ids) {
        const [ok, err, fetched] = await tryFn(() => resource.get(id));
        if (ok) {
          objectsToDelete.push(fetched);
        } else {
          objectsToDelete.push({ id });
        }
      }
      const result = await originalDeleteMany(ids);
      for (const oldData of objectsToDelete) {
        const partitionValues = oldData && plugin.config.includePartitions ? plugin.getPartitionValues(oldData, resource) : null;
        await plugin.logAudit({
          resourceName: resource.name,
          operation: "deleteMany",
          recordId: oldData.id,
          oldData: oldData && plugin.config.includeData ? JSON.stringify(plugin.truncateData(oldData)) : null,
          newData: null,
          partition: partitionValues ? plugin.getPrimaryPartition(partitionValues) : null,
          partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
        });
      }
      return result;
    };
    resource._originalDeleteMany = originalDeleteMany;
  }
  // Backward compatibility for tests
  installEventListenersForResource(resource) {
    return this.setupResourceAuditing(resource);
  }
  async logAudit(auditData) {
    if (!this.auditResource) {
      return;
    }
    const now = /* @__PURE__ */ new Date();
    const auditRecord = {
      id: `audit-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`,
      userId: this.getCurrentUserId?.() || "system",
      timestamp: now.toISOString(),
      createdAt: now.toISOString().slice(0, 10),
      // YYYY-MM-DD for partitioning
      metadata: JSON.stringify({ source: "audit-plugin", version: "2.0" }),
      resourceName: auditData.resourceName,
      operation: auditData.operation,
      recordId: auditData.recordId
    };
    if (auditData.oldData !== null) {
      auditRecord.oldData = auditData.oldData;
    }
    if (auditData.newData !== null) {
      auditRecord.newData = auditData.newData;
    }
    if (auditData.partition !== null) {
      auditRecord.partition = auditData.partition;
    }
    if (auditData.partitionValues !== null) {
      auditRecord.partitionValues = auditData.partitionValues;
    }
    try {
      await this.auditResource.insert(auditRecord);
    } catch (error) {
      console.warn("Audit logging failed:", error.message);
    }
  }
  getPartitionValues(data, resource) {
    if (!this.config.includePartitions) return null;
    const partitions = resource.$schema.partitions;
    if (!partitions) {
      return null;
    }
    const partitionValues = {};
    for (const [partitionName, partitionConfig] of Object.entries(partitions)) {
      const values = {};
      for (const field of Object.keys(partitionConfig.fields)) {
        values[field] = this.getNestedFieldValue(data, field);
      }
      if (Object.values(values).some((v) => v !== void 0 && v !== null)) {
        partitionValues[partitionName] = values;
      }
    }
    return Object.keys(partitionValues).length > 0 ? partitionValues : null;
  }
  getNestedFieldValue(data, fieldPath) {
    const parts = fieldPath.split(".");
    let value = data;
    for (const part of parts) {
      if (value && typeof value === "object" && part in value) {
        value = value[part];
      } else {
        return void 0;
      }
    }
    return value;
  }
  getPrimaryPartition(partitionValues) {
    if (!partitionValues) return null;
    const partitionNames = Object.keys(partitionValues);
    return partitionNames.length > 0 ? partitionNames[0] : null;
  }
  truncateData(data) {
    if (!this.config.includeData) return null;
    const dataStr = JSON.stringify(data);
    if (dataStr.length <= this.config.maxDataSize) {
      return data;
    }
    return {
      ...data,
      _truncated: true,
      _originalSize: dataStr.length,
      _truncatedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
  }
  async getAuditLogs(options = {}) {
    if (!this.auditResource) return [];
    const { resourceName, operation, recordId, partition, startDate, endDate, limit = 100, offset = 0 } = options;
    let items = [];
    if (resourceName && !operation && !recordId && !partition && !startDate && !endDate) {
      const [ok, err, result] = await tryFn(
        () => this.auditResource.query({ resourceName }, { limit: limit + offset })
      );
      items = ok && result ? result : [];
      return items.slice(offset, offset + limit);
    } else if (startDate && !resourceName && !operation && !recordId && !partition) {
      const dates = this._generateDateRange(startDate, endDate);
      for (const date of dates) {
        const [ok, err, result] = await tryFn(
          () => this.auditResource.query({ createdAt: date })
        );
        if (ok && result) {
          items.push(...result);
        }
      }
      return items.slice(offset, offset + limit);
    } else if (resourceName || operation || recordId || partition || startDate || endDate) {
      const fetchSize = Math.min(1e4, Math.max(1e3, (limit + offset) * 20));
      const result = await this.auditResource.list({ limit: fetchSize });
      items = result || [];
      if (resourceName) {
        items = items.filter((log) => log.resourceName === resourceName);
      }
      if (operation) {
        items = items.filter((log) => log.operation === operation);
      }
      if (recordId) {
        items = items.filter((log) => log.recordId === recordId);
      }
      if (partition) {
        items = items.filter((log) => log.partition === partition);
      }
      if (startDate || endDate) {
        items = items.filter((log) => {
          const timestamp = new Date(log.timestamp);
          if (startDate && timestamp < new Date(startDate)) return false;
          if (endDate && timestamp > new Date(endDate)) return false;
          return true;
        });
      }
      return items.slice(offset, offset + limit);
    } else {
      const result = await this.auditResource.page({ size: limit, offset });
      return result.items || [];
    }
  }
  _generateDateRange(startDate, endDate) {
    const dates = [];
    const start = new Date(startDate);
    const end = endDate ? new Date(endDate) : /* @__PURE__ */ new Date();
    for (let d = new Date(start); d <= end; d.setDate(d.getDate() + 1)) {
      dates.push(d.toISOString().slice(0, 10));
    }
    return dates;
  }
  async getRecordHistory(resourceName, recordId) {
    return await this.getAuditLogs({ resourceName, recordId });
  }
  async getPartitionHistory(resourceName, partitionName, partitionValues) {
    return await this.getAuditLogs({
      resourceName,
      partition: partitionName,
      partitionValues: JSON.stringify(partitionValues)
    });
  }
  async getAuditStats(options = {}) {
    const logs = await this.getAuditLogs(options);
    const stats = {
      total: logs.length,
      byOperation: {},
      byResource: {},
      byPartition: {},
      byUser: {},
      timeline: {}
    };
    for (const log of logs) {
      stats.byOperation[log.operation] = (stats.byOperation[log.operation] || 0) + 1;
      stats.byResource[log.resourceName] = (stats.byResource[log.resourceName] || 0) + 1;
      if (log.partition) {
        stats.byPartition[log.partition] = (stats.byPartition[log.partition] || 0) + 1;
      }
      stats.byUser[log.userId] = (stats.byUser[log.userId] || 0) + 1;
      const date = log.timestamp.split("T")[0];
      stats.timeline[date] = (stats.timeline[date] || 0) + 1;
    }
    return stats;
  }
  /**
   * Clean up audit logs older than retention period
   * @param {number} retentionDays - Number of days to retain (default: 90)
   * @returns {Promise<number>} Number of records deleted
   */
  async cleanupOldAudits(retentionDays = 90) {
    if (!this.auditResource) return 0;
    const cutoffDate = /* @__PURE__ */ new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    const datesToDelete = [];
    const startDate = new Date(cutoffDate);
    startDate.setDate(startDate.getDate() - 365);
    for (let d = new Date(startDate); d < cutoffDate; d.setDate(d.getDate() + 1)) {
      datesToDelete.push(d.toISOString().slice(0, 10));
    }
    let deletedCount = 0;
    for (const dateStr of datesToDelete) {
      const [ok, err, oldAudits] = await tryFn(
        () => this.auditResource.query({ createdAt: dateStr })
      );
      if (ok && oldAudits) {
        for (const audit of oldAudits) {
          const [delOk] = await tryFn(() => this.auditResource.delete(audit.id));
          if (delOk) {
            deletedCount++;
          }
        }
      }
    }
    return deletedCount;
  }
}

var audit_plugin = /*#__PURE__*/Object.freeze({
  __proto__: null,
  AuditPlugin: AuditPlugin
});

class BackupError extends S3dbError {
  constructor(message, details = {}) {
    const { driver = "unknown", operation = "unknown", backupId, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Backup Operation Error

Driver: ${driver}
Operation: ${operation}
${backupId ? `Backup ID: ${backupId}` : ""}

Common causes:
1. Invalid backup driver configuration
2. Destination storage not accessible
3. Insufficient permissions
4. Network connectivity issues
5. Invalid backup file format

Solution:
Check driver configuration and ensure destination storage is accessible.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/backup.md
`.trim();
    }
    super(message, { ...rest, driver, operation, backupId, description });
  }
}

class BaseBackupDriver {
  constructor(config = {}) {
    this.config = {
      compression: "gzip",
      encryption: null,
      verbose: false,
      ...config
    };
  }
  /**
   * Initialize the driver
   * @param {Database} database - S3DB database instance
   */
  async setup(database) {
    this.database = database;
    await this.onSetup();
  }
  /**
   * Override this method to perform driver-specific setup
   */
  async onSetup() {
  }
  /**
   * Upload a backup file to the destination
   * @param {string} filePath - Path to the backup file
   * @param {string} backupId - Unique backup identifier
   * @param {Object} manifest - Backup manifest with metadata
   * @returns {Object} Upload result with destination info
   */
  async upload(filePath, backupId, manifest) {
    throw new BackupError("upload() method must be implemented by subclass", {
      operation: "upload",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the upload() method"
    });
  }
  /**
   * Download a backup file from the destination
   * @param {string} backupId - Unique backup identifier
   * @param {string} targetPath - Local path to save the backup
   * @param {Object} metadata - Backup metadata
   * @returns {string} Path to downloaded file
   */
  async download(backupId, targetPath, metadata) {
    throw new BackupError("download() method must be implemented by subclass", {
      operation: "download",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the download() method"
    });
  }
  /**
   * Delete a backup from the destination
   * @param {string} backupId - Unique backup identifier
   * @param {Object} metadata - Backup metadata
   */
  async delete(backupId, metadata) {
    throw new BackupError("delete() method must be implemented by subclass", {
      operation: "delete",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the delete() method"
    });
  }
  /**
   * List backups available in the destination
   * @param {Object} options - List options (limit, prefix, etc.)
   * @returns {Array} List of backup metadata
   */
  async list(options = {}) {
    throw new BackupError("list() method must be implemented by subclass", {
      operation: "list",
      driver: this.constructor.name,
      suggestion: "Extend BaseBackupDriver and implement the list() method"
    });
  }
  /**
   * Verify backup integrity
   * @param {string} backupId - Unique backup identifier
   * @param {string} expectedChecksum - Expected file checksum
   * @param {Object} metadata - Backup metadata
   * @returns {boolean} True if backup is valid
   */
  async verify(backupId, expectedChecksum, metadata) {
    throw new BackupError("verify() method must be implemented by subclass", {
      operation: "verify",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the verify() method"
    });
  }
  /**
   * Get driver type identifier
   * @returns {string} Driver type
   */
  getType() {
    throw new BackupError("getType() method must be implemented by subclass", {
      operation: "getType",
      driver: this.constructor.name,
      suggestion: "Extend BaseBackupDriver and implement the getType() method"
    });
  }
  /**
   * Get driver-specific storage info
   * @returns {Object} Storage information
   */
  getStorageInfo() {
    return {
      type: this.getType(),
      config: this.config
    };
  }
  /**
   * Clean up resources
   */
  async cleanup() {
  }
  /**
   * Log message if verbose mode is enabled
   * @param {string} message - Message to log
   */
  log(message) {
    if (this.config.verbose) {
      console.log(`[${this.getType()}BackupDriver] ${message}`);
    }
  }
}

class FilesystemBackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      path: "./backups/{date}/",
      permissions: 420,
      directoryPermissions: 493,
      ...config
    });
  }
  getType() {
    return "filesystem";
  }
  async onSetup() {
    if (!this.config.path) {
      throw new BackupError("FilesystemBackupDriver: path configuration is required", {
        operation: "onSetup",
        driver: "filesystem",
        suggestion: 'Provide a path in config: new FilesystemBackupDriver({ path: "/path/to/backups" })'
      });
    }
    this.log(`Initialized with path: ${this.config.path}`);
  }
  /**
   * Resolve path template variables
   * @param {string} backupId - Backup identifier
   * @param {Object} manifest - Backup manifest
   * @returns {string} Resolved path
   */
  resolvePath(backupId, manifest = {}) {
    const now = /* @__PURE__ */ new Date();
    const dateStr = now.toISOString().slice(0, 10);
    const timeStr = now.toISOString().slice(11, 19).replace(/:/g, "-");
    return this.config.path.replace("{date}", dateStr).replace("{time}", timeStr).replace("{year}", now.getFullYear().toString()).replace("{month}", (now.getMonth() + 1).toString().padStart(2, "0")).replace("{day}", now.getDate().toString().padStart(2, "0")).replace("{backupId}", backupId).replace("{type}", manifest.type || "backup");
  }
  async upload(filePath, backupId, manifest) {
    const targetDir = this.resolvePath(backupId, manifest);
    const targetPath = path.join(targetDir, `${backupId}.backup`);
    const manifestPath = path.join(targetDir, `${backupId}.manifest.json`);
    const [createDirOk, createDirErr] = await tryFn(
      () => mkdir(targetDir, { recursive: true, mode: this.config.directoryPermissions })
    );
    if (!createDirOk) {
      throw new BackupError("Failed to create backup directory", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        targetDir,
        original: createDirErr,
        suggestion: "Check directory permissions and disk space"
      });
    }
    const [copyOk, copyErr] = await tryFn(() => copyFile(filePath, targetPath));
    if (!copyOk) {
      throw new BackupError("Failed to copy backup file", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        filePath,
        targetPath,
        original: copyErr,
        suggestion: "Check file permissions and disk space"
      });
    }
    const [manifestOk, manifestErr] = await tryFn(
      () => import('fs/promises').then((fs) => fs.writeFile(
        manifestPath,
        JSON.stringify(manifest, null, 2),
        { mode: this.config.permissions }
      ))
    );
    if (!manifestOk) {
      await tryFn(() => unlink(targetPath));
      throw new BackupError("Failed to write manifest file", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        manifestPath,
        original: manifestErr,
        suggestion: "Check directory permissions and disk space"
      });
    }
    const [statOk, , stats] = await tryFn(() => stat(targetPath));
    const size = statOk ? stats.size : 0;
    this.log(`Uploaded backup ${backupId} to ${targetPath} (${size} bytes)`);
    return {
      path: targetPath,
      manifestPath,
      size,
      uploadedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
  }
  async download(backupId, targetPath, metadata) {
    const sourcePath = metadata.path || path.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const [existsOk] = await tryFn(() => access(sourcePath));
    if (!existsOk) {
      throw new BackupError("Backup file not found", {
        operation: "download",
        driver: "filesystem",
        backupId,
        sourcePath,
        suggestion: "Check if backup exists using list() method"
      });
    }
    const targetDir = path.dirname(targetPath);
    await tryFn(() => mkdir(targetDir, { recursive: true }));
    const [copyOk, copyErr] = await tryFn(() => copyFile(sourcePath, targetPath));
    if (!copyOk) {
      throw new BackupError("Failed to download backup", {
        operation: "download",
        driver: "filesystem",
        backupId,
        sourcePath,
        targetPath,
        original: copyErr,
        suggestion: "Check file permissions and disk space"
      });
    }
    this.log(`Downloaded backup ${backupId} from ${sourcePath} to ${targetPath}`);
    return targetPath;
  }
  async delete(backupId, metadata) {
    const backupPath = metadata.path || path.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const manifestPath = metadata.manifestPath || path.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.manifest.json`
    );
    const [deleteBackupOk] = await tryFn(() => unlink(backupPath));
    const [deleteManifestOk] = await tryFn(() => unlink(manifestPath));
    if (!deleteBackupOk && !deleteManifestOk) {
      throw new BackupError("Failed to delete backup files", {
        operation: "delete",
        driver: "filesystem",
        backupId,
        backupPath,
        manifestPath,
        suggestion: "Check file permissions"
      });
    }
    this.log(`Deleted backup ${backupId}`);
  }
  async list(options = {}) {
    const { limit = 50, prefix = "" } = options;
    const basePath = this.resolvePath("*").replace("*", "");
    try {
      const results = [];
      await this._scanDirectory(path.dirname(basePath), prefix, results, limit);
      results.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
      return results.slice(0, limit);
    } catch (error) {
      this.log(`Error listing backups: ${error.message}`);
      return [];
    }
  }
  async _scanDirectory(dirPath, prefix, results, limit) {
    if (results.length >= limit) return;
    const [readDirOk, , files] = await tryFn(() => readdir(dirPath));
    if (!readDirOk) return;
    for (const file of files) {
      if (results.length >= limit) break;
      const fullPath = path.join(dirPath, file);
      const [statOk, , stats] = await tryFn(() => stat(fullPath));
      if (!statOk) continue;
      if (stats.isDirectory()) {
        await this._scanDirectory(fullPath, prefix, results, limit);
      } else if (file.endsWith(".manifest.json")) {
        const [readOk, , content] = await tryFn(
          () => import('fs/promises').then((fs) => fs.readFile(fullPath, "utf8"))
        );
        if (readOk) {
          try {
            const manifest = JSON.parse(content);
            const backupId = file.replace(".manifest.json", "");
            if (!prefix || backupId.includes(prefix)) {
              results.push({
                id: backupId,
                path: fullPath.replace(".manifest.json", ".backup"),
                manifestPath: fullPath,
                size: stats.size,
                createdAt: manifest.createdAt || stats.birthtime.toISOString(),
                ...manifest
              });
            }
          } catch (parseErr) {
            this.log(`Failed to parse manifest ${fullPath}: ${parseErr.message}`);
          }
        }
      }
    }
  }
  async verify(backupId, expectedChecksum, metadata) {
    const backupPath = metadata.path || path.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const [readOk, readErr] = await tryFn(async () => {
      const hash = crypto.createHash("sha256");
      const stream = createReadStream(backupPath);
      await pipeline(stream, hash);
      const actualChecksum = hash.digest("hex");
      return actualChecksum === expectedChecksum;
    });
    if (!readOk) {
      this.log(`Verification failed for ${backupId}: ${readErr.message}`);
      return false;
    }
    return readOk;
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      path: this.config.path,
      permissions: this.config.permissions,
      directoryPermissions: this.config.directoryPermissions
    };
  }
}

class S3BackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      bucket: null,
      // Will use database bucket if not specified
      path: "backups/{date}/",
      storageClass: "STANDARD_IA",
      serverSideEncryption: "AES256",
      client: null,
      // Will use database client if not specified
      ...config
    });
  }
  getType() {
    return "s3";
  }
  async onSetup() {
    if (!this.config.client) {
      this.config.client = this.database.client;
    }
    if (!this.config.bucket) {
      this.config.bucket = this.database.bucket;
    }
    if (!this.config.client) {
      throw new BackupError("S3BackupDriver: client is required", {
        operation: "onSetup",
        driver: "s3",
        suggestion: "Provide a client in config or ensure database has a client configured"
      });
    }
    if (!this.config.bucket) {
      throw new BackupError("S3BackupDriver: bucket is required", {
        operation: "onSetup",
        driver: "s3",
        suggestion: "Provide a bucket in config or ensure database has a bucket configured"
      });
    }
    this.log(`Initialized with bucket: ${this.config.bucket}, path: ${this.config.path}`);
  }
  /**
   * Resolve S3 key template variables
   * @param {string} backupId - Backup identifier
   * @param {Object} manifest - Backup manifest
   * @returns {string} Resolved S3 key
   */
  resolveKey(backupId, manifest = {}) {
    const now = /* @__PURE__ */ new Date();
    const dateStr = now.toISOString().slice(0, 10);
    const timeStr = now.toISOString().slice(11, 19).replace(/:/g, "-");
    const basePath = this.config.path.replace("{date}", dateStr).replace("{time}", timeStr).replace("{year}", now.getFullYear().toString()).replace("{month}", (now.getMonth() + 1).toString().padStart(2, "0")).replace("{day}", now.getDate().toString().padStart(2, "0")).replace("{backupId}", backupId).replace("{type}", manifest.type || "backup");
    return path.posix.join(basePath, `${backupId}.backup`);
  }
  resolveManifestKey(backupId, manifest = {}) {
    return this.resolveKey(backupId, manifest).replace(".backup", ".manifest.json");
  }
  async upload(filePath, backupId, manifest) {
    const backupKey = this.resolveKey(backupId, manifest);
    const manifestKey = this.resolveManifestKey(backupId, manifest);
    const [statOk, , stats] = await tryFn(() => stat(filePath));
    const fileSize = statOk ? stats.size : 0;
    const [uploadOk, uploadErr] = await tryFn(async () => {
      const fileStream = createReadStream(filePath);
      return await this.config.client.uploadObject({
        bucket: this.config.bucket,
        key: backupKey,
        body: fileStream,
        contentLength: fileSize,
        metadata: {
          "backup-id": backupId,
          "backup-type": manifest.type || "backup",
          "created-at": (/* @__PURE__ */ new Date()).toISOString()
        },
        storageClass: this.config.storageClass,
        serverSideEncryption: this.config.serverSideEncryption
      });
    });
    if (!uploadOk) {
      throw new BackupError("Failed to upload backup file to S3", {
        operation: "upload",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        key: backupKey,
        original: uploadErr,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    const [manifestOk, manifestErr] = await tryFn(
      () => this.config.client.uploadObject({
        bucket: this.config.bucket,
        key: manifestKey,
        body: JSON.stringify(manifest, null, 2),
        contentType: "application/json",
        metadata: {
          "backup-id": backupId,
          "manifest-for": backupKey
        },
        storageClass: this.config.storageClass,
        serverSideEncryption: this.config.serverSideEncryption
      })
    );
    if (!manifestOk) {
      await tryFn(() => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: backupKey
      }));
      throw new BackupError("Failed to upload manifest to S3", {
        operation: "upload",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        manifestKey,
        original: manifestErr,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    this.log(`Uploaded backup ${backupId} to s3://${this.config.bucket}/${backupKey} (${fileSize} bytes)`);
    return {
      bucket: this.config.bucket,
      key: backupKey,
      manifestKey,
      size: fileSize,
      storageClass: this.config.storageClass,
      uploadedAt: (/* @__PURE__ */ new Date()).toISOString(),
      etag: uploadOk?.ETag
    };
  }
  async download(backupId, targetPath, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const [downloadOk, downloadErr] = await tryFn(
      () => this.config.client.downloadObject({
        bucket: this.config.bucket,
        key: backupKey,
        filePath: targetPath
      })
    );
    if (!downloadOk) {
      throw new BackupError("Failed to download backup from S3", {
        operation: "download",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        key: backupKey,
        targetPath,
        original: downloadErr,
        suggestion: "Check if backup exists and S3 permissions are correct"
      });
    }
    this.log(`Downloaded backup ${backupId} from s3://${this.config.bucket}/${backupKey} to ${targetPath}`);
    return targetPath;
  }
  async delete(backupId, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const manifestKey = metadata.manifestKey || this.resolveManifestKey(backupId, metadata);
    const [deleteBackupOk] = await tryFn(
      () => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: backupKey
      })
    );
    const [deleteManifestOk] = await tryFn(
      () => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: manifestKey
      })
    );
    if (!deleteBackupOk && !deleteManifestOk) {
      throw new BackupError("Failed to delete backup from S3", {
        operation: "delete",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        backupKey,
        manifestKey,
        suggestion: "Check S3 delete permissions"
      });
    }
    this.log(`Deleted backup ${backupId} from S3`);
  }
  async list(options = {}) {
    const { limit = 50, prefix = "" } = options;
    const searchPrefix = this.config.path.replace(/\{[^}]+\}/g, "");
    const [listOk, listErr, response] = await tryFn(
      () => this.config.client.listObjects({
        bucket: this.config.bucket,
        prefix: searchPrefix,
        maxKeys: limit * 2
        // Get more to account for manifest files
      })
    );
    if (!listOk) {
      this.log(`Error listing S3 objects: ${listErr.message}`);
      return [];
    }
    const manifestObjects = (response.Contents || []).filter((obj) => obj.Key.endsWith(".manifest.json")).filter((obj) => !prefix || obj.Key.includes(prefix));
    const results = [];
    for (const obj of manifestObjects.slice(0, limit)) {
      const [manifestOk, , manifestContent] = await tryFn(
        () => this.config.client.getObject({
          bucket: this.config.bucket,
          key: obj.Key
        })
      );
      if (manifestOk) {
        try {
          const manifest = JSON.parse(manifestContent);
          const backupId = path.basename(obj.Key, ".manifest.json");
          results.push({
            id: backupId,
            bucket: this.config.bucket,
            key: obj.Key.replace(".manifest.json", ".backup"),
            manifestKey: obj.Key,
            size: obj.Size,
            lastModified: obj.LastModified,
            storageClass: obj.StorageClass,
            createdAt: manifest.createdAt || obj.LastModified,
            ...manifest
          });
        } catch (parseErr) {
          this.log(`Failed to parse manifest ${obj.Key}: ${parseErr.message}`);
        }
      }
    }
    results.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
    return results;
  }
  async verify(backupId, expectedChecksum, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const [verifyOk, verifyErr] = await tryFn(async () => {
      const headResponse = await this.config.client.headObject({
        bucket: this.config.bucket,
        key: backupKey
      });
      const etag = headResponse.ETag?.replace(/"/g, "");
      if (etag && !etag.includes("-")) {
        const expectedMd5 = crypto.createHash("md5").update(expectedChecksum).digest("hex");
        return etag === expectedMd5;
      } else {
        const [streamOk, , stream] = await tryFn(
          () => this.config.client.getObjectStream({
            bucket: this.config.bucket,
            key: backupKey
          })
        );
        if (!streamOk) return false;
        const hash = crypto.createHash("sha256");
        for await (const chunk of stream) {
          hash.update(chunk);
        }
        const actualChecksum = hash.digest("hex");
        return actualChecksum === expectedChecksum;
      }
    });
    if (!verifyOk) {
      this.log(`Verification failed for ${backupId}: ${verifyErr?.message || "checksum mismatch"}`);
      return false;
    }
    return true;
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      bucket: this.config.bucket,
      path: this.config.path,
      storageClass: this.config.storageClass,
      serverSideEncryption: this.config.serverSideEncryption
    };
  }
}

class MultiBackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      destinations: [],
      strategy: "all",
      // 'all', 'any', 'priority'
      concurrency: 3,
      ...config
    });
    this.drivers = [];
  }
  getType() {
    return "multi";
  }
  async onSetup() {
    if (!Array.isArray(this.config.destinations) || this.config.destinations.length === 0) {
      throw new BackupError("MultiBackupDriver requires non-empty destinations array", {
        operation: "onSetup",
        driver: "multi",
        destinationsProvided: this.config.destinations,
        suggestion: 'Provide destinations array: { destinations: [{ driver: "s3", config: {...} }, { driver: "filesystem", config: {...} }] }'
      });
    }
    for (const [index, destConfig] of this.config.destinations.entries()) {
      if (!destConfig.driver) {
        throw new BackupError(`Destination ${index} missing driver type`, {
          operation: "onSetup",
          driver: "multi",
          destinationIndex: index,
          destination: destConfig,
          suggestion: 'Each destination must have a driver property: { driver: "s3", config: {...} } or { driver: "filesystem", config: {...} }'
        });
      }
      try {
        const driver = createBackupDriver(destConfig.driver, destConfig.config || {});
        await driver.setup(this.database);
        this.drivers.push({
          driver,
          config: destConfig,
          index
        });
        this.log(`Setup destination ${index}: ${destConfig.driver}`);
      } catch (error) {
        throw new BackupError(`Failed to setup destination ${index}`, {
          operation: "onSetup",
          driver: "multi",
          destinationIndex: index,
          destinationDriver: destConfig.driver,
          destinationConfig: destConfig.config,
          original: error,
          suggestion: "Check destination driver configuration and ensure dependencies are available"
        });
      }
    }
    if (this.config.requireAll === false) {
      this.config.strategy = "any";
    }
    this.log(`Initialized with ${this.drivers.length} destinations, strategy: ${this.config.strategy}`);
  }
  async upload(filePath, backupId, manifest) {
    const strategy = this.config.strategy;
    const errors = [];
    if (strategy === "priority") {
      for (const { driver, config, index } of this.drivers) {
        const [ok, err, result] = await tryFn(
          () => driver.upload(filePath, backupId, manifest)
        );
        if (ok) {
          this.log(`Priority upload successful to destination ${index}`);
          return [{
            ...result,
            driver: config.driver,
            destination: index,
            status: "success"
          }];
        } else {
          errors.push({ destination: index, error: err.message });
          this.log(`Priority upload failed to destination ${index}: ${err.message}`);
        }
      }
      throw new BackupError("All priority destinations failed", {
        operation: "upload",
        driver: "multi",
        strategy: "priority",
        backupId,
        totalDestinations: this.drivers.length,
        failures: errors,
        suggestion: "Check destination configurations and ensure at least one destination is accessible"
      });
    }
    const uploadPromises = this.drivers.map(async ({ driver, config, index }) => {
      const [ok, err, result] = await tryFn(
        () => driver.upload(filePath, backupId, manifest)
      );
      if (ok) {
        this.log(`Upload successful to destination ${index}`);
        return {
          ...result,
          driver: config.driver,
          destination: index,
          status: "success"
        };
      } else {
        this.log(`Upload failed to destination ${index}: ${err.message}`);
        const errorResult = {
          driver: config.driver,
          destination: index,
          status: "failed",
          error: err.message
        };
        errors.push(errorResult);
        return errorResult;
      }
    });
    const allResults = await this._executeConcurrent(uploadPromises, this.config.concurrency);
    const successResults = allResults.filter((r) => r.status === "success");
    const failedResults = allResults.filter((r) => r.status === "failed");
    if (strategy === "all" && failedResults.length > 0) {
      throw new BackupError('Some destinations failed with strategy "all"', {
        operation: "upload",
        driver: "multi",
        strategy: "all",
        backupId,
        totalDestinations: this.drivers.length,
        successCount: successResults.length,
        failedCount: failedResults.length,
        failures: failedResults,
        suggestion: 'All destinations must succeed with "all" strategy. Use "any" strategy to tolerate failures, or fix failing destinations.'
      });
    }
    if (strategy === "any" && successResults.length === 0) {
      throw new BackupError('All destinations failed with strategy "any"', {
        operation: "upload",
        driver: "multi",
        strategy: "any",
        backupId,
        totalDestinations: this.drivers.length,
        failures: failedResults,
        suggestion: 'At least one destination must succeed with "any" strategy. Check all destination configurations.'
      });
    }
    return allResults;
  }
  async download(backupId, targetPath, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, err, result] = await tryFn(
        () => driverInstance.driver.download(backupId, targetPath, destMetadata)
      );
      if (ok) {
        this.log(`Downloaded from destination ${destMetadata.destination}`);
        return result;
      } else {
        this.log(`Download failed from destination ${destMetadata.destination}: ${err.message}`);
      }
    }
    throw new BackupError("Failed to download backup from any destination", {
      operation: "download",
      driver: "multi",
      backupId,
      targetPath,
      attemptedDestinations: destinations.length,
      suggestion: "Check if backup exists in at least one destination and destinations are accessible"
    });
  }
  async delete(backupId, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    const errors = [];
    let successCount = 0;
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, err] = await tryFn(
        () => driverInstance.driver.delete(backupId, destMetadata)
      );
      if (ok) {
        successCount++;
        this.log(`Deleted from destination ${destMetadata.destination}`);
      } else {
        errors.push(`${destMetadata.destination}: ${err.message}`);
        this.log(`Delete failed from destination ${destMetadata.destination}: ${err.message}`);
      }
    }
    if (successCount === 0 && errors.length > 0) {
      throw new BackupError("Failed to delete from any destination", {
        operation: "delete",
        driver: "multi",
        backupId,
        attemptedDestinations: destinations.length,
        failures: errors,
        suggestion: "Check if backup exists in destinations and destinations are accessible with delete permissions"
      });
    }
    if (errors.length > 0) {
      this.log(`Partial delete success, some errors: ${errors.join("; ")}`);
    }
  }
  async list(options = {}) {
    const allLists = await Promise.allSettled(
      this.drivers.map(
        ({ driver, index }) => driver.list(options).catch((err) => {
          this.log(`List failed for destination ${index}: ${err.message}`);
          return [];
        })
      )
    );
    const backupMap = /* @__PURE__ */ new Map();
    allLists.forEach((result, index) => {
      if (result.status === "fulfilled") {
        result.value.forEach((backup) => {
          const existing = backupMap.get(backup.id);
          if (!existing || new Date(backup.createdAt) > new Date(existing.createdAt)) {
            backupMap.set(backup.id, {
              ...backup,
              destinations: existing ? [...existing.destinations || [], { destination: index, ...backup }] : [{ destination: index, ...backup }]
            });
          }
        });
      }
    });
    const results = Array.from(backupMap.values()).sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt)).slice(0, options.limit || 50);
    return results;
  }
  async verify(backupId, expectedChecksum, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, , isValid] = await tryFn(
        () => driverInstance.driver.verify(backupId, expectedChecksum, destMetadata)
      );
      if (ok && isValid) {
        this.log(`Verification successful from destination ${destMetadata.destination}`);
        return true;
      }
    }
    return false;
  }
  async cleanup() {
    await Promise.all(
      this.drivers.map(
        ({ driver }) => tryFn(() => driver.cleanup()).catch(() => {
        })
      )
    );
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      strategy: this.config.strategy,
      destinations: this.drivers.map(({ driver, config, index }) => ({
        index,
        driver: config.driver,
        info: driver.getStorageInfo()
      }))
    };
  }
  /**
   * Execute promises with concurrency limit
   * @param {Array} promises - Array of promise functions
   * @param {number} concurrency - Max concurrent executions
   * @returns {Array} Results in original order
   */
  async _executeConcurrent(promises, concurrency) {
    const results = new Array(promises.length);
    const executing = [];
    for (let i = 0; i < promises.length; i++) {
      const promise = Promise.resolve(promises[i]).then((result) => {
        results[i] = result;
        return result;
      });
      executing.push(promise);
      if (executing.length >= concurrency) {
        await Promise.race(executing);
        executing.splice(executing.findIndex((p) => p === promise), 1);
      }
    }
    await Promise.all(executing);
    return results;
  }
}

const BACKUP_DRIVERS = {
  filesystem: FilesystemBackupDriver,
  s3: S3BackupDriver,
  multi: MultiBackupDriver
};
function createBackupDriver(driver, config = {}) {
  const DriverClass = BACKUP_DRIVERS[driver];
  if (!DriverClass) {
    throw new BackupError(`Unknown backup driver: ${driver}`, {
      operation: "createBackupDriver",
      driver,
      availableDrivers: Object.keys(BACKUP_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(BACKUP_DRIVERS).join(", ")}`
    });
  }
  return new DriverClass(config);
}
function validateBackupConfig(driver, config = {}) {
  if (!driver || typeof driver !== "string") {
    throw new BackupError("Driver type must be a non-empty string", {
      operation: "validateBackupConfig",
      driver,
      suggestion: "Provide a valid driver type string (filesystem, s3, or multi)"
    });
  }
  if (!BACKUP_DRIVERS[driver]) {
    throw new BackupError(`Unknown backup driver: ${driver}`, {
      operation: "validateBackupConfig",
      driver,
      availableDrivers: Object.keys(BACKUP_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(BACKUP_DRIVERS).join(", ")}`
    });
  }
  switch (driver) {
    case "filesystem":
      if (!config.path) {
        throw new BackupError('FilesystemBackupDriver requires "path" configuration', {
          operation: "validateBackupConfig",
          driver: "filesystem",
          config,
          suggestion: 'Provide a "path" property in config: { path: "/path/to/backups" }'
        });
      }
      break;
    case "s3":
      break;
    case "multi":
      if (!Array.isArray(config.destinations) || config.destinations.length === 0) {
        throw new BackupError('MultiBackupDriver requires non-empty "destinations" array', {
          operation: "validateBackupConfig",
          driver: "multi",
          config,
          suggestion: 'Provide destinations array: { destinations: [{ driver: "s3", config: {...} }] }'
        });
      }
      config.destinations.forEach((dest, index) => {
        if (!dest.driver) {
          throw new BackupError(`Destination ${index} must have a "driver" property`, {
            operation: "validateBackupConfig",
            driver: "multi",
            destinationIndex: index,
            destination: dest,
            suggestion: 'Each destination must have a driver property: { driver: "s3", config: {...} }'
          });
        }
        if (dest.driver !== "multi") {
          validateBackupConfig(dest.driver, dest.config || {});
        }
      });
      break;
  }
  return true;
}

class StreamingExporter {
  constructor(options = {}) {
    this.encoding = options.encoding || "utf8";
    this.compress = options.compress !== false;
    this.batchSize = options.batchSize || 100;
    this.onProgress = options.onProgress || null;
  }
  /**
   * Export single resource to JSONL file
   *
   * @param {Resource} resource - S3DB resource
   * @param {string} outputPath - Output file path
   * @param {string} type - Export type ('full' or 'incremental')
   * @param {Date} sinceTimestamp - For incremental backups
   * @returns {Promise<{recordCount: number, bytesWritten: number}>}
   */
  async exportResource(resource, outputPath, type = "full", sinceTimestamp = null) {
    let recordCount = 0;
    let bytesWritten = 0;
    const writeStream = createWriteStream(outputPath);
    let outputStream = writeStream;
    if (this.compress) {
      const gzipStream = zlib.createGzip();
      gzipStream.pipe(writeStream);
      outputStream = gzipStream;
    }
    try {
      let records;
      if (type === "incremental" && sinceTimestamp) {
        records = await resource.list({
          filter: { updatedAt: { ">": sinceTimestamp.toISOString() } }
        });
      } else {
        records = await resource.list();
      }
      for (const record of records) {
        const line = JSON.stringify(record) + "\n";
        const canWrite = outputStream.write(line, this.encoding);
        recordCount++;
        bytesWritten += Buffer.byteLength(line, this.encoding);
        if (this.onProgress && recordCount % 1e3 === 0) {
          this.onProgress({
            resourceName: resource.name,
            recordCount,
            bytesWritten
          });
        }
        if (!canWrite) {
          await new Promise((resolve) => outputStream.once("drain", resolve));
        }
      }
      outputStream.end();
      await new Promise((resolve, reject) => {
        writeStream.on("finish", resolve);
        writeStream.on("error", reject);
      });
      return { recordCount, bytesWritten };
    } catch (error) {
      outputStream.destroy();
      throw error;
    }
  }
  /**
   * Export multiple resources
   *
   * @param {Object} resources - Map of resource name -> resource
   * @param {string} outputDir - Output directory
   * @param {string} type - Export type
   * @param {Date} sinceTimestamp - For incremental
   * @returns {Promise<Map<string, {recordCount, bytesWritten}>>}
   */
  async exportResources(resources, outputDir, type = "full", sinceTimestamp = null) {
    const results = /* @__PURE__ */ new Map();
    for (const [resourceName, resource] of Object.entries(resources)) {
      const ext = this.compress ? ".jsonl.gz" : ".jsonl";
      const outputPath = `${outputDir}/${resourceName}${ext}`;
      const stats = await this.exportResource(resource, outputPath, type, sinceTimestamp);
      results.set(resourceName, {
        ...stats,
        filePath: outputPath,
        compressed: this.compress
      });
    }
    return results;
  }
}

class BackupPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      // Driver configuration
      driver: options.driver || "filesystem",
      driverConfig: options.config || {},
      // Scheduling configuration
      schedule: options.schedule || {},
      // Retention policy (Grandfather-Father-Son)
      retention: {
        daily: 7,
        weekly: 4,
        monthly: 12,
        yearly: 3,
        ...options.retention
      },
      // Backup options
      compression: options.compression || "gzip",
      encryption: options.encryption || null,
      verification: options.verification !== false,
      parallelism: options.parallelism || 4,
      include: options.include || null,
      exclude: options.exclude || [],
      backupMetadataResource: options.backupMetadataResource || "plg_backup_metadata",
      tempDir: options.tempDir || path.join(os.tmpdir(), "s3db", "backups"),
      verbose: options.verbose || false,
      // Hooks
      onBackupStart: options.onBackupStart || null,
      onBackupComplete: options.onBackupComplete || null,
      onBackupError: options.onBackupError || null,
      onRestoreStart: options.onRestoreStart || null,
      onRestoreComplete: options.onRestoreComplete || null,
      onRestoreError: options.onRestoreError || null
    };
    this.driver = null;
    this.activeBackups = /* @__PURE__ */ new Set();
    validateBackupConfig(this.config.driver, this.config.driverConfig);
    this._validateConfiguration();
  }
  _validateConfiguration() {
    if (this.config.encryption && (!this.config.encryption.key || !this.config.encryption.algorithm)) {
      throw new Error("BackupPlugin: Encryption requires both key and algorithm");
    }
    if (this.config.compression && !["none", "gzip", "brotli", "deflate"].includes(this.config.compression)) {
      throw new Error("BackupPlugin: Invalid compression type. Use: none, gzip, brotli, deflate");
    }
  }
  async onInstall() {
    this.driver = createBackupDriver(this.config.driver, this.config.driverConfig);
    await this.driver.setup(this.database);
    await mkdir(this.config.tempDir, { recursive: true });
    await this._createBackupMetadataResource();
    if (this.config.verbose) {
      const storageInfo = this.driver.getStorageInfo();
      console.log(`[BackupPlugin] Initialized with driver: ${storageInfo.type}`);
    }
    this.emit("db:plugin:initialized", {
      driver: this.driver.getType(),
      config: this.driver.getStorageInfo()
    });
  }
  async _createBackupMetadataResource() {
    const [ok] = await tryFn(() => this.database.createResource({
      name: this.config.backupMetadataResource,
      attributes: {
        id: "string|required",
        type: "string|required",
        timestamp: "number|required",
        resources: "json|required",
        driverInfo: "json|required",
        // Store driver info instead of destinations
        size: "number|default:0",
        compressed: "boolean|default:false",
        encrypted: "boolean|default:false",
        checksum: "string|default:null",
        status: "string|required",
        error: "string|default:null",
        duration: "number|default:0",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: true
    }));
    if (!ok && this.config.verbose) {
      console.log(`[BackupPlugin] Backup metadata resource '${this.config.backupMetadataResource}' already exists`);
    }
  }
  /**
   * Create a backup
   * @param {string} type - Backup type ('full' or 'incremental')
   * @param {Object} options - Backup options
   * @returns {Object} Backup result
   */
  async backup(type = "full", options = {}) {
    const backupId = this._generateBackupId(type);
    const startTime = Date.now();
    if (this.activeBackups.has(backupId)) {
      throw new Error(`Backup '${backupId}' is already in progress`);
    }
    try {
      this.activeBackups.add(backupId);
      if (this.config.onBackupStart) {
        await this._executeHook(this.config.onBackupStart, type, { backupId });
      }
      this.emit("plg:backup:start", { id: backupId, type });
      const metadata = await this._createBackupMetadata(backupId, type);
      const tempBackupDir = path.join(this.config.tempDir, backupId);
      await mkdir(tempBackupDir, { recursive: true });
      try {
        const manifest = await this._createBackupManifest(type, options);
        const exportedFiles = await this._exportResources(manifest.resources, tempBackupDir, type);
        if (exportedFiles.length === 0) {
          throw new Error("No resources were exported for backup");
        }
        const archiveExtension = this.config.compression !== "none" ? ".tar.gz" : ".json";
        const finalPath = path.join(tempBackupDir, `${backupId}${archiveExtension}`);
        const totalSize = await this._createArchive(exportedFiles, finalPath, this.config.compression);
        const checksum = await this._generateChecksum(finalPath);
        const uploadResult = await this.driver.upload(finalPath, backupId, manifest);
        if (this.config.verification) {
          const isValid = await this.driver.verify(backupId, checksum, uploadResult);
          if (!isValid) {
            throw new Error("Backup verification failed");
          }
        }
        const duration = Date.now() - startTime;
        await this._updateBackupMetadata(backupId, {
          status: "completed",
          size: totalSize,
          checksum,
          driverInfo: uploadResult,
          duration
        });
        if (this.config.onBackupComplete) {
          const stats = { backupId, type, size: totalSize, duration, driverInfo: uploadResult };
          await this._executeHook(this.config.onBackupComplete, type, stats);
        }
        this.emit("plg:backup:complete", {
          id: backupId,
          type,
          size: totalSize,
          duration,
          driverInfo: uploadResult
        });
        await this._cleanupOldBackups();
        return {
          id: backupId,
          type,
          size: totalSize,
          duration,
          checksum,
          driverInfo: uploadResult
        };
      } finally {
        await this._cleanupTempFiles(tempBackupDir);
      }
    } catch (error) {
      if (this.config.onBackupError) {
        await this._executeHook(this.config.onBackupError, type, { backupId, error });
      }
      await this._updateBackupMetadata(backupId, {
        status: "failed",
        error: error.message,
        duration: Date.now() - startTime
      });
      this.emit("plg:backup:error", { id: backupId, type, error: error.message });
      throw error;
    } finally {
      this.activeBackups.delete(backupId);
    }
  }
  _generateBackupId(type) {
    const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
    const random = Math.random().toString(36).substring(2, 8);
    return `${type}-${timestamp}-${random}`;
  }
  async _createBackupMetadata(backupId, type) {
    const now = /* @__PURE__ */ new Date();
    const metadata = {
      id: backupId,
      type,
      timestamp: Date.now(),
      resources: [],
      driverInfo: {},
      size: 0,
      status: "in_progress",
      compressed: this.config.compression !== "none",
      encrypted: !!this.config.encryption,
      checksum: null,
      error: null,
      duration: 0,
      createdAt: now.toISOString().slice(0, 10)
    };
    const [ok] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].insert(metadata)
    );
    return metadata;
  }
  async _updateBackupMetadata(backupId, updates) {
    const [ok] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].update(backupId, updates)
    );
  }
  async _createBackupManifest(type, options) {
    let resourcesToBackup = options.resources || (this.config.include ? this.config.include : await this.database.listResources());
    if (Array.isArray(resourcesToBackup) && resourcesToBackup.length > 0 && typeof resourcesToBackup[0] === "object") {
      resourcesToBackup = resourcesToBackup.map((resource) => resource.name || resource);
    }
    const filteredResources = resourcesToBackup.filter(
      (name) => !this.config.exclude.includes(name)
    );
    return {
      type,
      timestamp: Date.now(),
      resources: filteredResources,
      compression: this.config.compression,
      encrypted: !!this.config.encryption,
      s3db_version: this.database.constructor.version || "unknown"
    };
  }
  async _exportResources(resourceNames, tempDir, type) {
    const exportedFiles = [];
    const resourceStats = /* @__PURE__ */ new Map();
    const exporter = new StreamingExporter({
      compress: true,
      // Always use gzip for backups
      onProgress: this.config.verbose ? (stats) => {
        if (stats.recordCount % 1e4 === 0) {
          console.log(`[BackupPlugin] Exported ${stats.recordCount} records from '${stats.resourceName}'`);
        }
      } : null
    });
    let sinceTimestamp = null;
    if (type === "incremental") {
      const [lastBackupOk, , lastBackups] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          filter: {
            status: "completed",
            type: { $in: ["full", "incremental"] }
          },
          sort: { timestamp: -1 },
          limit: 1
        })
      );
      if (lastBackupOk && lastBackups && lastBackups.length > 0) {
        sinceTimestamp = new Date(lastBackups[0].timestamp);
      } else {
        sinceTimestamp = new Date(Date.now() - 24 * 60 * 60 * 1e3);
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Incremental backup since ${sinceTimestamp.toISOString()}`);
      }
    }
    for (const resourceName of resourceNames) {
      const resource = this.database.resources[resourceName];
      if (!resource) {
        if (this.config.verbose) {
          console.warn(`[BackupPlugin] Resource '${resourceName}' not found, skipping`);
        }
        continue;
      }
      const exportPath = path.join(tempDir, `${resourceName}.jsonl.gz`);
      try {
        const stats = await exporter.exportResource(resource, exportPath, type, sinceTimestamp);
        exportedFiles.push(exportPath);
        resourceStats.set(resourceName, {
          ...stats,
          definition: resource.config
        });
        if (this.config.verbose) {
          console.log(
            `[BackupPlugin] Exported ${stats.recordCount} records from '${resourceName}' (${(stats.bytesWritten / 1024 / 1024).toFixed(2)} MB compressed)`
          );
        }
      } catch (error) {
        if (this.config.verbose) {
          console.error(`[BackupPlugin] Error exporting '${resourceName}': ${error.message}`);
        }
        throw error;
      }
    }
    await this._generateMetadataFile(tempDir, resourceStats, type);
    exportedFiles.push(path.join(tempDir, "s3db.json"));
    return exportedFiles;
  }
  /**
   * Generate s3db.json metadata file
   */
  async _generateMetadataFile(tempDir, resourceStats, type) {
    const metadata = {
      version: "1.0",
      backupType: type,
      exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
      database: {
        bucket: this.database.bucket,
        region: this.database.region
      },
      resources: {}
    };
    for (const [resourceName, stats] of resourceStats.entries()) {
      metadata.resources[resourceName] = {
        name: resourceName,
        attributes: stats.definition.attributes || {},
        partitions: stats.definition.partitions || {},
        timestamps: stats.definition.timestamps || false,
        recordCount: stats.recordCount,
        exportFile: `${resourceName}.jsonl.gz`,
        compression: "gzip",
        format: "jsonl",
        bytesWritten: stats.bytesWritten
      };
    }
    const metadataPath = path.join(tempDir, "s3db.json");
    await writeFile(metadataPath, JSON.stringify(metadata, null, 2));
    if (this.config.verbose) {
      console.log(`[BackupPlugin] Generated s3db.json metadata`);
    }
  }
  async _createArchive(files, targetPath, compressionType) {
    const archive = {
      version: "1.0",
      created: (/* @__PURE__ */ new Date()).toISOString(),
      files: []
    };
    let totalSize = 0;
    for (const filePath of files) {
      const [readOk, readErr, content] = await tryFn(() => readFile(filePath, "utf8"));
      if (!readOk) {
        if (this.config.verbose) {
          console.warn(`[BackupPlugin] Failed to read ${filePath}: ${readErr?.message}`);
        }
        continue;
      }
      const fileName = path.basename(filePath);
      totalSize += content.length;
      archive.files.push({
        name: fileName,
        size: content.length,
        content
      });
    }
    const archiveJson = JSON.stringify(archive);
    if (compressionType === "none") {
      await writeFile(targetPath, archiveJson, "utf8");
    } else {
      const output = createWriteStream(targetPath);
      const gzip = zlib.createGzip({ level: 6 });
      await pipeline(
        async function* () {
          yield Buffer.from(archiveJson, "utf8");
        },
        gzip,
        output
      );
    }
    const [statOk, , stats] = await tryFn(() => stat(targetPath));
    return statOk ? stats.size : totalSize;
  }
  async _generateChecksum(filePath) {
    const [ok, err, result] = await tryFn(async () => {
      const hash = crypto.createHash("sha256");
      const stream = createReadStream(filePath);
      await pipeline(stream, hash);
      return hash.digest("hex");
    });
    if (!ok) {
      throw new Error(`Failed to generate checksum for ${filePath}: ${err?.message}`);
    }
    return result;
  }
  async _cleanupTempFiles(tempDir) {
    const [ok] = await tryFn(
      () => import('fs/promises').then((fs) => fs.rm(tempDir, { recursive: true, force: true }))
    );
  }
  /**
   * Restore from backup
   * @param {string} backupId - Backup identifier
   * @param {Object} options - Restore options
   * @returns {Object} Restore result
   */
  async restore(backupId, options = {}) {
    try {
      if (this.config.onRestoreStart) {
        await this._executeHook(this.config.onRestoreStart, backupId, options);
      }
      this.emit("plg:backup:restore-start", { id: backupId, options });
      const backup = await this.getBackupStatus(backupId);
      if (!backup) {
        throw new Error(`Backup '${backupId}' not found`);
      }
      if (backup.status !== "completed") {
        throw new Error(`Backup '${backupId}' is not in completed status`);
      }
      const tempRestoreDir = path.join(this.config.tempDir, `restore-${backupId}`);
      await mkdir(tempRestoreDir, { recursive: true });
      try {
        const downloadPath = path.join(tempRestoreDir, `${backupId}.backup`);
        await this.driver.download(backupId, downloadPath, backup.driverInfo);
        if (this.config.verification && backup.checksum) {
          const actualChecksum = await this._generateChecksum(downloadPath);
          if (actualChecksum !== backup.checksum) {
            throw new Error("Backup verification failed during restore");
          }
        }
        const restoredResources = await this._restoreFromBackup(downloadPath, options);
        if (this.config.onRestoreComplete) {
          await this._executeHook(this.config.onRestoreComplete, backupId, { restored: restoredResources });
        }
        this.emit("plg:backup:restore-complete", {
          id: backupId,
          restored: restoredResources
        });
        return {
          backupId,
          restored: restoredResources
        };
      } finally {
        await this._cleanupTempFiles(tempRestoreDir);
      }
    } catch (error) {
      if (this.config.onRestoreError) {
        await this._executeHook(this.config.onRestoreError, backupId, { error });
      }
      this.emit("plg:backup:restore-error", { id: backupId, error: error.message });
      throw error;
    }
  }
  async _restoreFromBackup(backupPath, options) {
    const restoredResources = [];
    try {
      let archiveData = "";
      if (this.config.compression !== "none") {
        const input = createReadStream(backupPath);
        const gunzip = zlib.createGunzip();
        const chunks = [];
        await new Promise((resolve, reject) => {
          input.pipe(gunzip).on("data", (chunk) => chunks.push(chunk)).on("end", resolve).on("error", reject);
        });
        archiveData = Buffer.concat(chunks).toString("utf8");
      } else {
        archiveData = await readFile(backupPath, "utf8");
      }
      let archive;
      try {
        archive = JSON.parse(archiveData);
      } catch (parseError) {
        throw new Error(`Failed to parse backup archive: ${parseError.message}`);
      }
      if (!archive || typeof archive !== "object") {
        throw new Error("Invalid backup archive: not a valid JSON object");
      }
      if (!archive.version || !archive.files) {
        throw new Error("Invalid backup archive format: missing version or files array");
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Restoring ${archive.files.length} files from backup`);
      }
      for (const file of archive.files) {
        try {
          const resourceData = JSON.parse(file.content);
          if (!resourceData.resourceName || !resourceData.definition) {
            if (this.config.verbose) {
              console.warn(`[BackupPlugin] Skipping invalid file: ${file.name}`);
            }
            continue;
          }
          const resourceName = resourceData.resourceName;
          if (options.resources && !options.resources.includes(resourceName)) {
            continue;
          }
          let resource = this.database.resources[resourceName];
          if (!resource) {
            if (this.config.verbose) {
              console.log(`[BackupPlugin] Creating resource '${resourceName}'`);
            }
            const [createOk, createErr] = await tryFn(
              () => this.database.createResource(resourceData.definition)
            );
            if (!createOk) {
              if (this.config.verbose) {
                console.warn(`[BackupPlugin] Failed to create resource '${resourceName}': ${createErr?.message}`);
              }
              continue;
            }
            resource = this.database.resources[resourceName];
          }
          if (resourceData.records && Array.isArray(resourceData.records)) {
            const mode = options.mode || "merge";
            if (mode === "replace") {
              const ids = await resource.listIds();
              for (const id of ids) {
                await resource.delete(id);
              }
            }
            let insertedCount = 0;
            for (const record of resourceData.records) {
              const [insertOk] = await tryFn(async () => {
                if (mode === "skip") {
                  const existing = await resource.get(record.id);
                  if (existing) {
                    return false;
                  }
                }
                await resource.insert(record);
                return true;
              });
              if (insertOk) {
                insertedCount++;
              }
            }
            restoredResources.push({
              name: resourceName,
              recordsRestored: insertedCount,
              totalRecords: resourceData.records.length
            });
            if (this.config.verbose) {
              console.log(`[BackupPlugin] Restored ${insertedCount}/${resourceData.records.length} records to '${resourceName}'`);
            }
          }
        } catch (fileError) {
          if (this.config.verbose) {
            console.warn(`[BackupPlugin] Error processing file ${file.name}: ${fileError.message}`);
          }
        }
      }
      return restoredResources;
    } catch (error) {
      if (this.config.verbose) {
        console.error(`[BackupPlugin] Error restoring backup: ${error.message}`);
      }
      throw new Error(`Failed to restore backup: ${error.message}`);
    }
  }
  /**
   * List available backups
   * @param {Object} options - List options
   * @returns {Array} List of backups
   */
  async listBackups(options = {}) {
    try {
      const driverBackups = await this.driver.list(options);
      const [metaOk, , metadataRecords] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          limit: options.limit || 50,
          sort: { timestamp: -1 }
        })
      );
      const metadataMap = /* @__PURE__ */ new Map();
      if (metaOk) {
        metadataRecords.forEach((record) => metadataMap.set(record.id, record));
      }
      const combinedBackups = driverBackups.map((backup) => ({
        ...backup,
        ...metadataMap.get(backup.id) || {}
      }));
      return combinedBackups;
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Error listing backups: ${error.message}`);
      }
      return [];
    }
  }
  /**
   * Get backup status
   * @param {string} backupId - Backup identifier
   * @returns {Object|null} Backup status
   */
  async getBackupStatus(backupId) {
    const [ok, , backup] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].get(backupId)
    );
    return ok ? backup : null;
  }
  async _cleanupOldBackups() {
    try {
      const [listOk, , allBackups] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          filter: { status: "completed" },
          sort: { timestamp: -1 }
        })
      );
      if (!listOk || !allBackups || allBackups.length === 0) {
        return;
      }
      const now = Date.now();
      const msPerDay = 24 * 60 * 60 * 1e3;
      const msPerWeek = 7 * msPerDay;
      const msPerMonth = 30 * msPerDay;
      const msPerYear = 365 * msPerDay;
      const categorized = {
        daily: [],
        weekly: [],
        monthly: [],
        yearly: []
      };
      for (const backup of allBackups) {
        const age = now - backup.timestamp;
        if (age <= msPerDay * this.config.retention.daily) {
          categorized.daily.push(backup);
        } else if (age <= msPerWeek * this.config.retention.weekly) {
          categorized.weekly.push(backup);
        } else if (age <= msPerMonth * this.config.retention.monthly) {
          categorized.monthly.push(backup);
        } else if (age <= msPerYear * this.config.retention.yearly) {
          categorized.yearly.push(backup);
        }
      }
      const toKeep = /* @__PURE__ */ new Set();
      categorized.daily.forEach((b) => toKeep.add(b.id));
      const weeklyByWeek = /* @__PURE__ */ new Map();
      for (const backup of categorized.weekly) {
        const weekNum = Math.floor((now - backup.timestamp) / msPerWeek);
        if (!weeklyByWeek.has(weekNum)) {
          weeklyByWeek.set(weekNum, backup);
          toKeep.add(backup.id);
        }
      }
      const monthlyByMonth = /* @__PURE__ */ new Map();
      for (const backup of categorized.monthly) {
        const monthNum = Math.floor((now - backup.timestamp) / msPerMonth);
        if (!monthlyByMonth.has(monthNum)) {
          monthlyByMonth.set(monthNum, backup);
          toKeep.add(backup.id);
        }
      }
      const yearlyByYear = /* @__PURE__ */ new Map();
      for (const backup of categorized.yearly) {
        const yearNum = Math.floor((now - backup.timestamp) / msPerYear);
        if (!yearlyByYear.has(yearNum)) {
          yearlyByYear.set(yearNum, backup);
          toKeep.add(backup.id);
        }
      }
      const backupsToDelete = allBackups.filter((b) => !toKeep.has(b.id));
      if (backupsToDelete.length === 0) {
        return;
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Cleaning up ${backupsToDelete.length} old backups (keeping ${toKeep.size})`);
      }
      for (const backup of backupsToDelete) {
        try {
          await this.driver.delete(backup.id, backup.driverInfo);
          await this.database.resources[this.config.backupMetadataResource].delete(backup.id);
          if (this.config.verbose) {
            console.log(`[BackupPlugin] Deleted old backup: ${backup.id}`);
          }
        } catch (deleteError) {
          if (this.config.verbose) {
            console.warn(`[BackupPlugin] Failed to delete backup ${backup.id}: ${deleteError.message}`);
          }
        }
      }
    } catch (error) {
      if (this.config.verbose) {
        console.warn(`[BackupPlugin] Error during cleanup: ${error.message}`);
      }
    }
  }
  async _executeHook(hook, ...args) {
    if (typeof hook === "function") {
      return await hook(...args);
    }
  }
  async start() {
    if (this.config.verbose) {
      const storageInfo = this.driver.getStorageInfo();
      console.log(`[BackupPlugin] Started with driver: ${storageInfo.type}`);
    }
  }
  async stop() {
    for (const backupId of this.activeBackups) {
      this.emit("plg:backup:cancelled", { id: backupId });
    }
    this.activeBackups.clear();
    if (this.driver) {
      await this.driver.cleanup();
    }
  }
}

class CacheError extends S3dbError {
  constructor(message, details = {}) {
    const { driver = "unknown", operation = "unknown", resourceName, key, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Cache Operation Error

Driver: ${driver}
Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}
${key ? `Key: ${key}` : ""}

Common causes:
1. Invalid cache key format
2. Cache driver not properly initialized
3. Resource not found or not cached
4. Memory limits exceeded
5. Filesystem permissions issues

Solution:
Check cache configuration and ensure the cache driver is properly initialized.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/cache.md
`.trim();
    }
    super(message, { ...rest, driver, operation, resourceName, key, description });
  }
}

class Cache extends EventEmitter {
  constructor(config = {}) {
    super();
    this.config = config;
  }
  // to implement:
  async _set(key, data) {
  }
  async _get(key) {
  }
  async _del(key) {
  }
  async _clear(key) {
  }
  validateKey(key) {
    if (key === null || key === void 0 || typeof key !== "string" || !key) {
      throw new CacheError("Invalid cache key", {
        operation: "validateKey",
        driver: this.constructor.name,
        key,
        keyType: typeof key,
        suggestion: "Cache key must be a non-empty string"
      });
    }
  }
  // generic class methods
  async set(key, data) {
    this.validateKey(key);
    await this._set(key, data);
    this.emit("set", { key, value: data });
    return data;
  }
  async get(key) {
    this.validateKey(key);
    const data = await this._get(key);
    this.emit("fetched", { key, value: data });
    return data;
  }
  async del(key) {
    this.validateKey(key);
    const data = await this._del(key);
    this.emit("deleted", { key, value: data });
    return data;
  }
  async delete(key) {
    return this.del(key);
  }
  async clear(prefix) {
    const data = await this._clear(prefix);
    this.emit("clear", { prefix, value: data });
    return data;
  }
  stats() {
    return typeof this.getStats === "function" ? this.getStats() : {};
  }
}

class S3Cache extends Cache {
  constructor({
    client,
    keyPrefix = "cache",
    ttl = 0,
    prefix = void 0,
    enableCompression = true,
    compressionThreshold = 1024
  }) {
    super();
    this.client = client;
    this.keyPrefix = keyPrefix;
    this.ttlMs = typeof ttl === "number" && ttl > 0 ? ttl : 0;
    this.ttlSeconds = this.ttlMs > 0 ? Math.ceil(this.ttlMs / 1e3) : 0;
    this.config.ttl = this.ttlMs;
    this.config.client = client;
    this.config.prefix = prefix !== void 0 ? prefix : keyPrefix + (keyPrefix.endsWith("/") ? "" : "/");
    this.config.enableCompression = enableCompression;
    this.config.compressionThreshold = compressionThreshold;
    this.storage = new PluginStorage(client, "cache");
  }
  /**
   * Compress data if enabled and above threshold
   * @private
   */
  _compressData(data) {
    const jsonString = JSON.stringify(data);
    if (!this.config.enableCompression || jsonString.length < this.config.compressionThreshold) {
      return {
        data: jsonString,
        compressed: false,
        originalSize: jsonString.length
      };
    }
    const compressed = zlib.gzipSync(jsonString).toString("base64");
    return {
      data: compressed,
      compressed: true,
      originalSize: jsonString.length,
      compressedSize: compressed.length,
      compressionRatio: (compressed.length / jsonString.length).toFixed(2)
    };
  }
  /**
   * Decompress data if needed
   * @private
   */
  _decompressData(storedData) {
    if (!storedData || !storedData.compressed) {
      return storedData && storedData.data ? JSON.parse(storedData.data) : null;
    }
    const buffer = Buffer.from(storedData.data, "base64");
    const decompressed = zlib.unzipSync(buffer).toString();
    return JSON.parse(decompressed);
  }
  async _set(key, data) {
    const compressed = this._compressData(data);
    return this.storage.set(
      this.storage.getPluginKey(null, this.keyPrefix, key),
      compressed,
      {
        ttl: this.ttlSeconds,
        behavior: "body-only",
        // Compressed data is already optimized, skip metadata encoding
        contentType: compressed.compressed ? "application/gzip" : "application/json"
      }
    );
  }
  async _get(key) {
    const storedData = await this.storage.get(
      this.storage.getPluginKey(null, this.keyPrefix, key)
    );
    if (!storedData) return null;
    return this._decompressData(storedData);
  }
  async _del(key) {
    await this.storage.delete(
      this.storage.getPluginKey(null, this.keyPrefix, key)
    );
    return true;
  }
  async _clear(prefix) {
    const basePrefix = `plugin=cache/${this.keyPrefix}`;
    const listPrefix = prefix ? `${basePrefix}/${prefix}` : basePrefix;
    const allKeys = await this.client.getAllKeys({ prefix: listPrefix });
    for (const key of allKeys) {
      if (!prefix || key.startsWith(`${basePrefix}/${prefix}`)) {
        await this.storage.delete(key);
      }
    }
    return true;
  }
  async size() {
    const keys = await this.keys();
    return keys.length;
  }
  async keys() {
    const pluginPrefix = `plugin=cache/${this.keyPrefix}`;
    const allKeys = await this.client.getAllKeys({ prefix: pluginPrefix });
    const prefixToRemove = `plugin=cache/${this.keyPrefix}/`;
    return allKeys.map((k) => k.startsWith(prefixToRemove) ? k.slice(prefixToRemove.length) : k);
  }
}

class MemoryCache extends Cache {
  constructor(config = {}) {
    super(config);
    this.caseSensitive = config.caseSensitive !== void 0 ? config.caseSensitive : true;
    this.serializer = typeof config.serializer === "function" ? config.serializer : JSON.stringify;
    const defaultDeserializer = (str) => {
      return JSON.parse(str, (key, value) => {
        if (typeof value === "string" && /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z$/.test(value)) {
          return new Date(value);
        }
        return value;
      });
    };
    this.deserializer = typeof config.deserializer === "function" ? config.deserializer : defaultDeserializer;
    this.enableStats = config.enableStats === true;
    this.evictionPolicy = (config.evictionPolicy || "fifo").toLowerCase();
    if (!["lru", "fifo"].includes(this.evictionPolicy)) {
      this.evictionPolicy = "fifo";
    }
    this.cache = {};
    this.meta = {};
    this.maxSize = config.maxSize !== void 0 ? config.maxSize : 1e3;
    if (config.maxMemoryBytes && config.maxMemoryBytes > 0 && config.maxMemoryPercent && config.maxMemoryPercent > 0) {
      throw new CacheError("[MemoryCache] Cannot use both maxMemoryBytes and maxMemoryPercent", {
        driver: "memory",
        operation: "constructor",
        statusCode: 400,
        retriable: false,
        suggestion: "Choose either maxMemoryBytes or maxMemoryPercent to limit memory usage."
      });
    }
    if (config.maxMemoryPercent && config.maxMemoryPercent > 0) {
      if (config.maxMemoryPercent > 1) {
        throw new CacheError("[MemoryCache] maxMemoryPercent must be between 0 and 1", {
          driver: "memory",
          operation: "constructor",
          statusCode: 400,
          retriable: false,
          suggestion: "Provide a fraction between 0 and 1 (e.g., 0.1 for 10%).",
          maxMemoryPercent: config.maxMemoryPercent
        });
      }
      const totalMemory = os$1.totalmem();
      this.maxMemoryBytes = Math.floor(totalMemory * config.maxMemoryPercent);
      this.maxMemoryPercent = config.maxMemoryPercent;
    } else {
      this.maxMemoryBytes = config.maxMemoryBytes !== void 0 ? config.maxMemoryBytes : 0;
      this.maxMemoryPercent = 0;
    }
    this.ttl = config.ttl !== void 0 ? config.ttl : 3e5;
    this.enableCompression = config.enableCompression !== void 0 ? config.enableCompression : false;
    this.compressionThreshold = config.compressionThreshold !== void 0 ? config.compressionThreshold : 1024;
    this.compressionStats = {
      totalCompressed: 0,
      totalOriginalSize: 0,
      totalCompressedSize: 0,
      compressionRatio: 0
    };
    this.currentMemoryBytes = 0;
    this.evictedDueToMemory = 0;
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      evictions: 0
    };
  }
  _normalizeKey(key) {
    return this.caseSensitive ? key : key.toLowerCase();
  }
  _recordStat(type) {
    if (!this.enableStats) return;
    if (Object.prototype.hasOwnProperty.call(this.stats, type)) {
      this.stats[type] += 1;
    }
  }
  _selectEvictionCandidate() {
    const entries = Object.entries(this.meta);
    if (entries.length === 0) {
      return null;
    }
    if (this.evictionPolicy === "lru") {
      entries.sort((a, b) => (a[1].lastAccess ?? a[1].ts) - (b[1].lastAccess ?? b[1].ts));
    } else {
      entries.sort((a, b) => (a[1].createdAt ?? a[1].ts) - (b[1].createdAt ?? b[1].ts));
    }
    return entries[0]?.[0] || null;
  }
  async _set(key, data) {
    const normalizedKey = this._normalizeKey(key);
    let serialized;
    try {
      serialized = this.serializer(data);
    } catch (error) {
      throw new CacheError(`Failed to serialize data for key '${key}'`, {
        driver: "memory",
        operation: "set",
        statusCode: 500,
        retriable: false,
        suggestion: "Ensure the custom serializer handles the provided data type.",
        key,
        original: error
      });
    }
    let finalData = serialized;
    let compressed = false;
    let originalSize = 0;
    let compressedSize = 0;
    if (typeof serialized !== "string") {
      throw new CacheError("MemoryCache serializer must return a string", {
        driver: "memory",
        operation: "set",
        statusCode: 500,
        retriable: false,
        suggestion: "Update the custom serializer to return a string output."
      });
    }
    originalSize = Buffer.byteLength(serialized, "utf8");
    if (this.enableCompression) {
      try {
        if (originalSize >= this.compressionThreshold) {
          const compressedBuffer = zlib.gzipSync(Buffer.from(serialized, "utf8"));
          finalData = {
            __compressed: true,
            __data: compressedBuffer.toString("base64"),
            __originalSize: originalSize
          };
          compressedSize = Buffer.byteLength(finalData.__data, "utf8");
          compressed = true;
          this.compressionStats.totalCompressed++;
          this.compressionStats.totalOriginalSize += originalSize;
          this.compressionStats.totalCompressedSize += compressedSize;
          this.compressionStats.compressionRatio = (this.compressionStats.totalCompressedSize / this.compressionStats.totalOriginalSize).toFixed(2);
        }
      } catch (error) {
        console.warn(`[MemoryCache] Compression failed for key '${key}':`, error.message);
      }
    }
    const itemSize = compressed ? compressedSize : originalSize;
    if (Object.prototype.hasOwnProperty.call(this.cache, normalizedKey)) {
      const oldSize = this.meta[normalizedKey]?.compressedSize || 0;
      this.currentMemoryBytes -= oldSize;
    }
    if (this.maxMemoryBytes > 0) {
      if (itemSize > this.maxMemoryBytes) {
        return data;
      }
      while (this.currentMemoryBytes + itemSize > this.maxMemoryBytes && Object.keys(this.cache).length > 0) {
        const candidate = this._selectEvictionCandidate();
        if (!candidate) break;
        const evictedSize = this.meta[candidate]?.compressedSize || 0;
        delete this.cache[candidate];
        delete this.meta[candidate];
        this.currentMemoryBytes -= evictedSize;
        this.evictedDueToMemory++;
        this._recordStat("evictions");
      }
    }
    if (this.maxSize > 0 && Object.keys(this.cache).length >= this.maxSize) {
      const candidate = this._selectEvictionCandidate();
      if (candidate) {
        const evictedSize = this.meta[candidate]?.compressedSize || 0;
        delete this.cache[candidate];
        delete this.meta[candidate];
        this.currentMemoryBytes -= evictedSize;
        this._recordStat("evictions");
      }
    }
    this.cache[normalizedKey] = finalData;
    const timestamp = Date.now();
    this.meta[normalizedKey] = {
      ts: timestamp,
      createdAt: timestamp,
      lastAccess: timestamp,
      compressed,
      originalSize,
      compressedSize: itemSize,
      originalKey: key
    };
    this.currentMemoryBytes += itemSize;
    this._recordStat("sets");
    return data;
  }
  async _get(key) {
    const normalizedKey = this._normalizeKey(key);
    if (!Object.prototype.hasOwnProperty.call(this.cache, normalizedKey)) {
      this._recordStat("misses");
      return null;
    }
    if (this.ttl > 0) {
      const now = Date.now();
      const meta = this.meta[normalizedKey];
      if (meta && now - (meta.createdAt ?? meta.ts) > this.ttl) {
        const itemSize = meta.compressedSize || 0;
        this.currentMemoryBytes -= itemSize;
        delete this.cache[normalizedKey];
        delete this.meta[normalizedKey];
        this._recordStat("misses");
        return null;
      }
    }
    const rawData = this.cache[normalizedKey];
    if (rawData && typeof rawData === "object" && rawData.__compressed) {
      try {
        const compressedBuffer = Buffer.from(rawData.__data, "base64");
        const decompressed = zlib.gunzipSync(compressedBuffer).toString("utf8");
        const value = this.deserializer(decompressed);
        this._recordStat("hits");
        if (this.evictionPolicy === "lru" && this.meta[normalizedKey]) {
          this.meta[normalizedKey].lastAccess = Date.now();
        }
        return value;
      } catch (error) {
        console.warn(`[MemoryCache] Decompression failed for key '${key}':`, error.message);
        delete this.cache[normalizedKey];
        delete this.meta[normalizedKey];
        this._recordStat("misses");
        return null;
      }
    }
    try {
      const value = typeof rawData === "string" ? this.deserializer(rawData) : rawData;
      this._recordStat("hits");
      if (this.evictionPolicy === "lru" && this.meta[normalizedKey]) {
        this.meta[normalizedKey].lastAccess = Date.now();
      }
      return value;
    } catch (error) {
      console.warn(`[MemoryCache] Deserialization failed for key '${key}':`, error.message);
      delete this.cache[normalizedKey];
      delete this.meta[normalizedKey];
      this._recordStat("misses");
      return null;
    }
  }
  async _del(key) {
    const normalizedKey = this._normalizeKey(key);
    if (Object.prototype.hasOwnProperty.call(this.cache, normalizedKey)) {
      const itemSize = this.meta[normalizedKey]?.compressedSize || 0;
      this.currentMemoryBytes -= itemSize;
    }
    delete this.cache[normalizedKey];
    delete this.meta[normalizedKey];
    this._recordStat("deletes");
    return true;
  }
  async _clear(prefix) {
    if (!prefix) {
      this.cache = {};
      this.meta = {};
      this.currentMemoryBytes = 0;
      this.evictedDueToMemory = 0;
      if (this.enableStats) {
        this.stats = { hits: 0, misses: 0, sets: 0, deletes: 0, evictions: 0 };
      }
      return true;
    }
    const normalizedPrefix = this._normalizeKey(prefix);
    for (const key of Object.keys(this.cache)) {
      if (key.startsWith(normalizedPrefix)) {
        const itemSize = this.meta[key]?.compressedSize || 0;
        this.currentMemoryBytes -= itemSize;
        delete this.cache[key];
        delete this.meta[key];
      }
    }
    return true;
  }
  async size() {
    return Object.keys(this.cache).length;
  }
  async keys() {
    return Object.keys(this.cache).map((key) => this.meta[key]?.originalKey || key);
  }
  getStats() {
    if (!this.enableStats) {
      return { enabled: false };
    }
    const total = this.stats.hits + this.stats.misses;
    const hitRate = total > 0 ? this.stats.hits / total : 0;
    return {
      ...this.stats,
      memoryUsageBytes: this.currentMemoryBytes,
      maxMemoryBytes: this.maxMemoryBytes,
      evictedDueToMemory: this.evictedDueToMemory,
      hitRate
    };
  }
  /**
   * Get compression statistics
   * @returns {Object} Compression stats including total compressed items, ratios, and space savings
   */
  getCompressionStats() {
    if (!this.enableCompression) {
      return { enabled: false, message: "Compression is disabled" };
    }
    const spaceSavings = this.compressionStats.totalOriginalSize > 0 ? ((this.compressionStats.totalOriginalSize - this.compressionStats.totalCompressedSize) / this.compressionStats.totalOriginalSize * 100).toFixed(2) : 0;
    return {
      enabled: true,
      totalItems: Object.keys(this.cache).length,
      compressedItems: this.compressionStats.totalCompressed,
      compressionThreshold: this.compressionThreshold,
      totalOriginalSize: this.compressionStats.totalOriginalSize,
      totalCompressedSize: this.compressionStats.totalCompressedSize,
      averageCompressionRatio: this.compressionStats.compressionRatio,
      spaceSavingsPercent: spaceSavings,
      memoryUsage: {
        uncompressed: `${(this.compressionStats.totalOriginalSize / 1024).toFixed(2)} KB`,
        compressed: `${(this.compressionStats.totalCompressedSize / 1024).toFixed(2)} KB`,
        saved: `${((this.compressionStats.totalOriginalSize - this.compressionStats.totalCompressedSize) / 1024).toFixed(2)} KB`
      }
    };
  }
  /**
   * Get memory usage statistics
   * @returns {Object} Memory stats including current usage, limits, and eviction counts
   */
  getMemoryStats() {
    const totalItems = Object.keys(this.cache).length;
    const memoryUsagePercent = this.maxMemoryBytes > 0 ? (this.currentMemoryBytes / this.maxMemoryBytes * 100).toFixed(2) : 0;
    const systemMemory = {
      total: os$1.totalmem(),
      free: os$1.freemem(),
      used: os$1.totalmem() - os$1.freemem()
    };
    const cachePercentOfTotal = systemMemory.total > 0 ? (this.currentMemoryBytes / systemMemory.total * 100).toFixed(2) : 0;
    return {
      currentMemoryBytes: this.currentMemoryBytes,
      maxMemoryBytes: this.maxMemoryBytes,
      maxMemoryPercent: this.maxMemoryPercent,
      memoryUsagePercent: parseFloat(memoryUsagePercent),
      cachePercentOfSystemMemory: parseFloat(cachePercentOfTotal),
      totalItems,
      maxSize: this.maxSize,
      evictedDueToMemory: this.evictedDueToMemory,
      averageItemSize: totalItems > 0 ? Math.round(this.currentMemoryBytes / totalItems) : 0,
      memoryUsage: {
        current: this._formatBytes(this.currentMemoryBytes),
        max: this.maxMemoryBytes > 0 ? this._formatBytes(this.maxMemoryBytes) : "unlimited",
        available: this.maxMemoryBytes > 0 ? this._formatBytes(this.maxMemoryBytes - this.currentMemoryBytes) : "unlimited"
      },
      systemMemory: {
        total: this._formatBytes(systemMemory.total),
        free: this._formatBytes(systemMemory.free),
        used: this._formatBytes(systemMemory.used),
        cachePercent: `${cachePercentOfTotal}%`
      }
    };
  }
  /**
   * Format bytes to human-readable format
   * @private
   */
  _formatBytes(bytes) {
    if (bytes === 0) return "0 B";
    const k = 1024;
    const sizes = ["B", "KB", "MB", "GB"];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return `${(bytes / Math.pow(k, i)).toFixed(2)} ${sizes[i]}`;
  }
}

const gzip = promisify(zlib.gzip);
const unzip = promisify(zlib.unzip);
class RedisCache extends Cache {
  constructor({
    host = "localhost",
    port = 6379,
    password,
    db = 0,
    keyPrefix = "cache",
    ttl = 36e5,
    enableCompression = true,
    compressionThreshold = 1024,
    connectTimeout = 5e3,
    commandTimeout = 5e3,
    retryAttempts = 3,
    retryDelay = 1e3,
    lazyConnect = true,
    keepAlive = true,
    keepAliveInitialDelay = 0,
    retryStrategy,
    enableStats = false,
    ...redisOptions
  }) {
    super();
    requirePluginDependency("ioredis", "RedisCache");
    this.config = {
      host,
      port,
      password,
      db,
      keyPrefix: keyPrefix.endsWith("/") ? keyPrefix : keyPrefix + "/",
      ttl,
      enableCompression,
      compressionThreshold,
      connectTimeout,
      commandTimeout,
      retryAttempts,
      retryDelay,
      lazyConnect,
      keepAlive,
      keepAliveInitialDelay,
      retryStrategy,
      enableStats,
      ...redisOptions
    };
    this.ttlMs = typeof ttl === "number" && ttl > 0 ? ttl : 0;
    this.ttlSeconds = this.ttlMs > 0 ? Math.ceil(this.ttlMs / 1e3) : 0;
    this.stats = {
      hits: 0,
      misses: 0,
      errors: 0,
      sets: 0,
      deletes: 0,
      enabled: enableStats
    };
    this.client = null;
    this.connected = false;
    this.connecting = false;
  }
  /**
   * Initialize Redis connection
   * @private
   */
  async _ensureConnection() {
    if (this.connected) return;
    if (this.connecting) {
      await new Promise((resolve) => {
        const check = setInterval(() => {
          if (this.connected || !this.connecting) {
            clearInterval(check);
            resolve();
          }
        }, 50);
      });
      return;
    }
    this.connecting = true;
    try {
      const Redis = (await import('ioredis')).default;
      this.client = new Redis({
        host: this.config.host,
        port: this.config.port,
        password: this.config.password,
        db: this.config.db,
        connectTimeout: this.config.connectTimeout,
        commandTimeout: this.config.commandTimeout,
        lazyConnect: this.config.lazyConnect,
        keepAlive: this.config.keepAlive,
        keepAliveInitialDelay: this.config.keepAliveInitialDelay,
        retryStrategy: this.config.retryStrategy || ((times) => {
          if (times > this.config.retryAttempts) {
            return null;
          }
          return Math.min(times * this.config.retryDelay, 5e3);
        }),
        ...this.config.redisOptions
      });
      if (this.config.lazyConnect) {
        await this.client.connect();
      }
      this.connected = true;
      this.connecting = false;
      this.client.on("error", (err) => {
        if (this.config.enableStats) {
          this.stats.errors++;
        }
        console.error("Redis connection error:", err);
      });
      this.client.on("close", () => {
        this.connected = false;
      });
      this.client.on("reconnecting", () => {
        this.connected = false;
        this.connecting = true;
      });
      this.client.on("ready", () => {
        this.connected = true;
        this.connecting = false;
      });
    } catch (error) {
      this.connecting = false;
      throw new CacheError("Failed to connect to Redis", {
        operation: "connect",
        driver: "RedisCache",
        config: {
          host: this.config.host,
          port: this.config.port,
          db: this.config.db
        },
        cause: error,
        suggestion: "Ensure Redis server is running and accessible. Install ioredis: npm install ioredis"
      });
    }
  }
  /**
   * Build full Redis key with prefix
   * @private
   */
  _getKey(key) {
    return `${this.config.keyPrefix}${key}`;
  }
  /**
   * Compress data if enabled and above threshold
   * @private
   */
  async _compressData(data) {
    const jsonString = JSON.stringify(data);
    if (!this.config.enableCompression || jsonString.length < this.config.compressionThreshold) {
      return {
        data: jsonString,
        compressed: false,
        originalSize: jsonString.length
      };
    }
    const compressed = await gzip(Buffer.from(jsonString, "utf-8"));
    return {
      data: compressed.toString("base64"),
      compressed: true,
      originalSize: jsonString.length,
      compressedSize: compressed.length,
      compressionRatio: (compressed.length / jsonString.length).toFixed(2)
    };
  }
  /**
   * Decompress data if needed
   * @private
   */
  async _decompressData(storedData) {
    if (!storedData) return null;
    const metadata = JSON.parse(storedData);
    if (!metadata.compressed) {
      return JSON.parse(metadata.data);
    }
    const buffer = Buffer.from(metadata.data, "base64");
    const decompressed = await unzip(buffer);
    return JSON.parse(decompressed.toString("utf-8"));
  }
  async _set(key, data) {
    await this._ensureConnection();
    try {
      const compressed = await this._compressData(data);
      const redisKey = this._getKey(key);
      const value = JSON.stringify(compressed);
      if (this.ttlSeconds > 0) {
        await this.client.setex(redisKey, this.ttlSeconds, value);
      } else {
        await this.client.set(redisKey, value);
      }
      if (this.config.enableStats) {
        this.stats.sets++;
      }
      return true;
    } catch (error) {
      if (this.config.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError("Failed to set cache value in Redis", {
        operation: "set",
        driver: "RedisCache",
        key,
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  async _get(key) {
    await this._ensureConnection();
    try {
      const redisKey = this._getKey(key);
      const value = await this.client.get(redisKey);
      if (!value) {
        if (this.config.enableStats) {
          this.stats.misses++;
        }
        return null;
      }
      if (this.config.enableStats) {
        this.stats.hits++;
      }
      return await this._decompressData(value);
    } catch (error) {
      if (this.config.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError("Failed to get cache value from Redis", {
        operation: "get",
        driver: "RedisCache",
        key,
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  async _del(key) {
    await this._ensureConnection();
    try {
      const redisKey = this._getKey(key);
      await this.client.del(redisKey);
      if (this.config.enableStats) {
        this.stats.deletes++;
      }
      return true;
    } catch (error) {
      if (this.config.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError("Failed to delete cache key from Redis", {
        operation: "delete",
        driver: "RedisCache",
        key,
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  async _clear(prefix) {
    await this._ensureConnection();
    try {
      const pattern = prefix ? `${this.config.keyPrefix}${prefix}*` : `${this.config.keyPrefix}*`;
      let cursor = "0";
      let deletedCount = 0;
      do {
        const [nextCursor, keys] = await this.client.scan(
          cursor,
          "MATCH",
          pattern,
          "COUNT",
          100
        );
        cursor = nextCursor;
        if (keys.length > 0) {
          await this.client.del(...keys);
          deletedCount += keys.length;
        }
      } while (cursor !== "0");
      if (this.config.enableStats) {
        this.stats.deletes += deletedCount;
      }
      return true;
    } catch (error) {
      if (this.config.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError("Failed to clear cache keys from Redis", {
        operation: "clear",
        driver: "RedisCache",
        prefix,
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  async size() {
    await this._ensureConnection();
    try {
      const pattern = `${this.config.keyPrefix}*`;
      let cursor = "0";
      let count = 0;
      do {
        const [nextCursor, keys] = await this.client.scan(
          cursor,
          "MATCH",
          pattern,
          "COUNT",
          100
        );
        cursor = nextCursor;
        count += keys.length;
      } while (cursor !== "0");
      return count;
    } catch (error) {
      throw new CacheError("Failed to get cache size from Redis", {
        operation: "size",
        driver: "RedisCache",
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  async keys() {
    await this._ensureConnection();
    try {
      const pattern = `${this.config.keyPrefix}*`;
      const allKeys = [];
      let cursor = "0";
      do {
        const [nextCursor, keys] = await this.client.scan(
          cursor,
          "MATCH",
          pattern,
          "COUNT",
          100
        );
        cursor = nextCursor;
        const cleanKeys = keys.map(
          (k) => k.startsWith(this.config.keyPrefix) ? k.slice(this.config.keyPrefix.length) : k
        );
        allKeys.push(...cleanKeys);
      } while (cursor !== "0");
      return allKeys;
    } catch (error) {
      throw new CacheError("Failed to get cache keys from Redis", {
        operation: "keys",
        driver: "RedisCache",
        cause: error,
        retriable: true,
        suggestion: "Check Redis connection and server status"
      });
    }
  }
  /**
   * Get cache statistics
   */
  getStats() {
    if (!this.stats.enabled) {
      return {
        enabled: false,
        message: "Statistics are disabled. Enable with enableStats: true"
      };
    }
    const total = this.stats.hits + this.stats.misses;
    const hitRate = total > 0 ? this.stats.hits / total : 0;
    return {
      enabled: true,
      hits: this.stats.hits,
      misses: this.stats.misses,
      errors: this.stats.errors,
      sets: this.stats.sets,
      deletes: this.stats.deletes,
      total,
      hitRate,
      hitRatePercent: (hitRate * 100).toFixed(2) + "%"
    };
  }
  /**
   * Disconnect from Redis
   */
  async disconnect() {
    if (this.client && this.connected) {
      await this.client.quit();
      this.connected = false;
      this.client = null;
    }
  }
}

class FilesystemCache extends Cache {
  constructor({
    directory,
    prefix = "cache",
    ttl = 36e5,
    enableCompression = true,
    compressionThreshold = 1024,
    createDirectory = true,
    fileExtension = ".cache",
    enableMetadata = true,
    maxFileSize = 10485760,
    // 10MB
    enableStats = false,
    enableCleanup = true,
    cleanupInterval = 3e5,
    // 5 minutes
    encoding = "utf8",
    fileMode = 420,
    enableBackup = false,
    backupSuffix = ".bak",
    enableLocking = false,
    lockTimeout = 5e3,
    enableJournal = false,
    journalFile = "cache.journal",
    ...config
  }) {
    super(config);
    if (!directory) {
      throw new CacheError("FilesystemCache requires a directory", {
        driver: "filesystem",
        operation: "constructor",
        statusCode: 400,
        retriable: false,
        suggestion: 'Pass { directory: "./cache" } or configure a valid cache directory before enabling FilesystemCache.'
      });
    }
    this.directory = path.resolve(directory);
    this.prefix = prefix;
    this.ttl = ttl;
    this.enableCompression = enableCompression;
    this.compressionThreshold = compressionThreshold;
    this.createDirectory = createDirectory;
    this.fileExtension = fileExtension;
    this.enableMetadata = enableMetadata;
    this.maxFileSize = maxFileSize;
    this.enableStats = enableStats;
    this.enableCleanup = enableCleanup;
    this.cleanupInterval = cleanupInterval;
    this.encoding = encoding;
    this.fileMode = fileMode;
    this.enableBackup = enableBackup;
    this.backupSuffix = backupSuffix;
    this.enableLocking = enableLocking;
    this.lockTimeout = lockTimeout;
    this.enableJournal = enableJournal;
    this.journalFile = path.join(this.directory, journalFile);
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      clears: 0,
      errors: 0
    };
    this.locks = /* @__PURE__ */ new Map();
    this.cleanupTimer = null;
    this._init();
  }
  async _init() {
    if (this.createDirectory) {
      await this._ensureDirectory(this.directory);
    }
    if (this.enableCleanup && this.cleanupInterval > 0) {
      this.cleanupTimer = setInterval(() => {
        this._cleanup().catch((err) => {
          console.warn("FilesystemCache cleanup error:", err.message);
        });
      }, this.cleanupInterval);
    }
  }
  async _ensureDirectory(dir) {
    const [ok, err] = await tryFn(async () => {
      await mkdir(dir, { recursive: true });
    });
    if (!ok && err.code !== "EEXIST") {
      throw new CacheError(`Failed to create cache directory: ${err.message}`, {
        driver: "filesystem",
        operation: "ensureDirectory",
        statusCode: 500,
        retriable: false,
        suggestion: "Check filesystem permissions and ensure the process can create directories.",
        directory: dir,
        original: err
      });
    }
  }
  _getFilePath(key) {
    const sanitizedKey = key.replace(/[<>:"/\\|?*]/g, "_");
    const filename = `${this.prefix}_${sanitizedKey}${this.fileExtension}`;
    return path.join(this.directory, filename);
  }
  _getMetadataPath(filePath) {
    return filePath + ".meta";
  }
  async _set(key, data) {
    const filePath = this._getFilePath(key);
    try {
      let serialized = JSON.stringify(data);
      const originalSize = Buffer.byteLength(serialized, this.encoding);
      if (originalSize > this.maxFileSize) {
        throw new CacheError("Cache data exceeds maximum file size", {
          driver: "filesystem",
          operation: "set",
          statusCode: 413,
          retriable: false,
          suggestion: "Increase maxFileSize or reduce the cached payload size.",
          key,
          size: originalSize,
          maxFileSize: this.maxFileSize
        });
      }
      let compressed = false;
      let finalData = serialized;
      if (this.enableCompression && originalSize >= this.compressionThreshold) {
        const compressedBuffer = zlib.gzipSync(Buffer.from(serialized, this.encoding));
        finalData = compressedBuffer.toString("base64");
        compressed = true;
      }
      const dir = path.dirname(filePath);
      await this._ensureDirectory(dir);
      if (this.enableBackup && await this._fileExists(filePath)) {
        const backupPath = filePath + this.backupSuffix;
        await this._copyFile(filePath, backupPath);
      }
      if (this.enableLocking) {
        await this._acquireLock(filePath);
      }
      try {
        await writeFile(filePath, finalData, {
          encoding: compressed ? "utf8" : this.encoding,
          mode: this.fileMode
        });
        if (this.enableMetadata) {
          const metadata = {
            key,
            timestamp: Date.now(),
            ttl: this.ttl,
            compressed,
            originalSize,
            compressedSize: compressed ? Buffer.byteLength(finalData, "utf8") : originalSize,
            compressionRatio: compressed ? (Buffer.byteLength(finalData, "utf8") / originalSize).toFixed(2) : 1
          };
          await writeFile(this._getMetadataPath(filePath), JSON.stringify(metadata), {
            encoding: this.encoding,
            mode: this.fileMode
          });
        }
        if (this.enableStats) {
          this.stats.sets++;
        }
        if (this.enableJournal) {
          await this._journalOperation("set", key, { size: originalSize, compressed });
        }
      } finally {
        if (this.enableLocking) {
          this._releaseLock(filePath);
        }
      }
      return data;
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError(`Failed to set cache key '${key}': ${error.message}`, {
        driver: "filesystem",
        operation: "set",
        statusCode: 500,
        retriable: false,
        suggestion: "Verify filesystem permissions and available disk space.",
        key,
        original: error
      });
    }
  }
  async _get(key) {
    const filePath = this._getFilePath(key);
    try {
      if (!await this._fileExists(filePath)) {
        if (this.enableStats) {
          this.stats.misses++;
        }
        return null;
      }
      let isExpired = false;
      if (this.enableMetadata) {
        const metadataPath = this._getMetadataPath(filePath);
        if (await this._fileExists(metadataPath)) {
          const [ok, err, metadata] = await tryFn(async () => {
            const metaContent = await readFile(metadataPath, this.encoding);
            return JSON.parse(metaContent);
          });
          if (ok && metadata.ttl > 0) {
            const age = Date.now() - metadata.timestamp;
            isExpired = age > metadata.ttl;
          }
        }
      } else if (this.ttl > 0) {
        const stats = await stat(filePath);
        const age = Date.now() - stats.mtime.getTime();
        isExpired = age > this.ttl;
      }
      if (isExpired) {
        await this._del(key);
        if (this.enableStats) {
          this.stats.misses++;
        }
        return null;
      }
      if (this.enableLocking) {
        await this._acquireLock(filePath);
      }
      try {
        const content = await readFile(filePath, this.encoding);
        let isCompressed = false;
        if (this.enableMetadata) {
          const metadataPath = this._getMetadataPath(filePath);
          if (await this._fileExists(metadataPath)) {
            const [ok, err, metadata] = await tryFn(async () => {
              const metaContent = await readFile(metadataPath, this.encoding);
              return JSON.parse(metaContent);
            });
            if (ok) {
              isCompressed = metadata.compressed;
            }
          }
        }
        let finalContent = content;
        if (isCompressed || this.enableCompression && content.match(/^[A-Za-z0-9+/=]+$/)) {
          try {
            const compressedBuffer = Buffer.from(content, "base64");
            finalContent = zlib.gunzipSync(compressedBuffer).toString(this.encoding);
          } catch (decompressError) {
            finalContent = content;
          }
        }
        const data = JSON.parse(finalContent);
        if (this.enableStats) {
          this.stats.hits++;
        }
        return data;
      } finally {
        if (this.enableLocking) {
          this._releaseLock(filePath);
        }
      }
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      await this._del(key);
      return null;
    }
  }
  async _del(key) {
    const filePath = this._getFilePath(key);
    try {
      if (await this._fileExists(filePath)) {
        await unlink(filePath);
      }
      if (this.enableMetadata) {
        const metadataPath = this._getMetadataPath(filePath);
        if (await this._fileExists(metadataPath)) {
          await unlink(metadataPath);
        }
      }
      if (this.enableBackup) {
        const backupPath = filePath + this.backupSuffix;
        if (await this._fileExists(backupPath)) {
          await unlink(backupPath);
        }
      }
      if (this.enableStats) {
        this.stats.deletes++;
      }
      if (this.enableJournal) {
        await this._journalOperation("delete", key);
      }
      return true;
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError(`Failed to delete cache key '${key}': ${error.message}`, {
        driver: "filesystem",
        operation: "delete",
        statusCode: 500,
        retriable: false,
        suggestion: "Ensure cache files are writable and not locked by another process.",
        key,
        original: error
      });
    }
  }
  async _clear(prefix) {
    try {
      if (!await this._fileExists(this.directory)) {
        if (this.enableStats) {
          this.stats.clears++;
        }
        return true;
      }
      const files = await readdir(this.directory);
      const cacheFiles = files.filter((file) => {
        if (!file.startsWith(this.prefix)) return false;
        if (!file.endsWith(this.fileExtension)) return false;
        if (prefix) {
          const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
          return keyPart.startsWith(prefix);
        }
        return true;
      });
      for (const file of cacheFiles) {
        const filePath = path.join(this.directory, file);
        try {
          if (await this._fileExists(filePath)) {
            await unlink(filePath);
          }
        } catch (error) {
          if (error.code !== "ENOENT") {
            throw error;
          }
        }
        if (this.enableMetadata) {
          try {
            const metadataPath = this._getMetadataPath(filePath);
            if (await this._fileExists(metadataPath)) {
              await unlink(metadataPath);
            }
          } catch (error) {
            if (error.code !== "ENOENT") {
              throw error;
            }
          }
        }
        if (this.enableBackup) {
          try {
            const backupPath = filePath + this.backupSuffix;
            if (await this._fileExists(backupPath)) {
              await unlink(backupPath);
            }
          } catch (error) {
            if (error.code !== "ENOENT") {
              throw error;
            }
          }
        }
      }
      if (this.enableStats) {
        this.stats.clears++;
      }
      if (this.enableJournal) {
        await this._journalOperation("clear", prefix || "all", { count: cacheFiles.length });
      }
      return true;
    } catch (error) {
      if (error.code === "ENOENT") {
        if (this.enableStats) {
          this.stats.clears++;
        }
        return true;
      }
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new CacheError(`Failed to clear cache: ${error.message}`, {
        driver: "filesystem",
        operation: "clear",
        statusCode: 500,
        retriable: false,
        suggestion: "Verify the cache directory is accessible and not in use by another process.",
        original: error
      });
    }
  }
  async size() {
    const keys = await this.keys();
    return keys.length;
  }
  async keys() {
    try {
      const files = await readdir(this.directory);
      const cacheFiles = files.filter(
        (file) => file.startsWith(this.prefix) && file.endsWith(this.fileExtension)
      );
      const keys = cacheFiles.map((file) => {
        const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
        return keyPart;
      });
      return keys;
    } catch (error) {
      console.warn("FilesystemCache: Failed to list keys:", error.message);
      return [];
    }
  }
  // Helper methods
  async _fileExists(filePath) {
    const [ok] = await tryFn(async () => {
      await stat(filePath);
    });
    return ok;
  }
  async _copyFile(src, dest) {
    const [ok, err] = await tryFn(async () => {
      const content = await readFile(src);
      await writeFile(dest, content);
    });
    if (!ok) {
      console.warn("FilesystemCache: Failed to create backup:", err.message);
    }
  }
  async _cleanup() {
    if (!this.ttl || this.ttl <= 0) return;
    try {
      const files = await readdir(this.directory);
      const now = Date.now();
      for (const file of files) {
        if (!file.startsWith(this.prefix) || !file.endsWith(this.fileExtension)) {
          continue;
        }
        const filePath = path.join(this.directory, file);
        let shouldDelete = false;
        if (this.enableMetadata) {
          const metadataPath = this._getMetadataPath(filePath);
          if (await this._fileExists(metadataPath)) {
            const [ok, err, metadata] = await tryFn(async () => {
              const metaContent = await readFile(metadataPath, this.encoding);
              return JSON.parse(metaContent);
            });
            if (ok && metadata.ttl > 0) {
              const age = now - metadata.timestamp;
              shouldDelete = age > metadata.ttl;
            }
          }
        } else {
          const [ok, err, stats] = await tryFn(async () => {
            return await stat(filePath);
          });
          if (ok) {
            const age = now - stats.mtime.getTime();
            shouldDelete = age > this.ttl;
          }
        }
        if (shouldDelete) {
          const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
          await this._del(keyPart);
        }
      }
    } catch (error) {
      console.warn("FilesystemCache cleanup error:", error.message);
    }
  }
  async _acquireLock(filePath) {
    if (!this.enableLocking) return;
    const lockKey = filePath;
    const startTime = Date.now();
    while (this.locks.has(lockKey)) {
      if (Date.now() - startTime > this.lockTimeout) {
        throw new CacheError(`Lock timeout for file: ${filePath}`, {
          driver: "filesystem",
          operation: "acquireLock",
          statusCode: 408,
          retriable: true,
          suggestion: "Increase lockTimeout or investigate long-running cache writes holding the lock.",
          key: lockKey
        });
      }
      await new Promise((resolve) => setTimeout(resolve, 10));
    }
    this.locks.set(lockKey, Date.now());
  }
  _releaseLock(filePath) {
    if (!this.enableLocking) return;
    this.locks.delete(filePath);
  }
  async _journalOperation(operation, key, metadata = {}) {
    if (!this.enableJournal) return;
    const entry = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      operation,
      key,
      metadata
    };
    const [ok, err] = await tryFn(async () => {
      const line = JSON.stringify(entry) + "\n";
      await fs__default.promises.appendFile(this.journalFile, line, this.encoding);
    });
    if (!ok) {
      console.warn("FilesystemCache journal error:", err.message);
    }
  }
  // Cleanup on process exit
  destroy() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
  }
  // Get cache statistics
  getStats() {
    return {
      ...this.stats,
      directory: this.directory,
      ttl: this.ttl,
      compression: this.enableCompression,
      metadata: this.enableMetadata,
      cleanup: this.enableCleanup,
      locking: this.enableLocking,
      journal: this.enableJournal
    };
  }
}

class PartitionAwareFilesystemCache extends FilesystemCache {
  constructor({
    partitionStrategy = "hierarchical",
    // 'hierarchical', 'flat', 'temporal'
    trackUsage = true,
    preloadRelated = false,
    preloadThreshold = 10,
    maxCacheSize = null,
    usageStatsFile = "partition-usage.json",
    ...config
  }) {
    super(config);
    this.partitionStrategy = partitionStrategy;
    this.trackUsage = trackUsage;
    this.preloadRelated = preloadRelated;
    this.preloadThreshold = preloadThreshold;
    this.maxCacheSize = maxCacheSize;
    this.usageStatsFile = path.join(this.directory, usageStatsFile);
    this.partitionUsage = /* @__PURE__ */ new Map();
    this.loadUsageStats();
  }
  /**
   * Generate partition-aware cache key
   */
  _getPartitionCacheKey(resource, action, partition, partitionValues = {}, params = {}) {
    const segments = [];
    if (resource) {
      segments.push(`resource=${this._sanitizePathValue(resource)}`);
    }
    if (partition) {
      segments.push(`partition=${this._sanitizePathValue(partition)}`);
      const sortedFields = Object.entries(partitionValues).filter(([, value]) => value !== null && value !== void 0).sort(([a], [b]) => a.localeCompare(b));
      for (const [field, value] of sortedFields) {
        segments.push(`${field}=${this._sanitizePathValue(value)}`);
      }
    }
    if (action) {
      segments.push(`action=${this._sanitizePathValue(action)}`);
    }
    if (Object.keys(params).length > 0) {
      const paramsStr = Object.entries(params).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}=${v}`).join("|");
      segments.push(`params=${this._sanitizePathValue(Buffer.from(paramsStr).toString("base64url"))}`);
    }
    return segments.join("/");
  }
  /**
   * Get directory path for partition cache
   */
  _getPartitionDirectory(resource, partition, partitionValues = {}) {
    const baseSegments = [];
    if (resource) {
      baseSegments.push(`resource=${this._sanitizePathValue(resource)}`);
    }
    if (!partition) {
      return path.join(this.directory, ...baseSegments);
    }
    if (this.partitionStrategy === "flat") {
      return path.join(this.directory, ...baseSegments, "partitions");
    }
    if (this.partitionStrategy === "temporal" && this._isTemporalPartition(partition, partitionValues)) {
      return this._getTemporalDirectory(path.join(this.directory, ...baseSegments), partition, partitionValues);
    }
    const pathParts = [
      this.directory,
      ...baseSegments,
      `partition=${this._sanitizePathValue(partition)}`
    ];
    const sortedFields = Object.entries(partitionValues).sort(([a], [b]) => a.localeCompare(b));
    for (const [field, value] of sortedFields) {
      if (value !== null && value !== void 0) {
        pathParts.push(`${field}=${this._sanitizePathValue(value)}`);
      }
    }
    return path.join(...pathParts);
  }
  /**
   * Enhanced set method with partition awareness
   */
  async _set(key, data, options = {}) {
    const { resource, action, partition, partitionValues, params } = options;
    if (resource && partition) {
      const partitionKey = this._getPartitionCacheKey(resource, action, partition, partitionValues, params);
      await this._ensurePartitionDirectoryForKey(partitionKey);
      if (this.trackUsage) {
        await this._trackPartitionUsage(resource, partition, partitionValues);
      }
      const payload = {
        data,
        metadata: {
          resource,
          partition,
          partitionValues,
          timestamp: Date.now(),
          ttl: this.ttl
        }
      };
      await super._set(partitionKey, payload);
      return data;
    }
    return super._set(key, data);
  }
  /**
   * Public set method with partition support
   */
  async set(resource, action, data, options = {}) {
    if (typeof resource === "string" && typeof action === "string" && options.partition) {
      const key = this._getPartitionCacheKey(resource, action, options.partition, options.partitionValues, options.params);
      return this._set(key, data, { resource, action, ...options });
    }
    return super.set(resource, action);
  }
  /**
   * Public get method with partition support
   */
  async get(resource, action, options = {}) {
    if (typeof resource === "string" && typeof action === "string" && options.partition) {
      const key = this._getPartitionCacheKey(resource, action, options.partition, options.partitionValues, options.params);
      return this._get(key, { resource, action, ...options });
    }
    return super.get(resource);
  }
  /**
   * Enhanced get method with partition awareness
   */
  async _get(key, options = {}) {
    const { resource, action, partition, partitionValues, params } = options;
    if (resource && partition) {
      const partitionKey = this._getPartitionCacheKey(resource, action, partition, partitionValues, params);
      const payload = await super._get(partitionKey);
      if (!payload) {
        if (this.preloadRelated) {
          await this._preloadRelatedPartitions(resource, partition, partitionValues);
        }
        return null;
      }
      if (this.trackUsage) {
        await this._trackPartitionUsage(resource, partition, partitionValues);
      }
      return payload?.data ?? null;
    }
    return super._get(key);
  }
  /**
   * Clear cache for specific partition
   */
  async clearPartition(resource, partition, partitionValues = {}) {
    const partitionDir = this._getPartitionDirectory(resource, partition, partitionValues);
    const [ok, err] = await tryFn(async () => {
      if (await this._fileExists(partitionDir)) {
        await rm(partitionDir, { recursive: true });
      }
    });
    if (!ok) {
      console.warn(`Failed to clear partition cache: ${err.message}`);
    }
    const usageKey = this._getUsageKey(resource, partition, partitionValues);
    this.partitionUsage.delete(usageKey);
    await this._saveUsageStats();
    return ok;
  }
  /**
   * Clear all partitions for a resource
   */
  async clearResourcePartitions(resource) {
    const resourceDir = path.join(this.directory, `resource=${resource}`);
    const [ok, err] = await tryFn(async () => {
      if (await this._fileExists(resourceDir)) {
        await rm(resourceDir, { recursive: true });
      }
    });
    for (const [key] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        this.partitionUsage.delete(key);
      }
    }
    await this._saveUsageStats();
    return ok;
  }
  async _clear(prefix) {
    await super._clear(prefix);
    if (!prefix) {
      const [entriesOk, , entries] = await tryFn(() => readdir(this.directory));
      if (entriesOk && entries) {
        for (const entry of entries) {
          const entryPath = path.join(this.directory, entry);
          const [statOk, , entryStat] = await tryFn(() => stat(entryPath));
          if (statOk && entryStat.isDirectory() && entry.startsWith("resource=")) {
            await rm(entryPath, { recursive: true }).catch(() => {
            });
          }
        }
      }
      this.partitionUsage.clear();
      await this._saveUsageStats();
      return true;
    }
    const segments = this._splitKeySegments(prefix).map((segment) => this._sanitizeFileName(segment));
    if (segments.length > 0) {
      const dirPath = path.join(this.directory, ...segments);
      if (await this._fileExists(dirPath)) {
        await rm(dirPath, { recursive: true }).catch(() => {
        });
      }
      const resourceSeg = segments.find((seg) => seg.startsWith("resource="));
      const partitionSeg = segments.find((seg) => seg.startsWith("partition="));
      const resourceVal = resourceSeg ? resourceSeg.split("=").slice(1).join("=") : "";
      const partitionVal = partitionSeg ? partitionSeg.split("=").slice(1).join("=") : "";
      const usagePrefix = `${resourceVal}/${partitionVal}`;
      for (const key of Array.from(this.partitionUsage.keys())) {
        if (key.startsWith(usagePrefix)) {
          this.partitionUsage.delete(key);
        }
      }
      await this._saveUsageStats();
    }
    return true;
  }
  /**
   * Get partition cache statistics
   */
  async getPartitionStats(resource, partition = null) {
    const stats = {
      totalFiles: 0,
      totalSize: 0,
      partitions: {},
      usage: {}
    };
    const resourceDir = path.join(this.directory, `resource=${resource}`);
    if (!await this._fileExists(resourceDir)) {
      return stats;
    }
    await this._calculateDirectoryStats(resourceDir, stats);
    for (const [key, usage] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        const partitionName = key.split("/")[1];
        if (!partition || partitionName === partition) {
          stats.usage[partitionName] = usage;
        }
      }
    }
    return stats;
  }
  /**
   * Get cache recommendations based on usage patterns
   */
  async getCacheRecommendations(resource) {
    const recommendations = [];
    const now = Date.now();
    const dayMs = 24 * 60 * 60 * 1e3;
    for (const [key, usage] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        const [, partition] = key.split("/");
        const daysSinceLastAccess = (now - usage.lastAccess) / dayMs;
        const accessesPerDay = usage.count / Math.max(1, daysSinceLastAccess);
        let recommendation = "keep";
        let priority = usage.count;
        if (daysSinceLastAccess > 30) {
          recommendation = "archive";
          priority = 0;
        } else if (accessesPerDay < 0.1) {
          recommendation = "reduce_ttl";
          priority = 1;
        } else if (accessesPerDay > 10) {
          recommendation = "preload";
          priority = 100;
        }
        recommendations.push({
          partition,
          recommendation,
          priority,
          usage: accessesPerDay,
          lastAccess: new Date(usage.lastAccess).toISOString()
        });
      }
    }
    return recommendations.sort((a, b) => b.priority - a.priority);
  }
  /**
   * Preload frequently accessed partitions
   */
  async warmPartitionCache(resource, options = {}) {
    const { partitions = [], maxFiles = 1e3 } = options;
    let warmedCount = 0;
    for (const partition of partitions) {
      const usageKey = `${resource}/${partition}`;
      const usage = this.partitionUsage.get(usageKey);
      if (usage && usage.count >= this.preloadThreshold) {
        console.log(`\u{1F525} Warming cache for ${resource}/${partition} (${usage.count} accesses)`);
        warmedCount++;
      }
      if (warmedCount >= maxFiles) break;
    }
    return warmedCount;
  }
  // Private helper methods
  async _trackPartitionUsage(resource, partition, partitionValues) {
    const usageKey = this._getUsageKey(resource, partition, partitionValues);
    const current = this.partitionUsage.get(usageKey) || {
      count: 0,
      firstAccess: Date.now(),
      lastAccess: Date.now()
    };
    current.count++;
    current.lastAccess = Date.now();
    this.partitionUsage.set(usageKey, current);
    if (current.count % 10 === 0) {
      await this._saveUsageStats();
    }
  }
  _getUsageKey(resource, partition, partitionValues) {
    const sanitizedResource = this._sanitizePathValue(resource || "");
    const sanitizedPartition = this._sanitizePathValue(partition || "");
    const valuePart = Object.entries(partitionValues).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}=${this._sanitizePathValue(v)}`).join("|");
    return `${sanitizedResource}/${sanitizedPartition}/${valuePart}`;
  }
  async _preloadRelatedPartitions(resource, partition, partitionValues) {
    console.log(`\u{1F3AF} Preloading related partitions for ${resource}/${partition}`);
    if (partitionValues.timestamp || partitionValues.date) ;
  }
  _isTemporalPartition(partition, partitionValues) {
    const temporalFields = ["date", "timestamp", "createdAt", "updatedAt"];
    return Object.keys(partitionValues).some(
      (field) => temporalFields.some((tf) => field.toLowerCase().includes(tf))
    );
  }
  _getTemporalDirectory(basePath, partition, partitionValues) {
    const dateValue = Object.values(partitionValues)[0];
    if (typeof dateValue === "string" && dateValue.match(/^\d{4}-\d{2}-\d{2}/)) {
      const [year, month, day] = dateValue.split("-");
      return path.join(basePath, "temporal", year, month, day);
    }
    return path.join(basePath, `partition=${partition}`);
  }
  _sanitizePathValue(value) {
    return String(value).replace(/[<>:"/\\|?*]/g, "_");
  }
  _sanitizeFileName(filename) {
    return filename.replace(/[<>:"/\\|?*]/g, "_");
  }
  _splitKeySegments(key) {
    return key.split("/").filter(Boolean);
  }
  async _ensurePartitionDirectoryForKey(key) {
    const segments = this._splitKeySegments(key);
    if (segments.length <= 1) {
      return;
    }
    const dirPath = path.join(
      this.directory,
      ...segments.slice(0, -1).map((segment) => this._sanitizeFileName(segment))
    );
    await this._ensureDirectory(dirPath);
  }
  _getFilePath(key) {
    const segments = this._splitKeySegments(key).map((segment) => this._sanitizeFileName(segment));
    const fileName = segments.pop() || this._sanitizeFileName(key);
    const dirPath = segments.length > 0 ? path.join(this.directory, ...segments) : this.directory;
    return path.join(dirPath, `${this.prefix}_${fileName}${this.fileExtension}`);
  }
  async _calculateDirectoryStats(dir, stats) {
    const [ok, err, files] = await tryFn(() => readdir(dir));
    if (!ok) return;
    for (const file of files) {
      const filePath = path.join(dir, file);
      const [statOk, statErr, fileStat] = await tryFn(() => stat(filePath));
      if (statOk) {
        if (fileStat.isDirectory()) {
          await this._calculateDirectoryStats(filePath, stats);
        } else {
          stats.totalFiles++;
          stats.totalSize += fileStat.size;
        }
      }
    }
  }
  async loadUsageStats() {
    const [ok, err, content] = await tryFn(async () => {
      const data = await readFile(this.usageStatsFile, "utf8");
      return JSON.parse(data);
    });
    if (ok && content) {
      this.partitionUsage = new Map(Object.entries(content));
    }
  }
  async _saveUsageStats() {
    const statsObject = Object.fromEntries(this.partitionUsage);
    await tryFn(async () => {
      await writeFile(
        this.usageStatsFile,
        JSON.stringify(statsObject, null, 2),
        "utf8"
      );
    });
  }
  async _writeFileWithMetadata(filePath, data) {
    const content = JSON.stringify(data);
    const [ok, err] = await tryFn(async () => {
      await writeFile(filePath, content, {
        encoding: this.encoding,
        mode: this.fileMode
      });
    });
    if (!ok) {
      throw new CacheError(`Failed to write cache file: ${err.message}`, {
        driver: "filesystem-partitioned",
        operation: "writeFileWithMetadata",
        statusCode: 500,
        retriable: false,
        suggestion: "Check filesystem permissions and disk space for the partition-aware cache directory.",
        filePath,
        original: err
      });
    }
    return true;
  }
  async _readFileWithMetadata(filePath) {
    const [ok, err, content] = await tryFn(async () => {
      return await readFile(filePath, this.encoding);
    });
    if (!ok || !content) return null;
    try {
      return JSON.parse(content);
    } catch (error) {
      return { data: content };
    }
  }
}

class MultiTierCache extends Cache {
  constructor({
    drivers = [],
    promoteOnHit = true,
    strategy = "write-through",
    // 'write-through' | 'lazy-promotion'
    fallbackOnError = true,
    verbose = false
  }) {
    super();
    if (!Array.isArray(drivers) || drivers.length === 0) {
      throw new CacheError("MultiTierCache requires at least one driver", {
        operation: "constructor",
        driver: "MultiTierCache",
        provided: drivers,
        suggestion: "Pass drivers array with at least one cache driver instance"
      });
    }
    this.drivers = drivers.map((d, index) => ({
      instance: d.driver,
      name: d.name || `L${index + 1}`,
      tier: index + 1
    }));
    this.config = {
      promoteOnHit,
      strategy,
      fallbackOnError,
      verbose
    };
    this.stats = {
      enabled: true,
      tiers: this.drivers.map((d) => ({
        name: d.name,
        hits: 0,
        misses: 0,
        promotions: 0,
        errors: 0,
        sets: 0
      }))
    };
  }
  /**
   * Log message if verbose enabled
   * @private
   */
  _log(...args) {
    if (this.config.verbose) {
      console.log("[MultiTierCache]", ...args);
    }
  }
  /**
   * Get value from cache tiers (cascade L1  L2  L3)
   * @private
   */
  async _get(key) {
    for (let i = 0; i < this.drivers.length; i++) {
      const tier = this.drivers[i];
      const tierStats = this.stats.tiers[i];
      try {
        const value = await tier.instance.get(key);
        if (value !== null && value !== void 0) {
          tierStats.hits++;
          this._log(`\u2713 Cache HIT on ${tier.name} for key: ${key}`);
          if (this.config.promoteOnHit && i > 0) {
            this._promoteToFasterTiers(key, value, i);
          }
          return value;
        } else {
          tierStats.misses++;
          this._log(`\u2717 Cache MISS on ${tier.name} for key: ${key}`);
        }
      } catch (error) {
        tierStats.errors++;
        this._log(`\u26A0 Error on ${tier.name} for key: ${key}`, error.message);
        if (!this.config.fallbackOnError) {
          throw new CacheError(`Cache get failed on ${tier.name}`, {
            operation: "get",
            driver: "MultiTierCache",
            tier: tier.name,
            key,
            cause: error,
            suggestion: "Enable fallbackOnError to skip failed tiers"
          });
        }
        continue;
      }
    }
    this._log(`\u2717 Cache MISS on ALL tiers for key: ${key}`);
    return null;
  }
  /**
   * Promote value to faster tiers (L2 hit  write to L1, L3 hit  write to L1+L2)
   * @private
   */
  async _promoteToFasterTiers(key, value, hitTierIndex) {
    for (let i = 0; i < hitTierIndex; i++) {
      const tier = this.drivers[i];
      const tierStats = this.stats.tiers[i];
      try {
        await tier.instance.set(key, value);
        tierStats.promotions++;
        this._log(`\u2191 Promoted key "${key}" to ${tier.name}`);
      } catch (error) {
        tierStats.errors++;
        this._log(`\u26A0 Failed to promote key "${key}" to ${tier.name}:`, error.message);
      }
    }
  }
  /**
   * Set value in cache tiers
   * @private
   */
  async _set(key, data) {
    if (this.config.strategy === "write-through") {
      return this._writeToAllTiers(key, data);
    } else if (this.config.strategy === "lazy-promotion") {
      return this._writeToL1Only(key, data);
    }
  }
  /**
   * Write-through strategy: write to all tiers immediately
   * @private
   */
  async _writeToAllTiers(key, data) {
    const results = await Promise.allSettled(
      this.drivers.map(async (tier, index) => {
        try {
          await tier.instance.set(key, data);
          this.stats.tiers[index].sets++;
          this._log(`\u2713 Wrote key "${key}" to ${tier.name}`);
          return { success: true, tier: tier.name };
        } catch (error) {
          this.stats.tiers[index].errors++;
          this._log(`\u26A0 Failed to write key "${key}" to ${tier.name}:`, error.message);
          return { success: false, tier: tier.name, error };
        }
      })
    );
    const l1Success = results[0]?.status === "fulfilled" && results[0].value.success;
    if (!l1Success && !this.config.fallbackOnError) {
      throw new CacheError("Failed to write to L1 cache", {
        operation: "set",
        driver: "MultiTierCache",
        key,
        results,
        suggestion: "Enable fallbackOnError or check L1 cache health"
      });
    }
    return true;
  }
  /**
   * Lazy-promotion strategy: write only to L1
   * @private
   */
  async _writeToL1Only(key, data) {
    const tier = this.drivers[0];
    const tierStats = this.stats.tiers[0];
    try {
      await tier.instance.set(key, data);
      tierStats.sets++;
      this._log(`\u2713 Wrote key "${key}" to ${tier.name} (lazy-promotion)`);
      return true;
    } catch (error) {
      tierStats.errors++;
      throw new CacheError(`Failed to write to ${tier.name}`, {
        operation: "set",
        driver: "MultiTierCache",
        tier: tier.name,
        key,
        cause: error,
        suggestion: "Check L1 cache health"
      });
    }
  }
  /**
   * Delete key from all tiers
   * @private
   */
  async _del(key) {
    const results = await Promise.allSettled(
      this.drivers.map(async (tier) => {
        try {
          await tier.instance.del(key);
          this._log(`\u2713 Deleted key "${key}" from ${tier.name}`);
          return { success: true, tier: tier.name };
        } catch (error) {
          this._log(`\u26A0 Failed to delete key "${key}" from ${tier.name}:`, error.message);
          return { success: false, tier: tier.name, error };
        }
      })
    );
    const anySuccess = results.some((r) => r.status === "fulfilled" && r.value.success);
    if (!anySuccess && !this.config.fallbackOnError) {
      throw new CacheError("Failed to delete from all cache tiers", {
        operation: "delete",
        driver: "MultiTierCache",
        key,
        results,
        suggestion: "Enable fallbackOnError or check cache health"
      });
    }
    return true;
  }
  /**
   * Clear all keys from all tiers
   * @private
   */
  async _clear(prefix) {
    await Promise.allSettled(
      this.drivers.map(async (tier) => {
        try {
          await tier.instance.clear(prefix);
          this._log(`\u2713 Cleared ${prefix ? `prefix "${prefix}"` : "all keys"} from ${tier.name}`);
          return { success: true, tier: tier.name };
        } catch (error) {
          this._log(`\u26A0 Failed to clear ${tier.name}:`, error.message);
          return { success: false, tier: tier.name, error };
        }
      })
    );
    return true;
  }
  /**
   * Get total size across all tiers (may have duplicates)
   */
  async size() {
    let totalSize = 0;
    for (const tier of this.drivers) {
      try {
        if (typeof tier.instance.size === "function") {
          const size = await tier.instance.size();
          totalSize += size;
        }
      } catch (error) {
        this._log(`\u26A0 Failed to get size from ${tier.name}:`, error.message);
      }
    }
    return totalSize;
  }
  /**
   * Get all keys from all tiers (deduplicated)
   */
  async keys() {
    const allKeys = /* @__PURE__ */ new Set();
    for (const tier of this.drivers) {
      try {
        if (typeof tier.instance.keys === "function") {
          const keys = await tier.instance.keys();
          keys.forEach((k) => allKeys.add(k));
        }
      } catch (error) {
        this._log(`\u26A0 Failed to get keys from ${tier.name}:`, error.message);
      }
    }
    return Array.from(allKeys);
  }
  /**
   * Get comprehensive statistics
   */
  getStats() {
    const totals = {
      hits: 0,
      misses: 0,
      promotions: 0,
      errors: 0,
      sets: 0
    };
    for (const tierStats of this.stats.tiers) {
      totals.hits += tierStats.hits;
      totals.misses += tierStats.misses;
      totals.promotions += tierStats.promotions;
      totals.errors += tierStats.errors;
      totals.sets += tierStats.sets;
    }
    const total = totals.hits + totals.misses;
    const hitRate = total > 0 ? totals.hits / total : 0;
    return {
      enabled: true,
      strategy: this.config.strategy,
      promoteOnHit: this.config.promoteOnHit,
      tiers: this.stats.tiers.map((t) => {
        const tierTotal = t.hits + t.misses;
        const tierHitRate = tierTotal > 0 ? t.hits / tierTotal : 0;
        return {
          ...t,
          hitRate: tierHitRate,
          hitRatePercent: (tierHitRate * 100).toFixed(2) + "%"
        };
      }),
      totals: {
        ...totals,
        total,
        hitRate,
        hitRatePercent: (hitRate * 100).toFixed(2) + "%"
      }
    };
  }
}

class CachePlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    const isMultiTier = Array.isArray(options.drivers) && options.drivers.length > 0;
    this.config = {
      // Driver configuration (single-tier or multi-tier)
      driver: options.driver || "s3",
      drivers: options.drivers,
      // Array of driver configs for multi-tier
      isMultiTier,
      // Multi-tier specific options
      promoteOnHit: options.promoteOnHit !== false,
      strategy: options.strategy || "write-through",
      // 'write-through' | 'lazy-promotion'
      fallbackOnError: options.fallbackOnError !== false,
      config: {
        ttl: options.ttl,
        maxSize: options.maxSize,
        maxMemoryBytes: options.maxMemoryBytes,
        maxMemoryPercent: options.maxMemoryPercent,
        ...options.config
        // Driver-specific config (can override ttl/maxSize/maxMemoryBytes/maxMemoryPercent)
      },
      // Resource filtering
      include: options.include || null,
      // Array of resource names to cache (null = all)
      exclude: options.exclude || [],
      // Array of resource names to exclude
      // Partition settings
      includePartitions: options.includePartitions !== false,
      partitionStrategy: options.partitionStrategy || "hierarchical",
      partitionAware: options.partitionAware !== false,
      trackUsage: options.trackUsage !== false,
      preloadRelated: options.preloadRelated !== false,
      // Retry configuration
      retryAttempts: options.retryAttempts || 3,
      retryDelay: options.retryDelay || 100,
      // ms
      // Logging
      verbose: options.verbose || false
    };
    this.stats = {
      hits: 0,
      misses: 0,
      writes: 0,
      deletes: 0,
      errors: 0,
      startTime: Date.now()
    };
  }
  async onInstall() {
    if (this.config.isMultiTier) {
      this.driver = await this._createMultiTierDriver();
    } else if (this.config.driver && typeof this.config.driver === "object") {
      this.driver = this.config.driver;
    } else {
      this.driver = await this._createSingleDriver(this.config.driver, this.config.config);
    }
    this.installDatabaseHooks();
    this.installResourceHooks();
  }
  /**
   * Install database hooks to handle resource creation/updates
   */
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", async ({ resource }) => {
      if (this.shouldCacheResource(resource.name)) {
        this.installResourceHooksForResource(resource);
      }
    });
  }
  async onStart() {
  }
  async onStop() {
  }
  /**
   * Create a single cache driver instance
   * @private
   */
  async _createSingleDriver(driverName, config) {
    if (driverName === "memory") {
      return new MemoryCache(config);
    } else if (driverName === "redis") {
      return new RedisCache(config);
    } else if (driverName === "filesystem") {
      if (this.config.partitionAware) {
        return new PartitionAwareFilesystemCache({
          partitionStrategy: this.config.partitionStrategy,
          trackUsage: this.config.trackUsage,
          preloadRelated: this.config.preloadRelated,
          ...config
        });
      } else {
        return new FilesystemCache(config);
      }
    } else {
      return new S3Cache({
        client: this.database.client,
        ...config
      });
    }
  }
  /**
   * Create multi-tier cache driver
   * @private
   */
  async _createMultiTierDriver() {
    const driverInstances = [];
    for (const driverConfig of this.config.drivers) {
      const driverInstance = await this._createSingleDriver(
        driverConfig.driver,
        driverConfig.config || {}
      );
      driverInstances.push({
        driver: driverInstance,
        name: driverConfig.name || `L${driverInstances.length + 1}-${driverConfig.driver}`
      });
    }
    return new MultiTierCache({
      drivers: driverInstances,
      promoteOnHit: this.config.promoteOnHit,
      strategy: this.config.strategy,
      fallbackOnError: this.config.fallbackOnError,
      verbose: this.config.verbose
    });
  }
  // Remove the old installDatabaseProxy method
  installResourceHooks() {
    for (const resource of Object.values(this.database.resources)) {
      if (!this.shouldCacheResource(resource.name)) {
        continue;
      }
      this.installResourceHooksForResource(resource);
    }
  }
  shouldCacheResource(resourceName) {
    const resource = this.database.resources[resourceName];
    if (resource?.$schema?.createdBy && resource.$schema.createdBy !== "user" && !this.config.include) {
      return false;
    }
    if (resourceName.startsWith("plg_") && !this.config.include) {
      return false;
    }
    if (this.config.exclude.includes(resourceName)) {
      return false;
    }
    if (this.config.include && !this.config.include.includes(resourceName)) {
      return false;
    }
    return true;
  }
  installResourceHooksForResource(resource) {
    if (!this.driver) return;
    const driver = this.driver;
    const instanceKey = this.instanceName || this.slug;
    resource.cacheInstances = resource.cacheInstances || {};
    resource.cacheInstances[instanceKey] = driver;
    if (!Object.prototype.hasOwnProperty.call(resource, "cache")) {
      Object.defineProperty(resource, "cache", {
        value: driver,
        writable: true,
        configurable: true,
        enumerable: false
      });
    }
    if (typeof resource.getCacheDriver !== "function") {
      Object.defineProperty(resource, "getCacheDriver", {
        value: (name = null) => {
          if (!name) {
            return resource.cache;
          }
          return resource.cacheInstances?.[name] || null;
        },
        writable: true,
        configurable: true,
        enumerable: false
      });
    }
    const computeCacheKey = async (options = {}) => {
      const { action, params = {}, partition, partitionValues } = options;
      return this.generateCacheKey(resource, action, params, partition, partitionValues);
    };
    resource.cacheKeyResolvers = resource.cacheKeyResolvers || {};
    resource.cacheKeyResolvers[instanceKey] = computeCacheKey;
    if (!resource.cacheKeyFor) {
      resource.cacheKeyFor = computeCacheKey;
    }
    if (typeof resource.getCacheKeyResolver !== "function") {
      Object.defineProperty(resource, "getCacheKeyResolver", {
        value: (name = null) => {
          if (!name) return resource.cacheKeyFor;
          return resource.cacheKeyResolvers?.[name] || null;
        },
        writable: true,
        configurable: true,
        enumerable: false
      });
    }
    if (this.driver instanceof PartitionAwareFilesystemCache) {
      resource.clearPartitionCache = async (partition, partitionValues = {}) => {
        return await this.driver.clearPartition(resource.name, partition, partitionValues);
      };
      resource.getPartitionCacheStats = async (partition = null) => {
        return await this.driver.getPartitionStats(resource.name, partition);
      };
      resource.getCacheRecommendations = async () => {
        return await this.driver.getCacheRecommendations(resource.name);
      };
      resource.warmPartitionCache = async (partitions = [], options = {}) => {
        return await this.driver.warmPartitionCache(resource.name, { partitions, ...options });
      };
    }
    const cacheMethods = [
      "count",
      "listIds",
      "getMany",
      "getAll",
      "page",
      "list",
      "get",
      "exists",
      "content",
      "hasContent",
      "query",
      "getFromPartition"
    ];
    for (const method of cacheMethods) {
      resource.useMiddleware(method, async (ctx, next) => {
        const resolveCacheKey = resource.cacheKeyResolvers?.[instanceKey] || computeCacheKey;
        let skipCache = false;
        const lastArg = ctx.args[ctx.args.length - 1];
        if (lastArg && typeof lastArg === "object" && lastArg.skipCache === true) {
          skipCache = true;
        }
        if (skipCache) {
          return await next();
        }
        let key;
        if (method === "getMany") {
          key = await resolveCacheKey({ action: method, params: { ids: ctx.args[0] } });
        } else if (method === "page") {
          const { offset, size, partition, partitionValues } = ctx.args[0] || {};
          key = await resolveCacheKey({ action: method, params: { offset, size }, partition, partitionValues });
        } else if (method === "list" || method === "listIds" || method === "count") {
          const { partition, partitionValues } = ctx.args[0] || {};
          key = await resolveCacheKey({ action: method, partition, partitionValues });
        } else if (method === "query") {
          const filter = ctx.args[0] || {};
          const options = ctx.args[1] || {};
          key = await resolveCacheKey({
            action: method,
            params: { filter, options: { limit: options.limit, offset: options.offset } },
            partition: options.partition,
            partitionValues: options.partitionValues
          });
        } else if (method === "getFromPartition") {
          const { id, partitionName, partitionValues } = ctx.args[0] || {};
          key = await resolveCacheKey({
            action: method,
            params: { id, partitionName },
            partition: partitionName,
            partitionValues
          });
        } else if (method === "getAll") {
          key = await resolveCacheKey({ action: method });
        } else if (["get", "exists", "content", "hasContent"].includes(method)) {
          key = await resolveCacheKey({ action: method, params: { id: ctx.args[0] } });
        }
        if (this.driver instanceof PartitionAwareFilesystemCache) {
          let partition, partitionValues;
          if (method === "list" || method === "listIds" || method === "count" || method === "page") {
            const args = ctx.args[0] || {};
            partition = args.partition;
            partitionValues = args.partitionValues;
          } else if (method === "query") {
            const options = ctx.args[1] || {};
            partition = options.partition;
            partitionValues = options.partitionValues;
          } else if (method === "getFromPartition") {
            const { partitionName, partitionValues: pValues } = ctx.args[0] || {};
            partition = partitionName;
            partitionValues = pValues;
          }
          const [ok, err, result] = await tryFn(() => driver._get(key, {
            resource: resource.name,
            action: method,
            partition,
            partitionValues
          }));
          if (ok && result !== null && result !== void 0) {
            this.stats.hits++;
            return result;
          }
          if (!ok && err.name !== "NoSuchKey") {
            this.stats.errors++;
            throw err;
          }
          this.stats.misses++;
          const freshResult = await next();
          this.stats.writes++;
          await driver._set(key, freshResult, {
            resource: resource.name,
            action: method,
            partition,
            partitionValues
          });
          return freshResult;
        } else {
          const [ok, err, result] = await tryFn(() => driver.get(key));
          if (ok && result !== null && result !== void 0) {
            this.stats.hits++;
            return result;
          }
          if (!ok && err.name !== "NoSuchKey") {
            this.stats.errors++;
            throw err;
          }
          this.stats.misses++;
          const freshResult = await next();
          this.stats.writes++;
          await driver.set(key, freshResult);
          return freshResult;
        }
      });
    }
    const writeMethods = ["insert", "update", "delete", "deleteMany", "setContent", "deleteContent", "replace"];
    for (const method of writeMethods) {
      resource.useMiddleware(method, async (ctx, next) => {
        const result = await next();
        if (method === "insert") {
          await this.clearCacheForResource(resource, ctx.args[0]);
        } else if (method === "update") {
          await this.clearCacheForResource(resource, { id: ctx.args[0], ...ctx.args[1] });
        } else if (method === "delete") {
          let data = { id: ctx.args[0] };
          if (typeof resource.get === "function") {
            const [ok, err, full] = await tryFn(() => resource.get(ctx.args[0]));
            if (ok && full) data = full;
          }
          await this.clearCacheForResource(resource, data);
        } else if (method === "setContent" || method === "deleteContent") {
          const id = ctx.args[0]?.id || ctx.args[0];
          await this.clearCacheForResource(resource, { id });
        } else if (method === "replace") {
          const id = ctx.args[0];
          await this.clearCacheForResource(resource, { id, ...ctx.args[1] });
        } else if (method === "deleteMany") {
          await this.clearCacheForResource(resource);
        }
        return result;
      });
    }
  }
  async clearCacheForResource(resource, data) {
    const driver = this._getDriverForResource(resource);
    if (!driver) return;
    const keyPrefix = `resource=${resource.name}`;
    if (data && data.id) {
      const itemSpecificMethods = ["get", "exists", "content", "hasContent"];
      for (const method of itemSpecificMethods) {
        const specificKey = await this.generateCacheKey(resource, method, { id: data.id });
        const [ok2, err2] = await this.clearCacheWithRetry(driver, specificKey);
        if (!ok2) {
          this.emit("plg:cache:clear-error", {
            resource: resource.name,
            method,
            id: data.id,
            error: err2.message
          });
          if (this.config.verbose) {
            console.warn(`[CachePlugin] Failed to clear ${method} cache for ${resource.name}:${data.id}:`, err2.message);
          }
        }
      }
      if (this.config.includePartitions === true && resource.$schema.partitions && Object.keys(resource.$schema.partitions).length > 0) {
        const partitionValues = this.getPartitionValues(data, resource);
        for (const [partitionName, values] of Object.entries(partitionValues)) {
          if (values && Object.keys(values).length > 0 && Object.values(values).some((v) => v !== null && v !== void 0)) {
            const partitionKeyPrefix = join(keyPrefix, `partition=${partitionName}`);
            const [ok2, err2] = await this.clearCacheWithRetry(driver, partitionKeyPrefix);
            if (!ok2) {
              this.emit("plg:cache:clear-error", {
                resource: resource.name,
                partition: partitionName,
                error: err2.message
              });
              if (this.config.verbose) {
                console.warn(`[CachePlugin] Failed to clear partition cache for ${resource.name}/${partitionName}:`, err2.message);
              }
            }
          }
        }
      }
    }
    const [ok, err] = await this.clearCacheWithRetry(driver, keyPrefix);
    if (!ok) {
      this.emit("plg:cache:clear-error", {
        resource: resource.name,
        type: "broad",
        error: err.message
      });
      if (this.config.verbose) {
        console.warn(`[CachePlugin] Failed to clear broad cache for ${resource.name}, trying specific methods:`, err.message);
      }
      const aggregateMethods = ["count", "list", "listIds", "getAll", "page", "query"];
      for (const method of aggregateMethods) {
        await this.clearCacheWithRetry(driver, `${keyPrefix}/action=${method}`);
        await this.clearCacheWithRetry(driver, `resource=${resource.name}/action=${method}`);
      }
    }
  }
  async clearCacheWithRetry(cache, key) {
    let lastError;
    for (let attempt = 0; attempt < this.config.retryAttempts; attempt++) {
      const [ok, err] = await tryFn(() => cache.clear(key));
      if (ok) {
        this.stats.deletes++;
        return [true, null];
      }
      lastError = err;
      if (err.name === "NoSuchKey" || err.code === "NoSuchKey") {
        return [true, null];
      }
      if (attempt < this.config.retryAttempts - 1) {
        const delay = this.config.retryDelay * Math.pow(2, attempt);
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
    return [false, lastError];
  }
  _getDriverForResource(resource) {
    const instanceKey = this.instanceName || this.slug;
    if (resource?.cacheInstances && instanceKey && resource.cacheInstances[instanceKey]) {
      return resource.cacheInstances[instanceKey];
    }
    return this.driver;
  }
  async generateCacheKey(resource, action, params = {}, partition = null, partitionValues = null) {
    const keyParts = [
      `resource=${resource.name}`,
      `action=${action}`
    ];
    if (partition && partitionValues && Object.keys(partitionValues).length > 0) {
      keyParts.push(`partition:${partition}`);
      for (const [field, value] of Object.entries(partitionValues)) {
        if (value !== null && value !== void 0) {
          keyParts.push(`${field}:${value}`);
        }
      }
    }
    if (Object.keys(params).length > 0) {
      const paramsHash = this.hashParams(params);
      keyParts.push(paramsHash);
    }
    return join(...keyParts) + ".json.gz";
  }
  hashParams(params) {
    const serialized = jsonStableStringify(params) || "empty";
    return crypto.createHash("md5").update(serialized).digest("hex").substring(0, 16);
  }
  // Utility methods
  async getCacheStats() {
    if (!this.driver) return null;
    const driverStats = typeof this.driver.getStats === "function" ? this.driver.getStats() : null;
    return {
      size: await this.driver.size(),
      keys: await this.driver.keys(),
      driver: this.driver.constructor.name,
      stats: driverStats
    };
  }
  async clearAllCache() {
    if (!this.driver) return;
    for (const resource of Object.values(this.database.resources)) {
      const driver = this._getDriverForResource(resource);
      if (!driver) continue;
      const keyPrefix = `resource=${resource.name}`;
      await driver.clear(keyPrefix);
    }
  }
  async warmCache(resourceName, options = {}) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new CacheError("Resource not found for cache warming", {
        operation: "warmCache",
        driver: this.driver?.constructor.name,
        resourceName,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name spelling or ensure resource has been created"
      });
    }
    const { includePartitions = true, sampleSize = 100 } = options;
    if (this.driver instanceof PartitionAwareFilesystemCache && resource.warmPartitionCache) {
      const partitionNames = resource.$schema.partitions ? Object.keys(resource.$schema.partitions) : [];
      return await resource.warmPartitionCache(partitionNames, options);
    }
    let offset = 0;
    const pageSize = 100;
    const sampledRecords = [];
    while (sampledRecords.length < sampleSize) {
      const [ok, err, pageResult] = await tryFn(() => resource.page({ offset, size: pageSize }));
      if (!ok || !pageResult) {
        break;
      }
      const pageItems = Array.isArray(pageResult) ? pageResult : pageResult.items || [];
      if (pageItems.length === 0) {
        break;
      }
      sampledRecords.push(...pageItems);
      offset += pageSize;
    }
    if (includePartitions && resource.$schema.partitions && sampledRecords.length > 0) {
      for (const [partitionName, partitionDef] of Object.entries(resource.$schema.partitions)) {
        if (partitionDef.fields) {
          const partitionValuesSet = /* @__PURE__ */ new Set();
          for (const record of sampledRecords) {
            const values = this.getPartitionValues(record, resource);
            if (values[partitionName]) {
              partitionValuesSet.add(JSON.stringify(values[partitionName]));
            }
          }
          for (const partitionValueStr of partitionValuesSet) {
            const partitionValues = JSON.parse(partitionValueStr);
            await tryFn(() => resource.list({ partition: partitionName, partitionValues }));
          }
        }
      }
    }
    return {
      resourceName,
      recordsSampled: sampledRecords.length,
      partitionsWarmed: includePartitions && resource.$schema.partitions ? Object.keys(resource.$schema.partitions).length : 0
    };
  }
  async analyzeCacheUsage() {
    if (!(this.driver instanceof PartitionAwareFilesystemCache)) {
      return { message: "Cache usage analysis is only available with PartitionAwareFilesystemCache" };
    }
    const analysis = {
      totalResources: Object.keys(this.database.resources).length,
      resourceStats: {},
      recommendations: {},
      summary: {
        mostUsedPartitions: [],
        leastUsedPartitions: [],
        suggestedOptimizations: []
      }
    };
    for (const [resourceName, resource] of Object.entries(this.database.resources)) {
      if (!this.shouldCacheResource(resourceName)) {
        continue;
      }
      try {
        analysis.resourceStats[resourceName] = await this.driver.getPartitionStats(resourceName);
        analysis.recommendations[resourceName] = await this.driver.getCacheRecommendations(resourceName);
      } catch (error) {
        analysis.resourceStats[resourceName] = { error: error.message };
      }
    }
    const allRecommendations = Object.values(analysis.recommendations).flat();
    analysis.summary.mostUsedPartitions = allRecommendations.filter((r) => r.recommendation === "preload").sort((a, b) => b.priority - a.priority).slice(0, 5);
    analysis.summary.leastUsedPartitions = allRecommendations.filter((r) => r.recommendation === "archive").slice(0, 5);
    analysis.summary.suggestedOptimizations = [
      `Consider preloading ${analysis.summary.mostUsedPartitions.length} high-usage partitions`,
      `Archive ${analysis.summary.leastUsedPartitions.length} unused partitions`,
      `Monitor cache hit rates for partition efficiency`
    ];
    return analysis;
  }
  /**
   * Get cache statistics including hit/miss rates
   * @returns {Object} Stats object with hits, misses, writes, deletes, errors, and calculated metrics
   */
  getStats() {
    const total = this.stats.hits + this.stats.misses;
    const hitRate = total > 0 ? this.stats.hits / total * 100 : 0;
    const missRate = total > 0 ? this.stats.misses / total * 100 : 0;
    const uptime = Date.now() - this.stats.startTime;
    const uptimeSeconds = Math.floor(uptime / 1e3);
    return {
      // Raw counters
      hits: this.stats.hits,
      misses: this.stats.misses,
      writes: this.stats.writes,
      deletes: this.stats.deletes,
      errors: this.stats.errors,
      // Calculated metrics
      total,
      hitRate: hitRate.toFixed(2) + "%",
      missRate: missRate.toFixed(2) + "%",
      hitRateDecimal: hitRate / 100,
      missRateDecimal: missRate / 100,
      // Uptime
      uptime: uptimeSeconds,
      uptimeFormatted: this._formatUptime(uptimeSeconds),
      startTime: new Date(this.stats.startTime).toISOString(),
      // Rates per second
      hitsPerSecond: uptimeSeconds > 0 ? (this.stats.hits / uptimeSeconds).toFixed(2) : 0,
      missesPerSecond: uptimeSeconds > 0 ? (this.stats.misses / uptimeSeconds).toFixed(2) : 0,
      writesPerSecond: uptimeSeconds > 0 ? (this.stats.writes / uptimeSeconds).toFixed(2) : 0
    };
  }
  /**
   * Reset cache statistics
   */
  resetStats() {
    this.stats = {
      hits: 0,
      misses: 0,
      writes: 0,
      deletes: 0,
      errors: 0,
      startTime: Date.now()
    };
  }
  /**
   * Format uptime in human-readable format
   * @private
   */
  _formatUptime(seconds) {
    const days = Math.floor(seconds / 86400);
    const hours = Math.floor(seconds % 86400 / 3600);
    const minutes = Math.floor(seconds % 3600 / 60);
    const secs = seconds % 60;
    const parts = [];
    if (days > 0) parts.push(`${days}d`);
    if (hours > 0) parts.push(`${hours}h`);
    if (minutes > 0) parts.push(`${minutes}m`);
    if (secs > 0 || parts.length === 0) parts.push(`${secs}s`);
    return parts.join(" ");
  }
}

class PuppeteerPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      // Browser Pool
      pool: {
        enabled: true,
        maxBrowsers: 5,
        maxTabsPerBrowser: 10,
        reuseTab: false,
        closeOnIdle: true,
        idleTimeout: 3e5,
        // 5 minutes
        ...options.pool
      },
      // Browser Launch Options
      launch: {
        headless: true,
        args: [
          "--no-sandbox",
          "--disable-setuid-sandbox",
          "--disable-dev-shm-usage",
          "--disable-accelerated-2d-canvas",
          "--no-first-run",
          "--no-zygote",
          "--disable-gpu"
        ],
        ignoreHTTPSErrors: true,
        ...options.launch
      },
      // Viewport & User Agent
      viewport: {
        width: 1920,
        height: 1080,
        deviceScaleFactor: 1,
        randomize: true,
        presets: ["desktop", "laptop", "tablet"],
        ...options.viewport
      },
      // User Agent Management
      userAgent: {
        enabled: true,
        random: true,
        filters: {
          deviceCategory: "desktop",
          ...options.userAgent?.filters
        },
        custom: options.userAgent?.custom || null,
        ...options.userAgent
      },
      // Stealth Mode (Anti-Detection)
      stealth: {
        enabled: true,
        enableEvasions: true,
        ...options.stealth
      },
      // Human Behavior Simulation
      humanBehavior: {
        enabled: true,
        mouse: {
          enabled: true,
          bezierCurves: true,
          overshoot: true,
          jitter: true,
          pathThroughElements: true,
          ...options.humanBehavior?.mouse
        },
        typing: {
          enabled: true,
          mistakes: true,
          corrections: true,
          pauseAfterWord: true,
          speedVariation: true,
          delayRange: [50, 150],
          ...options.humanBehavior?.typing
        },
        scrolling: {
          enabled: true,
          randomStops: true,
          backScroll: true,
          horizontalJitter: true,
          ...options.humanBehavior?.scrolling
        },
        ...options.humanBehavior
      },
      // Cookie Management & Farming
      cookies: {
        enabled: true,
        storage: {
          resource: "plg_puppeteer_cookies",
          autoSave: true,
          autoLoad: true,
          encrypt: true,
          ...options.cookies?.storage
        },
        farming: {
          enabled: true,
          warmup: {
            enabled: true,
            pages: ["https://www.google.com", "https://www.youtube.com", "https://www.wikipedia.org"],
            randomOrder: true,
            timePerPage: { min: 5e3, max: 15e3 },
            interactions: { scroll: true, click: true, hover: true },
            ...options.cookies?.farming?.warmup
          },
          rotation: {
            enabled: true,
            requestsPerCookie: 100,
            maxAge: 864e5,
            // 24 hours
            poolSize: 10,
            ...options.cookies?.farming?.rotation
          },
          reputation: {
            enabled: true,
            trackSuccess: true,
            retireThreshold: 0.5,
            ageBoost: true,
            ...options.cookies?.farming?.reputation
          },
          ...options.cookies?.farming
        },
        ...options.cookies
      },
      // Performance Optimization
      performance: {
        blockResources: {
          enabled: true,
          types: ["image", "stylesheet", "font", "media"],
          ...options.performance?.blockResources
        },
        cacheEnabled: true,
        javascriptEnabled: true,
        ...options.performance
      },
      // Network Monitoring (CDP)
      networkMonitor: {
        enabled: false,
        // Disabled by default (adds overhead)
        persist: false,
        // Save to S3DB
        filters: {
          types: null,
          // ['image', 'script'] or null for all
          statuses: null,
          // [404, 500] or null for all
          minSize: null,
          // Only requests >= size (bytes)
          maxSize: null,
          // Only requests <= size (bytes)
          saveErrors: true,
          // Always save failed requests
          saveLargeAssets: true,
          // Always save assets > 1MB
          ...options.networkMonitor?.filters
        },
        compression: {
          enabled: true,
          threshold: 10240,
          // Compress payloads > 10KB
          ...options.networkMonitor?.compression
        },
        ...options.networkMonitor
      },
      // Console Monitoring
      consoleMonitor: {
        enabled: false,
        // Disabled by default
        persist: false,
        // Save to S3DB
        filters: {
          levels: null,
          // ['error', 'warning'] or null for all
          excludePatterns: [],
          // Regex patterns to exclude
          includeStackTraces: true,
          includeSourceLocation: true,
          captureNetwork: false,
          // Also capture network errors
          ...options.consoleMonitor?.filters
        },
        ...options.consoleMonitor
      },
      // Screenshot & Recording
      screenshot: {
        fullPage: false,
        type: "png",
        ...options.screenshot
      },
      // Proxy Support
      proxy: {
        enabled: false,
        list: [],
        // Array of proxy URLs or objects
        selectionStrategy: "round-robin",
        // 'round-robin' | 'random' | 'least-used' | 'best-performance'
        bypassList: [],
        // Domains to bypass proxy
        healthCheck: {
          enabled: true,
          interval: 3e5,
          // 5 minutes
          testUrl: "https://www.google.com",
          timeout: 1e4,
          successRateThreshold: 0.3
        },
        // Legacy single proxy support (deprecated)
        server: null,
        username: null,
        password: null,
        ...options.proxy
      },
      // Error Handling & Retries
      retries: {
        enabled: true,
        maxAttempts: 3,
        backoff: "exponential",
        initialDelay: 1e3,
        ...options.retries
      },
      // Logging & Debugging
      debug: {
        enabled: false,
        screenshots: false,
        console: false,
        network: false,
        ...options.debug
      }
    };
    const resourceNamesOption = options.resourceNames || {};
    this._resourceDescriptors = {
      cookies: {
        defaultName: "plg_puppeteer_cookies",
        override: resourceNamesOption.cookies || options.cookies?.storage?.resource
      },
      consoleSessions: {
        defaultName: "plg_puppeteer_console_sessions",
        override: resourceNamesOption.consoleSessions
      },
      consoleMessages: {
        defaultName: "plg_puppeteer_console_messages",
        override: resourceNamesOption.consoleMessages
      },
      consoleErrors: {
        defaultName: "plg_puppeteer_console_errors",
        override: resourceNamesOption.consoleErrors
      },
      networkSessions: {
        defaultName: "plg_puppeteer_network_sessions",
        override: resourceNamesOption.networkSessions
      },
      networkRequests: {
        defaultName: "plg_puppeteer_network_requests",
        override: resourceNamesOption.networkRequests
      },
      networkErrors: {
        defaultName: "plg_puppeteer_network_errors",
        override: resourceNamesOption.networkErrors
      }
    };
    this.resourceNames = this._resolveResourceNames();
    this.config.cookies.storage.resource = this.resourceNames.cookies;
    this.browserPool = [];
    this.tabPool = /* @__PURE__ */ new Map();
    this.browserIdleTimers = /* @__PURE__ */ new Map();
    this.dedicatedBrowsers = /* @__PURE__ */ new Set();
    this.userAgentGenerator = null;
    this.ghostCursor = null;
    this.cookieManager = null;
    this.proxyManager = null;
    this.performanceManager = null;
    this.networkMonitor = null;
    this.consoleMonitor = null;
    this.initialized = false;
    if (this.config.pool.reuseTab) {
      this.emit("puppeteer.configWarning", {
        setting: "pool.reuseTab",
        message: "pool.reuseTab is not supported yet and will be ignored."
      });
    }
  }
  _resolveResourceNames() {
    return resolveResourceNames("puppeteer", this._resourceDescriptors, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.resourceNames = this._resolveResourceNames();
    if (this.config?.cookies?.storage) {
      this.config.cookies.storage.resource = this.resourceNames.cookies;
    }
  }
  /**
   * Install plugin and validate dependencies
   */
  async onInstall() {
    requirePluginDependency("puppeteer", this.name);
    requirePluginDependency("puppeteer-extra", this.name);
    requirePluginDependency("puppeteer-extra-plugin-stealth", this.name);
    requirePluginDependency("user-agents", this.name);
    requirePluginDependency("ghost-cursor", this.name);
    if (this.config.cookies.enabled) {
      await this._setupCookieStorage();
    }
    this.emit("puppeteer.installed");
  }
  /**
   * Start plugin and initialize browser pool
   */
  async onStart() {
    if (this.initialized) return;
    await this._importDependencies();
    if (this.config.cookies.enabled) {
      await this._initializeCookieManager();
    }
    if (this.config.proxy.enabled) {
      await this._initializeProxyManager();
    }
    await this._initializePerformanceManager();
    if (this.config.networkMonitor.enabled) {
      await this._initializeNetworkMonitor();
    }
    if (this.config.consoleMonitor.enabled) {
      await this._initializeConsoleMonitor();
    }
    if (this.config.pool.enabled) {
      await this._warmupBrowserPool();
    }
    this.initialized = true;
    this.emit("puppeteer.started");
  }
  /**
   * Stop plugin and cleanup resources
   */
  async onStop() {
    await this._closeBrowserPool();
    await this._closeDedicatedBrowsers();
    this.initialized = false;
    this.emit("puppeteer.stopped");
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    await this.onStop();
    this.emit("puppeteer.uninstalled");
  }
  /**
   * Import required dependencies (lazy loading)
   * @private
   */
  async _importDependencies() {
    const puppeteerModule = await import('puppeteer-extra');
    const StealthPlugin = (await import('puppeteer-extra-plugin-stealth')).default;
    const UserAgent = (await import('user-agents')).default;
    const { createCursor } = await import('ghost-cursor');
    this.puppeteer = puppeteerModule.default || puppeteerModule;
    if (this.config.stealth.enabled) {
      this.puppeteer.use(StealthPlugin());
    }
    if (this.config.userAgent.enabled && this.config.userAgent.random) {
      this.UserAgent = UserAgent;
    }
    this.createGhostCursor = createCursor;
  }
  /**
   * Setup cookie storage resource
   * @private
   */
  async _setupCookieStorage() {
    const resourceName = this.config.cookies.storage.resource;
    try {
      await this.database.getResource(resourceName);
      return;
    } catch (err) {
    }
    const [created, createErr] = await tryFn(() => this.database.createResource({
      name: resourceName,
      attributes: {
        sessionId: "string|required",
        cookies: "array|required",
        userAgent: "string",
        viewport: "object",
        proxyId: "string|optional",
        domain: "string",
        date: "string",
        reputation: {
          successCount: "number",
          failCount: "number",
          successRate: "number",
          lastUsed: "number"
        },
        metadata: {
          createdAt: "number",
          expiresAt: "number",
          requestCount: "number",
          age: "number"
        }
      },
      timestamps: true,
      behavior: "body-only",
      partitions: {
        byProxy: { fields: { proxyId: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (!created) {
      const existing = this.database.resources?.[resourceName];
      if (!existing) {
        throw createErr;
      }
    }
  }
  /**
   * Initialize proxy manager
   * @private
   */
  async _initializeProxyManager() {
    const { ProxyManager } = await Promise.resolve().then(function () { return proxyManager; });
    this.proxyManager = new ProxyManager(this);
    await this.proxyManager.initialize();
  }
  /**
   * Initialize cookie manager
   * @private
   */
  async _initializeCookieManager() {
    const { CookieManager } = await Promise.resolve().then(function () { return cookieManager; });
    this.cookieManager = new CookieManager(this);
    await this.cookieManager.initialize();
  }
  /**
   * Initialize performance manager
   * @private
   */
  async _initializePerformanceManager() {
    const { PerformanceManager } = await Promise.resolve().then(function () { return performanceManager; });
    this.performanceManager = new PerformanceManager(this);
    this.emit("puppeteer.performanceManager.initialized");
  }
  /**
   * Initialize network monitor
   * @private
   */
  async _initializeNetworkMonitor() {
    const { NetworkMonitor } = await Promise.resolve().then(function () { return networkMonitor; });
    this.networkMonitor = new NetworkMonitor(this);
    if (this.config.networkMonitor.persist) {
      await this.networkMonitor.initialize();
    }
    this.emit("puppeteer.networkMonitor.initialized");
  }
  /**
   * Initialize console monitor
   * @private
   */
  async _initializeConsoleMonitor() {
    const { ConsoleMonitor } = await Promise.resolve().then(function () { return consoleMonitor; });
    this.consoleMonitor = new ConsoleMonitor(this);
    if (this.config.consoleMonitor.persist) {
      await this.consoleMonitor.initialize();
    }
    this.emit("puppeteer.consoleMonitor.initialized");
  }
  /**
   * Warmup browser pool
   * @private
   */
  async _warmupBrowserPool() {
    const poolSize = Math.min(this.config.pool.maxBrowsers, 2);
    for (let i = 0; i < poolSize; i++) {
      await this._createBrowser();
    }
    this.emit("puppeteer.poolWarmed", { size: this.browserPool.length });
  }
  /**
   * Create a new browser instance
   * @private
   * @param {Object} proxy - Optional proxy configuration
   * @returns {Promise<Browser>}
   */
  async _createBrowser(proxy = null) {
    const launchOptions = {
      ...this.config.launch,
      args: [...this.config.launch.args || []]
    };
    if (proxy && this.proxyManager) {
      const proxyArgs = this.proxyManager.getProxyLaunchArgs(proxy);
      launchOptions.args.push(...proxyArgs);
    } else if (this.config.proxy.enabled && this.config.proxy.server) {
      launchOptions.args.push(`--proxy-server=${this.config.proxy.server}`);
    }
    const browser = await this.puppeteer.launch(launchOptions);
    if (!proxy && this.config.pool.enabled) {
      this.browserPool.push(browser);
      this.tabPool.set(browser, /* @__PURE__ */ new Set());
      browser.on("disconnected", () => {
        const index = this.browserPool.indexOf(browser);
        if (index > -1) {
          this.browserPool.splice(index, 1);
        }
        this.tabPool.delete(browser);
        this._clearIdleTimer(browser);
        this.dedicatedBrowsers.delete(browser);
      });
    }
    return browser;
  }
  /**
   * Get or create a browser instance
   * @private
   * @param {Object} proxy - Optional proxy configuration
   * @returns {Promise<Browser>}
   */
  async _getBrowser(proxy = null) {
    if (proxy) {
      return await this._createBrowser(proxy);
    }
    if (this.config.pool.enabled) {
      for (const browser of this.browserPool) {
        const tabs = this.tabPool.get(browser);
        if (!tabs || tabs.size < this.config.pool.maxTabsPerBrowser) {
          return browser;
        }
      }
      if (this.browserPool.length < this.config.pool.maxBrowsers) {
        return await this._createBrowser();
      }
      let targetBrowser = this.browserPool[0];
      let minTabs = this.tabPool.get(targetBrowser)?.size || 0;
      for (const browser of this.browserPool.slice(1)) {
        const tabs = this.tabPool.get(browser)?.size || 0;
        if (tabs < minTabs) {
          targetBrowser = browser;
          minTabs = tabs;
        }
      }
      return targetBrowser;
    } else {
      return await this._createBrowser();
    }
  }
  /**
   * Close all browsers in pool
   * @private
   */
  async _closeBrowserPool() {
    for (const browser of this.browserPool) {
      this._clearIdleTimer(browser);
      if (this.cookieManager) {
        const tabs = this.tabPool.get(browser);
        if (tabs) {
          for (const page of tabs) {
            if (!page || page._sessionSaved || !page._sessionId) {
              continue;
            }
            if (typeof page.isClosed === "function" && page.isClosed()) {
              continue;
            }
            try {
              await this.cookieManager.saveSession(page, page._sessionId, {
                success: !!page._navigationSuccess
              });
              page._sessionSaved = true;
            } catch (err) {
              page._sessionSaved = true;
              this.emit("puppeteer.cookieSaveFailed", {
                sessionId: page._sessionId,
                error: err.message
              });
            }
          }
        }
      }
      try {
        await browser.close();
      } catch (err) {
      }
    }
    this.browserPool = [];
    this.tabPool.clear();
  }
  /**
   * Clear idle timer for pooled browser
   * @private
   */
  _clearIdleTimer(browser) {
    const timer = this.browserIdleTimers.get(browser);
    if (timer) {
      clearTimeout(timer);
      this.browserIdleTimers.delete(browser);
    }
  }
  /**
   * Schedule pooled browser retirement when idle
   * @private
   */
  _scheduleIdleCloseIfNeeded(browser) {
    if (!this.config.pool.closeOnIdle) return;
    const tabs = this.tabPool.get(browser);
    if (!tabs || tabs.size > 0) return;
    if (this.browserIdleTimers.has(browser)) return;
    const timeout = this.config.pool.idleTimeout || 3e5;
    const timer = setTimeout(async () => {
      this.browserIdleTimers.delete(browser);
      const currentTabs = this.tabPool.get(browser);
      if (currentTabs && currentTabs.size === 0) {
        await this._retireIdleBrowser(browser);
      }
    }, timeout);
    if (typeof timer.unref === "function") {
      timer.unref();
    }
    this.browserIdleTimers.set(browser, timer);
  }
  /**
   * Retire pooled browser if still idle
   * @private
   * @param {Browser} browser
   */
  async _retireIdleBrowser(browser) {
    this.tabPool.delete(browser);
    const index = this.browserPool.indexOf(browser);
    if (index > -1) {
      this.browserPool.splice(index, 1);
    }
    try {
      await browser.close();
      this.emit("puppeteer.browserRetired", { pooled: true });
    } catch (err) {
      this.emit("puppeteer.browserRetiredError", {
        pooled: true,
        error: err.message
      });
    }
  }
  /**
   * Close dedicated (non-pooled) browsers
   * @private
   */
  async _closeDedicatedBrowsers() {
    for (const browser of Array.from(this.dedicatedBrowsers)) {
      try {
        await browser.close();
      } catch (err) {
      } finally {
        this.dedicatedBrowsers.delete(browser);
      }
    }
  }
  /**
   * Generate random user agent
   * @private
   * @returns {string}
   */
  _generateUserAgent() {
    if (this.config.userAgent.custom) {
      return this.config.userAgent.custom;
    }
    if (this.config.userAgent.random && this.UserAgent) {
      const userAgent = new this.UserAgent(this.config.userAgent.filters);
      return userAgent.toString();
    }
    return null;
  }
  /**
   * Generate random viewport
   * @private
   * @returns {Object}
   */
  _generateViewport() {
    if (!this.config.viewport.randomize) {
      return {
        width: this.config.viewport.width,
        height: this.config.viewport.height,
        deviceScaleFactor: this.config.viewport.deviceScaleFactor
      };
    }
    const presets = {
      desktop: [
        { width: 1920, height: 1080, deviceScaleFactor: 1 },
        { width: 1680, height: 1050, deviceScaleFactor: 1 },
        { width: 1600, height: 900, deviceScaleFactor: 1 },
        { width: 1440, height: 900, deviceScaleFactor: 1 },
        { width: 1366, height: 768, deviceScaleFactor: 1 }
      ],
      laptop: [
        { width: 1440, height: 900, deviceScaleFactor: 1 },
        { width: 1366, height: 768, deviceScaleFactor: 1 },
        { width: 1280, height: 800, deviceScaleFactor: 1 }
      ],
      tablet: [
        { width: 1024, height: 768, deviceScaleFactor: 2 },
        { width: 768, height: 1024, deviceScaleFactor: 2 }
      ]
    };
    const categories = this.config.viewport.presets || ["desktop"];
    const availablePresets = categories.flatMap((cat) => presets[cat] || []);
    return availablePresets[Math.floor(Math.random() * availablePresets.length)];
  }
  /**
   * PUBLIC API
   */
  /**
   * Navigate to URL with human behavior
   * @param {string} url - URL to navigate to
   * @param {Object} options - Navigation options
   * @returns {Promise<Page>}
   */
  async navigate(url, options = {}) {
    const {
      useSession = null,
      screenshot = false,
      waitUntil = "networkidle2",
      timeout = 3e4
    } = options;
    let proxy = null;
    let proxyId = null;
    if (useSession && this.proxyManager) {
      proxy = this.proxyManager.getProxyForSession(useSession, true);
      proxyId = proxy?.id || null;
    }
    const browser = await this._getBrowser(proxy);
    const page = await browser.newPage();
    const isPooledBrowser = !proxy && this.config.pool.enabled;
    if (isPooledBrowser) {
      const tabs = this.tabPool.get(browser);
      if (tabs) {
        tabs.add(page);
        this._clearIdleTimer(browser);
      }
    } else {
      this.dedicatedBrowsers.add(browser);
      browser.once("disconnected", () => {
        this.dedicatedBrowsers.delete(browser);
      });
    }
    if (proxy && this.proxyManager) {
      await this.proxyManager.authenticateProxy(page, proxy);
    }
    const viewport = this._generateViewport();
    await page.setViewport(viewport);
    const userAgent = this._generateUserAgent();
    if (userAgent) {
      await page.setUserAgent(userAgent);
    }
    if (this.config.performance.blockResources.enabled) {
      await page.setRequestInterception(true);
      page.on("request", (request) => {
        if (this.config.performance.blockResources.types.includes(request.resourceType())) {
          request.abort();
        } else {
          request.continue();
        }
      });
    }
    if (useSession && this.cookieManager) {
      await this.cookieManager.loadSession(page, useSession);
    }
    let cursor = null;
    if (this.config.humanBehavior.enabled && this.config.humanBehavior.mouse.enabled) {
      cursor = this.createGhostCursor(page);
    }
    let navigationSuccess = false;
    try {
      await page.goto(url, { waitUntil, timeout });
      navigationSuccess = true;
      if (proxyId && this.proxyManager) {
        this.proxyManager.recordProxyUsage(proxyId, true);
      }
    } catch (err) {
      if (proxyId && this.proxyManager) {
        this.proxyManager.recordProxyUsage(proxyId, false);
      }
      throw err;
    }
    if (screenshot) {
      const screenshotBuffer = await page.screenshot(this.config.screenshot);
      page._screenshot = screenshotBuffer;
    }
    page._cursor = cursor;
    page._userAgent = userAgent;
    page._viewport = viewport;
    page._proxyId = proxyId;
    page._sessionId = useSession;
    page._navigationSuccess = navigationSuccess;
    page._sessionSaved = false;
    if (this.config.humanBehavior.enabled) {
      this._attachHumanBehaviorMethods(page);
    }
    let hasSavedSession = false;
    let browserClosed = false;
    const originalClose = page.close?.bind(page) || (async () => {
    });
    const shouldAutoCloseBrowser = !isPooledBrowser;
    page.on("close", () => {
      if (isPooledBrowser) {
        const tabs = this.tabPool.get(browser);
        tabs?.delete(page);
        this._scheduleIdleCloseIfNeeded(browser);
      } else {
        this.dedicatedBrowsers.delete(browser);
      }
    });
    page.close = async (...closeArgs) => {
      if (!hasSavedSession && useSession && this.cookieManager && !page._sessionSaved) {
        try {
          await this.cookieManager.saveSession(page, useSession, {
            success: navigationSuccess
          });
          page._sessionSaved = true;
        } catch (err) {
          this.emit("puppeteer.cookieSaveFailed", {
            sessionId: useSession,
            error: err.message
          });
          page._sessionSaved = true;
        } finally {
          hasSavedSession = true;
        }
      }
      try {
        const result = await originalClose(...closeArgs);
        return result;
      } finally {
        if (isPooledBrowser) {
          const tabs = this.tabPool.get(browser);
          tabs?.delete(page);
          this._scheduleIdleCloseIfNeeded(browser);
        } else if (shouldAutoCloseBrowser && !browserClosed) {
          try {
            await browser.close();
            this.emit("puppeteer.browserClosed", { pooled: false });
          } catch (err) {
            this.emit("puppeteer.browserCloseFailed", {
              pooled: false,
              error: err.message
            });
          } finally {
            browserClosed = true;
            this.dedicatedBrowsers.delete(browser);
          }
        }
      }
    };
    this.emit("puppeteer.navigate", {
      url,
      userAgent,
      viewport,
      proxyId,
      sessionId: useSession
    });
    return page;
  }
  /**
   * Run handler with session-aware navigation helper
   * @param {string} sessionId - Session identifier
   * @param {Function} handler - Async function receiving the page instance
   * @param {Object} options - Navigate options (requires url)
   * @returns {Promise<*>}
   */
  async withSession(sessionId, handler, options = {}) {
    if (!sessionId) {
      throw new Error("withSession requires a sessionId");
    }
    if (typeof handler !== "function") {
      throw new TypeError("withSession handler must be a function");
    }
    const { url, ...navigateOptions } = options;
    if (!url) {
      throw new Error("withSession requires an options.url value");
    }
    this.emit("puppeteer.withSession.start", { sessionId, url });
    const page = await this.navigate(url, {
      ...navigateOptions,
      useSession: sessionId
    });
    let handlerError = null;
    try {
      const result = await handler(page, this);
      return result;
    } catch (err) {
      handlerError = err;
      throw err;
    } finally {
      try {
        await page.close();
      } catch (err) {
        this.emit("puppeteer.withSession.cleanupFailed", {
          sessionId,
          url,
          error: err.message
        });
      }
      this.emit("puppeteer.withSession.finish", {
        sessionId,
        url,
        error: handlerError ? handlerError.message : null
      });
    }
  }
  /**
   * Attach human behavior methods to page
   * @private
   */
  _attachHumanBehaviorMethods(page) {
    page.humanClick = async (selector, options = {}) => {
      const element = await page.$(selector);
      if (!element) throw new Error(`Element not found: ${selector}`);
      if (this.config.humanBehavior.mouse.pathThroughElements && page._cursor) {
        await page._cursor.moveTo(selector);
        await page._cursor.click();
      } else {
        await element.click();
      }
    };
    page.humanMoveTo = async (selector, options = {}) => {
      if (!page._cursor) {
        throw new Error("Ghost cursor not initialized");
      }
      await page._cursor.moveTo(selector);
    };
    page.humanType = async (selector, text, options = {}) => {
      const element = await page.$(selector);
      if (!element) throw new Error(`Element not found: ${selector}`);
      await element.click();
      if (this.config.humanBehavior.typing.mistakes) {
        await this._typeWithMistakes(page, text, options);
      } else {
        const [min, max] = this.config.humanBehavior.typing.delayRange;
        await page.type(selector, text, {
          delay: min + Math.random() * (max - min)
        });
      }
    };
    page.humanScroll = async (options = {}) => {
      const { distance = null, direction = "down" } = options;
      if (distance) {
        await page.evaluate((dist, dir) => {
          window.scrollBy(0, dir === "down" ? dist : -dist);
        }, distance, direction);
      } else {
        await this._scrollWithStops(page, direction);
      }
    };
  }
  /**
   * Type with random mistakes and corrections
   * @private
   */
  async _typeWithMistakes(page, text, options = {}) {
    const words = text.split(" ");
    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      if (Math.random() < 0.2 && word.length > 3) {
        const wrongPos = Math.floor(Math.random() * word.length);
        const wrongChar = String.fromCharCode(97 + Math.floor(Math.random() * 26));
        const wrongWord = word.slice(0, wrongPos) + wrongChar + word.slice(wrongPos + 1);
        await page.keyboard.type(wrongWord, { delay: 100 });
        await this._randomDelay(200, 500);
        for (let j = 0; j < wrongWord.length; j++) {
          await page.keyboard.press("Backspace");
          await this._randomDelay(50, 100);
        }
        await page.keyboard.type(word, { delay: 100 });
      } else {
        await page.keyboard.type(word, { delay: 100 });
      }
      if (i < words.length - 1) {
        await page.keyboard.press("Space");
        await this._randomDelay(100, 300);
      }
    }
  }
  /**
   * Scroll with random stops
   * @private
   */
  async _scrollWithStops(page, direction = "down") {
    const scrollHeight = await page.evaluate(() => document.body.scrollHeight);
    const viewportHeight = await page.evaluate(() => window.innerHeight);
    const steps = Math.floor(scrollHeight / viewportHeight);
    for (let i = 0; i < steps; i++) {
      await page.evaluate((dir, vh) => {
        window.scrollBy(0, dir === "down" ? vh : -vh);
      }, direction, viewportHeight);
      await this._randomDelay(500, 1500);
      if (this.config.humanBehavior.scrolling.backScroll && Math.random() < 0.1) {
        await page.evaluate(() => window.scrollBy(0, -100));
        await this._randomDelay(200, 500);
      }
    }
  }
  /**
   * Random delay helper
   * @private
   */
  async _randomDelay(min, max) {
    const delay = min + Math.random() * (max - min);
    return new Promise((resolve) => setTimeout(resolve, delay));
  }
  /**
   * Farm cookies for a session
   * @param {string} sessionId - Session identifier
   * @returns {Promise<void>}
   */
  async farmCookies(sessionId) {
    if (!this.cookieManager) {
      throw new Error("Cookie manager not initialized");
    }
    return await this.cookieManager.farmCookies(sessionId);
  }
  /**
   * Get cookie pool statistics
   * @returns {Promise<Object>}
   */
  async getCookieStats() {
    if (!this.cookieManager) {
      throw new Error("Cookie manager not initialized");
    }
    return await this.cookieManager.getStats();
  }
  /**
   * Get proxy pool statistics
   * @returns {Array}
   */
  getProxyStats() {
    if (!this.proxyManager) {
      throw new Error("Proxy manager not initialized");
    }
    return this.proxyManager.getProxyStats();
  }
  /**
   * Get session-proxy bindings
   * @returns {Array}
   */
  getSessionProxyBindings() {
    if (!this.proxyManager) {
      throw new Error("Proxy manager not initialized");
    }
    return this.proxyManager.getSessionBindings();
  }
  /**
   * Check health of all proxies
   * @returns {Promise<Object>}
   */
  async checkProxyHealth() {
    if (!this.proxyManager) {
      throw new Error("Proxy manager not initialized");
    }
    return await this.proxyManager.checkAllProxies();
  }
}

class CookieFarmError extends PluginError {
  constructor(message, details = {}) {
    const merged = {
      pluginName: details.pluginName || "CookieFarmPlugin",
      operation: details.operation || "unknown",
      statusCode: details.statusCode ?? 500,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Check CookieFarmPlugin configuration and persona storage before retrying.",
      ...details
    };
    super(message, merged);
  }
}
class PersonaNotFoundError extends CookieFarmError {
  constructor(personaId, details = {}) {
    super(`Persona not found: ${personaId}`, {
      code: "PERSONA_NOT_FOUND",
      personaId,
      statusCode: 404,
      retriable: false,
      suggestion: "Ensure the persona exists or create it before running CookieFarm operations.",
      docs: details.docs || "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/cookie-farm.md",
      ...details
    });
    this.name = "PersonaNotFoundError";
  }
}

class CookieFarmPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    const resourceNamesOption = options.resourceNames || {};
    this.config = {
      // Persona generation
      generation: {
        count: 10,
        // Initial personas to generate
        proxies: [],
        // List of proxies to use
        userAgentStrategy: "random",
        // 'random' | 'desktop-only' | 'mobile-only'
        viewportStrategy: "varied",
        // 'varied' | 'fixed' | 'desktop-only'
        ...options.generation
      },
      // Warmup process
      warmup: {
        enabled: true,
        sites: [
          "https://www.google.com",
          "https://www.youtube.com",
          "https://www.wikipedia.org",
          "https://www.reddit.com",
          "https://www.amazon.com"
        ],
        sitesPerPersona: 5,
        randomOrder: true,
        timePerSite: { min: 1e4, max: 2e4 },
        interactions: {
          scroll: true,
          hover: true,
          click: false
          // Safer - avoid accidental navigation
        },
        ...options.warmup
      },
      // Quality scoring
      quality: {
        enabled: true,
        factors: {
          age: 0.3,
          // 30% weight
          successRate: 0.4,
          // 40% weight
          requestCount: 0.2,
          // 20% weight
          warmupCompleted: 0.1
          // 10% weight
        },
        thresholds: {
          high: 0.8,
          // >= 80% = high quality
          medium: 0.5,
          // >= 50% = medium quality
          low: 0
          // < 50% = low quality
        },
        ...options.quality
      },
      // Rotation strategy
      rotation: {
        enabled: true,
        maxAge: 864e5,
        // 24 hours
        maxRequests: 200,
        minQualityScore: 0.3,
        retireOnFailureRate: 0.3,
        // Retire if success rate < 30%
        ...options.rotation
      },
      // Storage
      storage: {
        resource: "cookie_farm_personas",
        encrypt: true,
        ...options.storage
      },
      // Export/Import
      export: {
        format: "json",
        // 'json' | 'csv'
        includeCredentials: false,
        // Mask proxy credentials
        ...options.export
      },
      // Stealth mode (anti-detection)
      stealth: {
        enabled: true,
        timingProfile: "normal",
        // 'very-slow' | 'slow' | 'normal' | 'fast'
        consistentFingerprint: true,
        // Maintain consistent fingerprint per persona
        executeJSChallenges: true,
        // Auto-solve JS challenges
        humanBehavior: true,
        // Simulate mouse/scroll/typing
        requestPacing: true,
        // Throttle requests to avoid rate limits
        geoConsistency: true,
        // Match timezone/language to proxy geo
        ...options.stealth
      }
    };
    this._storageResourceDescriptor = {
      defaultName: "plg_cookie_farm_personas",
      override: resourceNamesOption.personas || options.storage?.resource
    };
    this.config.storage.resource = this._resolveStorageResourceName();
    this.puppeteerPlugin = null;
    this.stealthManager = null;
    this.personaPool = /* @__PURE__ */ new Map();
    this.initialized = false;
  }
  _resolveStorageResourceName() {
    return resolveResourceName("cookiefarm", this._storageResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    if (this.config?.storage) {
      this.config.storage.resource = this._resolveStorageResourceName();
    }
  }
  /**
   * Install plugin and validate dependencies
   */
  async onInstall() {
    const puppeteerPlugin = this._findPuppeteerDependency();
    if (!puppeteerPlugin) {
      throw new CookieFarmError("PuppeteerPlugin is required before installing CookieFarmPlugin", {
        pluginName: "CookieFarmPlugin",
        operation: "onInstall",
        statusCode: 400,
        retriable: false,
        suggestion: "Install PuppeteerPlugin in db configuration before adding CookieFarmPlugin."
      });
    }
    this.puppeteerPlugin = puppeteerPlugin;
    await this._setupPersonaStorage();
    this.emit("cookieFarm.installed");
  }
  /**
   * Locate PuppeteerPlugin dependency respecting namespaces
   * @private
   */
  _findPuppeteerDependency() {
    const registries = [
      this.database?.plugins,
      this.database?.pluginRegistry,
      Array.isArray(this.database?.pluginList) ? this.database.pluginList : null
    ].filter(Boolean);
    const candidates = [];
    for (const registry of registries) {
      if (Array.isArray(registry)) {
        candidates.push(...registry);
      } else {
        candidates.push(...Object.values(registry));
      }
    }
    if (candidates.length === 0) {
      return null;
    }
    const sameNamespace = candidates.find(
      (plugin) => plugin instanceof PuppeteerPlugin && (plugin.namespace === this.namespace || !this.namespace)
    );
    if (sameNamespace) return sameNamespace;
    return candidates.find((plugin) => plugin instanceof PuppeteerPlugin) || null;
  }
  /**
   * Start plugin
   */
  async onStart() {
    if (this.initialized) return;
    if (this.config.stealth.enabled) {
      const { StealthManager } = await Promise.resolve().then(function () { return stealthManager; });
      this.stealthManager = new StealthManager(this);
      this.emit("cookieFarm.stealthEnabled");
    }
    await this._loadPersonaPool();
    if (this.personaPool.size === 0 && this.config.generation.count > 0) {
      this.emit("cookieFarm.generatingInitialPersonas", {
        count: this.config.generation.count
      });
      await this.generatePersonas(this.config.generation.count);
    }
    this.initialized = true;
    this.emit("cookieFarm.started", {
      personaCount: this.personaPool.size,
      stealthEnabled: this.config.stealth.enabled
    });
  }
  /**
   * Stop plugin
   */
  async onStop() {
    this.initialized = false;
    this.emit("cookieFarm.stopped");
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    await this.onStop();
    this.emit("cookieFarm.uninstalled");
  }
  /**
   * Setup persona storage resource
   * @private
   */
  async _setupPersonaStorage() {
    const resourceName = this.config.storage.resource;
    try {
      await this.database.getResource(resourceName);
      return;
    } catch (err) {
      if (!["ResourceNotFoundError", "ResourceNotFound"].includes(err?.name)) {
        throw err;
      }
    }
    const [created, createErr] = await tryFn(() => this.database.createResource({
      name: resourceName,
      attributes: {
        personaId: "string|required",
        sessionId: "string|required",
        proxyId: "string|optional",
        userAgent: "string|required",
        viewport: {
          width: "number|required",
          height: "number|required",
          deviceScaleFactor: "number"
        },
        cookies: "array",
        fingerprint: {
          proxy: "string",
          userAgent: "string",
          viewport: "string"
        },
        reputation: {
          successCount: "number",
          failCount: "number",
          successRate: "number",
          totalRequests: "number"
        },
        quality: {
          score: "number",
          rating: "string",
          lastCalculated: "number"
        },
        metadata: {
          createdAt: "number",
          lastUsed: "number",
          expiresAt: "number",
          age: "number",
          warmupCompleted: "boolean",
          retired: "boolean"
        }
      },
      timestamps: true,
      behavior: "body-only",
      partitions: {
        byQuality: {
          fields: { "quality.rating": "string" }
        },
        byProxy: {
          fields: { proxyId: "string" }
        },
        byRetirement: {
          fields: { "metadata.retired": "boolean" }
        }
      }
    }));
    if (!created) {
      const existing = this.database.resources?.[resourceName];
      if (!existing) {
        throw createErr;
      }
    }
  }
  /**
   * Load persona pool from storage
   * @private
   */
  async _loadPersonaPool() {
    const storage = await this.database.getResource(this.config.storage.resource);
    const personas = await storage.list({ limit: 1e3 });
    for (const persona of personas) {
      this.personaPool.set(persona.personaId, persona);
    }
    this.emit("cookieFarm.personasLoaded", {
      count: this.personaPool.size
    });
  }
  /**
   * Generate new personas
   * @param {number} count - Number of personas to generate
   * @param {Object} options - Generation options
   * @returns {Promise<Array>}
   */
  async generatePersonas(count = 1, options = {}) {
    const {
      proxies = this.config.generation.proxies,
      warmup = this.config.warmup.enabled
    } = options;
    const generatedPersonas = [];
    for (let i = 0; i < count; i++) {
      const persona = await this._createPersona(proxies);
      generatedPersonas.push(persona);
      this.emit("cookieFarm.personaCreated", {
        personaId: persona.personaId,
        proxyId: persona.proxyId
      });
      if (warmup) {
        await this.warmupPersona(persona.personaId);
      }
    }
    this.emit("cookieFarm.personasGenerated", {
      count: generatedPersonas.length
    });
    return generatedPersonas;
  }
  /**
   * Create a single persona
   * @private
   * @param {Array} proxies - Available proxies
   * @returns {Promise<Object>}
   */
  async _createPersona(proxies = []) {
    const personaId = `persona_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const sessionId = `session_${personaId}`;
    const userAgent = this._generateUserAgent();
    const viewport = this._generateViewport();
    const fingerprint = {
      userAgent,
      viewport: `${viewport.width}x${viewport.height}`,
      proxy: null
    };
    let proxyId = null;
    if (proxies.length > 0 && this.puppeteerPlugin.config.proxy.enabled) {
      const proxy = this.puppeteerPlugin.proxyManager.getProxyForSession(sessionId, true);
      proxyId = proxy?.id || null;
      fingerprint.proxy = proxyId;
    }
    const persona = {
      personaId,
      sessionId,
      proxyId,
      userAgent,
      viewport,
      cookies: [],
      fingerprint,
      reputation: {
        successCount: 0,
        failCount: 0,
        successRate: 1,
        totalRequests: 0
      },
      quality: {
        score: 0,
        rating: "low",
        lastCalculated: Date.now()
      },
      metadata: {
        createdAt: Date.now(),
        lastUsed: null,
        expiresAt: Date.now() + this.config.rotation.maxAge,
        age: 0,
        warmupCompleted: false,
        retired: false
      }
    };
    const storage = this.database.getResource(this.config.storage.resource);
    await storage.insert(persona);
    this.personaPool.set(personaId, persona);
    return persona;
  }
  /**
   * Generate user agent based on strategy
   * @private
   */
  _generateUserAgent() {
    this.config.generation.userAgentStrategy;
    const desktopAgents = [
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ];
    return desktopAgents[Math.floor(Math.random() * desktopAgents.length)];
  }
  /**
   * Generate viewport based on strategy
   * @private
   */
  _generateViewport() {
    this.config.generation.viewportStrategy;
    const viewports = [
      { width: 1920, height: 1080, deviceScaleFactor: 1 },
      { width: 1680, height: 1050, deviceScaleFactor: 1 },
      { width: 1440, height: 900, deviceScaleFactor: 1 },
      { width: 1366, height: 768, deviceScaleFactor: 1 },
      { width: 1280, height: 800, deviceScaleFactor: 1 }
    ];
    return viewports[Math.floor(Math.random() * viewports.length)];
  }
  /**
   * Warmup a persona by visiting trusted sites
   * @param {string} personaId - Persona identifier
   * @returns {Promise<void>}
   */
  async warmupPersona(personaId) {
    const persona = this.personaPool.get(personaId);
    if (!persona) {
      throw new PersonaNotFoundError(personaId);
    }
    if (persona.metadata.warmupCompleted) {
      this.emit("cookieFarm.warmupSkipped", {
        personaId,
        reason: "already completed"
      });
      return;
    }
    this.emit("cookieFarm.warmupStarted", { personaId });
    const sites = [...this.config.warmup.sites];
    const sitesToVisit = sites.slice(0, this.config.warmup.sitesPerPersona);
    if (this.config.warmup.randomOrder) {
      sitesToVisit.sort(() => Math.random() - 0.5);
    }
    for (const url of sitesToVisit) {
      try {
        await this._visitSite(persona, url);
        this.emit("cookieFarm.warmupSiteCompleted", {
          personaId,
          url
        });
      } catch (err) {
        this.emit("cookieFarm.warmupSiteFailed", {
          personaId,
          url,
          error: err.message
        });
      }
    }
    persona.metadata.warmupCompleted = true;
    await this._calculateQuality(persona);
    await this._savePersona(persona);
    this.emit("cookieFarm.warmupCompleted", { personaId });
  }
  /**
   * Visit a site with persona
   * @private
   */
  async _visitSite(persona, url) {
    const page = await this.puppeteerPlugin.navigate(url, {
      useSession: persona.sessionId
    });
    const timeOnSite = this.config.warmup.timePerSite.min + Math.random() * (this.config.warmup.timePerSite.max - this.config.warmup.timePerSite.min);
    if (this.config.warmup.interactions.scroll) {
      await page.humanScroll({ direction: "down" });
      await this._delay(1e3);
    }
    if (this.config.warmup.interactions.hover) {
      try {
        const elements = await page.$$("a, button");
        if (elements.length > 0) {
          const randomElement = elements[Math.floor(Math.random() * elements.length)];
          await randomElement.hover();
        }
      } catch (err) {
      }
    }
    await this._delay(timeOnSite);
    persona.reputation.successCount++;
    persona.reputation.totalRequests++;
    persona.reputation.successRate = persona.reputation.successCount / persona.reputation.totalRequests;
    persona.metadata.lastUsed = Date.now();
    await page.close();
  }
  /**
   * Calculate quality score for persona
   * @private
   */
  async _calculateQuality(persona) {
    if (!this.config.quality.enabled) {
      return;
    }
    const factors = this.config.quality.factors;
    let score = 0;
    const ageInHours = persona.metadata.age / (1e3 * 60 * 60);
    const ageScore = Math.min(ageInHours / 24, 1);
    score += ageScore * factors.age;
    score += persona.reputation.successRate * factors.successRate;
    const requestScore = Math.min(
      persona.reputation.totalRequests / this.config.rotation.maxRequests,
      1
    );
    score += requestScore * factors.requestCount;
    const warmupScore = persona.metadata.warmupCompleted ? 1 : 0;
    score += warmupScore * factors.warmupCompleted;
    persona.quality.score = score;
    const thresholds = this.config.quality.thresholds;
    if (score >= thresholds.high) {
      persona.quality.rating = "high";
    } else if (score >= thresholds.medium) {
      persona.quality.rating = "medium";
    } else {
      persona.quality.rating = "low";
    }
    persona.quality.lastCalculated = Date.now();
  }
  /**
   * Save persona to storage
   * @private
   */
  async _savePersona(persona) {
    persona.metadata.age = Date.now() - persona.metadata.createdAt;
    const storage = this.database.getResource(this.config.storage.resource);
    await storage.update(persona.id, persona);
  }
  /**
   * Get persona by criteria
   * @param {Object} criteria - Selection criteria
   * @returns {Promise<Object|null>}
   */
  async getPersona(criteria = {}) {
    const {
      quality = null,
      // 'low' | 'medium' | 'high'
      minQualityScore = 0,
      proxyId = null,
      excludeRetired = true
    } = criteria;
    const candidates = Array.from(this.personaPool.values()).filter((persona) => {
      if (excludeRetired && persona.metadata.retired) {
        return false;
      }
      if (quality && persona.quality.rating !== quality) {
        return false;
      }
      if (persona.quality.score < minQualityScore) {
        return false;
      }
      if (proxyId && persona.proxyId !== proxyId) {
        return false;
      }
      return true;
    });
    if (candidates.length === 0) {
      return null;
    }
    candidates.sort((a, b) => b.quality.score - a.quality.score);
    return candidates[0];
  }
  /**
   * Record persona usage
   * @param {string} personaId - Persona identifier
   * @param {Object} result - Usage result
   */
  async recordUsage(personaId, result = {}) {
    const { success = true } = result;
    const persona = this.personaPool.get(personaId);
    if (!persona) {
      throw new PersonaNotFoundError(personaId);
    }
    persona.reputation.totalRequests++;
    persona.metadata.lastUsed = Date.now();
    if (success) {
      persona.reputation.successCount++;
    } else {
      persona.reputation.failCount++;
    }
    persona.reputation.successRate = persona.reputation.successCount / persona.reputation.totalRequests;
    await this._calculateQuality(persona);
    if (this._shouldRetire(persona)) {
      await this.retirePersona(personaId);
    } else {
      await this._savePersona(persona);
    }
    this.emit("cookieFarm.usageRecorded", {
      personaId,
      success,
      quality: persona.quality
    });
  }
  /**
   * Check if persona should be retired
   * @private
   */
  _shouldRetire(persona) {
    if (!this.config.rotation.enabled) {
      return false;
    }
    if (Date.now() > persona.metadata.expiresAt) {
      return true;
    }
    if (persona.reputation.totalRequests >= this.config.rotation.maxRequests) {
      return true;
    }
    if (persona.reputation.successRate < this.config.rotation.retireOnFailureRate) {
      return true;
    }
    if (persona.quality.score < this.config.rotation.minQualityScore) {
      return true;
    }
    return false;
  }
  /**
   * Retire a persona
   * @param {string} personaId - Persona identifier
   */
  async retirePersona(personaId) {
    const persona = this.personaPool.get(personaId);
    if (!persona) {
      throw new PersonaNotFoundError(personaId);
    }
    persona.metadata.retired = true;
    await this._savePersona(persona);
    this.emit("cookieFarm.personaRetired", {
      personaId,
      reason: "rotation policy"
    });
  }
  /**
   * Get statistics
   * @returns {Promise<Object>}
   */
  async getStats() {
    const personas = Array.from(this.personaPool.values());
    const stats = {
      total: personas.length,
      active: 0,
      retired: 0,
      byQuality: { high: 0, medium: 0, low: 0 },
      byProxy: {},
      warmupCompleted: 0,
      averageQualityScore: 0,
      averageSuccessRate: 0,
      totalRequests: 0
    };
    let qualitySum = 0;
    let successRateSum = 0;
    for (const persona of personas) {
      if (persona.metadata.retired) {
        stats.retired++;
      } else {
        stats.active++;
      }
      stats.byQuality[persona.quality.rating]++;
      if (persona.proxyId) {
        stats.byProxy[persona.proxyId] = (stats.byProxy[persona.proxyId] || 0) + 1;
      }
      if (persona.metadata.warmupCompleted) {
        stats.warmupCompleted++;
      }
      qualitySum += persona.quality.score;
      successRateSum += persona.reputation.successRate;
      stats.totalRequests += persona.reputation.totalRequests;
    }
    if (personas.length > 0) {
      stats.averageQualityScore = qualitySum / personas.length;
      stats.averageSuccessRate = successRateSum / personas.length;
    }
    return stats;
  }
  /**
   * Export personas
   * @param {Object} options - Export options
   * @returns {Promise<Array>}
   */
  async exportPersonas(options = {}) {
    const { includeRetired = false, format = this.config.export.format } = options;
    const personas = Array.from(this.personaPool.values()).filter((persona) => includeRetired || !persona.metadata.retired);
    if (!this.config.export.includeCredentials) {
      personas.forEach((persona) => {
        if (persona.fingerprint.proxy) {
          persona.fingerprint.proxy = persona.proxyId;
        }
      });
    }
    return personas;
  }
  /**
   * Delay helper
   * @private
   */
  async _delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}

class QueueError extends S3dbError {
  constructor(message, details = {}) {
    const { queueName, operation = "unknown", messageId, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Queue Operation Error

Operation: ${operation}
${queueName ? `Queue: ${queueName}` : ""}
${messageId ? `Message ID: ${messageId}` : ""}

Common causes:
1. Queue not properly configured
2. Message handler not registered
3. Queue resource not found
4. SQS/RabbitMQ connection failed
5. Message processing timeout

Solution:
Check queue configuration and message handler registration.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue.md
`.trim();
    }
    super(message, { ...rest, queueName, operation, messageId, description });
  }
}

class S3QueuePlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    const resourceNamesOption = options.resourceNames || {};
    if (!options.resource) {
      throw new QueueError('S3QueuePlugin requires "resource" option', {
        pluginName: "S3QueuePlugin",
        operation: "constructor",
        statusCode: 400,
        retriable: false,
        suggestion: 'Provide the target resource name: new S3QueuePlugin({ resource: "orders", ... }).'
      });
    }
    this.config = {
      ...options,
      resource: options.resource,
      visibilityTimeout: options.visibilityTimeout ?? 3e4,
      // 30 seconds
      pollInterval: options.pollInterval ?? 1e3,
      // 1 second
      maxAttempts: options.maxAttempts ?? 3,
      concurrency: options.concurrency ?? 1,
      deadLetterResource: options.deadLetterResource ?? null,
      autoStart: options.autoStart !== false,
      onMessage: options.onMessage,
      onError: options.onError,
      onComplete: options.onComplete,
      verbose: options.verbose ?? false
    };
    this.config.pollBatchSize = options.pollBatchSize ?? Math.max((this.config.concurrency || 1) * 4, 16);
    this.config.recoveryInterval = options.recoveryInterval ?? 5e3;
    this.config.recoveryBatchSize = options.recoveryBatchSize ?? Math.max((this.config.concurrency || 1) * 2, 10);
    this.config.processedCacheTTL = options.processedCacheTTL ?? 3e4;
    this.config.maxPollInterval = options.maxPollInterval ?? this.config.pollInterval;
    this._queueResourceDescriptor = {
      defaultName: `plg_s3queue_${this.config.resource}_queue`,
      override: resourceNamesOption.queue || options.queueResource
    };
    this.queueResourceName = this._resolveQueueResourceName();
    this.config.queueResourceName = this.queueResourceName;
    if (this.config.deadLetterResource) {
      this._deadLetterDescriptor = {
        defaultName: `plg_s3queue_${this.config.resource}_dead`,
        override: resourceNamesOption.deadLetter || this.config.deadLetterResource
      };
    } else {
      this._deadLetterDescriptor = null;
    }
    this.deadLetterResourceName = this._resolveDeadLetterResourceName();
    this.config.deadLetterResource = this.deadLetterResourceName;
    this.queueResource = null;
    this.targetResource = null;
    this.deadLetterResourceObj = null;
    this.workers = [];
    this.isRunning = false;
    this.workerId = `worker-${Date.now()}-${Math.random().toString(36).slice(2, 9)}`;
    this.processedCache = /* @__PURE__ */ new Map();
    this.cacheCleanupInterval = null;
    this.lockCleanupInterval = null;
    this.messageLocks = /* @__PURE__ */ new Map();
    this._lastRecovery = 0;
    this._recoveryInFlight = false;
  }
  _resolveQueueResourceName() {
    return resolveResourceName("s3queue", this._queueResourceDescriptor, {
      namespace: this.namespace
    });
  }
  _resolveDeadLetterResourceName() {
    if (!this._deadLetterDescriptor) return null;
    return resolveResourceName("s3queue", this._deadLetterDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    if (!this._queueResourceDescriptor) return;
    this.queueResourceName = this._resolveQueueResourceName();
    this.config.queueResourceName = this.queueResourceName;
    this.deadLetterResourceName = this._resolveDeadLetterResourceName();
    this.config.deadLetterResource = this.deadLetterResourceName;
  }
  async onInstall() {
    this.targetResource = this.database.resources[this.config.resource];
    if (!this.targetResource) {
      throw new QueueError(`Resource '${this.config.resource}' not found`, {
        pluginName: "S3QueuePlugin",
        operation: "onInstall",
        resourceName: this.config.resource,
        statusCode: 404,
        retriable: false,
        suggestion: "Create the resource before installing S3QueuePlugin or update the plugin configuration.",
        availableResources: Object.keys(this.database.resources || {})
      });
    }
    const queueName = this.queueResourceName;
    const [ok, err] = await tryFn(
      () => this.database.createResource({
        name: queueName,
        attributes: {
          id: "string|required",
          originalId: "string|required",
          // ID do registro original
          status: "string|required",
          // pending/processing/completed/failed/dead
          visibleAt: "number|required",
          // Timestamp de visibilidade
          claimedBy: "string|optional",
          // Worker que claimed
          claimedAt: "number|optional",
          // Timestamp do claim
          attempts: "number|default:0",
          maxAttempts: "number|default:3",
          error: "string|optional",
          result: "json|optional",
          createdAt: "string|required",
          completedAt: "number|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        asyncPartitions: true,
        partitions: {
          byStatus: { fields: { status: "string" } },
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        }
      })
    );
    if (ok) {
      this.queueResource = this.database.resources[queueName];
    } else {
      this.queueResource = this.database.resources[queueName];
      if (!this.queueResource) {
        throw new QueueError(`Failed to create queue resource: ${err?.message}`, {
          pluginName: "S3QueuePlugin",
          operation: "createQueueResource",
          queueName,
          statusCode: 500,
          retriable: false,
          suggestion: "Check database permissions and ensure createResource() was successful.",
          original: err
        });
      }
    }
    this.queueResourceName = this.queueResource.name;
    this.addHelperMethods();
    if (this.config.deadLetterResource) {
      await this.createDeadLetterResource();
    }
    if (this.config.verbose) {
      console.log(`[S3QueuePlugin] Setup completed for resource '${this.config.resource}'`);
    }
  }
  async onStart() {
    if (this.config.autoStart && this.config.onMessage) {
      await this.startProcessing();
    }
  }
  async onStop() {
    await this.stopProcessing();
  }
  addHelperMethods() {
    const plugin = this;
    const resource = this.targetResource;
    resource.enqueue = async function(data, options = {}) {
      const recordData = {
        id: data.id || idGenerator(),
        ...data
      };
      const record = await resource.insert(recordData);
      const queueEntry = {
        id: idGenerator(),
        originalId: record.id,
        status: "pending",
        visibleAt: Date.now(),
        attempts: 0,
        maxAttempts: options.maxAttempts || plugin.config.maxAttempts,
        createdAt: (/* @__PURE__ */ new Date()).toISOString().slice(0, 10)
      };
      await plugin.queueResource.insert(queueEntry);
      plugin.emit("plg:s3-queue:message-enqueued", { id: record.id, queueId: queueEntry.id });
      return record;
    };
    resource.queueStats = async function() {
      return await plugin.getStats();
    };
    resource.startProcessing = async function(handler, options = {}) {
      return await plugin.startProcessing(handler, options);
    };
    resource.stopProcessing = async function() {
      return await plugin.stopProcessing();
    };
    resource.extendQueueVisibility = async function(queueId, extraMilliseconds) {
      return await plugin.extendVisibility(queueId, extraMilliseconds);
    };
    resource.clearQueueCache = async function() {
      plugin.clearProcessedCache();
    };
  }
  async startProcessing(handler = null, options = {}) {
    if (this.isRunning) {
      if (this.config.verbose) {
        console.log("[S3QueuePlugin] Already running");
      }
      return;
    }
    const messageHandler = handler || this.config.onMessage;
    if (!messageHandler) {
      throw new QueueError("onMessage handler required", {
        pluginName: "S3QueuePlugin",
        operation: "startProcessing",
        queueName: this.queueResourceName,
        statusCode: 400,
        retriable: false,
        suggestion: "Pass a handler: resource.startProcessing(async msg => {...}) or configure onMessage in plugin options."
      });
    }
    this.isRunning = true;
    const concurrency = options.concurrency || this.config.concurrency;
    this.cacheCleanupInterval = setInterval(() => {
      const now = Date.now();
      const ttl = this.config.processedCacheTTL;
      for (const [queueId, expiresAt] of this.processedCache.entries()) {
        if (expiresAt <= now || expiresAt - now > ttl * 4) {
          this.processedCache.delete(queueId);
        }
      }
    }, 5e3);
    this._lastRecovery = 0;
    for (let i = 0; i < concurrency; i++) {
      const worker = this.createWorker(messageHandler, i);
      this.workers.push(worker);
    }
    if (this.config.verbose) {
      console.log(`[S3QueuePlugin] Started ${concurrency} workers`);
    }
    this.emit("plg:s3-queue:workers-started", { concurrency, workerId: this.workerId });
  }
  async stopProcessing() {
    if (!this.isRunning) return;
    this.isRunning = false;
    if (this.cacheCleanupInterval) {
      clearInterval(this.cacheCleanupInterval);
      this.cacheCleanupInterval = null;
    }
    await Promise.all(this.workers);
    this.workers = [];
    this.processedCache.clear();
    if (this.config.verbose) {
      console.log("[S3QueuePlugin] Stopped all workers");
    }
    this.emit("plg:s3-queue:workers-stopped", { workerId: this.workerId });
  }
  createWorker(handler, workerIndex) {
    return (async () => {
      let idleStreak = 0;
      while (this.isRunning) {
        try {
          const message = await this.claimMessage();
          if (message) {
            idleStreak = 0;
            await this.processMessage(message, handler);
          } else {
            idleStreak = Math.min(idleStreak + 1, 10);
            const delay = this._computeIdleDelay(idleStreak);
            await this._sleep(delay);
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[Worker ${workerIndex}] Error:`, error.message);
          }
          await this._sleep(1e3);
        }
      }
    })();
  }
  async claimMessage() {
    const now = Date.now();
    await this.recoverStalledMessages(now);
    const [ok, err, messages] = await tryFn(
      () => this.queueResource.query({
        status: "pending",
        visibleAt: { "<=": now }
      }, {
        limit: this.config.pollBatchSize
      })
    );
    if (!ok || !messages || messages.length === 0) {
      return null;
    }
    const available = messages.filter((m) => m.visibleAt <= now);
    if (available.length === 0) {
      return null;
    }
    for (const msg of available) {
      const claimed = await this.attemptClaim(msg);
      if (claimed) {
        return claimed;
      }
    }
    return null;
  }
  /**
   * Acquire a distributed lock using PluginStorage TTL
   * This ensures only one worker can claim a message at a time
   */
  _lockNameForMessage(messageId) {
    return `msg-${messageId}`;
  }
  async acquireLock(messageId) {
    const storage = this.getStorage();
    const lockName = this._lockNameForMessage(messageId);
    try {
      const lock = await storage.acquireLock(lockName, {
        ttl: 5,
        // 5 seconds
        timeout: 0,
        // Don't wait if locked
        workerId: this.workerId
      });
      if (lock) {
        this.messageLocks.set(lock.name, lock);
      }
      return lock;
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[acquireLock] Error: ${error.message}`);
      }
      return null;
    }
  }
  /**
   * Release a distributed lock via PluginStorage
   */
  async releaseLock(lockOrMessageId) {
    const storage = this.getStorage();
    let lock = null;
    if (lockOrMessageId && typeof lockOrMessageId === "object") {
      lock = lockOrMessageId;
    } else {
      const lockName = this._lockNameForMessage(lockOrMessageId);
      lock = this.messageLocks.get(lockName) || null;
    }
    if (!lock) {
      return;
    }
    try {
      await storage.releaseLock(lock);
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[releaseLock] Failed to release lock '${lock.name}': ${error.message}`);
      }
    } finally {
      if (lock?.name) {
        this.messageLocks.delete(lock.name);
      }
    }
  }
  /**
   * Clean up stale locks - NO LONGER NEEDED
   * TTL handles automatic expiration, no manual cleanup required
   */
  async cleanupStaleLocks() {
    return;
  }
  async attemptClaim(msg) {
    const now = Date.now();
    const lock = await this.acquireLock(msg.id);
    if (!lock) {
      return null;
    }
    try {
      const alreadyProcessed = await this._isRecentlyProcessed(msg.id);
      if (alreadyProcessed) {
        if (this.config.verbose) {
          console.log(`[attemptClaim] Message ${msg.id} already processed (in cache)`);
        }
        return null;
      }
      await this._markMessageProcessed(msg.id);
    } finally {
      await this.releaseLock(lock);
    }
    const [okGet, errGet, msgWithETag] = await tryFn(
      () => this.queueResource.get(msg.id)
    );
    if (!okGet || !msgWithETag) {
      await this._clearProcessedMarker(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Message ${msg.id} not found or error: ${errGet?.message}`);
      }
      return null;
    }
    if (msgWithETag.status !== "pending" || msgWithETag.visibleAt > now) {
      this.processedCache.delete(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Message ${msg.id} not claimable: status=${msgWithETag.status}, visibleAt=${msgWithETag.visibleAt}, now=${now}`);
      }
      return null;
    }
    if (this.config.verbose) {
      console.log(`[attemptClaim] Attempting to claim ${msg.id} with ETag: ${msgWithETag._etag}`);
    }
    const [ok, err, result] = await tryFn(
      () => this.queueResource.updateConditional(msgWithETag.id, {
        status: "processing",
        claimedBy: this.workerId,
        claimedAt: now,
        visibleAt: now + this.config.visibilityTimeout,
        attempts: msgWithETag.attempts + 1
      }, {
        ifMatch: msgWithETag._etag
        //  ATOMIC CLAIM using ETag!
      })
    );
    if (!ok || !result.success) {
      this.processedCache.delete(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Failed to claim ${msg.id}: ${err?.message || result.error}`);
      }
      return null;
    }
    if (this.config.verbose) {
      console.log(`[attemptClaim] Successfully claimed ${msg.id}`);
    }
    const [okRecord, errRecord, record] = await tryFn(
      () => this.targetResource.get(msgWithETag.originalId)
    );
    if (!okRecord) {
      await this.failMessage(msgWithETag.id, "Original record not found");
      return null;
    }
    return {
      queueId: msgWithETag.id,
      record,
      attempts: msgWithETag.attempts + 1,
      maxAttempts: msgWithETag.maxAttempts
    };
  }
  async processMessage(message, handler) {
    const startTime = Date.now();
    try {
      const result = await handler(message.record, {
        queueId: message.queueId,
        attempts: message.attempts,
        workerId: this.workerId
      });
      await this.completeMessage(message.queueId, result);
      const duration = Date.now() - startTime;
      this.emit("plg:s3-queue:message-completed", {
        queueId: message.queueId,
        originalId: message.record.id,
        duration,
        attempts: message.attempts
      });
      if (this.config.onComplete) {
        await this.config.onComplete(message.record, result);
      }
    } catch (error) {
      const shouldRetry = message.attempts < message.maxAttempts;
      if (shouldRetry) {
        await this.retryMessage(message.queueId, message.attempts, error.message);
        this.emit("plg:s3-queue:message-retry", {
          queueId: message.queueId,
          originalId: message.record.id,
          attempts: message.attempts,
          error: error.message
        });
      } else {
        await this.moveToDeadLetter(message.queueId, message.record, error.message);
        this.emit("plg:s3-queue:message-dead", {
          queueId: message.queueId,
          originalId: message.record.id,
          error: error.message
        });
      }
      if (this.config.onError) {
        await this.config.onError(error, message.record);
      }
    }
  }
  async completeMessage(queueId, result) {
    await this.queueResource.update(queueId, {
      status: "completed",
      completedAt: Date.now(),
      result
    });
  }
  async failMessage(queueId, error) {
    await this.queueResource.update(queueId, {
      status: "failed",
      error
    });
    await this._clearProcessedMarker(queueId);
  }
  async retryMessage(queueId, attempts, error) {
    const backoff = Math.min(Math.pow(2, attempts) * 1e3, 3e4);
    await this.queueResource.update(queueId, {
      status: "pending",
      visibleAt: Date.now() + backoff,
      error
    });
    await this._clearProcessedMarker(queueId);
  }
  async moveToDeadLetter(queueId, record, error) {
    if (this.config.deadLetterResource && this.deadLetterResourceObj) {
      const msg = await this.queueResource.get(queueId);
      await this.deadLetterResourceObj.insert({
        id: idGenerator(),
        originalId: record.id,
        queueId,
        data: record,
        error,
        attempts: msg.attempts,
        createdAt: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
    await this.queueResource.update(queueId, {
      status: "dead",
      error
    });
    await this._clearProcessedMarker(queueId);
  }
  async getStats() {
    const statusKeys = ["pending", "processing", "completed", "failed", "dead"];
    const stats = {
      total: 0,
      pending: 0,
      processing: 0,
      completed: 0,
      failed: 0,
      dead: 0
    };
    const counts = await Promise.all(
      statusKeys.map((status) => tryFn(() => this.queueResource.count({ status })))
    );
    let derivedTotal = 0;
    counts.forEach(([ok, err, count], index) => {
      const status = statusKeys[index];
      if (ok) {
        stats[status] = count || 0;
        derivedTotal += count || 0;
      } else if (this.config.verbose) {
        console.warn(`[S3QueuePlugin] Failed to count status '${status}':`, err?.message);
      }
    });
    const [totalOk, totalErr, totalCount] = await tryFn(() => this.queueResource.count());
    if (totalOk) {
      stats.total = totalCount || 0;
    } else {
      stats.total = derivedTotal;
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] Failed to count total messages:", totalErr?.message);
      }
    }
    return stats;
  }
  async createDeadLetterResource() {
    if (!this.config.deadLetterResource) return;
    const resourceName = this.config.deadLetterResource;
    const [ok, err] = await tryFn(
      () => this.database.createResource({
        name: resourceName,
        attributes: {
          id: "string|required",
          originalId: "string|required",
          queueId: "string|required",
          data: "json|required",
          error: "string|required",
          attempts: "number|required",
          createdAt: "string|required"
        },
        behavior: "body-overflow",
        timestamps: true
      })
    );
    if (ok) {
      this.deadLetterResourceObj = this.database.resources[resourceName];
    } else {
      this.deadLetterResourceObj = this.database.resources[resourceName];
      if (!this.deadLetterResourceObj) {
        throw err;
      }
    }
    this.deadLetterResourceName = this.deadLetterResourceObj.name;
    if (this.config.verbose) {
      console.log(`[S3QueuePlugin] Dead letter queue ready: ${this.deadLetterResourceName}`);
    }
  }
  async extendVisibility(queueId, extraMilliseconds) {
    if (!queueId || !extraMilliseconds || extraMilliseconds <= 0) {
      return false;
    }
    const [okGet, errGet, entry] = await tryFn(() => this.queueResource.get(queueId));
    if (!okGet || !entry) {
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] extendVisibility failed to load entry:", errGet?.message);
      }
      return false;
    }
    const baseTime = Math.max(entry.visibleAt || 0, Date.now());
    const newVisibleAt = baseTime + extraMilliseconds;
    const [okUpdate, errUpdate, result] = await tryFn(
      () => this.queueResource.updateConditional(queueId, {
        visibleAt: newVisibleAt,
        claimedAt: entry.claimedAt || Date.now()
      }, {
        ifMatch: entry._etag
      })
    );
    if (!okUpdate || !result?.success) {
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] extendVisibility conditional update failed:", errUpdate?.message || result?.error);
      }
      return false;
    }
    return true;
  }
  async recoverStalledMessages(now) {
    if (this.config.recoveryInterval <= 0) return;
    if (this._recoveryInFlight) return;
    if (this._lastRecovery && now - this._lastRecovery < this.config.recoveryInterval) {
      return;
    }
    this._recoveryInFlight = true;
    this._lastRecovery = now;
    try {
      const [ok, err, candidates] = await tryFn(
        () => this.queueResource.query({
          status: "processing",
          visibleAt: { "<=": now }
        }, {
          limit: this.config.recoveryBatchSize
        })
      );
      if (!ok) {
        if (this.config.verbose) {
          console.warn("[S3QueuePlugin] Failed to query stalled messages:", err?.message);
        }
        return;
      }
      if (!candidates || candidates.length === 0) {
        return;
      }
      for (const candidate of candidates) {
        await this._recoverSingleMessage(candidate, now);
      }
    } finally {
      this._recoveryInFlight = false;
    }
  }
  async _recoverSingleMessage(candidate, now) {
    const [okGet, errGet, queueEntry] = await tryFn(() => this.queueResource.get(candidate.id));
    if (!okGet || !queueEntry) {
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] Failed to load stalled message:", errGet?.message);
      }
      return;
    }
    if (queueEntry.status !== "processing" || queueEntry.visibleAt > now) {
      return;
    }
    if (queueEntry.maxAttempts !== void 0 && queueEntry.attempts >= queueEntry.maxAttempts) {
      let record = null;
      const [okRecord, , original] = await tryFn(() => this.targetResource.get(queueEntry.originalId));
      if (okRecord && original) {
        record = original;
      } else {
        record = { id: queueEntry.originalId, _missing: true };
      }
      await this.moveToDeadLetter(queueEntry.id, record, "visibility-timeout exceeded max attempts");
      this.emit("plg:s3-queue:message-dead", {
        queueId: queueEntry.id,
        originalId: queueEntry.originalId,
        error: "visibility-timeout exceeded max attempts"
      });
      return;
    }
    const [okUpdate, errUpdate, result] = await tryFn(
      () => this.queueResource.updateConditional(queueEntry.id, {
        status: "pending",
        visibleAt: now,
        claimedBy: null,
        claimedAt: null,
        error: "Recovered after visibility timeout"
      }, {
        ifMatch: queueEntry._etag
      })
    );
    if (!okUpdate || !result?.success) {
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] Failed to recover message:", errUpdate?.message || result?.error);
      }
      return;
    }
    await this._clearProcessedMarker(queueEntry.id);
    this.emit("plg:s3-queue:message-recovered", {
      queueId: queueEntry.id,
      originalId: queueEntry.originalId
    });
  }
  _computeIdleDelay(idleStreak) {
    const base = this.config.pollInterval;
    const maxInterval = Math.max(base, this.config.maxPollInterval || base);
    if (maxInterval <= base) {
      return base;
    }
    const factor = Math.pow(2, Math.max(0, idleStreak - 1));
    const delay = base * factor;
    return Math.min(delay, maxInterval);
  }
  async _sleep(ms) {
    if (!ms || ms <= 0) return;
    await new Promise((resolve) => setTimeout(resolve, ms));
  }
  clearProcessedCache() {
    this.processedCache.clear();
  }
  async _markMessageProcessed(messageId) {
    const ttl = Math.max(1e3, this.config.processedCacheTTL);
    const expiresAt = Date.now() + ttl;
    this.processedCache.set(messageId, expiresAt);
    const storage = this.getStorage();
    const key = storage.getPluginKey(null, "cache", "processed", messageId);
    const ttlSeconds = Math.max(1, Math.ceil(ttl / 1e3));
    const payload = {
      workerId: this.workerId,
      markedAt: Date.now()
    };
    const [ok, err] = await tryFn(
      () => storage.set(key, payload, {
        ttl: ttlSeconds,
        behavior: "body-only"
      })
    );
    if (!ok && this.config.verbose) {
      console.warn("[S3QueuePlugin] Failed to persist processed marker:", err?.message);
    }
  }
  async _isRecentlyProcessed(messageId) {
    const now = Date.now();
    const localExpiresAt = this.processedCache.get(messageId);
    if (localExpiresAt && localExpiresAt > now) {
      return true;
    }
    if (localExpiresAt && localExpiresAt <= now) {
      this.processedCache.delete(messageId);
    }
    const storage = this.getStorage();
    const key = storage.getPluginKey(null, "cache", "processed", messageId);
    const [ok, err, data] = await tryFn(() => storage.get(key));
    if (!ok) {
      if (err && err.code !== "NoSuchKey" && err.code !== "NotFound" && this.config.verbose) {
        console.warn("[S3QueuePlugin] Failed to read processed marker:", err.message || err);
      }
      return false;
    }
    if (!data) {
      return false;
    }
    const ttl = Math.max(1e3, this.config.processedCacheTTL);
    this.processedCache.set(messageId, now + ttl);
    return true;
  }
  async _clearProcessedMarker(messageId) {
    this.processedCache.delete(messageId);
    const storage = this.getStorage();
    const key = storage.getPluginKey(null, "cache", "processed", messageId);
    const [ok, err] = await tryFn(() => storage.delete(key));
    if (!ok && err && err.code !== "NoSuchKey" && err.code !== "NotFound" && this.config.verbose) {
      console.warn("[S3QueuePlugin] Failed to delete processed marker:", err.message || err);
    }
  }
}

const ONE_HOUR_SEC = 3600;
const ONE_DAY_SEC = 86400;
const THIRTY_DAYS_SEC = 2592e3;
const TEN_SECONDS_MS = 1e4;
const ONE_MINUTE_MS = 6e4;
const TEN_MINUTES_MS = 6e5;
const ONE_HOUR_MS = 36e5;
const ONE_DAY_MS = 864e5;
const ONE_WEEK_MS = 6048e5;
const SECONDS_TO_MS = 1e3;
const GRANULARITIES = {
  minute: {
    threshold: ONE_HOUR_SEC,
    // TTL < 1 hour
    interval: TEN_SECONDS_MS,
    // Check every 10 seconds
    cohortsToCheck: 3,
    // Check last 3 minutes
    cohortFormat: (date) => date.toISOString().substring(0, 16)
    // '2024-10-25T14:30'
  },
  hour: {
    threshold: ONE_DAY_SEC,
    // TTL < 24 hours
    interval: TEN_MINUTES_MS,
    // Check every 10 minutes
    cohortsToCheck: 2,
    // Check last 2 hours
    cohortFormat: (date) => date.toISOString().substring(0, 13)
    // '2024-10-25T14'
  },
  day: {
    threshold: THIRTY_DAYS_SEC,
    // TTL < 30 days
    interval: ONE_HOUR_MS,
    // Check every 1 hour
    cohortsToCheck: 2,
    // Check last 2 days
    cohortFormat: (date) => date.toISOString().substring(0, 10)
    // '2024-10-25'
  },
  week: {
    threshold: Infinity,
    // TTL >= 30 days
    interval: ONE_DAY_MS,
    // Check every 24 hours
    cohortsToCheck: 2,
    // Check last 2 weeks
    cohortFormat: (date) => {
      const year = date.getUTCFullYear();
      const week = getWeekNumber(date);
      return `${year}-W${String(week).padStart(2, "0")}`;
    }
  }
};
function getWeekNumber(date) {
  const d = new Date(Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()));
  const dayNum = d.getUTCDay() || 7;
  d.setUTCDate(d.getUTCDate() + 4 - dayNum);
  const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));
  return Math.ceil(((d - yearStart) / ONE_DAY_MS + 1) / 7);
}
function detectGranularity(ttl) {
  if (!ttl) return "day";
  if (ttl < GRANULARITIES.minute.threshold) return "minute";
  if (ttl < GRANULARITIES.hour.threshold) return "hour";
  if (ttl < GRANULARITIES.day.threshold) return "day";
  return "week";
}
function getExpiredCohorts(granularity, count) {
  const config = GRANULARITIES[granularity];
  const cohorts = [];
  const now = /* @__PURE__ */ new Date();
  for (let i = 0; i < count; i++) {
    let checkDate;
    switch (granularity) {
      case "minute":
        checkDate = new Date(now.getTime() - i * ONE_MINUTE_MS);
        break;
      case "hour":
        checkDate = new Date(now.getTime() - i * ONE_HOUR_MS);
        break;
      case "day":
        checkDate = new Date(now.getTime() - i * ONE_DAY_MS);
        break;
      case "week":
        checkDate = new Date(now.getTime() - i * ONE_WEEK_MS);
        break;
    }
    cohorts.push(config.cohortFormat(checkDate));
  }
  return cohorts;
}
class TTLPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.verbose = config.verbose !== void 0 ? config.verbose : false;
    this.resources = config.resources || {};
    this.batchSize = config.batchSize || 100;
    this.stats = {
      totalScans: 0,
      totalExpired: 0,
      totalDeleted: 0,
      totalArchived: 0,
      totalSoftDeleted: 0,
      totalCallbacks: 0,
      totalErrors: 0,
      lastScanAt: null,
      lastScanDuration: 0
    };
    this.intervals = [];
    this.isRunning = false;
    const resourceNamesOption = config.resourceNames || {};
    this.expirationIndex = null;
    this._indexResourceDescriptor = {
      defaultName: "plg_ttl_expiration_index",
      override: resourceNamesOption.index || config.indexResourceName
    };
    this.indexResourceName = this._resolveIndexResourceName();
  }
  /**
   * Install the plugin
   */
  async install(database) {
    await super.install(database);
    for (const [resourceName, config] of Object.entries(this.resources)) {
      this._validateResourceConfig(resourceName, config);
    }
    await this._createExpirationIndex();
    for (const [resourceName, config] of Object.entries(this.resources)) {
      this._setupResourceHooks(resourceName, config);
    }
    this._startIntervals();
    if (this.verbose) {
      console.log(`[TTLPlugin] Installed with ${Object.keys(this.resources).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "TTLPlugin",
      resources: Object.keys(this.resources)
    });
  }
  _resolveIndexResourceName() {
    return resolveResourceName("ttl", this._indexResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    if (!this._indexResourceDescriptor) return;
    this.indexResourceName = this._resolveIndexResourceName();
  }
  /**
   * Validate resource configuration
   */
  _validateResourceConfig(resourceName, config) {
    if (!config.ttl && !config.field) {
      throw new PluginError("[TTLPlugin] Missing TTL configuration", {
        pluginName: "TTLPlugin",
        operation: "validateResourceConfig",
        resourceName,
        statusCode: 400,
        retriable: false,
        suggestion: "Provide either ttl (in seconds) or field (absolute expiration timestamp) for each resource."
      });
    }
    const validStrategies = ["soft-delete", "hard-delete", "archive", "callback"];
    if (!config.onExpire || !validStrategies.includes(config.onExpire)) {
      throw new PluginError("[TTLPlugin] Invalid onExpire strategy", {
        pluginName: "TTLPlugin",
        operation: "validateResourceConfig",
        resourceName,
        statusCode: 400,
        retriable: false,
        suggestion: `Set onExpire to one of: ${validStrategies.join(", ")}`,
        onExpire: config.onExpire
      });
    }
    if (config.onExpire === "soft-delete" && !config.deleteField) {
      config.deleteField = "deletedat";
    }
    if (config.onExpire === "archive" && !config.archiveResource) {
      throw new PluginError("[TTLPlugin] Archive resource required", {
        pluginName: "TTLPlugin",
        operation: "validateResourceConfig",
        resourceName,
        statusCode: 400,
        retriable: false,
        suggestion: "Provide archiveResource pointing to the resource that stores archived records.",
        onExpire: config.onExpire
      });
    }
    if (config.onExpire === "callback" && typeof config.callback !== "function") {
      throw new PluginError("[TTLPlugin] Callback handler required", {
        pluginName: "TTLPlugin",
        operation: "validateResourceConfig",
        resourceName,
        statusCode: 400,
        retriable: false,
        suggestion: 'Provide a callback function: { onExpire: "callback", callback: async (ctx) => {...} }',
        onExpire: config.onExpire
      });
    }
    if (!config.field) {
      config.field = "_createdAt";
    }
    if (config.field === "_createdAt" && this.database) {
      const resource = this.database.resources[resourceName];
      if (resource && resource.$schema.timestamps === false) {
        console.warn(
          `[TTLPlugin] WARNING: Resource "${resourceName}" uses TTL with field "_createdAt" but timestamps are disabled. TTL will be calculated from indexing time, not creation time.`
        );
      }
    }
    config.granularity = detectGranularity(config.ttl);
  }
  /**
   * Create expiration index (plugin resource)
   */
  async _createExpirationIndex() {
    this.expirationIndex = await this.database.createResource({
      name: this.indexResourceName,
      attributes: {
        resourceName: "string|required",
        recordId: "string|required",
        expiresAtCohort: "string|required",
        expiresAtTimestamp: "number|required",
        // Exact expiration timestamp for precise checking
        granularity: "string|required",
        createdAt: "number"
      },
      partitions: {
        byExpiresAtCohort: {
          fields: { expiresAtCohort: "string" }
        }
      },
      asyncPartitions: false
      // Sync partitions for deterministic behavior
    });
    if (this.verbose) {
      console.log("[TTLPlugin] Created expiration index with partition");
    }
  }
  /**
   * Setup hooks for a resource
   */
  _setupResourceHooks(resourceName, config) {
    if (!this.database.resources[resourceName]) {
      if (this.verbose) {
        console.warn(`[TTLPlugin] Resource "${resourceName}" not found, skipping hooks`);
      }
      return;
    }
    const resource = this.database.resources[resourceName];
    if (typeof resource.insert !== "function" || typeof resource.delete !== "function") {
      if (this.verbose) {
        console.warn(`[TTLPlugin] Resource "${resourceName}" missing insert/delete methods, skipping hooks`);
      }
      return;
    }
    this.addMiddleware(resource, "insert", async (next, data, options) => {
      const result = await next(data, options);
      await this._addToIndex(resourceName, result, config);
      return result;
    });
    this.addMiddleware(resource, "delete", async (next, id, options) => {
      const result = await next(id, options);
      await this._removeFromIndex(resourceName, id);
      return result;
    });
    if (this.verbose) {
      console.log(`[TTLPlugin] Setup hooks for resource "${resourceName}"`);
    }
  }
  /**
   * Add record to expiration index
   */
  async _addToIndex(resourceName, record, config) {
    try {
      let baseTime = record[config.field];
      if (!baseTime && config.field === "_createdAt") {
        baseTime = Date.now();
      }
      if (!baseTime) {
        if (this.verbose) {
          console.warn(
            `[TTLPlugin] Record ${record.id} in ${resourceName} missing field "${config.field}", skipping index`
          );
        }
        return;
      }
      const baseTimestamp = typeof baseTime === "number" ? baseTime : new Date(baseTime).getTime();
      const expiresAt = config.ttl ? new Date(baseTimestamp + config.ttl * SECONDS_TO_MS) : new Date(baseTimestamp);
      const cohortConfig = GRANULARITIES[config.granularity];
      const cohort = cohortConfig.cohortFormat(expiresAt);
      const indexId = `${resourceName}:${record.id}`;
      await this.expirationIndex.insert({
        id: indexId,
        resourceName,
        recordId: record.id,
        expiresAtCohort: cohort,
        expiresAtTimestamp: expiresAt.getTime(),
        // Store exact timestamp for precise checking
        granularity: config.granularity,
        createdAt: Date.now()
      });
      if (this.verbose) {
        console.log(
          `[TTLPlugin] Added ${resourceName}:${record.id} to index (cohort: ${cohort}, granularity: ${config.granularity})`
        );
      }
    } catch (error) {
      console.error(`[TTLPlugin] Error adding to index:`, error);
      this.stats.totalErrors++;
    }
  }
  /**
   * Remove record from expiration index (O(1) using deterministic ID)
   */
  async _removeFromIndex(resourceName, recordId) {
    try {
      const indexId = `${resourceName}:${recordId}`;
      const [ok, err] = await tryFn(() => this.expirationIndex.delete(indexId));
      if (this.verbose && ok) {
        console.log(`[TTLPlugin] Removed index entry for ${resourceName}:${recordId}`);
      }
      if (!ok && err?.code !== "NoSuchKey") {
        throw err;
      }
    } catch (error) {
      console.error(`[TTLPlugin] Error removing from index:`, error);
    }
  }
  /**
   * Start interval-based cleanup for each granularity
   */
  _startIntervals() {
    const byGranularity = {
      minute: [],
      hour: [],
      day: [],
      week: []
    };
    for (const [name, config] of Object.entries(this.resources)) {
      byGranularity[config.granularity].push({ name, config });
    }
    for (const [granularity, resources] of Object.entries(byGranularity)) {
      if (resources.length === 0) continue;
      const granularityConfig = GRANULARITIES[granularity];
      const handle = setInterval(
        () => this._cleanupGranularity(granularity, resources),
        granularityConfig.interval
      );
      this.intervals.push(handle);
      if (this.verbose) {
        console.log(
          `[TTLPlugin] Started ${granularity} interval (${granularityConfig.interval}ms) for ${resources.length} resources`
        );
      }
    }
    this.isRunning = true;
  }
  /**
   * Stop all intervals
   */
  _stopIntervals() {
    for (const handle of this.intervals) {
      clearInterval(handle);
    }
    this.intervals = [];
    this.isRunning = false;
    if (this.verbose) {
      console.log("[TTLPlugin] Stopped all intervals");
    }
  }
  /**
   * Cleanup expired records for a specific granularity
   */
  async _cleanupGranularity(granularity, resources) {
    const startTime = Date.now();
    this.stats.totalScans++;
    try {
      const granularityConfig = GRANULARITIES[granularity];
      const cohorts = getExpiredCohorts(granularity, granularityConfig.cohortsToCheck);
      if (this.verbose) {
        console.log(`[TTLPlugin] Cleaning ${granularity} granularity, checking cohorts:`, cohorts);
      }
      for (const cohort of cohorts) {
        const expired = await this.expirationIndex.listPartition({
          partition: "byExpiresAtCohort",
          partitionValues: { expiresAtCohort: cohort }
        });
        const resourceNames = new Set(resources.map((r) => r.name));
        const filtered = expired.filter((e) => resourceNames.has(e.resourceName));
        if (this.verbose && filtered.length > 0) {
          console.log(`[TTLPlugin] Found ${filtered.length} expired records in cohort ${cohort}`);
        }
        for (let i = 0; i < filtered.length; i += this.batchSize) {
          const batch = filtered.slice(i, i + this.batchSize);
          for (const entry of batch) {
            const config = this.resources[entry.resourceName];
            await this._processExpiredEntry(entry, config);
          }
        }
      }
      this.stats.lastScanAt = (/* @__PURE__ */ new Date()).toISOString();
      this.stats.lastScanDuration = Date.now() - startTime;
      this.emit("plg:ttl:scan-completed", {
        granularity,
        duration: this.stats.lastScanDuration,
        cohorts
      });
    } catch (error) {
      console.error(`[TTLPlugin] Error in ${granularity} cleanup:`, error);
      this.stats.totalErrors++;
      this.emit("plg:ttl:cleanup-error", { granularity, error });
    }
  }
  /**
   * Process a single expired index entry
   */
  async _processExpiredEntry(entry, config) {
    try {
      if (!this.database.resources[entry.resourceName]) {
        if (this.verbose) {
          console.warn(`[TTLPlugin] Resource "${entry.resourceName}" not found during cleanup, skipping`);
        }
        return;
      }
      const resource = this.database.resources[entry.resourceName];
      const [ok, err, record] = await tryFn(() => resource.get(entry.recordId));
      if (!ok || !record) {
        await this.expirationIndex.delete(entry.id);
        return;
      }
      if (entry.expiresAtTimestamp && Date.now() < entry.expiresAtTimestamp) {
        return;
      }
      switch (config.onExpire) {
        case "soft-delete":
          await this._softDelete(resource, record, config);
          this.stats.totalSoftDeleted++;
          break;
        case "hard-delete":
          await this._hardDelete(resource, record);
          this.stats.totalDeleted++;
          break;
        case "archive":
          await this._archive(resource, record, config);
          this.stats.totalArchived++;
          this.stats.totalDeleted++;
          break;
        case "callback":
          const shouldDelete = await config.callback(record, resource);
          this.stats.totalCallbacks++;
          if (shouldDelete) {
            await this._hardDelete(resource, record);
            this.stats.totalDeleted++;
          }
          break;
      }
      await this.expirationIndex.delete(entry.id);
      this.stats.totalExpired++;
      this.emit("plg:ttl:record-expired", { resource: entry.resourceName, record });
    } catch (error) {
      console.error(`[TTLPlugin] Error processing expired entry:`, error);
      this.stats.totalErrors++;
    }
  }
  /**
   * Soft delete: Mark record as deleted
   */
  async _softDelete(resource, record, config) {
    const deleteField = config.deleteField || "deletedat";
    const updates = {
      [deleteField]: (/* @__PURE__ */ new Date()).toISOString(),
      isdeleted: "true"
      // Add isdeleted field for partition compatibility
    };
    await resource.update(record.id, updates);
    if (this.verbose) {
      console.log(`[TTLPlugin] Soft-deleted record ${record.id} in ${resource.name}`);
    }
  }
  /**
   * Hard delete: Remove record from S3
   */
  async _hardDelete(resource, record) {
    await resource.delete(record.id);
    if (this.verbose) {
      console.log(`[TTLPlugin] Hard-deleted record ${record.id} in ${resource.name}`);
    }
  }
  /**
   * Archive: Copy to another resource then delete
   */
  async _archive(resource, record, config) {
    if (!this.database.resources[config.archiveResource]) {
      throw new PluginError(`Archive resource "${config.archiveResource}" not found`, {
        pluginName: "TTLPlugin",
        operation: "_archive",
        resourceName: config.archiveResource,
        statusCode: 404,
        retriable: false,
        suggestion: 'Create the archive resource before using onExpire: "archive" or update archiveResource config.'
      });
    }
    const archiveResource = this.database.resources[config.archiveResource];
    const archiveData = {};
    for (const [key, value] of Object.entries(record)) {
      if (!key.startsWith("_")) {
        archiveData[key] = value;
      }
    }
    archiveData.archivedAt = (/* @__PURE__ */ new Date()).toISOString();
    archiveData.archivedFrom = resource.name;
    archiveData.originalId = record.id;
    if (!config.keepOriginalId) {
      delete archiveData.id;
    }
    await archiveResource.insert(archiveData);
    await resource.delete(record.id);
    if (this.verbose) {
      console.log(`[TTLPlugin] Archived record ${record.id} from ${resource.name} to ${config.archiveResource}`);
    }
  }
  /**
   * Manual cleanup of a specific resource
   */
  async cleanupResource(resourceName) {
    const config = this.resources[resourceName];
    if (!config) {
      throw new PluginError(`Resource "${resourceName}" not configured in TTLPlugin`, {
        pluginName: "TTLPlugin",
        operation: "cleanupResource",
        resourceName,
        statusCode: 404,
        retriable: false,
        suggestion: "Add the resource under TTLPlugin configuration before invoking cleanupResource."
      });
    }
    const granularity = config.granularity;
    await this._cleanupGranularity(granularity, [{ name: resourceName, config }]);
    return {
      resource: resourceName,
      granularity
    };
  }
  /**
   * Manual cleanup of all resources
   */
  async runCleanup() {
    const byGranularity = {
      minute: [],
      hour: [],
      day: [],
      week: []
    };
    for (const [name, config] of Object.entries(this.resources)) {
      byGranularity[config.granularity].push({ name, config });
    }
    for (const [granularity, resources] of Object.entries(byGranularity)) {
      if (resources.length > 0) {
        await this._cleanupGranularity(granularity, resources);
      }
    }
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      ...this.stats,
      resources: Object.keys(this.resources).length,
      isRunning: this.isRunning,
      intervals: this.intervals.length
    };
  }
  /**
   * Uninstall the plugin
   */
  async uninstall() {
    this._stopIntervals();
    await super.uninstall();
    if (this.verbose) {
      console.log("[TTLPlugin] Uninstalled");
    }
  }
}

function sanitizeNamespace$1(value) {
  return (value || "persona").toString().trim().toLowerCase().replace(/[^a-z0-9]+/g, "-");
}
function defaultJobsResource(namespace) {
  return `${namespace.replace(/[^a-z0-9]+/g, "_")}_persona_jobs`;
}
class CookieFarmSuitePlugin extends Plugin {
  constructor(options = {}) {
    const namespace = options.namespace || "persona";
    super({ ...options, namespace });
    this.namespace = this.namespace || sanitizeNamespace$1(namespace);
    const jobsResource = options.jobsResource || options.resources && options.resources.jobs || defaultJobsResource(this.namespace);
    this.config = {
      namespace: this.namespace,
      jobsResource,
      queue: {
        resource: jobsResource,
        deadLetterResource: options.queue?.deadLetterResource || null,
        visibilityTimeout: options.queue?.visibilityTimeout || 3e4,
        pollInterval: options.queue?.pollInterval || 1e3,
        maxAttempts: options.queue?.maxAttempts || 3,
        concurrency: options.queue?.concurrency || 1,
        autoStart: options.queue?.autoStart === true,
        ...options.queue
      },
      puppeteer: {
        pool: { enabled: false },
        ...options.puppeteer
      },
      cookieFarm: {
        ...options.cookieFarm
      },
      ttl: options.ttl || null,
      processor: typeof options.processor === "function" ? options.processor : null
    };
    this.pluginFactories = {
      puppeteer: options.pluginFactories?.puppeteer || ((pluginOptions) => new PuppeteerPlugin(pluginOptions)),
      cookieFarm: options.pluginFactories?.cookieFarm || ((pluginOptions) => new CookieFarmPlugin(pluginOptions)),
      queue: options.pluginFactories?.queue || ((queueOptions) => new S3QueuePlugin(queueOptions)),
      ttl: options.pluginFactories?.ttl || ((ttlOptions) => new TTLPlugin(ttlOptions))
    };
    this.dependencies = [];
    this.jobsResource = null;
    this.puppeteerPlugin = null;
    this.cookieFarmPlugin = null;
    this.queuePlugin = null;
    this.ttlPlugin = null;
    this.processor = this.config.processor;
    this.queueHandler = this.queueHandler.bind(this);
  }
  _dependencyName(alias) {
    return `${this.namespace}-${alias}`.toLowerCase();
  }
  async _installDependency(alias, plugin) {
    const name = this._dependencyName(alias);
    const instance = await this.database.usePlugin(plugin, name);
    this.dependencies.push({ name, instance });
    return instance;
  }
  async _ensureJobsResource() {
    if (this.database.resources?.[this.config.jobsResource]) {
      this.jobsResource = this.database.resources[this.config.jobsResource];
      return;
    }
    const [created, err, resource] = await tryFn(() => this.database.createResource({
      name: this.config.jobsResource,
      attributes: {
        id: "string|required",
        jobType: "string|required",
        payload: "json|optional",
        priority: "number|default:0",
        requestedBy: "string|optional",
        metadata: "json|optional",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: true,
      asyncPartitions: true,
      partitions: {
        byJobType: { fields: { jobType: "string" } },
        byPriority: { fields: { priority: "number" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
    if (!created) {
      if (resource) {
        this.jobsResource = resource;
        return;
      }
      throw err;
    }
    this.jobsResource = this.database.resources[this.config.jobsResource];
  }
  async onInstall() {
    await this._ensureJobsResource();
    this.puppeteerPlugin = await this._installDependency(
      "puppeteer",
      this.pluginFactories.puppeteer({
        namespace: this.namespace,
        ...this.config.puppeteer
      })
    );
    this.cookieFarmPlugin = await this._installDependency(
      "cookie-farm",
      this.pluginFactories.cookieFarm({
        namespace: this.namespace,
        ...this.config.cookieFarm
      })
    );
    const queueOptions = {
      namespace: this.namespace,
      resource: this.config.queue.resource,
      deadLetterResource: this.config.queue.deadLetterResource,
      visibilityTimeout: this.config.queue.visibilityTimeout,
      pollInterval: this.config.queue.pollInterval,
      maxAttempts: this.config.queue.maxAttempts,
      concurrency: this.config.queue.concurrency,
      autoStart: this.config.queue.autoStart && typeof this.processor === "function",
      onMessage: this.queueHandler,
      verbose: this.config.queue.verbose
    };
    this.queuePlugin = await this._installDependency("queue", this.pluginFactories.queue(queueOptions));
    if (this.config.ttl) {
      const ttlConfig = {
        namespace: this.namespace,
        ...this.config.ttl
      };
      ttlConfig.resources = ttlConfig.resources || {};
      if (!ttlConfig.resources[this.queuePlugin.queueResourceName]) {
        ttlConfig.resources[this.queuePlugin.queueResourceName] = {
          ttl: ttlConfig.queue?.ttl || 7200,
          onExpire: ttlConfig.queue?.onExpire || "hard-delete",
          field: ttlConfig.queue?.field || null
        };
      }
      delete ttlConfig.queue;
      this.ttlPlugin = await this._installDependency("ttl", this.pluginFactories.ttl(ttlConfig));
    }
    this.emit("cookieFarmSuite.installed", {
      namespace: this.namespace,
      jobsResource: this.config.jobsResource
    });
  }
  async onStart() {
    if (this.config.queue.autoStart && typeof this.processor === "function") {
      await this.startProcessing();
    }
  }
  async onStop() {
    await this.stopProcessing();
  }
  async onUninstall(options = {}) {
    await this.onStop();
    for (const dep of [...this.dependencies].reverse()) {
      await this.database.uninstallPlugin(dep.name, { purgeData: options.purgeData === true });
    }
    this.dependencies = [];
  }
  /**
   * Register a job processor.
   */
  async setProcessor(handler, { autoStart = true, concurrency } = {}) {
    this.processor = handler;
    if (autoStart && typeof handler === "function") {
      await this.startProcessing({ concurrency });
    }
  }
  /**
   * Enqueue a persona job.
   */
  async enqueueJob(data, options = {}) {
    if (!this.jobsResource?.enqueue) {
      throw new Error("[CookieFarmSuitePlugin] Queue helpers not initialized yet");
    }
    return await this.jobsResource.enqueue({
      createdAt: (/* @__PURE__ */ new Date()).toISOString().slice(0, 10),
      ...data
    }, options);
  }
  async startProcessing(options = {}) {
    if (!this.jobsResource?.startProcessing) return;
    const concurrency = options.concurrency || this.config.queue.concurrency;
    await this.jobsResource.startProcessing(this.queueHandler, { concurrency });
  }
  async stopProcessing() {
    if (this.jobsResource?.stopProcessing) {
      await this.jobsResource.stopProcessing();
    }
  }
  async queueHandler(record, context) {
    if (typeof this.processor !== "function") {
      throw new Error("[CookieFarmSuitePlugin] No processor registered. Call setProcessor(fn) first.");
    }
    const helpers = {
      puppeteer: this.puppeteerPlugin,
      cookieFarm: this.cookieFarmPlugin,
      queue: this.queuePlugin,
      enqueue: this.enqueueJob.bind(this),
      resource: this.jobsResource,
      plugin: this
    };
    return await this.processor(record, context, helpers);
  }
}

class CostsPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.config = {
      considerFreeTier: config.considerFreeTier !== void 0 ? config.considerFreeTier : false,
      region: config.region || "us-east-1",
      ...config
    };
    this.map = {
      PutObjectCommand: "put",
      GetObjectCommand: "get",
      CopyObjectCommand: "copy",
      HeadObjectCommand: "head",
      DeleteObjectCommand: "delete",
      DeleteObjectsCommand: "delete",
      ListObjectsV2Command: "list"
    };
    this.costs = {
      total: 0,
      // === REQUESTS PRICING ===
      requests: {
        prices: {
          put: 5e-3 / 1e3,
          copy: 5e-3 / 1e3,
          list: 5e-3 / 1e3,
          post: 5e-3 / 1e3,
          get: 4e-4 / 1e3,
          select: 4e-4 / 1e3,
          delete: 4e-4 / 1e3,
          head: 4e-4 / 1e3
        },
        total: 0,
        counts: {
          put: 0,
          post: 0,
          copy: 0,
          list: 0,
          get: 0,
          select: 0,
          delete: 0,
          head: 0
        },
        totalEvents: 0,
        events: {
          PutObjectCommand: 0,
          GetObjectCommand: 0,
          CopyObjectCommand: 0,
          HeadObjectCommand: 0,
          DeleteObjectCommand: 0,
          DeleteObjectsCommand: 0,
          ListObjectsV2Command: 0
        },
        subtotal: 0
      },
      // === STORAGE PRICING ===
      storage: {
        totalBytes: 0,
        totalGB: 0,
        // Tiered pricing (S3 Standard - us-east-1)
        tiers: [
          { limit: 50 * 1024, pricePerGB: 0.023 },
          // First 50 TB
          { limit: 500 * 1024, pricePerGB: 0.022 },
          // Next 450 TB
          { limit: 999999999, pricePerGB: 0.021 }
          // Over 500 TB (effectively unlimited)
        ],
        currentTier: 0,
        subtotal: 0
        // Monthly storage cost estimate
      },
      // === DATA TRANSFER PRICING ===
      dataTransfer: {
        // Upload (always free)
        inBytes: 0,
        inGB: 0,
        inCost: 0,
        // Always $0
        // Download (charged with tiers)
        outBytes: 0,
        outGB: 0,
        // Tiered pricing (out to internet)
        tiers: [
          { limit: 10 * 1024, pricePerGB: 0.09 },
          // First 10 TB
          { limit: 50 * 1024, pricePerGB: 0.085 },
          // Next 40 TB
          { limit: 150 * 1024, pricePerGB: 0.07 },
          // Next 100 TB
          { limit: 999999999, pricePerGB: 0.05 }
          // Over 150 TB (effectively unlimited)
        ],
        // Free tier (100GB/month aggregated across AWS)
        freeTierGB: 100,
        freeTierUsed: 0,
        currentTier: 0,
        subtotal: 0
        // Data transfer out cost
      }
    };
  }
  async onInstall() {
    if (!this.database || !this.database.client) {
      return;
    }
    this.client = this.database.client;
    this.client.costs = JSON.parse(JSON.stringify(this.costs));
  }
  async onStart() {
    if (this.client) {
      this.client.on("cl:response", (name, response, input) => this.addRequest(name, this.map[name], response, input));
    }
  }
  addRequest(name, method, response = {}, input = {}) {
    if (!method) return;
    this.costs.requests.totalEvents++;
    this.costs.requests.total++;
    this.costs.requests.events[name]++;
    this.costs.requests.counts[method]++;
    const requestCost = this.costs.requests.prices[method];
    this.costs.requests.subtotal += requestCost;
    let contentLength = 0;
    if (["put", "post", "copy"].includes(method)) {
      const body = input.Body || input.body;
      if (body) {
        if (typeof body === "string") {
          contentLength = Buffer.byteLength(body, "utf8");
        } else if (Buffer.isBuffer(body)) {
          contentLength = body.length;
        } else if (body.length !== void 0) {
          contentLength = body.length;
        }
      }
      if (contentLength > 0) {
        this.trackStorage(contentLength);
        this.trackDataTransferIn(contentLength);
      }
    }
    if (method === "get") {
      contentLength = response?.httpResponse?.headers?.["content-length"] || response?.ContentLength || 0;
      if (contentLength > 0) {
        this.trackDataTransferOut(contentLength);
      }
    }
    if (this.client && this.client.costs) {
      this.client.costs.requests.totalEvents++;
      this.client.costs.requests.total++;
      this.client.costs.requests.events[name]++;
      this.client.costs.requests.counts[method]++;
      this.client.costs.requests.subtotal += requestCost;
    }
    this.updateTotal();
  }
  trackStorage(bytes) {
    this.costs.storage.totalBytes += bytes;
    this.costs.storage.totalGB = this.costs.storage.totalBytes / (1024 * 1024 * 1024);
    this.costs.storage.subtotal = this.calculateStorageCost(this.costs.storage);
    if (this.client && this.client.costs) {
      this.client.costs.storage.totalBytes += bytes;
      this.client.costs.storage.totalGB = this.client.costs.storage.totalBytes / (1024 * 1024 * 1024);
      this.client.costs.storage.subtotal = this.calculateStorageCost(this.client.costs.storage);
    }
    this.updateTotal();
  }
  trackDataTransferIn(bytes) {
    this.costs.dataTransfer.inBytes += bytes;
    this.costs.dataTransfer.inGB = this.costs.dataTransfer.inBytes / (1024 * 1024 * 1024);
    if (this.client && this.client.costs) {
      this.client.costs.dataTransfer.inBytes += bytes;
      this.client.costs.dataTransfer.inGB = this.client.costs.dataTransfer.inBytes / (1024 * 1024 * 1024);
    }
    this.updateTotal();
  }
  trackDataTransferOut(bytes) {
    this.costs.dataTransfer.outBytes += bytes;
    this.costs.dataTransfer.outGB = this.costs.dataTransfer.outBytes / (1024 * 1024 * 1024);
    this.costs.dataTransfer.subtotal = this.calculateDataTransferCost(this.costs.dataTransfer);
    if (this.client && this.client.costs) {
      this.client.costs.dataTransfer.outBytes += bytes;
      this.client.costs.dataTransfer.outGB = this.client.costs.dataTransfer.outBytes / (1024 * 1024 * 1024);
      this.client.costs.dataTransfer.subtotal = this.calculateDataTransferCost(this.client.costs.dataTransfer);
    }
    this.updateTotal();
  }
  calculateStorageCost(storage) {
    const totalGB = storage.totalGB;
    let cost = 0;
    let remaining = totalGB;
    for (let i = 0; i < storage.tiers.length; i++) {
      const tier = storage.tiers[i];
      const prevLimit = i > 0 ? storage.tiers[i - 1].limit : 0;
      const tierCapacity = tier.limit - prevLimit;
      if (remaining <= 0) break;
      const gbInTier = Math.min(remaining, tierCapacity);
      cost += gbInTier * tier.pricePerGB;
      remaining -= gbInTier;
      if (remaining <= 0) {
        storage.currentTier = i;
        break;
      }
    }
    return cost;
  }
  calculateDataTransferCost(dataTransfer) {
    let totalGB = dataTransfer.outGB;
    let cost = 0;
    if (this.config && this.config.considerFreeTier) {
      const freeTierRemaining = dataTransfer.freeTierGB - dataTransfer.freeTierUsed;
      if (freeTierRemaining > 0 && totalGB > 0) {
        const gbToDeduct = Math.min(totalGB, freeTierRemaining);
        totalGB -= gbToDeduct;
        dataTransfer.freeTierUsed += gbToDeduct;
      }
    }
    let remaining = totalGB;
    for (let i = 0; i < dataTransfer.tiers.length; i++) {
      const tier = dataTransfer.tiers[i];
      const prevLimit = i > 0 ? dataTransfer.tiers[i - 1].limit : 0;
      const tierCapacity = tier.limit - prevLimit;
      if (remaining <= 0) break;
      const gbInTier = Math.min(remaining, tierCapacity);
      cost += gbInTier * tier.pricePerGB;
      remaining -= gbInTier;
      if (remaining <= 0) {
        dataTransfer.currentTier = i;
        break;
      }
    }
    return cost;
  }
  updateTotal() {
    this.costs.total = this.costs.requests.subtotal + this.costs.storage.subtotal + this.costs.dataTransfer.subtotal;
    if (this.client && this.client.costs) {
      this.client.costs.total = this.client.costs.requests.subtotal + this.client.costs.storage.subtotal + this.client.costs.dataTransfer.subtotal;
    }
  }
}

function createConfig(options, detectedTimezone) {
  const consolidation = options.consolidation || {};
  const locks = options.locks || {};
  const gc = options.garbageCollection || {};
  const analytics = options.analytics || {};
  const batch = options.batch || {};
  const lateArrivals = options.lateArrivals || {};
  const checkpoints = options.checkpoints || {};
  return {
    // Cohort (timezone)
    cohort: {
      timezone: options.cohort?.timezone || detectedTimezone
    },
    // Reducer function
    reducer: options.reducer || ((transactions) => {
      let baseValue = 0;
      for (const t of transactions) {
        if (t.operation === "set") {
          baseValue = t.value;
        } else if (t.operation === "add") {
          baseValue += t.value;
        } else if (t.operation === "sub") {
          baseValue -= t.value;
        }
      }
      return baseValue;
    }),
    // Consolidation settings
    consolidationInterval: consolidation.interval ?? 300,
    consolidationConcurrency: consolidation.concurrency ?? 5,
    consolidationWindow: consolidation.window ?? 24,
    autoConsolidate: consolidation.auto !== false,
    mode: consolidation.mode || "async",
    //  Performance tuning - Mark applied concurrency (default 50, up from 10)
    markAppliedConcurrency: consolidation.markAppliedConcurrency ?? 50,
    //  Performance tuning - Recalculate concurrency (default 50, up from 10)
    recalculateConcurrency: consolidation.recalculateConcurrency ?? 50,
    // Late arrivals
    lateArrivalStrategy: lateArrivals.strategy || "warn",
    // Batch transactions
    batchTransactions: batch.enabled || false,
    batchSize: batch.size || 100,
    // Locks
    lockTimeout: locks.timeout || 300,
    // Garbage collection
    transactionRetention: gc.retention ?? 30,
    gcInterval: gc.interval ?? 86400,
    // Analytics
    enableAnalytics: analytics.enabled || false,
    analyticsConfig: {
      periods: analytics.periods || ["hour", "day", "month"],
      metrics: analytics.metrics || ["count", "sum", "avg", "min", "max"],
      rollupStrategy: analytics.rollupStrategy || "incremental",
      retentionDays: analytics.retentionDays ?? 365
    },
    // Checkpoints
    enableCheckpoints: checkpoints.enabled !== false,
    checkpointStrategy: checkpoints.strategy || "hourly",
    checkpointRetention: checkpoints.retention ?? 90,
    checkpointThreshold: checkpoints.threshold ?? 1e3,
    deleteConsolidatedTransactions: checkpoints.deleteConsolidated !== false,
    autoCheckpoint: checkpoints.auto !== false,
    // Debug
    verbose: options.verbose || false
  };
}
function validateResourcesConfig(resources) {
  if (!resources || typeof resources !== "object") {
    throw new PluginError("EventualConsistencyPlugin requires a 'resources' option", {
      pluginName: "EventualConsistencyPlugin",
      operation: "validateResourcesConfig",
      statusCode: 400,
      retriable: false,
      suggestion: "Provide resources configuration, e.g., { resources: { urls: ['clicks', 'views'] } }"
    });
  }
  for (const [resourceName, fields] of Object.entries(resources)) {
    if (!Array.isArray(fields)) {
      throw new PluginError(`EventualConsistencyPlugin resources.${resourceName} must be an array of field names`, {
        pluginName: "EventualConsistencyPlugin",
        operation: "validateResourcesConfig",
        statusCode: 400,
        retriable: false,
        suggestion: 'Ensure each resource entry maps to an array of field names (e.g., resources.users = ["logins", "visits"]).'
      });
    }
  }
}
function logConfigWarnings(config) {
  if (config.batchTransactions && !config.verbose) {
    console.warn(
      `[EventualConsistency] WARNING: batch.enabled is true. This stores transactions in memory and will lose data if container crashes. Not recommended for distributed/production environments.`
    );
  }
  if (!config.enableCheckpoints && !config.verbose) {
    console.warn(
      `[EventualConsistency] INFO: checkpoints.enabled is false. Checkpoints improve performance in high-volume scenarios by creating snapshots. Consider enabling for production use.`
    );
  }
}
function logInitialization(config, fieldHandlers, timezoneAutoDetected) {
  if (!config.verbose) return;
  const totalFields = Array.from(fieldHandlers.values()).reduce((sum, handlers) => sum + handlers.size, 0);
  console.log(
    `[EventualConsistency] Initialized with ${fieldHandlers.size} resource(s), ${totalFields} field(s) total`
  );
  if (timezoneAutoDetected) {
    console.log(
      `[EventualConsistency] Using timezone: ${config.cohort.timezone} (${process.env.TZ ? "from TZ env var" : "default UTC"})`
    );
  }
}

function detectTimezone() {
  if (process.env.TZ) {
    return process.env.TZ;
  }
  return "UTC";
}
function getTimezoneOffset(timezone, verbose = false) {
  try {
    const now = /* @__PURE__ */ new Date();
    const utcDate = new Date(now.toLocaleString("en-US", { timeZone: "UTC" }));
    const tzDate = new Date(now.toLocaleString("en-US", { timeZone: timezone }));
    return tzDate.getTime() - utcDate.getTime();
  } catch (err) {
    const offsets = {
      "UTC": 0,
      "America/New_York": -5 * 36e5,
      "America/Chicago": -6 * 36e5,
      "America/Denver": -7 * 36e5,
      "America/Los_Angeles": -8 * 36e5,
      "America/Sao_Paulo": -3 * 36e5,
      "Europe/London": 0,
      "Europe/Paris": 1 * 36e5,
      "Europe/Berlin": 1 * 36e5,
      "Asia/Tokyo": 9 * 36e5,
      "Asia/Shanghai": 8 * 36e5,
      "Australia/Sydney": 10 * 36e5
    };
    if (verbose && !offsets[timezone]) {
      console.warn(
        `[EventualConsistency] Unknown timezone '${timezone}', using UTC. Consider using a valid IANA timezone (e.g., 'America/New_York')`
      );
    }
    return offsets[timezone] || 0;
  }
}
function getISOWeek(date) {
  const target = new Date(date.valueOf());
  const dayNr = (date.getUTCDay() + 6) % 7;
  target.setUTCDate(target.getUTCDate() - dayNr + 3);
  const yearStart = new Date(Date.UTC(target.getUTCFullYear(), 0, 1));
  const firstThursday = new Date(yearStart.valueOf());
  if (yearStart.getUTCDay() !== 4) {
    firstThursday.setUTCDate(yearStart.getUTCDate() + (4 - yearStart.getUTCDay() + 7) % 7);
  }
  const weekNumber = 1 + Math.round((target - firstThursday) / 6048e5);
  return {
    year: target.getUTCFullYear(),
    week: weekNumber
  };
}
function getCohortInfo(date, timezone, verbose = false) {
  const offset = getTimezoneOffset(timezone, verbose);
  const localDate = new Date(date.getTime() + offset);
  const year = localDate.getFullYear();
  const month = String(localDate.getMonth() + 1).padStart(2, "0");
  const day = String(localDate.getDate()).padStart(2, "0");
  const hour = String(localDate.getHours()).padStart(2, "0");
  const { year: weekYear, week: weekNumber } = getISOWeek(localDate);
  const week = `${weekYear}-W${String(weekNumber).padStart(2, "0")}`;
  return {
    date: `${year}-${month}-${day}`,
    hour: `${year}-${month}-${day}T${hour}`,
    // ISO-like format for hour partition
    week,
    // ISO 8601 week format (e.g., '2025-W42')
    month: `${year}-${month}`
  };
}
function createSyntheticSetTransaction(currentValue) {
  return {
    id: "__synthetic__",
    operation: "set",
    value: currentValue,
    timestamp: (/* @__PURE__ */ new Date(0)).toISOString(),
    synthetic: true
  };
}
function createFieldHandler(resourceName, fieldName) {
  return {
    resource: resourceName,
    field: fieldName,
    transactionResource: null,
    targetResource: null,
    analyticsResource: null,
    lockResource: null,
    checkpointResource: null,
    consolidationTimer: null,
    gcTimer: null,
    pendingTransactions: /* @__PURE__ */ new Map(),
    deferredSetup: false
  };
}
function validateNestedPath(resource, fieldPath) {
  const parts = fieldPath.split(".");
  const rootField = parts[0];
  if (!resource.attributes || !resource.attributes[rootField]) {
    return {
      valid: false,
      rootField,
      fullPath: fieldPath,
      error: `Root field "${rootField}" not found in resource attributes`
    };
  }
  if (parts.length === 1) {
    return { valid: true, rootField, fullPath: fieldPath };
  }
  let current = resource.attributes[rootField];
  let foundJson = false;
  let levelsAfterJson = 0;
  for (let i = 1; i < parts.length; i++) {
    const part = parts[i];
    if (foundJson) {
      levelsAfterJson++;
      if (levelsAfterJson > 1) {
        return {
          valid: false,
          rootField,
          fullPath: fieldPath,
          error: `Path "${fieldPath}" exceeds 1 level after 'json' field. Maximum nesting after 'json' is 1 level.`
        };
      }
      continue;
    }
    if (typeof current === "string") {
      if (current === "json" || current.startsWith("json|")) {
        foundJson = true;
        levelsAfterJson++;
        if (levelsAfterJson > 1) {
          return {
            valid: false,
            rootField,
            fullPath: fieldPath,
            error: `Path "${fieldPath}" exceeds 1 level after 'json' field`
          };
        }
        continue;
      }
      return {
        valid: false,
        rootField,
        fullPath: fieldPath,
        error: `Field "${parts.slice(0, i).join(".")}" is type "${current}" and cannot be nested`
      };
    }
    if (typeof current === "object") {
      if (current.$$type) {
        const type = current.$$type;
        if (type === "json" || type.includes("json")) {
          foundJson = true;
          levelsAfterJson++;
          continue;
        }
        if (type !== "object" && !type.includes("object")) {
          return {
            valid: false,
            rootField,
            fullPath: fieldPath,
            error: `Field "${parts.slice(0, i).join(".")}" is type "${type}" and cannot be nested`
          };
        }
      }
      if (!current[part]) {
        return {
          valid: false,
          rootField,
          fullPath: fieldPath,
          error: `Field "${part}" not found in "${parts.slice(0, i).join(".")}"`
        };
      }
      current = current[part];
    } else {
      return {
        valid: false,
        rootField,
        fullPath: fieldPath,
        error: `Invalid structure at "${parts.slice(0, i).join(".")}"`
      };
    }
  }
  return { valid: true, rootField, fullPath: fieldPath };
}
function resolveFieldAndPlugin(resource, field, value) {
  if (!resource._eventualConsistencyPlugins) {
    throw new PluginError("No eventual consistency plugins configured for this resource", {
      pluginName: "EventualConsistencyPlugin",
      operation: "resolveFieldAndPlugin",
      statusCode: 404,
      retriable: false,
      suggestion: "Configure EventualConsistencyPlugin resources before using helper methods."
    });
  }
  if (field.includes(".")) {
    const validation = validateNestedPath(resource, field);
    if (!validation.valid) {
      throw new PluginError(validation.error, {
        pluginName: "EventualConsistencyPlugin",
        operation: "resolveFieldAndPlugin",
        statusCode: 400,
        retriable: false,
        suggestion: "Ensure nested field paths exist on the resource before using dot notation."
      });
    }
    const rootField = validation.rootField;
    const fieldPlugin2 = resource._eventualConsistencyPlugins[rootField];
    if (!fieldPlugin2) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new PluginError(`No eventual consistency plugin found for root field "${rootField}"`, {
        pluginName: "EventualConsistencyPlugin",
        operation: "resolveFieldAndPlugin",
        statusCode: 404,
        retriable: false,
        suggestion: `Available fields: ${availableFields}`,
        field: rootField
      });
    }
    return {
      field: rootField,
      // Root field for plugin lookup
      fieldPath: field,
      // Full path for nested access
      value,
      plugin: fieldPlugin2
    };
  }
  const fieldPlugin = resource._eventualConsistencyPlugins[field];
  if (!fieldPlugin) {
    const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
    throw new PluginError(`No eventual consistency plugin found for field "${field}"`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "resolveFieldAndPlugin",
      statusCode: 404,
      retriable: false,
      suggestion: `Available fields: ${availableFields}`,
      field
    });
  }
  return { field, fieldPath: field, value, plugin: fieldPlugin };
}
function groupByCohort(transactions, cohortField) {
  const groups = {};
  for (const txn of transactions) {
    const cohort = txn[cohortField];
    if (!cohort) continue;
    if (!groups[cohort]) {
      groups[cohort] = [];
    }
    groups[cohort].push(txn);
  }
  return groups;
}
function ensureCohortHour(transaction, timezone = "UTC", verbose = false) {
  if (transaction.cohortHour) {
    return transaction;
  }
  if (transaction.timestamp) {
    const date = new Date(transaction.timestamp);
    const cohortInfo = getCohortInfo(date, timezone, verbose);
    if (verbose) {
      console.log(
        `[EventualConsistency] Transaction ${transaction.id} missing cohortHour, calculated from timestamp: ${cohortInfo.hour}`
      );
    }
    transaction.cohortHour = cohortInfo.hour;
    if (!transaction.cohortWeek) {
      transaction.cohortWeek = cohortInfo.week;
    }
    if (!transaction.cohortMonth) {
      transaction.cohortMonth = cohortInfo.month;
    }
  } else if (verbose) {
    console.warn(
      `[EventualConsistency] Transaction ${transaction.id} missing both cohortHour and timestamp, cannot calculate cohort`
    );
  }
  return transaction;
}
function ensureCohortHours(transactions, timezone = "UTC", verbose = false) {
  if (!transactions || !Array.isArray(transactions)) {
    return transactions;
  }
  return transactions.map((txn) => ensureCohortHour(txn, timezone, verbose));
}

function createPartitionConfig() {
  const partitions = {
    // Composite partition by originalId + applied status
    // This is THE MOST CRITICAL optimization for consolidation!
    // Why: Consolidation always queries { originalId, applied: false }
    // Without this: Reads ALL transactions (applied + pending) and filters manually
    // With this: Reads ONLY pending transactions - can be 1000x faster!
    byOriginalIdAndApplied: {
      fields: {
        originalId: "string",
        applied: "boolean"
      }
    },
    // Partition by time cohorts for batch consolidation across many records
    byHour: {
      fields: {
        cohortHour: "string"
      }
    },
    byDay: {
      fields: {
        cohortDate: "string"
      }
    },
    byWeek: {
      fields: {
        cohortWeek: "string"
      }
    },
    byMonth: {
      fields: {
        cohortMonth: "string"
      }
    }
  };
  return partitions;
}

async function createTransaction(handler, data, config) {
  const now = /* @__PURE__ */ new Date();
  const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
  const watermarkMs = config.consolidationWindow * 60 * 60 * 1e3;
  const watermarkTime = now.getTime() - watermarkMs;
  const cohortHourDate = /* @__PURE__ */ new Date(cohortInfo.hour + ":00:00Z");
  if (cohortHourDate.getTime() < watermarkTime) {
    const hoursLate = Math.floor((now.getTime() - cohortHourDate.getTime()) / (60 * 60 * 1e3));
    if (config.lateArrivalStrategy === "ignore") {
      if (config.verbose) {
        console.warn(
          `[EventualConsistency] Late arrival ignored: transaction for ${cohortInfo.hour} is ${hoursLate}h late (watermark: ${config.consolidationWindow}h)`
        );
      }
      return null;
    } else if (config.lateArrivalStrategy === "warn") {
      console.warn(
        `[EventualConsistency] Late arrival detected: transaction for ${cohortInfo.hour} is ${hoursLate}h late (watermark: ${config.consolidationWindow}h). Processing anyway, but consolidation may not pick it up.`
      );
    }
  }
  const transaction = {
    id: idGenerator(),
    originalId: data.originalId,
    field: handler.field,
    value: data.value || 0,
    operation: data.operation || "set",
    timestamp: now.toISOString(),
    cohortDate: cohortInfo.date,
    cohortHour: cohortInfo.hour,
    cohortWeek: cohortInfo.week,
    cohortMonth: cohortInfo.month,
    source: data.source || "unknown",
    applied: false
  };
  if (config.batchTransactions) {
    handler.pendingTransactions.set(transaction.id, transaction);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${handler.resource}.${handler.field} - Transaction batched: ${data.operation} ${data.value} for ${data.originalId} (batch: ${handler.pendingTransactions.size}/${config.batchSize})`
      );
    }
    if (handler.pendingTransactions.size >= config.batchSize) {
      await flushPendingTransactions(handler);
    }
  } else {
    await handler.transactionResource.insert(transaction);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${handler.resource}.${handler.field} - Transaction created: ${data.operation} ${data.value} for ${data.originalId} (cohort: ${cohortInfo.hour}, applied: false)`
      );
    }
  }
  return transaction;
}
async function flushPendingTransactions(handler) {
  if (handler.pendingTransactions.size === 0) return;
  const transactions = Array.from(handler.pendingTransactions.values());
  try {
    await Promise.all(
      transactions.map(
        (transaction) => handler.transactionResource.insert(transaction)
      )
    );
    handler.pendingTransactions.clear();
  } catch (error) {
    console.error("Failed to flush pending transactions:", error);
    throw error;
  }
}

function startConsolidationTimer(handler, resourceName, fieldName, runConsolidationCallback, config) {
  const intervalMs = config.consolidationInterval * 1e3;
  if (config.verbose) {
    const nextRun = new Date(Date.now() + intervalMs);
    console.log(
      `[EventualConsistency] ${resourceName}.${fieldName} - Consolidation timer started. Next run at ${nextRun.toISOString()} (every ${config.consolidationInterval}s)`
    );
  }
  handler.consolidationTimer = setInterval(async () => {
    await runConsolidationCallback(handler, resourceName, fieldName);
  }, intervalMs);
  return handler.consolidationTimer;
}
async function runConsolidation(transactionResource, consolidateRecordFn, emitFn, config) {
  const startTime = Date.now();
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${config.resource}.${config.field} - Starting consolidation run at ${(/* @__PURE__ */ new Date()).toISOString()}`
    );
  }
  try {
    const now = /* @__PURE__ */ new Date();
    const hoursToCheck = config.consolidationWindow || 24;
    const cohortHours = [];
    for (let i = 0; i < hoursToCheck; i++) {
      const date = new Date(now.getTime() - i * 60 * 60 * 1e3);
      const cohortInfo = getCohortInfo(date, config.cohort.timezone, config.verbose);
      cohortHours.push(cohortInfo.hour);
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Querying ${hoursToCheck} hour partitions for pending transactions...`
      );
    }
    const transactionsByHour = await Promise.all(
      cohortHours.map(async (cohortHour) => {
        const [ok, err, txns] = await tryFn(
          () => transactionResource.query({
            cohortHour,
            applied: false
          })
        );
        return ok ? txns : [];
      })
    );
    const transactions = transactionsByHour.flat();
    if (transactions.length === 0) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No pending transactions found. Next run in ${config.consolidationInterval}s`
        );
      }
      return;
    }
    const uniqueIds = [...new Set(transactions.map((t) => t.originalId))];
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Found ${transactions.length} pending transactions for ${uniqueIds.length} records. Consolidating with concurrency=${config.consolidationConcurrency}...`
      );
    }
    const { results, errors } = await PromisePool.for(uniqueIds).withConcurrency(config.consolidationConcurrency).process(async (id) => {
      return await consolidateRecordFn(id);
    });
    const duration = Date.now() - startTime;
    if (errors && errors.length > 0) {
      console.error(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidation completed with ${errors.length} errors in ${duration}ms:`,
        errors
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidation complete: ${results.length} records consolidated in ${duration}ms (${errors.length} errors). Next run in ${config.consolidationInterval}s`
      );
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:consolidated", {
        resource: config.resource,
        field: config.field,
        recordCount: uniqueIds.length,
        successCount: results.length,
        errorCount: errors.length,
        duration
      });
    }
  } catch (error) {
    const duration = Date.now() - startTime;
    console.error(
      `[EventualConsistency] ${config.resource}.${config.field} - Consolidation error after ${duration}ms:`,
      error
    );
    if (emitFn) {
      emitFn("plg:eventual-consistency:consolidation-error", error);
    }
  }
}
async function consolidateRecord(originalId, transactionResource, targetResource, storage, analyticsResource, updateAnalyticsFn, config) {
  const lockKey = `consolidation-${config.resource}-${config.field}-${originalId}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: config.lockTimeout || 30,
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] Lock for ${originalId} already held, skipping`);
    }
    const [recordOk, recordErr, record] = await tryFn(
      () => targetResource.get(originalId)
    );
    return recordOk && record ? record[config.field] || 0 : 0;
  }
  try {
    const [ok, err, transactions] = await tryFn(
      () => transactionResource.query({
        originalId,
        applied: false
      })
    );
    if (!ok || !transactions || transactions.length === 0) {
      const [recordOk2, recordErr2, record2] = await tryFn(
        () => targetResource.get(originalId)
      );
      const currentValue2 = recordOk2 && record2 ? record2[config.field] || 0 : 0;
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No pending transactions for ${originalId}, skipping`
        );
      }
      return currentValue2;
    }
    const [appliedOk, appliedErr, appliedTransactions] = await tryFn(
      () => transactionResource.query({
        originalId,
        applied: true
      })
    );
    let currentValue = 0;
    if (appliedOk && appliedTransactions && appliedTransactions.length > 0) {
      const [recordExistsOk, recordExistsErr, recordExists] = await tryFn(
        () => targetResource.get(originalId)
      );
      if (!recordExistsOk || !recordExists) {
        if (config.verbose) {
          console.log(
            `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist, deleting ${appliedTransactions.length} old applied transactions`
          );
        }
        const { results, errors } = await PromisePool.for(appliedTransactions).withConcurrency(10).process(async (txn) => {
          const [deleted] = await tryFn(() => transactionResource.delete(txn.id));
          return deleted;
        });
        if (config.verbose && errors && errors.length > 0) {
          console.warn(
            `[EventualConsistency] ${config.resource}.${config.field} - Failed to delete ${errors.length} old applied transactions`
          );
        }
        currentValue = 0;
        appliedTransactions.length = 0;
      } else {
        appliedTransactions.sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        const hasSetInApplied = appliedTransactions.some((t) => t.operation === "set");
        if (!hasSetInApplied) {
          const recordValue = recordExists[config.field] || 0;
          if (typeof recordValue === "number") {
            let appliedDelta = 0;
            for (const t of appliedTransactions) {
              if (t.operation === "add") appliedDelta += t.value;
              else if (t.operation === "sub") appliedDelta -= t.value;
            }
            const baseValue = recordValue - appliedDelta;
            const hasExistingAnchor = appliedTransactions.some((t) => t.source === "anchor");
            if (baseValue !== 0 && typeof baseValue === "number" && !hasExistingAnchor) {
              const firstTransactionDate = new Date(appliedTransactions[0].timestamp);
              const cohortInfo = getCohortInfo(firstTransactionDate, config.cohort.timezone, config.verbose);
              const anchorTransaction = {
                id: idGenerator(),
                originalId,
                field: config.field,
                fieldPath: config.field,
                // Add fieldPath for consistency
                value: baseValue,
                operation: "set",
                timestamp: new Date(firstTransactionDate.getTime() - 1).toISOString(),
                // 1ms before first txn to ensure it's first
                cohortDate: cohortInfo.date,
                cohortHour: cohortInfo.hour,
                cohortMonth: cohortInfo.month,
                source: "anchor",
                applied: true
              };
              await transactionResource.insert(anchorTransaction);
              appliedTransactions.unshift(anchorTransaction);
            }
          }
        }
        currentValue = config.reducer(appliedTransactions);
      }
    } else {
      const [recordOk2, recordErr2, record2] = await tryFn(
        () => targetResource.get(originalId)
      );
      currentValue = recordOk2 && record2 ? record2[config.field] || 0 : 0;
      if (currentValue !== 0 && typeof currentValue === "number") {
        let anchorTimestamp;
        if (transactions && transactions.length > 0) {
          const firstPendingDate = new Date(transactions[0].timestamp);
          anchorTimestamp = new Date(firstPendingDate.getTime() - 1).toISOString();
        } else {
          anchorTimestamp = (/* @__PURE__ */ new Date()).toISOString();
        }
        const cohortInfo = getCohortInfo(new Date(anchorTimestamp), config.cohort.timezone, config.verbose);
        const anchorTransaction = {
          id: idGenerator(),
          originalId,
          field: config.field,
          fieldPath: config.field,
          // Add fieldPath for consistency
          value: currentValue,
          operation: "set",
          timestamp: anchorTimestamp,
          cohortDate: cohortInfo.date,
          cohortHour: cohortInfo.hour,
          cohortMonth: cohortInfo.month,
          source: "anchor",
          applied: true
        };
        await transactionResource.insert(anchorTransaction);
        if (config.verbose) {
          console.log(
            `[EventualConsistency] ${config.resource}.${config.field} - Created anchor transaction for ${originalId} with base value ${currentValue}`
          );
        }
      }
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidating ${originalId}: ${transactions.length} pending transactions (current: ${currentValue} from ${appliedOk && appliedTransactions?.length > 0 ? "applied transactions" : "record"})`
      );
    }
    transactions.sort(
      (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
    );
    const transactionsByPath = {};
    for (const txn of transactions) {
      const path = txn.fieldPath || txn.field || config.field;
      if (!transactionsByPath[path]) {
        transactionsByPath[path] = [];
      }
      transactionsByPath[path].push(txn);
    }
    const appliedByPath = {};
    if (appliedOk && appliedTransactions && appliedTransactions.length > 0) {
      for (const txn of appliedTransactions) {
        const path = txn.fieldPath || txn.field || config.field;
        if (!appliedByPath[path]) {
          appliedByPath[path] = [];
        }
        appliedByPath[path].push(txn);
      }
    }
    const consolidatedValues = {};
    const lodash = await import('lodash-es');
    const [currentRecordOk, currentRecordErr, currentRecord] = await tryFn(
      () => targetResource.get(originalId)
    );
    for (const [fieldPath, pathTransactions] of Object.entries(transactionsByPath)) {
      let pathCurrentValue = 0;
      if (appliedByPath[fieldPath] && appliedByPath[fieldPath].length > 0) {
        appliedByPath[fieldPath].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        pathCurrentValue = config.reducer(appliedByPath[fieldPath]);
      } else {
        if (currentRecordOk && currentRecord) {
          const recordValue = lodash.get(currentRecord, fieldPath, 0);
          if (typeof recordValue === "number") {
            pathCurrentValue = recordValue;
          }
        }
      }
      if (pathCurrentValue !== 0) {
        pathTransactions.unshift(createSyntheticSetTransaction(pathCurrentValue));
      }
      const pathConsolidatedValue = config.reducer(pathTransactions);
      consolidatedValues[fieldPath] = pathConsolidatedValue;
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${fieldPath} - ${originalId}: ${pathCurrentValue} \u2192 ${pathConsolidatedValue} (${pathTransactions.length - (pathCurrentValue !== 0 ? 1 : 0)} pending txns)`
        );
      }
    }
    if (config.verbose) {
      console.log(
        `\u{1F525} [DEBUG] BEFORE targetResource.update() {
  originalId: '${originalId}',
  consolidatedValues: ${JSON.stringify(consolidatedValues, null, 2)}
}`
      );
    }
    const [recordOk, recordErr, record] = await tryFn(
      () => targetResource.get(originalId)
    );
    let updateOk, updateErr, updateResult;
    if (!recordOk || !record) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist yet. Will attempt update anyway (expected to fail).`
        );
      }
      const minimalRecord = { id: originalId };
      for (const [fieldPath, value] of Object.entries(consolidatedValues)) {
        lodash.set(minimalRecord, fieldPath, value);
      }
      const result = await tryFn(
        () => targetResource.update(originalId, minimalRecord)
      );
      updateOk = result[0];
      updateErr = result[1];
      updateResult = result[2];
    } else {
      for (const [fieldPath, value] of Object.entries(consolidatedValues)) {
        lodash.set(record, fieldPath, value);
      }
      const result = await tryFn(
        () => targetResource.update(originalId, record)
      );
      updateOk = result[0];
      updateErr = result[1];
      updateResult = result[2];
    }
    const consolidatedValue = consolidatedValues[config.field] || (record ? lodash.get(record, config.field, 0) : 0);
    if (config.verbose) {
      console.log(
        `\u{1F525} [DEBUG] AFTER targetResource.update() {
  updateOk: ${updateOk},
  updateErr: ${updateErr?.message || "undefined"},
  consolidatedValue (main field): ${consolidatedValue}
}`
      );
    }
    if (updateOk && config.verbose) {
      const [verifyOk, verifyErr, verifiedRecord] = await tryFn(
        () => targetResource.get(originalId, { skipCache: true })
      );
      for (const [fieldPath, expectedValue] of Object.entries(consolidatedValues)) {
        const actualValue = lodash.get(verifiedRecord, fieldPath);
        const match = actualValue === expectedValue;
        console.log(
          `\u{1F525} [DEBUG] VERIFICATION ${fieldPath} {
  expectedValue: ${expectedValue},
  actualValue: ${actualValue},
  ${match ? "\u2705 MATCH" : "\u274C MISMATCH"}
}`
        );
        if (!match) {
          console.error(
            `\u274C [CRITICAL BUG] Update reported success but value not persisted!
  Resource: ${config.resource}
  FieldPath: ${fieldPath}
  Record ID: ${originalId}
  Expected: ${expectedValue}
  Actually got: ${actualValue}
  This indicates a bug in s3db.js resource.update()`
          );
        }
      }
    }
    if (!updateOk) {
      if (updateErr?.message?.includes("does not exist")) {
        if (config.verbose) {
          console.warn(
            `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist. Skipping consolidation. ${transactions.length} transactions will remain pending until record is created.`
          );
        }
        return consolidatedValue;
      }
      console.error(
        `[EventualConsistency] ${config.resource}.${config.field} - FAILED to update ${originalId}: ${updateErr?.message || updateErr}`,
        { error: updateErr, consolidatedValue, currentValue }
      );
      throw updateErr;
    }
    if (updateOk) {
      const transactionsToUpdate = transactions.filter((txn) => txn.id !== "__synthetic__");
      const markAppliedConcurrency = config.markAppliedConcurrency || 50;
      const { results, errors } = await PromisePool.for(transactionsToUpdate).withConcurrency(markAppliedConcurrency).process(async (txn) => {
        const txnWithCohorts = ensureCohortHour(txn, config.cohort.timezone, false);
        const updateData = { applied: true };
        if (txnWithCohorts.cohortHour && !txn.cohortHour) {
          updateData.cohortHour = txnWithCohorts.cohortHour;
        }
        if (txnWithCohorts.cohortDate && !txn.cohortDate) {
          updateData.cohortDate = txnWithCohorts.cohortDate;
        }
        if (txnWithCohorts.cohortWeek && !txn.cohortWeek) {
          updateData.cohortWeek = txnWithCohorts.cohortWeek;
        }
        if (txnWithCohorts.cohortMonth && !txn.cohortMonth) {
          updateData.cohortMonth = txnWithCohorts.cohortMonth;
        }
        const [ok2, err2] = await tryFn(
          () => transactionResource.update(txn.id, updateData)
        );
        if (!ok2 && config.verbose) {
          console.warn(
            `[EventualConsistency] Failed to mark transaction ${txn.id} as applied:`,
            err2?.message,
            "Update data:",
            updateData
          );
        }
        return ok2;
      });
      if (errors && errors.length > 0 && config.verbose) {
        console.warn(`[EventualConsistency] ${errors.length} transactions failed to mark as applied`);
      }
      if (config.enableAnalytics && transactionsToUpdate.length > 0 && updateAnalyticsFn) {
        const [analyticsOk, analyticsErr] = await tryFn(
          () => updateAnalyticsFn(transactionsToUpdate)
        );
        if (!analyticsOk) {
          console.error(
            `[EventualConsistency] ${config.resource}.${config.field} - CRITICAL: Analytics update failed for ${originalId}, but consolidation succeeded:`,
            {
              error: analyticsErr?.message || analyticsErr,
              stack: analyticsErr?.stack,
              originalId,
              transactionCount: transactionsToUpdate.length
            }
          );
        }
      }
      if (targetResource && targetResource.cache && typeof targetResource.cache.delete === "function") {
        try {
          const cacheKey = await targetResource.cacheKeyFor({ id: originalId });
          await targetResource.cache.delete(cacheKey);
          if (config.verbose) {
            console.log(
              `[EventualConsistency] ${config.resource}.${config.field} - Cache invalidated for ${originalId}`
            );
          }
        } catch (cacheErr) {
          if (config.verbose) {
            console.warn(
              `[EventualConsistency] ${config.resource}.${config.field} - Failed to invalidate cache for ${originalId}: ${cacheErr?.message}`
            );
          }
        }
      }
    }
    return consolidatedValue;
  } finally {
    if (lock) {
      const [lockReleased, lockReleaseErr] = await tryFn(
        () => storage.releaseLock(lock)
      );
      if (!lockReleased && config.verbose) {
        console.warn(
          `[EventualConsistency] Failed to release lock ${lock?.name || lockKey}:`,
          lockReleaseErr?.message
        );
      }
    }
  }
}
async function getConsolidatedValue(originalId, options, transactionResource, targetResource, config) {
  const includeApplied = options.includeApplied || false;
  const startDate = options.startDate;
  const endDate = options.endDate;
  const query = { originalId };
  if (!includeApplied) {
    query.applied = false;
  }
  const [ok, err, transactions] = await tryFn(
    () => transactionResource.query(query)
  );
  if (!ok || !transactions || transactions.length === 0) {
    const [recordOk2, recordErr2, record2] = await tryFn(
      () => targetResource.get(originalId)
    );
    if (recordOk2 && record2) {
      return record2[config.field] || 0;
    }
    return 0;
  }
  let filtered = transactions;
  if (startDate || endDate) {
    filtered = transactions.filter((t) => {
      const timestamp = new Date(t.timestamp);
      if (startDate && timestamp < new Date(startDate)) return false;
      if (endDate && timestamp > new Date(endDate)) return false;
      return true;
    });
  }
  const [recordOk, recordErr, record] = await tryFn(
    () => targetResource.get(originalId)
  );
  const currentValue = recordOk && record ? record[config.field] || 0 : 0;
  const hasSetOperation = filtered.some((t) => t.operation === "set");
  if (currentValue !== 0 && !hasSetOperation) {
    filtered.unshift(createSyntheticSetTransaction(currentValue));
  }
  filtered.sort(
    (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
  );
  return config.reducer(filtered);
}
async function getCohortStats(cohortDate, transactionResource) {
  const [ok, err, transactions] = await tryFn(
    () => transactionResource.query({
      cohortDate
    })
  );
  if (!ok) return null;
  const stats = {
    date: cohortDate,
    transactionCount: transactions.length,
    totalValue: 0,
    byOperation: { set: 0, add: 0, sub: 0 },
    byOriginalId: {}
  };
  for (const txn of transactions) {
    stats.totalValue += txn.value || 0;
    stats.byOperation[txn.operation] = (stats.byOperation[txn.operation] || 0) + 1;
    if (!stats.byOriginalId[txn.originalId]) {
      stats.byOriginalId[txn.originalId] = {
        count: 0,
        value: 0
      };
    }
    stats.byOriginalId[txn.originalId].count++;
    stats.byOriginalId[txn.originalId].value += txn.value || 0;
  }
  return stats;
}
async function recalculateRecord(originalId, transactionResource, targetResource, storage, consolidateRecordFn, config) {
  const lockKey = `recalculate-${config.resource}-${config.field}-${originalId}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: config.lockTimeout || 30,
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] Recalculate lock for ${originalId} already held, skipping`);
    }
    throw new PluginError(`Cannot recalculate ${originalId}: lock already held by another worker`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "recalculateRecord",
      statusCode: 409,
      retriable: true,
      suggestion: "Retry after the other worker releases the lock or increase lock TTL if necessary.",
      recordId: originalId
    });
  }
  try {
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Starting recalculation for ${originalId} (resetting all transactions to pending)`
      );
    }
    const [allOk, allErr, allTransactions] = await tryFn(
      () => transactionResource.query({
        originalId
      })
    );
    if (!allOk || !allTransactions || allTransactions.length === 0) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No transactions found for ${originalId}, nothing to recalculate`
        );
      }
      return 0;
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Found ${allTransactions.length} total transactions for ${originalId}, marking all as pending...`
      );
    }
    const hasAnchor = allTransactions.some((txn) => txn.source === "anchor");
    if (!hasAnchor) {
      const now = /* @__PURE__ */ new Date();
      const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
      const oldestTransaction = allTransactions.sort(
        (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
      )[0];
      const anchorTimestamp = oldestTransaction ? new Date(new Date(oldestTransaction.timestamp).getTime() - 1).toISOString() : now.toISOString();
      const anchorCohortInfo = getCohortInfo(new Date(anchorTimestamp), config.cohort.timezone, config.verbose);
      const anchorTransaction = {
        id: idGenerator(),
        originalId,
        field: config.field,
        fieldPath: config.field,
        value: 0,
        // Always 0 for recalculate - we start from scratch
        operation: "set",
        timestamp: anchorTimestamp,
        cohortDate: anchorCohortInfo.date,
        cohortHour: anchorCohortInfo.hour,
        cohortMonth: anchorCohortInfo.month,
        source: "anchor",
        applied: true
        // Anchor is always applied
      };
      await transactionResource.insert(anchorTransaction);
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Created anchor transaction for ${originalId} with value 0`
        );
      }
    }
    const transactionsToReset = allTransactions.filter((txn) => txn.source !== "anchor");
    const recalculateConcurrency = config.recalculateConcurrency || 50;
    const { results, errors } = await PromisePool.for(transactionsToReset).withConcurrency(recalculateConcurrency).process(async (txn) => {
      const [ok, err] = await tryFn(
        () => transactionResource.update(txn.id, { applied: false })
      );
      if (!ok && config.verbose) {
        console.warn(`[EventualConsistency] Failed to reset transaction ${txn.id}:`, err?.message);
      }
      return ok;
    });
    if (errors && errors.length > 0) {
      console.warn(
        `[EventualConsistency] ${config.resource}.${config.field} - Failed to reset ${errors.length} transactions during recalculation`
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Reset ${results.length} transactions to pending, now resetting record value and running consolidation...`
      );
    }
    const [resetOk, resetErr] = await tryFn(
      () => targetResource.update(originalId, {
        [config.field]: 0
      })
    );
    if (!resetOk && config.verbose) {
      console.warn(
        `[EventualConsistency] ${config.resource}.${config.field} - Failed to reset record value for ${originalId}: ${resetErr?.message}`
      );
    }
    const consolidatedValue = await consolidateRecordFn(originalId);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Recalculation complete for ${originalId}: final value = ${consolidatedValue}`
      );
    }
    return consolidatedValue;
  } finally {
    if (lock) {
      const [lockReleased, lockReleaseErr] = await tryFn(
        () => storage.releaseLock(lock)
      );
      if (!lockReleased && config.verbose) {
        console.warn(
          `[EventualConsistency] Failed to release recalculate lock ${lock?.name || lockKey}:`,
          lockReleaseErr?.message
        );
      }
    }
  }
}

function startGarbageCollectionTimer(handler, resourceName, fieldName, runGCCallback, config) {
  const gcIntervalMs = config.gcInterval * 1e3;
  handler.gcTimer = setInterval(async () => {
    await runGCCallback(handler, resourceName, fieldName);
  }, gcIntervalMs);
  return handler.gcTimer;
}
async function runGarbageCollection(transactionResource, storage, config, emitFn) {
  const lockKey = `gc-${config.resource}-${config.field}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: 300,
    // 5 minutes for GC
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] GC already running in another container`);
    }
    return;
  }
  try {
    const now = Date.now();
    const retentionMs = config.transactionRetention * 24 * 60 * 60 * 1e3;
    const cutoffDate = new Date(now - retentionMs);
    const cutoffIso = cutoffDate.toISOString();
    if (config.verbose) {
      console.log(`[EventualConsistency] Running GC for transactions older than ${cutoffIso} (${config.transactionRetention} days)`);
    }
    const [ok, err, oldTransactions] = await tryFn(
      () => transactionResource.query({
        applied: true,
        timestamp: { "<": cutoffIso }
      })
    );
    if (!ok) {
      if (config.verbose) {
        console.warn(`[EventualConsistency] GC failed to query transactions:`, err?.message);
      }
      return;
    }
    if (!oldTransactions || oldTransactions.length === 0) {
      if (config.verbose) {
        console.log(`[EventualConsistency] No old transactions to clean up`);
      }
      return;
    }
    if (config.verbose) {
      console.log(`[EventualConsistency] Deleting ${oldTransactions.length} old transactions`);
    }
    const { results, errors } = await PromisePool.for(oldTransactions).withConcurrency(10).process(async (txn) => {
      const [deleted] = await tryFn(() => transactionResource.delete(txn.id));
      return deleted;
    });
    if (config.verbose) {
      console.log(`[EventualConsistency] GC completed: ${results.length} deleted, ${errors.length} errors`);
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:gc-completed", {
        resource: config.resource,
        field: config.field,
        deletedCount: results.length,
        errorCount: errors.length
      });
    }
  } catch (error) {
    if (config.verbose) {
      console.warn(`[EventualConsistency] GC error:`, error.message);
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:gc-error", error);
    }
  } finally {
    if (lock) {
      await tryFn(() => storage.releaseLock(lock));
    }
  }
}

async function updateAnalytics(transactions, analyticsResource, config) {
  if (!analyticsResource || transactions.length === 0) return;
  if (!config.field) {
    throw new PluginError("config.field is undefined in updateAnalytics()", {
      pluginName: "EventualConsistencyPlugin",
      operation: "updateAnalytics",
      statusCode: 500,
      retriable: false,
      suggestion: "Ensure each field handler uses its own configuration object when invoking analytics updates.",
      context: {
        resource: config.resource,
        field: config.field,
        transactions: transactions.length,
        analyticsResource: analyticsResource?.name || "unknown"
      }
    });
  }
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${config.resource}.${config.field} - Updating analytics for ${transactions.length} transactions...`
    );
  }
  try {
    const byHour = groupByCohort(transactions, "cohortHour");
    const cohortCount = Object.keys(byHour).length;
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Updating ${cohortCount} hourly analytics cohorts IN PARALLEL...`
      );
    }
    await Promise.all(
      Object.entries(byHour).map(
        ([cohort, txns]) => upsertAnalytics("hour", cohort, txns, analyticsResource, config)
      )
    );
    if (config.analyticsConfig.rollupStrategy === "incremental") {
      const uniqueHours = Object.keys(byHour);
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Rolling up ${uniqueHours.length} hours to daily/weekly/monthly analytics IN PARALLEL...`
        );
      }
      await Promise.all(
        uniqueHours.map(
          (cohortHour) => rollupAnalytics(cohortHour, analyticsResource, config)
        )
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Analytics update complete for ${cohortCount} cohorts`
      );
    }
  } catch (error) {
    console.error(
      `[EventualConsistency] CRITICAL: ${config.resource}.${config.field} - Analytics update failed:`,
      {
        error: error.message,
        stack: error.stack,
        field: config.field,
        resource: config.resource,
        transactionCount: transactions.length
      }
    );
    throw new PluginError(`Analytics update failed for ${config.resource}.${config.field}: ${error.message}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "updateAnalytics",
      statusCode: 500,
      retriable: true,
      suggestion: "Check the console logs above for the failing transaction and fix the reducer or analytics configuration.",
      resource: config.resource,
      field: config.field,
      original: error
    });
  }
}
async function upsertAnalytics(period, cohort, transactions, analyticsResource, config) {
  const id = `${period}-${cohort}`;
  const transactionCount = transactions.length;
  const signedValues = transactions.map((t) => {
    if (t.operation === "sub") return -t.value;
    return t.value;
  });
  const totalValue = signedValues.reduce((sum, v) => sum + v, 0);
  const avgValue = totalValue / transactionCount;
  const minValue = Math.min(...signedValues);
  const maxValue = Math.max(...signedValues);
  const operations = calculateOperationBreakdown(transactions);
  const recordCount = new Set(transactions.map((t) => t.originalId)).size;
  const now = (/* @__PURE__ */ new Date()).toISOString();
  const [existingOk, existingErr, existing] = await tryFn(
    () => analyticsResource.get(id)
  );
  if (existingOk && existing) {
    const newTransactionCount = existing.transactionCount + transactionCount;
    const newTotalValue = existing.totalValue + totalValue;
    const newAvgValue = newTotalValue / newTransactionCount;
    const newMinValue = Math.min(existing.minValue, minValue);
    const newMaxValue = Math.max(existing.maxValue, maxValue);
    const newOperations = { ...existing.operations };
    for (const [op, stats] of Object.entries(operations)) {
      if (!newOperations[op]) {
        newOperations[op] = { count: 0, sum: 0 };
      }
      newOperations[op].count += stats.count;
      newOperations[op].sum += stats.sum;
    }
    const newRecordCount = Math.max(existing.recordCount, recordCount);
    await tryFn(
      () => analyticsResource.update(id, {
        transactionCount: newTransactionCount,
        totalValue: newTotalValue,
        avgValue: newAvgValue,
        minValue: newMinValue,
        maxValue: newMaxValue,
        operations: newOperations,
        recordCount: newRecordCount,
        updatedAt: now
      })
    );
  } else {
    await tryFn(
      () => analyticsResource.insert({
        id,
        field: config.field,
        period,
        cohort,
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        consolidatedAt: now,
        updatedAt: now
      })
    );
  }
}
function calculateOperationBreakdown(transactions) {
  const breakdown = {};
  for (const txn of transactions) {
    const op = txn.operation;
    if (!breakdown[op]) {
      breakdown[op] = { count: 0, sum: 0 };
    }
    breakdown[op].count++;
    const signedValue = op === "sub" ? -txn.value : txn.value;
    breakdown[op].sum += signedValue;
  }
  return breakdown;
}
async function rollupAnalytics(cohortHour, analyticsResource, config) {
  const cohortDate = cohortHour.substring(0, 10);
  const cohortMonth = cohortHour.substring(0, 7);
  const date = new Date(cohortDate);
  const cohortWeek = getCohortWeekFromDate(date);
  await rollupPeriod("day", cohortDate, cohortDate, analyticsResource, config);
  await rollupPeriod("week", cohortWeek, cohortWeek, analyticsResource, config);
  await rollupPeriod("month", cohortMonth, cohortMonth, analyticsResource, config);
}
function getCohortWeekFromDate(date) {
  const target = new Date(date.valueOf());
  const dayNr = (date.getUTCDay() + 6) % 7;
  target.setUTCDate(target.getUTCDate() - dayNr + 3);
  const yearStart = new Date(Date.UTC(target.getUTCFullYear(), 0, 1));
  const firstThursday = new Date(yearStart.valueOf());
  if (yearStart.getUTCDay() !== 4) {
    firstThursday.setUTCDate(yearStart.getUTCDate() + (4 - yearStart.getUTCDay() + 7) % 7);
  }
  const weekNumber = 1 + Math.round((target - firstThursday) / 6048e5);
  const weekYear = target.getUTCFullYear();
  return `${weekYear}-W${String(weekNumber).padStart(2, "0")}`;
}
async function rollupPeriod(period, cohort, sourcePrefix, analyticsResource, config) {
  let sourcePeriod;
  if (period === "day") {
    sourcePeriod = "hour";
  } else if (period === "week") {
    sourcePeriod = "day";
  } else if (period === "month") {
    sourcePeriod = "day";
  } else {
    sourcePeriod = "day";
  }
  const [ok, err, allAnalytics] = await tryFn(
    () => analyticsResource.list()
  );
  if (!ok || !allAnalytics) return;
  let sourceAnalytics;
  if (period === "week") {
    sourceAnalytics = allAnalytics.filter((a) => {
      if (a.period !== sourcePeriod) return false;
      const dayDate = new Date(a.cohort);
      const dayWeek = getCohortWeekFromDate(dayDate);
      return dayWeek === cohort;
    });
  } else {
    sourceAnalytics = allAnalytics.filter(
      (a) => a.period === sourcePeriod && a.cohort.startsWith(sourcePrefix)
    );
  }
  if (sourceAnalytics.length === 0) return;
  const transactionCount = sourceAnalytics.reduce((sum, a) => sum + a.transactionCount, 0);
  const totalValue = sourceAnalytics.reduce((sum, a) => sum + a.totalValue, 0);
  const avgValue = totalValue / transactionCount;
  const minValue = Math.min(...sourceAnalytics.map((a) => a.minValue));
  const maxValue = Math.max(...sourceAnalytics.map((a) => a.maxValue));
  const operations = {};
  for (const analytics of sourceAnalytics) {
    for (const [op, stats] of Object.entries(analytics.operations || {})) {
      if (!operations[op]) {
        operations[op] = { count: 0, sum: 0 };
      }
      operations[op].count += stats.count;
      operations[op].sum += stats.sum;
    }
  }
  const recordCount = Math.max(...sourceAnalytics.map((a) => a.recordCount));
  const id = `${period}-${cohort}`;
  const now = (/* @__PURE__ */ new Date()).toISOString();
  const [existingOk, existingErr, existing] = await tryFn(
    () => analyticsResource.get(id)
  );
  if (existingOk && existing) {
    await tryFn(
      () => analyticsResource.update(id, {
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        updatedAt: now
      })
    );
  } else {
    await tryFn(
      () => analyticsResource.insert({
        id,
        field: config.field,
        period,
        cohort,
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        consolidatedAt: now,
        updatedAt: now
      })
    );
  }
}
function fillGaps(data, period, startDate, endDate) {
  if (!data || data.length === 0) {
    data = [];
  }
  const dataMap = /* @__PURE__ */ new Map();
  data.forEach((item) => {
    dataMap.set(item.cohort, item);
  });
  const result = [];
  const emptyRecord = {
    count: 0,
    sum: 0,
    avg: 0,
    min: 0,
    max: 0,
    recordCount: 0
  };
  if (period === "hour") {
    const start = /* @__PURE__ */ new Date(startDate + "T00:00:00Z");
    const end = /* @__PURE__ */ new Date(endDate + "T23:59:59Z");
    for (let dt = new Date(start); dt <= end; dt.setHours(dt.getHours() + 1)) {
      const cohort = dt.toISOString().substring(0, 13);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
    }
  } else if (period === "day") {
    const start = new Date(startDate);
    const end = new Date(endDate);
    for (let dt = new Date(start); dt <= end; dt.setDate(dt.getDate() + 1)) {
      const cohort = dt.toISOString().substring(0, 10);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
    }
  } else if (period === "month") {
    const startYear = parseInt(startDate.substring(0, 4));
    const startMonth = parseInt(startDate.substring(5, 7));
    const endYear = parseInt(endDate.substring(0, 4));
    const endMonth = parseInt(endDate.substring(5, 7));
    for (let year = startYear; year <= endYear; year++) {
      const firstMonth = year === startYear ? startMonth : 1;
      const lastMonth = year === endYear ? endMonth : 12;
      for (let month = firstMonth; month <= lastMonth; month++) {
        const cohort = `${year}-${month.toString().padStart(2, "0")}`;
        result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      }
    }
  }
  return result;
}
async function getAnalytics(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new PluginError(`No eventual consistency configured for resource: ${resourceName}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getAnalytics",
      statusCode: 404,
      retriable: false,
      suggestion: "Ensure the resource is registered under EventualConsistencyPlugin resources.",
      resourceName
    });
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new PluginError(`No eventual consistency configured for field: ${resourceName}.${field}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getAnalytics",
      statusCode: 404,
      retriable: false,
      suggestion: "Add the field to EventualConsistencyPlugin resources configuration.",
      resourceName,
      field
    });
  }
  if (!handler.analyticsResource) {
    throw new AnalyticsNotEnabledError({ resourceName, field, pluginName: "EventualConsistencyPlugin" });
  }
  const { period = "day", date, startDate, endDate, month, year, breakdown = false, recordId } = options;
  if (recordId) {
    return await getAnalyticsForRecord(resourceName, field, recordId, options, handler);
  }
  const [ok, err, allAnalytics] = await tryFn(
    () => handler.analyticsResource.list()
  );
  if (!ok || !allAnalytics) {
    return [];
  }
  let filtered = allAnalytics.filter((a) => a.period === period);
  if (date) {
    if (period === "hour") {
      filtered = filtered.filter((a) => a.cohort.startsWith(date));
    } else {
      filtered = filtered.filter((a) => a.cohort === date);
    }
  } else if (startDate && endDate) {
    filtered = filtered.filter((a) => a.cohort >= startDate && a.cohort <= endDate);
  } else if (month) {
    filtered = filtered.filter((a) => a.cohort.startsWith(month));
  } else if (year) {
    filtered = filtered.filter((a) => a.cohort.startsWith(String(year)));
  }
  filtered.sort((a, b) => a.cohort.localeCompare(b.cohort));
  if (breakdown === "operations") {
    return filtered.map((a) => ({
      cohort: a.cohort,
      ...a.operations
    }));
  }
  return filtered.map((a) => ({
    cohort: a.cohort,
    count: a.transactionCount,
    sum: a.totalValue,
    avg: a.avgValue,
    min: a.minValue,
    max: a.maxValue,
    operations: a.operations,
    recordCount: a.recordCount
  }));
}
async function getAnalyticsForRecord(resourceName, field, recordId, options, handler) {
  const { period = "day", date, startDate, endDate, month, year } = options;
  const [okTrue, errTrue, appliedTransactions] = await tryFn(
    () => handler.transactionResource.query({
      originalId: recordId,
      applied: true
    })
  );
  const [okFalse, errFalse, pendingTransactions] = await tryFn(
    () => handler.transactionResource.query({
      originalId: recordId,
      applied: false
    })
  );
  let allTransactions = [
    ...okTrue && appliedTransactions ? appliedTransactions : [],
    ...okFalse && pendingTransactions ? pendingTransactions : []
  ];
  if (allTransactions.length === 0) {
    return [];
  }
  allTransactions = ensureCohortHours(allTransactions, handler.config?.cohort?.timezone || "UTC", false);
  let filtered = allTransactions;
  if (date) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(date));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate === date);
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(date));
    }
  } else if (startDate && endDate) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour >= startDate && t.cohortHour <= endDate);
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate >= startDate && t.cohortDate <= endDate);
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth >= startDate && t.cohortMonth <= endDate);
    }
  } else if (month) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(month));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate.startsWith(month));
    }
  } else if (year) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(String(year)));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate.startsWith(String(year)));
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(String(year)));
    }
  }
  const cohortField = period === "hour" ? "cohortHour" : period === "day" ? "cohortDate" : "cohortMonth";
  const aggregated = aggregateTransactionsByCohort(filtered, cohortField);
  return aggregated;
}
function aggregateTransactionsByCohort(transactions, cohortField) {
  const groups = {};
  for (const txn of transactions) {
    const cohort = txn[cohortField];
    if (!cohort) continue;
    if (!groups[cohort]) {
      groups[cohort] = {
        cohort,
        count: 0,
        sum: 0,
        min: Infinity,
        max: -Infinity,
        recordCount: /* @__PURE__ */ new Set(),
        operations: {}
      };
    }
    const group = groups[cohort];
    const signedValue = txn.operation === "sub" ? -txn.value : txn.value;
    group.count++;
    group.sum += signedValue;
    group.min = Math.min(group.min, signedValue);
    group.max = Math.max(group.max, signedValue);
    group.recordCount.add(txn.originalId);
    const op = txn.operation;
    if (!group.operations[op]) {
      group.operations[op] = { count: 0, sum: 0 };
    }
    group.operations[op].count++;
    group.operations[op].sum += signedValue;
  }
  return Object.values(groups).map((g) => ({
    cohort: g.cohort,
    count: g.count,
    sum: g.sum,
    avg: g.sum / g.count,
    min: g.min === Infinity ? 0 : g.min,
    max: g.max === -Infinity ? 0 : g.max,
    recordCount: g.recordCount.size,
    operations: g.operations
  })).sort((a, b) => a.cohort.localeCompare(b.cohort));
}
async function getMonthByDay(resourceName, field, month, options, fieldHandlers) {
  const year = parseInt(month.substring(0, 4));
  const monthNum = parseInt(month.substring(5, 7));
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const startDate = firstDay.toISOString().substring(0, 10);
  const endDate = lastDay.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getDayByHour(resourceName, field, date, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    date
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", date, date);
  }
  return data;
}
async function getLastNDays(resourceName, field, days, options, fieldHandlers) {
  const dates = Array.from({ length: days }, (_, i) => {
    const date = /* @__PURE__ */ new Date();
    date.setDate(date.getDate() - i);
    return date.toISOString().substring(0, 10);
  }).reverse();
  const data = await getAnalytics(resourceName, field, {
    ...options,
    //  Include all options (recordId, etc.)
    period: "day",
    startDate: dates[0],
    endDate: dates[dates.length - 1]
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", dates[0], dates[dates.length - 1]);
  }
  return data;
}
async function getYearByMonth(resourceName, field, year, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "month",
    year
  }, fieldHandlers);
  if (options.fillGaps) {
    const startDate = `${year}-01`;
    const endDate = `${year}-12`;
    return fillGaps(data, "month", startDate, endDate);
  }
  return data;
}
async function getYearByWeek(resourceName, field, year, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    year
  }, fieldHandlers);
  if (options.fillGaps) {
    const startWeek = `${year}-W01`;
    const endWeek = `${year}-W53`;
    return fillGaps(data, "week", startWeek, endWeek);
  }
  return data;
}
async function getMonthByWeek(resourceName, field, month, options, fieldHandlers) {
  const year = parseInt(month.substring(0, 4));
  const monthNum = parseInt(month.substring(5, 7));
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const firstWeek = getCohortWeekFromDate(firstDay);
  const lastWeek = getCohortWeekFromDate(lastDay);
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    startDate: firstWeek,
    endDate: lastWeek
  }, fieldHandlers);
  return data;
}
async function getMonthByHour(resourceName, field, month, options, fieldHandlers) {
  let year, monthNum;
  if (month === "last") {
    const now = /* @__PURE__ */ new Date();
    now.setMonth(now.getMonth() - 1);
    year = now.getFullYear();
    monthNum = now.getMonth() + 1;
  } else {
    year = parseInt(month.substring(0, 4));
    monthNum = parseInt(month.substring(5, 7));
  }
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const startDate = firstDay.toISOString().substring(0, 10);
  const endDate = lastDay.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", startDate, endDate);
  }
  return data;
}
async function getTopRecords(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new PluginError(`No eventual consistency configured for resource: ${resourceName}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getTopRecords",
      statusCode: 404,
      retriable: false,
      suggestion: "Add the resource to EventualConsistencyPlugin resources configuration.",
      resourceName
    });
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new PluginError(`No eventual consistency configured for field: ${resourceName}.${field}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getTopRecords",
      statusCode: 404,
      retriable: false,
      suggestion: "Ensure the field is configured for eventual consistency before querying analytics.",
      resourceName,
      field
    });
  }
  if (!handler.transactionResource) {
    throw new PluginError("Transaction resource not initialized", {
      pluginName: "EventualConsistencyPlugin",
      operation: "getTopRecords",
      statusCode: 500,
      retriable: false,
      suggestion: "Verify plugin installation completed successfully and transaction resources were created.",
      resourceName,
      field
    });
  }
  const { period = "day", date, metric = "transactionCount", limit = 10 } = options;
  const [ok, err, transactions] = await tryFn(
    () => handler.transactionResource.list()
  );
  if (!ok || !transactions) {
    return [];
  }
  let filtered = transactions;
  if (date) {
    if (period === "hour") {
      filtered = transactions.filter((t) => t.cohortHour && t.cohortHour.startsWith(date));
    } else if (period === "day") {
      filtered = transactions.filter((t) => t.cohortDate === date);
    } else if (period === "month") {
      filtered = transactions.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(date));
    }
  }
  const byRecord = {};
  for (const txn of filtered) {
    const recordId = txn.originalId;
    if (!byRecord[recordId]) {
      byRecord[recordId] = { count: 0, sum: 0 };
    }
    byRecord[recordId].count++;
    byRecord[recordId].sum += txn.value;
  }
  const records = Object.entries(byRecord).map(([recordId, stats]) => ({
    recordId,
    count: stats.count,
    sum: stats.sum
  }));
  records.sort((a, b) => {
    if (metric === "transactionCount") {
      return b.count - a.count;
    } else if (metric === "totalValue") {
      return b.sum - a.sum;
    }
    return 0;
  });
  return records.slice(0, limit);
}
async function getYearByDay(resourceName, field, year, options, fieldHandlers) {
  const startDate = `${year}-01-01`;
  const endDate = `${year}-12-31`;
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getWeekByDay(resourceName, field, week, options, fieldHandlers) {
  const year = parseInt(week.substring(0, 4));
  const weekNum = parseInt(week.substring(6, 8));
  const jan4 = new Date(Date.UTC(year, 0, 4));
  const jan4Day = jan4.getUTCDay() || 7;
  const firstMonday = new Date(Date.UTC(year, 0, 4 - jan4Day + 1));
  const weekStart = new Date(firstMonday);
  weekStart.setUTCDate(weekStart.getUTCDate() + (weekNum - 1) * 7);
  const days = [];
  for (let i = 0; i < 7; i++) {
    const day = new Date(weekStart);
    day.setUTCDate(weekStart.getUTCDate() + i);
    days.push(day.toISOString().substring(0, 10));
  }
  const startDate = days[0];
  const endDate = days[6];
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getWeekByHour(resourceName, field, week, options, fieldHandlers) {
  const year = parseInt(week.substring(0, 4));
  const weekNum = parseInt(week.substring(6, 8));
  const jan4 = new Date(Date.UTC(year, 0, 4));
  const jan4Day = jan4.getUTCDay() || 7;
  const firstMonday = new Date(Date.UTC(year, 0, 4 - jan4Day + 1));
  const weekStart = new Date(firstMonday);
  weekStart.setUTCDate(weekStart.getUTCDate() + (weekNum - 1) * 7);
  const weekEnd = new Date(weekStart);
  weekEnd.setUTCDate(weekEnd.getUTCDate() + 6);
  const startDate = weekStart.toISOString().substring(0, 10);
  const endDate = weekEnd.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", startDate, endDate);
  }
  return data;
}
async function getLastNHours(resourceName, field, hours = 24, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const hoursAgo = new Date(now);
  hoursAgo.setHours(hoursAgo.getHours() - hours + 1);
  const startHour = hoursAgo.toISOString().substring(0, 13);
  const endHour = now.toISOString().substring(0, 13);
  const data = await getAnalytics(resourceName, field, {
    ...options,
    //  Include all options (recordId, etc.)
    period: "hour",
    startDate: startHour,
    endDate: endHour
  }, fieldHandlers);
  if (options.fillGaps) {
    const result = [];
    const emptyRecord = { count: 0, sum: 0, avg: 0, min: 0, max: 0, recordCount: 0 };
    const dataMap = new Map(data.map((d) => [d.cohort, d]));
    const current = new Date(hoursAgo);
    for (let i = 0; i < hours; i++) {
      const cohort = current.toISOString().substring(0, 13);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      current.setHours(current.getHours() + 1);
    }
    return result;
  }
  return data;
}
async function getLastNWeeks(resourceName, field, weeks = 4, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const weeksAgo = new Date(now);
  weeksAgo.setDate(weeksAgo.getDate() - weeks * 7);
  const weekCohorts = [];
  const currentDate = new Date(weeksAgo);
  while (currentDate <= now) {
    const weekCohort = getCohortWeekFromDate(currentDate);
    if (!weekCohorts.includes(weekCohort)) {
      weekCohorts.push(weekCohort);
    }
    currentDate.setDate(currentDate.getDate() + 7);
  }
  const startWeek = weekCohorts[0];
  const endWeek = weekCohorts[weekCohorts.length - 1];
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    startDate: startWeek,
    endDate: endWeek
  }, fieldHandlers);
  return data;
}
async function getLastNMonths(resourceName, field, months = 12, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const monthsAgo = new Date(now);
  monthsAgo.setMonth(monthsAgo.getMonth() - months + 1);
  const startDate = monthsAgo.toISOString().substring(0, 7);
  const endDate = now.toISOString().substring(0, 7);
  const data = await getAnalytics(resourceName, field, {
    ...options,
    //  Include all options (recordId, etc.)
    period: "month",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    const result = [];
    const emptyRecord = { count: 0, sum: 0, avg: 0, min: 0, max: 0, recordCount: 0 };
    const dataMap = new Map(data.map((d) => [d.cohort, d]));
    const current = new Date(monthsAgo);
    current.setDate(1);
    for (let i = 0; i < months; i++) {
      const cohort = current.toISOString().substring(0, 7);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      current.setMonth(current.getMonth() + 1);
    }
    return result;
  }
  return data;
}
async function getRawEvents(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new PluginError(`No eventual consistency configured for resource: ${resourceName}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getRawEvents",
      statusCode: 404,
      retriable: false,
      suggestion: "Add the resource under EventualConsistencyPlugin configuration to retrieve raw events.",
      resourceName
    });
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new PluginError(`No eventual consistency configured for field: ${resourceName}.${field}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "getRawEvents",
      statusCode: 404,
      retriable: false,
      suggestion: "Ensure the field is included in EventualConsistencyPlugin configuration.",
      resourceName,
      field
    });
  }
  if (!handler.transactionResource) {
    throw new PluginError("Transaction resource not initialized", {
      pluginName: "EventualConsistencyPlugin",
      operation: "getRawEvents",
      statusCode: 500,
      retriable: false,
      suggestion: "Verify plugin installation completed successfully and transaction resources were created.",
      resourceName,
      field
    });
  }
  const {
    recordId,
    startDate,
    endDate,
    cohortDate,
    cohortHour,
    cohortMonth,
    applied,
    operation,
    limit
  } = options;
  const query = {};
  if (recordId !== void 0) {
    query.originalId = recordId;
  }
  if (applied !== void 0) {
    query.applied = applied;
  }
  const [ok, err, allTransactions] = await tryFn(
    () => handler.transactionResource.query(query)
  );
  if (!ok || !allTransactions) {
    return [];
  }
  let filtered = allTransactions;
  if (operation !== void 0) {
    filtered = filtered.filter((t) => t.operation === operation);
  }
  if (cohortDate) {
    filtered = filtered.filter((t) => t.cohortDate === cohortDate);
  }
  if (cohortHour) {
    filtered = filtered.filter((t) => t.cohortHour === cohortHour);
  }
  if (cohortMonth) {
    filtered = filtered.filter((t) => t.cohortMonth === cohortMonth);
  }
  if (startDate && endDate) {
    const isHourly = startDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter(
      (t) => t[cohortField] && t[cohortField] >= startDate && t[cohortField] <= endDate
    );
  } else if (startDate) {
    const isHourly = startDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter((t) => t[cohortField] && t[cohortField] >= startDate);
  } else if (endDate) {
    const isHourly = endDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter((t) => t[cohortField] && t[cohortField] <= endDate);
  }
  filtered.sort((a, b) => {
    const aTime = new Date(a.timestamp || a.createdAt).getTime();
    const bTime = new Date(b.timestamp || b.createdAt).getTime();
    return bTime - aTime;
  });
  if (limit && limit > 0) {
    filtered = filtered.slice(0, limit);
  }
  return filtered;
}

function addHelperMethods(resource, plugin, config) {
  resource.set = async (id, field, value) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, value);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value,
      operation: "set",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "set",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    return value;
  };
  resource.add = async (id, field, amount) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, amount);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value: amount,
      operation: "add",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "add",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    const [ok, err, record] = await tryFn(() => handler.targetResource.get(id));
    if (!ok || !record) return amount;
    const lodash = await import('lodash-es');
    const currentValue = lodash.get(record, fieldPath, 0);
    return currentValue + amount;
  };
  resource.sub = async (id, field, amount) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, amount);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value: amount,
      operation: "sub",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "sub",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    const [ok, err, record] = await tryFn(() => handler.targetResource.get(id));
    if (!ok || !record) return -amount;
    const lodash = await import('lodash-es');
    const currentValue = lodash.get(record, fieldPath, 0);
    return currentValue - amount;
  };
  resource.increment = async (id, field) => {
    return await resource.add(id, field, 1);
  };
  resource.decrement = async (id, field) => {
    return await resource.sub(id, field, 1);
  };
  resource.consolidate = async (id, field) => {
    if (!field) {
      throw new PluginError("Field parameter is required: consolidate(id, field)", {
        pluginName: "EventualConsistencyPlugin",
        operation: "resource.consolidate",
        statusCode: 400,
        retriable: false,
        suggestion: "Invoke consolidate with both id and field parameters."
      });
    }
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new PluginError(`No eventual consistency plugin found for field "${field}"`, {
        pluginName: "EventualConsistencyPlugin",
        operation: "resource.consolidate",
        statusCode: 404,
        retriable: false,
        suggestion: `Available fields: ${availableFields}`,
        field
      });
    }
    return await plugin._consolidateWithHandler(handler, id);
  };
  resource.getConsolidatedValue = async (id, field, options = {}) => {
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new PluginError(`No eventual consistency plugin found for field "${field}"`, {
        pluginName: "EventualConsistencyPlugin",
        operation: "resource.getConsolidatedValue",
        statusCode: 404,
        retriable: false,
        suggestion: `Available fields: ${availableFields}`,
        field
      });
    }
    return await plugin._getConsolidatedValueWithHandler(handler, id, options);
  };
  resource.recalculate = async (id, field) => {
    if (!field) {
      throw new PluginError("Field parameter is required: recalculate(id, field)", {
        pluginName: "EventualConsistencyPlugin",
        operation: "resource.recalculate",
        statusCode: 400,
        retriable: false,
        suggestion: "Invoke recalculate with both id and field parameters."
      });
    }
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new PluginError(`No eventual consistency plugin found for field "${field}"`, {
        pluginName: "EventualConsistencyPlugin",
        operation: "resource.recalculate",
        statusCode: 404,
        retriable: false,
        suggestion: `Available fields: ${availableFields}`,
        field
      });
    }
    return await plugin._recalculateWithHandler(handler, id);
  };
}

async function onInstall(database, fieldHandlers, completeFieldSetupFn, watchForResourceFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    const targetResource = database.resources[resourceName];
    if (!targetResource) {
      for (const handler of resourceHandlers.values()) {
        handler.deferredSetup = true;
      }
      watchForResourceFn(resourceName);
      continue;
    }
    for (const [fieldName, handler] of resourceHandlers) {
      handler.targetResource = targetResource;
      await completeFieldSetupFn(handler);
    }
  }
}
function watchForResource(resourceName, database, fieldHandlers, completeFieldSetupFn) {
  const hookCallback = async ({ resource, config }) => {
    if (config.name === resourceName) {
      const resourceHandlers = fieldHandlers.get(resourceName);
      if (!resourceHandlers) return;
      for (const [fieldName, handler] of resourceHandlers) {
        if (handler.deferredSetup) {
          handler.targetResource = resource;
          handler.deferredSetup = false;
          await completeFieldSetupFn(handler);
        }
      }
    }
  };
  database.addHook("afterCreateResource", hookCallback);
}
async function completeFieldSetup(handler, database, config, plugin) {
  if (!handler.targetResource) return;
  const resourceName = handler.resource;
  const fieldName = handler.field;
  const transactionResourceName = `plg_${resourceName}_tx_${fieldName}`;
  const partitionConfig = createPartitionConfig();
  const [ok, err, transactionResource] = await tryFn(
    () => database.createResource({
      name: transactionResourceName,
      attributes: {
        id: "string|required",
        originalId: "string|required",
        field: "string|required",
        fieldPath: "string|optional",
        // Support for nested field paths (e.g., 'utmResults.medium')
        value: "number|required",
        operation: "string|required",
        timestamp: "string|required",
        cohortDate: "string|required",
        cohortHour: "string|required",
        cohortWeek: "string|optional",
        cohortMonth: "string|optional",
        source: "string|optional",
        applied: "boolean|optional"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: partitionConfig,
      asyncPartitions: true,
      createdBy: "EventualConsistencyPlugin"
    })
  );
  if (!ok && !database.resources[transactionResourceName]) {
    throw new PluginError(`Failed to create transaction resource for ${resourceName}.${fieldName}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "createTransactionResource",
      statusCode: 500,
      retriable: false,
      suggestion: "Verify database permissions and configuration for creating plugin resources.",
      resourceName,
      fieldName,
      original: err
    });
  }
  handler.transactionResource = ok ? transactionResource : database.resources[transactionResourceName];
  if (config.enableAnalytics) {
    await createAnalyticsResource(handler, database, resourceName, fieldName);
  }
  addHelperMethodsForHandler(handler, plugin, config);
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${resourceName}.${fieldName} - Setup complete. Resources: ${transactionResourceName}${config.enableAnalytics ? `, plg_${resourceName}_an_${fieldName}` : ""} (locks via PluginStorage TTL)`
    );
  }
}
async function createAnalyticsResource(handler, database, resourceName, fieldName) {
  const analyticsResourceName = `plg_${resourceName}_an_${fieldName}`;
  const [ok, err, analyticsResource] = await tryFn(
    () => database.createResource({
      name: analyticsResourceName,
      attributes: {
        id: "string|required",
        field: "string|required",
        period: "string|required",
        cohort: "string|required",
        transactionCount: "number|required",
        totalValue: "number|required",
        avgValue: "number|required",
        minValue: "number|required",
        maxValue: "number|required",
        operations: "object|optional",
        recordCount: "number|required",
        consolidatedAt: "string|required",
        updatedAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: false,
      asyncPartitions: true,
      //  Multi-attribute partitions for optimal analytics query performance
      partitions: {
        // Query by period (hour/day/week/month)
        byPeriod: {
          fields: { period: "string" }
        },
        // Query by period + cohort (e.g., all hour records for specific hours)
        byPeriodCohort: {
          fields: {
            period: "string",
            cohort: "string"
          }
        },
        // Query by field + period (e.g., all daily analytics for clicks field)
        byFieldPeriod: {
          fields: {
            field: "string",
            period: "string"
          }
        }
      },
      createdBy: "EventualConsistencyPlugin"
    })
  );
  if (!ok && !database.resources[analyticsResourceName]) {
    throw new PluginError(`Failed to create analytics resource for ${resourceName}.${fieldName}`, {
      pluginName: "EventualConsistencyPlugin",
      operation: "createAnalyticsResource",
      statusCode: 500,
      retriable: false,
      suggestion: "Verify database permissions and configuration for creating analytics resources.",
      resourceName,
      fieldName,
      original: err
    });
  }
  handler.analyticsResource = ok ? analyticsResource : database.resources[analyticsResourceName];
}
function addHelperMethodsForHandler(handler, plugin, config) {
  const resource = handler.targetResource;
  const fieldName = handler.field;
  if (!resource._eventualConsistencyPlugins) {
    resource._eventualConsistencyPlugins = {};
  }
  resource._eventualConsistencyPlugins[fieldName] = handler;
  if (!resource.add) {
    addHelperMethods(resource, plugin, config);
  }
}
async function onStart(fieldHandlers, config, runConsolidationFn, runGCFn, emitFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    for (const [fieldName, handler] of resourceHandlers) {
      if (!handler.deferredSetup) {
        if (config.autoConsolidate && config.mode === "async") {
          startConsolidationTimer(handler, resourceName, fieldName, runConsolidationFn, config);
        }
        if (config.transactionRetention && config.transactionRetention > 0) {
          startGarbageCollectionTimer(handler, resourceName, fieldName, runGCFn, config);
        }
        if (emitFn) {
          emitFn("plg:eventual-consistency:started", {
            resource: resourceName,
            field: fieldName,
            cohort: config.cohort
          });
        }
      }
    }
  }
}
async function onStop(fieldHandlers, emitFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    for (const [fieldName, handler] of resourceHandlers) {
      if (handler.consolidationTimer) {
        clearInterval(handler.consolidationTimer);
        handler.consolidationTimer = null;
      }
      if (handler.gcTimer) {
        clearInterval(handler.gcTimer);
        handler.gcTimer = null;
      }
      if (handler.pendingTransactions && handler.pendingTransactions.size > 0) {
        await flushPendingTransactions(handler);
      }
      if (emitFn) {
        emitFn("plg:eventual-consistency:stopped", {
          resource: resourceName,
          field: fieldName
        });
      }
    }
  }
}

class EventualConsistencyPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    validateResourcesConfig(options.resources);
    const detectedTimezone = detectTimezone();
    const timezoneAutoDetected = !options.cohort?.timezone;
    this.config = createConfig(options, detectedTimezone);
    this.fieldHandlers = /* @__PURE__ */ new Map();
    for (const [resourceName, fields] of Object.entries(options.resources)) {
      const resourceHandlers = /* @__PURE__ */ new Map();
      for (const fieldName of fields) {
        resourceHandlers.set(fieldName, createFieldHandler(resourceName, fieldName));
      }
      this.fieldHandlers.set(resourceName, resourceHandlers);
    }
    logConfigWarnings(this.config);
    logInitialization(this.config, this.fieldHandlers, timezoneAutoDetected);
  }
  /**
   * Install hook - create resources and register helpers
   */
  async onInstall() {
    await onInstall(
      this.database,
      this.fieldHandlers,
      (handler) => completeFieldSetup(handler, this.database, this.config, this),
      (resourceName) => watchForResource(
        resourceName,
        this.database,
        this.fieldHandlers,
        (handler) => completeFieldSetup(handler, this.database, this.config, this)
      )
    );
  }
  /**
   * Start hook - begin timers and emit events
   */
  async onStart() {
    await onStart(
      this.fieldHandlers,
      this.config,
      (handler, resourceName, fieldName) => this._runConsolidationForHandler(handler, resourceName, fieldName),
      (handler, resourceName, fieldName) => this._runGarbageCollectionForHandler(handler, resourceName, fieldName),
      (event, data) => this.emit(event, data)
    );
  }
  /**
   * Stop hook - stop timers and flush pending
   */
  async onStop() {
    await onStop(
      this.fieldHandlers,
      (event, data) => this.emit(event, data)
    );
  }
  /**
   * Create partition configuration
   * @returns {Object} Partition configuration
   */
  createPartitionConfig() {
    return createPartitionConfig();
  }
  /**
   * Get cohort information for a date
   * @param {Date} date - Date to get cohort info for
   * @returns {Object} Cohort information
   */
  getCohortInfo(date) {
    return getCohortInfo(date, this.config.cohort.timezone, this.config.verbose);
  }
  /**
   * Create a transaction for a field handler
   * @param {Object} handler - Field handler
   * @param {Object} data - Transaction data
   * @returns {Promise<Object|null>} Created transaction
   */
  async createTransaction(handler, data) {
    return await createTransaction(handler, data, this.config);
  }
  /**
   * Consolidate a single record (internal method)
   * This is used internally by consolidation timers and helper methods
   * @private
   */
  async consolidateRecord(originalId) {
    return await consolidateRecord(
      originalId,
      this.transactionResource,
      this.targetResource,
      this.getStorage(),
      this.analyticsResource,
      (transactions) => this.updateAnalytics(transactions),
      this.config
    );
  }
  /**
   * Get consolidated value without applying (internal method)
   * @private
   */
  async getConsolidatedValue(originalId, options = {}) {
    return await getConsolidatedValue(
      originalId,
      options,
      this.transactionResource,
      this.targetResource,
      this.config
    );
  }
  /**
   * Get cohort statistics
   * @param {string} cohortDate - Cohort date
   * @returns {Promise<Object|null>} Cohort statistics
   */
  async getCohortStats(cohortDate) {
    return await getCohortStats(cohortDate, this.transactionResource);
  }
  /**
   * Recalculate from scratch (internal method)
   * @private
   */
  async recalculateRecord(originalId) {
    return await recalculateRecord(
      originalId,
      this.transactionResource,
      this.targetResource,
      this.getStorage(),
      (id) => this.consolidateRecord(id),
      this.config
    );
  }
  /**
   * Update analytics
   * @private
   */
  async updateAnalytics(transactions) {
    return await updateAnalytics(transactions, this.analyticsResource, this.config);
  }
  /**
   * Helper method for sync mode consolidation
   * @private
   */
  async _syncModeConsolidate(handler, id, field) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.consolidateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Helper method for consolidate with handler
   * @private
   */
  async _consolidateWithHandler(handler, id) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.consolidateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Helper method for getConsolidatedValue with handler
   * @private
   */
  async _getConsolidatedValueWithHandler(handler, id, options) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    const result = await this.getConsolidatedValue(id, options);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    return result;
  }
  /**
   * Helper method for recalculate with handler
   * @private
   */
  async _recalculateWithHandler(handler, id) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.recalculateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Run consolidation for a handler
   * @private
   */
  async _runConsolidationForHandler(handler, resourceName, fieldName) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = resourceName;
    this.config.field = fieldName;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    try {
      await runConsolidation(
        this.transactionResource,
        (id) => this.consolidateRecord(id),
        (event, data) => this.emit(event, data),
        this.config
      );
    } finally {
      this.config.resource = oldResource;
      this.config.field = oldField;
      this.transactionResource = oldTransactionResource;
      this.targetResource = oldTargetResource;
      this.analyticsResource = oldAnalyticsResource;
    }
  }
  /**
   * Run garbage collection for a handler
   * @private
   */
  async _runGarbageCollectionForHandler(handler, resourceName, fieldName) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    this.config.resource = resourceName;
    this.config.field = fieldName;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    try {
      await runGarbageCollection(
        this.transactionResource,
        this.getStorage(),
        this.config,
        (event, data) => this.emit(event, data)
      );
    } finally {
      this.config.resource = oldResource;
      this.config.field = oldField;
      this.transactionResource = oldTransactionResource;
      this.targetResource = oldTargetResource;
    }
  }
  // Public Analytics API
  /**
   * Get analytics for a specific period
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @returns {Promise<Array>} Analytics data
   */
  async getAnalytics(resourceName, field, options = {}) {
    return await getAnalytics(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the month
   */
  async getMonthByDay(resourceName, field, month, options = {}) {
    return await getMonthByDay(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire day, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} date - Date in YYYY-MM-DD format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the day
   */
  async getDayByHour(resourceName, field, date, options = {}) {
    return await getDayByHour(resourceName, field, date, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N days, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} days - Number of days to look back (default: 7)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics
   */
  async getLastNDays(resourceName, field, days = 7, options = {}) {
    return await getLastNDays(resourceName, field, days, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by months
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Monthly analytics for the year
   */
  async getYearByMonth(resourceName, field, year, options = {}) {
    return await getYearByMonth(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format (or 'last' for previous month)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the month
   */
  async getMonthByHour(resourceName, field, month, options = {}) {
    return await getMonthByHour(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics for the year (up to 53 weeks)
   */
  async getYearByWeek(resourceName, field, year, options = {}) {
    return await getYearByWeek(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics for the month
   */
  async getMonthByWeek(resourceName, field, month, options = {}) {
    return await getMonthByWeek(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get top records by volume
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @returns {Promise<Array>} Top records
   */
  async getTopRecords(resourceName, field, options = {}) {
    return await getTopRecords(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the year (up to 365/366 records)
   */
  async getYearByDay(resourceName, field, year, options = {}) {
    return await getYearByDay(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire week, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} week - Week in YYYY-Www format (e.g., '2025-W42')
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the week (7 records)
   */
  async getWeekByDay(resourceName, field, week, options = {}) {
    return await getWeekByDay(resourceName, field, week, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire week, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} week - Week in YYYY-Www format (e.g., '2025-W42')
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the week (168 records)
   */
  async getWeekByHour(resourceName, field, week, options = {}) {
    return await getWeekByHour(resourceName, field, week, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} hours - Number of hours to look back (default: 24)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics
   */
  async getLastNHours(resourceName, field, hours = 24, options = {}) {
    return await getLastNHours(resourceName, field, hours, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} weeks - Number of weeks to look back (default: 4)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics
   */
  async getLastNWeeks(resourceName, field, weeks = 4, options = {}) {
    return await getLastNWeeks(resourceName, field, weeks, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N months
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} months - Number of months to look back (default: 12)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Monthly analytics
   */
  async getLastNMonths(resourceName, field, months = 12, options = {}) {
    return await getLastNMonths(resourceName, field, months, options, this.fieldHandlers);
  }
  /**
   * Get raw transaction events for custom aggregation
   *
   * This method provides direct access to the underlying transaction events,
   * allowing developers to perform custom aggregations beyond the pre-built analytics.
   * Useful for complex queries, custom metrics, or when you need the raw event data.
   *
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @param {string} options.recordId - Filter by specific record ID
   * @param {string} options.startDate - Start date filter (YYYY-MM-DD or YYYY-MM-DDTHH)
   * @param {string} options.endDate - End date filter (YYYY-MM-DD or YYYY-MM-DDTHH)
   * @param {string} options.cohortDate - Filter by cohort date (YYYY-MM-DD)
   * @param {string} options.cohortHour - Filter by cohort hour (YYYY-MM-DDTHH)
   * @param {string} options.cohortMonth - Filter by cohort month (YYYY-MM)
   * @param {boolean} options.applied - Filter by applied status (true/false/undefined for both)
   * @param {string} options.operation - Filter by operation type ('add', 'sub', 'set')
   * @param {number} options.limit - Maximum number of events to return
   * @returns {Promise<Array>} Raw transaction events
   *
   * @example
   * // Get all events for a specific record
   * const events = await plugin.getRawEvents('wallets', 'balance', {
   *   recordId: 'wallet1'
   * });
   *
   * @example
   * // Get events for a specific time range
   * const events = await plugin.getRawEvents('wallets', 'balance', {
   *   startDate: '2025-10-01',
   *   endDate: '2025-10-31'
   * });
   *
   * @example
   * // Get only pending (unapplied) transactions
   * const pending = await plugin.getRawEvents('wallets', 'balance', {
   *   applied: false
   * });
   */
  async getRawEvents(resourceName, field, options = {}) {
    return await getRawEvents(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get diagnostics information about the plugin state
   *
   * This method provides comprehensive diagnostic information about the EventualConsistencyPlugin,
   * including configured resources, field handlers, timers, and overall health status.
   * Useful for debugging initialization issues, configuration problems, or runtime errors.
   *
   * @param {Object} options - Diagnostic options
   * @param {string} options.resourceName - Optional: limit diagnostics to specific resource
   * @param {string} options.field - Optional: limit diagnostics to specific field
   * @param {boolean} options.includeStats - Include transaction statistics (default: false)
   * @returns {Promise<Object>} Diagnostic information
   *
   * @example
   * // Get overall plugin diagnostics
   * const diagnostics = await plugin.getDiagnostics();
   * console.log(diagnostics);
   *
   * @example
   * // Get diagnostics for specific resource/field with stats
   * const diagnostics = await plugin.getDiagnostics({
   *   resourceName: 'wallets',
   *   field: 'balance',
   *   includeStats: true
   * });
   */
  async getDiagnostics(options = {}) {
    const { resourceName, field, includeStats = false } = options;
    const diagnostics = {
      plugin: {
        name: "EventualConsistencyPlugin",
        initialized: this.database !== null && this.database !== void 0,
        verbose: this.config.verbose || false,
        timezone: this.config.cohort?.timezone || "UTC",
        consolidation: {
          mode: this.config.consolidation?.mode || "timer",
          interval: this.config.consolidation?.interval || 6e4,
          batchSize: this.config.consolidation?.batchSize || 100
        },
        garbageCollection: {
          enabled: this.config.garbageCollection?.enabled !== false,
          retentionDays: this.config.garbageCollection?.retentionDays || 30,
          interval: this.config.garbageCollection?.interval || 36e5
        }
      },
      resources: [],
      errors: [],
      warnings: []
    };
    for (const [resName, resourceHandlers] of this.fieldHandlers.entries()) {
      if (resourceName && resName !== resourceName) {
        continue;
      }
      const resourceDiag = {
        name: resName,
        fields: []
      };
      for (const [fieldName, handler] of resourceHandlers.entries()) {
        if (field && fieldName !== field) {
          continue;
        }
        const fieldDiag = {
          name: fieldName,
          type: handler.type || "counter",
          analyticsEnabled: handler.analyticsResource !== null && handler.analyticsResource !== void 0,
          resources: {
            transaction: handler.transactionResource?.name || null,
            target: handler.targetResource?.name || null,
            analytics: handler.analyticsResource?.name || null
          },
          timers: {
            consolidation: handler.consolidationTimer !== null && handler.consolidationTimer !== void 0,
            garbageCollection: handler.garbageCollectionTimer !== null && handler.garbageCollectionTimer !== void 0
          }
        };
        if (!handler.transactionResource) {
          diagnostics.errors.push({
            resource: resName,
            field: fieldName,
            issue: "Missing transaction resource",
            suggestion: "Ensure plugin is installed and resources are created after plugin installation"
          });
        }
        if (!handler.targetResource) {
          diagnostics.warnings.push({
            resource: resName,
            field: fieldName,
            issue: "Missing target resource",
            suggestion: "Target resource may not have been created yet"
          });
        }
        if (handler.analyticsResource && !handler.analyticsResource.name) {
          diagnostics.errors.push({
            resource: resName,
            field: fieldName,
            issue: "Invalid analytics resource",
            suggestion: "Analytics resource exists but has no name - possible initialization failure"
          });
        }
        if (includeStats && handler.transactionResource) {
          try {
            const [okPending, errPending, pendingTxns] = await handler.transactionResource.query({ applied: false }).catch(() => [false, null, []]);
            const [okApplied, errApplied, appliedTxns] = await handler.transactionResource.query({ applied: true }).catch(() => [false, null, []]);
            fieldDiag.stats = {
              pendingTransactions: okPending ? pendingTxns?.length || 0 : "error",
              appliedTransactions: okApplied ? appliedTxns?.length || 0 : "error",
              totalTransactions: okPending && okApplied ? (pendingTxns?.length || 0) + (appliedTxns?.length || 0) : "error"
            };
            if (handler.analyticsResource) {
              const [okAnalytics, errAnalytics, analyticsRecords] = await handler.analyticsResource.list().catch(() => [false, null, []]);
              fieldDiag.stats.analyticsRecords = okAnalytics ? analyticsRecords?.length || 0 : "error";
            }
          } catch (error) {
            diagnostics.warnings.push({
              resource: resName,
              field: fieldName,
              issue: "Failed to fetch statistics",
              error: error.message
            });
          }
        }
        resourceDiag.fields.push(fieldDiag);
      }
      if (resourceDiag.fields.length > 0) {
        diagnostics.resources.push(resourceDiag);
      }
    }
    diagnostics.health = {
      status: diagnostics.errors.length === 0 ? diagnostics.warnings.length === 0 ? "healthy" : "warning" : "error",
      totalResources: diagnostics.resources.length,
      totalFields: diagnostics.resources.reduce((sum, r) => sum + r.fields.length, 0),
      errorCount: diagnostics.errors.length,
      warningCount: diagnostics.warnings.length
    };
    return diagnostics;
  }
}

class FulltextError extends S3dbError {
  constructor(message, details = {}) {
    const { resourceName, query, operation = "unknown", ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Fulltext Search Operation Error

Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}
${query ? `Query: ${query}` : ""}

Common causes:
1. Resource not indexed for fulltext search
2. Invalid query syntax
3. Index not built yet
4. Search configuration missing
5. Field not indexed

Solution:
Ensure resource is configured for fulltext search and index is built.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/fulltext.md
`.trim();
    }
    super(message, { ...rest, resourceName, query, operation, description });
  }
}

class FullTextPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.indexResource = null;
    const resourceNamesOption = options.resourceNames || {};
    this._indexResourceDescriptor = {
      defaultName: "plg_fulltext_indexes",
      override: resourceNamesOption.index || options.indexResource
    };
    this.indexResourceName = this._resolveIndexResourceName();
    this.config = {
      minWordLength: options.minWordLength || 3,
      maxResults: options.maxResults || 100,
      ...options
    };
    this.indexes = /* @__PURE__ */ new Map();
    this.dirtyIndexes = /* @__PURE__ */ new Set();
    this.deletedIndexes = /* @__PURE__ */ new Set();
  }
  _resolveIndexResourceName() {
    return resolveResourceName("fulltext", this._indexResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.indexResourceName = this._resolveIndexResourceName();
  }
  async onInstall() {
    const [ok, err, indexResource] = await tryFn(() => this.database.createResource({
      name: this.indexResourceName,
      attributes: {
        id: "string|required",
        resourceName: "string|required",
        fieldName: "string|required",
        word: "string|required",
        recordIds: "json|required",
        // Array of record IDs containing this word
        count: "number|required",
        lastUpdated: "string|required"
      },
      partitions: {
        byResource: { fields: { resourceName: "string" } }
      },
      behavior: "body-overflow"
    }));
    if (ok) {
      this.indexResource = indexResource;
    } else if (this.database.resources[this.indexResourceName]) {
      this.indexResource = this.database.resources[this.indexResourceName];
    } else {
      throw err;
    }
    await this.loadIndexes();
    this.installDatabaseHooks();
    this.installIndexingHooks();
  }
  async start() {
  }
  async stop() {
    await this.saveIndexes();
    this.removeDatabaseHooks();
  }
  isInternalResource(name) {
    return name === this.indexResourceName || name === "plg_fulltext_indexes";
  }
  async loadIndexes() {
    if (!this.indexResource) return;
    const [ok, err, allIndexes] = await tryFn(() => this.indexResource.getAll());
    if (ok) {
      for (const indexRecord of allIndexes) {
        const key = `${indexRecord.resourceName}:${indexRecord.fieldName}:${indexRecord.word}`;
        this.indexes.set(key, {
          recordIds: indexRecord.recordIds || [],
          count: indexRecord.count || 0
        });
      }
    }
  }
  async saveIndexes() {
    if (!this.indexResource) return;
    const [ok, err] = await tryFn(async () => {
      for (const key of this.deletedIndexes) {
        const [resourceName] = key.split(":");
        const [queryOk, queryErr, results] = await tryFn(
          () => this.indexResource.query({ resourceName })
        );
        if (queryOk && results) {
          for (const index of results) {
            const indexKey = `${index.resourceName}:${index.fieldName}:${index.word}`;
            if (indexKey === key) {
              await this.indexResource.delete(index.id);
            }
          }
        }
      }
      for (const key of this.dirtyIndexes) {
        const [resourceName, fieldName, word] = key.split(":");
        const data = this.indexes.get(key);
        if (!data) continue;
        const [queryOk, queryErr, results] = await tryFn(
          () => this.indexResource.query({ resourceName })
        );
        let existingRecord = null;
        if (queryOk && results) {
          existingRecord = results.find(
            (index) => index.resourceName === resourceName && index.fieldName === fieldName && index.word === word
          );
        }
        if (existingRecord) {
          await this.indexResource.update(existingRecord.id, {
            recordIds: data.recordIds,
            count: data.count,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } else {
          await this.indexResource.insert({
            id: `index-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName,
            fieldName,
            word,
            recordIds: data.recordIds,
            count: data.count,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
      }
      this.dirtyIndexes.clear();
      this.deletedIndexes.clear();
    });
  }
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", (resource) => {
      if (!this.isInternalResource(resource.name)) {
        this.installResourceHooks(resource);
      }
    });
  }
  removeDatabaseHooks() {
    this.database.removeHook("afterCreateResource", this.installResourceHooks.bind(this));
  }
  installIndexingHooks() {
    if (!this.database.plugins) {
      this.database.plugins = {};
    }
    this.database.plugins.fulltext = this;
    for (const resource of Object.values(this.database.resources)) {
      if (this.isInternalResource(resource.name)) continue;
      this.installResourceHooks(resource);
    }
    if (!this.database._fulltextProxyInstalled) {
      this.database._previousCreateResourceForFullText = this.database.createResource;
      this.database.createResource = async function(...args) {
        const resource = await this._previousCreateResourceForFullText(...args);
        if (this.plugins?.fulltext && !this.plugins.fulltext.isInternalResource(resource.name)) {
          this.plugins.fulltext.installResourceHooks(resource);
        }
        return resource;
      };
      this.database._fulltextProxyInstalled = true;
    }
    for (const resource of Object.values(this.database.resources)) {
      if (!this.isInternalResource(resource.name)) {
        this.installResourceHooks(resource);
      }
    }
  }
  installResourceHooks(resource) {
    resource._insert = resource.insert;
    resource._update = resource.update;
    resource._delete = resource.delete;
    resource._deleteMany = resource.deleteMany;
    this.wrapResourceMethod(resource, "insert", async (result, args, methodName) => {
      const [data] = args;
      this.indexRecord(resource.name, result.id, data).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "update", async (result, args, methodName) => {
      const [id, data] = args;
      this.removeRecordFromIndex(resource.name, id).catch(() => {
      });
      this.indexRecord(resource.name, id, result).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "delete", async (result, args, methodName) => {
      const [id] = args;
      this.removeRecordFromIndex(resource.name, id).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "deleteMany", async (result, args, methodName) => {
      const [ids] = args;
      for (const id of ids) {
        this.removeRecordFromIndex(resource.name, id).catch(() => {
        });
      }
      return result;
    });
  }
  async indexRecord(resourceName, recordId, data) {
    const indexedFields = this.getIndexedFields(resourceName);
    if (!indexedFields || indexedFields.length === 0) {
      return;
    }
    for (const fieldName of indexedFields) {
      const fieldValue = this.getFieldValue(data, fieldName);
      if (!fieldValue) {
        continue;
      }
      const words = this.tokenize(fieldValue);
      for (const word of words) {
        if (word.length < this.config.minWordLength) {
          continue;
        }
        const key = `${resourceName}:${fieldName}:${word.toLowerCase()}`;
        const existing = this.indexes.get(key) || { recordIds: [], count: 0 };
        if (!existing.recordIds.includes(recordId)) {
          existing.recordIds.push(recordId);
          existing.count = existing.recordIds.length;
        }
        this.indexes.set(key, existing);
        this.dirtyIndexes.add(key);
      }
    }
  }
  async removeRecordFromIndex(resourceName, recordId) {
    for (const [key, data] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        const index = data.recordIds.indexOf(recordId);
        if (index > -1) {
          data.recordIds.splice(index, 1);
          data.count = data.recordIds.length;
          if (data.recordIds.length === 0) {
            this.indexes.delete(key);
            this.deletedIndexes.add(key);
          } else {
            this.indexes.set(key, data);
            this.dirtyIndexes.add(key);
          }
        }
      }
    }
  }
  getFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data && data[fieldPath] !== void 0 ? data[fieldPath] : null;
    }
    const keys = fieldPath.split(".");
    let value = data;
    for (const key of keys) {
      if (value && typeof value === "object" && key in value) {
        value = value[key];
      } else {
        return null;
      }
    }
    return value;
  }
  tokenize(text) {
    if (!text) return [];
    const str = String(text).toLowerCase();
    return str.replace(/[^\w\s\u00C0-\u017F]/g, " ").split(/\s+/).filter((word) => word.length > 0);
  }
  getIndexedFields(resourceName) {
    if (this.config.fields) {
      return this.config.fields;
    }
    const fieldMappings = {
      users: ["name", "email"],
      products: ["name", "description"],
      articles: ["title", "content"]
      // Add more mappings as needed
    };
    return fieldMappings[resourceName] || [];
  }
  // Main search method
  async search(resourceName, query, options = {}) {
    const {
      fields = null,
      // Specific fields to search in
      limit = this.config.maxResults,
      offset = 0,
      exactMatch = false
    } = options;
    if (!query || query.trim().length === 0) {
      return [];
    }
    const searchWords = this.tokenize(query);
    const results = /* @__PURE__ */ new Map();
    const searchFields = fields || this.getIndexedFields(resourceName);
    if (searchFields.length === 0) {
      return [];
    }
    for (const word of searchWords) {
      if (word.length < this.config.minWordLength) continue;
      for (const fieldName of searchFields) {
        if (exactMatch) {
          const key = `${resourceName}:${fieldName}:${word.toLowerCase()}`;
          const indexData = this.indexes.get(key);
          if (indexData) {
            for (const recordId of indexData.recordIds) {
              const currentScore = results.get(recordId) || 0;
              results.set(recordId, currentScore + 1);
            }
          }
        } else {
          for (const [key, indexData] of this.indexes.entries()) {
            if (key.startsWith(`${resourceName}:${fieldName}:${word.toLowerCase()}`)) {
              for (const recordId of indexData.recordIds) {
                const currentScore = results.get(recordId) || 0;
                results.set(recordId, currentScore + 1);
              }
            }
          }
        }
      }
    }
    const sortedResults = Array.from(results.entries()).map(([recordId, score]) => ({ recordId, score })).sort((a, b) => b.score - a.score).slice(offset, offset + limit);
    return sortedResults;
  }
  // Search and return full records
  async searchRecords(resourceName, query, options = {}) {
    const searchResults = await this.search(resourceName, query, options);
    if (searchResults.length === 0) {
      return [];
    }
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new FulltextError(`Resource '${resourceName}' not found`, {
        operation: "searchRecords",
        resourceName,
        query,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before searching"
      });
    }
    const recordIds = searchResults.map((result2) => result2.recordId);
    const records = await resource.getMany(recordIds);
    const result = records.filter((record) => record && typeof record === "object").map((record) => {
      const searchResult = searchResults.find((sr) => sr.recordId === record.id);
      return {
        ...record,
        _searchScore: searchResult ? searchResult.score : 0
      };
    }).sort((a, b) => b._searchScore - a._searchScore);
    return result;
  }
  // Utility methods
  async rebuildIndex(resourceName) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new FulltextError(`Resource '${resourceName}' not found`, {
        operation: "rebuildIndex",
        resourceName,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before rebuilding index"
      });
    }
    for (const [key] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        this.indexes.delete(key);
      }
    }
    const allRecords = await resource.getAll();
    const batchSize = 100;
    for (let i = 0; i < allRecords.length; i += batchSize) {
      const batch = allRecords.slice(i, i + batchSize);
      for (const record of batch) {
        const [ok, err] = await tryFn(() => this.indexRecord(resourceName, record.id, record));
      }
    }
    await this.saveIndexes();
  }
  async getIndexStats() {
    const stats = {
      totalIndexes: this.indexes.size,
      resources: {},
      totalWords: 0
    };
    for (const [key, data] of this.indexes.entries()) {
      const [resourceName, fieldName] = key.split(":");
      if (!stats.resources[resourceName]) {
        stats.resources[resourceName] = {
          fields: {},
          totalRecords: /* @__PURE__ */ new Set(),
          totalWords: 0
        };
      }
      if (!stats.resources[resourceName].fields[fieldName]) {
        stats.resources[resourceName].fields[fieldName] = {
          words: 0,
          totalOccurrences: 0
        };
      }
      stats.resources[resourceName].fields[fieldName].words++;
      stats.resources[resourceName].fields[fieldName].totalOccurrences += data.count;
      stats.resources[resourceName].totalWords++;
      for (const recordId of data.recordIds) {
        stats.resources[resourceName].totalRecords.add(recordId);
      }
      stats.totalWords++;
    }
    for (const resourceName in stats.resources) {
      stats.resources[resourceName].totalRecords = stats.resources[resourceName].totalRecords.size;
    }
    return stats;
  }
  async rebuildAllIndexes({ timeout } = {}) {
    if (timeout) {
      return Promise.race([
        this._rebuildAllIndexesInternal(),
        new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout")), timeout))
      ]);
    }
    return this._rebuildAllIndexesInternal();
  }
  async _rebuildAllIndexesInternal() {
    const resourceNames = Object.keys(this.database.resources).filter((name) => !this.isInternalResource(name));
    for (const resourceName of resourceNames) {
      const [ok, err] = await tryFn(() => this.rebuildIndex(resourceName));
    }
  }
  async clearIndex(resourceName) {
    for (const [key] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        this.indexes.delete(key);
      }
    }
    await this.saveIndexes();
  }
  async clearAllIndexes() {
    this.indexes.clear();
    await this.saveIndexes();
  }
}

class GeoPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.resources = config.resources || {};
    this.verbose = config.verbose !== void 0 ? config.verbose : false;
    this.base32 = "0123456789bcdefghjkmnpqrstuvwxyz";
  }
  /**
   * Install the plugin
   */
  async install(database) {
    await super.install(database);
    for (const [resourceName, config] of Object.entries(this.resources)) {
      await this._setupResource(resourceName, config);
    }
    this.database.addHook("afterCreateResource", async (context) => {
      const { resource, config: resourceConfig } = context;
      const geoConfig = this.resources[resource.name];
      if (geoConfig) {
        await this._setupResource(resource.name, geoConfig);
      }
    });
    if (this.verbose) {
      console.log(`[GeoPlugin] Installed with ${Object.keys(this.resources).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "GeoPlugin",
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Setup a resource with geo capabilities
   */
  async _setupResource(resourceName, config) {
    if (!this.database.resources[resourceName]) {
      if (this.verbose) {
        console.warn(`[GeoPlugin] Resource "${resourceName}" not found, will setup when created`);
      }
      return;
    }
    const resource = this.database.resources[resourceName];
    if (!resource || typeof resource.addHook !== "function") {
      if (this.verbose) {
        console.warn(`[GeoPlugin] Resource "${resourceName}" not found or invalid`);
      }
      return;
    }
    if (!config.latField || !config.lonField) {
      throw new PluginError(`[GeoPlugin] Resource "${resourceName}" must have "latField" and "lonField" configured`, {
        pluginName: "GeoPlugin",
        operation: "setupResource",
        resourceName,
        statusCode: 400,
        retriable: false,
        suggestion: 'Update GeoPlugin configuration with { latField: "...", lonField: "..." } for the resource.'
      });
    }
    if (!config.precision || config.precision < 1 || config.precision > 12) {
      config.precision = 5;
    }
    resource._geoConfig = config;
    const latField = resource.attributes[config.latField];
    const lonField = resource.attributes[config.lonField];
    const isLatOptional = typeof latField === "object" && latField.optional === true;
    const isLonOptional = typeof lonField === "object" && lonField.optional === true;
    const areCoordinatesOptional = isLatOptional || isLonOptional;
    const geohashType = areCoordinatesOptional ? "string|optional" : "string";
    let needsUpdate = false;
    const newAttributes = { ...resource.attributes };
    if (config.addGeohash && !newAttributes.geohash) {
      newAttributes.geohash = geohashType;
      needsUpdate = true;
    }
    if (!newAttributes._geohash) {
      newAttributes._geohash = geohashType;
      needsUpdate = true;
    }
    if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
      for (const zoom of config.zoomLevels) {
        const fieldName = `_geohash_zoom${zoom}`;
        if (!newAttributes[fieldName]) {
          newAttributes[fieldName] = geohashType;
          needsUpdate = true;
        }
      }
    }
    if (needsUpdate) {
      resource.updateAttributes(newAttributes);
      if (this.database.uploadMetadataFile) {
        await this.database.uploadMetadataFile();
      }
    }
    if (config.usePartitions) {
      await this._setupPartitions(resource, config);
    }
    this._addHooks(resource, config);
    this._addHelperMethods(resource, config);
    if (this.verbose) {
      console.log(
        `[GeoPlugin] Setup resource "${resourceName}" with precision ${config.precision} (~${this._getPrecisionDistance(config.precision)}km cells)` + (config.usePartitions ? " [Partitions enabled]" : "")
      );
    }
  }
  /**
   * Setup geohash partitions for efficient spatial queries
   * Creates multiple zoom-level partitions if zoomLevels configured
   */
  async _setupPartitions(resource, config) {
    const updatedConfig = { ...resource.config };
    updatedConfig.partitions = updatedConfig.partitions || {};
    let partitionsCreated = 0;
    if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
      for (const zoom of config.zoomLevels) {
        const partitionName = `byGeohashZoom${zoom}`;
        const fieldName = `_geohash_zoom${zoom}`;
        if (!updatedConfig.partitions[partitionName]) {
          updatedConfig.partitions[partitionName] = {
            fields: {
              [fieldName]: "string"
            }
          };
          partitionsCreated++;
          if (this.verbose) {
            console.log(
              `[GeoPlugin] Created ${partitionName} partition for "${resource.name}" (precision ${zoom}, ~${this._getPrecisionDistance(zoom)}km cells)`
            );
          }
        }
      }
    } else {
      const hasGeohashPartition = resource.config.partitions && resource.config.partitions.byGeohash;
      if (!hasGeohashPartition) {
        updatedConfig.partitions.byGeohash = {
          fields: {
            _geohash: "string"
          }
        };
        partitionsCreated++;
        if (this.verbose) {
          console.log(`[GeoPlugin] Created byGeohash partition for "${resource.name}"`);
        }
      }
    }
    if (partitionsCreated > 0) {
      resource.config = updatedConfig;
      resource.setupPartitionHooks();
      if (this.database.uploadMetadataFile) {
        await this.database.uploadMetadataFile();
      }
    }
  }
  /**
   * Add hooks to automatically calculate geohash at all zoom levels
   */
  _addHooks(resource, config) {
    const calculateGeohash = async (data) => {
      const lat = data[config.latField];
      const lon = data[config.lonField];
      if (lat !== void 0 && lon !== void 0) {
        const geohash = this.encodeGeohash(lat, lon, config.precision);
        if (config.addGeohash) {
          data.geohash = geohash;
        }
        data._geohash = geohash;
        if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
          for (const zoom of config.zoomLevels) {
            const zoomGeohash = this.encodeGeohash(lat, lon, zoom);
            data[`_geohash_zoom${zoom}`] = zoomGeohash;
          }
        }
      }
      return data;
    };
    resource.addHook("beforeInsert", calculateGeohash);
    resource.addHook("beforeUpdate", calculateGeohash);
  }
  /**
   * Add helper methods to resource
   */
  _addHelperMethods(resource, config) {
    const plugin = this;
    resource.findNearby = async function({ lat, lon, radius = 10, limit = 100 }) {
      if (lat === void 0 || lon === void 0) {
        throw new PluginError("Latitude and longitude are required for findNearby()", {
          pluginName: "GeoPlugin",
          operation: "findNearby",
          resourceName: resource.name,
          statusCode: 400,
          retriable: false,
          suggestion: "Call findNearby({ lat, lon, radius }) with both coordinates."
        });
      }
      const longitude = lon;
      let allRecords = [];
      if (config.usePartitions) {
        let partitionName, fieldName, precision;
        if (config.zoomLevels && config.zoomLevels.length > 0) {
          const optimalZoom = plugin._selectOptimalZoom(config.zoomLevels, radius);
          partitionName = `byGeohashZoom${optimalZoom}`;
          fieldName = `_geohash_zoom${optimalZoom}`;
          precision = optimalZoom;
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] Auto-selected zoom${optimalZoom} (${plugin._getPrecisionDistance(optimalZoom)}km cells) for ${radius}km radius query`
            );
          }
        } else {
          partitionName = "byGeohash";
          fieldName = "_geohash";
          precision = config.precision;
        }
        if (this.config.partitions?.[partitionName]) {
          const centerGeohash = plugin.encodeGeohash(lat, longitude, precision);
          const neighbors = plugin.getNeighbors(centerGeohash);
          const geohashesToSearch = [centerGeohash, ...neighbors];
          const partitionResults = await Promise.all(
            geohashesToSearch.map(async (geohash) => {
              const [ok, err, records] = await tryFn(async () => {
                return await this.listPartition({
                  partition: partitionName,
                  partitionValues: { [fieldName]: geohash },
                  limit: limit * 2
                });
              });
              return ok ? records : [];
            })
          );
          allRecords = partitionResults.flat();
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] findNearby searched ${geohashesToSearch.length} ${partitionName} partitions, found ${allRecords.length} candidates`
            );
          }
        } else {
          allRecords = await this.list({ limit: limit * 10 });
        }
      } else {
        allRecords = await this.list({ limit: limit * 10 });
      }
      const withDistances = allRecords.map((record) => {
        const recordLat = record[config.latField];
        const recordLon = record[config.lonField];
        if (recordLat === void 0 || recordLon === void 0) {
          return null;
        }
        const distance = plugin.calculateDistance(lat, longitude, recordLat, recordLon);
        return {
          ...record,
          _distance: distance
        };
      }).filter((record) => record !== null && record._distance <= radius).sort((a, b) => a._distance - b._distance).slice(0, limit);
      return withDistances;
    };
    resource.findInBounds = async function({ north, south, east, west, limit = 100 }) {
      if (north === void 0 || south === void 0 || east === void 0 || west === void 0) {
        throw new PluginError("Bounding box requires north, south, east, west coordinates", {
          pluginName: "GeoPlugin",
          operation: "findInBounds",
          resourceName: resource.name,
          statusCode: 400,
          retriable: false,
          suggestion: "Call findInBounds({ north, south, east, west }) with all four boundaries."
        });
      }
      let allRecords = [];
      if (config.usePartitions) {
        let partitionName, precision;
        if (config.zoomLevels && config.zoomLevels.length > 0) {
          const centerLat = (north + south) / 2;
          const centerLon = (east + west) / 2;
          const latRadius = plugin.calculateDistance(centerLat, centerLon, north, centerLon);
          const lonRadius = plugin.calculateDistance(centerLat, centerLon, centerLat, east);
          const approximateRadius = Math.max(latRadius, lonRadius);
          const optimalZoom = plugin._selectOptimalZoom(config.zoomLevels, approximateRadius);
          partitionName = `byGeohashZoom${optimalZoom}`;
          precision = optimalZoom;
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] Auto-selected zoom${optimalZoom} (${plugin._getPrecisionDistance(optimalZoom)}km cells) for ${approximateRadius.toFixed(1)}km bounding box`
            );
          }
        } else {
          partitionName = "byGeohash";
          precision = config.precision;
        }
        if (this.config.partitions?.[partitionName]) {
          const geohashesToSearch = plugin._getGeohashesInBounds({
            north,
            south,
            east,
            west,
            precision
          });
          const partitionResults = await Promise.all(
            geohashesToSearch.map(async (geohash) => {
              const [ok, err, records] = await tryFn(async () => {
                const fieldName = config.zoomLevels ? `_geohash_zoom${precision}` : "_geohash";
                return await this.listPartition({
                  partition: partitionName,
                  partitionValues: { [fieldName]: geohash },
                  limit: limit * 2
                });
              });
              return ok ? records : [];
            })
          );
          allRecords = partitionResults.flat();
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] findInBounds searched ${geohashesToSearch.length} ${partitionName} partitions, found ${allRecords.length} candidates`
            );
          }
        } else {
          allRecords = await this.list({ limit: limit * 10 });
        }
      } else {
        allRecords = await this.list({ limit: limit * 10 });
      }
      const inBounds = allRecords.filter((record) => {
        const lat = record[config.latField];
        const lon = record[config.lonField];
        if (lat === void 0 || lon === void 0) {
          return false;
        }
        return lat <= north && lat >= south && lon <= east && lon >= west;
      }).slice(0, limit);
      return inBounds;
    };
    resource.getDistance = async function(id1, id2) {
      let record1, record2;
      try {
        [record1, record2] = await Promise.all([
          this.get(id1),
          this.get(id2)
        ]);
      } catch (err) {
        if (err.name === "NoSuchKey" || err.message?.includes("No such key")) {
          throw new PluginError("One or both records not found for distance calculation", {
            pluginName: "GeoPlugin",
            operation: "getDistance",
            resourceName: resource.name,
            statusCode: 404,
            retriable: false,
            suggestion: "Ensure both record IDs exist before calling getDistance().",
            ids: [id1, id2],
            original: err
          });
        }
        throw err;
      }
      if (!record1 || !record2) {
        throw new PluginError("One or both records not found for distance calculation", {
          pluginName: "GeoPlugin",
          operation: "getDistance",
          resourceName: resource.name,
          statusCode: 404,
          retriable: false,
          suggestion: "Ensure both record IDs exist before calling getDistance().",
          ids: [id1, id2]
        });
      }
      const lat1 = record1[config.latField];
      const lon1 = record1[config.lonField];
      const lat2 = record2[config.latField];
      const lon2 = record2[config.lonField];
      if (lat1 === void 0 || lon1 === void 0 || lat2 === void 0 || lon2 === void 0) {
        throw new PluginError("One or both records are missing coordinates", {
          pluginName: "GeoPlugin",
          operation: "getDistance",
          resourceName: resource.name,
          statusCode: 422,
          retriable: false,
          suggestion: `Check that both records contain ${config.latField} and ${config.lonField} before using geospatial helpers.`,
          ids: [id1, id2]
        });
      }
      const distance = plugin.calculateDistance(lat1, lon1, lat2, lon2);
      return {
        distance,
        unit: "km",
        from: id1,
        to: id2
      };
    };
  }
  /**
   * Encode coordinates to geohash
   * @param {number} latitude - Latitude (-90 to 90)
   * @param {number} longitude - Longitude (-180 to 180)
   * @param {number} precision - Number of characters in geohash
   * @returns {string} Geohash string
   */
  encodeGeohash(latitude, longitude, precision = 5) {
    let idx = 0;
    let bit = 0;
    let evenBit = true;
    let geohash = "";
    let latMin = -90;
    let latMax = 90;
    let lonMin = -180;
    let lonMax = 180;
    while (geohash.length < precision) {
      if (evenBit) {
        const lonMid = (lonMin + lonMax) / 2;
        if (longitude > lonMid) {
          idx |= 1 << 4 - bit;
          lonMin = lonMid;
        } else {
          lonMax = lonMid;
        }
      } else {
        const latMid = (latMin + latMax) / 2;
        if (latitude > latMid) {
          idx |= 1 << 4 - bit;
          latMin = latMid;
        } else {
          latMax = latMid;
        }
      }
      evenBit = !evenBit;
      if (bit < 4) {
        bit++;
      } else {
        geohash += this.base32[idx];
        bit = 0;
        idx = 0;
      }
    }
    return geohash;
  }
  /**
   * Decode geohash to coordinates
   * @param {string} geohash - Geohash string
   * @returns {Object} { latitude, longitude, error }
   */
  decodeGeohash(geohash) {
    let evenBit = true;
    let latMin = -90;
    let latMax = 90;
    let lonMin = -180;
    let lonMax = 180;
    for (let i = 0; i < geohash.length; i++) {
      const chr = geohash[i];
      const idx = this.base32.indexOf(chr);
      if (idx === -1) {
        throw new PluginError(`Invalid geohash character: ${chr}`, {
          pluginName: "GeoPlugin",
          operation: "decodeGeohash",
          statusCode: 400,
          retriable: false,
          suggestion: "Ensure geohash strings use the base32 alphabet 0123456789bcdefghjkmnpqrstuvwxyz.",
          geohash
        });
      }
      for (let n = 4; n >= 0; n--) {
        const bitN = idx >> n & 1;
        if (evenBit) {
          const lonMid = (lonMin + lonMax) / 2;
          if (bitN === 1) {
            lonMin = lonMid;
          } else {
            lonMax = lonMid;
          }
        } else {
          const latMid = (latMin + latMax) / 2;
          if (bitN === 1) {
            latMin = latMid;
          } else {
            latMax = latMid;
          }
        }
        evenBit = !evenBit;
      }
    }
    const latitude = (latMin + latMax) / 2;
    const longitude = (lonMin + lonMax) / 2;
    return {
      latitude,
      longitude,
      error: {
        latitude: latMax - latMin,
        longitude: lonMax - lonMin
      }
    };
  }
  /**
   * Calculate distance between two coordinates using Haversine formula
   * @param {number} lat1 - Latitude of point 1
   * @param {number} lon1 - Longitude of point 1
   * @param {number} lat2 - Latitude of point 2
   * @param {number} lon2 - Longitude of point 2
   * @returns {number} Distance in kilometers
   */
  calculateDistance(lat1, lon1, lat2, lon2) {
    const R = 6371;
    const dLat = this._toRadians(lat2 - lat1);
    const dLon = this._toRadians(lon2 - lon1);
    const a = Math.sin(dLat / 2) * Math.sin(dLat / 2) + Math.cos(this._toRadians(lat1)) * Math.cos(this._toRadians(lat2)) * Math.sin(dLon / 2) * Math.sin(dLon / 2);
    const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
    return R * c;
  }
  /**
   * Get geohash neighbors (8 surrounding cells)
   * @param {string} geohash - Center geohash
   * @returns {Array<string>} Array of 8 neighboring geohashes
   */
  getNeighbors(geohash) {
    const decoded = this.decodeGeohash(geohash);
    const { latitude, longitude, error } = decoded;
    const latStep = error.latitude;
    const lonStep = error.longitude;
    const neighbors = [];
    const directions = [
      [-latStep, -lonStep],
      // SW
      [-latStep, 0],
      // S
      [-latStep, lonStep],
      // SE
      [0, -lonStep],
      // W
      [0, lonStep],
      // E
      [latStep, -lonStep],
      // NW
      [latStep, 0],
      // N
      [latStep, lonStep]
      // NE
    ];
    for (const [latDelta, lonDelta] of directions) {
      const neighborHash = this.encodeGeohash(
        latitude + latDelta,
        longitude + lonDelta,
        geohash.length
      );
      neighbors.push(neighborHash);
    }
    return neighbors;
  }
  /**
   * Get all geohashes that cover a bounding box
   * @param {Object} bounds - Bounding box { north, south, east, west, precision }
   * @returns {Array<string>} Array of unique geohashes covering the area
   */
  _getGeohashesInBounds({ north, south, east, west, precision }) {
    const geohashes = /* @__PURE__ */ new Set();
    const cellSize = this._getPrecisionDistance(precision);
    const latStep = cellSize / 111;
    const lonStep = cellSize / (111 * Math.cos(this._toRadians((north + south) / 2)));
    for (let lat = south; lat <= north; lat += latStep) {
      for (let lon = west; lon <= east; lon += lonStep) {
        const geohash = this.encodeGeohash(lat, lon, precision);
        geohashes.add(geohash);
      }
    }
    const corners = [
      [north, west],
      [north, east],
      [south, west],
      [south, east],
      [(north + south) / 2, west],
      [(north + south) / 2, east],
      [north, (east + west) / 2],
      [south, (east + west) / 2]
    ];
    for (const [lat, lon] of corners) {
      const geohash = this.encodeGeohash(lat, lon, precision);
      geohashes.add(geohash);
    }
    return Array.from(geohashes);
  }
  /**
   * Convert degrees to radians
   */
  _toRadians(degrees) {
    return degrees * (Math.PI / 180);
  }
  /**
   * Get approximate cell size for precision level
   */
  _getPrecisionDistance(precision) {
    const distances = {
      1: 5e3,
      2: 1250,
      3: 156,
      4: 39,
      5: 4.9,
      6: 1.2,
      7: 0.15,
      8: 0.038,
      9: 47e-4,
      10: 12e-4,
      11: 15e-5,
      12: 37e-6
    };
    return distances[precision] || 5;
  }
  /**
   * Select optimal zoom level based on search radius
   * @param {Array<number>} zoomLevels - Available zoom levels
   * @param {number} radiusKm - Search radius in kilometers
   * @returns {number} Optimal zoom precision
   */
  _selectOptimalZoom(zoomLevels, radiusKm) {
    if (!zoomLevels || zoomLevels.length === 0) {
      return null;
    }
    const targetCellSize = radiusKm / 2.5;
    let bestZoom = zoomLevels[0];
    let bestDiff = Math.abs(this._getPrecisionDistance(bestZoom) - targetCellSize);
    for (const zoom of zoomLevels) {
      const cellSize = this._getPrecisionDistance(zoom);
      const diff = Math.abs(cellSize - targetCellSize);
      if (diff < bestDiff) {
        bestDiff = diff;
        bestZoom = zoom;
      }
    }
    return bestZoom;
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      resources: Object.keys(this.resources).length,
      configurations: Object.entries(this.resources).map(([name, config]) => ({
        resource: name,
        latField: config.latField,
        lonField: config.lonField,
        precision: config.precision,
        cellSize: `~${this._getPrecisionDistance(config.precision)}km`
      }))
    };
  }
  /**
   * Uninstall the plugin
   */
  async uninstall() {
    if (this.verbose) {
      console.log("[GeoPlugin] Uninstalled");
    }
    this.emit("db:plugin:uninstalled", {
      plugin: "GeoPlugin"
    });
    await super.uninstall();
  }
}

class MetricsPlugin extends Plugin {
  constructor(options = {}) {
    super();
    const resourceNamesOption = options.resourceNames || {};
    const legacyResourceOption = options.resources || {};
    const resourceOverrides = {
      metrics: resourceNamesOption.metrics ?? legacyResourceOption.metrics,
      errors: resourceNamesOption.errors ?? legacyResourceOption.errors,
      performance: resourceNamesOption.performance ?? legacyResourceOption.performance
    };
    this._resourceDescriptors = {
      metrics: {
        defaultName: "plg_metrics",
        override: resourceOverrides.metrics
      },
      errors: {
        defaultName: "plg_metrics_errors",
        override: resourceOverrides.errors
      },
      performance: {
        defaultName: "plg_metrics_performance",
        override: resourceOverrides.performance
      }
    };
    this.resourceNames = this._resolveResourceNames();
    this.config = {
      collectPerformance: options.collectPerformance !== false,
      collectErrors: options.collectErrors !== false,
      collectUsage: options.collectUsage !== false,
      retentionDays: options.retentionDays || 30,
      flushInterval: options.flushInterval || 6e4,
      // 1 minute
      // Prometheus configuration
      prometheus: {
        enabled: options.prometheus?.enabled !== false,
        // Enabled by default
        mode: options.prometheus?.mode || "auto",
        // 'auto' | 'integrated' | 'standalone'
        port: options.prometheus?.port || 9090,
        // Standalone server port
        path: options.prometheus?.path || "/metrics",
        // Metrics endpoint path
        includeResourceLabels: options.prometheus?.includeResourceLabels !== false
      },
      ...options
    };
    this.metrics = {
      operations: {
        insert: { count: 0, totalTime: 0, errors: 0 },
        update: { count: 0, totalTime: 0, errors: 0 },
        delete: { count: 0, totalTime: 0, errors: 0 },
        get: { count: 0, totalTime: 0, errors: 0 },
        list: { count: 0, totalTime: 0, errors: 0 },
        count: { count: 0, totalTime: 0, errors: 0 }
      },
      resources: {},
      errors: [],
      performance: [],
      startTime: (/* @__PURE__ */ new Date()).toISOString()
    };
    this.flushTimer = null;
    this.metricsServer = null;
  }
  _resolveResourceNames() {
    return resolveResourceNames("metrics", this._resourceDescriptors, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.resourceNames = this._resolveResourceNames();
  }
  async onInstall() {
    if (typeof process !== "undefined" && process.env.NODE_ENV === "test") return;
    const [ok, err] = await tryFn(async () => {
      const [ok1, err1, metricsResource] = await tryFn(() => this.database.createResource({
        name: this.resourceNames.metrics,
        attributes: {
          id: "string|required",
          type: "string|required",
          // 'operation', 'error', 'performance'
          resourceName: "string",
          operation: "string",
          count: "number|required",
          totalTime: "number|required",
          errors: "number|required",
          avgTime: "number|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.metricsResource = ok1 ? metricsResource : this.database.resources[this.resourceNames.metrics];
      const [ok2, err2, errorsResource] = await tryFn(() => this.database.createResource({
        name: this.resourceNames.errors,
        attributes: {
          id: "string|required",
          resourceName: "string|required",
          operation: "string|required",
          error: "string|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.errorsResource = ok2 ? errorsResource : this.database.resources[this.resourceNames.errors];
      const [ok3, err3, performanceResource] = await tryFn(() => this.database.createResource({
        name: this.resourceNames.performance,
        attributes: {
          id: "string|required",
          resourceName: "string|required",
          operation: "string|required",
          duration: "number|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.performanceResource = ok3 ? performanceResource : this.database.resources[this.resourceNames.performance];
    });
    if (!ok) {
      this.metricsResource = this.database.resources[this.resourceNames.metrics];
      this.errorsResource = this.database.resources[this.resourceNames.errors];
      this.performanceResource = this.database.resources[this.resourceNames.performance];
    }
    this.installDatabaseHooks();
    this.installMetricsHooks();
    if (typeof process !== "undefined" && process.env.NODE_ENV !== "test") {
      this.startFlushTimer();
    }
  }
  async start() {
    await this._setupPrometheusExporter();
  }
  async stop() {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
      this.flushTimer = null;
    }
    if (this.metricsServer) {
      await new Promise((resolve) => {
        this.metricsServer.close(() => {
          console.log("[Metrics Plugin] Standalone metrics server stopped");
          this.metricsServer = null;
          resolve();
        });
      });
    }
    this.removeDatabaseHooks();
  }
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", (resource) => {
      if (!this.isInternalResource(resource.name)) {
        this.installResourceHooks(resource);
      }
    });
  }
  removeDatabaseHooks() {
    this.database.removeHook("afterCreateResource", this.installResourceHooks.bind(this));
  }
  isInternalResource(resourceName) {
    return Object.values(this.resourceNames).includes(resourceName);
  }
  installMetricsHooks() {
    for (const resource of Object.values(this.database.resources)) {
      if (this.isInternalResource(resource.name)) {
        continue;
      }
      this.installResourceHooks(resource);
    }
    this.database._createResource = this.database.createResource;
    this.database.createResource = async function(...args) {
      const resource = await this._createResource(...args);
      if (this.plugins?.metrics && !this.plugins.metrics.isInternalResource(resource.name)) {
        this.plugins.metrics.installResourceHooks(resource);
      }
      return resource;
    };
  }
  installResourceHooks(resource) {
    resource._insert = resource.insert;
    resource._update = resource.update;
    resource._delete = resource.delete;
    resource._deleteMany = resource.deleteMany;
    resource._get = resource.get;
    resource._getMany = resource.getMany;
    resource._getAll = resource.getAll;
    resource._list = resource.list;
    resource._listIds = resource.listIds;
    resource._count = resource.count;
    resource._page = resource.page;
    resource.insert = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._insert(...args));
      this.recordOperation(resource.name, "insert", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "insert", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.update = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._update(...args));
      this.recordOperation(resource.name, "update", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "update", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.delete = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._delete(...args));
      this.recordOperation(resource.name, "delete", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "delete", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.deleteMany = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._deleteMany(...args));
      this.recordOperation(resource.name, "delete", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "delete", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.get = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._get(...args));
      this.recordOperation(resource.name, "get", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "get", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.getMany = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._getMany(...args));
      this.recordOperation(resource.name, "get", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "get", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.getAll = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._getAll(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.list = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._list(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.listIds = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._listIds(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.count = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._count(...args));
      this.recordOperation(resource.name, "count", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "count", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.page = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._page(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
  }
  recordOperation(resourceName, operation, duration, isError) {
    if (this.metrics.operations[operation]) {
      this.metrics.operations[operation].count++;
      this.metrics.operations[operation].totalTime += duration;
      if (isError) {
        this.metrics.operations[operation].errors++;
      }
    }
    if (!this.metrics.resources[resourceName]) {
      this.metrics.resources[resourceName] = {
        insert: { count: 0, totalTime: 0, errors: 0 },
        update: { count: 0, totalTime: 0, errors: 0 },
        delete: { count: 0, totalTime: 0, errors: 0 },
        get: { count: 0, totalTime: 0, errors: 0 },
        list: { count: 0, totalTime: 0, errors: 0 },
        count: { count: 0, totalTime: 0, errors: 0 }
      };
    }
    if (this.metrics.resources[resourceName][operation]) {
      this.metrics.resources[resourceName][operation].count++;
      this.metrics.resources[resourceName][operation].totalTime += duration;
      if (isError) {
        this.metrics.resources[resourceName][operation].errors++;
      }
    }
    if (this.config.collectPerformance) {
      this.metrics.performance.push({
        resourceName,
        operation,
        duration,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
  }
  recordError(resourceName, operation, error) {
    if (!this.config.collectErrors) return;
    this.metrics.errors.push({
      resourceName,
      operation,
      error: error.message,
      stack: error.stack,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  }
  startFlushTimer() {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
    }
    if (this.config.flushInterval > 0) {
      this.flushTimer = setInterval(() => {
        this.flushMetrics().catch(() => {
        });
      }, this.config.flushInterval);
    }
  }
  async flushMetrics() {
    if (!this.metricsResource) return;
    const [ok, err] = await tryFn(async () => {
      let metadata, perfMetadata, errorMetadata, resourceMetadata;
      if (typeof process !== "undefined" && process.env.NODE_ENV === "test") {
        metadata = {};
        perfMetadata = {};
        errorMetadata = {};
        resourceMetadata = {};
      } else {
        metadata = { global: "true" };
        perfMetadata = { perf: "true" };
        errorMetadata = { error: "true" };
        resourceMetadata = { resource: "true" };
      }
      const now = /* @__PURE__ */ new Date();
      const createdAt = now.toISOString().slice(0, 10);
      for (const [operation, data] of Object.entries(this.metrics.operations)) {
        if (data.count > 0) {
          await this.metricsResource.insert({
            id: `metrics-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            type: "operation",
            resourceName: "global",
            operation,
            count: data.count,
            totalTime: data.totalTime,
            errors: data.errors,
            avgTime: data.count > 0 ? data.totalTime / data.count : 0,
            timestamp: now.toISOString(),
            createdAt,
            metadata
          });
        }
      }
      for (const [resourceName, operations] of Object.entries(this.metrics.resources)) {
        for (const [operation, data] of Object.entries(operations)) {
          if (data.count > 0) {
            await this.metricsResource.insert({
              id: `metrics-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
              type: "operation",
              resourceName,
              operation,
              count: data.count,
              totalTime: data.totalTime,
              errors: data.errors,
              avgTime: data.count > 0 ? data.totalTime / data.count : 0,
              timestamp: now.toISOString(),
              createdAt,
              metadata: resourceMetadata
            });
          }
        }
      }
      if (this.config.collectPerformance && this.metrics.performance.length > 0) {
        for (const perf of this.metrics.performance) {
          await this.performanceResource.insert({
            id: `perf-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName: perf.resourceName,
            operation: perf.operation,
            duration: perf.duration,
            timestamp: perf.timestamp,
            createdAt: perf.timestamp.slice(0, 10),
            // YYYY-MM-DD from timestamp
            metadata: perfMetadata
          });
        }
      }
      if (this.config.collectErrors && this.metrics.errors.length > 0) {
        for (const error of this.metrics.errors) {
          await this.errorsResource.insert({
            id: `error-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName: error.resourceName,
            operation: error.operation,
            error: error.error,
            stack: error.stack,
            timestamp: error.timestamp,
            createdAt: error.timestamp.slice(0, 10),
            // YYYY-MM-DD from timestamp
            metadata: errorMetadata
          });
        }
      }
      this.resetMetrics();
    });
  }
  resetMetrics() {
    for (const operation of Object.keys(this.metrics.operations)) {
      this.metrics.operations[operation] = { count: 0, totalTime: 0, errors: 0 };
    }
    for (const resourceName of Object.keys(this.metrics.resources)) {
      for (const operation of Object.keys(this.metrics.resources[resourceName])) {
        this.metrics.resources[resourceName][operation] = { count: 0, totalTime: 0, errors: 0 };
      }
    }
    this.metrics.performance = [];
    this.metrics.errors = [];
  }
  // Utility methods
  async getMetrics(options = {}) {
    const {
      type = "operation",
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    if (!this.metricsResource) return [];
    const allMetrics = await this.metricsResource.getAll();
    let filtered = allMetrics.filter((metric) => {
      if (type && metric.type !== type) return false;
      if (resourceName && metric.resourceName !== resourceName) return false;
      if (operation && metric.operation !== operation) return false;
      if (startDate && new Date(metric.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(metric.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getErrorLogs(options = {}) {
    if (!this.errorsResource) return [];
    const {
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    const allErrors = await this.errorsResource.getAll();
    let filtered = allErrors.filter((error) => {
      if (resourceName && error.resourceName !== resourceName) return false;
      if (operation && error.operation !== operation) return false;
      if (startDate && new Date(error.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(error.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getPerformanceLogs(options = {}) {
    if (!this.performanceResource) return [];
    const {
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    const allPerformance = await this.performanceResource.getAll();
    let filtered = allPerformance.filter((perf) => {
      if (resourceName && perf.resourceName !== resourceName) return false;
      if (operation && perf.operation !== operation) return false;
      if (startDate && new Date(perf.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(perf.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getStats() {
    const now = /* @__PURE__ */ new Date();
    const startDate = new Date(now.getTime() - 24 * 60 * 60 * 1e3);
    const [metrics, errors, performance] = await Promise.all([
      this.getMetrics({ startDate: startDate.toISOString() }),
      this.getErrorLogs({ startDate: startDate.toISOString() }),
      this.getPerformanceLogs({ startDate: startDate.toISOString() })
    ]);
    const stats = {
      period: "24h",
      totalOperations: 0,
      totalErrors: errors.length,
      avgResponseTime: 0,
      operationsByType: {},
      resources: {},
      uptime: {
        startTime: this.metrics.startTime,
        duration: now.getTime() - new Date(this.metrics.startTime).getTime()
      }
    };
    for (const metric of metrics) {
      if (metric.type === "operation") {
        stats.totalOperations += metric.count;
        if (!stats.operationsByType[metric.operation]) {
          stats.operationsByType[metric.operation] = {
            count: 0,
            errors: 0,
            avgTime: 0
          };
        }
        stats.operationsByType[metric.operation].count += metric.count;
        stats.operationsByType[metric.operation].errors += metric.errors;
        const current = stats.operationsByType[metric.operation];
        const totalCount2 = current.count;
        const newAvg = (current.avgTime * (totalCount2 - metric.count) + metric.totalTime) / totalCount2;
        current.avgTime = newAvg;
      }
    }
    const totalTime = metrics.reduce((sum, m) => sum + m.totalTime, 0);
    const totalCount = metrics.reduce((sum, m) => sum + m.count, 0);
    stats.avgResponseTime = totalCount > 0 ? totalTime / totalCount : 0;
    return stats;
  }
  async cleanupOldData() {
    const cutoffDate = /* @__PURE__ */ new Date();
    cutoffDate.setDate(cutoffDate.getDate() - this.config.retentionDays);
    cutoffDate.toISOString().slice(0, 10);
    const datesToDelete = [];
    const startDate = new Date(cutoffDate);
    startDate.setDate(startDate.getDate() - 365);
    for (let d = new Date(startDate); d < cutoffDate; d.setDate(d.getDate() + 1)) {
      datesToDelete.push(d.toISOString().slice(0, 10));
    }
    if (this.metricsResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldMetrics] = await tryFn(
          () => this.metricsResource.query({ createdAt: dateStr })
        );
        if (ok && oldMetrics) {
          for (const metric of oldMetrics) {
            await tryFn(() => this.metricsResource.delete(metric.id));
          }
        }
      }
    }
    if (this.errorsResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldErrors] = await tryFn(
          () => this.errorsResource.query({ createdAt: dateStr })
        );
        if (ok && oldErrors) {
          for (const error of oldErrors) {
            await tryFn(() => this.errorsResource.delete(error.id));
          }
        }
      }
    }
    if (this.performanceResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldPerformance] = await tryFn(
          () => this.performanceResource.query({ createdAt: dateStr })
        );
        if (ok && oldPerformance) {
          for (const perf of oldPerformance) {
            await tryFn(() => this.performanceResource.delete(perf.id));
          }
        }
      }
    }
  }
  /**
   * Get metrics in Prometheus format
   * @returns {Promise<string>} Prometheus metrics text
   */
  async getPrometheusMetrics() {
    const { formatPrometheusMetrics } = await Promise.resolve().then(function () { return prometheusFormatter; });
    return formatPrometheusMetrics(this);
  }
  /**
   * Setup Prometheus metrics exporter
   * Chooses mode based on configuration and API Plugin availability
   * @private
   */
  async _setupPrometheusExporter() {
    if (!this.config.prometheus.enabled) {
      return;
    }
    const mode = this.config.prometheus.mode;
    const apiPlugin = this.database.plugins?.api || this.database.plugins?.ApiPlugin;
    if (mode === "auto") {
      if (apiPlugin && apiPlugin.server) {
        await this._setupIntegratedMetrics(apiPlugin);
      } else {
        await this._setupStandaloneMetrics();
      }
    } else if (mode === "integrated") {
      if (!apiPlugin || !apiPlugin.server) {
        throw new PluginError("[Metrics Plugin] prometheus.mode=integrated requires API Plugin to be active", {
          pluginName: "MetricsPlugin",
          operation: "_setupPrometheusExporter",
          statusCode: 400,
          retriable: false,
          suggestion: 'Install and start the API plugin or switch prometheus.mode to "standalone" or "auto".'
        });
      }
      await this._setupIntegratedMetrics(apiPlugin);
    } else if (mode === "standalone") {
      await this._setupStandaloneMetrics();
    } else {
      console.warn(
        `[Metrics Plugin] Unknown prometheus.mode="${mode}". Valid modes: auto, integrated, standalone`
      );
    }
  }
  /**
   * Setup integrated metrics (uses API Plugin's server)
   * @param {ApiPlugin} apiPlugin - API Plugin instance
   * @private
   */
  async _setupIntegratedMetrics(apiPlugin) {
    const app = apiPlugin.getApp();
    const path = this.config.prometheus.path;
    if (!app) {
      console.error("[Metrics Plugin] Failed to get Hono app from API Plugin");
      return;
    }
    app.get(path, async (c) => {
      try {
        const metrics = await this.getPrometheusMetrics();
        return c.text(metrics, 200, {
          "Content-Type": "text/plain; version=0.0.4; charset=utf-8"
        });
      } catch (err) {
        console.error("[Metrics Plugin] Error generating Prometheus metrics:", err);
        return c.text("Internal Server Error", 500);
      }
    });
    const port = apiPlugin.config?.port || 3e3;
    console.log(
      `[Metrics Plugin] Prometheus metrics available at http://localhost:${port}${path} (integrated mode)`
    );
  }
  /**
   * Setup standalone metrics server (separate HTTP server)
   * @private
   */
  async _setupStandaloneMetrics() {
    const { createServer } = await import('http');
    const port = this.config.prometheus.port;
    const path = this.config.prometheus.path;
    this.metricsServer = createServer(async (req, res) => {
      res.setHeader("Access-Control-Allow-Origin", "*");
      res.setHeader("Access-Control-Allow-Methods", "GET");
      res.setHeader("Access-Control-Allow-Headers", "Content-Type");
      if (req.url === path && req.method === "GET") {
        try {
          const metrics = await this.getPrometheusMetrics();
          res.writeHead(200, {
            "Content-Type": "text/plain; version=0.0.4; charset=utf-8",
            "Content-Length": Buffer.byteLength(metrics, "utf8")
          });
          res.end(metrics);
        } catch (err) {
          console.error("[Metrics Plugin] Error generating Prometheus metrics:", err);
          res.writeHead(500, { "Content-Type": "text/plain" });
          res.end("Internal Server Error");
        }
      } else if (req.method === "OPTIONS") {
        res.writeHead(204);
        res.end();
      } else {
        res.writeHead(404, { "Content-Type": "text/plain" });
        res.end("Not Found");
      }
    });
    this.metricsServer.listen(port, "0.0.0.0", () => {
      console.log(
        `[Metrics Plugin] Prometheus metrics available at http://0.0.0.0:${port}${path} (standalone mode)`
      );
    });
    this.metricsServer.on("error", (err) => {
      console.error("[Metrics Plugin] Standalone metrics server error:", err);
    });
  }
}

class AsyncEventEmitter extends EventEmitter {
  constructor() {
    super();
    this._asyncMode = true;
  }
  emit(event, ...args) {
    if (!this._asyncMode) {
      return super.emit(event, ...args);
    }
    const listeners = this.listeners(event);
    if (listeners.length === 0) {
      return false;
    }
    setImmediate(async () => {
      for (const listener of listeners) {
        try {
          await listener(...args);
        } catch (error) {
          if (event !== "error") {
            this.emit("error", error);
          } else {
            console.error("Error in error handler:", error);
          }
        }
      }
    });
    return true;
  }
  emitSync(event, ...args) {
    return super.emit(event, ...args);
  }
  setAsyncMode(enabled) {
    this._asyncMode = enabled;
  }
}

function secretHandler(actual, errors, schema) {
  if (!this.passphrase) {
    errors.push(new ValidationError("Missing configuration for secrets encryption.", {
      actual,
      type: "encryptionKeyMissing",
      suggestion: "Provide a passphrase for secret encryption."
    }));
    return actual;
  }
  const [ok, err, res] = tryFnSync(() => encrypt(String(actual), this.passphrase));
  if (ok) return res;
  errors.push(new ValidationError("Problem encrypting secret.", {
    actual,
    type: "encryptionProblem",
    error: err,
    suggestion: "Check the passphrase and input value."
  }));
  return actual;
}
function passwordHandler(actual, errors, schema) {
  if (!this.bcryptRounds) {
    errors.push(new ValidationError("Missing bcrypt rounds configuration.", {
      actual,
      type: "bcryptRoundsMissing",
      suggestion: "Provide bcryptRounds in database configuration."
    }));
    return actual;
  }
  const [okHash, errHash, hash] = tryFnSync(() => hashPasswordSync(String(actual), this.bcryptRounds));
  if (!okHash) {
    errors.push(new ValidationError("Problem hashing password.", {
      actual,
      type: "passwordHashingProblem",
      error: errHash,
      suggestion: "Check the bcryptRounds configuration and password value."
    }));
    return actual;
  }
  const [okCompact, errCompact, compacted] = tryFnSync(() => compactHash(hash));
  if (!okCompact) {
    errors.push(new ValidationError("Problem compacting password hash.", {
      actual,
      type: "hashCompactionProblem",
      error: errCompact,
      suggestion: "Bcrypt hash format may be invalid."
    }));
    return hash;
  }
  return compacted;
}
function jsonHandler(actual, errors, schema) {
  if (isString(actual)) return actual;
  const [ok, err, json] = tryFnSync(() => JSON.stringify(actual));
  if (!ok) throw new ValidationError("Failed to stringify JSON", { original: err, input: actual });
  return json;
}
class Validator extends FastestValidator {
  constructor({ options, passphrase, bcryptRounds = 10, autoEncrypt = true, autoHash = true } = {}) {
    super(merge({}, {
      useNewCustomCheckerFunction: true,
      messages: {
        encryptionKeyMissing: "Missing configuration for secrets encryption.",
        encryptionProblem: "Problem encrypting secret. Actual: {actual}. Error: {error}",
        bcryptRoundsMissing: "Missing bcrypt rounds configuration for password hashing.",
        passwordHashingProblem: "Problem hashing password. Error: {error}"
      },
      defaults: {
        string: {
          trim: true
        },
        object: {
          strict: "remove"
        },
        number: {
          convert: true
        }
      }
    }, options));
    this.passphrase = passphrase;
    this.bcryptRounds = bcryptRounds;
    this.autoEncrypt = autoEncrypt;
    this.autoHash = autoHash;
    this.alias("secret", {
      type: "string",
      custom: this.autoEncrypt ? secretHandler : void 0,
      messages: {
        string: "The '{field}' field must be a string.",
        stringMin: "This secret '{field}' field length must be at least {expected} long."
      }
    });
    this.alias("secretAny", {
      type: "any",
      custom: this.autoEncrypt ? secretHandler : void 0
    });
    this.alias("secretNumber", {
      type: "number",
      custom: this.autoEncrypt ? secretHandler : void 0
    });
    this.alias("password", {
      type: "string",
      custom: this.autoHash ? passwordHandler : void 0,
      messages: {
        string: "The '{field}' field must be a string.",
        stringMin: "This password '{field}' field length must be at least {expected} long."
      }
    });
    this.alias("json", {
      type: "any",
      custom: this.autoEncrypt ? jsonHandler : void 0
    });
    this.alias("embedding", {
      type: "array",
      items: "number",
      empty: false
    });
  }
}
const ValidatorManager = new Proxy(Validator, {
  instance: null,
  construct(target, args) {
    if (!this.instance) this.instance = new target(...args);
    return this.instance;
  }
});

function isValidIPv4(ip) {
  if (typeof ip !== "string") return false;
  const ipv4Regex = /^(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})$/;
  const match = ip.match(ipv4Regex);
  if (!match) return false;
  for (let i = 1; i <= 4; i++) {
    const octet = parseInt(match[i], 10);
    if (octet < 0 || octet > 255) return false;
  }
  return true;
}
function isValidIPv6(ip) {
  if (typeof ip !== "string") return false;
  const ipv6Regex = /^(([0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]+|::(ffff(:0{1,4})?:)?((25[0-5]|(2[0-4]|1?[0-9])?[0-9])\.){3}(25[0-5]|(2[0-4]|1?[0-9])?[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1?[0-9])?[0-9])\.){3}(25[0-5]|(2[0-4]|1?[0-9])?[0-9]))$/;
  return ipv6Regex.test(ip);
}
function encodeIPv4(ip) {
  if (!isValidIPv4(ip)) {
    throw new ValidationError("Invalid IPv4 address", {
      field: "ip",
      value: ip,
      retriable: false,
      suggestion: 'Provide a valid IPv4 address (e.g., "192.168.0.1").'
    });
  }
  const octets = ip.split(".").map((octet) => parseInt(octet, 10));
  const buffer = Buffer.from(octets);
  return buffer.toString("base64");
}
function decodeIPv4(encoded) {
  if (typeof encoded !== "string") {
    throw new ValidationError("Encoded IPv4 must be a string", {
      field: "encoded",
      retriable: false,
      suggestion: "Pass the base64-encoded IPv4 string returned by encodeIPv4()."
    });
  }
  const [ok, err, result] = tryFn(() => {
    const buffer = Buffer.from(encoded, "base64");
    if (buffer.length !== 4) {
      throw new ValidationError("Invalid encoded IPv4 length", {
        field: "encoded",
        value: encoded,
        retriable: false,
        suggestion: "Ensure the encoded IPv4 string was produced by encodeIPv4()."
      });
    }
    return Array.from(buffer).join(".");
  });
  if (!ok) {
    if (err instanceof ValidationError) {
      throw err;
    }
    throw new ValidationError("Failed to decode IPv4", {
      field: "encoded",
      retriable: false,
      suggestion: "Confirm the value is a base64-encoded IPv4 string generated by encodeIPv4().",
      original: err
    });
  }
  return result;
}
function expandIPv6(ip) {
  if (!isValidIPv6(ip)) {
    throw new ValidationError("Invalid IPv6 address", {
      field: "ip",
      value: ip,
      retriable: false,
      suggestion: 'Provide a valid IPv6 address (e.g., "2001:db8::1").'
    });
  }
  let expanded = ip;
  if (expanded === "::") {
    return "0000:0000:0000:0000:0000:0000:0000:0000";
  }
  if (expanded.includes("::")) {
    const parts = expanded.split("::");
    const leftParts = parts[0] ? parts[0].split(":") : [];
    const rightParts = parts[1] ? parts[1].split(":") : [];
    const missingGroups = 8 - leftParts.length - rightParts.length;
    const middleParts = Array(missingGroups).fill("0");
    expanded = [...leftParts, ...middleParts, ...rightParts].join(":");
  }
  const groups = expanded.split(":");
  const paddedGroups = groups.map((group) => group.padStart(4, "0"));
  return paddedGroups.join(":");
}
function compressIPv6(ip) {
  let compressed = ip.split(":").map((group) => {
    return parseInt(group, 16).toString(16);
  }).join(":");
  const zeroSequences = [];
  let currentSequence = { start: -1, length: 0 };
  compressed.split(":").forEach((group, index) => {
    if (group === "0") {
      if (currentSequence.start === -1) {
        currentSequence.start = index;
        currentSequence.length = 1;
      } else {
        currentSequence.length++;
      }
    } else {
      if (currentSequence.length > 0) {
        zeroSequences.push({ ...currentSequence });
        currentSequence = { start: -1, length: 0 };
      }
    }
  });
  if (currentSequence.length > 0) {
    zeroSequences.push(currentSequence);
  }
  const longestSequence = zeroSequences.filter((seq) => seq.length >= 2).sort((a, b) => b.length - a.length)[0];
  if (longestSequence) {
    const parts = compressed.split(":");
    const before = parts.slice(0, longestSequence.start).join(":");
    const after = parts.slice(longestSequence.start + longestSequence.length).join(":");
    if (before && after) {
      compressed = `${before}::${after}`;
    } else if (before) {
      compressed = `${before}::`;
    } else if (after) {
      compressed = `::${after}`;
    } else {
      compressed = "::";
    }
  }
  return compressed;
}
function encodeIPv6(ip) {
  if (!isValidIPv6(ip)) {
    throw new ValidationError("Invalid IPv6 address", {
      field: "ip",
      value: ip,
      retriable: false,
      suggestion: 'Provide a valid IPv6 address (e.g., "2001:db8::1").'
    });
  }
  const expanded = expandIPv6(ip);
  const groups = expanded.split(":");
  const bytes = [];
  for (const group of groups) {
    const value = parseInt(group, 16);
    bytes.push(value >> 8 & 255);
    bytes.push(value & 255);
  }
  const buffer = Buffer.from(bytes);
  return buffer.toString("base64");
}
function decodeIPv6(encoded, compress = true) {
  if (typeof encoded !== "string") {
    throw new ValidationError("Encoded IPv6 must be a string", {
      field: "encoded",
      retriable: false,
      suggestion: "Pass the base64-encoded IPv6 string returned by encodeIPv6()."
    });
  }
  if (encoded.length !== 24 && isValidIPv6(encoded)) {
    return compress ? encoded : expandIPv6(encoded);
  }
  const [ok, err, result] = tryFn(() => {
    const buffer = Buffer.from(encoded, "base64");
    if (buffer.length !== 16) {
      throw new ValidationError("Invalid encoded IPv6 length", {
        field: "encoded",
        value: encoded,
        retriable: false,
        suggestion: "Ensure the encoded IPv6 string was produced by encodeIPv6()."
      });
    }
    const groups = [];
    for (let i = 0; i < 16; i += 2) {
      const value = buffer[i] << 8 | buffer[i + 1];
      groups.push(value.toString(16).padStart(4, "0"));
    }
    const fullAddress = groups.join(":");
    return compress ? compressIPv6(fullAddress) : fullAddress;
  });
  if (!ok) {
    if (err instanceof ValidationError) {
      throw err;
    }
    throw new ValidationError("Failed to decode IPv6", {
      field: "encoded",
      retriable: false,
      suggestion: "Confirm the value is a base64-encoded IPv6 string generated by encodeIPv6().",
      original: err
    });
  }
  return result;
}

function encodeGeoLat(lat, precision = 6) {
  if (lat === null || lat === void 0) return lat;
  if (typeof lat !== "number" || isNaN(lat)) return lat;
  if (!isFinite(lat)) return lat;
  if (lat < -90 || lat > 90) {
    throw new ValidationError("Latitude out of range", {
      field: "lat",
      value: lat,
      min: -90,
      max: 90,
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a latitude between -90 and +90 degrees."
    });
  }
  const normalized = lat + 90;
  const scale = Math.pow(10, precision);
  const scaled = Math.round(normalized * scale);
  return "~" + encode(scaled);
}
function decodeGeoLat(encoded, precision = 6) {
  if (typeof encoded !== "string") return encoded;
  if (!encoded.startsWith("~")) return encoded;
  const scaled = decode(encoded.slice(1));
  if (isNaN(scaled)) return NaN;
  const scale = Math.pow(10, precision);
  const normalized = scaled / scale;
  return normalized - 90;
}
function encodeGeoLon(lon, precision = 6) {
  if (lon === null || lon === void 0) return lon;
  if (typeof lon !== "number" || isNaN(lon)) return lon;
  if (!isFinite(lon)) return lon;
  if (lon < -180 || lon > 180) {
    throw new ValidationError("Longitude out of range", {
      field: "lon",
      value: lon,
      min: -180,
      max: 180,
      statusCode: 400,
      retriable: false,
      suggestion: "Provide a longitude between -180 and +180 degrees."
    });
  }
  const normalized = lon + 180;
  const scale = Math.pow(10, precision);
  const scaled = Math.round(normalized * scale);
  return "~" + encode(scaled);
}
function decodeGeoLon(encoded, precision = 6) {
  if (typeof encoded !== "string") return encoded;
  if (!encoded.startsWith("~")) return encoded;
  const scaled = decode(encoded.slice(1));
  if (isNaN(scaled)) return NaN;
  const scale = Math.pow(10, precision);
  const normalized = scaled / scale;
  return normalized - 180;
}
function encodeGeoPoint(lat, lon, precision = 6) {
  const latEncoded = encodeGeoLat(lat, precision);
  const lonEncoded = encodeGeoLon(lon, precision);
  return latEncoded + lonEncoded;
}
function decodeGeoPoint(encoded, precision = 6) {
  if (typeof encoded !== "string") return { latitude: NaN, longitude: NaN };
  const parts = encoded.split("~").filter((p) => p.length > 0);
  if (parts.length !== 2) {
    return { latitude: NaN, longitude: NaN };
  }
  const latitude = decodeGeoLat("~" + parts[0], precision);
  const longitude = decodeGeoLon("~" + parts[1], precision);
  return { latitude, longitude };
}

function generateBase62Mapping(keys) {
  const mapping = {};
  const reversedMapping = {};
  keys.forEach((key, index) => {
    const base62Key = encode(index);
    mapping[key] = base62Key;
    reversedMapping[base62Key] = key;
  });
  return { mapping, reversedMapping };
}
function generatePluginAttributeHash(pluginName, attributeName) {
  const input = `${pluginName}:${attributeName}`;
  const hash = createHash("sha256").update(input).digest();
  const num = hash.readUInt32BE(0);
  const base62Hash = encode(num);
  const paddedHash = base62Hash.padStart(3, "0").substring(0, 3);
  return "p" + paddedHash.toLowerCase();
}
function generatePluginMapping(attributes) {
  const mapping = {};
  const reversedMapping = {};
  const usedHashes = /* @__PURE__ */ new Set();
  for (const { key, pluginName } of attributes) {
    let hash = generatePluginAttributeHash(pluginName, key);
    let counter = 1;
    let finalHash = hash;
    while (usedHashes.has(finalHash)) {
      finalHash = `${hash}${counter}`;
      counter++;
    }
    usedHashes.add(finalHash);
    mapping[key] = finalHash;
    reversedMapping[finalHash] = key;
  }
  return { mapping, reversedMapping };
}
const SchemaActions = {
  trim: (value) => value == null ? value : value.trim(),
  encrypt: async (value, { passphrase }) => {
    if (value === null || value === void 0) return value;
    const [ok, err, res] = await tryFn(() => encrypt(value, passphrase));
    return ok ? res : value;
  },
  decrypt: async (value, { passphrase }) => {
    if (value === null || value === void 0) return value;
    const [ok, err, raw] = await tryFn(() => decrypt(value, passphrase));
    if (!ok) return value;
    if (raw === "null") return null;
    if (raw === "undefined") return void 0;
    return raw;
  },
  hashPassword: async (value, { bcryptRounds = 10 }) => {
    if (value === null || value === void 0) return value;
    const [okHash, errHash, hash] = await tryFn(() => hashPassword(String(value), bcryptRounds));
    if (!okHash) return value;
    const [okCompact, errCompact, compacted] = tryFnSync(() => compactHash(hash));
    return okCompact ? compacted : hash;
  },
  toString: (value) => value == null ? value : String(value),
  fromArray: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const escapedItems = value.map((item) => {
      if (typeof item === "string") {
        return item.replace(/\\/g, "\\\\").replace(new RegExp(`\\${separator}`, "g"), `\\${separator}`);
      }
      return String(item);
    });
    return escapedItems.join(separator);
  },
  toArray: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value;
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const items = [];
    let current = "";
    let i = 0;
    const str = String(value);
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items;
  },
  toJSON: (value) => {
    if (value === null) return null;
    if (value === void 0) return void 0;
    if (typeof value === "string") {
      const [ok2, err2, parsed] = tryFnSync(() => JSON.parse(value));
      if (ok2 && typeof parsed === "object") return value;
      return value;
    }
    const [ok, err, json] = tryFnSync(() => JSON.stringify(value));
    return ok ? json : value;
  },
  fromJSON: (value) => {
    if (value === null) return null;
    if (value === void 0) return void 0;
    if (typeof value !== "string") return value;
    if (value === "") return "";
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(value));
    return ok ? parsed : value;
  },
  toNumber: (value) => isString(value) ? value.includes(".") ? parseFloat(value) : parseInt(value) : value,
  toBool: (value) => [true, 1, "true", "1", "yes", "y"].includes(value),
  fromBool: (value) => [true, 1, "true", "1", "yes", "y"].includes(value) ? "1" : "0",
  fromBase62: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") return value;
    if (typeof value === "string") {
      const n = decode(value);
      return isNaN(n) ? void 0 : n;
    }
    return void 0;
  },
  toBase62: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") {
      return encode(value);
    }
    if (typeof value === "string") {
      const n = Number(value);
      return isNaN(n) ? value : encode(n);
    }
    return value;
  },
  fromBase62Decimal: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") return value;
    if (typeof value === "string") {
      const n = decodeDecimal(value);
      return isNaN(n) ? void 0 : n;
    }
    return void 0;
  },
  toBase62Decimal: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") {
      return encodeDecimal(value);
    }
    if (typeof value === "string") {
      const n = Number(value);
      return isNaN(n) ? value : encodeDecimal(n);
    }
    return value;
  },
  fromArrayOfNumbers: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const base62Items = value.map((item) => {
      if (typeof item === "number" && !isNaN(item)) {
        return encode(item);
      }
      const n = Number(item);
      return isNaN(n) ? "" : encode(n);
    });
    return base62Items.join(separator);
  },
  toArrayOfNumbers: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value.map((v) => typeof v === "number" ? v : decode(v));
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const str = String(value);
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decode(v);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  fromArrayOfDecimals: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const base62Items = value.map((item) => {
      if (typeof item === "number" && !isNaN(item)) {
        return encodeDecimal(item);
      }
      const n = Number(item);
      return isNaN(n) ? "" : encodeDecimal(n);
    });
    return base62Items.join(separator);
  },
  toArrayOfDecimals: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value.map((v) => typeof v === "number" ? v : decodeDecimal(v));
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const str = String(value);
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decodeDecimal(v);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  fromArrayOfEmbeddings: (value, { separator, precision = 6 }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "^[]";
    }
    return encodeFixedPointBatch(value, precision);
  },
  toArrayOfEmbeddings: (value, { separator, precision = 6 }) => {
    if (Array.isArray(value)) {
      return value;
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "" || value === "^[]") {
      return [];
    }
    const str = String(value);
    if (str.startsWith("^[")) {
      return decodeFixedPointBatch(str, precision);
    }
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decodeFixedPoint(v, precision);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  encodeIPv4: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!isValidIPv4(value)) return value;
    const [ok, err, encoded] = tryFnSync(() => encodeIPv4(value));
    return ok ? encoded : value;
  },
  decodeIPv4: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeIPv4(value));
    return ok ? decoded : value;
  },
  encodeIPv6: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!isValidIPv6(value)) return value;
    const [ok, err, encoded] = tryFnSync(() => encodeIPv6(value));
    return ok ? encoded : value;
  },
  decodeIPv6: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeIPv6(value));
    return ok ? decoded : value;
  },
  // Money type - Integer-based (banking standard)
  // Simplified approach: decimals instead of currency
  encodeMoney: (value, { decimals = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const multiplier = Math.pow(10, decimals);
    const integerValue = Math.round(value * multiplier);
    const [ok, err, encoded] = tryFnSync(() => "$" + encode(integerValue));
    return ok ? encoded : value;
  },
  decodeMoney: (value, { decimals = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!value.startsWith("$")) return value;
    const [ok, err, integerValue] = tryFnSync(() => decode(value.slice(1)));
    if (!ok || isNaN(integerValue)) return value;
    const divisor = Math.pow(10, decimals);
    return integerValue / divisor;
  },
  // Decimal type - Fixed-point for non-monetary decimals
  encodeDecimalFixed: (value, { precision = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeFixedPoint(value, precision));
    return ok ? encoded : value;
  },
  decodeDecimalFixed: (value, { precision = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeFixedPoint(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Latitude
  encodeGeoLatitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeGeoLat(value, precision));
    return ok ? encoded : value;
  },
  decodeGeoLatitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoLat(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Longitude
  encodeGeoLongitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeGeoLon(value, precision));
    return ok ? encoded : value;
  },
  decodeGeoLongitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoLon(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Point (lat+lon pair)
  encodeGeoPointPair: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (Array.isArray(value) && value.length === 2) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value[0], value[1], precision));
      return ok ? encoded : value;
    }
    if (typeof value === "object" && value.lat !== void 0 && value.lon !== void 0) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value.lat, value.lon, precision));
      return ok ? encoded : value;
    }
    if (typeof value === "object" && value.latitude !== void 0 && value.longitude !== void 0) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value.latitude, value.longitude, precision));
      return ok ? encoded : value;
    }
    return value;
  },
  decodeGeoPointPair: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoPoint(value, precision));
    return ok ? decoded : value;
  }
};
class Schema {
  constructor(args) {
    const {
      map,
      pluginMap,
      name,
      attributes,
      passphrase,
      bcryptRounds,
      version = 1,
      options = {},
      _pluginAttributeMetadata,
      _pluginAttributes
    } = args;
    this.name = name;
    this.version = version;
    this.attributes = attributes || {};
    this.passphrase = passphrase ?? "secret";
    this.bcryptRounds = bcryptRounds ?? 10;
    this.options = merge({}, this.defaultOptions(), options);
    this.allNestedObjectsOptional = this.options.allNestedObjectsOptional ?? false;
    this._pluginAttributeMetadata = _pluginAttributeMetadata || {};
    this._pluginAttributes = _pluginAttributes || {};
    const processedAttributes = this.preprocessAttributesForValidation(this.attributes);
    this.validator = new ValidatorManager({
      autoEncrypt: false,
      passphrase: this.passphrase,
      bcryptRounds: this.bcryptRounds
    }).compile(merge(
      { $$async: true, $$strict: false },
      processedAttributes
    ));
    if (this.options.generateAutoHooks) this.generateAutoHooks();
    if (!isEmpty(map)) {
      this.map = map;
      this.reversedMap = invert(map);
    } else {
      const flatAttrs = flatten(this.attributes, { safe: true });
      const leafKeys = Object.keys(flatAttrs).filter((k) => !k.includes("$$"));
      const objectKeys = this.extractObjectKeys(this.attributes);
      const allKeys = [.../* @__PURE__ */ new Set([...leafKeys, ...objectKeys])];
      const userKeys = [];
      const pluginAttributes = [];
      for (const key of allKeys) {
        const attrDef = this.getAttributeDefinition(key);
        if (typeof attrDef === "object" && attrDef !== null && attrDef.__plugin__) {
          pluginAttributes.push({ key, pluginName: attrDef.__plugin__ });
        } else if (typeof attrDef === "string" && this._pluginAttributeMetadata && this._pluginAttributeMetadata[key]) {
          const pluginName = this._pluginAttributeMetadata[key].__plugin__;
          pluginAttributes.push({ key, pluginName });
        } else {
          userKeys.push(key);
        }
      }
      const { mapping, reversedMapping } = generateBase62Mapping(userKeys);
      this.map = mapping;
      this.reversedMap = reversedMapping;
      const { mapping: pMapping, reversedMapping: pReversedMapping } = generatePluginMapping(pluginAttributes);
      this.pluginMap = pMapping;
      this.reversedPluginMap = pReversedMapping;
      this._pluginAttributes = {};
      for (const { key, pluginName } of pluginAttributes) {
        if (!this._pluginAttributes[pluginName]) {
          this._pluginAttributes[pluginName] = [];
        }
        this._pluginAttributes[pluginName].push(key);
      }
    }
    if (!isEmpty(pluginMap)) {
      this.pluginMap = pluginMap;
      this.reversedPluginMap = invert(pluginMap);
    }
    if (!this.pluginMap) {
      this.pluginMap = {};
      this.reversedPluginMap = {};
    }
    if (!this._pluginAttributes) {
      this._pluginAttributes = {};
    }
  }
  defaultOptions() {
    return {
      autoEncrypt: true,
      autoDecrypt: true,
      arraySeparator: "|",
      generateAutoHooks: true,
      hooks: {
        beforeMap: {},
        afterMap: {},
        beforeUnmap: {},
        afterUnmap: {}
      }
    };
  }
  addHook(hook, attribute, action, params = {}) {
    if (!this.options.hooks[hook][attribute]) this.options.hooks[hook][attribute] = [];
    const hookEntry = Object.keys(params).length > 0 ? { action, params } : action;
    this.options.hooks[hook][attribute] = uniq([...this.options.hooks[hook][attribute], hookEntry]);
  }
  extractObjectKeys(obj, prefix = "") {
    const objectKeys = [];
    for (const [key, value] of Object.entries(obj)) {
      if (key.startsWith("$$")) continue;
      const fullKey = prefix ? `${prefix}.${key}` : key;
      if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        objectKeys.push(fullKey);
        if (value.$$type === "object") {
          objectKeys.push(...this.extractObjectKeys(value, fullKey));
        }
      }
    }
    return objectKeys;
  }
  _generateHooksFromOriginalAttributes(attributes, prefix = "") {
    for (const [key, value] of Object.entries(attributes)) {
      if (key.startsWith("$$")) continue;
      const fullKey = prefix ? `${prefix}.${key}` : key;
      if (typeof value === "object" && value !== null && !Array.isArray(value) && value.type) {
        if (value.type === "array" && value.items) {
          const itemsType = value.items;
          const arrayLength = typeof value.length === "number" ? value.length : null;
          if (itemsType === "string" || typeof itemsType === "string" && itemsType.includes("string")) {
            this.addHook("beforeMap", fullKey, "fromArray");
            this.addHook("afterUnmap", fullKey, "toArray");
          } else if (itemsType === "number" || typeof itemsType === "string" && itemsType.includes("number")) {
            const isIntegerArray = typeof itemsType === "string" && itemsType.includes("integer");
            const isEmbedding = !isIntegerArray && arrayLength !== null && arrayLength >= 256;
            if (isIntegerArray) {
              this.addHook("beforeMap", fullKey, "fromArrayOfNumbers");
              this.addHook("afterUnmap", fullKey, "toArrayOfNumbers");
            } else if (isEmbedding) {
              this.addHook("beforeMap", fullKey, "fromArrayOfEmbeddings");
              this.addHook("afterUnmap", fullKey, "toArrayOfEmbeddings");
            } else {
              this.addHook("beforeMap", fullKey, "fromArrayOfDecimals");
              this.addHook("afterUnmap", fullKey, "toArrayOfDecimals");
            }
          }
        }
      } else if (typeof value === "object" && value !== null && !Array.isArray(value) && !value.type) {
        this._generateHooksFromOriginalAttributes(value, fullKey);
      }
    }
  }
  generateAutoHooks() {
    this._generateHooksFromOriginalAttributes(this.attributes);
    const schema = flatten(cloneDeep(this.attributes), { safe: true });
    for (const [name, definition] of Object.entries(schema)) {
      if (name.includes("$$")) continue;
      if (this.options.hooks.beforeMap[name] || this.options.hooks.afterUnmap[name]) {
        continue;
      }
      const defStr = typeof definition === "string" ? definition : "";
      const defType = typeof definition === "object" && definition !== null ? definition.type : null;
      const isEmbeddingType = defStr.includes("embedding") || defType === "embedding";
      if (isEmbeddingType) {
        const lengthMatch = defStr.match(/embedding:(\d+)/);
        if (lengthMatch) {
          parseInt(lengthMatch[1], 10);
        } else if (defStr.includes("length:")) {
          const match = defStr.match(/length:(\d+)/);
          if (match) parseInt(match[1], 10);
        }
        this.addHook("beforeMap", name, "fromArrayOfEmbeddings");
        this.addHook("afterUnmap", name, "toArrayOfEmbeddings");
        continue;
      }
      const isArray = defStr.includes("array") || defType === "array";
      if (isArray) {
        let itemsType = null;
        if (typeof definition === "object" && definition !== null && definition.items) {
          itemsType = definition.items;
        } else if (defStr.includes("items:string")) {
          itemsType = "string";
        } else if (defStr.includes("items:number")) {
          itemsType = "number";
        }
        if (itemsType === "string" || typeof itemsType === "string" && itemsType.includes("string")) {
          this.addHook("beforeMap", name, "fromArray");
          this.addHook("afterUnmap", name, "toArray");
        } else if (itemsType === "number" || typeof itemsType === "string" && itemsType.includes("number")) {
          const isIntegerArray = defStr.includes("integer:true") || defStr.includes("|integer:") || defStr.includes("|integer") || typeof itemsType === "string" && itemsType.includes("integer");
          let arrayLength = null;
          if (typeof definition === "object" && definition !== null && typeof definition.length === "number") {
            arrayLength = definition.length;
          } else if (defStr.includes("length:")) {
            const match = defStr.match(/length:(\d+)/);
            if (match) arrayLength = parseInt(match[1], 10);
          }
          const isEmbedding = !isIntegerArray && arrayLength !== null && arrayLength >= 256;
          if (isIntegerArray) {
            this.addHook("beforeMap", name, "fromArrayOfNumbers");
            this.addHook("afterUnmap", name, "toArrayOfNumbers");
          } else if (isEmbedding) {
            this.addHook("beforeMap", name, "fromArrayOfEmbeddings");
            this.addHook("afterUnmap", name, "toArrayOfEmbeddings");
          } else {
            this.addHook("beforeMap", name, "fromArrayOfDecimals");
            this.addHook("afterUnmap", name, "toArrayOfDecimals");
          }
        }
        continue;
      }
      if (defStr.includes("secret") || defType === "secret") {
        if (this.options.autoEncrypt) {
          this.addHook("beforeMap", name, "encrypt");
        }
        if (this.options.autoDecrypt) {
          this.addHook("afterUnmap", name, "decrypt");
        }
        continue;
      }
      if (defStr.includes("password") || defType === "password") {
        if (this.options.autoEncrypt) {
          this.addHook("beforeMap", name, "hashPassword");
        }
        continue;
      }
      if (defStr.includes("ip4") || defType === "ip4") {
        this.addHook("beforeMap", name, "encodeIPv4");
        this.addHook("afterUnmap", name, "decodeIPv4");
        continue;
      }
      if (defStr.includes("ip6") || defType === "ip6") {
        this.addHook("beforeMap", name, "encodeIPv6");
        this.addHook("afterUnmap", name, "decodeIPv6");
        continue;
      }
      if (defStr.includes("money") || defType === "money" || defStr.includes("crypto") || defType === "crypto") {
        let decimals = 2;
        if (defStr.includes("crypto") || defType === "crypto") {
          decimals = 8;
        }
        const decimalsMatch = defStr.match(/(?:money|crypto):(\d+)/i);
        if (decimalsMatch) {
          decimals = parseInt(decimalsMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeMoney", { decimals });
        this.addHook("afterUnmap", name, "decodeMoney", { decimals });
        continue;
      }
      if (defStr.includes("decimal") || defType === "decimal") {
        let precision = 2;
        const precisionMatch = defStr.match(/decimal:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeDecimalFixed", { precision });
        this.addHook("afterUnmap", name, "decodeDecimalFixed", { precision });
        continue;
      }
      if (defStr.includes("geo:lat") || defType === "geo" && defStr.includes("lat")) {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:lat:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoLatitude", { precision });
        this.addHook("afterUnmap", name, "decodeGeoLatitude", { precision });
        continue;
      }
      if (defStr.includes("geo:lon") || defType === "geo" && defStr.includes("lon")) {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:lon:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoLongitude", { precision });
        this.addHook("afterUnmap", name, "decodeGeoLongitude", { precision });
        continue;
      }
      if (defStr.includes("geo:point") || defType === "geo:point") {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:point:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoPointPair", { precision });
        this.addHook("afterUnmap", name, "decodeGeoPointPair", { precision });
        continue;
      }
      if (defStr.includes("number") || defType === "number") {
        const isInteger = defStr.includes("integer:true") || defStr.includes("|integer:") || defStr.includes("|integer");
        if (isInteger) {
          this.addHook("beforeMap", name, "toBase62");
          this.addHook("afterUnmap", name, "fromBase62");
        } else {
          this.addHook("beforeMap", name, "toBase62Decimal");
          this.addHook("afterUnmap", name, "fromBase62Decimal");
        }
        continue;
      }
      if (defStr.includes("boolean") || defType === "boolean") {
        this.addHook("beforeMap", name, "fromBool");
        this.addHook("afterUnmap", name, "toBool");
        continue;
      }
      if (defStr.includes("json") || defType === "json") {
        this.addHook("beforeMap", name, "toJSON");
        this.addHook("afterUnmap", name, "fromJSON");
        continue;
      }
      if (definition === "object" || defStr.includes("object") || defType === "object") {
        this.addHook("beforeMap", name, "toJSON");
        this.addHook("afterUnmap", name, "fromJSON");
        continue;
      }
    }
  }
  static import(data) {
    let {
      map,
      pluginMap,
      _pluginAttributeMetadata,
      name,
      options,
      version,
      attributes
    } = isString(data) ? JSON.parse(data) : data;
    const [ok, err, attrs] = tryFnSync(() => Schema._importAttributes(attributes));
    if (!ok) throw new SchemaError("Failed to import schema attributes", { original: err, input: attributes });
    attributes = attrs;
    const schema = new Schema({
      map,
      pluginMap: pluginMap || {},
      name,
      options,
      version,
      attributes
    });
    if (_pluginAttributeMetadata) {
      schema._pluginAttributeMetadata = _pluginAttributeMetadata;
    }
    return schema;
  }
  /**
   * Recursively import attributes, parsing only stringified objects (legacy)
   */
  static _importAttributes(attrs) {
    if (typeof attrs === "string") {
      const [ok, err, parsed] = tryFnSync(() => JSON.parse(attrs));
      if (ok && typeof parsed === "object" && parsed !== null) {
        const [okNested, errNested, nested] = tryFnSync(() => Schema._importAttributes(parsed));
        if (!okNested) throw new SchemaError("Failed to parse nested schema attribute", { original: errNested, input: attrs });
        return nested;
      }
      return attrs;
    }
    if (Array.isArray(attrs)) {
      const [okArr, errArr, arr] = tryFnSync(() => attrs.map((a) => Schema._importAttributes(a)));
      if (!okArr) throw new SchemaError("Failed to import array schema attributes", { original: errArr, input: attrs });
      return arr;
    }
    if (typeof attrs === "object" && attrs !== null) {
      const out = {};
      for (const [k, v] of Object.entries(attrs)) {
        const [okObj, errObj, val] = tryFnSync(() => Schema._importAttributes(v));
        if (!okObj) throw new SchemaError("Failed to import object schema attribute", { original: errObj, key: k, input: v });
        out[k] = val;
      }
      return out;
    }
    return attrs;
  }
  export() {
    const data = {
      version: this.version,
      name: this.name,
      options: this.options,
      attributes: this._exportAttributes(this.attributes),
      map: this.map,
      pluginMap: this.pluginMap || {},
      _pluginAttributeMetadata: this._pluginAttributeMetadata || {},
      _pluginAttributes: this._pluginAttributes || {}
    };
    return data;
  }
  /**
   * Recursively export attributes, keeping objects as objects and only serializing leaves as string
   */
  _exportAttributes(attrs) {
    if (typeof attrs === "string") {
      return attrs;
    }
    if (Array.isArray(attrs)) {
      return attrs.map((a) => this._exportAttributes(a));
    }
    if (typeof attrs === "object" && attrs !== null) {
      const out = {};
      for (const [k, v] of Object.entries(attrs)) {
        out[k] = this._exportAttributes(v);
      }
      return out;
    }
    return attrs;
  }
  async applyHooksActions(resourceItem, hook) {
    const cloned = cloneDeep(resourceItem);
    for (const [attribute, actions] of Object.entries(this.options.hooks[hook])) {
      for (const actionEntry of actions) {
        const actionName = typeof actionEntry === "string" ? actionEntry : actionEntry.action;
        const actionParams = typeof actionEntry === "object" ? actionEntry.params : {};
        const value = get(cloned, attribute);
        if (value !== void 0 && typeof SchemaActions[actionName] === "function") {
          set(cloned, attribute, await SchemaActions[actionName](value, {
            passphrase: this.passphrase,
            bcryptRounds: this.bcryptRounds,
            separator: this.options.arraySeparator,
            ...actionParams
            // Merge custom parameters (currency, precision, etc.)
          }));
        }
      }
    }
    return cloned;
  }
  async validate(resourceItem, { mutateOriginal = false } = {}) {
    let data = mutateOriginal ? resourceItem : cloneDeep(resourceItem);
    const result = await this.validator(data);
    return result;
  }
  async mapper(resourceItem) {
    let obj = cloneDeep(resourceItem);
    obj = await this.applyHooksActions(obj, "beforeMap");
    const flattenedObj = flatten(obj, { safe: true });
    const rest = { "_v": this.version + "" };
    for (const [key, value] of Object.entries(flattenedObj)) {
      const mappedKey = this.pluginMap[key] || this.map[key] || key;
      const attrDef = this.getAttributeDefinition(key);
      if (typeof value === "number" && typeof attrDef === "string" && attrDef.includes("number")) {
        rest[mappedKey] = encode(value);
      } else if (typeof value === "string") {
        if (value === "[object Object]") {
          rest[mappedKey] = "{}";
        } else if (value.startsWith("{") || value.startsWith("[")) {
          rest[mappedKey] = value;
        } else {
          rest[mappedKey] = value;
        }
      } else if (Array.isArray(value) || typeof value === "object" && value !== null) {
        rest[mappedKey] = JSON.stringify(value);
      } else {
        rest[mappedKey] = value;
      }
    }
    await this.applyHooksActions(rest, "afterMap");
    return rest;
  }
  async unmapper(mappedResourceItem, mapOverride, pluginMapOverride) {
    let obj = cloneDeep(mappedResourceItem);
    delete obj._v;
    obj = await this.applyHooksActions(obj, "beforeUnmap");
    const reversedMap = mapOverride ? invert(mapOverride) : this.reversedMap;
    const reversedPluginMap = pluginMapOverride ? invert(pluginMapOverride) : this.reversedPluginMap;
    const rest = {};
    for (const [key, value] of Object.entries(obj)) {
      let originalKey = reversedPluginMap[key] || reversedMap[key] || key;
      if (!originalKey) {
        originalKey = key;
      }
      let parsedValue = value;
      const attrDef = this.getAttributeDefinition(originalKey);
      const hasAfterUnmapHook = this.options.hooks?.afterUnmap?.[originalKey];
      if (!hasAfterUnmapHook && typeof attrDef === "string" && attrDef.includes("number") && !attrDef.includes("array") && !attrDef.includes("decimal")) {
        if (typeof parsedValue === "string" && parsedValue !== "") {
          parsedValue = decode(parsedValue);
        } else if (typeof parsedValue === "number") ; else {
          parsedValue = void 0;
        }
      } else if (typeof value === "string") {
        if (value === "[object Object]") {
          parsedValue = {};
        } else if (value.startsWith("{") || value.startsWith("[")) {
          const [ok, err, parsed] = tryFnSync(() => JSON.parse(value));
          if (ok) parsedValue = parsed;
        }
      }
      if (this.attributes) {
        if (typeof attrDef === "string" && attrDef.includes("array")) {
          if (!hasAfterUnmapHook) {
            if (Array.isArray(parsedValue)) ; else if (typeof parsedValue === "string" && parsedValue.trim().startsWith("[")) {
              const [okArr, errArr, arr] = tryFnSync(() => JSON.parse(parsedValue));
              if (okArr && Array.isArray(arr)) {
                parsedValue = arr;
              }
            } else {
              parsedValue = SchemaActions.toArray(parsedValue, { separator: this.options.arraySeparator });
            }
          }
        }
      }
      if (this.options.hooks && this.options.hooks.afterUnmap && this.options.hooks.afterUnmap[originalKey]) {
        for (const actionEntry of this.options.hooks.afterUnmap[originalKey]) {
          const actionName = typeof actionEntry === "string" ? actionEntry : actionEntry.action;
          const actionParams = typeof actionEntry === "object" ? actionEntry.params : {};
          if (typeof SchemaActions[actionName] === "function") {
            parsedValue = await SchemaActions[actionName](parsedValue, {
              passphrase: this.passphrase,
              bcryptRounds: this.bcryptRounds,
              separator: this.options.arraySeparator,
              ...actionParams
              // Merge custom parameters (currency, precision, etc.)
            });
          }
        }
      }
      rest[originalKey] = parsedValue;
    }
    await this.applyHooksActions(rest, "afterUnmap");
    const result = unflatten(rest);
    for (const [key, value] of Object.entries(mappedResourceItem)) {
      if (key.startsWith("$")) {
        result[key] = value;
      }
    }
    return result;
  }
  // Helper to get attribute definition by dot notation key
  getAttributeDefinition(key) {
    const parts = key.split(".");
    let def = this.attributes;
    for (const part of parts) {
      if (!def) return void 0;
      def = def[part];
    }
    return def;
  }
  /**
   * Regenerate plugin attribute mapping
   * Called when plugin attributes are added or removed
   * @returns {void}
   */
  regeneratePluginMapping() {
    const flatAttrs = flatten(this.attributes, { safe: true });
    const leafKeys = Object.keys(flatAttrs).filter((k) => !k.includes("$$"));
    const objectKeys = this.extractObjectKeys(this.attributes);
    const allKeys = [.../* @__PURE__ */ new Set([...leafKeys, ...objectKeys])];
    const pluginAttributes = [];
    for (const key of allKeys) {
      const attrDef = this.getAttributeDefinition(key);
      if (typeof attrDef === "object" && attrDef !== null && attrDef.__plugin__) {
        pluginAttributes.push({ key, pluginName: attrDef.__plugin__ });
      } else if (typeof attrDef === "string" && this._pluginAttributeMetadata && this._pluginAttributeMetadata[key]) {
        const pluginName = this._pluginAttributeMetadata[key].__plugin__;
        pluginAttributes.push({ key, pluginName });
      }
    }
    const { mapping, reversedMapping } = generatePluginMapping(pluginAttributes);
    this.pluginMap = mapping;
    this.reversedPluginMap = reversedMapping;
    this._pluginAttributes = {};
    for (const { key, pluginName } of pluginAttributes) {
      if (!this._pluginAttributes[pluginName]) {
        this._pluginAttributes[pluginName] = [];
      }
      this._pluginAttributes[pluginName].push(key);
    }
  }
  /**
   * Preprocess attributes to convert nested objects into validator-compatible format
   * @param {Object} attributes - Original attributes
   * @returns {Object} Processed attributes for validator
   */
  preprocessAttributesForValidation(attributes) {
    const processed = {};
    for (const [key, value] of Object.entries(attributes)) {
      if (typeof value === "string") {
        if (value === "ip4" || value.startsWith("ip4|")) {
          processed[key] = value.replace(/^ip4/, "string");
          continue;
        }
        if (value === "ip6" || value.startsWith("ip6|")) {
          processed[key] = value.replace(/^ip6/, "string");
          continue;
        }
        if (value === "money" || value.startsWith("money:") || value.startsWith("money|") || value === "crypto" || value.startsWith("crypto:") || value.startsWith("crypto|")) {
          const rest = value.replace(/^(?:money|crypto)(?::\d+)?/, "");
          const hasMin = rest.includes("min:");
          processed[key] = hasMin ? `number${rest}` : `number|min:0${rest}`;
          continue;
        }
        if (value === "decimal" || value.startsWith("decimal:") || value.startsWith("decimal|")) {
          const rest = value.replace(/^decimal(:\d+)?/, "");
          processed[key] = `number${rest}`;
          continue;
        }
        if (value.startsWith("geo:lat")) {
          const rest = value.replace(/^geo:lat(:\d+)?/, "");
          const hasMin = rest.includes("min:");
          const hasMax = rest.includes("max:");
          let validation = "number";
          if (!hasMin) validation += "|min:-90";
          if (!hasMax) validation += "|max:90";
          processed[key] = validation + rest;
          continue;
        }
        if (value.startsWith("geo:lon")) {
          const rest = value.replace(/^geo:lon(:\d+)?/, "");
          const hasMin = rest.includes("min:");
          const hasMax = rest.includes("max:");
          let validation = "number";
          if (!hasMin) validation += "|min:-180";
          if (!hasMax) validation += "|max:180";
          processed[key] = validation + rest;
          continue;
        }
        if (value.startsWith("geo:point")) {
          processed[key] = "any";
          continue;
        }
        if (value.startsWith("embedding:")) {
          const lengthMatch = value.match(/embedding:(\d+)/);
          if (lengthMatch) {
            const length = lengthMatch[1];
            const rest = value.substring(`embedding:${length}`.length);
            processed[key] = `array|items:number|length:${length}|empty:false${rest}`;
            continue;
          }
        }
        if (value.startsWith("embedding|") || value === "embedding") {
          processed[key] = value.replace(/^embedding/, "array|items:number|empty:false");
          continue;
        }
        processed[key] = value;
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        const hasValidatorType = value.type !== void 0 && key !== "$$type";
        if (hasValidatorType) {
          const { __plugin__, __pluginCreated__, ...cleanValue } = value;
          if (cleanValue.type === "ip4") {
            processed[key] = { ...cleanValue, type: "string" };
          } else if (cleanValue.type === "ip6") {
            processed[key] = { ...cleanValue, type: "string" };
          } else if (cleanValue.type === "money" || cleanValue.type === "crypto") {
            processed[key] = { ...cleanValue, type: "number", min: cleanValue.min !== void 0 ? cleanValue.min : 0 };
          } else if (cleanValue.type === "decimal") {
            processed[key] = { ...cleanValue, type: "number" };
          } else if (cleanValue.type === "geo:lat" || cleanValue.type === "geo-lat") {
            processed[key] = {
              ...cleanValue,
              type: "number",
              min: cleanValue.min !== void 0 ? cleanValue.min : -90,
              max: cleanValue.max !== void 0 ? cleanValue.max : 90
            };
          } else if (cleanValue.type === "geo:lon" || cleanValue.type === "geo-lon") {
            processed[key] = {
              ...cleanValue,
              type: "number",
              min: cleanValue.min !== void 0 ? cleanValue.min : -180,
              max: cleanValue.max !== void 0 ? cleanValue.max : 180
            };
          } else if (cleanValue.type === "geo:point" || cleanValue.type === "geo-point") {
            processed[key] = { ...cleanValue, type: "any" };
          } else if (cleanValue.type === "object" && cleanValue.properties) {
            processed[key] = {
              ...cleanValue,
              properties: this.preprocessAttributesForValidation(cleanValue.properties)
            };
          } else {
            processed[key] = cleanValue;
          }
        } else {
          const isExplicitRequired = value.$$type && value.$$type.includes("required");
          const isExplicitOptional = value.$$type && value.$$type.includes("optional");
          const objectConfig = {
            type: "object",
            properties: this.preprocessAttributesForValidation(value),
            strict: false
          };
          if (isExplicitRequired) ; else if (isExplicitOptional || this.allNestedObjectsOptional) {
            objectConfig.optional = true;
          }
          processed[key] = objectConfig;
        }
      } else {
        processed[key] = value;
      }
    }
    return processed;
  }
}

class ResourceIdsReader extends EventEmitter {
  constructor({ resource }) {
    super();
    this.resource = resource;
    this.client = resource.client;
    this.stream = new ReadableStream({
      highWaterMark: this.client.parallelism * 3,
      start: this._start.bind(this),
      pull: this._pull.bind(this),
      cancel: this._cancel.bind(this)
    });
  }
  build() {
    return this.stream.getReader();
  }
  async _start(controller) {
    this.controller = controller;
    this.continuationToken = null;
    this.closeNextIteration = false;
  }
  async _pull(controller) {
    if (this.closeNextIteration) {
      controller.close();
      return;
    }
    const response = await this.client.listObjects({
      prefix: `resource=${this.resource.name}`,
      continuationToken: this.continuationToken
    });
    const keys = response?.Contents.map((x) => x.Key).map((x) => x.replace(this.client.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x).map((x) => x.replace(`resource=${this.resource.name}/id=`, ""));
    this.continuationToken = response.NextContinuationToken;
    this.enqueue(keys);
    if (!response.IsTruncated) this.closeNextIteration = true;
  }
  enqueue(ids) {
    ids.forEach((key) => {
      this.controller.enqueue(key);
      this.emit("id", key);
    });
  }
  _cancel(reason) {
  }
}

class ResourceIdsPageReader extends ResourceIdsReader {
  enqueue(ids) {
    this.controller.enqueue(ids);
    this.emit("page", ids);
  }
}

class ResourceReader extends EventEmitter {
  constructor({ resource, batchSize = 10, concurrency = 5 }) {
    super();
    if (!resource) {
      throw new StreamError("Resource is required for ResourceReader", {
        operation: "constructor",
        resource: resource?.name,
        suggestion: "Pass a valid Resource instance when creating ResourceReader"
      });
    }
    this.resource = resource;
    this.client = resource.client;
    this.batchSize = batchSize;
    this.concurrency = concurrency;
    this.input = new ResourceIdsPageReader({ resource: this.resource });
    this.transform = new Transform({
      objectMode: true,
      transform: this._transform.bind(this)
    });
    this.input.on("data", (chunk) => {
      this.transform.write(chunk);
    });
    this.input.on("end", () => {
      this.transform.end();
    });
    this.input.on("error", (error) => {
      this.emit("error", error);
    });
    this.transform.on("data", (data) => {
      this.emit("data", data);
    });
    this.transform.on("end", () => {
      this.emit("end");
    });
    this.transform.on("error", (error) => {
      this.emit("error", error);
    });
  }
  build() {
    return this;
  }
  async _transform(chunk, encoding, callback) {
    const [ok, err] = await tryFn(async () => {
      await PromisePool.for(chunk).withConcurrency(this.concurrency).handleError(async (error, content) => {
        this.emit("error", error, content);
      }).process(async (id) => {
        const data = await this.resource.get(id);
        this.push(data);
        return data;
      });
    });
    callback(err);
  }
  resume() {
    this.input.resume();
  }
}

class ResourceWriter extends EventEmitter {
  constructor({ resource, batchSize = 10, concurrency = 5 }) {
    super();
    this.resource = resource;
    this.client = resource.client;
    this.batchSize = batchSize;
    this.concurrency = concurrency;
    this.buffer = [];
    this.writing = false;
    this.writable = new Writable({
      objectMode: true,
      write: this._write.bind(this)
    });
    this.writable.on("finish", () => {
      this.emit("finish");
    });
    this.writable.on("error", (error) => {
      this.emit("error", error);
    });
  }
  build() {
    return this;
  }
  write(chunk) {
    this.buffer.push(chunk);
    this._maybeWrite().catch((error) => {
      this.emit("error", error);
    });
    return true;
  }
  end() {
    this.ended = true;
    this._maybeWrite().catch((error) => {
      this.emit("error", error);
    });
  }
  async _maybeWrite() {
    if (this.writing) return;
    if (this.buffer.length === 0 && !this.ended) return;
    this.writing = true;
    while (this.buffer.length > 0) {
      const batch = this.buffer.splice(0, this.batchSize);
      const [ok, err] = await tryFn(async () => {
        await PromisePool.for(batch).withConcurrency(this.concurrency).handleError(async (error, content) => {
          this.emit("error", error, content);
        }).process(async (item) => {
          const [ok2, err2, result] = await tryFn(async () => {
            const res = await this.resource.insert(item);
            return res;
          });
          if (!ok2) {
            this.emit("error", err2, item);
            return null;
          }
          return result;
        });
      });
      if (!ok) {
        this.emit("error", err);
      }
    }
    this.writing = false;
    if (this.ended) {
      this.writable.emit("finish");
    }
  }
  async _write(chunk, encoding, callback) {
    callback();
  }
}

function streamToString(stream) {
  return new Promise((resolve, reject) => {
    if (!stream) {
      return reject(new StreamError("Stream is undefined", {
        operation: "streamToString",
        suggestion: "Ensure a valid stream is passed to streamToString()"
      }));
    }
    const chunks = [];
    stream.on("data", (chunk) => chunks.push(chunk));
    stream.on("error", reject);
    stream.on("end", () => resolve(Buffer.concat(chunks).toString("utf-8")));
  });
}

const S3_METADATA_LIMIT_BYTES = 2047;
async function handleInsert$4({ resource, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on insert", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "insert"
    });
  }
  return { mappedData, body: "" };
}
async function handleUpdate$4({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on update", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "update",
      id
    });
  }
  return { mappedData, body: JSON.stringify(mappedData) };
}
async function handleUpsert$4({ resource, id, data, mappedData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on upsert", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "upsert",
      id
    });
  }
  return { mappedData, body: "" };
}
async function handleGet$4({ resource, metadata, body }) {
  return { metadata, body };
}

var enforceLimits = /*#__PURE__*/Object.freeze({
  __proto__: null,
  S3_METADATA_LIMIT_BYTES: S3_METADATA_LIMIT_BYTES,
  handleGet: handleGet$4,
  handleInsert: handleInsert$4,
  handleUpdate: handleUpdate$4,
  handleUpsert: handleUpsert$4
});

async function handleInsert$3({ resource, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "insert",
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
    const metadataOnly = { _v: mappedData._v };
    if (resource.schema?.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
      metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
    }
    return { mappedData: metadataOnly, body: JSON.stringify(mappedData) };
  }
  return { mappedData, body: "" };
}
async function handleUpdate$3({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "update",
      id,
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
  }
  return { mappedData, body: JSON.stringify(data) };
}
async function handleUpsert$3({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "upsert",
      id,
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
  }
  return { mappedData, body: JSON.stringify(data) };
}
async function handleGet$3({ resource, metadata, body }) {
  if (body && body.trim() !== "") {
    const [ok, error, result] = tryFn(() => {
      const bodyData = JSON.parse(body);
      return {
        metadata: {
          ...bodyData,
          ...metadata
        },
        body
      };
    });
    if (ok) {
      return result;
    } else {
      return { metadata, body };
    }
  }
  return { metadata, body };
}

var userManaged = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$3,
  handleInsert: handleInsert$3,
  handleUpdate: handleUpdate$3,
  handleUpsert: handleUpsert$3
});

const TRUNCATED_FLAG = "$truncated";
const TRUNCATED_FLAG_VALUE = "true";
const TRUNCATED_FLAG_BYTES = calculateUTF8Bytes(TRUNCATED_FLAG) + calculateUTF8Bytes(TRUNCATED_FLAG_VALUE);
async function handleInsert$2({ resource, data, mappedData, originalData }) {
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  const attributeSizes = calculateAttributeSizes(mappedData);
  const sortedFields = Object.entries(attributeSizes).sort(([, a], [, b]) => a - b);
  const resultFields = {};
  let currentSize = 0;
  let truncated = false;
  if (mappedData._v) {
    resultFields._v = mappedData._v;
    currentSize += attributeSizes._v;
  }
  for (const [fieldName, size] of sortedFields) {
    if (fieldName === "_v") continue;
    const fieldValue = mappedData[fieldName];
    const spaceNeeded = size + (truncated ? 0 : TRUNCATED_FLAG_BYTES);
    if (currentSize + spaceNeeded <= effectiveLimit) {
      resultFields[fieldName] = fieldValue;
      currentSize += size;
    } else {
      const availableSpace = effectiveLimit - currentSize - (truncated ? 0 : TRUNCATED_FLAG_BYTES);
      if (availableSpace > 0) {
        const truncatedValue = truncateValue(fieldValue, availableSpace);
        resultFields[fieldName] = truncatedValue;
        truncated = true;
        currentSize += calculateUTF8Bytes(truncatedValue);
      } else {
        resultFields[fieldName] = "";
        truncated = true;
      }
      break;
    }
  }
  let finalSize = calculateTotalSize(resultFields) + (truncated ? TRUNCATED_FLAG_BYTES : 0);
  while (finalSize > effectiveLimit) {
    const fieldNames = Object.keys(resultFields).filter((f) => f !== "_v" && f !== "$truncated");
    if (fieldNames.length === 0) {
      break;
    }
    const lastField = fieldNames[fieldNames.length - 1];
    resultFields[lastField] = "";
    finalSize = calculateTotalSize(resultFields) + TRUNCATED_FLAG_BYTES;
    truncated = true;
  }
  if (truncated) {
    resultFields[TRUNCATED_FLAG] = TRUNCATED_FLAG_VALUE;
  }
  return { mappedData: resultFields, body: "" };
}
async function handleUpdate$2({ resource, id, data, mappedData, originalData }) {
  return handleInsert$2({ resource, data, mappedData, originalData });
}
async function handleUpsert$2({ resource, id, data, mappedData }) {
  return handleInsert$2({ resource, data, mappedData });
}
async function handleGet$2({ resource, metadata, body }) {
  return { metadata, body };
}
function truncateValue(value, maxBytes) {
  if (typeof value === "string") {
    return truncateString(value, maxBytes);
  } else if (typeof value === "object" && value !== null) {
    const jsonStr = JSON.stringify(value);
    return truncateString(jsonStr, maxBytes);
  } else {
    const stringValue = String(value);
    return truncateString(stringValue, maxBytes);
  }
}
function truncateString(str, maxBytes) {
  const encoder = new TextEncoder();
  let bytes = encoder.encode(str);
  if (bytes.length <= maxBytes) {
    return str;
  }
  let length = str.length;
  while (length > 0) {
    const truncated = str.substring(0, length);
    bytes = encoder.encode(truncated);
    if (bytes.length <= maxBytes) {
      return truncated;
    }
    length--;
  }
  return "";
}

var dataTruncate = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$2,
  handleInsert: handleInsert$2,
  handleUpdate: handleUpdate$2,
  handleUpsert: handleUpsert$2
});

const OVERFLOW_FLAG = "$overflow";
const OVERFLOW_FLAG_VALUE = "true";
const OVERFLOW_FLAG_BYTES = calculateUTF8Bytes(OVERFLOW_FLAG) + calculateUTF8Bytes(OVERFLOW_FLAG_VALUE);
async function handleInsert$1({ resource, data, mappedData, originalData }) {
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  const attributeSizes = calculateAttributeSizes(mappedData);
  const sortedFields = Object.entries(attributeSizes).sort(([, a], [, b]) => a - b);
  const metadataFields = {};
  const bodyFields = {};
  let currentSize = 0;
  let willOverflow = false;
  if (mappedData._v) {
    metadataFields._v = mappedData._v;
    currentSize += attributeSizes._v;
  }
  if (resource.schema?.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    const pluginMapStr = JSON.stringify(resource.schema.pluginMap);
    const pluginMapSize = calculateUTF8Bytes("_pluginMap") + calculateUTF8Bytes(pluginMapStr);
    metadataFields._pluginMap = pluginMapStr;
    currentSize += pluginMapSize;
  }
  let reservedLimit = effectiveLimit;
  for (const [fieldName, size] of sortedFields) {
    if (fieldName === "_v") continue;
    if (!willOverflow && currentSize + size > effectiveLimit) {
      reservedLimit -= OVERFLOW_FLAG_BYTES;
      willOverflow = true;
    }
    if (!willOverflow && currentSize + size <= reservedLimit) {
      metadataFields[fieldName] = mappedData[fieldName];
      currentSize += size;
    } else {
      bodyFields[fieldName] = mappedData[fieldName];
      willOverflow = true;
    }
  }
  if (willOverflow) {
    metadataFields[OVERFLOW_FLAG] = OVERFLOW_FLAG_VALUE;
  }
  const hasOverflow = Object.keys(bodyFields).length > 0;
  let body = hasOverflow ? JSON.stringify(bodyFields) : "";
  return { mappedData: metadataFields, body };
}
async function handleUpdate$1({ resource, id, data, mappedData, originalData }) {
  return handleInsert$1({ resource, data, mappedData, originalData });
}
async function handleUpsert$1({ resource, id, data, mappedData }) {
  return handleInsert$1({ resource, data, mappedData });
}
async function handleGet$1({ resource, metadata, body }) {
  let bodyData = {};
  if (body && body.trim() !== "") {
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(body));
    if (ok) {
      bodyData = parsed;
    } else {
      bodyData = {};
    }
  }
  const mergedData = {
    ...bodyData,
    ...metadata
  };
  delete mergedData.$overflow;
  return { metadata: mergedData, body };
}

var bodyOverflow = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$1,
  handleInsert: handleInsert$1,
  handleUpdate: handleUpdate$1,
  handleUpsert: handleUpsert$1
});

async function handleInsert({ resource, data, mappedData }) {
  const metadataOnly = {
    "_v": mappedData._v || String(resource.version)
  };
  metadataOnly._map = JSON.stringify(resource.schema.map);
  if (resource.schema.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
  }
  const body = JSON.stringify(mappedData);
  return { mappedData: metadataOnly, body };
}
async function handleUpdate({ resource, id, data, mappedData }) {
  const metadataOnly = {
    "_v": mappedData._v || String(resource.version)
  };
  metadataOnly._map = JSON.stringify(resource.schema.map);
  if (resource.schema.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
  }
  const body = JSON.stringify(mappedData);
  return { mappedData: metadataOnly, body };
}
async function handleUpsert({ resource, id, data, mappedData }) {
  return handleInsert({ resource, data, mappedData });
}
async function handleGet({ resource, metadata, body }) {
  let bodyData = {};
  if (body && body.trim() !== "") {
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(body));
    if (ok) {
      bodyData = parsed;
    } else {
      bodyData = {};
    }
  }
  const mergedData = {
    ...bodyData,
    ...metadata
    // metadata contains _v
  };
  return { metadata: mergedData, body };
}

var bodyOnly = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet,
  handleInsert: handleInsert,
  handleUpdate: handleUpdate,
  handleUpsert: handleUpsert
});

const behaviors = {
  "user-managed": userManaged,
  "enforce-limits": enforceLimits,
  "truncate-data": dataTruncate,
  "body-overflow": bodyOverflow,
  "body-only": bodyOnly
};
function getBehavior(behaviorName) {
  const behavior = behaviors[behaviorName];
  if (!behavior) {
    throw new BehaviorError(`Unknown behavior: ${behaviorName}`, {
      behavior: behaviorName,
      availableBehaviors: Object.keys(behaviors),
      operation: "getBehavior"
    });
  }
  return behavior;
}
const AVAILABLE_BEHAVIORS = Object.keys(behaviors);
const DEFAULT_BEHAVIOR = "user-managed";

class Resource extends AsyncEventEmitter {
  /**
   * Create a new Resource instance
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.client - S3 client instance
   * @param {string} [config.version='v1'] - Resource version
   * @param {Object} [config.attributes={}] - Resource attributes schema
   * @param {string} [config.behavior='user-managed'] - Resource behavior strategy
   * @param {string} [config.passphrase='secret'] - Encryption passphrase (for 'secret' type)
   * @param {number} [config.bcryptRounds=10] - Bcrypt rounds (for 'password' type)
   * @param {number} [config.parallelism=10] - Parallelism for bulk operations
   * @param {Array} [config.observers=[]] - Observer instances
   * @param {boolean} [config.cache=false] - Enable caching
   * @param {boolean} [config.autoDecrypt=true] - Auto-decrypt secret fields
   * @param {boolean} [config.timestamps=false] - Enable automatic timestamps
   * @param {Object} [config.partitions={}] - Partition definitions
   * @param {boolean} [config.paranoid=true] - Security flag for dangerous operations
   * @param {boolean} [config.allNestedObjectsOptional=false] - Make nested objects optional
   * @param {Object} [config.hooks={}] - Custom hooks
   * @param {Object} [config.options={}] - Additional options
   * @param {Function} [config.idGenerator] - Custom ID generator function
   * @param {number} [config.idSize=22] - Size for auto-generated IDs
   * @param {boolean} [config.versioningEnabled=false] - Enable versioning for this resource
   * @param {Object} [config.events={}] - Event listeners to automatically add
   * @param {boolean} [config.asyncEvents=true] - Whether events should be emitted asynchronously
   * @example
   * const users = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: {
   *     name: 'string|required',
   *     email: 'string|required',
   *     password: 'secret|required'
   *   },
   *   behavior: 'user-managed',
   *   passphrase: 'my-secret-key',
   *   timestamps: true,
   *   partitions: {
   *     byRegion: {
   *       fields: { region: 'string' }
   *     }
   *   },
   *   hooks: {
   *     beforeInsert: [async (data) => {
      *       return data;
   *     }]
   *   },
   *   events: {
   *     insert: (ev) => console.log('Inserted:', ev.id),
   *     update: [
   *       (ev) => console.warn('Update detected'),
   *       (ev) => console.log('Updated:', ev.id)
   *     ],
   *     delete: (ev) => console.log('Deleted:', ev.id)
   *   }
   * });
   * 
   * // With custom ID size
   * const shortIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idSize: 8 // Generate 8-character IDs
   * });
   * 
   * // With custom ID generator function
   * const customIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idGenerator: () => `user_${Date.now()}_${Math.random().toString(36).substr(2, 5)}`
   * });
   * 
   * // With custom ID generator using size parameter
   * const longIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idGenerator: 32 // Generate 32-character IDs (same as idSize: 32)
   * });
   */
  constructor(config = {}) {
    super();
    this._instanceId = idGenerator(7);
    const validation = validateResourceConfig(config);
    if (!validation.isValid) {
      const errorDetails = validation.errors.map((err) => `  \u2022 ${err}`).join("\n");
      throw new ResourceError(
        `Invalid Resource ${config.name || "[unnamed]"} configuration:
${errorDetails}`,
        {
          resourceName: config.name,
          validation: validation.errors
        }
      );
    }
    const {
      name,
      client,
      version = "1",
      attributes = {},
      behavior = DEFAULT_BEHAVIOR,
      passphrase = "secret",
      bcryptRounds = 10,
      parallelism = 10,
      observers = [],
      cache = false,
      autoDecrypt = true,
      timestamps = false,
      partitions = {},
      paranoid = true,
      allNestedObjectsOptional = true,
      hooks = {},
      idGenerator: customIdGenerator,
      idSize = 22,
      versioningEnabled = false,
      strictValidation = true,
      events = {},
      asyncEvents = true,
      asyncPartitions = true,
      strictPartitions = false,
      createdBy = "user",
      guard
    } = config;
    this.name = name;
    this.client = client;
    this.version = version;
    this.behavior = behavior;
    this.observers = observers;
    this.parallelism = parallelism;
    this.passphrase = passphrase ?? "secret";
    this.bcryptRounds = bcryptRounds;
    this.versioningEnabled = versioningEnabled;
    this.strictValidation = strictValidation;
    this.setAsyncMode(asyncEvents);
    this.idGenerator = this.configureIdGenerator(customIdGenerator, idSize);
    if (typeof customIdGenerator === "number" && customIdGenerator > 0) {
      this.idSize = customIdGenerator;
    } else if (typeof idSize === "number" && idSize > 0) {
      this.idSize = idSize;
    } else {
      this.idSize = 22;
    }
    this.idGeneratorType = this.getIdGeneratorType(customIdGenerator, this.idSize);
    this.config = {
      cache,
      hooks,
      paranoid,
      timestamps,
      partitions,
      autoDecrypt,
      allNestedObjectsOptional,
      asyncEvents,
      asyncPartitions,
      strictPartitions,
      createdBy
    };
    this.$schema = cloneDeep(config);
    this.$schema._createdAt = Date.now();
    this.$schema._updatedAt = Date.now();
    this.hooks = {
      // Insert hooks
      beforeInsert: [],
      afterInsert: [],
      // Update hooks
      beforeUpdate: [],
      afterUpdate: [],
      // Delete hooks
      beforeDelete: [],
      afterDelete: [],
      // Get hooks
      beforeGet: [],
      afterGet: [],
      // List hooks
      beforeList: [],
      afterList: [],
      // Query hooks
      beforeQuery: [],
      afterQuery: [],
      // Patch hooks
      beforePatch: [],
      afterPatch: [],
      // Replace hooks
      beforeReplace: [],
      afterReplace: [],
      // Exists hooks
      beforeExists: [],
      afterExists: [],
      // Count hooks
      beforeCount: [],
      afterCount: [],
      // GetMany hooks
      beforeGetMany: [],
      afterGetMany: [],
      // DeleteMany hooks
      beforeDeleteMany: [],
      afterDeleteMany: []
    };
    this.attributes = attributes || {};
    this.map = config.map;
    this.applyConfiguration({ map: this.map });
    if (hooks) {
      for (const [event, hooksArr] of Object.entries(hooks)) {
        if (Array.isArray(hooksArr) && this.hooks[event]) {
          for (const fn of hooksArr) {
            if (typeof fn === "function") {
              this.hooks[event].push(fn.bind(this));
            }
          }
        }
      }
    }
    if (events && Object.keys(events).length > 0) {
      for (const [eventName, listeners] of Object.entries(events)) {
        if (Array.isArray(listeners)) {
          for (const listener of listeners) {
            if (typeof listener === "function") {
              this.on(eventName, listener.bind(this));
            }
          }
        } else if (typeof listeners === "function") {
          this.on(eventName, listeners.bind(this));
        }
      }
    }
    this.guard = this._normalizeGuard(guard);
    this._initMiddleware();
  }
  /**
   * Configure ID generator based on provided options
   * @param {Function|number} customIdGenerator - Custom ID generator function or size
   * @param {number} idSize - Size for auto-generated IDs
   * @returns {Function} Configured ID generator function
   * @private
   */
  configureIdGenerator(customIdGenerator, idSize) {
    if (typeof customIdGenerator === "function") {
      return () => String(customIdGenerator());
    }
    if (typeof customIdGenerator === "number" && customIdGenerator > 0) {
      return createCustomGenerator(getUrlAlphabet(), customIdGenerator);
    }
    if (typeof idSize === "number" && idSize > 0 && idSize !== 22) {
      return createCustomGenerator(getUrlAlphabet(), idSize);
    }
    return idGenerator;
  }
  /**
   * Get a serializable representation of the ID generator type
   * @param {Function|number} customIdGenerator - Custom ID generator function or size
   * @param {number} idSize - Size for auto-generated IDs
   * @returns {string|number} Serializable ID generator type
   * @private
   */
  getIdGeneratorType(customIdGenerator, idSize) {
    if (typeof customIdGenerator === "function") {
      return "custom_function";
    }
    return idSize;
  }
  export() {
    const exported = this.schema.export();
    exported.behavior = this.behavior;
    exported.timestamps = this.config.timestamps;
    exported.partitions = this.config.partitions || {};
    exported.paranoid = this.config.paranoid;
    exported.allNestedObjectsOptional = this.config.allNestedObjectsOptional;
    exported.autoDecrypt = this.config.autoDecrypt;
    exported.cache = this.config.cache;
    exported.hooks = this.hooks;
    exported.map = this.map;
    return exported;
  }
  /**
   * Apply configuration settings (timestamps, partitions, hooks)
   * This method ensures that all configuration-dependent features are properly set up
   */
  applyConfiguration({ map } = {}) {
    if (this.config.timestamps) {
      if (!this.attributes.createdAt) {
        this.attributes.createdAt = "string|optional";
      }
      if (!this.attributes.updatedAt) {
        this.attributes.updatedAt = "string|optional";
      }
      if (!this.config.partitions) {
        this.config.partitions = {};
      }
      if (!this.config.partitions.byCreatedDate) {
        this.config.partitions.byCreatedDate = {
          fields: {
            createdAt: "date|maxlength:10"
          }
        };
      }
      if (!this.config.partitions.byUpdatedDate) {
        this.config.partitions.byUpdatedDate = {
          fields: {
            updatedAt: "date|maxlength:10"
          }
        };
      }
    }
    this.setupPartitionHooks();
    if (this.versioningEnabled) {
      if (!this.config.partitions.byVersion) {
        this.config.partitions.byVersion = {
          fields: {
            _v: "string"
          }
        };
      }
    }
    this.schema = new Schema({
      name: this.name,
      attributes: this.attributes,
      passphrase: this.passphrase,
      bcryptRounds: this.bcryptRounds,
      version: this.version,
      options: {
        autoDecrypt: this.config.autoDecrypt,
        allNestedObjectsOptional: this.config.allNestedObjectsOptional
      },
      map: map || this.map
    });
    this.validatePartitions();
  }
  /**
   * Update resource attributes and rebuild schema
   * @param {Object} newAttributes - New attributes definition
   */
  updateAttributes(newAttributes) {
    const oldAttributes = this.attributes;
    this.attributes = newAttributes;
    this.applyConfiguration();
    return { oldAttributes, newAttributes };
  }
  /**
   * Add a plugin-created attribute to the resource schema
   * This ensures plugin attributes don't interfere with user-defined attributes
   * by using a separate mapping namespace (p0, p1, p2, ...)
   *
   * @param {string} name - Attribute name (e.g., '_hasEmbedding', 'clusterId')
   * @param {Object|string} definition - Attribute definition
   * @param {string} pluginName - Name of plugin adding the attribute
   * @returns {void}
   *
   * @example
   * // VectorPlugin adding tracking field
   * resource.addPluginAttribute('_hasEmbedding', {
   *   type: 'boolean',
   *   optional: true,
   *   default: false
   * }, 'VectorPlugin');
   *
   * // Shorthand notation
   * resource.addPluginAttribute('clusterId', 'string|optional', 'VectorPlugin');
   */
  addPluginAttribute(name, definition, pluginName) {
    if (!pluginName) {
      throw new ResourceError(
        "Plugin name is required when adding plugin attributes",
        { resource: this.name, attribute: name }
      );
    }
    const existingDef = this.schema.getAttributeDefinition(name);
    if (existingDef && (!existingDef.__plugin__ || existingDef.__plugin__ !== pluginName)) {
      throw new ResourceError(
        `Attribute '${name}' already exists and is not from plugin '${pluginName}'`,
        { resource: this.name, attribute: name, plugin: pluginName }
      );
    }
    let defObject = definition;
    if (typeof definition === "object" && definition !== null) {
      defObject = { ...definition };
    }
    if (typeof defObject === "object" && defObject !== null) {
      defObject.__plugin__ = pluginName;
      defObject.__pluginCreated__ = Date.now();
    }
    this.schema.attributes[name] = defObject;
    this.attributes[name] = defObject;
    if (typeof defObject === "string") {
      if (!this.schema._pluginAttributeMetadata) {
        this.schema._pluginAttributeMetadata = {};
      }
      this.schema._pluginAttributeMetadata[name] = {
        __plugin__: pluginName,
        __pluginCreated__: Date.now()
      };
    }
    this.schema.regeneratePluginMapping();
    if (this.schema.options.generateAutoHooks) {
      this.schema.generateAutoHooks();
    }
    const processedAttributes = this.schema.preprocessAttributesForValidation(this.schema.attributes);
    this.schema.validator = new ValidatorManager({ autoEncrypt: false }).compile(merge(
      { $$async: true, $$strict: false },
      processedAttributes
    ));
    if (this.database) {
      this.database.emit("plugin-attribute-added", {
        resource: this.name,
        attribute: name,
        plugin: pluginName,
        definition: defObject
      });
    }
  }
  /**
   * Remove a plugin-created attribute from the resource schema
   * Called when a plugin is uninstalled or no longer needs the attribute
   *
   * @param {string} name - Attribute name to remove
   * @param {string} [pluginName] - Optional plugin name for safety check
   * @returns {boolean} True if attribute was removed, false if not found
   *
   * @example
   * resource.removePluginAttribute('_hasEmbedding', 'VectorPlugin');
   */
  removePluginAttribute(name, pluginName = null) {
    const attrDef = this.schema.getAttributeDefinition(name);
    const metadata = this.schema._pluginAttributeMetadata?.[name];
    const isPluginAttr = typeof attrDef === "object" && attrDef?.__plugin__ || metadata;
    if (!attrDef || !isPluginAttr) {
      return false;
    }
    const actualPlugin = attrDef?.__plugin__ || metadata?.__plugin__;
    if (pluginName && actualPlugin !== pluginName) {
      throw new ResourceError(
        `Attribute '${name}' belongs to plugin '${actualPlugin}', not '${pluginName}'`,
        { resource: this.name, attribute: name, actualPlugin, requestedPlugin: pluginName }
      );
    }
    delete this.schema.attributes[name];
    delete this.attributes[name];
    if (this.schema._pluginAttributeMetadata?.[name]) {
      delete this.schema._pluginAttributeMetadata[name];
    }
    this.schema.regeneratePluginMapping();
    if (this.database) {
      this.database.emit("plugin-attribute-removed", {
        resource: this.name,
        attribute: name,
        plugin: actualPlugin
      });
    }
    return true;
  }
  /**
   * Add a hook function for a specific event
   * @param {string} event - Hook event (beforeInsert, afterInsert, etc.)
   * @param {Function} fn - Hook function
   */
  addHook(event, fn) {
    if (this.hooks[event]) {
      this.hooks[event].push(fn.bind(this));
    }
  }
  /**
   * Execute hooks for a specific event
   * @param {string} event - Hook event
   * @param {*} data - Data to pass to hooks
   * @returns {*} Modified data
   */
  async executeHooks(event, data) {
    if (!this.hooks[event]) return data;
    let result = data;
    for (const hook of this.hooks[event]) {
      result = await hook(result);
    }
    return result;
  }
  /**
   * Setup automatic partition hooks
   */
  setupPartitionHooks() {
    if (!this.config.partitions) {
      return;
    }
    const partitions = this.config.partitions;
    if (Object.keys(partitions).length === 0) {
      return;
    }
    if (!this.hooks.afterInsert) {
      this.hooks.afterInsert = [];
    }
    this.hooks.afterInsert.push(async (data) => {
      await this.createPartitionReferences(data);
      return data;
    });
    if (!this.hooks.afterDelete) {
      this.hooks.afterDelete = [];
    }
    this.hooks.afterDelete.push(async (data) => {
      await this.deletePartitionReferences(data);
      return data;
    });
  }
  /**
   * Validate data against resource schema without saving
   * @param {Object} data - Data to validate
   * @param {Object} options - Validation options
   * @param {boolean} options.throwOnError - Throw error if validation fails (default: false)
   * @param {boolean} options.includeId - Include ID validation (default: false)
   * @param {boolean} options.mutateOriginal - Allow mutation of original data (default: false)
   * @returns {Promise<{valid: boolean, isValid: boolean, errors: Array, data: Object, original: Object}>} Validation result
   * @example
   * // Validate before insert
   * const result = await resource.validate({
   *   name: 'John Doe',
   *   email: 'invalid-email' // Will fail email validation
   * });
   *
   * if (!result.valid) {
   *   console.log('Validation errors:', result.errors);
   *   // [{ field: 'email', message: '...', ... }]
   * }
   *
   * // Throw on error
   * try {
   *   await resource.validate({ email: 'bad' }, { throwOnError: true });
   * } catch (err) {
   *   console.log('Validation failed:', err.message);
   * }
   */
  async validate(data, options = {}) {
    const {
      throwOnError = false,
      includeId = false,
      mutateOriginal = false
    } = options;
    const dataToValidate = mutateOriginal ? data : cloneDeep(data);
    if (!includeId && dataToValidate.id) {
      delete dataToValidate.id;
    }
    const result = {
      original: cloneDeep(data),
      isValid: false,
      errors: [],
      data: dataToValidate
    };
    try {
      const check = await this.schema.validate(dataToValidate, { mutateOriginal });
      if (check === true) {
        result.isValid = true;
      } else {
        result.errors = Array.isArray(check) ? check : [check];
        result.isValid = false;
        if (throwOnError) {
          const error = new Error("Validation failed");
          error.validationErrors = result.errors;
          error.invalidData = data;
          throw error;
        }
      }
    } catch (err) {
      if (!throwOnError) {
        result.errors = [{ message: err.message, error: err }];
        result.isValid = false;
      } else {
        throw err;
      }
    }
    return result;
  }
  /**
   * Validate that all partition fields exist in current resource attributes
   * @throws {Error} If partition fields don't exist in current schema (only when strictValidation is true)
   */
  validatePartitions() {
    if (!this.strictValidation) {
      return;
    }
    if (!this.config.partitions) {
      return;
    }
    const partitions = this.config.partitions;
    if (Object.keys(partitions).length === 0) {
      return;
    }
    const currentAttributes = Object.keys(this.attributes || {});
    for (const [partitionName, partitionDef] of Object.entries(partitions)) {
      if (!partitionDef.fields) {
        continue;
      }
      for (const fieldName of Object.keys(partitionDef.fields)) {
        if (!this.fieldExistsInAttributes(fieldName)) {
          throw new PartitionError(`Partition '${partitionName}' uses field '${fieldName}' which does not exist in resource attributes. Available fields: ${currentAttributes.join(", ")}.`, { resourceName: this.name, partitionName, fieldName, availableFields: currentAttributes, operation: "validatePartitions" });
        }
      }
    }
  }
  /**
   * Check if a field (including nested fields) exists in the current attributes
   * @param {string} fieldName - Field name (can be nested like 'utm.source')
   * @returns {boolean} True if field exists
   */
  fieldExistsInAttributes(fieldName) {
    if (fieldName.startsWith("_")) {
      return true;
    }
    if (!fieldName.includes(".")) {
      return Object.keys(this.attributes || {}).includes(fieldName);
    }
    const keys = fieldName.split(".");
    let currentLevel = this.attributes || {};
    for (const key of keys) {
      if (!currentLevel || typeof currentLevel !== "object" || !(key in currentLevel)) {
        return false;
      }
      currentLevel = currentLevel[key];
    }
    return true;
  }
  /**
   * Find orphaned partitions (partitions that reference non-existent fields)
   * @returns {Object} Object with orphaned partition names as keys and details as values
   * @example
   * const orphaned = resource.findOrphanedPartitions();
   * // Returns: { byRegion: { missingFields: ['region'], definition: {...} } }
   */
  findOrphanedPartitions() {
    const orphaned = {};
    if (!this.config.partitions) {
      return orphaned;
    }
    for (const [partitionName, partitionDef] of Object.entries(this.config.partitions)) {
      if (!partitionDef.fields) {
        continue;
      }
      const missingFields = [];
      for (const fieldName of Object.keys(partitionDef.fields)) {
        if (!this.fieldExistsInAttributes(fieldName)) {
          missingFields.push(fieldName);
        }
      }
      if (missingFields.length > 0) {
        orphaned[partitionName] = {
          missingFields,
          definition: partitionDef,
          allFields: Object.keys(partitionDef.fields)
        };
      }
    }
    return orphaned;
  }
  /**
   * Remove orphaned partitions (partitions that reference non-existent fields)
   * WARNING: This will modify the resource configuration and should be followed by uploadMetadataFile()
   * @param {Object} options - Options
   * @param {boolean} options.dryRun - If true, only returns what would be removed without modifying (default: false)
   * @returns {Object} Object with removed partition names and details
   * @example
   * // Dry run to see what would be removed
   * const toRemove = resource.removeOrphanedPartitions({ dryRun: true });
   * console.log('Would remove:', toRemove);
   *
   * // Actually remove orphaned partitions
   * const removed = resource.removeOrphanedPartitions();
   * await database.uploadMetadataFile(); // Save changes to S3
   */
  removeOrphanedPartitions({ dryRun = false } = {}) {
    const orphaned = this.findOrphanedPartitions();
    if (Object.keys(orphaned).length === 0) {
      return {};
    }
    if (dryRun) {
      return orphaned;
    }
    for (const partitionName of Object.keys(orphaned)) {
      delete this.config.partitions[partitionName];
    }
    this.emit("orphanedPartitionsRemoved", {
      resourceName: this.name,
      removed: Object.keys(orphaned),
      details: orphaned
    });
    return orphaned;
  }
  /**
   * Apply a single partition rule to a field value
   * @param {*} value - The field value
   * @param {string} rule - The partition rule
   * @returns {*} Transformed value
   */
  applyPartitionRule(value, rule) {
    if (value === void 0 || value === null) {
      return value;
    }
    let transformedValue = value;
    if (typeof rule === "string" && rule.includes("maxlength:")) {
      const maxLengthMatch = rule.match(/maxlength:(\d+)/);
      if (maxLengthMatch) {
        const maxLength = parseInt(maxLengthMatch[1]);
        if (typeof transformedValue === "string" && transformedValue.length > maxLength) {
          transformedValue = transformedValue.substring(0, maxLength);
        }
      }
    }
    if (rule.includes("date")) {
      if (transformedValue instanceof Date) {
        transformedValue = transformedValue.toISOString().split("T")[0];
      } else if (typeof transformedValue === "string") {
        if (transformedValue.includes("T") && transformedValue.includes("Z")) {
          transformedValue = transformedValue.split("T")[0];
        } else {
          const date = new Date(transformedValue);
          if (!isNaN(date.getTime())) {
            transformedValue = date.toISOString().split("T")[0];
          }
        }
      }
    }
    return transformedValue;
  }
  /**
   * Get the main resource key (new format without version in path)
   * @param {string} id - Resource ID
   * @returns {string} The main S3 key path
   */
  getResourceKey(id) {
    const key = join("resource=" + this.name, "data", `id=${id}`);
    return key;
  }
  /**
   * Generate partition key for a resource in a specific partition
   * @param {Object} params - Partition key parameters
   * @param {string} params.partitionName - Name of the partition
   * @param {string} params.id - Resource ID
   * @param {Object} params.data - Resource data for partition value extraction
   * @returns {string|null} The partition key path or null if required fields are missing
   * @example
   * const partitionKey = resource.getPartitionKey({
   *   partitionName: 'byUtmSource',
   *   id: 'user-123',
   *   data: { utm: { source: 'google' } }
   * });
   * // Returns: 'resource=users/partition=byUtmSource/utm.source=google/id=user-123'
   * 
   * // Returns null if required field is missing
   * const nullKey = resource.getPartitionKey({
   *   partitionName: 'byUtmSource',
   *   id: 'user-123',
   *   data: { name: 'John' } // Missing utm.source
   * });
   * // Returns: null
   */
  getPartitionKey({ partitionName, id, data }) {
    if (!this.config.partitions || !this.config.partitions[partitionName]) {
      throw new PartitionError(`Partition '${partitionName}' not found`, { resourceName: this.name, partitionName, operation: "getPartitionKey" });
    }
    const partition = this.config.partitions[partitionName];
    const partitionSegments = [];
    const sortedFields = Object.entries(partition.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const fieldValue = this.getNestedFieldValue(data, fieldName);
      const transformedValue = this.applyPartitionRule(fieldValue, rule);
      if (transformedValue === void 0 || transformedValue === null) {
        return null;
      }
      partitionSegments.push(`${fieldName}=${transformedValue}`);
    }
    if (partitionSegments.length === 0) {
      return null;
    }
    const finalId = id || data?.id;
    if (!finalId) {
      return null;
    }
    return join(`resource=${this.name}`, `partition=${partitionName}`, ...partitionSegments, `id=${finalId}`);
  }
  /**
   * Get nested field value from data object using dot notation
   * @param {Object} data - Data object
   * @param {string} fieldPath - Field path (e.g., "utm.source", "address.city")
   * @returns {*} Field value
   */
  getNestedFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data[fieldPath];
    }
    const keys = fieldPath.split(".");
    let currentLevel = data;
    for (const key of keys) {
      if (!currentLevel || typeof currentLevel !== "object" || !(key in currentLevel)) {
        return void 0;
      }
      currentLevel = currentLevel[key];
    }
    return currentLevel;
  }
  /**
   * Calculate estimated content length for body data
   * @param {string|Buffer} body - Body content
   * @returns {number} Estimated content length in bytes
   */
  calculateContentLength(body) {
    if (!body) return 0;
    if (Buffer.isBuffer(body)) return body.length;
    if (typeof body === "string") return Buffer.byteLength(body, "utf8");
    if (typeof body === "object") return Buffer.byteLength(JSON.stringify(body), "utf8");
    return Buffer.byteLength(String(body), "utf8");
  }
  /**
   * Emit standardized events with optional ID-specific variant
   *
   * @private
   * @param {string} event - Event name
   * @param {Object} payload - Event payload
   * @param {string} [id] - Optional ID for ID-specific events
   */
  _emitStandardized(event, payload, id = null) {
    this.emit(event, payload);
    if (id) {
      this.emit(`${event}:${id}`, payload);
    }
  }
  /**
   * Insert a new resource object
   * @param {Object} attributes - Resource attributes
   * @param {string} [attributes.id] - Custom ID (optional, auto-generated if not provided)
   * @returns {Promise<Object>} The created resource object with all attributes
   * @example
   * // Insert with auto-generated ID
   * const user = await resource.insert({
   *   name: 'John Doe',
   *   email: 'john@example.com',
   *   age: 30
   * });
      * 
   * // Insert with custom ID
   * const user = await resource.insert({
   *   id: 'user-123',
   *   name: 'John Doe',
   *   email: 'john@example.com'
   * });
   */
  async insert({ id: id$1, ...attributes }) {
    const providedId = id$1 !== void 0 && id$1 !== null && String(id$1).trim() !== "";
    if (this.config.timestamps) {
      attributes.createdAt = (/* @__PURE__ */ new Date()).toISOString();
      attributes.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const attributesWithDefaults = this.applyDefaults(attributes);
    const completeData = id$1 !== void 0 ? { id: id$1, ...attributesWithDefaults } : { ...attributesWithDefaults };
    const preProcessedData = await this.executeHooks("beforeInsert", completeData);
    const extraProps = Object.keys(preProcessedData).filter(
      (k) => !(k in completeData) || preProcessedData[k] !== completeData[k]
    );
    const extraData = {};
    for (const k of extraProps) extraData[k] = preProcessedData[k];
    const shouldValidateId = preProcessedData.id !== void 0 && preProcessedData.id !== null;
    const {
      errors,
      isValid,
      data: validated
    } = await this.validate(preProcessedData, { includeId: shouldValidateId });
    if (!isValid) {
      const errorMsg = errors && errors.length && errors[0].message ? errors[0].message : "Insert failed";
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: preProcessedData,
        validation: errors,
        message: errorMsg
      });
    }
    const { id: validatedId, ...validatedAttributes } = validated;
    Object.assign(validatedAttributes, extraData);
    let finalId = validatedId || preProcessedData.id || id$1;
    if (!finalId) {
      finalId = this.idGenerator();
      if (!finalId || finalId.trim() === "") {
        const { idGenerator } = await Promise.resolve().then(function () { return id; });
        finalId = idGenerator();
      }
    }
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: validatedAttributes,
      mappedData,
      originalData: completeData
    });
    const finalMetadata = processedMetadata;
    if (!finalId || String(finalId).trim() === "") {
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: preProcessedData,
        validation: [{ message: "Generated ID is invalid", field: "id" }],
        message: "Generated ID is invalid"
      });
    }
    const shouldCheckExists = providedId || shouldValidateId || validatedId !== void 0;
    if (shouldCheckExists) {
      const alreadyExists = await this.exists(finalId);
      if (alreadyExists) {
        throw new InvalidResourceItem({
          bucket: this.client.config.bucket,
          resourceName: this.name,
          attributes: preProcessedData,
          validation: [{ message: `Resource with id '${finalId}' already exists`, field: "id" }],
          message: `Resource with id '${finalId}' already exists`
        });
      }
    }
    const key = this.getResourceKey(finalId);
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    if (this.behavior === "body-only" && (!body || body === "")) {
      throw new ResourceError("Body required for body-only behavior", {
        resourceName: this.name,
        operation: "insert",
        id: finalId,
        statusCode: 400,
        retriable: false,
        suggestion: 'Include a request body when using behavior "body-only" or switch to "body-overflow".'
      });
    }
    const [okPut, errPut, putResult] = await tryFn(() => this.client.putObject({
      key,
      body,
      contentType,
      metadata: finalMetadata
    }));
    if (!okPut) {
      const msg = errPut && errPut.message ? errPut.message : "";
      if (msg.includes("metadata headers exceed") || msg.includes("Insert failed")) {
        const totalSize = calculateTotalSize(finalMetadata);
        const effectiveLimit = calculateEffectiveLimit({
          s3Limit: 2047,
          systemConfig: {
            version: this.version,
            timestamps: this.config.timestamps,
            id: finalId
          }
        });
        const excess = totalSize - effectiveLimit;
        errPut.totalSize = totalSize;
        errPut.limit = 2047;
        errPut.effectiveLimit = effectiveLimit;
        errPut.excess = excess;
        throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "insert", id: finalId, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
      }
      throw errPut;
    }
    const insertedObject = await this.get(finalId);
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.createPartitionReferences(insertedObject);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.createPartitionReferences(insertedObject).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "insert",
              id: finalId,
              error: err,
              message: err.message
            });
          });
        });
      } else {
        const [ok, err] = await tryFn(() => this.createPartitionReferences(insertedObject));
        if (!ok) {
          this.emit("partitionIndexError", {
            operation: "insert",
            id: finalId,
            error: err,
            message: err.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterInsert.filter(
        (hook) => !hook.toString().includes("createPartitionReferences")
      );
      let finalResult = insertedObject;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("inserted", finalResult, finalResult?.id || insertedObject?.id);
      return finalResult;
    } else {
      const finalResult = await this.executeHooks("afterInsert", insertedObject);
      this._emitStandardized("inserted", finalResult, finalResult?.id || insertedObject?.id);
      return finalResult;
    }
  }
  /**
   * Retrieve a resource object by ID
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} The resource object with all attributes and metadata
   * @example
   * const user = await resource.get('user-123');
   */
  async get(id) {
    if (isObject$1(id)) {
      throw new ValidationError("Resource id must be a string", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: 'Pass the resource id as a string value (e.g. "user-123").'
      });
    }
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide a non-empty id when calling resource methods."
      });
    }
    await this.executeHooks("beforeGet", { id });
    const key = this.getResourceKey(id);
    const [ok, err, request] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "get",
        id
      });
    }
    const objectVersionRaw = request.Metadata?._v || this.version;
    const objectVersion = typeof objectVersionRaw === "string" && objectVersionRaw.startsWith("v") ? objectVersionRaw.slice(1) : objectVersionRaw;
    const schema = await this.getSchemaForVersion(objectVersion);
    let metadata = await schema.unmapper(request.Metadata);
    const behaviorImpl = getBehavior(this.behavior);
    let body = "";
    if (request.ContentLength > 0) {
      const [okBody, errBody, fullObject] = await tryFn(() => this.client.getObject(key));
      if (okBody) {
        body = await streamToString(fullObject.Body);
      } else {
        body = "";
      }
    }
    const { metadata: processedMetadata } = await behaviorImpl.handleGet({
      resource: this,
      metadata,
      body
    });
    let data = await this.composeFullObjectFromWrite({
      id,
      metadata: processedMetadata,
      body,
      behavior: this.behavior
    });
    data._contentLength = request.ContentLength;
    data._lastModified = request.LastModified;
    data._hasContent = request.ContentLength > 0;
    data._mimeType = request.ContentType || null;
    data._etag = request.ETag;
    data._v = objectVersion;
    if (request.VersionId) data._versionId = request.VersionId;
    if (request.Expiration) data._expiresAt = request.Expiration;
    data._definitionHash = this.getDefinitionHash();
    if (objectVersion !== this.version) {
      data = await this.applyVersionMapping(data, objectVersion, this.version);
    }
    data = await this.executeHooks("afterGet", data);
    this._emitStandardized("fetched", data, data.id);
    const value = data;
    return value;
  }
  /**
   * Retrieve a resource object by ID, or return null if not found
   * @param {string} id - Resource ID
   * @returns {Promise<Object|null>} The resource object or null if not found
   * @example
   * const user = await resource.getOrNull('user-123');
   * if (user) {
   *   console.log('Found user:', user.name);
   * } else {
   *   console.log('User not found');
   * }
   */
  async getOrNull(id) {
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (!ok && err && (err.name === "NoSuchKey" || err.message?.includes("NoSuchKey"))) {
      return null;
    }
    if (!ok) {
      throw err;
    }
    return data;
  }
  /**
   * Retrieve a resource object by ID, or throw ResourceNotFoundError if not found
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} The resource object
   * @throws {ResourceError} If resource does not exist
   * @example
   * // Throws error if user doesn't exist (no need for null check)
   * const user = await resource.getOrThrow('user-123');
   * console.log('User name:', user.name); // Safe to access
   */
  async getOrThrow(id) {
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (!ok && err && (err.name === "NoSuchKey" || err.message?.includes("NoSuchKey"))) {
      throw new ResourceError(`Resource '${this.name}' with id '${id}' not found`, {
        resourceName: this.name,
        operation: "getOrThrow",
        id,
        code: "RESOURCE_NOT_FOUND"
      });
    }
    if (!ok) {
      throw err;
    }
    return data;
  }
  /**
   * Check if a resource exists by ID
   * @returns {Promise<boolean>} True if resource exists, false otherwise
   */
  async exists(id) {
    await this.executeHooks("beforeExists", { id });
    const key = this.getResourceKey(id);
    const [ok, err] = await tryFn(() => this.client.headObject(key));
    await this.executeHooks("afterExists", { id, exists: ok });
    return ok;
  }
  /**
   * Update an existing resource object
   * @param {string} id - Resource ID
   * @param {Object} attributes - Attributes to update (partial update supported)
   * @returns {Promise<Object>} The updated resource object with all attributes
   * @example
   * // Update specific fields
   * const updatedUser = await resource.update('user-123', {
   *   name: 'John Updated',
   *   age: 31
   * });
   * 
   * // Update with timestamps (if enabled)
   * const updatedUser = await resource.update('user-123', {
   *   email: 'newemail@example.com'
   * });
      */
  async update(id, attributes) {
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide the target id when calling update()."
      });
    }
    const exists = await this.exists(id);
    if (!exists) {
      throw new ResourceError(`Resource with id '${id}' does not exist`, {
        resourceName: this.name,
        id,
        statusCode: 404,
        retriable: false,
        suggestion: "Ensure the record exists or create it before attempting an update."
      });
    }
    const originalData = await this.get(id);
    const attributesClone = cloneDeep(attributes);
    let mergedData = cloneDeep(originalData);
    for (const [key2, value] of Object.entries(attributesClone)) {
      if (key2.includes(".")) {
        let ref = mergedData;
        const parts = key2.split(".");
        for (let i = 0; i < parts.length - 1; i++) {
          if (typeof ref[parts[i]] !== "object" || ref[parts[i]] === null) {
            ref[parts[i]] = {};
          }
          ref = ref[parts[i]];
        }
        ref[parts[parts.length - 1]] = cloneDeep(value);
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      mergedData.updatedAt = now;
      if (!mergedData.metadata) mergedData.metadata = {};
      mergedData.metadata.updatedAt = now;
    }
    const preProcessedData = await this.executeHooks("beforeUpdate", cloneDeep(mergedData));
    const completeData = { ...originalData, ...preProcessedData, id };
    const { isValid, errors, data } = await this.validate(cloneDeep(completeData), { includeId: true });
    if (!isValid) {
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: preProcessedData,
        validation: errors,
        message: "validation: " + (errors && errors.length ? JSON.stringify(errors) : "unknown")
      });
    }
    await this.schema.mapper(data);
    const earlyBehaviorImpl = getBehavior(this.behavior);
    const tempMappedData = await this.schema.mapper({ ...originalData, ...preProcessedData });
    tempMappedData._v = String(this.version);
    await earlyBehaviorImpl.handleUpdate({
      resource: this,
      id,
      data: { ...originalData, ...preProcessedData },
      mappedData: tempMappedData,
      originalData: { ...attributesClone, id }
    });
    const { id: validatedId, ...validatedAttributes } = data;
    const oldData = { ...originalData, id };
    const newData = { ...validatedAttributes, id };
    await this.handlePartitionReferenceUpdates(oldData, newData);
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleUpdate({
      resource: this,
      id,
      data: validatedAttributes,
      mappedData,
      originalData: { ...attributesClone, id }
    });
    const finalMetadata = processedMetadata;
    const key = this.getResourceKey(id);
    let existingContentType = void 0;
    let finalBody = body;
    if (body === "" && this.behavior !== "body-overflow") {
      const [ok2, err2, existingObject] = await tryFn(() => this.client.getObject(key));
      if (ok2 && existingObject.ContentLength > 0) {
        const existingBodyBuffer = Buffer.from(await existingObject.Body.transformToByteArray());
        const existingBodyString = existingBodyBuffer.toString();
        const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(existingBodyString)));
        if (!okParse) {
          finalBody = existingBodyBuffer;
          existingContentType = existingObject.ContentType;
        }
      }
    }
    let finalContentType = existingContentType;
    if (finalBody && finalBody !== "" && !finalContentType) {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(finalBody)));
      if (okParse) finalContentType = "application/json";
    }
    if (this.versioningEnabled && originalData._v !== this.version) {
      await this.createHistoricalVersion(id, originalData);
    }
    const [ok, err] = await tryFn(() => this.client.putObject({
      key,
      body: finalBody,
      contentType: finalContentType,
      metadata: finalMetadata
    }));
    if (!ok && err && err.message && err.message.includes("metadata headers exceed")) {
      const totalSize = calculateTotalSize(finalMetadata);
      const effectiveLimit = calculateEffectiveLimit({
        s3Limit: 2047,
        systemConfig: {
          version: this.version,
          timestamps: this.config.timestamps,
          id
        }
      });
      const excess = totalSize - effectiveLimit;
      err.totalSize = totalSize;
      err.limit = 2047;
      err.effectiveLimit = effectiveLimit;
      err.excess = excess;
      this.emit("exceedsLimit", {
        operation: "update",
        totalSize,
        limit: 2047,
        effectiveLimit,
        excess,
        data: validatedAttributes
      });
      throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "update", id, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
    } else if (!ok) {
      throw mapAwsError(err, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "update",
        id
      });
    }
    const updatedData = await this.composeFullObjectFromWrite({
      id,
      metadata: finalMetadata,
      body: finalBody,
      behavior: this.behavior
    });
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(originalData, updatedData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(originalData, updatedData).catch((err2) => {
            this.emit("partitionIndexError", {
              operation: "update",
              id,
              error: err2,
              message: err2.message
            });
          });
        });
      } else {
        const [ok2, err2] = await tryFn(() => this.handlePartitionReferenceUpdates(originalData, updatedData));
        if (!ok2) {
          this.emit("partitionIndexError", {
            operation: "update",
            id,
            error: err2,
            message: err2.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterUpdate.filter(
        (hook) => !hook.toString().includes("handlePartitionReferenceUpdates")
      );
      let finalResult = updatedData;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return finalResult;
    } else {
      const finalResult = await this.executeHooks("afterUpdate", updatedData);
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return finalResult;
    }
  }
  /**
   * Patch resource (partial update optimized for metadata-only behaviors)
   *
   * This method provides an optimized update path for resources using metadata-only behaviors
   * (enforce-limits, truncate-data). It uses HeadObject + CopyObject for atomic updates without
   * body transfer, eliminating race conditions and reducing latency by ~50%.
   *
   * For behaviors that store data in body (body-overflow, body-only), it automatically falls
   * back to the standard update() method.
   *
   * @param {string} id - Resource ID
   * @param {Object} fields - Fields to update (partial data)
   * @param {Object} options - Update options
   * @param {string} options.partition - Partition name (if using partitions)
   * @param {Object} options.partitionValues - Partition values (if using partitions)
   * @returns {Promise<Object>} Updated resource data
   *
   * @example
   * // Fast atomic update (enforce-limits behavior)
   * await resource.patch('user-123', { status: 'active', loginCount: 42 });
   *
   * @example
   * // With partitions
   * await resource.patch('order-456', { status: 'shipped' }, {
   *   partition: 'byRegion',
   *   partitionValues: { region: 'US' }
   * });
   */
  async patch(id, fields, options = {}) {
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide the target id when calling patch()."
      });
    }
    if (!fields || typeof fields !== "object") {
      throw new ValidationError("fields must be a non-empty object", {
        field: "fields",
        statusCode: 400,
        retriable: false,
        suggestion: 'Pass a plain object with the fields to update (e.g. { status: "active" }).'
      });
    }
    await this.executeHooks("beforePatch", { id, fields, options });
    const behavior = this.behavior;
    const hasNestedFields = Object.keys(fields).some((key) => key.includes("."));
    let result;
    if ((behavior === "enforce-limits" || behavior === "truncate-data") && !hasNestedFields) {
      result = await this._patchViaCopyObject(id, fields, options);
    } else {
      result = await this.update(id, fields, options);
    }
    const finalResult = await this.executeHooks("afterPatch", result);
    return finalResult;
  }
  /**
   * Internal helper: Optimized patch using HeadObject + CopyObject
   * Only works for metadata-only behaviors (enforce-limits, truncate-data)
   * Only for simple field updates (no nested fields with dot notation)
   * @private
   */
  async _patchViaCopyObject(id, fields, options = {}) {
    const { partition, partitionValues } = options;
    const key = this.getResourceKey(id);
    const headResponse = await this.client.headObject(key);
    const currentMetadata = headResponse.Metadata || {};
    let currentData = await this.schema.unmapper(currentMetadata);
    if (!currentData.id) {
      currentData.id = id;
    }
    const fieldsClone = cloneDeep(fields);
    let mergedData = cloneDeep(currentData);
    for (const [key2, value] of Object.entries(fieldsClone)) {
      if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      mergedData.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const validationResult = await this.schema.validate(mergedData);
    if (validationResult !== true) {
      throw new ValidationError("Validation failed during patch", validationResult);
    }
    const newMetadata = await this.schema.mapper(mergedData);
    newMetadata._v = String(this.version);
    await this.client.copyObject({
      from: key,
      to: key,
      metadataDirective: "REPLACE",
      metadata: newMetadata
    });
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      const oldData = { ...currentData, id };
      const newData = { ...mergedData, id };
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(oldData, newData).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "patch",
              id,
              error: err
            });
          });
        });
      } else {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      }
    }
    return mergedData;
  }
  /**
   * Replace resource (full object replacement without GET)
   *
   * This method performs a direct PUT operation without fetching the current object.
   * Use this when you already have the complete object and want to replace it entirely,
   * saving 1 S3 request (GET).
   *
   *  Warning: You must provide ALL required fields. Missing fields will NOT be preserved
   * from the current object. This method does not merge with existing data.
   *
   * @param {string} id - Resource ID
   * @param {Object} fullData - Complete object data (all required fields)
   * @param {Object} options - Update options
   * @param {string} options.partition - Partition name (if using partitions)
   * @param {Object} options.partitionValues - Partition values (if using partitions)
   * @returns {Promise<Object>} Replaced resource data
   *
   * @example
   * // Replace entire object (must include ALL required fields)
   * await resource.replace('user-123', {
   *   name: 'John Doe',
   *   email: 'john@example.com',
   *   status: 'active',
   *   loginCount: 42
   * });
   *
   * @example
   * // With partitions
   * await resource.replace('order-456', fullOrderData, {
   *   partition: 'byRegion',
   *   partitionValues: { region: 'US' }
   * });
   */
  async replace(id, fullData, options = {}) {
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide the target id when calling replace()."
      });
    }
    if (!fullData || typeof fullData !== "object") {
      throw new ValidationError("fullData must be a non-empty object", {
        field: "fullData",
        statusCode: 400,
        retriable: false,
        suggestion: "Pass a plain object containing the full resource payload to replace()."
      });
    }
    await this.executeHooks("beforeReplace", { id, fullData, options });
    const { partition, partitionValues } = options;
    const dataClone = cloneDeep(fullData);
    const attributesWithDefaults = this.applyDefaults(dataClone);
    if (this.config.timestamps) {
      if (!attributesWithDefaults.createdAt) {
        attributesWithDefaults.createdAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      attributesWithDefaults.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const completeData = { id, ...attributesWithDefaults };
    const {
      errors,
      isValid,
      data: validated
    } = await this.validate(completeData, { includeId: true });
    if (!isValid) {
      const errorMsg = errors && errors.length && errors[0].message ? errors[0].message : "Replace failed";
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: completeData,
        validation: errors,
        message: errorMsg
      });
    }
    const { id: validatedId, ...validatedAttributes } = validated;
    const mappedMetadata = await this.schema.mapper(validatedAttributes);
    mappedMetadata._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: finalMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: validatedAttributes,
      mappedData: mappedMetadata,
      originalData: completeData
    });
    const key = this.getResourceKey(id);
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    if (this.behavior === "body-only" && (!body || body === "")) {
      throw new ResourceError("Body required for body-only behavior", {
        resourceName: this.name,
        operation: "replace",
        id,
        statusCode: 400,
        retriable: false,
        suggestion: 'Include a request body when using behavior "body-only" or switch to "body-overflow".'
      });
    }
    const [okPut, errPut] = await tryFn(() => this.client.putObject({
      key,
      body,
      contentType,
      metadata: finalMetadata
    }));
    if (!okPut) {
      const msg = errPut && errPut.message ? errPut.message : "";
      if (msg.includes("metadata headers exceed") || msg.includes("Replace failed")) {
        const totalSize = calculateTotalSize(finalMetadata);
        const effectiveLimit = calculateEffectiveLimit({
          s3Limit: 2047,
          systemConfig: {
            version: this.version,
            timestamps: this.config.timestamps,
            id
          }
        });
        const excess = totalSize - effectiveLimit;
        errPut.totalSize = totalSize;
        errPut.limit = 2047;
        errPut.effectiveLimit = effectiveLimit;
        errPut.excess = excess;
        throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "replace", id, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
      }
      throw errPut;
    }
    const replacedObject = { id, ...validatedAttributes };
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates({}, replacedObject);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates({}, replacedObject).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "replace",
              id,
              error: err
            });
          });
        });
      } else {
        await this.handlePartitionReferenceUpdates({}, replacedObject);
      }
    }
    const finalResult = await this.executeHooks("afterReplace", replacedObject);
    return finalResult;
  }
  /**
   * Update with conditional check (If-Match ETag)
   * @param {string} id - Resource ID
   * @param {Object} attributes - Attributes to update
   * @param {Object} options - Options including ifMatch (ETag)
   * @returns {Promise<Object>} { success: boolean, data?: Object, etag?: string, error?: string }
   * @example
   * const msg = await resource.get('msg-123');
   * const result = await resource.updateConditional('msg-123', { status: 'processing' }, { ifMatch: msg._etag });
   * if (!result.success) {
   *   console.log('Update failed - object was modified by another process');
   * }
   */
  async updateConditional(id, attributes, options = {}) {
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide the target id when calling updateConditional()."
      });
    }
    const { ifMatch } = options;
    if (!ifMatch) {
      throw new ValidationError("updateConditional requires ifMatch option with ETag value", {
        field: "ifMatch",
        statusCode: 428,
        retriable: false,
        suggestion: "Pass the current object ETag in options.ifMatch to enable conditional updates."
      });
    }
    const exists = await this.exists(id);
    if (!exists) {
      return {
        success: false,
        error: `Resource with id '${id}' does not exist`
      };
    }
    const originalData = await this.get(id);
    const attributesClone = cloneDeep(attributes);
    let mergedData = cloneDeep(originalData);
    for (const [key2, value] of Object.entries(attributesClone)) {
      if (key2.includes(".")) {
        let ref = mergedData;
        const parts = key2.split(".");
        for (let i = 0; i < parts.length - 1; i++) {
          if (typeof ref[parts[i]] !== "object" || ref[parts[i]] === null) {
            ref[parts[i]] = {};
          }
          ref = ref[parts[i]];
        }
        ref[parts[parts.length - 1]] = cloneDeep(value);
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      mergedData.updatedAt = now;
      if (!mergedData.metadata) mergedData.metadata = {};
      mergedData.metadata.updatedAt = now;
    }
    const preProcessedData = await this.executeHooks("beforeUpdate", cloneDeep(mergedData));
    const completeData = { ...originalData, ...preProcessedData, id };
    const { isValid, errors, data } = await this.validate(cloneDeep(completeData), { includeId: true });
    if (!isValid) {
      return {
        success: false,
        error: "Validation failed: " + (errors && errors.length ? JSON.stringify(errors) : "unknown"),
        validationErrors: errors
      };
    }
    const { id: validatedId, ...validatedAttributes } = data;
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleUpdate({
      resource: this,
      id,
      data: validatedAttributes,
      mappedData,
      originalData: { ...attributesClone, id }
    });
    const key = this.getResourceKey(id);
    let existingContentType = void 0;
    let finalBody = body;
    if (body === "" && this.behavior !== "body-overflow") {
      const [ok2, err2, existingObject] = await tryFn(() => this.client.getObject(key));
      if (ok2 && existingObject.ContentLength > 0) {
        const existingBodyBuffer = Buffer.from(await existingObject.Body.transformToByteArray());
        const existingBodyString = existingBodyBuffer.toString();
        const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(existingBodyString)));
        if (!okParse) {
          finalBody = existingBodyBuffer;
          existingContentType = existingObject.ContentType;
        }
      }
    }
    let finalContentType = existingContentType;
    if (finalBody && finalBody !== "" && !finalContentType) {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(finalBody)));
      if (okParse) finalContentType = "application/json";
    }
    const [ok, err, response] = await tryFn(() => this.client.putObject({
      key,
      body: finalBody,
      contentType: finalContentType,
      metadata: processedMetadata,
      ifMatch
      //  Conditional write with ETag
    }));
    if (!ok) {
      if (err.name === "PreconditionFailed" || err.$metadata?.httpStatusCode === 412) {
        return {
          success: false,
          error: "ETag mismatch - object was modified by another process"
        };
      }
      return {
        success: false,
        error: err.message || "Update failed"
      };
    }
    const updatedData = await this.composeFullObjectFromWrite({
      id,
      metadata: processedMetadata,
      body: finalBody,
      behavior: this.behavior
    });
    const oldData = { ...originalData, id };
    const newData = { ...validatedAttributes, id };
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(oldData, newData).catch((err2) => {
            this.emit("partitionIndexError", {
              operation: "updateConditional",
              id,
              error: err2,
              message: err2.message
            });
          });
        });
      } else {
        const [ok2, err2] = await tryFn(() => this.handlePartitionReferenceUpdates(oldData, newData));
        if (!ok2) {
          this.emit("partitionIndexError", {
            operation: "updateConditional",
            id,
            error: err2,
            message: err2.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterUpdate.filter(
        (hook) => !hook.toString().includes("handlePartitionReferenceUpdates")
      );
      let finalResult = updatedData;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return {
        success: true,
        data: finalResult,
        etag: response.ETag
      };
    } else {
      await this.handlePartitionReferenceUpdates(oldData, newData);
      const finalResult = await this.executeHooks("afterUpdate", updatedData);
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return {
        success: true,
        data: finalResult,
        etag: response.ETag
      };
    }
  }
  /**
   * Delete a resource object by ID
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} S3 delete response
   * @example
   * await resource.delete('user-123');
   */
  async delete(id) {
    if (isEmpty(id)) {
      throw new ValidationError("Resource id cannot be empty", {
        field: "id",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide the target id when calling delete()."
      });
    }
    let objectData;
    let deleteError = null;
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (ok) {
      objectData = data;
    } else {
      objectData = { id };
      deleteError = err;
    }
    await this.executeHooks("beforeDelete", objectData);
    const key = this.getResourceKey(id);
    const [ok2, err2, response] = await tryFn(() => this.client.deleteObject(key));
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0 && objectData) {
      if (this.config.strictPartitions) {
        await this.deletePartitionReferences(objectData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.deletePartitionReferences(objectData).catch((err3) => {
            this.emit("partitionIndexError", {
              operation: "delete",
              id,
              error: err3,
              message: err3.message
            });
          });
        });
      } else {
        const [ok3, err3] = await tryFn(() => this.deletePartitionReferences(objectData));
        if (!ok3) {
          this.emit("partitionIndexError", {
            operation: "delete",
            id,
            error: err3,
            message: err3.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterDelete.filter(
        (hook) => !hook.toString().includes("deletePartitionReferences")
      );
      let afterDeleteData = objectData;
      for (const hook of nonPartitionHooks) {
        afterDeleteData = await hook(afterDeleteData);
      }
    } else {
      await this.executeHooks("afterDelete", objectData);
    }
    this._emitStandardized("deleted", {
      ...objectData,
      $before: { ...objectData },
      $after: null
    }, id);
    if (deleteError) {
      throw mapAwsError(deleteError, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "delete",
        id
      });
    }
    if (!ok2) throw mapAwsError(err2, {
      key,
      resourceName: this.name,
      operation: "delete",
      id
    });
    return response;
  }
  /**
   * Insert or update a resource object (upsert operation)
   * @param {Object} params - Upsert parameters
   * @param {string} params.id - Resource ID (required for upsert)
   * @param {...Object} params - Resource attributes (any additional properties)
   * @returns {Promise<Object>} The inserted or updated resource object
   * @example
   * // Will insert if doesn't exist, update if exists
   * const user = await resource.upsert({
   *   id: 'user-123',
   *   name: 'John Doe',
   *   email: 'john@example.com'
   * });
   */
  async upsert({ id, ...attributes }) {
    const exists = await this.exists(id);
    if (exists) {
      return this.update(id, attributes);
    }
    return this.insert({ id, ...attributes });
  }
  /**
   * Count resources with optional partition filtering
   * @param {Object} [params] - Count parameters
   * @param {string} [params.partition] - Partition name to count in
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @returns {Promise<number>} Total count of matching resources
   * @example
   * // Count all resources
   * const total = await resource.count();
   * 
   * // Count in specific partition
   * const googleUsers = await resource.count({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
   * 
   * // Count in multi-field partition
   * const usElectronics = await resource.count({
   *   partition: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async count({ partition = null, partitionValues = {} } = {}) {
    await this.executeHooks("beforeCount", { partition, partitionValues });
    let prefix;
    if (partition && Object.keys(partitionValues).length > 0) {
      const partitionDef = this.config.partitions[partition];
      if (!partitionDef) {
        throw new PartitionError(`Partition '${partition}' not found`, { resourceName: this.name, partitionName: partition, operation: "count" });
      }
      const partitionSegments = [];
      const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
      for (const [fieldName, rule] of sortedFields) {
        const value = partitionValues[fieldName];
        if (value !== void 0 && value !== null) {
          const transformedValue = this.applyPartitionRule(value, rule);
          partitionSegments.push(`${fieldName}=${transformedValue}`);
        }
      }
      if (partitionSegments.length > 0) {
        prefix = `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
      } else {
        prefix = `resource=${this.name}/partition=${partition}`;
      }
    } else {
      prefix = `resource=${this.name}/data`;
    }
    const count = await this.client.count({ prefix });
    await this.executeHooks("afterCount", { count, partition, partitionValues });
    this._emitStandardized("count", count);
    return count;
  }
  /**
   * Insert multiple resources in parallel
   * @param {Object[]} objects - Array of resource objects to insert
   * @returns {Promise<Object[]>} Array of inserted resource objects
   * @example
   * const users = [
   *   { name: 'John', email: 'john@example.com' },
   *   { name: 'Jane', email: 'jane@example.com' },
   *   { name: 'Bob', email: 'bob@example.com' }
   * ];
   * const insertedUsers = await resource.insertMany(users);
      */
  async insertMany(objects) {
    const { results } = await PromisePool.for(objects).withConcurrency(this.parallelism).handleError(async (error, content2) => {
      this.emit("error", error, content2);
      this.observers.map((x) => x.emit("error", this.name, error, content2));
    }).process(async (attributes) => {
      const result = await this.insert(attributes);
      return result;
    });
    this._emitStandardized("inserted-many", objects.length);
    return results;
  }
  /**
   * Delete multiple resources by their IDs in parallel
   * @param {string[]} ids - Array of resource IDs to delete
   * @returns {Promise<Object[]>} Array of S3 delete responses
   * @example
   * const deletedIds = ['user-1', 'user-2', 'user-3'];
   * const results = await resource.deleteMany(deletedIds);
      */
  async deleteMany(ids) {
    await this.executeHooks("beforeDeleteMany", { ids });
    const packages = chunk(
      ids.map((id) => this.getResourceKey(id)),
      1e3
    );
    ids.map((id) => this.getResourceKey(id));
    const { results } = await PromisePool.for(packages).withConcurrency(this.parallelism).handleError(async (error, content2) => {
      this.emit("error", error, content2);
      this.observers.map((x) => x.emit("error", this.name, error, content2));
    }).process(async (keys) => {
      const response = await this.client.deleteObjects(keys);
      keys.forEach((key) => {
        const parts = key.split("/");
        const idPart = parts.find((part) => part.startsWith("id="));
        const id = idPart ? idPart.replace("id=", "") : null;
        if (id) {
          this.emit("deleted", id);
          this.observers.map((x) => x.emit("deleted", this.name, id));
        }
      });
      return response;
    });
    await this.executeHooks("afterDeleteMany", { ids, results });
    this._emitStandardized("deleted-many", ids.length);
    return results;
  }
  async deleteAll() {
    if (this.config.paranoid !== false) {
      throw new ResourceError("deleteAll() is a dangerous operation and requires paranoid: false option.", { resourceName: this.name, operation: "deleteAll", paranoid: this.config.paranoid, suggestion: "Set paranoid: false to allow deleteAll." });
    }
    const prefix = `resource=${this.name}/data`;
    const deletedCount = await this.client.deleteAll({ prefix });
    this._emitStandardized("deleted-all", {
      version: this.version,
      prefix,
      deletedCount
    });
    return { deletedCount, version: this.version };
  }
  /**
   * Delete all data for this resource across ALL versions
   * @returns {Promise<Object>} Deletion report
   */
  async deleteAllData() {
    if (this.config.paranoid !== false) {
      throw new ResourceError("deleteAllData() is a dangerous operation and requires paranoid: false option.", { resourceName: this.name, operation: "deleteAllData", paranoid: this.config.paranoid, suggestion: "Set paranoid: false to allow deleteAllData." });
    }
    const prefix = `resource=${this.name}`;
    const deletedCount = await this.client.deleteAll({ prefix });
    this._emitStandardized("deleted-all-data", {
      resource: this.name,
      prefix,
      deletedCount
    });
    return { deletedCount, resource: this.name };
  }
  /**
   * List resource IDs with optional partition filtering and pagination
   * @param {Object} [params] - List parameters
   * @param {string} [params.partition] - Partition name to list from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {number} [params.limit] - Maximum number of results to return
   * @param {number} [params.offset=0] - Offset for pagination
   * @returns {Promise<string[]>} Array of resource IDs (strings)
   * @example
   * // List all IDs
   * const allIds = await resource.listIds();
   * 
   * // List IDs with pagination
   * const firstPageIds = await resource.listIds({ limit: 10, offset: 0 });
   * const secondPageIds = await resource.listIds({ limit: 10, offset: 10 });
   * 
   * // List IDs from specific partition
   * const googleUserIds = await resource.listIds({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
   * 
   * // List IDs from multi-field partition
   * const usElectronicsIds = await resource.listIds({
   *   partition: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async listIds({ partition = null, partitionValues = {}, limit, offset = 0 } = {}) {
    let prefix;
    if (partition && Object.keys(partitionValues).length > 0) {
      if (!this.config.partitions || !this.config.partitions[partition]) {
        throw new PartitionError(`Partition '${partition}' not found`, { resourceName: this.name, partitionName: partition, operation: "listIds" });
      }
      const partitionDef = this.config.partitions[partition];
      const partitionSegments = [];
      const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
      for (const [fieldName, rule] of sortedFields) {
        const value = partitionValues[fieldName];
        if (value !== void 0 && value !== null) {
          const transformedValue = this.applyPartitionRule(value, rule);
          partitionSegments.push(`${fieldName}=${transformedValue}`);
        }
      }
      if (partitionSegments.length > 0) {
        prefix = `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
      } else {
        prefix = `resource=${this.name}/partition=${partition}`;
      }
    } else {
      prefix = `resource=${this.name}/data`;
    }
    const keys = await this.client.getKeysPage({
      prefix,
      offset,
      amount: limit || 1e3
      // Default to 1000 if no limit specified
    });
    const ids = keys.map((key) => {
      const parts = key.split("/");
      const idPart = parts.find((part) => part.startsWith("id="));
      return idPart ? idPart.replace("id=", "") : null;
    }).filter(Boolean);
    this._emitStandardized("listed-ids", ids.length);
    return ids;
  }
  /**
   * List resources with optional partition filtering and pagination
   * @param {Object} [params] - List parameters
   * @param {string} [params.partition] - Partition name to list from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {number} [params.limit] - Maximum number of results
   * @param {number} [params.offset=0] - Number of results to skip
   * @returns {Promise<Object[]>} Array of resource objects
   * @example
   * // List all resources
   * const allUsers = await resource.list();
   * 
   * // List with pagination
   * const first10 = await resource.list({ limit: 10, offset: 0 });
   * 
   * // List from specific partition
   * const usUsers = await resource.list({
   *   partition: 'byCountry',
   *   partitionValues: { 'profile.country': 'US' }
   * });
   */
  async list({ partition = null, partitionValues = {}, limit, offset = 0 } = {}) {
    await this.executeHooks("beforeList", { partition, partitionValues, limit, offset });
    const [ok, err, result] = await tryFn(async () => {
      if (!partition) {
        return await this.listMain({ limit, offset });
      }
      return await this.listPartition({ partition, partitionValues, limit, offset });
    });
    if (!ok) {
      return this.handleListError(err, { partition, partitionValues });
    }
    const finalResult = await this.executeHooks("afterList", result);
    return finalResult;
  }
  async listMain({ limit, offset = 0 }) {
    const [ok, err, ids] = await tryFn(() => this.listIds({ limit, offset }));
    if (!ok) throw err;
    const results = await this.processListResults(ids, "main");
    this._emitStandardized("list", { count: results.length, errors: 0 });
    return results;
  }
  async listPartition({ partition, partitionValues, limit, offset = 0 }) {
    if (!this.config.partitions?.[partition]) {
      this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 0 });
      return [];
    }
    const partitionDef = this.config.partitions[partition];
    const prefix = this.buildPartitionPrefix(partition, partitionDef, partitionValues);
    const [ok, err, keys] = await tryFn(() => this.client.getAllKeys({ prefix }));
    if (!ok) throw err;
    const ids = this.extractIdsFromKeys(keys).slice(offset);
    const filteredIds = limit ? ids.slice(0, limit) : ids;
    const results = await this.processPartitionResults(filteredIds, partition, partitionDef, keys);
    this._emitStandardized("list", { partition, partitionValues, count: results.length, errors: 0 });
    return results;
  }
  /**
   * Build partition prefix from partition definition and values
   */
  buildPartitionPrefix(partition, partitionDef, partitionValues) {
    const partitionSegments = [];
    const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const value = partitionValues[fieldName];
      if (value !== void 0 && value !== null) {
        const transformedValue = this.applyPartitionRule(value, rule);
        partitionSegments.push(`${fieldName}=${transformedValue}`);
      }
    }
    if (partitionSegments.length > 0) {
      return `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
    }
    return `resource=${this.name}/partition=${partition}`;
  }
  /**
   * Extract IDs from S3 keys
   */
  extractIdsFromKeys(keys) {
    return keys.map((key) => {
      const parts = key.split("/");
      const idPart = parts.find((part) => part.startsWith("id="));
      return idPart ? idPart.replace("id=", "") : null;
    }).filter(Boolean);
  }
  /**
   * Process list results with error handling
   */
  async processListResults(ids, context = "main") {
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
    }).process(async (id) => {
      const [ok, err, result] = await tryFn(() => this.get(id));
      if (ok) {
        return result;
      }
      return this.handleResourceError(err, id, context);
    });
    this._emitStandardized("list", { count: results.length, errors: 0 });
    return results;
  }
  /**
   * Process partition results with error handling
   */
  async processPartitionResults(ids, partition, partitionDef, keys) {
    const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
    }).process(async (id) => {
      const [ok, err, result] = await tryFn(async () => {
        const actualPartitionValues = this.extractPartitionValuesFromKey(id, keys, sortedFields);
        return await this.getFromPartition({
          id,
          partitionName: partition,
          partitionValues: actualPartitionValues
        });
      });
      if (ok) return result;
      return this.handleResourceError(err, id, "partition");
    });
    return results.filter((item) => item !== null);
  }
  /**
   * Extract partition values from S3 key for specific ID
   */
  extractPartitionValuesFromKey(id, keys, sortedFields) {
    const keyForId = keys.find((key) => key.includes(`id=${id}`));
    if (!keyForId) {
      throw new PartitionError(`Partition key not found for ID ${id}`, { resourceName: this.name, id, operation: "extractPartitionValuesFromKey" });
    }
    const keyParts = keyForId.split("/");
    const actualPartitionValues = {};
    for (const [fieldName] of sortedFields) {
      const fieldPart = keyParts.find((part) => part.startsWith(`${fieldName}=`));
      if (fieldPart) {
        const value = fieldPart.replace(`${fieldName}=`, "");
        actualPartitionValues[fieldName] = value;
      }
    }
    return actualPartitionValues;
  }
  /**
   * Handle resource-specific errors
   */
  handleResourceError(error, id, context) {
    if (error.message.includes("Cipher job failed") || error.message.includes("OperationError")) {
      return {
        id,
        _decryptionFailed: true,
        _error: error.message,
        ...context === "partition" && { _partition: context }
      };
    }
    throw error;
  }
  /**
   * Handle list method errors
   */
  handleListError(error, { partition, partitionValues }) {
    if (error.message.includes("Partition '") && error.message.includes("' not found")) {
      this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 1 });
      return [];
    }
    this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 1 });
    return [];
  }
  /**
   * Get multiple resources by their IDs
   * @param {string[]} ids - Array of resource IDs
   * @returns {Promise<Object[]>} Array of resource objects
   * @example
   * const users = await resource.getMany(['user-1', 'user-2', 'user-3']);
      */
  async getMany(ids) {
    await this.executeHooks("beforeGetMany", { ids });
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.client.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
      return {
        id,
        _error: error.message,
        _decryptionFailed: error.message.includes("Cipher job failed") || error.message.includes("OperationError")
      };
    }).process(async (id) => {
      const [ok, err, data] = await tryFn(() => this.get(id));
      if (ok) return data;
      if (err.message.includes("Cipher job failed") || err.message.includes("OperationError")) {
        return {
          id,
          _decryptionFailed: true,
          _error: err.message
        };
      }
      throw err;
    });
    const finalResults = await this.executeHooks("afterGetMany", results);
    this._emitStandardized("fetched-many", ids.length);
    return finalResults;
  }
  /**
   * Get all resources (equivalent to list() without pagination)
   * @returns {Promise<Object[]>} Array of all resource objects
   * @example
   * const allUsers = await resource.getAll();
      */
  async getAll() {
    const [ok, err, ids] = await tryFn(() => this.listIds());
    if (!ok) throw err;
    const results = [];
    for (const id of ids) {
      const [ok2, err2, item] = await tryFn(() => this.get(id));
      if (ok2) {
        results.push(item);
      }
    }
    return results;
  }
  /**
   * Get a page of resources with pagination metadata
   * @param {Object} [params] - Page parameters
   * @param {number} [params.offset=0] - Offset for pagination
   * @param {number} [params.size=100] - Page size
   * @param {string} [params.partition] - Partition name to page from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {boolean} [params.skipCount=false] - Skip total count for performance (useful for large collections)
   * @returns {Promise<Object>} Page result with items and pagination info
   * @example
   * // Get first page of all resources
   * const page = await resource.page({ offset: 0, size: 10 });
         * 
   * // Get page from specific partition
   * const googlePage = await resource.page({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' },
   *   offset: 0,
   *   size: 5
   * });
   * 
   * // Skip count for performance in large collections
   * const fastPage = await resource.page({ 
   *   offset: 0, 
   *   size: 100, 
   *   skipCount: true 
   * });
      */
  async page({ offset = 0, size = 100, partition = null, partitionValues = {}, skipCount = false } = {}) {
    const [ok, err, result] = await tryFn(async () => {
      let totalItems = null;
      let totalPages = null;
      if (!skipCount) {
        const [okCount, errCount, count] = await tryFn(() => this.count({ partition, partitionValues }));
        if (okCount) {
          totalItems = count;
          totalPages = Math.ceil(totalItems / size);
        } else {
          totalItems = null;
          totalPages = null;
        }
      }
      const page = Math.floor(offset / size);
      let items = [];
      if (size <= 0) {
        items = [];
      } else {
        const [okList, errList, listResult] = await tryFn(() => this.list({ partition, partitionValues, limit: size, offset }));
        items = okList ? listResult : [];
      }
      const result2 = {
        items,
        totalItems,
        page,
        pageSize: size,
        totalPages,
        hasMore: items.length === size && offset + size < (totalItems || Infinity),
        _debug: {
          requestedSize: size,
          requestedOffset: offset,
          actualItemsReturned: items.length,
          skipCount,
          hasTotalItems: totalItems !== null
        }
      };
      this._emitStandardized("paginated", result2);
      return result2;
    });
    if (ok) return result;
    return {
      items: [],
      totalItems: null,
      page: Math.floor(offset / size),
      pageSize: size,
      totalPages: null,
      _debug: {
        requestedSize: size,
        requestedOffset: offset,
        actualItemsReturned: 0,
        skipCount,
        hasTotalItems: false,
        error: err.message
      }
    };
  }
  readable() {
    const stream = new ResourceReader({ resource: this });
    return stream.build();
  }
  writable() {
    const stream = new ResourceWriter({ resource: this });
    return stream.build();
  }
  /**
   * Set binary content for a resource
   * @param {Object} params - Content parameters
   * @param {string} params.id - Resource ID
   * @param {Buffer|string} params.buffer - Content buffer or string
   * @param {string} [params.contentType='application/octet-stream'] - Content type
   * @returns {Promise<Object>} Updated resource data
   * @example
   * // Set image content
   * const imageBuffer = fs.readFileSync('image.jpg');
   * await resource.setContent({
   *   id: 'user-123',
   *   buffer: imageBuffer,
   *   contentType: 'image/jpeg'
   * });
   * 
   * // Set text content
   * await resource.setContent({
   *   id: 'document-456',
   *   buffer: 'Hello World',
   *   contentType: 'text/plain'
   * });
   */
  async setContent({ id, buffer, contentType = "application/octet-stream" }) {
    const [ok, err, currentData] = await tryFn(() => this.get(id));
    if (!ok || !currentData) {
      throw new ResourceError(`Resource with id '${id}' not found`, { resourceName: this.name, id, operation: "setContent" });
    }
    const updatedData = {
      ...currentData,
      _hasContent: true,
      _contentLength: buffer.length,
      _mimeType: contentType
    };
    const mappedMetadata = await this.schema.mapper(updatedData);
    const [ok2, err2] = await tryFn(() => this.client.putObject({
      key: this.getResourceKey(id),
      metadata: mappedMetadata,
      body: buffer,
      contentType
    }));
    if (!ok2) throw err2;
    this._emitStandardized("content-set", { id, contentType, contentLength: buffer.length }, id);
    return updatedData;
  }
  /**
   * Retrieve binary content associated with a resource
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} Object with buffer and contentType
   * @example
   * const content = await resource.content('user-123');
   * if (content.buffer) {
         *   // Save to file
   *   fs.writeFileSync('output.jpg', content.buffer);
   * } else {
      * }
   */
  async content(id) {
    const key = this.getResourceKey(id);
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      if (err.name === "NoSuchKey") {
        return {
          buffer: null,
          contentType: null
        };
      }
      throw err;
    }
    const buffer = Buffer.from(await response.Body.transformToByteArray());
    const contentType = response.ContentType || null;
    this._emitStandardized("content-fetched", { id, contentLength: buffer.length, contentType }, id);
    return {
      buffer,
      contentType
    };
  }
  /**
   * Check if binary content exists for a resource
   * @param {string} id - Resource ID
   * @returns {boolean}
   */
  async hasContent(id) {
    const key = this.getResourceKey(id);
    const [ok, err, response] = await tryFn(() => this.client.headObject(key));
    if (!ok) return false;
    return response.ContentLength > 0;
  }
  /**
   * Delete binary content but preserve metadata
   * @param {string} id - Resource ID
   */
  async deleteContent(id) {
    const key = this.getResourceKey(id);
    const [ok, err, existingObject] = await tryFn(() => this.client.headObject(key));
    if (!ok) throw err;
    const existingMetadata = existingObject.Metadata || {};
    const [ok2, err2, response] = await tryFn(() => this.client.putObject({
      key,
      body: "",
      metadata: existingMetadata
    }));
    if (!ok2) throw err2;
    this._emitStandardized("content-deleted", id, id);
    return response;
  }
  /**
   * Generate definition hash for this resource
   * @returns {string} SHA256 hash of the resource definition (name + attributes)
   */
  getDefinitionHash() {
    const definition = {
      attributes: this.attributes,
      behavior: this.behavior
    };
    const stableString = jsonStableStringify(definition);
    return `sha256:${createHash("sha256").update(stableString).digest("hex")}`;
  }
  /**
   * Extract version from S3 key
   * @param {string} key - S3 object key
   * @returns {string|null} Version string or null
   */
  extractVersionFromKey(key) {
    const parts = key.split("/");
    const versionPart = parts.find((part) => part.startsWith("v="));
    return versionPart ? versionPart.replace("v=", "") : null;
  }
  /**
   * Get schema for a specific version
   * @param {string} version - Version string (e.g., 'v1', 'v2')
   * @returns {Object} Schema object for the version
   */
  async getSchemaForVersion(version) {
    return this.schema;
  }
  /**
   * Create partition references after insert
   * @param {Object} data - Inserted object data
   */
  async createPartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const promises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        const partitionMetadata = {
          _v: String(this.version)
        };
        return this.client.putObject({
          key: partitionKey,
          metadata: partitionMetadata,
          body: "",
          contentType: void 0
        });
      }
      return null;
    });
    const results = await Promise.allSettled(promises);
    const failures = results.filter((r) => r.status === "rejected");
    if (failures.length > 0) {
      this.emit("partitionIndexWarning", {
        operation: "create",
        id: data.id,
        failures: failures.map((f) => f.reason)
      });
    }
  }
  /**
   * Delete partition references after delete
   * @param {Object} data - Deleted object data
   */
  async deletePartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const keysToDelete = [];
    for (const [partitionName, partition] of Object.entries(partitions)) {
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        keysToDelete.push(partitionKey);
      }
    }
    if (keysToDelete.length > 0) {
      const [ok, err] = await tryFn(() => this.client.deleteObjects(keysToDelete));
    }
  }
  /**
   * Query resources with simple filtering and pagination
   * @param {Object} [filter={}] - Filter criteria (exact field matches)
   * @param {Object} [options] - Query options
   * @param {number} [options.limit=100] - Maximum number of results
   * @param {number} [options.offset=0] - Offset for pagination
   * @param {string} [options.partition] - Partition name to query from
   * @param {Object} [options.partitionValues] - Partition field values to filter by
   * @returns {Promise<Object[]>} Array of filtered resource objects
   * @example
   * // Query all resources (no filter)
   * const allUsers = await resource.query();
   * 
   * // Query with simple filter
   * const activeUsers = await resource.query({ status: 'active' });
   * 
   * // Query with multiple filters
   * const usElectronics = await resource.query({
   *   category: 'electronics',
   *   region: 'US'
   * });
   * 
   * // Query with pagination
   * const firstPage = await resource.query(
   *   { status: 'active' },
   *   { limit: 10, offset: 0 }
   * );
   * 
   * // Query within partition
   * const googleUsers = await resource.query(
   *   { status: 'active' },
   *   {
   *     partition: 'byUtmSource',
   *     partitionValues: { 'utm.source': 'google' },
   *     limit: 5
   *   }
   * );
   */
  async query(filter = {}, { limit = 100, offset = 0, partition = null, partitionValues = {} } = {}) {
    await this.executeHooks("beforeQuery", { filter, limit, offset, partition, partitionValues });
    if (Object.keys(filter).length === 0) {
      return await this.list({ partition, partitionValues, limit, offset });
    }
    const results = [];
    let currentOffset = offset;
    const batchSize = Math.min(limit, 50);
    while (results.length < limit) {
      const batch = await this.list({
        partition,
        partitionValues,
        limit: batchSize,
        offset: currentOffset
      });
      if (batch.length === 0) {
        break;
      }
      const filteredBatch = batch.filter((doc) => {
        return Object.entries(filter).every(([key, value]) => {
          return doc[key] === value;
        });
      });
      results.push(...filteredBatch);
      currentOffset += batchSize;
      if (batch.length < batchSize) {
        break;
      }
    }
    const finalResults = results.slice(0, limit);
    return await this.executeHooks("afterQuery", finalResults);
  }
  /**
   * Handle partition reference updates with change detection
   * @param {Object} oldData - Original object data before update
   * @param {Object} newData - Updated object data
   */
  async handlePartitionReferenceUpdates(oldData, newData) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const updatePromises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const [ok, err] = await tryFn(() => this.handlePartitionReferenceUpdate(partitionName, partition, oldData, newData));
      if (!ok) {
        return { partitionName, error: err };
      }
      return { partitionName, success: true };
    });
    await Promise.allSettled(updatePromises);
    const id = newData.id || oldData.id;
    const cleanupPromises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const prefix = `resource=${this.name}/partition=${partitionName}`;
      const [okKeys, errKeys, keys] = await tryFn(() => this.client.getAllKeys({ prefix }));
      if (!okKeys) {
        return;
      }
      const validKey = this.getPartitionKey({ partitionName, id, data: newData });
      const staleKeys = keys.filter((key) => key.endsWith(`/id=${id}`) && key !== validKey);
      if (staleKeys.length > 0) {
        const [okDel, errDel] = await tryFn(() => this.client.deleteObjects(staleKeys));
      }
    });
    await Promise.allSettled(cleanupPromises);
  }
  /**
   * Handle partition reference update for a specific partition
   * @param {string} partitionName - Name of the partition
   * @param {Object} partition - Partition definition
   * @param {Object} oldData - Original object data before update
   * @param {Object} newData - Updated object data
   */
  async handlePartitionReferenceUpdate(partitionName, partition, oldData, newData) {
    const id = newData.id || oldData.id;
    const oldPartitionKey = this.getPartitionKey({ partitionName, id, data: oldData });
    const newPartitionKey = this.getPartitionKey({ partitionName, id, data: newData });
    if (oldPartitionKey !== newPartitionKey) {
      if (oldPartitionKey) {
        const [ok, err] = await tryFn(async () => {
          await this.client.deleteObject(oldPartitionKey);
        });
      }
      if (newPartitionKey) {
        const [ok, err] = await tryFn(async () => {
          const partitionMetadata = {
            _v: String(this.version)
          };
          await this.client.putObject({
            key: newPartitionKey,
            metadata: partitionMetadata,
            body: "",
            contentType: void 0
          });
        });
      }
    } else if (newPartitionKey) {
      const [ok, err] = await tryFn(async () => {
        const partitionMetadata = {
          _v: String(this.version)
        };
        await this.client.putObject({
          key: newPartitionKey,
          metadata: partitionMetadata,
          body: "",
          contentType: void 0
        });
      });
    }
  }
  /**
   * Update partition objects to keep them in sync
   * @param {Object} data - Updated object data
   */
  async updatePartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    for (const [partitionName, partition] of Object.entries(partitions)) {
      if (!partition || !partition.fields || typeof partition.fields !== "object") {
        continue;
      }
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        const partitionMetadata = {
          _v: String(this.version)
        };
        const [ok, err] = await tryFn(async () => {
          await this.client.putObject({
            key: partitionKey,
            metadata: partitionMetadata,
            body: "",
            contentType: void 0
          });
        });
      }
    }
  }
  /**
   * Get a resource object directly from a specific partition
   * @param {Object} params - Partition parameters
   * @param {string} params.id - Resource ID
   * @param {string} params.partitionName - Name of the partition
   * @param {Object} params.partitionValues - Values for partition fields
   * @returns {Promise<Object>} The resource object with partition metadata
   * @example
   * // Get user from UTM source partition
   * const user = await resource.getFromPartition({
   *   id: 'user-123',
   *   partitionName: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
         * 
   * // Get product from multi-field partition
   * const product = await resource.getFromPartition({
   *   id: 'product-456',
   *   partitionName: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async getFromPartition({ id, partitionName, partitionValues = {} }) {
    if (!this.config.partitions || !this.config.partitions[partitionName]) {
      throw new PartitionError(`Partition '${partitionName}' not found`, { resourceName: this.name, partitionName, operation: "getFromPartition" });
    }
    const partition = this.config.partitions[partitionName];
    const partitionSegments = [];
    const sortedFields = Object.entries(partition.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const value = partitionValues[fieldName];
      if (value !== void 0 && value !== null) {
        const transformedValue = this.applyPartitionRule(value, rule);
        partitionSegments.push(`${fieldName}=${transformedValue}`);
      }
    }
    if (partitionSegments.length === 0) {
      throw new PartitionError(`No partition values provided for partition '${partitionName}'`, { resourceName: this.name, partitionName, operation: "getFromPartition" });
    }
    const partitionKey = join(`resource=${this.name}`, `partition=${partitionName}`, ...partitionSegments, `id=${id}`);
    const [ok, err] = await tryFn(async () => {
      await this.client.headObject(partitionKey);
    });
    if (!ok) {
      throw new ResourceError(`Resource with id '${id}' not found in partition '${partitionName}'`, { resourceName: this.name, id, partitionName, operation: "getFromPartition" });
    }
    const data = await this.get(id);
    data._partition = partitionName;
    data._partitionValues = partitionValues;
    this._emitStandardized("partition-fetched", data, data.id);
    return data;
  }
  /**
   * Create a historical version of an object
   * @param {string} id - Resource ID
   * @param {Object} data - Object data to store historically
   */
  async createHistoricalVersion(id, data) {
    const historicalKey = join(`resource=${this.name}`, `historical`, `id=${id}`);
    const historicalData = {
      ...data,
      _v: data._v || this.version,
      _historicalTimestamp: (/* @__PURE__ */ new Date()).toISOString()
    };
    const mappedData = await this.schema.mapper(historicalData);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: historicalData,
      mappedData
    });
    const finalMetadata = {
      ...processedMetadata,
      _v: data._v || this.version,
      _historicalTimestamp: historicalData._historicalTimestamp
    };
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    await this.client.putObject({
      key: historicalKey,
      metadata: finalMetadata,
      body,
      contentType
    });
  }
  /**
   * Apply version mapping to convert an object from one version to another
   * @param {Object} data - Object data to map
   * @param {string} fromVersion - Source version
   * @param {string} toVersion - Target version
   * @returns {Object} Mapped object data
   */
  async applyVersionMapping(data, fromVersion, toVersion) {
    if (fromVersion === toVersion) {
      return data;
    }
    const mappedData = {
      ...data,
      _v: toVersion,
      _originalVersion: fromVersion,
      _versionMapped: true
    };
    return mappedData;
  }
  /**
   * Compose the full object (metadata + body) as returned by .get(),
   * using in-memory data after insert/update, according to behavior
   */
  async composeFullObjectFromWrite({ id, metadata, body, behavior }) {
    const behaviorFlags = {};
    if (metadata && metadata["$truncated"] === "true") {
      behaviorFlags.$truncated = "true";
    }
    if (metadata && metadata["$overflow"] === "true") {
      behaviorFlags.$overflow = "true";
    }
    let unmappedMetadata = {};
    const [ok, err, unmapped] = await tryFn(() => this.schema.unmapper(metadata));
    unmappedMetadata = ok ? unmapped : metadata;
    const filterInternalFields = (obj) => {
      if (!obj || typeof obj !== "object") return obj;
      const filtered2 = {};
      const pluginAttrNames = this.schema._pluginAttributes ? Object.values(this.schema._pluginAttributes).flat() : [];
      for (const [key, value] of Object.entries(obj)) {
        if (!key.startsWith("_") || key === "_geohash" || key.startsWith("_geohash_zoom") || pluginAttrNames.includes(key)) {
          filtered2[key] = value;
        }
      }
      return filtered2;
    };
    const fixValue = (v) => {
      if (typeof v === "object" && v !== null) {
        return v;
      }
      if (typeof v === "string") {
        if (v === "[object Object]") return {};
        if (v.startsWith("{") || v.startsWith("[")) {
          const [ok2, err2, parsed] = tryFnSync(() => JSON.parse(v));
          return ok2 ? parsed : v;
        }
        return v;
      }
      return v;
    };
    if (behavior === "body-overflow") {
      const hasOverflow = metadata && metadata["$overflow"] === "true";
      let bodyData = {};
      if (hasOverflow && body) {
        const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(JSON.parse(body)));
        if (okBody) {
          let pluginMapFromMeta = null;
          if (metadata && metadata._pluginmap) {
            const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(
              () => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap)
            );
            pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
          }
          const [okUnmap, errUnmap, unmappedBody] = await tryFn(
            () => this.schema.unmapper(parsedBody, void 0, pluginMapFromMeta)
          );
          bodyData = okUnmap ? unmappedBody : {};
        }
      }
      const merged = { ...unmappedMetadata, ...bodyData, id };
      Object.keys(merged).forEach((k) => {
        merged[k] = fixValue(merged[k]);
      });
      const result2 = filterInternalFields(merged);
      if (hasOverflow) {
        result2.$overflow = "true";
      }
      return result2;
    }
    if (behavior === "body-only") {
      const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(body ? JSON.parse(body) : {}));
      let mapFromMeta = this.schema.map;
      let pluginMapFromMeta = null;
      if (metadata && metadata._map) {
        const [okMap, errMap, parsedMap] = await tryFn(() => Promise.resolve(typeof metadata._map === "string" ? JSON.parse(metadata._map) : metadata._map));
        mapFromMeta = okMap ? parsedMap : this.schema.map;
      }
      if (metadata && metadata._pluginmap) {
        const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(() => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap));
        pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
      }
      const [okUnmap, errUnmap, unmappedBody] = await tryFn(() => this.schema.unmapper(parsedBody, mapFromMeta, pluginMapFromMeta));
      const result2 = okUnmap ? { ...unmappedBody, id } : { id };
      Object.keys(result2).forEach((k) => {
        result2[k] = fixValue(result2[k]);
      });
      return result2;
    }
    if (behavior === "user-managed" && body && body.trim() !== "") {
      const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okBody) {
        let pluginMapFromMeta = null;
        if (metadata && metadata._pluginmap) {
          const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(
            () => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap)
          );
          pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
        }
        const [okUnmap, errUnmap, unmappedBody] = await tryFn(
          () => this.schema.unmapper(parsedBody, void 0, pluginMapFromMeta)
        );
        const bodyData = okUnmap ? unmappedBody : {};
        const merged = { ...bodyData, ...unmappedMetadata, id };
        Object.keys(merged).forEach((k) => {
          merged[k] = fixValue(merged[k]);
        });
        return filterInternalFields(merged);
      }
    }
    const result = { ...unmappedMetadata, id };
    Object.keys(result).forEach((k) => {
      result[k] = fixValue(result[k]);
    });
    const filtered = filterInternalFields(result);
    if (behaviorFlags.$truncated) {
      filtered.$truncated = behaviorFlags.$truncated;
    }
    if (behaviorFlags.$overflow) {
      filtered.$overflow = behaviorFlags.$overflow;
    }
    return filtered;
  }
  // --- GUARDS SYSTEM ---
  /**
   * Normalize guard configuration
   * @param {Object|Array|undefined} guard - Guard configuration
   * @returns {Object|null} Normalized guard config
   * @private
   */
  _normalizeGuard(guard) {
    if (!guard) return null;
    if (Array.isArray(guard)) {
      return { "*": guard };
    }
    return guard;
  }
  /**
   * Execute guard for operation
   * @param {string} operation - Operation name (list, get, insert, update, etc)
   * @param {Object} context - Framework-agnostic context
   * @param {Object} context.user - Decoded JWT token
   * @param {Object} context.params - Route params
   * @param {Object} context.body - Request body
   * @param {Object} context.query - Query string
   * @param {Object} context.headers - Request headers
   * @param {Function} context.setPartition - Helper to set partition
   * @param {Object} [resource] - Resource record (for get/update/delete)
   * @returns {Promise<boolean>} True if allowed, false if denied
   */
  async executeGuard(operation, context, resource = null) {
    if (!this.guard) return true;
    let guardFn = this.guard[operation];
    if (!guardFn) {
      guardFn = this.guard["*"];
    }
    if (!guardFn) return true;
    if (typeof guardFn === "boolean") {
      return guardFn;
    }
    if (Array.isArray(guardFn)) {
      return this._checkRolesScopes(guardFn, context.user);
    }
    if (typeof guardFn === "function") {
      try {
        const result = await guardFn(context, resource);
        return result === true;
      } catch (err) {
        console.error(`Guard error for ${operation}:`, err);
        return false;
      }
    }
    return false;
  }
  /**
   * Check if user has required roles or scopes
   * @param {Array<string>} requiredRolesScopes - Required roles/scopes
   * @param {Object} user - User from JWT token
   * @returns {boolean} True if user has any of required roles/scopes
   * @private
   */
  _checkRolesScopes(requiredRolesScopes, user) {
    if (!user) return false;
    const userScopes = user.scope?.split(" ") || [];
    const clientId = user.azp || process.env.CLIENT_ID || "default";
    const clientRoles = user.resource_access?.[clientId]?.roles || [];
    const realmRoles = user.realm_access?.roles || [];
    const azureRoles = user.roles || [];
    const userRoles = [...clientRoles, ...realmRoles, ...azureRoles];
    return requiredRolesScopes.some((required) => {
      return userScopes.includes(required) || userRoles.includes(required);
    });
  }
  // --- MIDDLEWARE SYSTEM ---
  _initMiddleware() {
    this._middlewares = /* @__PURE__ */ new Map();
    this._middlewareMethods = [
      "get",
      "list",
      "listIds",
      "getAll",
      "count",
      "page",
      "insert",
      "update",
      "delete",
      "deleteMany",
      "exists",
      "getMany",
      "content",
      "hasContent",
      "query",
      "getFromPartition",
      "setContent",
      "deleteContent",
      "replace"
    ];
    for (const method of this._middlewareMethods) {
      this._middlewares.set(method, []);
      if (!this[`_original_${method}`]) {
        this[`_original_${method}`] = this[method].bind(this);
        this[method] = async (...args) => {
          const ctx = { resource: this, args, method };
          let idx = -1;
          const stack = this._middlewares.get(method);
          const dispatch = async (i) => {
            if (i <= idx) {
              throw new ResourceError("Resource middleware next() called multiple times", {
                resourceName: this.name,
                operation: method,
                statusCode: 500,
                retriable: false,
                suggestion: "Ensure each middleware awaits next() at most once."
              });
            }
            idx = i;
            if (i < stack.length) {
              return await stack[i](ctx, () => dispatch(i + 1));
            } else {
              return await this[`_original_${method}`](...ctx.args);
            }
          };
          return await dispatch(0);
        };
      }
    }
  }
  useMiddleware(method, fn) {
    if (!this._middlewares) this._initMiddleware();
    if (!this._middlewares.has(method)) throw new ResourceError(`No such method for middleware: ${method}`, { operation: "useMiddleware", method });
    this._middlewares.get(method).push(fn);
  }
  // Utility to apply schema default values
  applyDefaults(data) {
    const out = { ...data };
    for (const [key, def] of Object.entries(this.attributes)) {
      if (out[key] === void 0) {
        if (typeof def === "string" && def.includes("default:")) {
          const match = def.match(/default:([^|]+)/);
          if (match) {
            let val = match[1];
            if (def.includes("boolean")) val = val === "true";
            else if (def.includes("number")) val = Number(val);
            out[key] = val;
          }
        }
      }
    }
    return out;
  }
  // ============================================================================
  // STATE MACHINE METHODS
  // ============================================================================
  /**
   * State machine accessor object
   * Provides namespaced access to state machine operations
   * @type {Object}
   * @property {Function} send - Trigger state transition
   * @property {Function} get - Get current state
   * @property {Function} canTransition - Check if transition is valid
   * @property {Function} getValidEvents - Get valid events for current state
   * @property {Function} initialize - Initialize entity with initial state
   * @property {Function} history - Get transition history
   * @example
   * await orders.state.send('order-123', 'CONFIRM');
   * const state = await orders.state.get('order-123');
   * const canShip = await orders.state.canTransition('order-123', 'SHIP');
   */
  get state() {
    const resource = this;
    const throwIfNoStateMachine = () => {
      if (!resource._stateMachine) {
        throw new ResourceError(`State machine not configured for resource '${resource.name}'`, {
          resourceName: resource.name,
          operation: "stateMachine",
          statusCode: 400,
          retriable: false,
          suggestion: "Install and configure the StateMachinePlugin before calling resource.state.* methods.",
          docs: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/state-machine.md"
        });
      }
    };
    return {
      /**
       * Trigger a state transition
       * @param {string} id - Entity ID
       * @param {string} event - Event name
       * @param {Object} [eventData] - Event data
       * @returns {Promise<Object>} Transition result
       * @example
       * await orders.state.send('order-123', 'CONFIRM', { confirmedBy: 'user-456' });
       */
      send: async (id, event, eventData) => {
        throwIfNoStateMachine();
        return resource._stateMachine.send(id, event, eventData);
      },
      /**
       * Get current state of an entity
       * @param {string} id - Entity ID
       * @returns {Promise<string>} Current state
       * @example
       * const currentState = await orders.state.get('order-123');
       */
      get: async (id) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getState(id);
      },
      /**
       * Check if a transition is valid
       * @param {string} id - Entity ID
       * @param {string} event - Event name
       * @returns {Promise<boolean>} True if transition is valid
       * @example
       * const canConfirm = await orders.state.canTransition('order-123', 'CONFIRM');
       */
      canTransition: async (id, event) => {
        throwIfNoStateMachine();
        return resource._stateMachine.canTransition(id, event);
      },
      /**
       * Get all valid events for the current state
       * @param {string} id - Entity ID
       * @returns {Promise<Array<string>>} Array of valid event names
       * @example
       * const events = await orders.state.getValidEvents('order-123');
       * // Returns: ['SHIP', 'CANCEL']
       */
      getValidEvents: async (id) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getValidEvents(id);
      },
      /**
       * Initialize entity with initial state
       * @param {string} id - Entity ID
       * @param {Object} [context] - Initial context data
       * @returns {Promise<void>}
       * @example
       * await orders.state.initialize('order-456', { customerId: 'user-123' });
       */
      initialize: async (id, context) => {
        throwIfNoStateMachine();
        return resource._stateMachine.initializeEntity(id, context);
      },
      /**
       * Get transition history for an entity
       * @param {string} id - Entity ID
       * @param {Object} [options] - Query options
       * @param {number} [options.limit=100] - Maximum number of transitions
       * @param {Date} [options.fromDate] - Filter from date
       * @param {Date} [options.toDate] - Filter to date
       * @returns {Promise<Array<Object>>} Transition history
       * @example
       * const history = await orders.state.history('order-123', { limit: 50 });
       */
      history: async (id, options) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getTransitionHistory(id, options);
      }
    };
  }
  /**
   * Internal method to attach state machine instance
   * This is called by StateMachinePlugin during initialization
   * @private
   * @param {Object} stateMachine - State machine instance
   */
  _attachStateMachine(stateMachine) {
    this._stateMachine = stateMachine;
  }
}
function validateResourceConfig(config) {
  const errors = [];
  if (!config.name) {
    errors.push("Resource 'name' is required");
  } else if (typeof config.name !== "string") {
    errors.push("Resource 'name' must be a string");
  } else if (config.name.trim() === "") {
    errors.push("Resource 'name' cannot be empty");
  }
  if (!config.client) {
    errors.push("S3 'client' is required");
  }
  if (!config.attributes) {
    errors.push("Resource 'attributes' are required");
  } else if (typeof config.attributes !== "object" || Array.isArray(config.attributes)) {
    errors.push("Resource 'attributes' must be an object");
  } else if (Object.keys(config.attributes).length === 0) {
    errors.push("Resource 'attributes' cannot be empty");
  }
  if (config.version !== void 0 && typeof config.version !== "string") {
    errors.push("Resource 'version' must be a string");
  }
  if (config.behavior !== void 0 && typeof config.behavior !== "string") {
    errors.push("Resource 'behavior' must be a string");
  }
  if (config.passphrase !== void 0 && typeof config.passphrase !== "string") {
    errors.push("Resource 'passphrase' must be a string");
  }
  if (config.parallelism !== void 0) {
    if (typeof config.parallelism !== "number" || !Number.isInteger(config.parallelism)) {
      errors.push("Resource 'parallelism' must be an integer");
    } else if (config.parallelism < 1) {
      errors.push("Resource 'parallelism' must be greater than 0");
    }
  }
  if (config.observers !== void 0 && !Array.isArray(config.observers)) {
    errors.push("Resource 'observers' must be an array");
  }
  const booleanFields = ["cache", "autoDecrypt", "timestamps", "paranoid", "allNestedObjectsOptional"];
  for (const field of booleanFields) {
    if (config[field] !== void 0 && typeof config[field] !== "boolean") {
      errors.push(`Resource '${field}' must be a boolean`);
    }
  }
  if (config.idGenerator !== void 0) {
    if (typeof config.idGenerator !== "function" && typeof config.idGenerator !== "number") {
      errors.push("Resource 'idGenerator' must be a function or a number (size)");
    } else if (typeof config.idGenerator === "number" && config.idGenerator <= 0) {
      errors.push("Resource 'idGenerator' size must be greater than 0");
    }
  }
  if (config.idSize !== void 0) {
    if (typeof config.idSize !== "number" || !Number.isInteger(config.idSize)) {
      errors.push("Resource 'idSize' must be an integer");
    } else if (config.idSize <= 0) {
      errors.push("Resource 'idSize' must be greater than 0");
    }
  }
  if (config.partitions !== void 0) {
    if (typeof config.partitions !== "object" || Array.isArray(config.partitions)) {
      errors.push("Resource 'partitions' must be an object");
    } else {
      for (const [partitionName, partitionDef] of Object.entries(config.partitions)) {
        if (typeof partitionDef !== "object" || Array.isArray(partitionDef)) {
          errors.push(`Partition '${partitionName}' must be an object`);
        } else if (!partitionDef.fields) {
          errors.push(`Partition '${partitionName}' must have a 'fields' property`);
        } else if (typeof partitionDef.fields !== "object" || Array.isArray(partitionDef.fields)) {
          errors.push(`Partition '${partitionName}.fields' must be an object`);
        } else {
          for (const [fieldName, fieldType] of Object.entries(partitionDef.fields)) {
            if (typeof fieldType !== "string") {
              errors.push(`Partition '${partitionName}.fields.${fieldName}' must be a string`);
            }
          }
        }
      }
    }
  }
  if (config.hooks !== void 0) {
    if (typeof config.hooks !== "object" || Array.isArray(config.hooks)) {
      errors.push("Resource 'hooks' must be an object");
    } else {
      const validHookEvents = [
        "beforeInsert",
        "afterInsert",
        "beforeUpdate",
        "afterUpdate",
        "beforeDelete",
        "afterDelete",
        "beforeGet",
        "afterGet",
        "beforeList",
        "afterList",
        "beforeQuery",
        "afterQuery",
        "beforeExists",
        "afterExists",
        "beforeCount",
        "afterCount",
        "beforePatch",
        "afterPatch",
        "beforeReplace",
        "afterReplace",
        "beforeGetMany",
        "afterGetMany",
        "beforeDeleteMany",
        "afterDeleteMany"
      ];
      for (const [event, hooksArr] of Object.entries(config.hooks)) {
        if (!validHookEvents.includes(event)) {
          errors.push(`Invalid hook event '${event}'. Valid events: ${validHookEvents.join(", ")}`);
        } else if (!Array.isArray(hooksArr)) {
          errors.push(`Resource 'hooks.${event}' must be an array`);
        } else {
          for (let i = 0; i < hooksArr.length; i++) {
            const hook = hooksArr[i];
            if (typeof hook !== "function") {
              if (typeof hook === "string") continue;
              continue;
            }
          }
        }
      }
    }
  }
  if (config.events !== void 0) {
    if (typeof config.events !== "object" || Array.isArray(config.events)) {
      errors.push("Resource 'events' must be an object");
    } else {
      for (const [eventName, listeners] of Object.entries(config.events)) {
        if (Array.isArray(listeners)) {
          for (let i = 0; i < listeners.length; i++) {
            const listener = listeners[i];
            if (typeof listener !== "function") {
              errors.push(`Resource 'events.${eventName}[${i}]' must be a function`);
            }
          }
        } else if (typeof listeners !== "function") {
          errors.push(`Resource 'events.${eventName}' must be a function or array of functions`);
        }
      }
    }
  }
  return {
    isValid: errors.length === 0,
    errors
  };
}

class MLError extends PluginError {
  constructor(message, context = {}) {
    const merged = {
      pluginName: context.pluginName || "MLPlugin",
      operation: context.operation || "unknown",
      statusCode: context.statusCode ?? 500,
      retriable: context.retriable ?? false,
      suggestion: context.suggestion ?? "Review ML plugin configuration and datasets before retrying.",
      ...context
    };
    super(message, merged);
    this.name = "MLError";
  }
}
class ModelConfigError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: context.statusCode ?? 400,
      retriable: context.retriable ?? false,
      suggestion: context.suggestion ?? "Validate layer definitions, optimizer, and loss function values.",
      ...context
    });
    this.name = "ModelConfigError";
  }
}
class TrainingError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      retriable: context.retriable ?? true,
      suggestion: context.suggestion ?? "Inspect training logs, data shapes, and GPU availability, then retry.",
      ...context
    });
    this.name = "TrainingError";
  }
}
let PredictionError$1 = class PredictionError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      retriable: context.retriable ?? true,
      suggestion: context.suggestion ?? "Verify the model is loaded and input tensors match the expected schema.",
      ...context
    });
    this.name = "PredictionError";
  }
};
class ModelNotFoundError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: 404,
      retriable: false,
      suggestion: context.suggestion ?? "Train the model or load it from storage before invoking inference.",
      ...context
    });
    this.name = "ModelNotFoundError";
  }
}
let ModelNotTrainedError$1 = class ModelNotTrainedError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: 409,
      retriable: false,
      suggestion: context.suggestion ?? "Run train() for this model or load a trained checkpoint.",
      ...context
    });
    this.name = "ModelNotTrainedError";
  }
};
class DataValidationError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: 422,
      retriable: false,
      suggestion: context.suggestion ?? "Normalize input data and ensure required features are provided.",
      ...context
    });
    this.name = "DataValidationError";
  }
}
class InsufficientDataError extends MLError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: 400,
      retriable: false,
      suggestion: context.suggestion ?? "Collect more samples, reduce batch size, or adjust minimumRecords configuration.",
      ...context
    });
    this.name = "InsufficientDataError";
  }
}
class TensorFlowDependencyError extends MLError {
  constructor(message = "TensorFlow.js is not installed. Run: pnpm add @tensorflow/tfjs-node", context = {}) {
    super(message, {
      retriable: false,
      suggestion: context.suggestion ?? "Install @tensorflow/tfjs-node or @tensorflow/tfjs to enable ML features.",
      ...context
    });
    this.name = "TensorFlowDependencyError";
  }
}

class BaseModel {
  constructor(config = {}) {
    if (this.constructor === BaseModel) {
      throw new Error("BaseModel is an abstract class and cannot be instantiated directly");
    }
    this.config = {
      name: config.name || "unnamed",
      resource: config.resource,
      features: config.features || [],
      target: config.target,
      minSamples: Math.max(1, config.minSamples ?? 10),
      modelConfig: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        shuffle: true,
        ...config.modelConfig
      },
      verbose: config.verbose || false
    };
    this.model = null;
    this.isTrained = false;
    this.normalizer = {
      features: {},
      target: {}
    };
    this.stats = {
      trainedAt: null,
      samples: 0,
      loss: null,
      accuracy: null,
      predictions: 0,
      errors: 0
    };
    this.tf = null;
    this._tfValidated = false;
  }
  /**
   * Validate and load TensorFlow.js (lazy loading)
   * @private
   */
  async _validateTensorFlow() {
    if (this._tfValidated) {
      return;
    }
    try {
      this.tf = require("@tensorflow/tfjs-node");
      this._tfValidated = true;
    } catch (requireError) {
      try {
        const tfModule = await import('@tensorflow/tfjs-node');
        this.tf = tfModule.default || tfModule;
        this._tfValidated = true;
      } catch (importError) {
        throw new TensorFlowDependencyError(
          "TensorFlow.js is not installed. Run: pnpm add @tensorflow/tfjs-node",
          { originalError: importError.message }
        );
      }
    }
  }
  /**
   * Abstract method: Build the model architecture
   * Must be implemented by subclasses
   * @abstract
   */
  buildModel() {
    throw new Error("buildModel() must be implemented by subclass");
  }
  /**
   * Train the model with provided data
   * @param {Array} data - Training data records
   * @returns {Object} Training results
   */
  async train(data) {
    if (!this._tfValidated) {
      await this._validateTensorFlow();
    }
    try {
      if (!data || data.length === 0) {
        throw new InsufficientDataError("No training data provided", {
          model: this.config.name
        });
      }
      const configuredMin = this.config.minSamples ?? 10;
      const batchSize = this.config.modelConfig.batchSize || configuredMin;
      const minSamples = Math.max(1, Math.min(configuredMin, batchSize));
      if (data.length < minSamples) {
        throw new InsufficientDataError(
          `Insufficient training data: ${data.length} samples (minimum: ${minSamples})`,
          { model: this.config.name, samples: data.length, minimum: minSamples }
        );
      }
      const { xs, ys } = this._prepareData(data);
      if (!this.model) {
        this.buildModel();
      }
      const history = await this.model.fit(xs, ys, {
        epochs: this.config.modelConfig.epochs,
        batchSize: this.config.modelConfig.batchSize,
        validationSplit: this.config.modelConfig.validationSplit,
        shuffle: this.config.modelConfig.shuffle,
        verbose: this.config.verbose ? 1 : 0,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            if (this.config.verbose && epoch % 10 === 0) {
              console.log(`[MLPlugin] ${this.config.name} - Epoch ${epoch}: loss=${logs.loss.toFixed(4)}`);
            }
          }
        }
      });
      this.isTrained = true;
      this.stats.trainedAt = (/* @__PURE__ */ new Date()).toISOString();
      this.stats.samples = data.length;
      this.stats.loss = history.history.loss[history.history.loss.length - 1];
      if (history.history.acc) {
        this.stats.accuracy = history.history.acc[history.history.acc.length - 1];
      }
      xs.dispose();
      ys.dispose();
      if (this.config.verbose) {
        console.log(`[MLPlugin] ${this.config.name} - Training completed:`, {
          samples: this.stats.samples,
          loss: this.stats.loss,
          accuracy: this.stats.accuracy
        });
      }
      return {
        loss: this.stats.loss,
        accuracy: this.stats.accuracy,
        epochs: this.config.modelConfig.epochs,
        samples: this.stats.samples
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof InsufficientDataError || error instanceof DataValidationError) {
        throw error;
      }
      throw new TrainingError(`Training failed: ${error.message}`, {
        model: this.config.name,
        originalError: error.message
      });
    }
  }
  /**
   * Make a prediction with the trained model
   * @param {Object} input - Input features
   * @returns {Object} Prediction result
   */
  async predict(input) {
    if (!this._tfValidated) {
      await this._validateTensorFlow();
    }
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      this._validateInput(input);
      const features = this._extractFeatures(input);
      const normalizedFeatures = this._normalizeFeatures(features);
      const inputTensor = this.tf.tensor2d([normalizedFeatures]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const prediction = this._denormalizePrediction(predictionArray[0]);
      this.stats.predictions++;
      return {
        prediction,
        confidence: this._calculateConfidence(predictionArray[0])
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError$1 || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError$1(`Prediction failed: ${error.message}`, {
        model: this.config.name,
        input,
        originalError: error.message
      });
    }
  }
  /**
   * Make predictions for multiple inputs
   * @param {Array} inputs - Array of input objects
   * @returns {Array} Array of prediction results
   */
  async predictBatch(inputs) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    for (const input of inputs) {
      predictions.push(await this.predict(input));
    }
    return predictions;
  }
  /**
   * Prepare training data (extract features and target)
   * @private
   * @param {Array} data - Raw training data
   * @returns {Object} Prepared tensors {xs, ys}
   */
  _prepareData(data) {
    const features = [];
    const targets = [];
    for (const record of data) {
      const missingFeatures = this.config.features.filter((f) => !(f in record));
      if (missingFeatures.length > 0) {
        throw new DataValidationError(
          `Missing features in training data: ${missingFeatures.join(", ")}`,
          { model: this.config.name, missingFeatures, record }
        );
      }
      if (!(this.config.target in record)) {
        throw new DataValidationError(
          `Missing target "${this.config.target}" in training data`,
          { model: this.config.name, target: this.config.target, record }
        );
      }
      const featureValues = this._extractFeatures(record);
      features.push(featureValues);
      targets.push(record[this.config.target]);
    }
    this._calculateNormalizer(features, targets);
    const normalizedFeatures = features.map((f) => this._normalizeFeatures(f));
    const normalizedTargets = targets.map((t) => this._normalizeTarget(t));
    return {
      xs: this.tf.tensor2d(normalizedFeatures),
      ys: this._prepareTargetTensor(normalizedTargets)
    };
  }
  /**
   * Prepare target tensor (can be overridden by subclasses)
   * @protected
   * @param {Array} targets - Normalized target values
   * @returns {Tensor} Target tensor
   */
  _prepareTargetTensor(targets) {
    return this.tf.tensor2d(targets.map((t) => [t]));
  }
  /**
   * Extract feature values from a record
   * @private
   * @param {Object} record - Data record
   * @returns {Array} Feature values
   */
  _extractFeatures(record) {
    return this.config.features.map((feature) => {
      const value = record[feature];
      if (typeof value !== "number") {
        throw new DataValidationError(
          `Feature "${feature}" must be a number, got ${typeof value}`,
          { model: this.config.name, feature, value, type: typeof value }
        );
      }
      return value;
    });
  }
  /**
   * Calculate normalization parameters (min-max scaling)
   * @private
   */
  _calculateNormalizer(features, targets) {
    const numFeatures = features[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const featureName = this.config.features[i];
      const values = features.map((f) => f[i]);
      this.normalizer.features[featureName] = {
        min: Math.min(...values),
        max: Math.max(...values)
      };
    }
    this.normalizer.target = {
      min: Math.min(...targets),
      max: Math.max(...targets)
    };
  }
  /**
   * Normalize features using min-max scaling
   * @private
   */
  _normalizeFeatures(features) {
    return features.map((value, i) => {
      const featureName = this.config.features[i];
      const { min, max } = this.normalizer.features[featureName];
      if (max === min) return 0.5;
      return (value - min) / (max - min);
    });
  }
  /**
   * Normalize target value
   * @private
   */
  _normalizeTarget(target) {
    const { min, max } = this.normalizer.target;
    if (max === min) return 0.5;
    return (target - min) / (max - min);
  }
  /**
   * Denormalize prediction
   * @private
   */
  _denormalizePrediction(normalizedValue) {
    const { min, max } = this.normalizer.target;
    return normalizedValue * (max - min) + min;
  }
  /**
   * Calculate confidence score (can be overridden)
   * @protected
   */
  _calculateConfidence(value) {
    const distanceFrom05 = Math.abs(value - 0.5);
    return Math.min(0.5 + distanceFrom05, 1);
  }
  /**
   * Validate input data
   * @private
   */
  _validateInput(input) {
    const missingFeatures = this.config.features.filter((f) => !(f in input));
    if (missingFeatures.length > 0) {
      throw new DataValidationError(
        `Missing features: ${missingFeatures.join(", ")}`,
        { model: this.config.name, missingFeatures, input }
      );
    }
  }
  /**
   * Export model to JSON (for persistence)
   * @returns {Object} Serialized model
   */
  async export() {
    if (!this.model) {
      return null;
    }
    const modelJSON = await this.model.toJSON();
    return {
      config: this.config,
      normalizer: this.normalizer,
      stats: this.stats,
      isTrained: this.isTrained,
      model: modelJSON
    };
  }
  /**
   * Import model from JSON
   * @param {Object} data - Serialized model data
   */
  async import(data) {
    if (!this._tfValidated) {
      await this._validateTensorFlow();
    }
    this.config = {
      ...this.config,
      ...data.config,
      modelConfig: {
        ...this.config.modelConfig,
        ...data.config?.modelConfig || {}
      }
    };
    if (data.config?.minSamples) {
      this.config.minSamples = Math.max(1, data.config.minSamples);
    }
    this.normalizer = data.normalizer || this.normalizer;
    this.stats = data.stats || this.stats;
    this.isTrained = data.isTrained ?? false;
    if (this.model && typeof this.model.dispose === "function") {
      this.model.dispose();
    }
    if (data.model) {
      this.model = await this.tf.models.modelFromJSON(data.model);
    } else {
      this.buildModel();
    }
  }
  /**
   * Dispose model and free memory
   */
  dispose() {
    if (this.model) {
      this.model.dispose();
      this.model = null;
    }
    this.isTrained = false;
  }
  /**
   * Get model statistics
   */
  getStats() {
    return {
      ...this.stats,
      isTrained: this.isTrained,
      config: this.config
    };
  }
}

class RegressionModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      polynomial: config.modelConfig?.polynomial || 1,
      // Degree (1 = linear, 2+ = polynomial)
      units: config.modelConfig?.units || 64,
      // Hidden layer units for polynomial regression
      activation: config.modelConfig?.activation || "relu"
    };
    if (this.config.modelConfig.polynomial < 1 || this.config.modelConfig.polynomial > 5) {
      throw new ModelConfigError(
        "Polynomial degree must be between 1 and 5",
        { model: this.config.name, polynomial: this.config.modelConfig.polynomial }
      );
    }
  }
  /**
   * Build regression model architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    const polynomial = this.config.modelConfig.polynomial;
    this.model = this.tf.sequential();
    if (polynomial === 1) {
      this.model.add(this.tf.layers.dense({
        inputShape: [numFeatures],
        units: 1,
        useBias: true
      }));
    } else {
      this.model.add(this.tf.layers.dense({
        inputShape: [numFeatures],
        units: this.config.modelConfig.units,
        activation: this.config.modelConfig.activation,
        useBias: true
      }));
      if (polynomial >= 3) {
        this.model.add(this.tf.layers.dense({
          units: Math.floor(this.config.modelConfig.units / 2),
          activation: this.config.modelConfig.activation
        }));
      }
      this.model.add(this.tf.layers.dense({
        units: 1
      }));
    }
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: "meanSquaredError",
      metrics: ["mse", "mae"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built regression model (polynomial degree: ${polynomial})`);
      this.model.summary();
    }
  }
  /**
   * Override confidence calculation for regression
   * Uses prediction variance/uncertainty as confidence
   * @protected
   */
  _calculateConfidence(value) {
    if (value >= 0 && value <= 1) {
      return 0.9 + Math.random() * 0.1;
    }
    const distance = Math.abs(value < 0 ? value : value - 1);
    return Math.max(0.5, 1 - distance);
  }
  /**
   * Get R score (coefficient of determination)
   * Measures how well the model explains the variance in the data
   * @param {Array} data - Test data
   * @returns {number} R score (0-1, higher is better)
   */
  async calculateR2Score(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    const actuals = [];
    for (const record of data) {
      const { prediction } = await this.predict(record);
      predictions.push(prediction);
      actuals.push(record[this.config.target]);
    }
    const meanActual = actuals.reduce((sum, val) => sum + val, 0) / actuals.length;
    const tss = actuals.reduce((sum, actual) => {
      return sum + Math.pow(actual - meanActual, 2);
    }, 0);
    const rss = predictions.reduce((sum, pred, i) => {
      return sum + Math.pow(actuals[i] - pred, 2);
    }, 0);
    const r2 = 1 - rss / tss;
    return r2;
  }
  /**
   * Export model with regression-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "regression",
      polynomial: this.config.modelConfig.polynomial
    };
  }
}

class ClassificationModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      units: config.modelConfig?.units || 64,
      // Hidden layer units
      activation: config.modelConfig?.activation || "relu",
      dropout: config.modelConfig?.dropout || 0.2
      // Dropout rate for regularization
    };
    this.classes = [];
    this.classToIndex = {};
    this.indexToClass = {};
  }
  /**
   * Build classification model architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    const numClasses = this.classes.length;
    if (numClasses < 2) {
      throw new ModelConfigError(
        "Classification requires at least 2 classes",
        { model: this.config.name, numClasses }
      );
    }
    this.model = this.tf.sequential();
    this.model.add(this.tf.layers.dense({
      inputShape: [numFeatures],
      units: this.config.modelConfig.units,
      activation: this.config.modelConfig.activation,
      useBias: true
    }));
    if (this.config.modelConfig.dropout > 0) {
      this.model.add(this.tf.layers.dropout({
        rate: this.config.modelConfig.dropout
      }));
    }
    this.model.add(this.tf.layers.dense({
      units: Math.floor(this.config.modelConfig.units / 2),
      activation: this.config.modelConfig.activation
    }));
    const isBinary = numClasses === 2;
    this.model.add(this.tf.layers.dense({
      units: isBinary ? 1 : numClasses,
      activation: isBinary ? "sigmoid" : "softmax"
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: isBinary ? "binaryCrossentropy" : "categoricalCrossentropy",
      metrics: ["accuracy"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built classification model (${numClasses} classes, ${isBinary ? "binary" : "multi-class"})`);
      this.model.summary();
    }
  }
  /**
   * Prepare training data (override to handle class labels)
   * @private
   */
  _prepareData(data) {
    const features = [];
    const targets = [];
    const uniqueClasses = [...new Set(data.map((r) => r[this.config.target]))];
    this.classes = uniqueClasses.sort();
    this.classes.forEach((cls, idx) => {
      this.classToIndex[cls] = idx;
      this.indexToClass[idx] = cls;
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Detected ${this.classes.length} classes:`, this.classes);
    }
    for (const record of data) {
      const missingFeatures = this.config.features.filter((f) => !(f in record));
      if (missingFeatures.length > 0) {
        throw new DataValidationError(
          `Missing features in training data: ${missingFeatures.join(", ")}`,
          { model: this.config.name, missingFeatures, record }
        );
      }
      if (!(this.config.target in record)) {
        throw new DataValidationError(
          `Missing target "${this.config.target}" in training data`,
          { model: this.config.name, target: this.config.target, record }
        );
      }
      const featureValues = this._extractFeatures(record);
      features.push(featureValues);
      const targetClass = record[this.config.target];
      if (!(targetClass in this.classToIndex)) {
        throw new DataValidationError(
          `Unknown class "${targetClass}" in training data`,
          { model: this.config.name, targetClass, knownClasses: this.classes }
        );
      }
      targets.push(this.classToIndex[targetClass]);
    }
    this._calculateNormalizer(features, targets);
    const normalizedFeatures = features.map((f) => this._normalizeFeatures(f));
    return {
      xs: this.tf.tensor2d(normalizedFeatures),
      ys: this._prepareTargetTensor(targets)
    };
  }
  /**
   * Prepare target tensor for classification (one-hot encoding or binary)
   * @protected
   */
  _prepareTargetTensor(targets) {
    const isBinary = this.classes.length === 2;
    if (isBinary) {
      return this.tf.tensor2d(targets.map((t) => [t]));
    } else {
      return this.tf.oneHot(targets, this.classes.length);
    }
  }
  /**
   * Calculate normalization parameters (skip target normalization for classification)
   * @private
   */
  _calculateNormalizer(features, targets) {
    const numFeatures = features[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const featureName = this.config.features[i];
      const values = features.map((f) => f[i]);
      this.normalizer.features[featureName] = {
        min: Math.min(...values),
        max: Math.max(...values)
      };
    }
    this.normalizer.target = { min: 0, max: 1 };
  }
  /**
   * Make a prediction (override to return class label)
   */
  async predict(input) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      this._validateInput(input);
      const features = this._extractFeatures(input);
      const normalizedFeatures = this._normalizeFeatures(features);
      const inputTensor = this.tf.tensor2d([normalizedFeatures]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const isBinary = this.classes.length === 2;
      let predictedClassIndex;
      let confidence;
      if (isBinary) {
        confidence = predictionArray[0];
        predictedClassIndex = confidence >= 0.5 ? 1 : 0;
      } else {
        predictedClassIndex = predictionArray.indexOf(Math.max(...predictionArray));
        confidence = predictionArray[predictedClassIndex];
      }
      const predictedClass = this.indexToClass[predictedClassIndex];
      this.stats.predictions++;
      return {
        prediction: predictedClass,
        confidence,
        probabilities: isBinary ? {
          [this.classes[0]]: 1 - predictionArray[0],
          [this.classes[1]]: predictionArray[0]
        } : Object.fromEntries(
          this.classes.map((cls, idx) => [cls, predictionArray[idx]])
        )
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError$1 || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError(`Prediction failed: ${error.message}`, {
        model: this.config.name,
        input,
        originalError: error.message
      });
    }
  }
  /**
   * Calculate confusion matrix
   * @param {Array} data - Test data
   * @returns {Object} Confusion matrix and metrics
   */
  async calculateConfusionMatrix(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const matrix = {};
    this.classes.length;
    for (const actualClass of this.classes) {
      matrix[actualClass] = {};
      for (const predictedClass of this.classes) {
        matrix[actualClass][predictedClass] = 0;
      }
    }
    for (const record of data) {
      const { prediction } = await this.predict(record);
      const actual = record[this.config.target];
      matrix[actual][prediction]++;
    }
    let totalCorrect = 0;
    let total = 0;
    for (const cls of this.classes) {
      totalCorrect += matrix[cls][cls];
      total += Object.values(matrix[cls]).reduce((sum, val) => sum + val, 0);
    }
    const accuracy = total > 0 ? totalCorrect / total : 0;
    return {
      matrix,
      accuracy,
      total,
      correct: totalCorrect
    };
  }
  /**
   * Export model with classification-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "classification",
      classes: this.classes,
      classToIndex: this.classToIndex,
      indexToClass: this.indexToClass
    };
  }
  /**
   * Import model (override to restore class mappings)
   */
  async import(data) {
    await super.import(data);
    this.classes = data.classes || [];
    this.classToIndex = data.classToIndex || {};
    this.indexToClass = data.indexToClass || {};
  }
}

class TimeSeriesModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      lookback: config.modelConfig?.lookback || 10,
      // Number of past timesteps to use
      lstmUnits: config.modelConfig?.lstmUnits || 50,
      // LSTM layer units
      denseUnits: config.modelConfig?.denseUnits || 25,
      // Dense layer units
      dropout: config.modelConfig?.dropout || 0.2,
      recurrentDropout: config.modelConfig?.recurrentDropout || 0.2
    };
    this.config.modelConfig.shuffle = config.modelConfig?.shuffle ?? false;
    if (this.config.modelConfig.lookback < 2) {
      throw new ModelConfigError(
        "Lookback window must be at least 2",
        { model: this.config.name, lookback: this.config.modelConfig.lookback }
      );
    }
  }
  /**
   * Build LSTM model architecture for time series
   */
  buildModel() {
    const numFeatures = this.config.features.length + 1;
    const lookback = this.config.modelConfig.lookback;
    this.model = this.tf.sequential();
    this.model.add(this.tf.layers.lstm({
      inputShape: [lookback, numFeatures],
      units: this.config.modelConfig.lstmUnits,
      returnSequences: false,
      dropout: this.config.modelConfig.dropout,
      recurrentDropout: this.config.modelConfig.recurrentDropout
    }));
    this.model.add(this.tf.layers.dense({
      units: this.config.modelConfig.denseUnits,
      activation: "relu"
    }));
    if (this.config.modelConfig.dropout > 0) {
      this.model.add(this.tf.layers.dropout({
        rate: this.config.modelConfig.dropout
      }));
    }
    this.model.add(this.tf.layers.dense({
      units: 1
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: "meanSquaredError",
      metrics: ["mse", "mae"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built LSTM time series model (lookback: ${lookback})`);
      this.model.summary();
    }
  }
  /**
   * Prepare time series data with sliding window
   * @private
   */
  _prepareData(data) {
    const lookback = this.config.modelConfig.lookback;
    if (data.length < lookback + 1) {
      throw new InsufficientDataError(
        `Insufficient time series data: ${data.length} samples (minimum: ${lookback + 1})`,
        { model: this.config.name, samples: data.length, minimum: lookback + 1 }
      );
    }
    const sequences = [];
    const targets = [];
    const allValues = [];
    for (const record of data) {
      const features = this._extractFeatures(record);
      const target = record[this.config.target];
      allValues.push([...features, target]);
    }
    this._calculateTimeSeriesNormalizer(allValues);
    for (let i = 0; i <= data.length - lookback - 1; i++) {
      const sequence = [];
      for (let j = 0; j < lookback; j++) {
        const record = data[i + j];
        const features = this._extractFeatures(record);
        const target = record[this.config.target];
        const combined = [...features, target];
        const normalized = this._normalizeSequenceStep(combined);
        sequence.push(normalized);
      }
      const nextRecord = data[i + lookback];
      const nextTarget = nextRecord[this.config.target];
      sequences.push(sequence);
      targets.push(this._normalizeTarget(nextTarget));
    }
    return {
      xs: this.tf.tensor3d(sequences),
      // [samples, lookback, features]
      ys: this.tf.tensor2d(targets.map((t) => [t]))
      // [samples, 1]
    };
  }
  /**
   * Calculate normalization for time series
   * @private
   */
  _calculateTimeSeriesNormalizer(allValues) {
    const numFeatures = allValues[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const values = allValues.map((v) => v[i]);
      const min = Math.min(...values);
      const max = Math.max(...values);
      if (i < this.config.features.length) {
        const featureName = this.config.features[i];
        this.normalizer.features[featureName] = { min, max };
      } else {
        this.normalizer.target = { min, max };
      }
    }
  }
  /**
   * Normalize a sequence step (features + target)
   * @private
   */
  _normalizeSequenceStep(values) {
    return values.map((value, i) => {
      let min, max;
      if (i < this.config.features.length) {
        const featureName = this.config.features[i];
        ({ min, max } = this.normalizer.features[featureName]);
      } else {
        ({ min, max } = this.normalizer.target);
      }
      if (max === min) return 0.5;
      return (value - min) / (max - min);
    });
  }
  /**
   * Predict next value in time series
   * @param {Array} sequence - Array of recent records (length = lookback)
   * @returns {Object} Prediction result
   */
  async predict(sequence) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      if (!Array.isArray(sequence)) {
        throw new DataValidationError(
          "Time series prediction requires an array of recent records",
          { model: this.config.name, input: typeof sequence }
        );
      }
      if (sequence.length !== this.config.modelConfig.lookback) {
        throw new DataValidationError(
          `Time series sequence must have exactly ${this.config.modelConfig.lookback} timesteps, got ${sequence.length}`,
          { model: this.config.name, expected: this.config.modelConfig.lookback, got: sequence.length }
        );
      }
      const normalizedSequence = [];
      for (const record of sequence) {
        this._validateInput(record);
        const features = this._extractFeatures(record);
        const target = record[this.config.target];
        const combined = [...features, target];
        normalizedSequence.push(this._normalizeSequenceStep(combined));
      }
      const inputTensor = this.tf.tensor3d([normalizedSequence]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const prediction = this._denormalizePrediction(predictionArray[0]);
      this.stats.predictions++;
      return {
        prediction,
        confidence: this._calculateConfidence(predictionArray[0])
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError$1 || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError(`Time series prediction failed: ${error.message}`, {
        model: this.config.name,
        originalError: error.message
      });
    }
  }
  /**
   * Predict multiple future timesteps
   * @param {Array} initialSequence - Initial sequence of records
   * @param {number} steps - Number of steps to predict ahead
   * @returns {Array} Array of predictions
   */
  async predictMultiStep(initialSequence, steps = 1) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    let currentSequence = [...initialSequence];
    for (let i = 0; i < steps; i++) {
      const { prediction } = await this.predict(currentSequence);
      predictions.push(prediction);
      currentSequence.shift();
      const lastRecord = currentSequence[currentSequence.length - 1];
      const syntheticRecord = {
        ...lastRecord,
        [this.config.target]: prediction
      };
      currentSequence.push(syntheticRecord);
    }
    return predictions;
  }
  /**
   * Calculate Mean Absolute Percentage Error (MAPE)
   * @param {Array} data - Test data (must be sequential)
   * @returns {number} MAPE (0-100, lower is better)
   */
  async calculateMAPE(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const lookback = this.config.modelConfig.lookback;
    if (data.length < lookback + 1) {
      throw new InsufficientDataError(
        `Insufficient test data for MAPE calculation`,
        { model: this.config.name, samples: data.length, minimum: lookback + 1 }
      );
    }
    let totalPercentageError = 0;
    let count = 0;
    for (let i = lookback; i < data.length; i++) {
      const sequence = data.slice(i - lookback, i);
      const { prediction } = await this.predict(sequence);
      const actual = data[i][this.config.target];
      if (actual !== 0) {
        const percentageError = Math.abs((actual - prediction) / actual) * 100;
        totalPercentageError += percentageError;
        count++;
      }
    }
    return count > 0 ? totalPercentageError / count : 0;
  }
  /**
   * Export model with time series-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "timeseries",
      lookback: this.config.modelConfig.lookback
    };
  }
}

class NeuralNetworkModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      layers: config.modelConfig?.layers || [
        { units: 64, activation: "relu", dropout: 0.2 },
        { units: 32, activation: "relu", dropout: 0.1 }
      ],
      // Array of hidden layer configurations
      outputActivation: config.modelConfig?.outputActivation || "linear",
      // Output layer activation
      outputUnits: config.modelConfig?.outputUnits || 1,
      // Number of output units
      loss: config.modelConfig?.loss || "meanSquaredError",
      // Loss function
      metrics: config.modelConfig?.metrics || ["mse", "mae"]
      // Metrics to track
    };
    this._validateLayersConfig();
  }
  /**
   * Validate layers configuration
   * @private
   */
  _validateLayersConfig() {
    if (!Array.isArray(this.config.modelConfig.layers) || this.config.modelConfig.layers.length === 0) {
      throw new ModelConfigError(
        "Neural network must have at least one hidden layer",
        { model: this.config.name, layers: this.config.modelConfig.layers }
      );
    }
    for (const [index, layer] of this.config.modelConfig.layers.entries()) {
      if (!layer.units || typeof layer.units !== "number" || layer.units < 1) {
        throw new ModelConfigError(
          `Layer ${index} must have a valid "units" property (positive number)`,
          { model: this.config.name, layer, index }
        );
      }
      if (layer.activation && !this._isValidActivation(layer.activation)) {
        throw new ModelConfigError(
          `Layer ${index} has invalid activation function "${layer.activation}"`,
          { model: this.config.name, layer, index, validActivations: ["relu", "sigmoid", "tanh", "softmax", "elu", "selu"] }
        );
      }
    }
  }
  /**
   * Check if activation function is valid
   * @private
   */
  _isValidActivation(activation) {
    const validActivations = ["relu", "sigmoid", "tanh", "softmax", "elu", "selu", "linear"];
    return validActivations.includes(activation);
  }
  /**
   * Build custom neural network architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    this.model = this.tf.sequential();
    for (const [index, layerConfig] of this.config.modelConfig.layers.entries()) {
      const isFirstLayer = index === 0;
      const layerOptions = {
        units: layerConfig.units,
        activation: layerConfig.activation || "relu",
        useBias: true
      };
      if (isFirstLayer) {
        layerOptions.inputShape = [numFeatures];
      }
      this.model.add(this.tf.layers.dense(layerOptions));
      if (layerConfig.dropout && layerConfig.dropout > 0) {
        this.model.add(this.tf.layers.dropout({
          rate: layerConfig.dropout
        }));
      }
      if (layerConfig.batchNormalization) {
        this.model.add(this.tf.layers.batchNormalization());
      }
    }
    this.model.add(this.tf.layers.dense({
      units: this.config.modelConfig.outputUnits,
      activation: this.config.modelConfig.outputActivation
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: this.config.modelConfig.loss,
      metrics: this.config.modelConfig.metrics
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built custom neural network:`);
      console.log(`  - Hidden layers: ${this.config.modelConfig.layers.length}`);
      console.log(`  - Total parameters:`, this._countParameters());
      this.model.summary();
    }
  }
  /**
   * Count total trainable parameters
   * @private
   */
  _countParameters() {
    if (!this.model) return 0;
    let totalParams = 0;
    for (const layer of this.model.layers) {
      if (layer.countParams) {
        totalParams += layer.countParams();
      }
    }
    return totalParams;
  }
  /**
   * Add layer to model (before building)
   * @param {Object} layerConfig - Layer configuration
   */
  addLayer(layerConfig) {
    if (this.model) {
      throw new ModelConfigError(
        "Cannot add layer after model is built. Use addLayer() before training.",
        { model: this.config.name }
      );
    }
    this.config.modelConfig.layers.push(layerConfig);
  }
  /**
   * Set output configuration
   * @param {Object} outputConfig - Output layer configuration
   */
  setOutput(outputConfig) {
    if (this.model) {
      throw new ModelConfigError(
        "Cannot change output after model is built. Use setOutput() before training.",
        { model: this.config.name }
      );
    }
    if (outputConfig.activation) {
      this.config.modelConfig.outputActivation = outputConfig.activation;
    }
    if (outputConfig.units) {
      this.config.modelConfig.outputUnits = outputConfig.units;
    }
    if (outputConfig.loss) {
      this.config.modelConfig.loss = outputConfig.loss;
    }
    if (outputConfig.metrics) {
      this.config.modelConfig.metrics = outputConfig.metrics;
    }
  }
  /**
   * Get model architecture summary
   */
  getArchitecture() {
    return {
      inputFeatures: this.config.features,
      hiddenLayers: this.config.modelConfig.layers.map((layer, index) => ({
        index,
        units: layer.units,
        activation: layer.activation || "relu",
        dropout: layer.dropout || 0,
        batchNormalization: layer.batchNormalization || false
      })),
      outputLayer: {
        units: this.config.modelConfig.outputUnits,
        activation: this.config.modelConfig.outputActivation
      },
      totalParameters: this._countParameters(),
      loss: this.config.modelConfig.loss,
      metrics: this.config.modelConfig.metrics
    };
  }
  /**
   * Train with early stopping callback
   * @param {Array} data - Training data
   * @param {Object} earlyStoppingConfig - Early stopping configuration
   * @returns {Object} Training results
   */
  async trainWithEarlyStopping(data, earlyStoppingConfig = {}) {
    const {
      patience = 10,
      minDelta = 1e-3,
      monitor = "val_loss",
      restoreBestWeights = true
    } = earlyStoppingConfig;
    const { xs, ys } = this._prepareData(data);
    if (!this.model) {
      this.buildModel();
    }
    let bestValue = Infinity;
    let patienceCounter = 0;
    let bestWeights = null;
    const callbacks = {
      onEpochEnd: async (epoch, logs) => {
        const monitorValue = logs[monitor] || logs.loss;
        if (this.config.verbose && epoch % 10 === 0) {
          console.log(`[MLPlugin] ${this.config.name} - Epoch ${epoch}: ${monitor}=${monitorValue.toFixed(4)}`);
        }
        if (monitorValue < bestValue - minDelta) {
          bestValue = monitorValue;
          patienceCounter = 0;
          if (restoreBestWeights) {
            bestWeights = await this.model.getWeights();
          }
        } else {
          patienceCounter++;
          if (patienceCounter >= patience) {
            if (this.config.verbose) {
              console.log(`[MLPlugin] ${this.config.name} - Early stopping at epoch ${epoch}`);
            }
            this.model.stopTraining = true;
          }
        }
      }
    };
    const history = await this.model.fit(xs, ys, {
      epochs: this.config.modelConfig.epochs,
      batchSize: this.config.modelConfig.batchSize,
      validationSplit: this.config.modelConfig.validationSplit,
      verbose: this.config.verbose ? 1 : 0,
      callbacks
    });
    if (restoreBestWeights && bestWeights) {
      this.model.setWeights(bestWeights);
    }
    this.isTrained = true;
    this.stats.trainedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.stats.samples = data.length;
    this.stats.loss = history.history.loss[history.history.loss.length - 1];
    xs.dispose();
    ys.dispose();
    return {
      loss: this.stats.loss,
      epochs: history.epoch.length,
      samples: this.stats.samples,
      stoppedEarly: history.epoch.length < this.config.modelConfig.epochs
    };
  }
  /**
   * Export model with neural network-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "neural-network",
      architecture: this.getArchitecture()
    };
  }
}

class MLPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      models: options.models || {},
      verbose: options.verbose || false,
      minTrainingSamples: options.minTrainingSamples || 10,
      saveModel: options.saveModel !== false,
      // Default true
      saveTrainingData: options.saveTrainingData || false,
      enableVersioning: options.enableVersioning !== false
      // Default true
    };
    this.models = {};
    this._dependenciesValidated = false;
    this.modelVersions = /* @__PURE__ */ new Map();
    this.modelCache = /* @__PURE__ */ new Map();
    this.training = /* @__PURE__ */ new Map();
    this.insertCounters = /* @__PURE__ */ new Map();
    this._pendingAutoTrainingHandlers = /* @__PURE__ */ new Map();
    this._autoTrainingInitialized = /* @__PURE__ */ new Set();
    this.intervals = [];
    this.stats = {
      totalTrainings: 0,
      totalPredictions: 0,
      totalErrors: 0,
      startedAt: null
    };
  }
  /**
   * Install the plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[MLPlugin] Installing ML Plugin...");
    }
    if (!this._dependenciesValidated) {
      let tfAvailable = false;
      try {
        await import('@tensorflow/tfjs-node');
        tfAvailable = true;
        if (this.config.verbose) {
          console.log("[MLPlugin] TensorFlow.js loaded successfully");
        }
      } catch (directImportErr) {
        const result = await requirePluginDependency("ml-plugin", {
          throwOnError: false,
          checkVersions: true
        });
        if (!result.valid) {
          throw new TensorFlowDependencyError(
            "TensorFlow.js dependency not found. Install with: pnpm add @tensorflow/tfjs-node\n" + result.messages.join("\n")
          );
        }
        tfAvailable = result.valid;
      }
      if (!tfAvailable) {
        throw new TensorFlowDependencyError(
          "TensorFlow.js dependency not found. Install with: pnpm add @tensorflow/tfjs-node"
        );
      }
      this._dependenciesValidated = true;
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      this._validateModelConfig(modelName, modelConfig);
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      await this._initializeModel(modelName, modelConfig);
    }
    this._buildModelCache();
    this._injectResourceMethods();
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.autoTrain) {
        this._setupAutoTraining(modelName, modelConfig);
      }
    }
    this.stats.startedAt = (/* @__PURE__ */ new Date()).toISOString();
    if (this.config.verbose) {
      console.log(`[MLPlugin] Installed with ${Object.keys(this.models).length} models`);
    }
    this.emit("db:plugin:installed", {
      plugin: "MLPlugin",
      models: Object.keys(this.models)
    });
  }
  /**
   * Start the plugin
   */
  async onStart() {
    if (this.config.enableVersioning) {
      for (const modelName of Object.keys(this.models)) {
        await this._initializeVersioning(modelName);
      }
    }
    for (const modelName of Object.keys(this.models)) {
      await this._loadModel(modelName);
    }
    if (this.config.verbose) {
      console.log("[MLPlugin] Started");
    }
  }
  /**
   * Stop the plugin
   */
  async onStop() {
    for (const handle of this.intervals) {
      clearInterval(handle);
    }
    this.intervals = [];
    for (const [modelName, model] of Object.entries(this.models)) {
      if (model && model.dispose) {
        model.dispose();
      }
    }
    for (const handler of this._pendingAutoTrainingHandlers.values()) {
      this.database.off("db:resource-created", handler);
    }
    this._pendingAutoTrainingHandlers.clear();
    this._autoTrainingInitialized.clear();
    if (this.config.verbose) {
      console.log("[MLPlugin] Stopped");
    }
  }
  /**
   * Uninstall the plugin
   */
  async onUninstall(options = {}) {
    await this.onStop();
    if (options.purgeData) {
      for (const modelName of Object.keys(this.models)) {
        await this._deleteModel(modelName);
        await this._deleteTrainingData(modelName);
      }
      if (this.config.verbose) {
        console.log("[MLPlugin] Purged all model data and training data");
      }
    }
  }
  /**
   * Build model cache for fast lookup
   * @private
   */
  _buildModelCache() {
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      const cacheKey = `${modelConfig.resource}_${modelConfig.target}`;
      this.modelCache.set(cacheKey, modelName);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Cached model "${modelName}" for ${modelConfig.resource}.predict(..., '${modelConfig.target}')`);
      }
    }
  }
  /**
   * Inject ML methods into Resource instances
   * @private
   */
  _injectResourceMethods() {
    if (!this.database._mlPlugin) {
      this.database._mlPlugin = this;
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "ml")) {
      Object.defineProperty(Resource.prototype, "ml", {
        get() {
          const resource = this;
          const mlPlugin = resource.database?._mlPlugin;
          if (!mlPlugin) {
            throw new MLError("MLPlugin is not installed on this database instance", {
              pluginName: "MLPlugin",
              operation: "Resource.ml accessor",
              statusCode: 400,
              retriable: false,
              suggestion: "Install MLPlugin via db.usePlugin(new MLPlugin(...)) before calling resource.ml.* methods."
            });
          }
          return {
            /**
             * Auto-setup and train ML model (zero-config)
             * @param {string} target - Target attribute to predict
             * @param {Object} options - Configuration options
             * @returns {Promise<Object>} Training results
             */
            learn: async (target, options = {}) => {
              return await mlPlugin._resourceLearn(resource.name, target, options);
            },
            /**
             * Make prediction
             * @param {Object} input - Input features
             * @param {string} target - Target attribute
             * @returns {Promise<Object>} Prediction result
             */
            predict: async (input, target) => {
              return await mlPlugin._resourcePredict(resource.name, input, target);
            },
            /**
             * Train model manually
             * @param {string} target - Target attribute
             * @param {Object} options - Training options
             * @returns {Promise<Object>} Training results
             */
            train: async (target, options = {}) => {
              return await mlPlugin._resourceTrainModel(resource.name, target, options);
            },
            /**
             * List all models for this resource
             * @returns {Array} List of models
             */
            list: () => {
              return mlPlugin._resourceListModels(resource.name);
            },
            /**
             * List model versions
             * @param {string} target - Target attribute
             * @returns {Promise<Array>} List of versions
             */
            versions: async (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.listModelVersions(modelName);
            },
            /**
             * Rollback to previous version
             * @param {string} target - Target attribute
             * @param {number} version - Version to rollback to (optional)
             * @returns {Promise<Object>} Rollback info
             */
            rollback: async (target, version = null) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.rollbackVersion(modelName, version);
            },
            /**
             * Compare two versions
             * @param {string} target - Target attribute
             * @param {number} v1 - First version
             * @param {number} v2 - Second version
             * @returns {Promise<Object>} Comparison results
             */
            compare: async (target, v1, v2) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.compareVersions(modelName, v1, v2);
            },
            /**
             * Get model statistics
             * @param {string} target - Target attribute
             * @returns {Object} Model stats
             */
            stats: (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return mlPlugin.getModelStats(modelName);
            },
            /**
             * Export model
             * @param {string} target - Target attribute
             * @returns {Promise<Object>} Exported model
             */
            export: async (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.exportModel(modelName);
            },
            /**
             * Import model
             * @param {string} target - Target attribute
             * @param {Object} data - Model data
             * @returns {Promise<void>}
             */
            import: async (target, data) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.importModel(modelName, data);
            }
          };
        },
        configurable: true
      });
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "predict")) {
      Resource.prototype.predict = async function(input, targetAttribute) {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new MLError("MLPlugin is not installed on this database instance", {
            pluginName: "MLPlugin",
            operation: "Resource.predict",
            statusCode: 400,
            retriable: false,
            suggestion: "Install MLPlugin via db.usePlugin(new MLPlugin(...)) before calling resource.predict()."
          });
        }
        return await mlPlugin._resourcePredict(this.name, input, targetAttribute);
      };
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "trainModel")) {
      Resource.prototype.trainModel = async function(targetAttribute, options = {}) {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new MLError("MLPlugin is not installed on this database instance", {
            pluginName: "MLPlugin",
            operation: "Resource.trainModel",
            statusCode: 400,
            retriable: false,
            suggestion: "Install MLPlugin via db.usePlugin(new MLPlugin(...)) before calling resource.trainModel()."
          });
        }
        return await mlPlugin._resourceTrainModel(this.name, targetAttribute, options);
      };
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "listModels")) {
      Resource.prototype.listModels = function() {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new MLError("MLPlugin is not installed on this database instance", {
            pluginName: "MLPlugin",
            operation: "Resource.listModels",
            statusCode: 400,
            retriable: false,
            suggestion: "Install MLPlugin via db.usePlugin(new MLPlugin(...)) before calling resource.listModels()."
          });
        }
        return mlPlugin._resourceListModels(this.name);
      };
    }
    if (this.config.verbose) {
      console.log("[MLPlugin] Injected ML namespace (resource.ml.*) into Resource prototype");
    }
  }
  /**
   * Find model for a resource and target attribute
   * @private
   */
  _findModelForResource(resourceName, targetAttribute) {
    const cacheKey = `${resourceName}_${targetAttribute}`;
    if (this.modelCache.has(cacheKey)) {
      return this.modelCache.get(cacheKey);
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.resource === resourceName && modelConfig.target === targetAttribute) {
        this.modelCache.set(cacheKey, modelName);
        return modelName;
      }
    }
    return null;
  }
  /**
   * Auto-setup and train ML model (resource.ml.learn implementation)
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute to predict
   * @param {Object} options - Configuration options
   * @returns {Promise<Object>} Training results
   * @private
   */
  async _resourceLearn(resourceName, target, options = {}) {
    let modelName = this._findModelForResource(resourceName, target);
    if (modelName) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Model "${modelName}" already exists, retraining...`);
      }
      return await this.train(modelName, options);
    }
    modelName = `${resourceName}_${target}_auto`;
    if (this.config.verbose) {
      console.log(`[MLPlugin] Auto-creating model "${modelName}" for ${resourceName}.${target}...`);
    }
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new ModelConfigError(
        `Resource "${resourceName}" not found`,
        { resourceName, availableResources: Object.keys(this.database.resources) }
      );
    }
    let modelType = options.type;
    if (!modelType) {
      modelType = await this._autoDetectType(resourceName, target);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-detected type: ${modelType}`);
      }
    }
    let features = options.features;
    if (!features || features.length === 0) {
      features = await this._autoSelectFeatures(resourceName, target);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-selected features: ${features.join(", ")}`);
      }
    }
    const [samplesOk, samplesErr, sampleData] = await tryFn(() => resource.list());
    const sampleCount = samplesOk && sampleData ? sampleData.length : 0;
    let defaultModelConfig = this._getDefaultModelConfig(modelType);
    const userProvidedBatchSize = options.modelConfig && options.modelConfig.batchSize !== void 0;
    if (!userProvidedBatchSize && sampleCount > 0 && sampleCount < defaultModelConfig.batchSize) {
      defaultModelConfig.batchSize = Math.max(4, Math.floor(sampleCount / 2));
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-adjusted batchSize to ${defaultModelConfig.batchSize} based on ${sampleCount} samples`);
      }
    }
    const customModelConfig = options.modelConfig || {};
    const mergedModelConfig = {
      ...defaultModelConfig,
      ...customModelConfig,
      // Preserve auto-adjusted batchSize if user didn't provide one
      ...!userProvidedBatchSize && { batchSize: defaultModelConfig.batchSize }
    };
    const modelConfig = {
      type: modelType,
      resource: resourceName,
      features,
      target,
      autoTrain: options.autoTrain !== void 0 ? options.autoTrain : false,
      saveModel: options.saveModel !== void 0 ? options.saveModel : true,
      saveTrainingData: options.saveTrainingData !== void 0 ? options.saveTrainingData : false,
      modelConfig: mergedModelConfig,
      ...options
    };
    this.config.models[modelName] = modelConfig;
    await this._initializeModel(modelName, modelConfig);
    this._buildModelCache();
    if (this.config.verbose) {
      console.log(`[MLPlugin] Training model "${modelName}"...`);
    }
    const result = await this.train(modelName, options);
    if (this.config.verbose) {
      console.log(`[MLPlugin] \u2705 Model "${modelName}" ready!`);
    }
    return {
      modelName,
      type: modelType,
      features,
      target,
      ...result
    };
  }
  /**
   * Auto-detect model type based on target attribute
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute
   * @returns {Promise<string>} Model type
   * @private
   */
  async _autoDetectType(resourceName, target) {
    const resource = this.database.resources[resourceName];
    const [ok, err, samples] = await tryFn(() => resource.list({ limit: 100 }));
    if (!ok || !samples || samples.length === 0) {
      return "regression";
    }
    const targetValues = samples.map((s) => s[target]).filter((v) => v != null);
    if (targetValues.length === 0) {
      return "regression";
    }
    const isNumeric = targetValues.every((v) => typeof v === "number");
    if (isNumeric) {
      const hasTimestamp = samples.every((s) => s.timestamp || s.createdAt || s.date);
      if (hasTimestamp) {
        return "timeseries";
      }
      return "regression";
    }
    const isCategorical = targetValues.every((v) => typeof v === "string" || typeof v === "boolean");
    if (isCategorical) {
      return "classification";
    }
    return "regression";
  }
  /**
   * Auto-select best features for prediction
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute
   * @returns {Promise<Array>} Selected features
   * @private
   */
  async _autoSelectFeatures(resourceName, target) {
    const resource = this.database.resources[resourceName];
    const schema = resource.schema;
    const attributes = schema?.attributes || {};
    const numericFields = [];
    for (const [fieldName, fieldDef] of Object.entries(attributes)) {
      if (fieldName === target) continue;
      if (["id", "createdAt", "updatedAt", "createdBy"].includes(fieldName)) continue;
      const fieldType = typeof fieldDef === "string" ? fieldDef.split("|")[0] : fieldDef.type;
      if (fieldType === "number" || fieldType === "integer" || fieldType === "float") {
        numericFields.push(fieldName);
      }
    }
    if (numericFields.length === 0) {
      const [ok, err, samples] = await tryFn(() => resource.list({ limit: 10 }));
      if (ok && samples && samples.length > 0) {
        const firstSample = samples[0];
        for (const [key, value] of Object.entries(firstSample)) {
          if (key === target) continue;
          if (["id", "createdAt", "updatedAt", "createdBy"].includes(key)) continue;
          if (typeof value === "number") {
            numericFields.push(key);
          }
        }
      }
    }
    if (numericFields.length === 0) {
      throw new ModelConfigError(
        `No numeric features found for target "${target}" in resource "${resourceName}"`,
        { resourceName, target, availableAttributes: Object.keys(attributes) }
      );
    }
    return numericFields;
  }
  /**
   * Get default model config for type
   * @param {string} type - Model type
   * @returns {Object} Default config
   * @private
   */
  _getDefaultModelConfig(type) {
    const defaults = {
      regression: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        polynomial: 1
      },
      classification: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        units: 64,
        dropout: 0.2
      },
      timeseries: {
        epochs: 50,
        batchSize: 16,
        learningRate: 1e-3,
        validationSplit: 0.2,
        lookback: 10,
        lstmUnits: 50
      },
      "neural-network": {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        layers: [
          { units: 64, activation: "relu", dropout: 0.2 },
          { units: 32, activation: "relu" }
        ]
      }
    };
    return defaults[type] || defaults.regression;
  }
  /**
   * Resource predict implementation
   * @private
   */
  async _resourcePredict(resourceName, input, targetAttribute) {
    const modelName = this._findModelForResource(resourceName, targetAttribute);
    if (!modelName) {
      throw new ModelNotFoundError(
        `No model found for resource "${resourceName}" with target "${targetAttribute}"`,
        { resourceName, targetAttribute, availableModels: Object.keys(this.models) }
      );
    }
    if (this.config.verbose) {
      console.log(`[MLPlugin] Resource prediction: ${resourceName}.predict(..., '${targetAttribute}') -> model "${modelName}"`);
    }
    return await this.predict(modelName, input);
  }
  /**
   * Resource trainModel implementation
   * @private
   */
  async _resourceTrainModel(resourceName, targetAttribute, options = {}) {
    const modelName = this._findModelForResource(resourceName, targetAttribute);
    if (!modelName) {
      throw new ModelNotFoundError(
        `No model found for resource "${resourceName}" with target "${targetAttribute}"`,
        { resourceName, targetAttribute, availableModels: Object.keys(this.models) }
      );
    }
    if (this.config.verbose) {
      console.log(`[MLPlugin] Resource training: ${resourceName}.trainModel('${targetAttribute}') -> model "${modelName}"`);
    }
    return await this.train(modelName, options);
  }
  /**
   * List models for a resource
   * @private
   */
  _resourceListModels(resourceName) {
    const models = [];
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.resource === resourceName) {
        models.push({
          name: modelName,
          type: modelConfig.type,
          target: modelConfig.target,
          features: modelConfig.features,
          isTrained: this.models[modelName]?.isTrained || false
        });
      }
    }
    return models;
  }
  /**
   * Validate model configuration
   * @private
   */
  _validateModelConfig(modelName, config) {
    const validTypes = ["regression", "classification", "timeseries", "neural-network"];
    if (!config.type || !validTypes.includes(config.type)) {
      throw new ModelConfigError(
        `Model "${modelName}" must have a valid type: ${validTypes.join(", ")}`,
        { modelName, type: config.type, validTypes }
      );
    }
    if (!config.resource) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify a resource`,
        { modelName }
      );
    }
    if (!config.features || !Array.isArray(config.features) || config.features.length === 0) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify at least one feature`,
        { modelName, features: config.features }
      );
    }
    if (!config.target) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify a target field`,
        { modelName }
      );
    }
  }
  /**
   * Initialize a model instance
   * @private
   */
  async _initializeModel(modelName, config) {
    const modelOptions = {
      name: modelName,
      resource: config.resource,
      features: config.features,
      target: config.target,
      minSamples: config.minSamples ?? this.config.minTrainingSamples,
      modelConfig: config.modelConfig || {},
      verbose: this.config.verbose
    };
    try {
      switch (config.type) {
        case "regression":
          this.models[modelName] = new RegressionModel(modelOptions);
          break;
        case "classification":
          this.models[modelName] = new ClassificationModel(modelOptions);
          break;
        case "timeseries":
          this.models[modelName] = new TimeSeriesModel(modelOptions);
          break;
        case "neural-network":
          this.models[modelName] = new NeuralNetworkModel(modelOptions);
          break;
        default:
          throw new ModelConfigError(
            `Unknown model type: ${config.type}`,
            { modelName, type: config.type }
          );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Initialized model "${modelName}" (${config.type})`);
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to initialize model "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Setup auto-training for a model
   * @private
  */
  _setupAutoTraining(modelName, config) {
    if (!this.insertCounters.has(modelName)) {
      this.insertCounters.set(modelName, 0);
    }
    const resource = this.database.resources[config.resource];
    if (!resource) {
      if (this.config.verbose) {
        console.warn(`[MLPlugin] Resource "${config.resource}" not found for model "${modelName}". Auto-training will attach when resource is created.`);
      }
      if (!this._pendingAutoTrainingHandlers.has(modelName)) {
        const handler = (createdName) => {
          if (createdName !== config.resource) {
            return;
          }
          this.database.off("db:resource-created", handler);
          this._pendingAutoTrainingHandlers.delete(modelName);
          this._setupAutoTraining(modelName, config);
        };
        this._pendingAutoTrainingHandlers.set(modelName, handler);
        this.database.on("db:resource-created", handler);
      }
      return;
    }
    if (this._autoTrainingInitialized.has(modelName)) {
      return;
    }
    if (config.trainAfterInserts && config.trainAfterInserts > 0) {
      this.addMiddleware(resource, "insert", async (next, data, options) => {
        const result = await next(data, options);
        const currentCount = this.insertCounters.get(modelName) || 0;
        this.insertCounters.set(modelName, currentCount + 1);
        if (this.insertCounters.get(modelName) >= config.trainAfterInserts) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] Auto-training "${modelName}" after ${config.trainAfterInserts} inserts`);
          }
          this.insertCounters.set(modelName, 0);
          this.train(modelName).catch((err) => {
            console.error(`[MLPlugin] Auto-training failed for "${modelName}":`, err.message);
          });
        }
        return result;
      });
    }
    if (config.trainInterval && config.trainInterval > 0) {
      const handle = setInterval(async () => {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Auto-training "${modelName}" (interval: ${config.trainInterval}ms)`);
        }
        try {
          await this.train(modelName);
        } catch (error) {
          console.error(`[MLPlugin] Auto-training failed for "${modelName}":`, error.message);
        }
      }, config.trainInterval);
      this.intervals.push(handle);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Setup interval training for "${modelName}" (every ${config.trainInterval}ms)`);
      }
    }
    this._autoTrainingInitialized.add(modelName);
  }
  /**
   * Train a model
   * @param {string} modelName - Model name
   * @param {Object} options - Training options
   * @returns {Object} Training results
   */
  async train(modelName, options = {}) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    if (this.training.get(modelName)) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Model "${modelName}" is already training, skipping...`);
      }
      return { skipped: true, reason: "already_training" };
    }
    this.training.set(modelName, true);
    try {
      const modelConfig = this.config.models[modelName];
      const resource = this.database.resources[modelConfig.resource];
      if (!resource) {
        throw new ModelNotFoundError(
          `Resource "${modelConfig.resource}" not found`,
          { modelName, resource: modelConfig.resource }
        );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Fetching training data for "${modelName}"...`);
      }
      let data;
      const partition = modelConfig.partition;
      if (partition && partition.name) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Using partition "${partition.name}" with values:`, partition.values);
        }
        const [ok, err, partitionData] = await tryFn(
          () => resource.listPartition({
            partition: partition.name,
            partitionValues: partition.values
          })
        );
        if (!ok) {
          throw new TrainingError(
            `Failed to fetch training data from partition: ${err.message}`,
            { modelName, resource: modelConfig.resource, partition: partition.name, originalError: err.message }
          );
        }
        data = partitionData;
      } else {
        const [ok, err, allData] = await tryFn(() => resource.list());
        if (!ok) {
          throw new TrainingError(
            `Failed to fetch training data: ${err.message}`,
            { modelName, resource: modelConfig.resource, originalError: err.message }
          );
        }
        data = allData;
      }
      if (modelConfig.filter && typeof modelConfig.filter === "function") {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Applying custom filter function...`);
        }
        const originalLength = data.length;
        data = data.filter(modelConfig.filter);
        if (this.config.verbose) {
          console.log(`[MLPlugin] Filter reduced dataset from ${originalLength} to ${data.length} samples`);
        }
      }
      if (modelConfig.map && typeof modelConfig.map === "function") {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Applying custom map function...`);
        }
        data = data.map(modelConfig.map);
      }
      if (!data || data.length < this.config.minTrainingSamples) {
        throw new TrainingError(
          `Insufficient training data: ${data?.length || 0} samples (minimum: ${this.config.minTrainingSamples})`,
          { modelName, samples: data?.length || 0, minimum: this.config.minTrainingSamples }
        );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Training "${modelName}" with ${data.length} samples...`);
      }
      const shouldSaveTrainingData = modelConfig.saveTrainingData !== void 0 ? modelConfig.saveTrainingData : this.config.saveTrainingData;
      if (shouldSaveTrainingData) {
        await this._saveTrainingData(modelName, data);
      }
      const result = await model.train(data);
      const shouldSaveModel = modelConfig.saveModel !== void 0 ? modelConfig.saveModel : this.config.saveModel;
      if (shouldSaveModel) {
        await this._saveModel(modelName);
      }
      this.stats.totalTrainings++;
      if (this.config.verbose) {
        console.log(`[MLPlugin] Training completed for "${modelName}":`, result);
      }
      this.emit("plg:ml:model-trained", {
        modelName,
        type: modelConfig.type,
        result
      });
      return result;
    } catch (error) {
      this.stats.totalErrors++;
      if (error instanceof MLError) {
        throw error;
      }
      throw new TrainingError(
        `Training failed for "${modelName}": ${error.message}`,
        { modelName, originalError: error.message }
      );
    } finally {
      this.training.set(modelName, false);
    }
  }
  /**
   * Make a prediction
   * @param {string} modelName - Model name
   * @param {Object|Array} input - Input data (object for single prediction, array for time series)
   * @returns {Object} Prediction result
   */
  async predict(modelName, input) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    try {
      const result = await model.predict(input);
      this.stats.totalPredictions++;
      this.emit("plg:ml:prediction", {
        modelName,
        input,
        result
      });
      return result;
    } catch (error) {
      this.stats.totalErrors++;
      throw error;
    }
  }
  /**
   * Make predictions for multiple inputs
   * @param {string} modelName - Model name
   * @param {Array} inputs - Array of input objects
   * @returns {Array} Array of prediction results
   */
  async predictBatch(modelName, inputs) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return await model.predictBatch(inputs);
  }
  /**
   * Retrain a model (reset and train from scratch)
   * @param {string} modelName - Model name
   * @param {Object} options - Options
   * @returns {Object} Training results
   */
  async retrain(modelName, options = {}) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    if (model.dispose) {
      model.dispose();
    }
    const modelConfig = this.config.models[modelName];
    await this._initializeModel(modelName, modelConfig);
    return await this.train(modelName, options);
  }
  /**
   * Get model statistics
   * @param {string} modelName - Model name
   * @returns {Object} Model stats
   */
  getModelStats(modelName) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return model.getStats();
  }
  /**
   * Get plugin statistics
   * @returns {Object} Plugin stats
   */
  getStats() {
    return {
      ...this.stats,
      models: Object.keys(this.models).length,
      trainedModels: Object.values(this.models).filter((m) => m.isTrained).length
    };
  }
  /**
   * Export a model
   * @param {string} modelName - Model name
   * @returns {Object} Serialized model
   */
  async exportModel(modelName) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return await model.export();
  }
  /**
   * Import a model
   * @param {string} modelName - Model name
   * @param {Object} data - Serialized model data
   */
  async importModel(modelName, data) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    await model.import(data);
    await this._saveModel(modelName);
    if (this.config.verbose) {
      console.log(`[MLPlugin] Imported model "${modelName}"`);
    }
  }
  /**
   * Initialize versioning for a model
   * @private
   */
  async _initializeVersioning(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, versionInfo] = await tryFn(
        () => storage.get(storage.getPluginKey(resourceName, "metadata", modelName, "versions"))
      );
      if (ok && versionInfo) {
        this.modelVersions.set(modelName, {
          currentVersion: versionInfo.currentVersion || 1,
          latestVersion: versionInfo.latestVersion || 1
        });
        if (this.config.verbose) {
          console.log(`[MLPlugin] Loaded version info for "${modelName}": v${versionInfo.currentVersion}`);
        }
      } else {
        this.modelVersions.set(modelName, {
          currentVersion: 1,
          latestVersion: 0
          // No versions yet
        });
        if (this.config.verbose) {
          console.log(`[MLPlugin] Initialized versioning for "${modelName}"`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to initialize versioning for "${modelName}":`, error.message);
      this.modelVersions.set(modelName, { currentVersion: 1, latestVersion: 0 });
    }
  }
  /**
   * Get next version number for a model
   * @private
   */
  _getNextVersion(modelName) {
    const versionInfo = this.modelVersions.get(modelName) || { latestVersion: 0 };
    return versionInfo.latestVersion + 1;
  }
  /**
   * Update version info in storage
   * @private
   */
  async _updateVersionInfo(modelName, version) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const versionInfo = this.modelVersions.get(modelName) || { currentVersion: 1, latestVersion: 0 };
      versionInfo.latestVersion = Math.max(versionInfo.latestVersion, version);
      versionInfo.currentVersion = version;
      this.modelVersions.set(modelName, versionInfo);
      await storage.set(
        storage.getPluginKey(resourceName, "metadata", modelName, "versions"),
        {
          modelName,
          currentVersion: versionInfo.currentVersion,
          latestVersion: versionInfo.latestVersion,
          updatedAt: (/* @__PURE__ */ new Date()).toISOString()
        },
        { behavior: "body-overflow" }
      );
      if (this.config.verbose) {
        console.log(`[MLPlugin] Updated version info for "${modelName}": current=v${versionInfo.currentVersion}, latest=v${versionInfo.latestVersion}`);
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to update version info for "${modelName}":`, error.message);
    }
  }
  /**
   * Save model to plugin storage
   * @private
   */
  async _saveModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const exportedModel = await this.models[modelName].export();
      if (!exportedModel) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Model "${modelName}" not trained, skipping save`);
        }
        return;
      }
      const modelStats = this.models[modelName].getStats();
      const timestamp = (/* @__PURE__ */ new Date()).toISOString();
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const version = this._getNextVersion(modelName);
        await storage.set(
          storage.getPluginKey(resourceName, "models", modelName, `v${version}`),
          {
            modelName,
            version,
            type: "model",
            modelData: exportedModel,
            // TensorFlow.js model object (will go to body)
            metrics: {
              loss: modelStats.loss,
              accuracy: modelStats.accuracy,
              samples: modelStats.samples
            },
            savedAt: timestamp
          },
          { behavior: "body-only" }
          // Large binary data goes to S3 body
        );
        await this._updateVersionInfo(modelName, version);
        await storage.set(
          storage.getPluginKey(resourceName, "metadata", modelName, "active"),
          {
            modelName,
            version,
            type: "reference",
            updatedAt: timestamp
          },
          { behavior: "body-overflow" }
          // Small metadata
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved model "${modelName}" v${version} to S3 (resource=${resourceName}/plugin=ml/models/${modelName}/v${version})`);
        }
      } else {
        await storage.set(
          storage.getPluginKey(resourceName, "models", modelName, "latest"),
          {
            modelName,
            type: "model",
            modelData: exportedModel,
            metrics: {
              loss: modelStats.loss,
              accuracy: modelStats.accuracy,
              samples: modelStats.samples
            },
            savedAt: timestamp
          },
          { behavior: "body-only" }
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved model "${modelName}" to S3 (resource=${resourceName}/plugin=ml/models/${modelName}/latest)`);
        }
      }
      const activeVersion = enableVersioning ? this.modelVersions.get(modelName)?.latestVersion || 1 : void 0;
      const compatibilityData = enableVersioning ? {
        storageKey: storage.getPluginKey(resourceName, "models", modelName, `v${activeVersion}`),
        version: activeVersion
      } : exportedModel;
      await storage.set(
        `model_${modelName}`,
        {
          modelName,
          type: "model",
          data: compatibilityData,
          metrics: {
            loss: modelStats.loss,
            accuracy: modelStats.accuracy,
            samples: modelStats.samples
          },
          savedAt: timestamp
        },
        { behavior: enableVersioning ? "body-overflow" : "body-only" }
      );
    } catch (error) {
      console.error(`[MLPlugin] Failed to save model "${modelName}":`, error.message);
    }
  }
  /**
   * Save intermediate training data to plugin storage (incremental - only new samples)
   * @private
   */
  async _saveTrainingData(modelName, rawData) {
    try {
      const storage = this.getStorage();
      const model = this.models[modelName];
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const modelStats = model.getStats();
      const enableVersioning = this.config.enableVersioning;
      const processedData = rawData.map((item) => {
        const features = {};
        modelConfig.features.forEach((feature) => {
          features[feature] = item[feature];
        });
        return {
          id: item.id || `${Date.now()}_${Math.random()}`,
          // Use record ID or generate
          features,
          target: item[modelConfig.target]
        };
      });
      if (enableVersioning) {
        const version = this._getNextVersion(modelName);
        const [ok, err, existing] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
        );
        let history = [];
        let previousSampleIds = /* @__PURE__ */ new Set();
        if (ok && existing && existing.history) {
          history = existing.history;
          history.forEach((entry) => {
            if (entry.sampleIds) {
              entry.sampleIds.forEach((id) => previousSampleIds.add(id));
            }
          });
        }
        const currentSampleIds = new Set(processedData.map((d) => d.id));
        const newSamples = processedData.filter((d) => !previousSampleIds.has(d.id));
        const newSampleIds = newSamples.map((d) => d.id);
        if (newSamples.length > 0) {
          await storage.set(
            storage.getPluginKey(resourceName, "training", "data", modelName, `v${version}`),
            {
              modelName,
              version,
              samples: newSamples,
              // Only new samples
              features: modelConfig.features,
              target: modelConfig.target,
              savedAt: (/* @__PURE__ */ new Date()).toISOString()
            },
            { behavior: "body-only" }
            // Dataset goes to S3 body
          );
        }
        const historyEntry = {
          version,
          totalSamples: processedData.length,
          // Total cumulative
          newSamples: newSamples.length,
          // Only new in this version
          sampleIds: Array.from(currentSampleIds),
          // All IDs for this version
          newSampleIds,
          // IDs of new samples
          storageKey: newSamples.length > 0 ? `training/data/${modelName}/v${version}` : null,
          metrics: {
            loss: modelStats.loss,
            accuracy: modelStats.accuracy,
            r2: modelStats.r2
          },
          trainedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        history.push(historyEntry);
        await storage.set(
          storage.getPluginKey(resourceName, "training", "history", modelName),
          {
            modelName,
            type: "training_history",
            totalTrainings: history.length,
            latestVersion: version,
            history,
            // Array of metadata entries (not full data)
            updatedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-overflow" }
          // History metadata
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved training data for "${modelName}" v${version}: ${newSamples.length} new samples (total: ${processedData.length}, storage: resource=${resourceName}/plugin=ml/training/data/${modelName}/v${version})`);
        }
      } else {
        await storage.set(
          storage.getPluginKey(resourceName, "training", "data", modelName, "latest"),
          {
            modelName,
            type: "training_data",
            samples: processedData,
            features: modelConfig.features,
            target: modelConfig.target,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-only" }
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved training data for "${modelName}" (${processedData.length} samples) to S3 (resource=${resourceName}/plugin=ml/training/data/${modelName}/latest)`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to save training data for "${modelName}":`, error.message);
    }
  }
  /**
   * Load model from plugin storage
   * @private
   */
  async _loadModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const [okRef, errRef, activeRef] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "metadata", modelName, "active"))
        );
        if (okRef && activeRef && activeRef.version) {
          const version = activeRef.version;
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`))
          );
          if (ok && versionData && versionData.modelData) {
            await this.models[modelName].import(versionData.modelData);
            if (this.config.verbose) {
              console.log(`[MLPlugin] Loaded model "${modelName}" v${version} (active) from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/v${version})`);
            }
            return;
          }
        }
        const versionInfo = this.modelVersions.get(modelName);
        if (versionInfo && versionInfo.latestVersion > 0) {
          const version = versionInfo.latestVersion;
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`))
          );
          if (ok && versionData && versionData.modelData) {
            await this.models[modelName].import(versionData.modelData);
            if (this.config.verbose) {
              console.log(`[MLPlugin] Loaded model "${modelName}" v${version} (latest) from S3`);
            }
            return;
          }
        }
        if (this.config.verbose) {
          console.log(`[MLPlugin] No saved model versions found for "${modelName}"`);
        }
      } else {
        const [ok, err, record] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "models", modelName, "latest"))
        );
        if (!ok || !record || !record.modelData) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] No saved model found for "${modelName}"`);
          }
          return;
        }
        await this.models[modelName].import(record.modelData);
        if (this.config.verbose) {
          console.log(`[MLPlugin] Loaded model "${modelName}" from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/latest)`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to load model "${modelName}":`, error.message);
    }
  }
  /**
   * Load training data from plugin storage (reconstructs specific version from incremental data)
   * @param {string} modelName - Model name
   * @param {number} version - Version number (optional, defaults to latest)
   * @returns {Object|null} Training data or null if not found
   */
  async getTrainingData(modelName, version = null) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (!enableVersioning) {
        const [ok, err, record] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "data", modelName, "latest"))
        );
        if (!ok || !record) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] No saved training data found for "${modelName}"`);
          }
          return null;
        }
        const samplesArray = Array.isArray(record.samples) ? record.samples : [];
        return {
          modelName: record.modelName,
          samples: samplesArray.length,
          features: record.features,
          target: record.target,
          data: samplesArray,
          savedAt: record.savedAt
        };
      }
      const [okHistory, errHistory, historyData] = await tryFn(
        () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
      );
      if (!okHistory || !historyData || !historyData.history) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] No training history found for "${modelName}"`);
        }
        return null;
      }
      const historyEntries = Array.isArray(historyData.history) ? historyData.history : JSON.parse(historyData.history);
      const targetVersion = version || historyData.latestVersion;
      const reconstructedSamples = [];
      for (const entry of historyEntries) {
        if (entry.version > targetVersion) break;
        if (entry.storageKey && entry.newSamples > 0) {
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "training", "data", modelName, `v${entry.version}`))
          );
          if (ok && versionData && versionData.samples) {
            reconstructedSamples.push(...versionData.samples);
          }
        }
      }
      const targetEntry = historyEntries.find((e) => e.version === targetVersion);
      return {
        modelName,
        version: targetVersion,
        samples: reconstructedSamples.length,
        totalSamples: reconstructedSamples.length,
        features: modelConfig.features,
        target: modelConfig.target,
        data: reconstructedSamples,
        metrics: targetEntry?.metrics,
        savedAt: targetEntry?.trainedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load training data for "${modelName}":`, error.message);
      return null;
    }
  }
  /**
   * Delete model from plugin storage (all versions)
   * @private
   */
  async _deleteModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const versionInfo = this.modelVersions.get(modelName);
        if (versionInfo && versionInfo.latestVersion > 0) {
          for (let v = 1; v <= versionInfo.latestVersion; v++) {
            await storage.delete(storage.getPluginKey(resourceName, "models", modelName, `v${v}`));
          }
        }
        await storage.delete(storage.getPluginKey(resourceName, "metadata", modelName, "active"));
        await storage.delete(storage.getPluginKey(resourceName, "metadata", modelName, "versions"));
      } else {
        await storage.delete(storage.getPluginKey(resourceName, "models", modelName, "latest"));
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Deleted model "${modelName}" from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/)`);
      }
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Could not delete model "${modelName}": ${error.message}`);
      }
    }
  }
  /**
   * Delete training data from plugin storage (all versions)
   * @private
   */
  async _deleteTrainingData(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const [ok, err, historyData] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
        );
        if (ok && historyData && historyData.history) {
          for (const entry of historyData.history) {
            if (entry.storageKey) {
              await storage.delete(storage.getPluginKey(resourceName, "training", "data", modelName, `v${entry.version}`));
            }
          }
        }
        await storage.delete(storage.getPluginKey(resourceName, "training", "history", modelName));
      } else {
        await storage.delete(storage.getPluginKey(resourceName, "training", "data", modelName, "latest"));
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Deleted training data for "${modelName}" from S3 (resource=${resourceName}/plugin=ml/training/)`);
      }
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Could not delete training data "${modelName}": ${error.message}`);
      }
    }
  }
  /**
   * List all versions of a model
   * @param {string} modelName - Model name
   * @returns {Array} List of version info
   */
  async listModelVersions(modelName) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const versionInfo = this.modelVersions.get(modelName) || { latestVersion: 0 };
      const versions = [];
      for (let v = 1; v <= versionInfo.latestVersion; v++) {
        const [ok, err, versionData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${v}`)));
        if (ok && versionData) {
          versions.push({
            version: v,
            savedAt: versionData.savedAt,
            isCurrent: v === versionInfo.currentVersion,
            metrics: versionData.metrics
          });
        }
      }
      return versions;
    } catch (error) {
      console.error(`[MLPlugin] Failed to list versions for "${modelName}":`, error.message);
      return [];
    }
  }
  /**
   * Load a specific version of a model
   * @param {string} modelName - Model name
   * @param {number} version - Version number
   */
  async loadModelVersion(modelName, version) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    if (!this.models[modelName]) {
      throw new ModelNotFoundError(`Model "${modelName}" not found`, { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, versionData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`)));
      if (!ok || !versionData) {
        throw new MLError(`Version ${version} not found for model "${modelName}"`, { modelName, version });
      }
      if (!versionData.modelData) {
        throw new MLError(`Model data not found in version ${version}`, { modelName, version });
      }
      await this.models[modelName].import(versionData.modelData);
      const versionInfo = this.modelVersions.get(modelName);
      if (versionInfo) {
        versionInfo.currentVersion = version;
        this.modelVersions.set(modelName, versionInfo);
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Loaded model "${modelName}" v${version}`);
      }
      return {
        version,
        metrics: typeof versionData.metrics === "string" ? JSON.parse(versionData.metrics) : versionData.metrics || {},
        savedAt: versionData.savedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load version ${version} for "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Set active version for a model (used for predictions)
   * @param {string} modelName - Model name
   * @param {number} version - Version number
   */
  async setActiveVersion(modelName, version) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    const modelConfig = this.config.models[modelName];
    const resourceName = modelConfig.resource;
    await this.loadModelVersion(modelName, version);
    await this._updateVersionInfo(modelName, version);
    const storage = this.getStorage();
    await storage.set(storage.getPluginKey(resourceName, "metadata", modelName, "active"), {
      modelName,
      version,
      type: "reference",
      updatedAt: (/* @__PURE__ */ new Date()).toISOString()
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] Set model "${modelName}" active version to v${version}`);
    }
    return { modelName, version };
  }
  /**
   * Get training history for a model
   * @param {string} modelName - Model name
   * @returns {Array} Training history
   */
  async getTrainingHistory(modelName) {
    if (!this.config.enableVersioning) {
      return await this.getTrainingData(modelName);
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, historyData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName)));
      if (!ok || !historyData) {
        return null;
      }
      const historyEntries = Array.isArray(historyData.history) ? historyData.history : JSON.parse(historyData.history);
      return {
        modelName: historyData.modelName,
        totalTrainings: historyData.totalTrainings,
        latestVersion: historyData.latestVersion,
        history: historyEntries,
        updatedAt: historyData.updatedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load training history for "${modelName}":`, error.message);
      return null;
    }
  }
  /**
   * Compare metrics between two versions
   * @param {string} modelName - Model name
   * @param {number} version1 - First version
   * @param {number} version2 - Second version
   * @returns {Object} Comparison results
   */
  async compareVersions(modelName, version1, version2) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok1, err1, v1Data] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version1}`)));
      const [ok2, err2, v2Data] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version2}`)));
      if (!ok1 || !v1Data) {
        throw new MLError(`Version ${version1} not found`, { modelName, version: version1 });
      }
      if (!ok2 || !v2Data) {
        throw new MLError(`Version ${version2} not found`, { modelName, version: version2 });
      }
      const metrics1 = typeof v1Data.metrics === "string" ? JSON.parse(v1Data.metrics) : v1Data.metrics || {};
      const metrics2 = typeof v2Data.metrics === "string" ? JSON.parse(v2Data.metrics) : v2Data.metrics || {};
      return {
        modelName,
        version1: {
          version: version1,
          savedAt: v1Data.savedAt,
          metrics: metrics1
        },
        version2: {
          version: version2,
          savedAt: v2Data.savedAt,
          metrics: metrics2
        },
        improvement: {
          loss: metrics1.loss && metrics2.loss ? ((metrics1.loss - metrics2.loss) / metrics1.loss * 100).toFixed(2) + "%" : "N/A",
          accuracy: metrics1.accuracy && metrics2.accuracy ? ((metrics2.accuracy - metrics1.accuracy) / metrics1.accuracy * 100).toFixed(2) + "%" : "N/A"
        }
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to compare versions for "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Rollback to a previous version
   * @param {string} modelName - Model name
   * @param {number} version - Version to rollback to (defaults to previous version)
   * @returns {Object} Rollback info
   */
  async rollbackVersion(modelName, version = null) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    const versionInfo = this.modelVersions.get(modelName);
    if (!versionInfo) {
      throw new MLError(`No version info found for model "${modelName}"`, { modelName });
    }
    const targetVersion = version !== null ? version : Math.max(1, versionInfo.currentVersion - 1);
    if (targetVersion === versionInfo.currentVersion) {
      throw new MLError("Cannot rollback to the same version", { modelName, version: targetVersion });
    }
    if (targetVersion < 1 || targetVersion > versionInfo.latestVersion) {
      throw new MLError(`Invalid version ${targetVersion}`, { modelName, version: targetVersion, latestVersion: versionInfo.latestVersion });
    }
    const result = await this.setActiveVersion(modelName, targetVersion);
    if (this.config.verbose) {
      console.log(`[MLPlugin] Rolled back model "${modelName}" from v${versionInfo.currentVersion} to v${targetVersion}`);
    }
    return {
      modelName,
      previousVersion: versionInfo.currentVersion,
      currentVersion: targetVersion,
      ...result
    };
  }
}

function sanitizeNamespace(value) {
  return (value || "spider").toString().trim().toLowerCase().replace(/[^a-z0-9]+/g, "-");
}
function defaultTargetsResource(namespace) {
  return `${namespace.replace(/[^a-z0-9]+/g, "_")}_targets`;
}
class SpiderSuitePlugin extends Plugin {
  constructor(options = {}) {
    const namespace = options.namespace || "spider";
    super({ ...options, namespace });
    this.namespace = this.namespace || sanitizeNamespace(namespace);
    const targetsResource = options.targetsResource || options.resources && options.resources.targets || defaultTargetsResource(this.namespace);
    this.config = {
      namespace: this.namespace,
      targetsResource,
      queue: {
        resource: targetsResource,
        deadLetterResource: options.queue?.deadLetterResource || null,
        visibilityTimeout: options.queue?.visibilityTimeout || 3e4,
        pollInterval: options.queue?.pollInterval || 1e3,
        maxAttempts: options.queue?.maxAttempts || 3,
        concurrency: options.queue?.concurrency || 3,
        autoStart: options.queue?.autoStart === true,
        ...options.queue
      },
      puppeteer: {
        // Disable pool warmup by default to avoid immediate browser launches
        pool: { enabled: false },
        ...options.puppeteer
      },
      ttl: options.ttl || null,
      processor: typeof options.processor === "function" ? options.processor : null
    };
    this.pluginFactories = {
      puppeteer: options.pluginFactories?.puppeteer || ((pluginOptions) => new PuppeteerPlugin(pluginOptions)),
      queue: options.pluginFactories?.queue || ((queueOptions) => new S3QueuePlugin(queueOptions)),
      ttl: options.pluginFactories?.ttl || ((ttlOptions) => new TTLPlugin(ttlOptions))
    };
    this.dependencies = [];
    this.targetsResource = null;
    this.puppeteerPlugin = null;
    this.queuePlugin = null;
    this.ttlPlugin = null;
    this.processor = this.config.processor;
    this.queueHandler = this.queueHandler.bind(this);
  }
  _dependencyName(alias) {
    return `${this.namespace}-${alias}`.toLowerCase();
  }
  async _installDependency(alias, plugin) {
    const name = this._dependencyName(alias);
    const instance = await this.database.usePlugin(plugin, name);
    this.dependencies.push({ name, instance });
    return instance;
  }
  async _ensureTargetsResource() {
    if (this.database.resources?.[this.config.targetsResource]) {
      this.targetsResource = this.database.resources[this.config.targetsResource];
      return;
    }
    const [created, err, resource] = await tryFn(() => this.database.createResource({
      name: this.config.targetsResource,
      attributes: {
        id: "string|required",
        url: "string|required",
        method: "string|optional",
        depth: "number|optional",
        priority: "number|default:0",
        headers: "json|optional",
        metadata: "json|optional",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: true,
      asyncPartitions: true,
      partitions: {
        byPriority: { fields: { priority: "number" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
    if (!created) {
      if (resource) {
        this.targetsResource = resource;
        return;
      }
      throw err;
    }
    this.targetsResource = this.database.resources[this.config.targetsResource];
  }
  async onInstall() {
    await this._ensureTargetsResource();
    this.puppeteerPlugin = await this._installDependency(
      "puppeteer",
      this.pluginFactories.puppeteer({
        namespace: this.namespace,
        ...this.config.puppeteer
      })
    );
    const queueOptions = {
      namespace: this.namespace,
      resource: this.config.queue.resource,
      deadLetterResource: this.config.queue.deadLetterResource,
      visibilityTimeout: this.config.queue.visibilityTimeout,
      pollInterval: this.config.queue.pollInterval,
      maxAttempts: this.config.queue.maxAttempts,
      concurrency: this.config.queue.concurrency,
      autoStart: this.config.queue.autoStart && typeof this.processor === "function",
      onMessage: this.queueHandler,
      verbose: this.config.queue.verbose
    };
    this.queuePlugin = await this._installDependency("queue", this.pluginFactories.queue(queueOptions));
    if (this.config.ttl) {
      const ttlConfig = {
        namespace: this.namespace,
        ...this.config.ttl
      };
      ttlConfig.resources = ttlConfig.resources || {};
      if (!ttlConfig.resources[this.queuePlugin.queueResourceName]) {
        ttlConfig.resources[this.queuePlugin.queueResourceName] = {
          ttl: ttlConfig.queue?.ttl || 3600,
          onExpire: ttlConfig.queue?.onExpire || "hard-delete",
          field: ttlConfig.queue?.field || null
        };
      }
      delete ttlConfig.queue;
      this.ttlPlugin = await this._installDependency("ttl", this.pluginFactories.ttl(ttlConfig));
    }
    this.emit("spiderSuite.installed", {
      namespace: this.namespace,
      targetsResource: this.config.targetsResource
    });
  }
  async onStart() {
    if (this.config.queue.autoStart && typeof this.processor === "function") {
      await this.startProcessing();
    }
  }
  async onStop() {
    await this.stopProcessing();
  }
  async onUninstall(options = {}) {
    await this.onStop();
    for (const dep of [...this.dependencies].reverse()) {
      await this.database.uninstallPlugin(dep.name, { purgeData: options.purgeData === true });
    }
    this.dependencies = [];
  }
  /**
   * Register a queue processor.
   */
  async setProcessor(handler, { autoStart = true, concurrency } = {}) {
    this.processor = handler;
    if (autoStart && typeof handler === "function") {
      await this.startProcessing({ concurrency });
    }
  }
  /**
   * Enqueue a target for crawling.
   */
  async enqueueTarget(data, options = {}) {
    if (!this.targetsResource?.enqueue) {
      throw new Error("[SpiderSuitePlugin] Queue helpers not initialized yet");
    }
    return await this.targetsResource.enqueue({
      createdAt: (/* @__PURE__ */ new Date()).toISOString().slice(0, 10),
      ...data
    }, options);
  }
  /**
   * Start processing queued targets.
   */
  async startProcessing(options = {}) {
    if (!this.targetsResource?.startProcessing) return;
    const concurrency = options.concurrency || this.config.queue.concurrency;
    await this.targetsResource.startProcessing(this.queueHandler, { concurrency });
  }
  /**
   * Stop processing queued targets.
   */
  async stopProcessing() {
    if (this.targetsResource?.stopProcessing) {
      await this.targetsResource.stopProcessing();
    }
  }
  async queueHandler(record, context) {
    if (typeof this.processor !== "function") {
      throw new Error("[SpiderSuitePlugin] No processor registered. Call setProcessor(fn) first.");
    }
    const helpers = {
      puppeteer: this.puppeteerPlugin,
      queue: this.queuePlugin,
      enqueue: this.enqueueTarget.bind(this),
      resource: this.targetsResource,
      plugin: this
    };
    return await this.processor(record, context, helpers);
  }
}

/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */
function listCacheClear() {
  this.__data__ = [];
  this.size = 0;
}

/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */
function eq(value, other) {
  return value === other || (value !== value && other !== other);
}

/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */
function assocIndexOf(array, key) {
  var length = array.length;
  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }
  return -1;
}

/** Used for built-in method references. */
var arrayProto = Array.prototype;

/** Built-in value references. */
var splice = arrayProto.splice;

/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }
  var lastIndex = data.length - 1;
  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }
  --this.size;
  return true;
}

/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  return index < 0 ? undefined : data[index][1];
}

/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}

/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */
function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    ++this.size;
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }
  return this;
}

/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function ListCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

// Add methods to `ListCache`.
ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;

/**
 * Removes all key-value entries from the stack.
 *
 * @private
 * @name clear
 * @memberOf Stack
 */
function stackClear() {
  this.__data__ = new ListCache;
  this.size = 0;
}

/**
 * Removes `key` and its value from the stack.
 *
 * @private
 * @name delete
 * @memberOf Stack
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function stackDelete(key) {
  var data = this.__data__,
      result = data['delete'](key);

  this.size = data.size;
  return result;
}

/**
 * Gets the stack value for `key`.
 *
 * @private
 * @name get
 * @memberOf Stack
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function stackGet(key) {
  return this.__data__.get(key);
}

/**
 * Checks if a stack value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Stack
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function stackHas(key) {
  return this.__data__.has(key);
}

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof global == 'object' && global && global.Object === Object && global;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/** Built-in value references. */
var Symbol$1 = root.Symbol;

/** Used for built-in method references. */
var objectProto$b = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$8 = objectProto$b.hasOwnProperty;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var nativeObjectToString$1 = objectProto$b.toString;

/** Built-in value references. */
var symToStringTag$1 = Symbol$1 ? Symbol$1.toStringTag : undefined;

/**
 * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the raw `toStringTag`.
 */
function getRawTag(value) {
  var isOwn = hasOwnProperty$8.call(value, symToStringTag$1),
      tag = value[symToStringTag$1];

  try {
    value[symToStringTag$1] = undefined;
    var unmasked = true;
  } catch (e) {}

  var result = nativeObjectToString$1.call(value);
  if (unmasked) {
    if (isOwn) {
      value[symToStringTag$1] = tag;
    } else {
      delete value[symToStringTag$1];
    }
  }
  return result;
}

/** Used for built-in method references. */
var objectProto$a = Object.prototype;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var nativeObjectToString = objectProto$a.toString;

/**
 * Converts `value` to a string using `Object.prototype.toString`.
 *
 * @private
 * @param {*} value The value to convert.
 * @returns {string} Returns the converted string.
 */
function objectToString(value) {
  return nativeObjectToString.call(value);
}

/** `Object#toString` result references. */
var nullTag = '[object Null]',
    undefinedTag = '[object Undefined]';

/** Built-in value references. */
var symToStringTag = Symbol$1 ? Symbol$1.toStringTag : undefined;

/**
 * The base implementation of `getTag` without fallbacks for buggy environments.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
function baseGetTag(value) {
  if (value == null) {
    return value === undefined ? undefinedTag : nullTag;
  }
  return (symToStringTag && symToStringTag in Object(value))
    ? getRawTag(value)
    : objectToString(value);
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return value != null && (type == 'object' || type == 'function');
}

/** `Object#toString` result references. */
var asyncTag = '[object AsyncFunction]',
    funcTag$1 = '[object Function]',
    genTag = '[object GeneratorFunction]',
    proxyTag = '[object Proxy]';

/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */
function isFunction(value) {
  if (!isObject(value)) {
    return false;
  }
  // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 9 which returns 'object' for typed arrays and other constructors.
  var tag = baseGetTag(value);
  return tag == funcTag$1 || tag == genTag || tag == asyncTag || tag == proxyTag;
}

/** Used to detect overreaching core-js shims. */
var coreJsData = root['__core-js_shared__'];

/** Used to detect methods masquerading as native. */
var maskSrcKey = (function() {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? ('Symbol(src)_1.' + uid) : '';
}());

/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */
function isMasked(func) {
  return !!maskSrcKey && (maskSrcKey in func);
}

/** Used for built-in method references. */
var funcProto$1 = Function.prototype;

/** Used to resolve the decompiled source of functions. */
var funcToString$1 = funcProto$1.toString;

/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to convert.
 * @returns {string} Returns the source code.
 */
function toSource(func) {
  if (func != null) {
    try {
      return funcToString$1.call(func);
    } catch (e) {}
    try {
      return (func + '');
    } catch (e) {}
  }
  return '';
}

/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */
var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;

/** Used to detect host constructors (Safari). */
var reIsHostCtor = /^\[object .+?Constructor\]$/;

/** Used for built-in method references. */
var funcProto = Function.prototype,
    objectProto$9 = Object.prototype;

/** Used to resolve the decompiled source of functions. */
var funcToString = funcProto.toString;

/** Used to check objects for own properties. */
var hasOwnProperty$7 = objectProto$9.hasOwnProperty;

/** Used to detect if a method is native. */
var reIsNative = RegExp('^' +
  funcToString.call(hasOwnProperty$7).replace(reRegExpChar, '\\$&')
  .replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$'
);

/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */
function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }
  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}

/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */
function getValue(object, key) {
  return object == null ? undefined : object[key];
}

/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */
function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}

/* Built-in method references that are verified to be native. */
var Map$1 = getNative(root, 'Map');

/* Built-in method references that are verified to be native. */
var nativeCreate = getNative(Object, 'create');

/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */
function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
  this.size = 0;
}

/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function hashDelete(key) {
  var result = this.has(key) && delete this.__data__[key];
  this.size -= result ? 1 : 0;
  return result;
}

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED$2 = '__lodash_hash_undefined__';

/** Used for built-in method references. */
var objectProto$8 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$6 = objectProto$8.hasOwnProperty;

/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function hashGet(key) {
  var data = this.__data__;
  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED$2 ? undefined : result;
  }
  return hasOwnProperty$6.call(data, key) ? data[key] : undefined;
}

/** Used for built-in method references. */
var objectProto$7 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$5 = objectProto$7.hasOwnProperty;

/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty$5.call(data, key);
}

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED$1 = '__lodash_hash_undefined__';

/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */
function hashSet(key, value) {
  var data = this.__data__;
  this.size += this.has(key) ? 0 : 1;
  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED$1 : value;
  return this;
}

/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Hash(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

// Add methods to `Hash`.
Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;

/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */
function mapCacheClear() {
  this.size = 0;
  this.__data__ = {
    'hash': new Hash,
    'map': new (Map$1 || ListCache),
    'string': new Hash
  };
}

/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */
function isKeyable(value) {
  var type = typeof value;
  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')
    ? (value !== '__proto__')
    : (value === null);
}

/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */
function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key)
    ? data[typeof key == 'string' ? 'string' : 'hash']
    : data.map;
}

/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function mapCacheDelete(key) {
  var result = getMapData(this, key)['delete'](key);
  this.size -= result ? 1 : 0;
  return result;
}

/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}

/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}

/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */
function mapCacheSet(key, value) {
  var data = getMapData(this, key),
      size = data.size;

  data.set(key, value);
  this.size += data.size == size ? 0 : 1;
  return this;
}

/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function MapCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

// Add methods to `MapCache`.
MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;

/** Used as the size to enable large array optimizations. */
var LARGE_ARRAY_SIZE = 200;

/**
 * Sets the stack `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Stack
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the stack cache instance.
 */
function stackSet(key, value) {
  var data = this.__data__;
  if (data instanceof ListCache) {
    var pairs = data.__data__;
    if (!Map$1 || (pairs.length < LARGE_ARRAY_SIZE - 1)) {
      pairs.push([key, value]);
      this.size = ++data.size;
      return this;
    }
    data = this.__data__ = new MapCache(pairs);
  }
  data.set(key, value);
  this.size = data.size;
  return this;
}

/**
 * Creates a stack cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Stack(entries) {
  var data = this.__data__ = new ListCache(entries);
  this.size = data.size;
}

// Add methods to `Stack`.
Stack.prototype.clear = stackClear;
Stack.prototype['delete'] = stackDelete;
Stack.prototype.get = stackGet;
Stack.prototype.has = stackHas;
Stack.prototype.set = stackSet;

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED = '__lodash_hash_undefined__';

/**
 * Adds `value` to the array cache.
 *
 * @private
 * @name add
 * @memberOf SetCache
 * @alias push
 * @param {*} value The value to cache.
 * @returns {Object} Returns the cache instance.
 */
function setCacheAdd(value) {
  this.__data__.set(value, HASH_UNDEFINED);
  return this;
}

/**
 * Checks if `value` is in the array cache.
 *
 * @private
 * @name has
 * @memberOf SetCache
 * @param {*} value The value to search for.
 * @returns {number} Returns `true` if `value` is found, else `false`.
 */
function setCacheHas(value) {
  return this.__data__.has(value);
}

/**
 *
 * Creates an array cache object to store unique values.
 *
 * @private
 * @constructor
 * @param {Array} [values] The values to cache.
 */
function SetCache(values) {
  var index = -1,
      length = values == null ? 0 : values.length;

  this.__data__ = new MapCache;
  while (++index < length) {
    this.add(values[index]);
  }
}

// Add methods to `SetCache`.
SetCache.prototype.add = SetCache.prototype.push = setCacheAdd;
SetCache.prototype.has = setCacheHas;

/**
 * A specialized version of `_.some` for arrays without support for iteratee
 * shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {boolean} Returns `true` if any element passes the predicate check,
 *  else `false`.
 */
function arraySome(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length;

  while (++index < length) {
    if (predicate(array[index], index, array)) {
      return true;
    }
  }
  return false;
}

/**
 * Checks if a `cache` value for `key` exists.
 *
 * @private
 * @param {Object} cache The cache to query.
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function cacheHas(cache, key) {
  return cache.has(key);
}

/** Used to compose bitmasks for value comparisons. */
var COMPARE_PARTIAL_FLAG$3 = 1,
    COMPARE_UNORDERED_FLAG$1 = 2;

/**
 * A specialized version of `baseIsEqualDeep` for arrays with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Array} array The array to compare.
 * @param {Array} other The other array to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `array` and `other` objects.
 * @returns {boolean} Returns `true` if the arrays are equivalent, else `false`.
 */
function equalArrays(array, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG$3,
      arrLength = array.length,
      othLength = other.length;

  if (arrLength != othLength && !(isPartial && othLength > arrLength)) {
    return false;
  }
  // Check that cyclic values are equal.
  var arrStacked = stack.get(array);
  var othStacked = stack.get(other);
  if (arrStacked && othStacked) {
    return arrStacked == other && othStacked == array;
  }
  var index = -1,
      result = true,
      seen = (bitmask & COMPARE_UNORDERED_FLAG$1) ? new SetCache : undefined;

  stack.set(array, other);
  stack.set(other, array);

  // Ignore non-index properties.
  while (++index < arrLength) {
    var arrValue = array[index],
        othValue = other[index];

    if (customizer) {
      var compared = isPartial
        ? customizer(othValue, arrValue, index, other, array, stack)
        : customizer(arrValue, othValue, index, array, other, stack);
    }
    if (compared !== undefined) {
      if (compared) {
        continue;
      }
      result = false;
      break;
    }
    // Recursively compare arrays (susceptible to call stack limits).
    if (seen) {
      if (!arraySome(other, function(othValue, othIndex) {
            if (!cacheHas(seen, othIndex) &&
                (arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {
              return seen.push(othIndex);
            }
          })) {
        result = false;
        break;
      }
    } else if (!(
          arrValue === othValue ||
            equalFunc(arrValue, othValue, bitmask, customizer, stack)
        )) {
      result = false;
      break;
    }
  }
  stack['delete'](array);
  stack['delete'](other);
  return result;
}

/** Built-in value references. */
var Uint8Array$1 = root.Uint8Array;

/**
 * Converts `map` to its key-value pairs.
 *
 * @private
 * @param {Object} map The map to convert.
 * @returns {Array} Returns the key-value pairs.
 */
function mapToArray(map) {
  var index = -1,
      result = Array(map.size);

  map.forEach(function(value, key) {
    result[++index] = [key, value];
  });
  return result;
}

/**
 * Converts `set` to an array of its values.
 *
 * @private
 * @param {Object} set The set to convert.
 * @returns {Array} Returns the values.
 */
function setToArray(set) {
  var index = -1,
      result = Array(set.size);

  set.forEach(function(value) {
    result[++index] = value;
  });
  return result;
}

/** Used to compose bitmasks for value comparisons. */
var COMPARE_PARTIAL_FLAG$2 = 1,
    COMPARE_UNORDERED_FLAG = 2;

/** `Object#toString` result references. */
var boolTag$1 = '[object Boolean]',
    dateTag$1 = '[object Date]',
    errorTag$1 = '[object Error]',
    mapTag$2 = '[object Map]',
    numberTag$1 = '[object Number]',
    regexpTag$1 = '[object RegExp]',
    setTag$2 = '[object Set]',
    stringTag$1 = '[object String]',
    symbolTag = '[object Symbol]';

var arrayBufferTag$1 = '[object ArrayBuffer]',
    dataViewTag$2 = '[object DataView]';

/** Used to convert symbols to primitives and strings. */
var symbolProto = Symbol$1 ? Symbol$1.prototype : undefined,
    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;

/**
 * A specialized version of `baseIsEqualDeep` for comparing objects of
 * the same `toStringTag`.
 *
 * **Note:** This function only supports comparing values with tags of
 * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {string} tag The `toStringTag` of the objects to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {
  switch (tag) {
    case dataViewTag$2:
      if ((object.byteLength != other.byteLength) ||
          (object.byteOffset != other.byteOffset)) {
        return false;
      }
      object = object.buffer;
      other = other.buffer;

    case arrayBufferTag$1:
      if ((object.byteLength != other.byteLength) ||
          !equalFunc(new Uint8Array$1(object), new Uint8Array$1(other))) {
        return false;
      }
      return true;

    case boolTag$1:
    case dateTag$1:
    case numberTag$1:
      // Coerce booleans to `1` or `0` and dates to milliseconds.
      // Invalid dates are coerced to `NaN`.
      return eq(+object, +other);

    case errorTag$1:
      return object.name == other.name && object.message == other.message;

    case regexpTag$1:
    case stringTag$1:
      // Coerce regexes to strings and treat strings, primitives and objects,
      // as equal. See http://www.ecma-international.org/ecma-262/7.0/#sec-regexp.prototype.tostring
      // for more details.
      return object == (other + '');

    case mapTag$2:
      var convert = mapToArray;

    case setTag$2:
      var isPartial = bitmask & COMPARE_PARTIAL_FLAG$2;
      convert || (convert = setToArray);

      if (object.size != other.size && !isPartial) {
        return false;
      }
      // Assume cyclic values are equal.
      var stacked = stack.get(object);
      if (stacked) {
        return stacked == other;
      }
      bitmask |= COMPARE_UNORDERED_FLAG;

      // Recursively compare objects (susceptible to call stack limits).
      stack.set(object, other);
      var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);
      stack['delete'](object);
      return result;

    case symbolTag:
      if (symbolValueOf) {
        return symbolValueOf.call(object) == symbolValueOf.call(other);
      }
  }
  return false;
}

/**
 * Appends the elements of `values` to `array`.
 *
 * @private
 * @param {Array} array The array to modify.
 * @param {Array} values The values to append.
 * @returns {Array} Returns `array`.
 */
function arrayPush(array, values) {
  var index = -1,
      length = values.length,
      offset = array.length;

  while (++index < length) {
    array[offset + index] = values[index];
  }
  return array;
}

/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */
var isArray = Array.isArray;

/**
 * The base implementation of `getAllKeys` and `getAllKeysIn` which uses
 * `keysFunc` and `symbolsFunc` to get the enumerable property names and
 * symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Function} keysFunc The function to get the keys of `object`.
 * @param {Function} symbolsFunc The function to get the symbols of `object`.
 * @returns {Array} Returns the array of property names and symbols.
 */
function baseGetAllKeys(object, keysFunc, symbolsFunc) {
  var result = keysFunc(object);
  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));
}

/**
 * A specialized version of `_.filter` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {Array} Returns the new filtered array.
 */
function arrayFilter(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length,
      resIndex = 0,
      result = [];

  while (++index < length) {
    var value = array[index];
    if (predicate(value, index, array)) {
      result[resIndex++] = value;
    }
  }
  return result;
}

/**
 * This method returns a new empty array.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {Array} Returns the new empty array.
 * @example
 *
 * var arrays = _.times(2, _.stubArray);
 *
 * console.log(arrays);
 * // => [[], []]
 *
 * console.log(arrays[0] === arrays[1]);
 * // => false
 */
function stubArray() {
  return [];
}

/** Used for built-in method references. */
var objectProto$6 = Object.prototype;

/** Built-in value references. */
var propertyIsEnumerable$1 = objectProto$6.propertyIsEnumerable;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeGetSymbols = Object.getOwnPropertySymbols;

/**
 * Creates an array of the own enumerable symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of symbols.
 */
var getSymbols = !nativeGetSymbols ? stubArray : function(object) {
  if (object == null) {
    return [];
  }
  object = Object(object);
  return arrayFilter(nativeGetSymbols(object), function(symbol) {
    return propertyIsEnumerable$1.call(object, symbol);
  });
};

/**
 * The base implementation of `_.times` without support for iteratee shorthands
 * or max array length checks.
 *
 * @private
 * @param {number} n The number of times to invoke `iteratee`.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns the array of results.
 */
function baseTimes(n, iteratee) {
  var index = -1,
      result = Array(n);

  while (++index < n) {
    result[index] = iteratee(index);
  }
  return result;
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return value != null && typeof value == 'object';
}

/** `Object#toString` result references. */
var argsTag$2 = '[object Arguments]';

/**
 * The base implementation of `_.isArguments`.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 */
function baseIsArguments(value) {
  return isObjectLike(value) && baseGetTag(value) == argsTag$2;
}

/** Used for built-in method references. */
var objectProto$5 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$4 = objectProto$5.hasOwnProperty;

/** Built-in value references. */
var propertyIsEnumerable = objectProto$5.propertyIsEnumerable;

/**
 * Checks if `value` is likely an `arguments` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 *  else `false`.
 * @example
 *
 * _.isArguments(function() { return arguments; }());
 * // => true
 *
 * _.isArguments([1, 2, 3]);
 * // => false
 */
var isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {
  return isObjectLike(value) && hasOwnProperty$4.call(value, 'callee') &&
    !propertyIsEnumerable.call(value, 'callee');
};

/**
 * This method returns `false`.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {boolean} Returns `false`.
 * @example
 *
 * _.times(2, _.stubFalse);
 * // => [false, false]
 */
function stubFalse() {
  return false;
}

/** Detect free variable `exports`. */
var freeExports$1 = typeof exports == 'object' && exports && !exports.nodeType && exports;

/** Detect free variable `module`. */
var freeModule$1 = freeExports$1 && typeof module == 'object' && module && !module.nodeType && module;

/** Detect the popular CommonJS extension `module.exports`. */
var moduleExports$1 = freeModule$1 && freeModule$1.exports === freeExports$1;

/** Built-in value references. */
var Buffer$1 = moduleExports$1 ? root.Buffer : undefined;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeIsBuffer = Buffer$1 ? Buffer$1.isBuffer : undefined;

/**
 * Checks if `value` is a buffer.
 *
 * @static
 * @memberOf _
 * @since 4.3.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.
 * @example
 *
 * _.isBuffer(new Buffer(2));
 * // => true
 *
 * _.isBuffer(new Uint8Array(2));
 * // => false
 */
var isBuffer = nativeIsBuffer || stubFalse;

/** Used as references for various `Number` constants. */
var MAX_SAFE_INTEGER$1 = 9007199254740991;

/** Used to detect unsigned integer values. */
var reIsUint = /^(?:0|[1-9]\d*)$/;

/**
 * Checks if `value` is a valid array-like index.
 *
 * @private
 * @param {*} value The value to check.
 * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.
 * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.
 */
function isIndex(value, length) {
  var type = typeof value;
  length = length == null ? MAX_SAFE_INTEGER$1 : length;

  return !!length &&
    (type == 'number' ||
      (type != 'symbol' && reIsUint.test(value))) &&
        (value > -1 && value % 1 == 0 && value < length);
}

/** Used as references for various `Number` constants. */
var MAX_SAFE_INTEGER = 9007199254740991;

/**
 * Checks if `value` is a valid array-like length.
 *
 * **Note:** This method is loosely based on
 * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.
 * @example
 *
 * _.isLength(3);
 * // => true
 *
 * _.isLength(Number.MIN_VALUE);
 * // => false
 *
 * _.isLength(Infinity);
 * // => false
 *
 * _.isLength('3');
 * // => false
 */
function isLength(value) {
  return typeof value == 'number' &&
    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;
}

/** `Object#toString` result references. */
var argsTag$1 = '[object Arguments]',
    arrayTag$1 = '[object Array]',
    boolTag = '[object Boolean]',
    dateTag = '[object Date]',
    errorTag = '[object Error]',
    funcTag = '[object Function]',
    mapTag$1 = '[object Map]',
    numberTag = '[object Number]',
    objectTag$2 = '[object Object]',
    regexpTag = '[object RegExp]',
    setTag$1 = '[object Set]',
    stringTag = '[object String]',
    weakMapTag$1 = '[object WeakMap]';

var arrayBufferTag = '[object ArrayBuffer]',
    dataViewTag$1 = '[object DataView]',
    float32Tag = '[object Float32Array]',
    float64Tag = '[object Float64Array]',
    int8Tag = '[object Int8Array]',
    int16Tag = '[object Int16Array]',
    int32Tag = '[object Int32Array]',
    uint8Tag = '[object Uint8Array]',
    uint8ClampedTag = '[object Uint8ClampedArray]',
    uint16Tag = '[object Uint16Array]',
    uint32Tag = '[object Uint32Array]';

/** Used to identify `toStringTag` values of typed arrays. */
var typedArrayTags = {};
typedArrayTags[float32Tag] = typedArrayTags[float64Tag] =
typedArrayTags[int8Tag] = typedArrayTags[int16Tag] =
typedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =
typedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =
typedArrayTags[uint32Tag] = true;
typedArrayTags[argsTag$1] = typedArrayTags[arrayTag$1] =
typedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =
typedArrayTags[dataViewTag$1] = typedArrayTags[dateTag] =
typedArrayTags[errorTag] = typedArrayTags[funcTag] =
typedArrayTags[mapTag$1] = typedArrayTags[numberTag] =
typedArrayTags[objectTag$2] = typedArrayTags[regexpTag] =
typedArrayTags[setTag$1] = typedArrayTags[stringTag] =
typedArrayTags[weakMapTag$1] = false;

/**
 * The base implementation of `_.isTypedArray` without Node.js optimizations.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 */
function baseIsTypedArray(value) {
  return isObjectLike(value) &&
    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];
}

/**
 * The base implementation of `_.unary` without support for storing metadata.
 *
 * @private
 * @param {Function} func The function to cap arguments for.
 * @returns {Function} Returns the new capped function.
 */
function baseUnary(func) {
  return function(value) {
    return func(value);
  };
}

/** Detect free variable `exports`. */
var freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;

/** Detect free variable `module`. */
var freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;

/** Detect the popular CommonJS extension `module.exports`. */
var moduleExports = freeModule && freeModule.exports === freeExports;

/** Detect free variable `process` from Node.js. */
var freeProcess = moduleExports && freeGlobal.process;

/** Used to access faster Node.js helpers. */
var nodeUtil = (function() {
  try {
    // Use `util.types` for Node.js 10+.
    var types = freeModule && freeModule.require && freeModule.require('util').types;

    if (types) {
      return types;
    }

    // Legacy `process.binding('util')` for Node.js < 10.
    return freeProcess && freeProcess.binding && freeProcess.binding('util');
  } catch (e) {}
}());

/* Node.js helper references. */
var nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;

/**
 * Checks if `value` is classified as a typed array.
 *
 * @static
 * @memberOf _
 * @since 3.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 * @example
 *
 * _.isTypedArray(new Uint8Array);
 * // => true
 *
 * _.isTypedArray([]);
 * // => false
 */
var isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;

/** Used for built-in method references. */
var objectProto$4 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$3 = objectProto$4.hasOwnProperty;

/**
 * Creates an array of the enumerable property names of the array-like `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @param {boolean} inherited Specify returning inherited property names.
 * @returns {Array} Returns the array of property names.
 */
function arrayLikeKeys(value, inherited) {
  var isArr = isArray(value),
      isArg = !isArr && isArguments(value),
      isBuff = !isArr && !isArg && isBuffer(value),
      isType = !isArr && !isArg && !isBuff && isTypedArray(value),
      skipIndexes = isArr || isArg || isBuff || isType,
      result = skipIndexes ? baseTimes(value.length, String) : [],
      length = result.length;

  for (var key in value) {
    if ((hasOwnProperty$3.call(value, key)) &&
        !(skipIndexes && (
           // Safari 9 has enumerable `arguments.length` in strict mode.
           key == 'length' ||
           // Node.js 0.10 has enumerable non-index properties on buffers.
           (isBuff && (key == 'offset' || key == 'parent')) ||
           // PhantomJS 2 has enumerable non-index properties on typed arrays.
           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||
           // Skip index properties.
           isIndex(key, length)
        ))) {
      result.push(key);
    }
  }
  return result;
}

/** Used for built-in method references. */
var objectProto$3 = Object.prototype;

/**
 * Checks if `value` is likely a prototype object.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.
 */
function isPrototype(value) {
  var Ctor = value && value.constructor,
      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto$3;

  return value === proto;
}

/**
 * Creates a unary function that invokes `func` with its argument transformed.
 *
 * @private
 * @param {Function} func The function to wrap.
 * @param {Function} transform The argument transform.
 * @returns {Function} Returns the new function.
 */
function overArg(func, transform) {
  return function(arg) {
    return func(transform(arg));
  };
}

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeKeys = overArg(Object.keys, Object);

/** Used for built-in method references. */
var objectProto$2 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$2 = objectProto$2.hasOwnProperty;

/**
 * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 */
function baseKeys(object) {
  if (!isPrototype(object)) {
    return nativeKeys(object);
  }
  var result = [];
  for (var key in Object(object)) {
    if (hasOwnProperty$2.call(object, key) && key != 'constructor') {
      result.push(key);
    }
  }
  return result;
}

/**
 * Checks if `value` is array-like. A value is considered array-like if it's
 * not a function and has a `value.length` that's an integer greater than or
 * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is array-like, else `false`.
 * @example
 *
 * _.isArrayLike([1, 2, 3]);
 * // => true
 *
 * _.isArrayLike(document.body.children);
 * // => true
 *
 * _.isArrayLike('abc');
 * // => true
 *
 * _.isArrayLike(_.noop);
 * // => false
 */
function isArrayLike(value) {
  return value != null && isLength(value.length) && !isFunction(value);
}

/**
 * Creates an array of the own enumerable property names of `object`.
 *
 * **Note:** Non-object values are coerced to objects. See the
 * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)
 * for more details.
 *
 * @static
 * @since 0.1.0
 * @memberOf _
 * @category Object
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 * @example
 *
 * function Foo() {
 *   this.a = 1;
 *   this.b = 2;
 * }
 *
 * Foo.prototype.c = 3;
 *
 * _.keys(new Foo);
 * // => ['a', 'b'] (iteration order is not guaranteed)
 *
 * _.keys('hi');
 * // => ['0', '1']
 */
function keys(object) {
  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);
}

/**
 * Creates an array of own enumerable property names and symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names and symbols.
 */
function getAllKeys(object) {
  return baseGetAllKeys(object, keys, getSymbols);
}

/** Used to compose bitmasks for value comparisons. */
var COMPARE_PARTIAL_FLAG$1 = 1;

/** Used for built-in method references. */
var objectProto$1 = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty$1 = objectProto$1.hasOwnProperty;

/**
 * A specialized version of `baseIsEqualDeep` for objects with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function equalObjects(object, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG$1,
      objProps = getAllKeys(object),
      objLength = objProps.length,
      othProps = getAllKeys(other),
      othLength = othProps.length;

  if (objLength != othLength && !isPartial) {
    return false;
  }
  var index = objLength;
  while (index--) {
    var key = objProps[index];
    if (!(isPartial ? key in other : hasOwnProperty$1.call(other, key))) {
      return false;
    }
  }
  // Check that cyclic values are equal.
  var objStacked = stack.get(object);
  var othStacked = stack.get(other);
  if (objStacked && othStacked) {
    return objStacked == other && othStacked == object;
  }
  var result = true;
  stack.set(object, other);
  stack.set(other, object);

  var skipCtor = isPartial;
  while (++index < objLength) {
    key = objProps[index];
    var objValue = object[key],
        othValue = other[key];

    if (customizer) {
      var compared = isPartial
        ? customizer(othValue, objValue, key, other, object, stack)
        : customizer(objValue, othValue, key, object, other, stack);
    }
    // Recursively compare objects (susceptible to call stack limits).
    if (!(compared === undefined
          ? (objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack))
          : compared
        )) {
      result = false;
      break;
    }
    skipCtor || (skipCtor = key == 'constructor');
  }
  if (result && !skipCtor) {
    var objCtor = object.constructor,
        othCtor = other.constructor;

    // Non `Object` object instances with different constructors are not equal.
    if (objCtor != othCtor &&
        ('constructor' in object && 'constructor' in other) &&
        !(typeof objCtor == 'function' && objCtor instanceof objCtor &&
          typeof othCtor == 'function' && othCtor instanceof othCtor)) {
      result = false;
    }
  }
  stack['delete'](object);
  stack['delete'](other);
  return result;
}

/* Built-in method references that are verified to be native. */
var DataView = getNative(root, 'DataView');

/* Built-in method references that are verified to be native. */
var Promise$1 = getNative(root, 'Promise');

/* Built-in method references that are verified to be native. */
var Set$1 = getNative(root, 'Set');

/* Built-in method references that are verified to be native. */
var WeakMap = getNative(root, 'WeakMap');

/** `Object#toString` result references. */
var mapTag = '[object Map]',
    objectTag$1 = '[object Object]',
    promiseTag = '[object Promise]',
    setTag = '[object Set]',
    weakMapTag = '[object WeakMap]';

var dataViewTag = '[object DataView]';

/** Used to detect maps, sets, and weakmaps. */
var dataViewCtorString = toSource(DataView),
    mapCtorString = toSource(Map$1),
    promiseCtorString = toSource(Promise$1),
    setCtorString = toSource(Set$1),
    weakMapCtorString = toSource(WeakMap);

/**
 * Gets the `toStringTag` of `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
var getTag = baseGetTag;

// Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.
if ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||
    (Map$1 && getTag(new Map$1) != mapTag) ||
    (Promise$1 && getTag(Promise$1.resolve()) != promiseTag) ||
    (Set$1 && getTag(new Set$1) != setTag) ||
    (WeakMap && getTag(new WeakMap) != weakMapTag)) {
  getTag = function(value) {
    var result = baseGetTag(value),
        Ctor = result == objectTag$1 ? value.constructor : undefined,
        ctorString = Ctor ? toSource(Ctor) : '';

    if (ctorString) {
      switch (ctorString) {
        case dataViewCtorString: return dataViewTag;
        case mapCtorString: return mapTag;
        case promiseCtorString: return promiseTag;
        case setCtorString: return setTag;
        case weakMapCtorString: return weakMapTag;
      }
    }
    return result;
  };
}

/** Used to compose bitmasks for value comparisons. */
var COMPARE_PARTIAL_FLAG = 1;

/** `Object#toString` result references. */
var argsTag = '[object Arguments]',
    arrayTag = '[object Array]',
    objectTag = '[object Object]';

/** Used for built-in method references. */
var objectProto = Object.prototype;

/** Used to check objects for own properties. */
var hasOwnProperty = objectProto.hasOwnProperty;

/**
 * A specialized version of `baseIsEqual` for arrays and objects which performs
 * deep comparisons and tracks traversed objects enabling objects with circular
 * references to be compared.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} [stack] Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {
  var objIsArr = isArray(object),
      othIsArr = isArray(other),
      objTag = objIsArr ? arrayTag : getTag(object),
      othTag = othIsArr ? arrayTag : getTag(other);

  objTag = objTag == argsTag ? objectTag : objTag;
  othTag = othTag == argsTag ? objectTag : othTag;

  var objIsObj = objTag == objectTag,
      othIsObj = othTag == objectTag,
      isSameTag = objTag == othTag;

  if (isSameTag && isBuffer(object)) {
    if (!isBuffer(other)) {
      return false;
    }
    objIsArr = true;
    objIsObj = false;
  }
  if (isSameTag && !objIsObj) {
    stack || (stack = new Stack);
    return (objIsArr || isTypedArray(object))
      ? equalArrays(object, other, bitmask, customizer, equalFunc, stack)
      : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);
  }
  if (!(bitmask & COMPARE_PARTIAL_FLAG)) {
    var objIsWrapped = objIsObj && hasOwnProperty.call(object, '__wrapped__'),
        othIsWrapped = othIsObj && hasOwnProperty.call(other, '__wrapped__');

    if (objIsWrapped || othIsWrapped) {
      var objUnwrapped = objIsWrapped ? object.value() : object,
          othUnwrapped = othIsWrapped ? other.value() : other;

      stack || (stack = new Stack);
      return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);
    }
  }
  if (!isSameTag) {
    return false;
  }
  stack || (stack = new Stack);
  return equalObjects(object, other, bitmask, customizer, equalFunc, stack);
}

/**
 * The base implementation of `_.isEqual` which supports partial comparisons
 * and tracks traversed objects.
 *
 * @private
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @param {boolean} bitmask The bitmask flags.
 *  1 - Unordered comparison
 *  2 - Partial comparison
 * @param {Function} [customizer] The function to customize comparisons.
 * @param {Object} [stack] Tracks traversed `value` and `other` objects.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 */
function baseIsEqual(value, other, bitmask, customizer, stack) {
  if (value === other) {
    return true;
  }
  if (value == null || other == null || (!isObjectLike(value) && !isObjectLike(other))) {
    return value !== value && other !== other;
  }
  return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);
}

/**
 * Performs a deep comparison between two values to determine if they are
 * equivalent.
 *
 * **Note:** This method supports comparing arrays, array buffers, booleans,
 * date objects, error objects, maps, numbers, `Object` objects, regexes,
 * sets, strings, symbols, and typed arrays. `Object` objects are compared
 * by their own, not inherited, enumerable properties. Functions and DOM
 * nodes are compared by strict equality, i.e. `===`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.isEqual(object, other);
 * // => true
 *
 * object === other;
 * // => false
 */
function isEqual(value, other) {
  return baseIsEqual(value, other);
}

class BaseCloudDriver {
  /**
   * @param {Object} options
   * @param {string} options.id - Unique identifier for this cloud source
   * @param {string} options.driver - Driver name (aws, gcp, do, ...)
   * @param {Object} options.credentials - Authentication material
   * @param {Object} options.config - Driver specific configuration
   * @param {Object} options.globals - Global plugin options
   * @param {Function} options.logger - Optional logger fn (level, msg, meta)
   */
  constructor(options = {}) {
    const {
      id,
      driver,
      credentials = {},
      config = {},
      globals = {},
      logger = null
    } = options;
    if (!driver) {
      throw new Error('Cloud driver requires a "driver" identifier');
    }
    this.id = id || driver;
    this.driver = driver;
    this.credentials = credentials;
    this.config = config;
    this.globals = globals;
    this.logger = typeof logger === "function" ? logger : () => {
    };
  }
  /**
   * Perform driver bootstrapping (auth warm-up, SDK clients, etc).
   * Default implementation is a no-op.
   */
  async initialize() {
    return;
  }
  /**
   * Fetch resources from the cloud API.
   * Must be implemented by subclasses.
   * @param {Object} options
   * @returns {Promise<Array<Object>|AsyncIterable<Object>>}
   */
  // eslint-disable-next-line no-unused-vars
  async listResources(options = {}) {
    throw new Error(`Driver "${this.driver}" does not implement listResources()`);
  }
  /**
   * Optional health check hook.
   * @returns {Promise<{ok: boolean, details?: any}>}
   */
  async healthCheck() {
    return { ok: true };
  }
  /**
   * Graceful shutdown hook for long-lived SDK clients.
   */
  async destroy() {
    return;
  }
}

const DEFAULT_SERVICES$1 = [
  "ec2",
  "s3",
  "rds",
  "iam",
  "lambda",
  "vpc",
  "elb",
  "alb",
  "nlb",
  "dynamodb",
  "sqs",
  "sns",
  "ecs",
  "eks",
  "apigateway",
  "cloudfront",
  "route53",
  "kms",
  "secretsmanager",
  "ssm",
  "elasticache",
  "efs",
  "ecr",
  "stepfunctions",
  "eventbridge",
  "cloudwatch",
  "logs",
  "cloudtrail",
  "config",
  "acm",
  "waf",
  "wafv2",
  "cognito",
  "ebs",
  "vpn",
  "transitgateway",
  "backup",
  "kinesis"
];
const GLOBAL_REGION = "us-east-1";
function normaliseServiceName$1(name) {
  return (name || "").toString().trim().toLowerCase();
}
function buildTagObject(entries, keyKey = "Key", valueKey = "Value") {
  if (!Array.isArray(entries) || entries.length === 0) {
    return null;
  }
  const out = {};
  for (const entry of entries) {
    if (!entry || typeof entry !== "object") continue;
    const key = entry[keyKey];
    if (!key) continue;
    out[key] = entry[valueKey] ?? null;
  }
  return Object.keys(out).length ? out : null;
}
function buildCredentialProvider(credentials = {}) {
  if (!credentials || typeof credentials !== "object") {
    return fromNodeProviderChain();
  }
  if (credentials.accessKeyId && credentials.secretAccessKey) {
    const staticCredentials = {
      accessKeyId: credentials.accessKeyId,
      secretAccessKey: credentials.secretAccessKey,
      sessionToken: credentials.sessionToken
    };
    return async () => staticCredentials;
  }
  if (credentials.profile) {
    return fromIni({ profile: credentials.profile });
  }
  if (credentials.processProfile) {
    return fromProcess({ profile: credentials.processProfile });
  }
  return fromNodeProviderChain();
}
function ensureArray$1(value, fallback = []) {
  if (!value) return fallback;
  if (Array.isArray(value)) return value;
  return [value];
}
function shouldCollect$1(service, includeSet, excludeSet) {
  const name = normaliseServiceName$1(service);
  if (excludeSet.has(name)) return false;
  if (includeSet.size > 0 && !includeSet.has(name)) return false;
  return true;
}
function extractEc2Tags(instance) {
  if (!instance?.Tags) return null;
  const tags = {};
  for (const { Key, Value } of instance.Tags) {
    if (!Key) continue;
    tags[Key] = Value ?? null;
  }
  return Object.keys(tags).length ? tags : null;
}
class AwsInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "aws" });
    this._clients = {
      ec2: /* @__PURE__ */ new Map(),
      s3: null,
      rds: /* @__PURE__ */ new Map(),
      iam: null,
      lambda: /* @__PURE__ */ new Map(),
      sts: null,
      elb: /* @__PURE__ */ new Map(),
      elbv2: /* @__PURE__ */ new Map(),
      dynamodb: /* @__PURE__ */ new Map(),
      sqs: /* @__PURE__ */ new Map(),
      sns: /* @__PURE__ */ new Map(),
      ecs: /* @__PURE__ */ new Map(),
      eks: /* @__PURE__ */ new Map(),
      apigateway: /* @__PURE__ */ new Map(),
      apigatewayv2: /* @__PURE__ */ new Map(),
      cloudfront: null,
      route53: null,
      kms: /* @__PURE__ */ new Map(),
      secretsmanager: /* @__PURE__ */ new Map(),
      ssm: /* @__PURE__ */ new Map(),
      elasticache: /* @__PURE__ */ new Map(),
      efs: /* @__PURE__ */ new Map(),
      ecr: /* @__PURE__ */ new Map(),
      sfn: /* @__PURE__ */ new Map(),
      eventbridge: /* @__PURE__ */ new Map(),
      cloudwatch: /* @__PURE__ */ new Map(),
      logs: /* @__PURE__ */ new Map(),
      cloudtrail: /* @__PURE__ */ new Map(),
      config: /* @__PURE__ */ new Map(),
      acm: /* @__PURE__ */ new Map(),
      waf: null,
      wafv2: /* @__PURE__ */ new Map(),
      cognito: /* @__PURE__ */ new Map(),
      backup: /* @__PURE__ */ new Map(),
      kinesis: /* @__PURE__ */ new Map()
    };
    this._accountId = null;
    this._credentialProvider = buildCredentialProvider(this.credentials);
    this._services = ensureArray$1(this.config?.services, DEFAULT_SERVICES$1).map(normaliseServiceName$1).filter(Boolean);
    if (!this._services.length) {
      this._services = [...DEFAULT_SERVICES$1];
    }
    this._regions = ensureArray$1(this.config?.regions, [this.config?.region || GLOBAL_REGION]);
    if (!this._regions.length) {
      this._regions = [GLOBAL_REGION];
    }
  }
  async initialize() {
    await this._initializeSts();
    this.logger("info", "AWS driver initialized", {
      accountId: this._accountId,
      services: this._services,
      regions: this._regions
    });
  }
  async *_collectEc2Instances() {
    for (const region of this._regions) {
      const client = this._getEc2Client(region);
      const paginator = paginateDescribeInstances({ client }, {});
      for await (const page of paginator) {
        const reservations = page.Reservations || [];
        for (const reservation of reservations) {
          const instances = reservation.Instances || [];
          for (const instance of instances) {
            const instanceId = instance.InstanceId;
            if (!instanceId) continue;
            yield {
              provider: "aws",
              accountId: this._accountId,
              region,
              service: "ec2",
              resourceType: "ec2.instance",
              resourceId: instanceId,
              name: extractInstanceName(instance),
              tags: extractEc2Tags(instance),
              configuration: sanitizeConfiguration$1(instance)
            };
          }
        }
      }
    }
  }
  async *_collectS3Buckets() {
    const client = this._getS3Client();
    const response = await client.send(new ListBucketsCommand({}));
    const buckets = response.Buckets || [];
    for (const bucket of buckets) {
      const bucketName = bucket.Name;
      if (!bucketName) continue;
      const region = await this._resolveBucketRegion(client, bucketName);
      const tags = await this._resolveBucketTags(client, bucketName);
      yield {
        provider: "aws",
        accountId: this._accountId,
        region,
        service: "s3",
        resourceType: "s3.bucket",
        resourceId: bucketName,
        name: bucketName,
        tags,
        configuration: sanitizeConfiguration$1({
          ...bucket,
          Region: region,
          Owner: response.Owner || null
        })
      };
    }
  }
  async *_collectRdsInstances() {
    for (const region of this._regions) {
      const client = this._getRdsClient(region);
      const paginator = paginateDescribeDBInstances({ client }, {});
      for await (const page of paginator) {
        const instances = page.DBInstances || [];
        for (const instance of instances) {
          const resourceId = instance.DbiResourceId || instance.DBInstanceIdentifier;
          if (!resourceId) continue;
          const arn = instance.DBInstanceArn;
          const tags = await this._safeListTagsForResource(client, arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "rds",
            resourceType: "rds.instance",
            resourceId,
            name: instance.DBInstanceIdentifier || resourceId,
            tags,
            configuration: sanitizeConfiguration$1(instance)
          };
        }
      }
    }
  }
  async *_collectIamIdentities() {
    const client = this._getIamClient();
    const userPaginator = paginateListUsers({ client }, {});
    for await (const page of userPaginator) {
      const users = page.Users || [];
      for (const user of users) {
        const tags = await this._safeListIamTags(client, new ListUserTagsCommand({ UserName: user.UserName }));
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: null,
          service: "iam",
          resourceType: "iam.user",
          resourceId: user.Arn || user.UserId || user.UserName,
          name: user.UserName,
          tags,
          configuration: sanitizeConfiguration$1(user)
        };
      }
    }
    const rolePaginator = paginateListRoles({ client }, {});
    for await (const page of rolePaginator) {
      const roles = page.Roles || [];
      for (const role of roles) {
        const tags = await this._safeListIamTags(client, new ListRoleTagsCommand({ RoleName: role.RoleName }));
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: null,
          service: "iam",
          resourceType: "iam.role",
          resourceId: role.Arn || role.RoleId || role.RoleName,
          name: role.RoleName,
          tags,
          configuration: sanitizeConfiguration$1(role)
        };
      }
    }
  }
  async *_collectLambdaFunctions() {
    for (const region of this._regions) {
      const client = this._getLambdaClient(region);
      const paginator = paginateListFunctions({ client }, {});
      for await (const page of paginator) {
        const functions = page.Functions || [];
        for (const lambda of functions) {
          const arn = lambda.FunctionArn;
          let tags = null;
          if (arn) {
            tags = await this._safeListLambdaTags(client, arn);
          }
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "lambda",
            resourceType: "lambda.function",
            resourceId: arn || lambda.FunctionName,
            name: lambda.FunctionName,
            tags,
            configuration: sanitizeConfiguration$1(lambda)
          };
        }
      }
    }
  }
  async *_collectVpcResources() {
    for (const region of this._regions) {
      const client = this._getEc2Client(region);
      const vpcPaginator = paginateDescribeVpcs({ client }, {});
      for await (const page of vpcPaginator) {
        const vpcs = page.Vpcs || [];
        for (const vpc of vpcs) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.vpc",
            resourceId: vpc.VpcId,
            name: extractEc2Tags(vpc)?.Name || vpc.VpcId,
            tags: extractEc2Tags(vpc),
            configuration: sanitizeConfiguration$1(vpc)
          };
        }
      }
      const subnetPaginator = paginateDescribeSubnets({ client }, {});
      for await (const page of subnetPaginator) {
        const subnets = page.Subnets || [];
        for (const subnet of subnets) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.subnet",
            resourceId: subnet.SubnetId,
            name: extractEc2Tags(subnet)?.Name || subnet.SubnetId,
            tags: extractEc2Tags(subnet),
            configuration: sanitizeConfiguration$1(subnet)
          };
        }
      }
      const sgPaginator = paginateDescribeSecurityGroups({ client }, {});
      for await (const page of sgPaginator) {
        const groups = page.SecurityGroups || [];
        for (const sg of groups) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.security-group",
            resourceId: sg.GroupId,
            name: sg.GroupName,
            tags: extractEc2Tags(sg),
            configuration: sanitizeConfiguration$1(sg)
          };
        }
      }
      const rtPaginator = paginateDescribeRouteTables({ client }, {});
      for await (const page of rtPaginator) {
        const tables = page.RouteTables || [];
        for (const rt of tables) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.route-table",
            resourceId: rt.RouteTableId,
            name: extractEc2Tags(rt)?.Name || rt.RouteTableId,
            tags: extractEc2Tags(rt),
            configuration: sanitizeConfiguration$1(rt)
          };
        }
      }
      const igwPaginator = paginateDescribeInternetGateways({ client }, {});
      for await (const page of igwPaginator) {
        const gateways = page.InternetGateways || [];
        for (const igw of gateways) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.internet-gateway",
            resourceId: igw.InternetGatewayId,
            name: extractEc2Tags(igw)?.Name || igw.InternetGatewayId,
            tags: extractEc2Tags(igw),
            configuration: sanitizeConfiguration$1(igw)
          };
        }
      }
      const natPaginator = paginateDescribeNatGateways({ client }, {});
      for await (const page of natPaginator) {
        const gateways = page.NatGateways || [];
        for (const nat of gateways) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.nat-gateway",
            resourceId: nat.NatGatewayId,
            name: extractEc2Tags(nat)?.Name || nat.NatGatewayId,
            tags: extractEc2Tags(nat),
            configuration: sanitizeConfiguration$1(nat)
          };
        }
      }
      const aclPaginator = paginateDescribeNetworkAcls({ client }, {});
      for await (const page of aclPaginator) {
        const acls = page.NetworkAcls || [];
        for (const acl of acls) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "vpc.network-acl",
            resourceId: acl.NetworkAclId,
            name: extractEc2Tags(acl)?.Name || acl.NetworkAclId,
            tags: extractEc2Tags(acl),
            configuration: sanitizeConfiguration$1(acl)
          };
        }
      }
    }
  }
  async *_collectLoadBalancers() {
    for (const region of this._regions) {
      const elbClient = this._getElbClient(region);
      const classicPaginator = paginateDescribeLoadBalancers({ client: elbClient }, {});
      for await (const page of classicPaginator) {
        const lbs = page.LoadBalancerDescriptions || [];
        for (const lb of lbs) {
          const tags = await this._safeListClassicLBTags(elbClient, lb.LoadBalancerName);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "elb",
            resourceType: "elb.classic",
            resourceId: lb.LoadBalancerName,
            name: lb.LoadBalancerName,
            tags,
            configuration: sanitizeConfiguration$1(lb)
          };
        }
      }
      const elbv2Client = this._getElbv2Client(region);
      const v2Paginator = paginateDescribeLoadBalancers$1({ client: elbv2Client }, {});
      for await (const page of v2Paginator) {
        const lbs = page.LoadBalancers || [];
        for (const lb of lbs) {
          const arn = lb.LoadBalancerArn;
          const tags = await this._safeListELBv2Tags(elbv2Client, [arn]);
          const lbType = lb.Type === "application" ? "alb" : lb.Type === "network" ? "nlb" : "elb";
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: lbType,
            resourceType: `${lbType}.load-balancer`,
            resourceId: arn,
            name: lb.LoadBalancerName,
            tags,
            configuration: sanitizeConfiguration$1(lb)
          };
        }
      }
      const tgPaginator = paginateDescribeTargetGroups({ client: elbv2Client }, {});
      for await (const page of tgPaginator) {
        const groups = page.TargetGroups || [];
        for (const tg of groups) {
          const arn = tg.TargetGroupArn;
          const tags = await this._safeListELBv2Tags(elbv2Client, [arn]);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "elb",
            resourceType: "elb.target-group",
            resourceId: arn,
            name: tg.TargetGroupName,
            tags,
            configuration: sanitizeConfiguration$1(tg)
          };
        }
      }
    }
  }
  async *_collectDynamoDBTables() {
    for (const region of this._regions) {
      const client = this._getDynamoDBClient(region);
      const paginator = paginateListTables({ client }, {});
      for await (const page of paginator) {
        const tables = page.TableNames || [];
        for (const tableName of tables) {
          const description = await client.send(new DescribeTableCommand({ TableName: tableName }));
          const table = description.Table;
          const arn = table?.TableArn;
          let tags = null;
          if (arn) {
            tags = await this._safeListDynamoDBTags(client, arn);
          }
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "dynamodb",
            resourceType: "dynamodb.table",
            resourceId: arn || tableName,
            name: tableName,
            tags,
            configuration: sanitizeConfiguration$1(table)
          };
        }
      }
    }
  }
  async *_collectSQSQueues() {
    for (const region of this._regions) {
      const client = this._getSqsClient(region);
      const paginator = paginateListQueues({ client }, {});
      for await (const page of paginator) {
        const urls = page.QueueUrls || [];
        for (const queueUrl of urls) {
          const attributes = await this._safeGetQueueAttributes(client, queueUrl);
          const tags = await this._safeListQueueTags(client, queueUrl);
          const queueName = queueUrl.split("/").pop();
          const arn = attributes?.QueueArn;
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "sqs",
            resourceType: "sqs.queue",
            resourceId: arn || queueUrl,
            name: queueName,
            tags,
            configuration: sanitizeConfiguration$1({ ...attributes, QueueUrl: queueUrl })
          };
        }
      }
    }
  }
  async *_collectSNSTopics() {
    for (const region of this._regions) {
      const client = this._getSnsClient(region);
      const paginator = paginateListTopics({ client }, {});
      for await (const page of paginator) {
        const topics = page.Topics || [];
        for (const topic of topics) {
          const arn = topic.TopicArn;
          const attributes = await this._safeGetTopicAttributes(client, arn);
          const tags = await this._safeListSNSTags(client, arn);
          const topicName = arn?.split(":").pop();
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "sns",
            resourceType: "sns.topic",
            resourceId: arn,
            name: topicName,
            tags,
            configuration: sanitizeConfiguration$1({ ...attributes, TopicArn: arn })
          };
        }
      }
    }
  }
  async *_collectECSResources() {
    for (const region of this._regions) {
      const client = this._getEcsClient(region);
      const clusterPaginator = paginateListClusters({ client }, {});
      for await (const page of clusterPaginator) {
        const arns = page.clusterArns || [];
        for (const arn of arns) {
          const tags = await this._safeListECSTags(client, arn);
          const name = arn.split("/").pop();
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ecs",
            resourceType: "ecs.cluster",
            resourceId: arn,
            name,
            tags,
            configuration: sanitizeConfiguration$1({ clusterArn: arn })
          };
          const servicePaginator = paginateListServices({ client }, { cluster: arn });
          for await (const servicePage of servicePaginator) {
            const serviceArns = servicePage.serviceArns || [];
            if (serviceArns.length === 0) continue;
            const described = await client.send(new DescribeServicesCommand({
              cluster: arn,
              services: serviceArns,
              include: ["TAGS"]
            }));
            const services = described.services || [];
            for (const service of services) {
              yield {
                provider: "aws",
                accountId: this._accountId,
                region,
                service: "ecs",
                resourceType: "ecs.service",
                resourceId: service.serviceArn,
                name: service.serviceName,
                tags: buildTagObject(service.tags),
                configuration: sanitizeConfiguration$1(service)
              };
            }
          }
        }
      }
      const taskDefPaginator = paginateListTaskDefinitions({ client }, {});
      for await (const page of taskDefPaginator) {
        const arns = page.taskDefinitionArns || [];
        for (const arn of arns) {
          const described = await client.send(new DescribeTaskDefinitionCommand({
            taskDefinition: arn,
            include: ["TAGS"]
          }));
          const taskDef = described.taskDefinition;
          const tags = buildTagObject(described.tags);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ecs",
            resourceType: "ecs.task-definition",
            resourceId: taskDef?.taskDefinitionArn || arn,
            name: taskDef?.family,
            tags,
            configuration: sanitizeConfiguration$1(taskDef)
          };
        }
      }
    }
  }
  async *_collectEKSClusters() {
    for (const region of this._regions) {
      const client = this._getEksClient(region);
      const clusterPaginator = paginateListClusters$1({ client }, {});
      for await (const page of clusterPaginator) {
        const names = page.clusters || [];
        for (const name of names) {
          const described = await client.send(new DescribeClusterCommand({ name }));
          const cluster = described.cluster;
          const arn = cluster?.arn;
          const tags = await this._safeListEKSTags(client, arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "eks",
            resourceType: "eks.cluster",
            resourceId: arn || name,
            name,
            tags,
            configuration: sanitizeConfiguration$1(cluster)
          };
          const ngPaginator = paginateListNodegroups({ client }, { clusterName: name });
          for await (const ngPage of ngPaginator) {
            const nodegroups = ngPage.nodegroups || [];
            for (const ngName of nodegroups) {
              const ngDescribed = await client.send(new DescribeNodegroupCommand({
                clusterName: name,
                nodegroupName: ngName
              }));
              const ng = ngDescribed.nodegroup;
              const ngArn = ng?.nodegroupArn;
              const ngTags = await this._safeListEKSTags(client, ngArn);
              yield {
                provider: "aws",
                accountId: this._accountId,
                region,
                service: "eks",
                resourceType: "eks.nodegroup",
                resourceId: ngArn || ngName,
                name: ngName,
                tags: ngTags,
                configuration: sanitizeConfiguration$1(ng)
              };
            }
          }
        }
      }
    }
  }
  async *_collectAPIGateways() {
    for (const region of this._regions) {
      const v1Client = this._getApiGatewayClient(region);
      const v1Paginator = paginateGetRestApis({ client: v1Client }, {});
      for await (const page of v1Paginator) {
        const apis = page.items || [];
        for (const api of apis) {
          const tags = await this._safeGetAPIGatewayTags(v1Client, api.id);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "apigateway",
            resourceType: "apigateway.rest-api",
            resourceId: api.id,
            name: api.name,
            tags,
            configuration: sanitizeConfiguration$1(api)
          };
        }
      }
      const v2Client = this._getApiGatewayV2Client(region);
      let nextToken;
      do {
        const response = await v2Client.send(new GetApisCommand({ NextToken: nextToken }));
        const apis = response.Items || [];
        nextToken = response.NextToken;
        for (const api of apis) {
          const tags = await this._safeGetAPIGatewayV2Tags(v2Client, api.ApiId);
          const type = api.ProtocolType?.toLowerCase() || "http";
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "apigateway",
            resourceType: `apigateway.${type}-api`,
            resourceId: api.ApiId,
            name: api.Name,
            tags,
            configuration: sanitizeConfiguration$1(api)
          };
        }
      } while (nextToken);
    }
  }
  async *_collectCloudFrontDistributions() {
    const client = this._getCloudFrontClient();
    const paginator = paginateListDistributions({ client }, {});
    for await (const page of paginator) {
      const items = page.DistributionList?.Items || [];
      for (const dist of items) {
        const arn = dist.ARN;
        const tags = await this._safeListCloudFrontTags(client, arn);
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: null,
          service: "cloudfront",
          resourceType: "cloudfront.distribution",
          resourceId: dist.Id,
          name: dist.DomainName,
          tags,
          configuration: sanitizeConfiguration$1(dist)
        };
      }
    }
  }
  async *_collectRoute53HostedZones() {
    const client = this._getRoute53Client();
    const paginator = paginateListHostedZones({ client }, {});
    for await (const page of paginator) {
      const zones = page.HostedZones || [];
      for (const zone of zones) {
        const zoneId = zone.Id?.replace("/hostedzone/", "");
        const tags = await this._safeListRoute53Tags(client, zone.Id);
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: null,
          service: "route53",
          resourceType: "route53.hosted-zone",
          resourceId: zoneId,
          name: zone.Name,
          tags,
          configuration: sanitizeConfiguration$1(zone)
        };
      }
    }
  }
  async *_collectKMSKeys() {
    for (const region of this._regions) {
      const client = this._getKmsClient(region);
      const paginator = paginateListKeys({ client }, {});
      for await (const page of paginator) {
        const keys = page.Keys || [];
        for (const key of keys) {
          const described = await client.send(new DescribeKeyCommand({ KeyId: key.KeyId }));
          const metadata = described.KeyMetadata;
          const tags = await this._safeListKMSTags(client, key.KeyId);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "kms",
            resourceType: "kms.key",
            resourceId: metadata?.Arn || key.KeyId,
            name: metadata?.Description || key.KeyId,
            tags,
            configuration: sanitizeConfiguration$1(metadata)
          };
        }
      }
    }
  }
  async *_collectSecretsManagerSecrets() {
    for (const region of this._regions) {
      const client = this._getSecretsManagerClient(region);
      const paginator = paginateListSecrets({ client }, {});
      for await (const page of paginator) {
        const secrets = page.SecretList || [];
        for (const secret of secrets) {
          const described = await client.send(new DescribeSecretCommand({ SecretId: secret.ARN }));
          const tags = buildTagObject(described.Tags);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "secretsmanager",
            resourceType: "secretsmanager.secret",
            resourceId: described.ARN || secret.ARN,
            name: described.Name || secret.Name,
            tags,
            configuration: sanitizeConfiguration$1(described)
          };
        }
      }
    }
  }
  async *_collectSSMParameters() {
    for (const region of this._regions) {
      const client = this._getSsmClient(region);
      const paginator = paginateDescribeParameters({ client }, {});
      for await (const page of paginator) {
        const params = page.Parameters || [];
        for (const param of params) {
          const tags = await this._safeListSSMTags(client, param.Name);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ssm",
            resourceType: "ssm.parameter",
            resourceId: param.Name,
            name: param.Name,
            tags,
            configuration: sanitizeConfiguration$1(param)
          };
        }
      }
    }
  }
  async *_collectElastiCacheClusters() {
    for (const region of this._regions) {
      const client = this._getElastiCacheClient(region);
      const paginator = paginateDescribeCacheClusters({ client }, { ShowCacheNodeInfo: true });
      for await (const page of paginator) {
        const clusters = page.CacheClusters || [];
        for (const cluster of clusters) {
          const arn = cluster.ARN;
          const tags = await this._safeListElastiCacheTags(client, arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "elasticache",
            resourceType: "elasticache.cluster",
            resourceId: arn || cluster.CacheClusterId,
            name: cluster.CacheClusterId,
            tags,
            configuration: sanitizeConfiguration$1(cluster)
          };
        }
      }
    }
  }
  async *_collectEFSFileSystems() {
    for (const region of this._regions) {
      const client = this._getEfsClient(region);
      const paginator = paginateDescribeFileSystems({ client }, {});
      for await (const page of paginator) {
        const filesystems = page.FileSystems || [];
        for (const fs of filesystems) {
          const tags = await this._safeDescribeEFSTags(client, fs.FileSystemId);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "efs",
            resourceType: "efs.filesystem",
            resourceId: fs.FileSystemArn || fs.FileSystemId,
            name: fs.Name || fs.FileSystemId,
            tags,
            configuration: sanitizeConfiguration$1(fs)
          };
        }
      }
    }
  }
  async *_collectECRRepositories() {
    for (const region of this._regions) {
      const client = this._getEcrClient(region);
      const paginator = paginateDescribeRepositories({ client }, {});
      for await (const page of paginator) {
        const repos = page.repositories || [];
        for (const repo of repos) {
          const tags = await this._safeListECRTags(client, repo.repositoryArn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ecr",
            resourceType: "ecr.repository",
            resourceId: repo.repositoryArn,
            name: repo.repositoryName,
            tags,
            configuration: sanitizeConfiguration$1(repo)
          };
        }
      }
    }
  }
  async *_collectStepFunctionsStateMachines() {
    for (const region of this._regions) {
      const client = this._getSfnClient(region);
      const paginator = paginateListStateMachines({ client }, {});
      for await (const page of paginator) {
        const machines = page.stateMachines || [];
        for (const machine of machines) {
          const tags = await this._safeListSFNTags(client, machine.stateMachineArn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "stepfunctions",
            resourceType: "stepfunctions.statemachine",
            resourceId: machine.stateMachineArn,
            name: machine.name,
            tags,
            configuration: sanitizeConfiguration$1(machine)
          };
        }
      }
    }
  }
  async *_collectEventBridgeResources() {
    for (const region of this._regions) {
      const client = this._getEventBridgeClient(region);
      const busPaginator = paginateListEventBuses({ client }, {});
      for await (const page of busPaginator) {
        const buses = page.EventBuses || [];
        for (const bus of buses) {
          const tags = await this._safeListEventBridgeTags(client, bus.Arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "eventbridge",
            resourceType: "eventbridge.bus",
            resourceId: bus.Arn || bus.Name,
            name: bus.Name,
            tags,
            configuration: sanitizeConfiguration$1(bus)
          };
        }
      }
      const rulePaginator = paginateListRules({ client }, {});
      for await (const page of rulePaginator) {
        const rules = page.Rules || [];
        for (const rule of rules) {
          const tags = await this._safeListEventBridgeTags(client, rule.Arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "eventbridge",
            resourceType: "eventbridge.rule",
            resourceId: rule.Arn || rule.Name,
            name: rule.Name,
            tags,
            configuration: sanitizeConfiguration$1(rule)
          };
        }
      }
    }
  }
  async *_collectCloudWatchResources() {
    for (const region of this._regions) {
      const cwClient = this._getCloudWatchClient(region);
      const alarmPaginator = paginateDescribeAlarms({ client: cwClient }, {});
      for await (const page of alarmPaginator) {
        const alarms = page.MetricAlarms || [];
        for (const alarm of alarms) {
          const tags = await this._safeListCloudWatchTags(cwClient, alarm.AlarmArn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "cloudwatch",
            resourceType: "cloudwatch.alarm",
            resourceId: alarm.AlarmArn || alarm.AlarmName,
            name: alarm.AlarmName,
            tags,
            configuration: sanitizeConfiguration$1(alarm)
          };
        }
      }
      const logsClient = this._getCloudWatchLogsClient(region);
      const logsPaginator = paginateDescribeLogGroups({ client: logsClient }, {});
      for await (const page of logsPaginator) {
        const groups = page.logGroups || [];
        for (const group of groups) {
          const tags = await this._safeListCWLogsTags(logsClient, group.logGroupName);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "logs",
            resourceType: "logs.group",
            resourceId: group.arn || group.logGroupName,
            name: group.logGroupName,
            tags,
            configuration: sanitizeConfiguration$1(group)
          };
        }
      }
    }
  }
  async *_collectCloudTrails() {
    for (const region of this._regions) {
      const client = this._getCloudTrailClient(region);
      const paginator = paginateListTrails({ client }, {});
      for await (const page of paginator) {
        const trails = page.Trails || [];
        for (const trailInfo of trails) {
          const described = await client.send(new GetTrailCommand({ Name: trailInfo.TrailARN || trailInfo.Name }));
          const trail = described.Trail;
          const tags = await this._safeListCloudTrailTags(client, trail?.TrailARN);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "cloudtrail",
            resourceType: "cloudtrail.trail",
            resourceId: trail?.TrailARN || trail?.Name,
            name: trail?.Name,
            tags,
            configuration: sanitizeConfiguration$1(trail)
          };
        }
      }
    }
  }
  async *_collectConfigResources() {
    for (const region of this._regions) {
      const client = this._getConfigServiceClient(region);
      const recorderResponse = await client.send(new DescribeConfigurationRecordersCommand({}));
      const recorders = recorderResponse.ConfigurationRecorders || [];
      for (const recorder of recorders) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "config",
          resourceType: "config.recorder",
          resourceId: recorder.name,
          name: recorder.name,
          tags: null,
          configuration: sanitizeConfiguration$1(recorder)
        };
      }
      const channelResponse = await client.send(new DescribeDeliveryChannelsCommand({}));
      const channels = channelResponse.DeliveryChannels || [];
      for (const channel of channels) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "config",
          resourceType: "config.delivery-channel",
          resourceId: channel.name,
          name: channel.name,
          tags: null,
          configuration: sanitizeConfiguration$1(channel)
        };
      }
    }
  }
  async *_collectACMCertificates() {
    for (const region of this._regions) {
      const client = this._getAcmClient(region);
      const paginator = paginateListCertificates({ client }, {});
      for await (const page of paginator) {
        const certs = page.CertificateSummaryList || [];
        for (const certSummary of certs) {
          const arn = certSummary.CertificateArn;
          const described = await client.send(new DescribeCertificateCommand({ CertificateArn: arn }));
          const cert = described.Certificate;
          const tags = await this._safeListACMTags(client, arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "acm",
            resourceType: "acm.certificate",
            resourceId: arn,
            name: cert?.DomainName,
            tags,
            configuration: sanitizeConfiguration$1(cert)
          };
        }
      }
    }
  }
  async *_collectWAFResources() {
    const wafClient = this._getWafClient();
    const classicPaginator = paginateListWebACLs({ client: wafClient }, {});
    for await (const page of classicPaginator) {
      const webACLs = page.WebACLs || [];
      for (const acl of webACLs) {
        const tags = await this._safeListWAFTags(wafClient, acl.WebACLId);
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: null,
          service: "waf",
          resourceType: "waf.webacl",
          resourceId: acl.WebACLId,
          name: acl.Name,
          tags,
          configuration: sanitizeConfiguration$1(acl)
        };
      }
    }
  }
  async *_collectWAFV2Resources() {
    for (const region of this._regions) {
      const client = this._getWafv2Client(region);
      const regionalPaginator = paginateListWebACLs$1({ client }, { Scope: "REGIONAL" });
      for await (const page of regionalPaginator) {
        const webACLs = page.WebACLs || [];
        for (const acl of webACLs) {
          const tags = await this._safeListWAFV2Tags(client, acl.ARN);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "wafv2",
            resourceType: "wafv2.webacl",
            resourceId: acl.ARN,
            name: acl.Name,
            tags,
            configuration: sanitizeConfiguration$1(acl)
          };
        }
      }
    }
    const cfClient = this._getWafv2Client(GLOBAL_REGION);
    const cfPaginator = paginateListWebACLs$1({ client: cfClient }, { Scope: "CLOUDFRONT" });
    for await (const page of cfPaginator) {
      const webACLs = page.WebACLs || [];
      for (const acl of webACLs) {
        const tags = await this._safeListWAFV2Tags(cfClient, acl.ARN);
        yield {
          provider: "aws",
          accountId: this._accountId,
          region: GLOBAL_REGION,
          service: "wafv2",
          resourceType: "wafv2.webacl-cloudfront",
          resourceId: acl.ARN,
          name: acl.Name,
          tags,
          configuration: sanitizeConfiguration$1(acl)
        };
      }
    }
  }
  async *_collectCognitoUserPools() {
    for (const region of this._regions) {
      const client = this._getCognitoClient(region);
      const paginator = paginateListUserPools({ client }, { MaxResults: 60 });
      for await (const page of paginator) {
        const pools = page.UserPools || [];
        for (const pool of pools) {
          const described = await client.send(new DescribeUserPoolCommand({ UserPoolId: pool.Id }));
          const fullPool = described.UserPool;
          const tags = await this._safeListCognitoTags(client, fullPool?.Arn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "cognito",
            resourceType: "cognito.userpool",
            resourceId: fullPool?.Arn || pool.Id,
            name: pool.Name,
            tags,
            configuration: sanitizeConfiguration$1(fullPool)
          };
        }
      }
    }
  }
  async *_collectEBSResources() {
    for (const region of this._regions) {
      const client = this._getEc2Client(region);
      const volPaginator = paginateDescribeVolumes({ client }, {});
      for await (const page of volPaginator) {
        const volumes = page.Volumes || [];
        for (const volume of volumes) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ebs",
            resourceType: "ebs.volume",
            resourceId: volume.VolumeId,
            name: extractEc2Tags(volume)?.Name || volume.VolumeId,
            tags: extractEc2Tags(volume),
            configuration: sanitizeConfiguration$1(volume)
          };
        }
      }
      const snapPaginator = paginateDescribeSnapshots({ client }, { OwnerIds: ["self"] });
      for await (const page of snapPaginator) {
        const snapshots = page.Snapshots || [];
        for (const snapshot of snapshots) {
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "ebs",
            resourceType: "ebs.snapshot",
            resourceId: snapshot.SnapshotId,
            name: extractEc2Tags(snapshot)?.Name || snapshot.SnapshotId,
            tags: extractEc2Tags(snapshot),
            configuration: sanitizeConfiguration$1(snapshot)
          };
        }
      }
    }
  }
  async *_collectVPNResources() {
    for (const region of this._regions) {
      const client = this._getEc2Client(region);
      const vpnResult = await client.send(new DescribeVpnConnectionsCommand({}));
      const connections = vpnResult.VpnConnections || [];
      for (const vpn of connections) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "vpn",
          resourceType: "vpn.connection",
          resourceId: vpn.VpnConnectionId,
          name: extractEc2Tags(vpn)?.Name || vpn.VpnConnectionId,
          tags: extractEc2Tags(vpn),
          configuration: sanitizeConfiguration$1(vpn)
        };
      }
      const cgwResult = await client.send(new DescribeCustomerGatewaysCommand({}));
      const gateways = cgwResult.CustomerGateways || [];
      for (const cgw of gateways) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "vpn",
          resourceType: "vpn.customer-gateway",
          resourceId: cgw.CustomerGatewayId,
          name: extractEc2Tags(cgw)?.Name || cgw.CustomerGatewayId,
          tags: extractEc2Tags(cgw),
          configuration: sanitizeConfiguration$1(cgw)
        };
      }
    }
  }
  async *_collectTransitGatewayResources() {
    for (const region of this._regions) {
      const client = this._getEc2Client(region);
      const tgwResult = await client.send(new DescribeTransitGatewaysCommand({}));
      const gateways = tgwResult.TransitGateways || [];
      for (const tgw of gateways) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "transitgateway",
          resourceType: "transitgateway.gateway",
          resourceId: tgw.TransitGatewayId,
          name: extractEc2Tags(tgw)?.Name || tgw.TransitGatewayId,
          tags: extractEc2Tags(tgw),
          configuration: sanitizeConfiguration$1(tgw)
        };
      }
      const attResult = await client.send(new DescribeTransitGatewayAttachmentsCommand({}));
      const attachments = attResult.TransitGatewayAttachments || [];
      for (const att of attachments) {
        yield {
          provider: "aws",
          accountId: this._accountId,
          region,
          service: "transitgateway",
          resourceType: "transitgateway.attachment",
          resourceId: att.TransitGatewayAttachmentId,
          name: extractEc2Tags(att)?.Name || att.TransitGatewayAttachmentId,
          tags: extractEc2Tags(att),
          configuration: sanitizeConfiguration$1(att)
        };
      }
    }
  }
  async *_collectBackupResources() {
    for (const region of this._regions) {
      const client = this._getBackupClient(region);
      const planPaginator = paginateListBackupPlans({ client }, {});
      for await (const page of planPaginator) {
        const plans = page.BackupPlansList || [];
        for (const plan of plans) {
          const tags = await this._safeListBackupTags(client, plan.BackupPlanArn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "backup",
            resourceType: "backup.plan",
            resourceId: plan.BackupPlanArn,
            name: plan.BackupPlanName,
            tags,
            configuration: sanitizeConfiguration$1(plan)
          };
        }
      }
      const vaultPaginator = paginateListBackupVaults({ client }, {});
      for await (const page of vaultPaginator) {
        const vaults = page.BackupVaultList || [];
        for (const vault of vaults) {
          const tags = await this._safeListBackupTags(client, vault.BackupVaultArn);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "backup",
            resourceType: "backup.vault",
            resourceId: vault.BackupVaultArn,
            name: vault.BackupVaultName,
            tags,
            configuration: sanitizeConfiguration$1(vault)
          };
        }
      }
    }
  }
  async *_collectKinesisStreams() {
    for (const region of this._regions) {
      const client = this._getKinesisClient(region);
      const paginator = paginateListStreams({ client }, {});
      for await (const page of paginator) {
        const streamNames = page.StreamNames || [];
        for (const streamName of streamNames) {
          const described = await client.send(new DescribeStreamCommand({ StreamName: streamName }));
          const stream = described.StreamDescription;
          const arn = stream?.StreamARN;
          const tags = await this._safeListKinesisTags(client, streamName);
          yield {
            provider: "aws",
            accountId: this._accountId,
            region,
            service: "kinesis",
            resourceType: "kinesis.stream",
            resourceId: arn || streamName,
            name: streamName,
            tags,
            configuration: sanitizeConfiguration$1(stream)
          };
        }
      }
    }
  }
  async *listResources(options = {}) {
    const discoveryInclude = ensureArray$1(options.discovery?.include).map(normaliseServiceName$1).filter(Boolean);
    const discoveryExclude = ensureArray$1(options.discovery?.exclude).map(normaliseServiceName$1).filter(Boolean);
    const includeSet = new Set(discoveryInclude);
    const excludeSet = new Set(discoveryExclude);
    const runtime = options.runtime || {};
    const emitProgress = typeof runtime.emitProgress === "function" ? runtime.emitProgress.bind(runtime) : null;
    const collectors = {
      ec2: this._collectEc2Instances.bind(this),
      s3: this._collectS3Buckets.bind(this),
      rds: this._collectRdsInstances.bind(this),
      iam: this._collectIamIdentities.bind(this),
      lambda: this._collectLambdaFunctions.bind(this),
      vpc: this._collectVpcResources.bind(this),
      elb: this._collectLoadBalancers.bind(this),
      alb: this._collectLoadBalancers.bind(this),
      nlb: this._collectLoadBalancers.bind(this),
      dynamodb: this._collectDynamoDBTables.bind(this),
      sqs: this._collectSQSQueues.bind(this),
      sns: this._collectSNSTopics.bind(this),
      ecs: this._collectECSResources.bind(this),
      eks: this._collectEKSClusters.bind(this),
      apigateway: this._collectAPIGateways.bind(this),
      cloudfront: this._collectCloudFrontDistributions.bind(this),
      route53: this._collectRoute53HostedZones.bind(this),
      kms: this._collectKMSKeys.bind(this),
      secretsmanager: this._collectSecretsManagerSecrets.bind(this),
      ssm: this._collectSSMParameters.bind(this),
      elasticache: this._collectElastiCacheClusters.bind(this),
      efs: this._collectEFSFileSystems.bind(this),
      ecr: this._collectECRRepositories.bind(this),
      stepfunctions: this._collectStepFunctionsStateMachines.bind(this),
      eventbridge: this._collectEventBridgeResources.bind(this),
      cloudwatch: this._collectCloudWatchResources.bind(this),
      logs: this._collectCloudWatchResources.bind(this),
      cloudtrail: this._collectCloudTrails.bind(this),
      config: this._collectConfigResources.bind(this),
      acm: this._collectACMCertificates.bind(this),
      waf: this._collectWAFResources.bind(this),
      wafv2: this._collectWAFV2Resources.bind(this),
      cognito: this._collectCognitoUserPools.bind(this),
      ebs: this._collectEBSResources.bind(this),
      vpn: this._collectVPNResources.bind(this),
      transitgateway: this._collectTransitGatewayResources.bind(this),
      backup: this._collectBackupResources.bind(this),
      kinesis: this._collectKinesisStreams.bind(this)
    };
    for (const service of this._services) {
      if (!collectors[service]) {
        this.logger("debug", "AWS service collector not implemented, skipping", { service });
        continue;
      }
      if (!shouldCollect$1(service, includeSet, excludeSet)) {
        this.logger("debug", "AWS service filtered out", { service });
        continue;
      }
      try {
        for await (const resource of collectors[service]()) {
          if (emitProgress) {
            emitProgress({
              service,
              resourceId: resource.resourceId,
              resourceType: resource.resourceType
            });
          }
          yield resource;
        }
      } catch (err) {
        this.logger("error", "AWS service collection failed, skipping to next service", {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  async _initializeSts() {
    if (this._accountId) return;
    const client = this._getStsClient();
    const response = await client.send(new GetCallerIdentityCommand({}));
    this._accountId = response.Account || null;
  }
  _getStsClient() {
    if (!this._clients.sts) {
      this._clients.sts = new STSClient({
        region: this.config?.region || GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.sts;
  }
  _getEc2Client(region) {
    if (!this._clients.ec2.has(region)) {
      this._clients.ec2.set(region, new EC2Client({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.ec2.get(region);
  }
  _getS3Client() {
    if (!this._clients.s3) {
      this._clients.s3 = new S3Client$1({
        region: this.config?.s3Region || GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.s3;
  }
  _getRdsClient(region) {
    if (!this._clients.rds.has(region)) {
      this._clients.rds.set(region, new RDSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.rds.get(region);
  }
  _getIamClient() {
    if (!this._clients.iam) {
      this._clients.iam = new IAMClient({
        region: this.config?.iamRegion || GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.iam;
  }
  _getLambdaClient(region) {
    if (!this._clients.lambda.has(region)) {
      this._clients.lambda.set(region, new LambdaClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.lambda.get(region);
  }
  _getElbClient(region) {
    if (!this._clients.elb.has(region)) {
      this._clients.elb.set(region, new ElasticLoadBalancingClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.elb.get(region);
  }
  _getElbv2Client(region) {
    if (!this._clients.elbv2.has(region)) {
      this._clients.elbv2.set(region, new ElasticLoadBalancingV2Client({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.elbv2.get(region);
  }
  _getDynamoDBClient(region) {
    if (!this._clients.dynamodb.has(region)) {
      this._clients.dynamodb.set(region, new DynamoDBClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.dynamodb.get(region);
  }
  _getSqsClient(region) {
    if (!this._clients.sqs.has(region)) {
      this._clients.sqs.set(region, new SQSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.sqs.get(region);
  }
  _getSnsClient(region) {
    if (!this._clients.sns.has(region)) {
      this._clients.sns.set(region, new SNSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.sns.get(region);
  }
  _getEcsClient(region) {
    if (!this._clients.ecs.has(region)) {
      this._clients.ecs.set(region, new ECSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.ecs.get(region);
  }
  _getEksClient(region) {
    if (!this._clients.eks.has(region)) {
      this._clients.eks.set(region, new EKSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.eks.get(region);
  }
  _getApiGatewayClient(region) {
    if (!this._clients.apigateway.has(region)) {
      this._clients.apigateway.set(region, new APIGatewayClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.apigateway.get(region);
  }
  _getApiGatewayV2Client(region) {
    if (!this._clients.apigatewayv2.has(region)) {
      this._clients.apigatewayv2.set(region, new ApiGatewayV2Client({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.apigatewayv2.get(region);
  }
  _getCloudFrontClient() {
    if (!this._clients.cloudfront) {
      this._clients.cloudfront = new CloudFrontClient({
        region: GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.cloudfront;
  }
  _getRoute53Client() {
    if (!this._clients.route53) {
      this._clients.route53 = new Route53Client({
        region: GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.route53;
  }
  _getKmsClient(region) {
    if (!this._clients.kms.has(region)) {
      this._clients.kms.set(region, new KMSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.kms.get(region);
  }
  _getSecretsManagerClient(region) {
    if (!this._clients.secretsmanager.has(region)) {
      this._clients.secretsmanager.set(region, new SecretsManagerClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.secretsmanager.get(region);
  }
  _getSsmClient(region) {
    if (!this._clients.ssm.has(region)) {
      this._clients.ssm.set(region, new SSMClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.ssm.get(region);
  }
  _getElastiCacheClient(region) {
    if (!this._clients.elasticache.has(region)) {
      this._clients.elasticache.set(region, new ElastiCacheClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.elasticache.get(region);
  }
  _getEfsClient(region) {
    if (!this._clients.efs.has(region)) {
      this._clients.efs.set(region, new EFSClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.efs.get(region);
  }
  _getEcrClient(region) {
    if (!this._clients.ecr.has(region)) {
      this._clients.ecr.set(region, new ECRClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.ecr.get(region);
  }
  _getSfnClient(region) {
    if (!this._clients.sfn.has(region)) {
      this._clients.sfn.set(region, new SFNClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.sfn.get(region);
  }
  _getEventBridgeClient(region) {
    if (!this._clients.eventbridge.has(region)) {
      this._clients.eventbridge.set(region, new EventBridgeClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.eventbridge.get(region);
  }
  _getCloudWatchClient(region) {
    if (!this._clients.cloudwatch.has(region)) {
      this._clients.cloudwatch.set(region, new CloudWatchClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.cloudwatch.get(region);
  }
  _getCloudWatchLogsClient(region) {
    if (!this._clients.logs.has(region)) {
      this._clients.logs.set(region, new CloudWatchLogsClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.logs.get(region);
  }
  _getCloudTrailClient(region) {
    if (!this._clients.cloudtrail.has(region)) {
      this._clients.cloudtrail.set(region, new CloudTrailClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.cloudtrail.get(region);
  }
  _getConfigServiceClient(region) {
    if (!this._clients.config.has(region)) {
      this._clients.config.set(region, new ConfigServiceClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.config.get(region);
  }
  _getAcmClient(region) {
    if (!this._clients.acm.has(region)) {
      this._clients.acm.set(region, new ACMClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.acm.get(region);
  }
  _getWafClient() {
    if (!this._clients.waf) {
      this._clients.waf = new WAFClient({
        region: GLOBAL_REGION,
        credentials: this._credentialProvider
      });
    }
    return this._clients.waf;
  }
  _getWafv2Client(region) {
    if (!this._clients.wafv2.has(region)) {
      this._clients.wafv2.set(region, new WAFV2Client({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.wafv2.get(region);
  }
  _getCognitoClient(region) {
    if (!this._clients.cognito.has(region)) {
      this._clients.cognito.set(region, new CognitoIdentityProviderClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.cognito.get(region);
  }
  _getBackupClient(region) {
    if (!this._clients.backup.has(region)) {
      this._clients.backup.set(region, new BackupClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.backup.get(region);
  }
  _getKinesisClient(region) {
    if (!this._clients.kinesis.has(region)) {
      this._clients.kinesis.set(region, new KinesisClient({
        region,
        credentials: this._credentialProvider
      }));
    }
    return this._clients.kinesis.get(region);
  }
  async _resolveBucketRegion(client, bucketName) {
    try {
      const output = await client.send(new GetBucketLocationCommand({ Bucket: bucketName }));
      if (!output?.LocationConstraint) return "us-east-1";
      if (output.LocationConstraint === "EU") return "eu-west-1";
      return output.LocationConstraint;
    } catch (err) {
      this.logger("warn", "Failed to resolve bucket region", { bucketName, error: err.message });
      return null;
    }
  }
  async _resolveBucketTags(client, bucketName) {
    try {
      const output = await client.send(new GetBucketTaggingCommand({ Bucket: bucketName }));
      return buildTagObject(output?.TagSet);
    } catch (err) {
      if (err?.name === "NoSuchTagSet" || err?.$metadata?.httpStatusCode === 404) {
        return null;
      }
      this.logger("warn", "Failed to resolve bucket tags", { bucketName, error: err.message });
      return null;
    }
  }
  async _safeListTagsForResource(client, arn) {
    if (!arn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand({ ResourceName: arn }));
      return buildTagObject(output?.TagList);
    } catch (err) {
      this.logger("warn", "Failed to list RDS tags", { arn, error: err.message });
      return null;
    }
  }
  async _safeListIamTags(client, command) {
    try {
      const output = await client.send(command);
      return buildTagObject(output?.Tags);
    } catch (err) {
      if (err?.name === "NoSuchEntity") {
        return null;
      }
      this.logger("warn", "Failed to list IAM tags", { error: err.message });
      return null;
    }
  }
  async _safeListLambdaTags(client, functionArn) {
    try {
      const output = await client.send(new ListTagsCommand({ Resource: functionArn }));
      return output?.Tags || null;
    } catch (err) {
      this.logger("warn", "Failed to list Lambda tags", { functionArn, error: err.message });
      return null;
    }
  }
  async _safeListClassicLBTags(client, loadBalancerName) {
    try {
      const output = await client.send(new DescribeTagsCommand({
        LoadBalancerNames: [loadBalancerName]
      }));
      const tagDescriptions = output?.TagDescriptions?.[0];
      return buildTagObject(tagDescriptions?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list Classic LB tags", { loadBalancerName, error: err.message });
      return null;
    }
  }
  async _safeListELBv2Tags(client, resourceArns) {
    try {
      const output = await client.send(new DescribeTagsCommand$1({
        ResourceArns: resourceArns
      }));
      const tagDescription = output?.TagDescriptions?.[0];
      return buildTagObject(tagDescription?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list ELBv2 tags", { error: err.message });
      return null;
    }
  }
  async _safeListDynamoDBTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsOfResourceCommand({
        ResourceArn: resourceArn
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list DynamoDB tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeGetQueueAttributes(client, queueUrl) {
    try {
      const output = await client.send(new GetQueueAttributesCommand({
        QueueUrl: queueUrl,
        AttributeNames: ["All"]
      }));
      return output?.Attributes || null;
    } catch (err) {
      this.logger("warn", "Failed to get queue attributes", { queueUrl, error: err.message });
      return null;
    }
  }
  async _safeListQueueTags(client, queueUrl) {
    try {
      const output = await client.send(new ListQueueTagsCommand({
        QueueUrl: queueUrl
      }));
      return output?.Tags || null;
    } catch (err) {
      if (err?.name === "QueueDoesNotExist") {
        return null;
      }
      this.logger("warn", "Failed to list queue tags", { queueUrl, error: err.message });
      return null;
    }
  }
  async _safeGetTopicAttributes(client, topicArn) {
    try {
      const output = await client.send(new GetTopicAttributesCommand({
        TopicArn: topicArn
      }));
      return output?.Attributes || null;
    } catch (err) {
      this.logger("warn", "Failed to get topic attributes", { topicArn, error: err.message });
      return null;
    }
  }
  async _safeListSNSTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$1({
        ResourceArn: resourceArn
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list SNS tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListECSTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$2({
        resourceArn
      }));
      return buildTagObject(output?.tags);
    } catch (err) {
      this.logger("warn", "Failed to list ECS tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListEKSTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand$3({
        resourceArn
      }));
      return output?.tags || null;
    } catch (err) {
      this.logger("warn", "Failed to list EKS tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeGetAPIGatewayTags(client, resourceId) {
    try {
      const output = await client.send(new GetTagsCommand({
        resourceArn: `arn:aws:apigateway:${this._regions[0]}::/restapis/${resourceId}`
      }));
      return output?.tags || null;
    } catch (err) {
      this.logger("warn", "Failed to get API Gateway tags", { resourceId, error: err.message });
      return null;
    }
  }
  async _safeGetAPIGatewayV2Tags(client, resourceId) {
    try {
      const output = await client.send(new GetTagsCommand$1({
        ResourceArn: resourceId
      }));
      return output?.Tags || null;
    } catch (err) {
      this.logger("warn", "Failed to get API Gateway v2 tags", { resourceId, error: err.message });
      return null;
    }
  }
  async _safeListCloudFrontTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$4({
        Resource: resourceArn
      }));
      return buildTagObject(output?.Tags?.Items);
    } catch (err) {
      this.logger("warn", "Failed to list CloudFront tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListRoute53Tags(client, resourceId) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$5({
        ResourceType: "hostedzone",
        ResourceId: resourceId.replace("/hostedzone/", "")
      }));
      return buildTagObject(output?.ResourceTagSet?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list Route53 tags", { resourceId, error: err.message });
      return null;
    }
  }
  async _safeListKMSTags(client, keyId) {
    try {
      const output = await client.send(new ListResourceTagsCommand({
        KeyId: keyId
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list KMS tags", { keyId, error: err.message });
      return null;
    }
  }
  async _safeListSSMTags(client, resourceId) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$6({
        ResourceType: "Parameter",
        ResourceId: resourceId
      }));
      return buildTagObject(output?.TagList);
    } catch (err) {
      this.logger("warn", "Failed to list SSM tags", { resourceId, error: err.message });
      return null;
    }
  }
  async _safeListElastiCacheTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand$7({
        ResourceName: resourceArn
      }));
      return buildTagObject(output?.TagList);
    } catch (err) {
      this.logger("warn", "Failed to list ElastiCache tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeDescribeEFSTags(client, fileSystemId) {
    try {
      const output = await client.send(new DescribeTagsCommand$2({
        FileSystemId: fileSystemId
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to describe EFS tags", { fileSystemId, error: err.message });
      return null;
    }
  }
  async _safeListECRTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$8({
        resourceArn
      }));
      return buildTagObject(output?.tags);
    } catch (err) {
      this.logger("warn", "Failed to list ECR tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListSFNTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$9({
        resourceArn
      }));
      return buildTagObject(output?.tags);
    } catch (err) {
      this.logger("warn", "Failed to list Step Functions tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListEventBridgeTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand$a({
        ResourceARN: resourceArn
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list EventBridge tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListCloudWatchTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand$b({
        ResourceARN: resourceArn
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list CloudWatch tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListCWLogsTags(client, logGroupName) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$c({
        resourceArn: logGroupName
      }));
      return output?.tags || null;
    } catch (err) {
      this.logger("warn", "Failed to list CloudWatch Logs tags", { logGroupName, error: err.message });
      return null;
    }
  }
  async _safeListCloudTrailTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsCommand$1({
        ResourceIdList: [resourceArn]
      }));
      const tagsList = output?.ResourceTagList?.[0]?.TagsList;
      return buildTagObject(tagsList);
    } catch (err) {
      this.logger("warn", "Failed to list CloudTrail tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListACMTags(client, certificateArn) {
    try {
      const output = await client.send(new ListTagsForCertificateCommand({
        CertificateArn: certificateArn
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list ACM tags", { certificateArn, error: err.message });
      return null;
    }
  }
  async _safeListWAFTags(client, resourceId) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$d({
        ResourceARN: `arn:aws:waf::${this._accountId}:webacl/${resourceId}`
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list WAF tags", { resourceId, error: err.message });
      return null;
    }
  }
  async _safeListWAFV2Tags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsForResourceCommand$e({
        ResourceARN: resourceArn
      }));
      return buildTagObject(output?.TagInfoForResource?.TagList);
    } catch (err) {
      this.logger("warn", "Failed to list WAFv2 tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListCognitoTags(client, resourceArn) {
    if (!resourceArn) return null;
    try {
      const output = await client.send(new ListTagsForResourceCommand$f({
        ResourceArn: resourceArn
      }));
      return output?.Tags || null;
    } catch (err) {
      this.logger("warn", "Failed to list Cognito tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListBackupTags(client, resourceArn) {
    try {
      const output = await client.send(new ListTagsCommand$2({
        ResourceArn: resourceArn
      }));
      return output?.Tags || null;
    } catch (err) {
      this.logger("warn", "Failed to list Backup tags", { resourceArn, error: err.message });
      return null;
    }
  }
  async _safeListKinesisTags(client, streamName) {
    try {
      const output = await client.send(new ListTagsForStreamCommand({
        StreamName: streamName
      }));
      return buildTagObject(output?.Tags);
    } catch (err) {
      this.logger("warn", "Failed to list Kinesis tags", { streamName, error: err.message });
      return null;
    }
  }
}
function extractInstanceName(instance) {
  if (!instance?.Tags) return null;
  const nameTag = instance.Tags.find((tag) => tag.Key === "Name");
  return nameTag?.Value || null;
}
function sanitizeConfiguration$1(payload) {
  if (!payload || typeof payload !== "object") return payload;
  return JSON.parse(JSON.stringify(payload));
}

const DEFAULT_SERVICES = [
  "compute",
  "gke",
  "run",
  "functions",
  "appengine",
  "storage",
  "sql",
  "bigquery",
  "spanner",
  "firestore",
  "vpc",
  "loadbalancing",
  "dns",
  "cdn",
  "iam",
  "kms",
  "secretmanager",
  "pubsub",
  "tasks",
  "scheduler",
  "monitoring",
  "logging",
  "artifactregistry",
  "containerregistry"
];
function normaliseServiceName(name) {
  return (name || "").toString().trim().toLowerCase();
}
function ensureArray(value, defaultValue = []) {
  if (Array.isArray(value)) return value;
  if (value != null) return [value];
  return defaultValue;
}
function shouldCollect(service, includeSet, excludeSet) {
  if (excludeSet.size > 0 && excludeSet.has(service)) return false;
  if (includeSet.size > 0 && !includeSet.has(service)) return false;
  return true;
}
function sanitizeConfiguration(config) {
  return config;
}
function extractLabels(resource) {
  return resource?.labels || null;
}
class GcpInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "gcp" });
    this._clients = {
      compute: null,
      container: null,
      run: null,
      cloudfunctions: null,
      appengine: null,
      storage: null,
      sqladmin: null,
      bigquery: null,
      spanner: null,
      firestore: null,
      iam: null,
      cloudkms: null,
      secretmanager: null,
      pubsub: null,
      cloudtasks: null,
      cloudscheduler: null,
      monitoring: null,
      logging: null,
      artifactregistry: null
    };
    this._auth = null;
    this._projectId = this.config?.projectId || null;
    this._services = ensureArray(this.config?.services, DEFAULT_SERVICES).map(normaliseServiceName).filter(Boolean);
    if (!this._services.length) {
      this._services = [...DEFAULT_SERVICES];
    }
    this._regions = ensureArray(this.config?.regions, [this.config?.region || "us-central1"]);
    if (!this._regions.length) {
      this._regions = ["us-central1"];
    }
  }
  async initialize() {
    await this._initializeAuth();
    this.logger("info", "GCP driver initialized", {
      cloudId: this.id,
      projectId: this._projectId,
      regions: this._regions,
      services: this._services.length
    });
  }
  async _initializeAuth() {
    const credentials = this.credentials || {};
    if (credentials.keyFile) {
      this._auth = new GoogleAuth({
        keyFile: credentials.keyFile,
        scopes: ["https://www.googleapis.com/auth/cloud-platform"]
      });
    } else if (credentials.credentials) {
      this._auth = new GoogleAuth({
        credentials: credentials.credentials,
        scopes: ["https://www.googleapis.com/auth/cloud-platform"]
      });
    } else {
      this._auth = new GoogleAuth({
        scopes: ["https://www.googleapis.com/auth/cloud-platform"]
      });
    }
    if (!this._projectId) {
      this._projectId = await this._auth.getProjectId();
    }
    this.logger("debug", "GCP authentication initialized", {
      projectId: this._projectId,
      hasKeyFile: !!credentials.keyFile,
      hasCredentials: !!credentials.credentials
    });
  }
  async *_collectComputeInstances() {
    const { compute } = await import('@google-cloud/compute');
    const computeClient = new compute.InstancesClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const zones = await this._listZonesInRegion(region);
        for (const zone of zones) {
          const request = {
            project: this._projectId,
            zone: zone.name
          };
          const [instances] = await computeClient.list(request);
          for (const instance of instances) {
            yield {
              provider: "gcp",
              projectId: this._projectId,
              region,
              service: "compute",
              resourceType: "gcp.compute.instance",
              resourceId: instance.id?.toString() || instance.name,
              name: instance.name,
              labels: extractLabels(instance),
              metadata: { zone: zone.name },
              configuration: sanitizeConfiguration(instance)
            };
          }
        }
      } catch (err) {
        this.logger("warn", "Failed to collect Compute instances", { region, error: err.message });
      }
    }
  }
  async *_collectGKEClusters() {
    const { ClusterManagerClient } = await import('@google-cloud/container');
    const client = new ClusterManagerClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const parent = `projects/${this._projectId}/locations/${region}`;
        const [response] = await client.listClusters({ parent });
        for (const cluster of response.clusters || []) {
          yield {
            provider: "gcp",
            projectId: this._projectId,
            region,
            service: "gke",
            resourceType: "gcp.gke.cluster",
            resourceId: cluster.name,
            name: cluster.name,
            labels: extractLabels(cluster),
            metadata: { zone: cluster.zone, location: cluster.location },
            configuration: sanitizeConfiguration(cluster)
          };
        }
      } catch (err) {
        this.logger("warn", "Failed to collect GKE clusters", { region, error: err.message });
      }
    }
  }
  async *_collectCloudRunServices() {
    const { ServicesClient } = await import('@google-cloud/run');
    const client = new ServicesClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const parent = `projects/${this._projectId}/locations/${region}`;
        const request = { parent };
        const [services] = await client.listServices(request);
        for (const service of services) {
          yield {
            provider: "gcp",
            projectId: this._projectId,
            region,
            service: "run",
            resourceType: "gcp.run.service",
            resourceId: service.uid || service.name,
            name: service.name?.split("/").pop(),
            labels: extractLabels(service.metadata),
            metadata: {},
            configuration: sanitizeConfiguration(service)
          };
        }
      } catch (err) {
        this.logger("warn", "Failed to collect Cloud Run services", { region, error: err.message });
      }
    }
  }
  async *_collectCloudFunctions() {
    const { CloudFunctionsServiceClient } = await import('@google-cloud/functions');
    const client = new CloudFunctionsServiceClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const parent = `projects/${this._projectId}/locations/${region}`;
        const [functions] = await client.listFunctions({ parent });
        for (const fn of functions) {
          yield {
            provider: "gcp",
            projectId: this._projectId,
            region,
            service: "functions",
            resourceType: "gcp.functions.function",
            resourceId: fn.name?.split("/").pop(),
            name: fn.name?.split("/").pop(),
            labels: extractLabels(fn),
            metadata: {},
            configuration: sanitizeConfiguration(fn)
          };
        }
      } catch (err) {
        this.logger("warn", "Failed to collect Cloud Functions", { region, error: err.message });
      }
    }
  }
  async *_collectStorageBuckets() {
    const { Storage } = await import('@google-cloud/storage');
    const storage = new Storage({ auth: this._auth, projectId: this._projectId });
    try {
      const [buckets] = await storage.getBuckets();
      for (const bucket of buckets) {
        const [metadata] = await bucket.getMetadata();
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: metadata.location,
          service: "storage",
          resourceType: "gcp.storage.bucket",
          resourceId: bucket.id || bucket.name,
          name: bucket.name,
          labels: extractLabels(metadata),
          metadata: { location: metadata.location, storageClass: metadata.storageClass },
          configuration: sanitizeConfiguration(metadata)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect Storage buckets", { error: err.message });
    }
  }
  async *_collectCloudSQLInstances() {
    const { SqlInstancesServiceClient } = await import('@google-cloud/sql');
    const client = new SqlInstancesServiceClient({ auth: this._auth });
    try {
      const request = { project: this._projectId };
      const [instances] = await client.list(request);
      for (const instance of instances) {
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: instance.region,
          service: "sql",
          resourceType: "gcp.sql.instance",
          resourceId: instance.name,
          name: instance.name,
          labels: extractLabels({ labels: instance.settings?.userLabels }),
          metadata: { databaseVersion: instance.databaseVersion },
          configuration: sanitizeConfiguration(instance)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect Cloud SQL instances", { error: err.message });
    }
  }
  async *_collectBigQueryDatasets() {
    const { BigQuery } = await import('@google-cloud/bigquery');
    const bigquery = new BigQuery({ auth: this._auth, projectId: this._projectId });
    try {
      const [datasets] = await bigquery.getDatasets();
      for (const dataset of datasets) {
        const [metadata] = await dataset.getMetadata();
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: metadata.location,
          service: "bigquery",
          resourceType: "gcp.bigquery.dataset",
          resourceId: dataset.id,
          name: dataset.id?.split(":").pop(),
          labels: extractLabels(metadata),
          metadata: { location: metadata.location },
          configuration: sanitizeConfiguration(metadata)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect BigQuery datasets", { error: err.message });
    }
  }
  async *_collectPubSubTopics() {
    const { PubSub } = await import('@google-cloud/pubsub');
    const pubsub = new PubSub({ auth: this._auth, projectId: this._projectId });
    try {
      const [topics] = await pubsub.getTopics();
      for (const topic of topics) {
        const [metadata] = await topic.getMetadata();
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "pubsub",
          resourceType: "gcp.pubsub.topic",
          resourceId: topic.name?.split("/").pop(),
          name: topic.name?.split("/").pop(),
          labels: extractLabels(metadata),
          metadata: {},
          configuration: sanitizeConfiguration(metadata)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect Pub/Sub topics", { error: err.message });
    }
  }
  async *_collectPubSubSubscriptions() {
    const { PubSub } = await import('@google-cloud/pubsub');
    const pubsub = new PubSub({ auth: this._auth, projectId: this._projectId });
    try {
      const [subscriptions] = await pubsub.getSubscriptions();
      for (const subscription of subscriptions) {
        const [metadata] = await subscription.getMetadata();
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "pubsub",
          resourceType: "gcp.pubsub.subscription",
          resourceId: subscription.name?.split("/").pop(),
          name: subscription.name?.split("/").pop(),
          labels: extractLabels(metadata),
          metadata: { topic: metadata.topic },
          configuration: sanitizeConfiguration(metadata)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect Pub/Sub subscriptions", { error: err.message });
    }
  }
  async *_collectVPCNetworks() {
    const { compute } = await import('@google-cloud/compute');
    const networksClient = new compute.NetworksClient({ auth: this._auth });
    try {
      const request = { project: this._projectId };
      const [networks] = await networksClient.list(request);
      for (const network of networks) {
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "vpc",
          resourceType: "gcp.vpc.network",
          resourceId: network.id?.toString() || network.name,
          name: network.name,
          labels: null,
          metadata: { autoCreateSubnetworks: network.autoCreateSubnetworks },
          configuration: sanitizeConfiguration(network)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect VPC networks", { error: err.message });
    }
  }
  async *_collectVPCSubnets() {
    const { compute } = await import('@google-cloud/compute');
    const subnetsClient = new compute.SubnetworksClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const request = {
          project: this._projectId,
          region
        };
        const [subnets] = await subnetsClient.list(request);
        for (const subnet of subnets) {
          yield {
            provider: "gcp",
            projectId: this._projectId,
            region,
            service: "vpc",
            resourceType: "gcp.vpc.subnet",
            resourceId: subnet.id?.toString() || subnet.name,
            name: subnet.name,
            labels: null,
            metadata: { network: subnet.network, ipCidrRange: subnet.ipCidrRange },
            configuration: sanitizeConfiguration(subnet)
          };
        }
      } catch (err) {
        this.logger("warn", "Failed to collect VPC subnets", { region, error: err.message });
      }
    }
  }
  async *_collectVPCFirewalls() {
    const { compute } = await import('@google-cloud/compute');
    const firewallsClient = new compute.FirewallsClient({ auth: this._auth });
    try {
      const request = { project: this._projectId };
      const [firewalls] = await firewallsClient.list(request);
      for (const firewall of firewalls) {
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "vpc",
          resourceType: "gcp.vpc.firewall",
          resourceId: firewall.id?.toString() || firewall.name,
          name: firewall.name,
          labels: null,
          metadata: { network: firewall.network, direction: firewall.direction },
          configuration: sanitizeConfiguration(firewall)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect VPC firewalls", { error: err.message });
    }
  }
  async *_collectIAMServiceAccounts() {
    const { IAMClient } = await import('@google-cloud/iam');
    const client = new IAMClient({ auth: this._auth });
    try {
      const parent = `projects/${this._projectId}`;
      const request = { name: parent };
      const [serviceAccounts] = await client.listServiceAccounts(request);
      for (const sa of serviceAccounts) {
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "iam",
          resourceType: "gcp.iam.serviceaccount",
          resourceId: sa.uniqueId || sa.email,
          name: sa.email,
          labels: null,
          metadata: { email: sa.email },
          configuration: sanitizeConfiguration(sa)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect IAM service accounts", { error: err.message });
    }
  }
  async *_collectKMSKeyRings() {
    const { KeyManagementServiceClient } = await import('@google-cloud/kms');
    const client = new KeyManagementServiceClient({ auth: this._auth });
    for (const region of this._regions) {
      try {
        const parent = `projects/${this._projectId}/locations/${region}`;
        const [keyRings] = await client.listKeyRings({ parent });
        for (const keyRing of keyRings) {
          yield {
            provider: "gcp",
            projectId: this._projectId,
            region,
            service: "kms",
            resourceType: "gcp.kms.keyring",
            resourceId: keyRing.name?.split("/").pop(),
            name: keyRing.name?.split("/").pop(),
            labels: null,
            metadata: {},
            configuration: sanitizeConfiguration(keyRing)
          };
        }
      } catch (err) {
        this.logger("warn", "Failed to collect KMS key rings", { region, error: err.message });
      }
    }
  }
  async *_collectSecretManagerSecrets() {
    const { SecretManagerServiceClient } = await import('@google-cloud/secret-manager');
    const client = new SecretManagerServiceClient({ auth: this._auth });
    try {
      const parent = `projects/${this._projectId}`;
      const [secrets] = await client.listSecrets({ parent });
      for (const secret of secrets) {
        yield {
          provider: "gcp",
          projectId: this._projectId,
          region: null,
          service: "secretmanager",
          resourceType: "gcp.secretmanager.secret",
          resourceId: secret.name?.split("/").pop(),
          name: secret.name?.split("/").pop(),
          labels: extractLabels(secret),
          metadata: {},
          configuration: sanitizeConfiguration(secret)
        };
      }
    } catch (err) {
      this.logger("warn", "Failed to collect Secret Manager secrets", { error: err.message });
    }
  }
  async _listZonesInRegion(region) {
    const { compute } = await import('@google-cloud/compute');
    const zonesClient = new compute.ZonesClient({ auth: this._auth });
    try {
      const request = { project: this._projectId };
      const [zones] = await zonesClient.list(request);
      return zones.filter((z) => z.region?.includes(region));
    } catch (err) {
      this.logger("warn", "Failed to list zones", { region, error: err.message });
      return [];
    }
  }
  async *listResources(options = {}) {
    const discoveryInclude = ensureArray(options.discovery?.include).map(normaliseServiceName).filter(Boolean);
    const discoveryExclude = ensureArray(options.discovery?.exclude).map(normaliseServiceName).filter(Boolean);
    const includeSet = new Set(discoveryInclude);
    const excludeSet = new Set(discoveryExclude);
    const runtime = options.runtime || {};
    const emitProgress = typeof runtime.emitProgress === "function" ? runtime.emitProgress.bind(runtime) : null;
    const collectors = {
      compute: this._collectComputeInstances.bind(this),
      gke: this._collectGKEClusters.bind(this),
      run: this._collectCloudRunServices.bind(this),
      functions: this._collectCloudFunctions.bind(this),
      storage: this._collectStorageBuckets.bind(this),
      sql: this._collectCloudSQLInstances.bind(this),
      bigquery: this._collectBigQueryDatasets.bind(this),
      pubsub: async function* () {
        yield* this._collectPubSubTopics();
        yield* this._collectPubSubSubscriptions();
      }.bind(this),
      vpc: async function* () {
        yield* this._collectVPCNetworks();
        yield* this._collectVPCSubnets();
        yield* this._collectVPCFirewalls();
      }.bind(this),
      iam: this._collectIAMServiceAccounts.bind(this),
      kms: this._collectKMSKeyRings.bind(this),
      secretmanager: this._collectSecretManagerSecrets.bind(this)
    };
    for (const service of this._services) {
      if (!collectors[service]) {
        this.logger("debug", "GCP service collector not implemented, skipping", { service });
        continue;
      }
      if (!shouldCollect(service, includeSet, excludeSet)) {
        this.logger("debug", "GCP service filtered out", { service });
        continue;
      }
      try {
        for await (const resource of collectors[service]()) {
          if (emitProgress) {
            emitProgress({
              service,
              resourceId: resource.resourceId,
              resourceType: resource.resourceType
            });
          }
          yield resource;
        }
      } catch (err) {
        this.logger("error", "GCP service collection failed, skipping to next service", {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
}

class VultrInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "vultr" });
    this._apiKey = null;
    this._client = null;
    this._accountId = this.config?.accountId || "vultr";
    this._services = this.config?.services || [
      "instances",
      "baremetal",
      "kubernetes",
      "blockstorage",
      "snapshots",
      "loadbalancers",
      "firewalls",
      "vpc",
      "dns",
      "databases",
      "sshkeys",
      "objectstorage"
    ];
  }
  /**
   * Initialize the Vultr API client.
   */
  async _initializeClient() {
    if (this._client) return;
    const credentials = this.credentials || {};
    this._apiKey = credentials.apiKey || credentials.token || process.env.VULTR_API_KEY;
    if (!this._apiKey) {
      throw new Error("Vultr API key is required. Provide via credentials.apiKey or VULTR_API_KEY env var.");
    }
    const { VultrNode } = await import('@vultr/vultr-node');
    this._client = VultrNode.initialize({ apiKey: this._apiKey });
    this.logger("info", "Vultr API client initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeClient();
    const serviceCollectors = {
      instances: () => this._collectInstances(),
      baremetal: () => this._collectBareMetal(),
      kubernetes: () => this._collectKubernetes(),
      blockstorage: () => this._collectBlockStorage(),
      snapshots: () => this._collectSnapshots(),
      loadbalancers: () => this._collectLoadBalancers(),
      firewalls: () => this._collectFirewalls(),
      vpc: () => this._collectVPC(),
      dns: () => this._collectDNS(),
      databases: () => this._collectDatabases(),
      sshkeys: () => this._collectSSHKeys(),
      objectstorage: () => this._collectObjectStorage()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Vultr service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Vultr ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Vultr service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Compute Instances (VPS).
   */
  async *_collectInstances() {
    try {
      const response = await this._client.instances.listInstances();
      const instances = response.instances || [];
      for (const instance of instances) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: instance.region,
          service: "instances",
          resourceType: "vultr.compute.instance",
          resourceId: instance.id,
          name: instance.label || instance.hostname || instance.id,
          tags: instance.tags || [],
          configuration: this._sanitize(instance)
        };
      }
      this.logger("info", `Collected ${instances.length} Vultr instances`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr instances", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Bare Metal servers.
   */
  async *_collectBareMetal() {
    try {
      const response = await this._client.bareMetal.listBareMetalServers();
      const servers = response.bare_metals || [];
      for (const server of servers) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: server.region,
          service: "baremetal",
          resourceType: "vultr.baremetal.server",
          resourceId: server.id,
          name: server.label || server.id,
          tags: server.tags || [],
          configuration: this._sanitize(server)
        };
      }
      this.logger("info", `Collected ${servers.length} Vultr bare metal servers`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr bare metal", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Kubernetes clusters (VKE).
   */
  async *_collectKubernetes() {
    try {
      const response = await this._client.kubernetes.listKubernetesClusters();
      const clusters = response.vke_clusters || [];
      for (const cluster of clusters) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: cluster.region,
          service: "kubernetes",
          resourceType: "vultr.kubernetes.cluster",
          resourceId: cluster.id,
          name: cluster.label || cluster.id,
          tags: [],
          configuration: this._sanitize(cluster)
        };
        try {
          const npResponse = await this._client.kubernetes.listNodePools({ "vke-id": cluster.id });
          const nodePools = npResponse.node_pools || [];
          for (const nodePool of nodePools) {
            yield {
              provider: "vultr",
              accountId: this._accountId,
              region: cluster.region,
              service: "kubernetes",
              resourceType: "vultr.kubernetes.nodepool",
              resourceId: nodePool.id,
              name: nodePool.label || nodePool.id,
              tags: [],
              metadata: { clusterId: cluster.id, clusterLabel: cluster.label },
              configuration: this._sanitize(nodePool)
            };
          }
        } catch (npErr) {
          this.logger("warn", `Failed to collect node pools for cluster ${cluster.id}`, {
            clusterId: cluster.id,
            error: npErr.message
          });
        }
      }
      this.logger("info", `Collected ${clusters.length} Vultr Kubernetes clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr Kubernetes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Block Storage volumes.
   */
  async *_collectBlockStorage() {
    try {
      const response = await this._client.blockStorage.listBlockStorages();
      const volumes = response.blocks || [];
      for (const volume of volumes) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: volume.region,
          service: "blockstorage",
          resourceType: "vultr.blockstorage.volume",
          resourceId: volume.id,
          name: volume.label || volume.id,
          tags: [],
          configuration: this._sanitize(volume)
        };
      }
      this.logger("info", `Collected ${volumes.length} Vultr block storage volumes`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr block storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Snapshots.
   */
  async *_collectSnapshots() {
    try {
      const response = await this._client.snapshots.listSnapshots();
      const snapshots = response.snapshots || [];
      for (const snapshot of snapshots) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: null,
          // Snapshots are global
          service: "snapshots",
          resourceType: "vultr.snapshot",
          resourceId: snapshot.id,
          name: snapshot.description || snapshot.id,
          tags: [],
          configuration: this._sanitize(snapshot)
        };
      }
      this.logger("info", `Collected ${snapshots.length} Vultr snapshots`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr snapshots", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Load Balancers.
   */
  async *_collectLoadBalancers() {
    try {
      const response = await this._client.loadBalancers.listLoadBalancers();
      const lbs = response.load_balancers || [];
      for (const lb of lbs) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: lb.region,
          service: "loadbalancers",
          resourceType: "vultr.loadbalancer",
          resourceId: lb.id,
          name: lb.label || lb.id,
          tags: [],
          configuration: this._sanitize(lb)
        };
      }
      this.logger("info", `Collected ${lbs.length} Vultr load balancers`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr load balancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Firewall Groups.
   */
  async *_collectFirewalls() {
    try {
      const response = await this._client.firewalls.listFirewallGroups();
      const firewalls = response.firewall_groups || [];
      for (const firewall of firewalls) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: null,
          // Firewalls are global
          service: "firewalls",
          resourceType: "vultr.firewall.group",
          resourceId: firewall.id,
          name: firewall.description || firewall.id,
          tags: [],
          configuration: this._sanitize(firewall)
        };
        try {
          const rulesResponse = await this._client.firewalls.listFirewallGroupRules({
            "firewall-group-id": firewall.id
          });
          const rules = rulesResponse.firewall_rules || [];
          for (const rule of rules) {
            yield {
              provider: "vultr",
              accountId: this._accountId,
              region: null,
              service: "firewalls",
              resourceType: "vultr.firewall.rule",
              resourceId: `${firewall.id}/${rule.id}`,
              name: `${firewall.description || firewall.id} - Rule ${rule.id}`,
              tags: [],
              metadata: { firewallGroupId: firewall.id },
              configuration: this._sanitize(rule)
            };
          }
        } catch (rulesErr) {
          this.logger("warn", `Failed to collect firewall rules for ${firewall.id}`, {
            firewallId: firewall.id,
            error: rulesErr.message
          });
        }
      }
      this.logger("info", `Collected ${firewalls.length} Vultr firewall groups`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr firewalls", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect VPC/VPC 2.0 networks.
   */
  async *_collectVPC() {
    try {
      try {
        const response = await this._client.vpc2.listVPC2s();
        const vpcs = response.vpcs || [];
        for (const vpc of vpcs) {
          yield {
            provider: "vultr",
            accountId: this._accountId,
            region: vpc.region,
            service: "vpc",
            resourceType: "vultr.vpc.network",
            resourceId: vpc.id,
            name: vpc.description || vpc.id,
            tags: [],
            configuration: this._sanitize(vpc)
          };
        }
        this.logger("info", `Collected ${vpcs.length} Vultr VPC 2.0 networks`);
      } catch (vpc2Err) {
        this.logger("warn", "Failed to collect VPC 2.0, trying legacy VPC", {
          error: vpc2Err.message
        });
        const legacyResponse = await this._client.vpc.listVPCs();
        const legacyVpcs = legacyResponse.vpcs || [];
        for (const vpc of legacyVpcs) {
          yield {
            provider: "vultr",
            accountId: this._accountId,
            region: vpc.region,
            service: "vpc",
            resourceType: "vultr.vpc.network.legacy",
            resourceId: vpc.id,
            name: vpc.description || vpc.id,
            tags: [],
            configuration: this._sanitize(vpc)
          };
        }
        this.logger("info", `Collected ${legacyVpcs.length} Vultr legacy VPC networks`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Vultr VPC", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS domains and records.
   */
  async *_collectDNS() {
    try {
      const response = await this._client.dns.listDomains();
      const domains = response.domains || [];
      for (const domain of domains) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: null,
          // DNS is global
          service: "dns",
          resourceType: "vultr.dns.domain",
          resourceId: domain.domain,
          name: domain.domain,
          tags: [],
          configuration: this._sanitize(domain)
        };
        try {
          const recordsResponse = await this._client.dns.listRecords({ "dns-domain": domain.domain });
          const records = recordsResponse.records || [];
          for (const record of records) {
            yield {
              provider: "vultr",
              accountId: this._accountId,
              region: null,
              service: "dns",
              resourceType: "vultr.dns.record",
              resourceId: record.id,
              name: `${record.name}.${domain.domain}`,
              tags: [],
              metadata: { domain: domain.domain },
              configuration: this._sanitize(record)
            };
          }
        } catch (recordsErr) {
          this.logger("warn", `Failed to collect DNS records for ${domain.domain}`, {
            domain: domain.domain,
            error: recordsErr.message
          });
        }
      }
      this.logger("info", `Collected ${domains.length} Vultr DNS domains`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr DNS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Managed Databases.
   */
  async *_collectDatabases() {
    try {
      const response = await this._client.databases.listDatabases();
      const databases = response.databases || [];
      for (const db of databases) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: db.region,
          service: "databases",
          resourceType: "vultr.database",
          resourceId: db.id,
          name: db.label || db.id,
          tags: db.tag ? [db.tag] : [],
          configuration: this._sanitize(db)
        };
      }
      this.logger("info", `Collected ${databases.length} Vultr managed databases`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr databases", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SSH Keys.
   */
  async *_collectSSHKeys() {
    try {
      const response = await this._client.sshKeys.listSshKeys();
      const keys = response.ssh_keys || [];
      for (const key of keys) {
        yield {
          provider: "vultr",
          accountId: this._accountId,
          region: null,
          // SSH keys are global
          service: "sshkeys",
          resourceType: "vultr.sshkey",
          resourceId: key.id,
          name: key.name || key.id,
          tags: [],
          configuration: this._sanitize(key)
        };
      }
      this.logger("info", `Collected ${keys.length} Vultr SSH keys`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr SSH keys", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Object Storage buckets.
   */
  async *_collectObjectStorage() {
    try {
      const clustersResponse = await this._client.objectStorage.listObjectStorageClusters();
      const clusters = clustersResponse.clusters || [];
      for (const cluster of clusters) {
        try {
          const response = await this._client.objectStorage.listObjectStorages();
          const storages = response.object_storages || [];
          for (const storage of storages) {
            if (storage.object_storage_cluster_id === cluster.id) {
              yield {
                provider: "vultr",
                accountId: this._accountId,
                region: cluster.region,
                service: "objectstorage",
                resourceType: "vultr.objectstorage.bucket",
                resourceId: storage.id,
                name: storage.label || storage.id,
                tags: [],
                metadata: { clusterId: cluster.id, clusterRegion: cluster.region },
                configuration: this._sanitize(storage)
              };
            }
          }
        } catch (storageErr) {
          this.logger("warn", `Failed to collect object storage for cluster ${cluster.id}`, {
            clusterId: cluster.id,
            error: storageErr.message
          });
        }
      }
      this.logger("info", `Collected object storage from ${clusters.length} Vultr clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect Vultr object storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = ["api_key", "password", "secret", "token", "ssh_key", "private_key"];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class DigitalOceanInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "digitalocean" });
    this._apiToken = null;
    this._client = null;
    this._accountId = this.config?.accountId || "digitalocean";
    this._services = this.config?.services || [
      "droplets",
      "kubernetes",
      "databases",
      "volumes",
      "snapshots",
      "loadbalancers",
      "firewalls",
      "vpc",
      "floatingips",
      "domains",
      "cdn",
      "registry",
      "apps",
      "sshkeys",
      "spaces"
    ];
    this._regions = this.config?.regions || null;
  }
  /**
   * Initialize the DigitalOcean API client.
   */
  async _initializeClient() {
    if (this._client) return;
    const credentials = this.credentials || {};
    this._apiToken = credentials.token || credentials.apiToken || process.env.DIGITALOCEAN_TOKEN;
    if (!this._apiToken) {
      throw new Error("DigitalOcean API token is required. Provide via credentials.token or DIGITALOCEAN_TOKEN env var.");
    }
    const { DigitalOcean } = await import('digitalocean-js');
    this._client = new DigitalOcean(this._apiToken);
    this.logger("info", "DigitalOcean API client initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeClient();
    const serviceCollectors = {
      droplets: () => this._collectDroplets(),
      kubernetes: () => this._collectKubernetes(),
      databases: () => this._collectDatabases(),
      volumes: () => this._collectVolumes(),
      snapshots: () => this._collectSnapshots(),
      loadbalancers: () => this._collectLoadBalancers(),
      firewalls: () => this._collectFirewalls(),
      vpc: () => this._collectVPC(),
      floatingips: () => this._collectFloatingIPs(),
      domains: () => this._collectDomains(),
      cdn: () => this._collectCDN(),
      registry: () => this._collectRegistry(),
      apps: () => this._collectApps(),
      sshkeys: () => this._collectSSHKeys(),
      spaces: () => this._collectSpaces()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown DigitalOcean service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting DigitalOcean ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `DigitalOcean service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Droplets (VMs).
   */
  async *_collectDroplets() {
    try {
      const response = await this._client.droplets.getAllDroplets();
      const droplets = response.droplets || [];
      for (const droplet of droplets) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: droplet.region?.slug || null,
          service: "droplets",
          resourceType: "digitalocean.droplet",
          resourceId: droplet.id?.toString(),
          name: droplet.name,
          tags: droplet.tags || [],
          configuration: this._sanitize(droplet)
        };
      }
      this.logger("info", `Collected ${droplets.length} DigitalOcean droplets`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean droplets", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Kubernetes clusters (DOKS).
   */
  async *_collectKubernetes() {
    try {
      const response = await this._client.kubernetes.listClusters();
      const clusters = response.kubernetes_clusters || [];
      for (const cluster of clusters) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: cluster.region,
          service: "kubernetes",
          resourceType: "digitalocean.kubernetes.cluster",
          resourceId: cluster.id,
          name: cluster.name,
          tags: cluster.tags || [],
          configuration: this._sanitize(cluster)
        };
        if (cluster.node_pools && Array.isArray(cluster.node_pools)) {
          for (const nodePool of cluster.node_pools) {
            yield {
              provider: "digitalocean",
              accountId: this._accountId,
              region: cluster.region,
              service: "kubernetes",
              resourceType: "digitalocean.kubernetes.nodepool",
              resourceId: nodePool.id,
              name: nodePool.name,
              tags: nodePool.tags || [],
              metadata: { clusterId: cluster.id, clusterName: cluster.name },
              configuration: this._sanitize(nodePool)
            };
          }
        }
      }
      this.logger("info", `Collected ${clusters.length} DigitalOcean Kubernetes clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean Kubernetes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Managed Databases.
   */
  async *_collectDatabases() {
    try {
      const response = await this._client.databases.listClusters();
      const databases = response.databases || [];
      for (const db of databases) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: db.region,
          service: "databases",
          resourceType: "digitalocean.database.cluster",
          resourceId: db.id,
          name: db.name,
          tags: db.tags || [],
          configuration: this._sanitize(db)
        };
      }
      this.logger("info", `Collected ${databases.length} DigitalOcean managed databases`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean databases", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Block Storage Volumes.
   */
  async *_collectVolumes() {
    try {
      const response = await this._client.volumes.getAllVolumes();
      const volumes = response.volumes || [];
      for (const volume of volumes) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: volume.region?.slug || null,
          service: "volumes",
          resourceType: "digitalocean.volume",
          resourceId: volume.id,
          name: volume.name,
          tags: volume.tags || [],
          configuration: this._sanitize(volume)
        };
      }
      this.logger("info", `Collected ${volumes.length} DigitalOcean volumes`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean volumes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Snapshots.
   */
  async *_collectSnapshots() {
    try {
      const response = await this._client.snapshots.getAll();
      const snapshots = response.snapshots || [];
      for (const snapshot of snapshots) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: snapshot.regions?.[0] || null,
          service: "snapshots",
          resourceType: "digitalocean.snapshot",
          resourceId: snapshot.id,
          name: snapshot.name,
          tags: snapshot.tags || [],
          configuration: this._sanitize(snapshot)
        };
      }
      this.logger("info", `Collected ${snapshots.length} DigitalOcean snapshots`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean snapshots", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Load Balancers.
   */
  async *_collectLoadBalancers() {
    try {
      const response = await this._client.loadBalancers.getAllLoadBalancers();
      const lbs = response.load_balancers || [];
      for (const lb of lbs) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: lb.region?.slug || null,
          service: "loadbalancers",
          resourceType: "digitalocean.loadbalancer",
          resourceId: lb.id,
          name: lb.name,
          tags: lb.tags || [],
          configuration: this._sanitize(lb)
        };
      }
      this.logger("info", `Collected ${lbs.length} DigitalOcean load balancers`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean load balancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Firewalls.
   */
  async *_collectFirewalls() {
    try {
      const response = await this._client.firewalls.getAllFirewalls();
      const firewalls = response.firewalls || [];
      for (const firewall of firewalls) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: null,
          // Firewalls are global
          service: "firewalls",
          resourceType: "digitalocean.firewall",
          resourceId: firewall.id,
          name: firewall.name,
          tags: firewall.tags || [],
          configuration: this._sanitize(firewall)
        };
      }
      this.logger("info", `Collected ${firewalls.length} DigitalOcean firewalls`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean firewalls", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect VPCs.
   */
  async *_collectVPC() {
    try {
      const response = await this._client.vpcs.listVpcs();
      const vpcs = response.vpcs || [];
      for (const vpc of vpcs) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: vpc.region,
          service: "vpc",
          resourceType: "digitalocean.vpc",
          resourceId: vpc.id,
          name: vpc.name,
          tags: [],
          configuration: this._sanitize(vpc)
        };
      }
      this.logger("info", `Collected ${vpcs.length} DigitalOcean VPCs`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean VPCs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Floating IPs.
   */
  async *_collectFloatingIPs() {
    try {
      const response = await this._client.floatingIps.getAllFloatingIps();
      const ips = response.floating_ips || [];
      for (const ip of ips) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: ip.region?.slug || null,
          service: "floatingips",
          resourceType: "digitalocean.floatingip",
          resourceId: ip.ip,
          name: ip.ip,
          tags: [],
          configuration: this._sanitize(ip)
        };
      }
      this.logger("info", `Collected ${ips.length} DigitalOcean floating IPs`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean floating IPs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS Domains and Records.
   */
  async *_collectDomains() {
    try {
      const response = await this._client.domains.getAllDomains();
      const domains = response.domains || [];
      for (const domain of domains) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: null,
          // DNS is global
          service: "domains",
          resourceType: "digitalocean.domain",
          resourceId: domain.name,
          name: domain.name,
          tags: [],
          configuration: this._sanitize(domain)
        };
        try {
          const recordsResponse = await this._client.domains.getAllDomainRecords(domain.name);
          const records = recordsResponse.domain_records || [];
          for (const record of records) {
            yield {
              provider: "digitalocean",
              accountId: this._accountId,
              region: null,
              service: "domains",
              resourceType: "digitalocean.domain.record",
              resourceId: `${domain.name}/${record.id}`,
              name: `${record.name}.${domain.name}`,
              tags: [],
              metadata: { domain: domain.name },
              configuration: this._sanitize(record)
            };
          }
        } catch (recordsErr) {
          this.logger("warn", `Failed to collect DNS records for ${domain.name}`, {
            domain: domain.name,
            error: recordsErr.message
          });
        }
      }
      this.logger("info", `Collected ${domains.length} DigitalOcean domains`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean domains", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect CDN Endpoints.
   */
  async *_collectCDN() {
    try {
      const response = await this._client.cdnEndpoints.getAllEndpoints();
      const endpoints = response.endpoints || [];
      for (const endpoint of endpoints) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: null,
          // CDN is global
          service: "cdn",
          resourceType: "digitalocean.cdn.endpoint",
          resourceId: endpoint.id,
          name: endpoint.endpoint,
          tags: [],
          configuration: this._sanitize(endpoint)
        };
      }
      this.logger("info", `Collected ${endpoints.length} DigitalOcean CDN endpoints`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean CDN", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Container Registry.
   */
  async *_collectRegistry() {
    try {
      const response = await this._client.registry.get();
      const registry = response.registry;
      if (registry) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: registry.region,
          service: "registry",
          resourceType: "digitalocean.registry",
          resourceId: registry.name,
          name: registry.name,
          tags: [],
          configuration: this._sanitize(registry)
        };
        try {
          const reposResponse = await this._client.registry.listRepositories(registry.name);
          const repositories = reposResponse.repositories || [];
          for (const repo of repositories) {
            yield {
              provider: "digitalocean",
              accountId: this._accountId,
              region: registry.region,
              service: "registry",
              resourceType: "digitalocean.registry.repository",
              resourceId: repo.name,
              name: repo.name,
              tags: [],
              metadata: { registryName: registry.name },
              configuration: this._sanitize(repo)
            };
          }
        } catch (reposErr) {
          this.logger("warn", `Failed to collect registry repositories`, {
            registry: registry.name,
            error: reposErr.message
          });
        }
      }
      this.logger("info", `Collected DigitalOcean container registry`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean registry", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect App Platform apps.
   */
  async *_collectApps() {
    try {
      const response = await this._client.apps.listApps();
      const apps = response.apps || [];
      for (const app of apps) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: app.region?.slug || null,
          service: "apps",
          resourceType: "digitalocean.app",
          resourceId: app.id,
          name: app.spec?.name || app.id,
          tags: [],
          configuration: this._sanitize(app)
        };
      }
      this.logger("info", `Collected ${apps.length} DigitalOcean App Platform apps`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean apps", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SSH Keys.
   */
  async *_collectSSHKeys() {
    try {
      const response = await this._client.accountKeys.getAllKeys();
      const keys = response.ssh_keys || [];
      for (const key of keys) {
        yield {
          provider: "digitalocean",
          accountId: this._accountId,
          region: null,
          // SSH keys are global
          service: "sshkeys",
          resourceType: "digitalocean.sshkey",
          resourceId: key.id?.toString(),
          name: key.name,
          tags: [],
          configuration: this._sanitize(key)
        };
      }
      this.logger("info", `Collected ${keys.length} DigitalOcean SSH keys`);
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean SSH keys", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Spaces (Object Storage).
   * Note: Spaces API is S3-compatible, not part of the main DO API.
   * This is a placeholder - full implementation would require AWS S3 SDK.
   */
  async *_collectSpaces() {
    try {
      this.logger("info", "Spaces collection requires S3-compatible API implementation");
    } catch (err) {
      this.logger("error", "Failed to collect DigitalOcean Spaces", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "token",
      "password",
      "secret",
      "api_key",
      "ssh_key",
      "private_key",
      "public_key",
      "connection_string",
      "uri"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class OracleInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "oracle" });
    this._provider = null;
    this._tenancyId = null;
    this._compartmentId = null;
    this._accountId = this.config?.accountId || "oracle";
    this._services = this.config?.services || [
      "compute",
      "kubernetes",
      "database",
      "blockstorage",
      "objectstorage",
      "filestorage",
      "vcn",
      "loadbalancer",
      "identity",
      "dns"
    ];
    this._regions = this.config?.regions || null;
  }
  /**
   * Initialize the OCI provider and clients.
   */
  async _initializeProvider() {
    if (this._provider) return;
    const credentials = this.credentials || {};
    const common = await import('oci-common');
    if (credentials.configFilePath) {
      this._provider = new common.ConfigFileAuthenticationDetailsProvider(
        credentials.configFilePath,
        credentials.profile || "DEFAULT"
      );
    } else if (credentials.instancePrincipal) {
      this._provider = await common.ResourcePrincipalAuthenticationDetailsProvider.builder();
    } else if (credentials.user && credentials.fingerprint && credentials.privateKey) {
      this._provider = new common.SimpleAuthenticationDetailsProvider(
        credentials.tenancy || this.config?.tenancyId,
        credentials.user,
        credentials.fingerprint,
        credentials.privateKey,
        credentials.passphrase || null,
        credentials.region || this.config?.region || common.Region.US_ASHBURN_1
      );
    } else {
      this._provider = new common.ConfigFileAuthenticationDetailsProvider();
    }
    this._tenancyId = credentials.tenancy || this.config?.tenancyId;
    this._compartmentId = this.config?.compartmentId || this._tenancyId;
    this.logger("info", "OCI provider initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeProvider();
    const serviceCollectors = {
      compute: () => this._collectCompute(),
      kubernetes: () => this._collectKubernetes(),
      database: () => this._collectDatabases(),
      blockstorage: () => this._collectBlockStorage(),
      objectstorage: () => this._collectObjectStorage(),
      filestorage: () => this._collectFileStorage(),
      vcn: () => this._collectVCN(),
      loadbalancer: () => this._collectLoadBalancers(),
      identity: () => this._collectIdentity(),
      dns: () => this._collectDNS()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown OCI service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting OCI ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `OCI service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Compute instances.
   */
  async *_collectCompute() {
    try {
      const { core } = await import('oci-core');
      const computeClient = new core.ComputeClient({ authenticationDetailsProvider: this._provider });
      const regions = await this._getRegions();
      for (const region of regions) {
        computeClient.region = region;
        const instancesResponse = await computeClient.listInstances({
          compartmentId: this._compartmentId
        });
        const instances = instancesResponse.items || [];
        for (const instance of instances) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "compute",
            resourceType: "oracle.compute.instance",
            resourceId: instance.id,
            name: instance.displayName || instance.id,
            tags: this._extractTags(instance.freeformTags, instance.definedTags),
            configuration: this._sanitize(instance)
          };
        }
        this.logger("info", `Collected ${instances.length} OCI compute instances in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI compute", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Kubernetes (OKE) clusters.
   */
  async *_collectKubernetes() {
    try {
      const { containerengine } = await import('oci-containerengine');
      const containerClient = new containerengine.ContainerEngineClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        containerClient.region = region;
        const clustersResponse = await containerClient.listClusters({
          compartmentId: this._compartmentId
        });
        const clusters = clustersResponse.items || [];
        for (const cluster of clusters) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "kubernetes",
            resourceType: "oracle.kubernetes.cluster",
            resourceId: cluster.id,
            name: cluster.name,
            tags: this._extractTags(cluster.freeformTags, cluster.definedTags),
            configuration: this._sanitize(cluster)
          };
          try {
            const nodePoolsResponse = await containerClient.listNodePools({
              compartmentId: this._compartmentId,
              clusterId: cluster.id
            });
            const nodePools = nodePoolsResponse.items || [];
            for (const nodePool of nodePools) {
              yield {
                provider: "oracle",
                accountId: this._accountId,
                region: region.regionName,
                service: "kubernetes",
                resourceType: "oracle.kubernetes.nodepool",
                resourceId: nodePool.id,
                name: nodePool.name,
                tags: this._extractTags(nodePool.freeformTags, nodePool.definedTags),
                metadata: { clusterId: cluster.id, clusterName: cluster.name },
                configuration: this._sanitize(nodePool)
              };
            }
          } catch (npErr) {
            this.logger("warn", `Failed to collect node pools for cluster ${cluster.id}`, {
              clusterId: cluster.id,
              error: npErr.message
            });
          }
        }
        this.logger("info", `Collected ${clusters.length} OCI OKE clusters in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI Kubernetes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Databases (Autonomous Database, DB Systems).
   */
  async *_collectDatabases() {
    try {
      const { database } = await import('oci-database');
      const databaseClient = new database.DatabaseClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        databaseClient.region = region;
        const autonomousDbsResponse = await databaseClient.listAutonomousDatabases({
          compartmentId: this._compartmentId
        });
        const autonomousDbs = autonomousDbsResponse.items || [];
        for (const db of autonomousDbs) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "database",
            resourceType: "oracle.database.autonomous",
            resourceId: db.id,
            name: db.displayName || db.dbName,
            tags: this._extractTags(db.freeformTags, db.definedTags),
            configuration: this._sanitize(db)
          };
        }
        const dbSystemsResponse = await databaseClient.listDbSystems({
          compartmentId: this._compartmentId
        });
        const dbSystems = dbSystemsResponse.items || [];
        for (const dbSystem of dbSystems) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "database",
            resourceType: "oracle.database.system",
            resourceId: dbSystem.id,
            name: dbSystem.displayName,
            tags: this._extractTags(dbSystem.freeformTags, dbSystem.definedTags),
            configuration: this._sanitize(dbSystem)
          };
        }
        this.logger("info", `Collected ${autonomousDbs.length} Autonomous DBs and ${dbSystems.length} DB Systems in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI databases", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Block Storage volumes.
   */
  async *_collectBlockStorage() {
    try {
      const { core } = await import('oci-core');
      const blockstorageClient = new core.BlockstorageClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        blockstorageClient.region = region;
        const volumesResponse = await blockstorageClient.listVolumes({
          compartmentId: this._compartmentId
        });
        const volumes = volumesResponse.items || [];
        for (const volume of volumes) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "blockstorage",
            resourceType: "oracle.blockstorage.volume",
            resourceId: volume.id,
            name: volume.displayName,
            tags: this._extractTags(volume.freeformTags, volume.definedTags),
            configuration: this._sanitize(volume)
          };
        }
        this.logger("info", `Collected ${volumes.length} OCI block volumes in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI block storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Object Storage buckets.
   */
  async *_collectObjectStorage() {
    try {
      const { objectstorage } = await import('oci-objectstorage');
      const objectStorageClient = new objectstorage.ObjectStorageClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      const namespaceResponse = await objectStorageClient.getNamespace({});
      const namespace = namespaceResponse.value;
      for (const region of regions) {
        objectStorageClient.region = region;
        const bucketsResponse = await objectStorageClient.listBuckets({
          namespaceName: namespace,
          compartmentId: this._compartmentId
        });
        const buckets = bucketsResponse.items || [];
        for (const bucket of buckets) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "objectstorage",
            resourceType: "oracle.objectstorage.bucket",
            resourceId: bucket.name,
            name: bucket.name,
            tags: this._extractTags(bucket.freeformTags, bucket.definedTags),
            metadata: { namespace },
            configuration: this._sanitize(bucket)
          };
        }
        this.logger("info", `Collected ${buckets.length} OCI object storage buckets in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI object storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect File Storage file systems.
   */
  async *_collectFileStorage() {
    try {
      const { filestorage } = await import('oci-filestorage');
      const fileStorageClient = new filestorage.FileStorageClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        fileStorageClient.region = region;
        const fileSystemsResponse = await fileStorageClient.listFileSystems({
          compartmentId: this._compartmentId,
          availabilityDomain: region.regionName
          // Note: may need proper AD
        });
        const fileSystems = fileSystemsResponse.items || [];
        for (const fs of fileSystems) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "filestorage",
            resourceType: "oracle.filestorage.filesystem",
            resourceId: fs.id,
            name: fs.displayName,
            tags: this._extractTags(fs.freeformTags, fs.definedTags),
            configuration: this._sanitize(fs)
          };
        }
        this.logger("info", `Collected ${fileSystems.length} OCI file systems in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI file storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect VCN (Virtual Cloud Network) resources.
   */
  async *_collectVCN() {
    try {
      const { core } = await import('oci-core');
      const vcnClient = new core.VirtualNetworkClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        vcnClient.region = region;
        const vcnsResponse = await vcnClient.listVcns({
          compartmentId: this._compartmentId
        });
        const vcns = vcnsResponse.items || [];
        for (const vcn of vcns) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "vcn",
            resourceType: "oracle.vcn.network",
            resourceId: vcn.id,
            name: vcn.displayName,
            tags: this._extractTags(vcn.freeformTags, vcn.definedTags),
            configuration: this._sanitize(vcn)
          };
          try {
            const subnetsResponse = await vcnClient.listSubnets({
              compartmentId: this._compartmentId,
              vcnId: vcn.id
            });
            const subnets = subnetsResponse.items || [];
            for (const subnet of subnets) {
              yield {
                provider: "oracle",
                accountId: this._accountId,
                region: region.regionName,
                service: "vcn",
                resourceType: "oracle.vcn.subnet",
                resourceId: subnet.id,
                name: subnet.displayName,
                tags: this._extractTags(subnet.freeformTags, subnet.definedTags),
                metadata: { vcnId: vcn.id, vcnName: vcn.displayName },
                configuration: this._sanitize(subnet)
              };
            }
          } catch (subnetErr) {
            this.logger("warn", `Failed to collect subnets for VCN ${vcn.id}`, {
              vcnId: vcn.id,
              error: subnetErr.message
            });
          }
        }
        this.logger("info", `Collected ${vcns.length} OCI VCNs in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI VCN", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Load Balancers.
   */
  async *_collectLoadBalancers() {
    try {
      const { loadbalancer } = await import('oci-loadbalancer');
      const lbClient = new loadbalancer.LoadBalancerClient({
        authenticationDetailsProvider: this._provider
      });
      const regions = await this._getRegions();
      for (const region of regions) {
        lbClient.region = region;
        const lbsResponse = await lbClient.listLoadBalancers({
          compartmentId: this._compartmentId
        });
        const lbs = lbsResponse.items || [];
        for (const lb of lbs) {
          yield {
            provider: "oracle",
            accountId: this._accountId,
            region: region.regionName,
            service: "loadbalancer",
            resourceType: "oracle.loadbalancer",
            resourceId: lb.id,
            name: lb.displayName,
            tags: this._extractTags(lb.freeformTags, lb.definedTags),
            configuration: this._sanitize(lb)
          };
        }
        this.logger("info", `Collected ${lbs.length} OCI load balancers in ${region.regionName}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect OCI load balancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Identity resources (users, groups, compartments).
   */
  async *_collectIdentity() {
    try {
      const { identity } = await import('oci-identity');
      const identityClient = new identity.IdentityClient({
        authenticationDetailsProvider: this._provider
      });
      const usersResponse = await identityClient.listUsers({
        compartmentId: this._tenancyId
      });
      const users = usersResponse.items || [];
      for (const user of users) {
        yield {
          provider: "oracle",
          accountId: this._accountId,
          region: null,
          // Identity is global
          service: "identity",
          resourceType: "oracle.identity.user",
          resourceId: user.id,
          name: user.name,
          tags: this._extractTags(user.freeformTags, user.definedTags),
          configuration: this._sanitize(user)
        };
      }
      const groupsResponse = await identityClient.listGroups({
        compartmentId: this._tenancyId
      });
      const groups = groupsResponse.items || [];
      for (const group of groups) {
        yield {
          provider: "oracle",
          accountId: this._accountId,
          region: null,
          service: "identity",
          resourceType: "oracle.identity.group",
          resourceId: group.id,
          name: group.name,
          tags: this._extractTags(group.freeformTags, group.definedTags),
          configuration: this._sanitize(group)
        };
      }
      const compartmentsResponse = await identityClient.listCompartments({
        compartmentId: this._tenancyId
      });
      const compartments = compartmentsResponse.items || [];
      for (const compartment of compartments) {
        yield {
          provider: "oracle",
          accountId: this._accountId,
          region: null,
          service: "identity",
          resourceType: "oracle.identity.compartment",
          resourceId: compartment.id,
          name: compartment.name,
          tags: this._extractTags(compartment.freeformTags, compartment.definedTags),
          configuration: this._sanitize(compartment)
        };
      }
      this.logger("info", `Collected ${users.length} users, ${groups.length} groups, ${compartments.length} compartments`);
    } catch (err) {
      this.logger("error", "Failed to collect OCI identity", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS zones.
   */
  async *_collectDNS() {
    try {
      const { dns } = await import('oci-dns');
      const dnsClient = new dns.DnsClient({
        authenticationDetailsProvider: this._provider
      });
      const zonesResponse = await dnsClient.listZones({
        compartmentId: this._compartmentId
      });
      const zones = zonesResponse.items || [];
      for (const zone of zones) {
        yield {
          provider: "oracle",
          accountId: this._accountId,
          region: null,
          // DNS is global
          service: "dns",
          resourceType: "oracle.dns.zone",
          resourceId: zone.id,
          name: zone.name,
          tags: this._extractTags(zone.freeformTags, zone.definedTags),
          configuration: this._sanitize(zone)
        };
      }
      this.logger("info", `Collected ${zones.length} OCI DNS zones`);
    } catch (err) {
      this.logger("error", "Failed to collect OCI DNS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Get list of subscribed regions.
   */
  async _getRegions() {
    if (this._regions && Array.isArray(this._regions)) {
      const common = await import('oci-common');
      return this._regions.map((r) => ({ regionName: r, region: common.Region[r] }));
    }
    const { identity } = await import('oci-identity');
    const identityClient = new identity.IdentityClient({
      authenticationDetailsProvider: this._provider
    });
    const regionsResponse = await identityClient.listRegionSubscriptions({
      tenancyId: this._tenancyId
    });
    return regionsResponse.items || [];
  }
  /**
   * Extract tags from OCI freeform and defined tags.
   */
  _extractTags(freeformTags, definedTags) {
    const tags = {};
    if (freeformTags && typeof freeformTags === "object") {
      Object.assign(tags, freeformTags);
    }
    if (definedTags && typeof definedTags === "object") {
      for (const [namespace, namespaceTags] of Object.entries(definedTags)) {
        for (const [key, value] of Object.entries(namespaceTags)) {
          tags[`${namespace}.${key}`] = value;
        }
      }
    }
    return tags;
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "password",
      "adminPassword",
      "privateKey",
      "publicKey",
      "secret",
      "token",
      "connectionString",
      "connectionStrings"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class AzureInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "azure" });
    this._credential = null;
    this._subscriptionId = null;
    this._accountId = this.config?.accountId || "azure";
    this._services = this.config?.services || [
      "compute",
      "kubernetes",
      "storage",
      "disks",
      "databases",
      "cosmosdb",
      "network",
      "containerregistry",
      "dns",
      "identity"
    ];
    this._resourceGroups = this.config?.resourceGroups || null;
  }
  /**
   * Initialize Azure credential and subscription.
   */
  async _initializeCredential() {
    if (this._credential) return;
    const credentials = this.credentials || {};
    const { DefaultAzureCredential, ClientSecretCredential } = await import('@azure/identity');
    if (credentials.clientId && credentials.clientSecret && credentials.tenantId) {
      this._credential = new ClientSecretCredential(
        credentials.tenantId,
        credentials.clientId,
        credentials.clientSecret
      );
    } else {
      this._credential = new DefaultAzureCredential();
    }
    this._subscriptionId = credentials.subscriptionId || this.config?.subscriptionId;
    if (!this._subscriptionId) {
      throw new Error("Azure subscription ID is required. Provide via credentials.subscriptionId or config.subscriptionId.");
    }
    this.logger("info", "Azure credential initialized", {
      accountId: this._accountId,
      subscriptionId: this._subscriptionId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeCredential();
    const serviceCollectors = {
      compute: () => this._collectCompute(),
      kubernetes: () => this._collectKubernetes(),
      storage: () => this._collectStorage(),
      disks: () => this._collectDisks(),
      databases: () => this._collectDatabases(),
      cosmosdb: () => this._collectCosmosDB(),
      network: () => this._collectNetwork(),
      containerregistry: () => this._collectContainerRegistry(),
      dns: () => this._collectDNS(),
      identity: () => this._collectIdentity()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Azure service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Azure ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Azure service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Compute resources (VMs, VM scale sets).
   */
  async *_collectCompute() {
    try {
      const { ComputeManagementClient } = await import('@azure/arm-compute');
      const computeClient = new ComputeManagementClient(this._credential, this._subscriptionId);
      const vmsIterator = computeClient.virtualMachines.listAll();
      for await (const vm of vmsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: vm.location,
          service: "compute",
          resourceType: "azure.compute.virtualmachine",
          resourceId: vm.id,
          name: vm.name,
          tags: vm.tags || {},
          configuration: this._sanitize(vm)
        };
      }
      const scaleSetsIterator = computeClient.virtualMachineScaleSets.listAll();
      for await (const scaleSet of scaleSetsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: scaleSet.location,
          service: "compute",
          resourceType: "azure.compute.vmscaleset",
          resourceId: scaleSet.id,
          name: scaleSet.name,
          tags: scaleSet.tags || {},
          configuration: this._sanitize(scaleSet)
        };
      }
      this.logger("info", `Collected Azure compute resources`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure compute", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Kubernetes (AKS) clusters.
   */
  async *_collectKubernetes() {
    try {
      const { ContainerServiceClient } = await import('@azure/arm-containerservice');
      const aksClient = new ContainerServiceClient(this._credential, this._subscriptionId);
      const clustersIterator = aksClient.managedClusters.list();
      for await (const cluster of clustersIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: cluster.location,
          service: "kubernetes",
          resourceType: "azure.kubernetes.cluster",
          resourceId: cluster.id,
          name: cluster.name,
          tags: cluster.tags || {},
          configuration: this._sanitize(cluster)
        };
        if (cluster.agentPoolProfiles && Array.isArray(cluster.agentPoolProfiles)) {
          for (const pool of cluster.agentPoolProfiles) {
            yield {
              provider: "azure",
              accountId: this._accountId,
              region: cluster.location,
              service: "kubernetes",
              resourceType: "azure.kubernetes.nodepool",
              resourceId: `${cluster.id}/agentPools/${pool.name}`,
              name: pool.name,
              tags: {},
              metadata: { clusterId: cluster.id, clusterName: cluster.name },
              configuration: this._sanitize(pool)
            };
          }
        }
      }
      this.logger("info", `Collected Azure AKS clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure Kubernetes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Storage Accounts.
   */
  async *_collectStorage() {
    try {
      const { StorageManagementClient } = await import('@azure/arm-storage');
      const storageClient = new StorageManagementClient(this._credential, this._subscriptionId);
      const accountsIterator = storageClient.storageAccounts.list();
      for await (const account of accountsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: account.location,
          service: "storage",
          resourceType: "azure.storage.account",
          resourceId: account.id,
          name: account.name,
          tags: account.tags || {},
          configuration: this._sanitize(account)
        };
      }
      this.logger("info", `Collected Azure storage accounts`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Disks and Snapshots.
   */
  async *_collectDisks() {
    try {
      const { ComputeManagementClient } = await import('@azure/arm-compute');
      const computeClient = new ComputeManagementClient(this._credential, this._subscriptionId);
      const disksIterator = computeClient.disks.list();
      for await (const disk of disksIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: disk.location,
          service: "disks",
          resourceType: "azure.disk",
          resourceId: disk.id,
          name: disk.name,
          tags: disk.tags || {},
          configuration: this._sanitize(disk)
        };
      }
      const snapshotsIterator = computeClient.snapshots.list();
      for await (const snapshot of snapshotsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: snapshot.location,
          service: "disks",
          resourceType: "azure.snapshot",
          resourceId: snapshot.id,
          name: snapshot.name,
          tags: snapshot.tags || {},
          configuration: this._sanitize(snapshot)
        };
      }
      this.logger("info", `Collected Azure disks and snapshots`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure disks", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SQL Databases.
   */
  async *_collectDatabases() {
    try {
      const { SqlManagementClient } = await import('@azure/arm-sql');
      const sqlClient = new SqlManagementClient(this._credential, this._subscriptionId);
      const serversIterator = sqlClient.servers.list();
      for await (const server of serversIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: server.location,
          service: "databases",
          resourceType: "azure.sql.server",
          resourceId: server.id,
          name: server.name,
          tags: server.tags || {},
          configuration: this._sanitize(server)
        };
        try {
          const resourceGroupName = this._extractResourceGroup(server.id);
          const databasesIterator = sqlClient.databases.listByServer(resourceGroupName, server.name);
          for await (const database of databasesIterator) {
            yield {
              provider: "azure",
              accountId: this._accountId,
              region: database.location,
              service: "databases",
              resourceType: "azure.sql.database",
              resourceId: database.id,
              name: database.name,
              tags: database.tags || {},
              metadata: { serverId: server.id, serverName: server.name },
              configuration: this._sanitize(database)
            };
          }
        } catch (dbErr) {
          this.logger("warn", `Failed to collect databases for server ${server.name}`, {
            serverId: server.id,
            error: dbErr.message
          });
        }
      }
      this.logger("info", `Collected Azure SQL databases`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure databases", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Cosmos DB accounts.
   */
  async *_collectCosmosDB() {
    try {
      const { CosmosDBManagementClient } = await import('@azure/arm-cosmosdb');
      const cosmosClient = new CosmosDBManagementClient(this._credential, this._subscriptionId);
      const accountsIterator = cosmosClient.databaseAccounts.list();
      for await (const account of accountsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: account.location,
          service: "cosmosdb",
          resourceType: "azure.cosmosdb.account",
          resourceId: account.id,
          name: account.name,
          tags: account.tags || {},
          configuration: this._sanitize(account)
        };
      }
      this.logger("info", `Collected Azure Cosmos DB accounts`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure Cosmos DB", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Network resources (VNets, Subnets, Load Balancers, Public IPs).
   */
  async *_collectNetwork() {
    try {
      const { NetworkManagementClient } = await import('@azure/arm-network');
      const networkClient = new NetworkManagementClient(this._credential, this._subscriptionId);
      const vnetsIterator = networkClient.virtualNetworks.listAll();
      for await (const vnet of vnetsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: vnet.location,
          service: "network",
          resourceType: "azure.network.virtualnetwork",
          resourceId: vnet.id,
          name: vnet.name,
          tags: vnet.tags || {},
          configuration: this._sanitize(vnet)
        };
        if (vnet.subnets && Array.isArray(vnet.subnets)) {
          for (const subnet of vnet.subnets) {
            yield {
              provider: "azure",
              accountId: this._accountId,
              region: vnet.location,
              service: "network",
              resourceType: "azure.network.subnet",
              resourceId: subnet.id,
              name: subnet.name,
              tags: {},
              metadata: { vnetId: vnet.id, vnetName: vnet.name },
              configuration: this._sanitize(subnet)
            };
          }
        }
      }
      const lbsIterator = networkClient.loadBalancers.listAll();
      for await (const lb of lbsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: lb.location,
          service: "network",
          resourceType: "azure.network.loadbalancer",
          resourceId: lb.id,
          name: lb.name,
          tags: lb.tags || {},
          configuration: this._sanitize(lb)
        };
      }
      const ipsIterator = networkClient.publicIPAddresses.listAll();
      for await (const ip of ipsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: ip.location,
          service: "network",
          resourceType: "azure.network.publicip",
          resourceId: ip.id,
          name: ip.name,
          tags: ip.tags || {},
          configuration: this._sanitize(ip)
        };
      }
      const nsgsIterator = networkClient.networkSecurityGroups.listAll();
      for await (const nsg of nsgsIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: nsg.location,
          service: "network",
          resourceType: "azure.network.securitygroup",
          resourceId: nsg.id,
          name: nsg.name,
          tags: nsg.tags || {},
          configuration: this._sanitize(nsg)
        };
      }
      this.logger("info", `Collected Azure network resources`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure network", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Container Registry.
   */
  async *_collectContainerRegistry() {
    try {
      const { ContainerRegistryManagementClient } = await import('@azure/arm-containerregistry');
      const acrClient = new ContainerRegistryManagementClient(this._credential, this._subscriptionId);
      const registriesIterator = acrClient.registries.list();
      for await (const registry of registriesIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: registry.location,
          service: "containerregistry",
          resourceType: "azure.containerregistry",
          resourceId: registry.id,
          name: registry.name,
          tags: registry.tags || {},
          configuration: this._sanitize(registry)
        };
      }
      this.logger("info", `Collected Azure container registries`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure container registry", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS zones.
   */
  async *_collectDNS() {
    try {
      const { DnsManagementClient } = await import('@azure/arm-dns');
      const dnsClient = new DnsManagementClient(this._credential, this._subscriptionId);
      const zonesIterator = dnsClient.zones.list();
      for await (const zone of zonesIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: zone.location,
          service: "dns",
          resourceType: "azure.dns.zone",
          resourceId: zone.id,
          name: zone.name,
          tags: zone.tags || {},
          configuration: this._sanitize(zone)
        };
      }
      this.logger("info", `Collected Azure DNS zones`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure DNS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Managed Identities.
   */
  async *_collectIdentity() {
    try {
      const { ManagedServiceIdentityClient } = await import('@azure/arm-msi');
      const identityClient = new ManagedServiceIdentityClient(this._credential, this._subscriptionId);
      const identitiesIterator = identityClient.userAssignedIdentities.listBySubscription();
      for await (const identity of identitiesIterator) {
        yield {
          provider: "azure",
          accountId: this._accountId,
          region: identity.location,
          service: "identity",
          resourceType: "azure.identity.userassigned",
          resourceId: identity.id,
          name: identity.name,
          tags: identity.tags || {},
          configuration: this._sanitize(identity)
        };
      }
      this.logger("info", `Collected Azure managed identities`);
    } catch (err) {
      this.logger("error", "Failed to collect Azure identity", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Extract resource group name from Azure resource ID.
   */
  _extractResourceGroup(resourceId) {
    if (!resourceId) return null;
    const match = resourceId.match(/\/resourceGroups\/([^\/]+)/i);
    return match ? match[1] : null;
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "administratorLogin",
      "administratorLoginPassword",
      "password",
      "adminPassword",
      "adminUsername",
      "connectionString",
      "primaryKey",
      "secondaryKey",
      "keys",
      "secret",
      "token"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class LinodeInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "linode" });
    this._apiToken = null;
    this._accountId = this.config?.accountId || "linode";
    this._services = this.config?.services || [
      "linodes",
      "kubernetes",
      "volumes",
      "nodebalancers",
      "firewalls",
      "vlans",
      "domains",
      "images",
      "objectstorage",
      "databases",
      "stackscripts",
      "placementgroups"
    ];
    this._regions = this.config?.regions || null;
  }
  /**
   * Initialize Linode API client.
   */
  async _initializeClient() {
    if (this._apiToken) return;
    const credentials = this.credentials || {};
    this._apiToken = credentials.token || credentials.apiToken || process.env.LINODE_TOKEN;
    if (!this._apiToken) {
      throw new Error("Linode API token is required. Provide via credentials.token or LINODE_TOKEN env var.");
    }
    const { setToken } = await import('@linode/api-v4');
    setToken(this._apiToken);
    this.logger("info", "Linode API client initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeClient();
    const serviceCollectors = {
      linodes: () => this._collectLinodes(),
      kubernetes: () => this._collectKubernetes(),
      volumes: () => this._collectVolumes(),
      nodebalancers: () => this._collectNodeBalancers(),
      firewalls: () => this._collectFirewalls(),
      vlans: () => this._collectVLANs(),
      domains: () => this._collectDomains(),
      images: () => this._collectImages(),
      objectstorage: () => this._collectObjectStorage(),
      databases: () => this._collectDatabases(),
      stackscripts: () => this._collectStackScripts(),
      placementgroups: () => this._collectPlacementGroups()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Linode service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Linode ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Linode service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Linodes (compute instances).
   */
  async *_collectLinodes() {
    try {
      const { getLinodes } = await import('@linode/api-v4/lib/linodes');
      const response = await getLinodes();
      const linodes = response.data || [];
      for (const linode of linodes) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: linode.region,
          service: "linodes",
          resourceType: "linode.compute.instance",
          resourceId: linode.id?.toString(),
          name: linode.label,
          tags: linode.tags || [],
          configuration: this._sanitize(linode)
        };
      }
      this.logger("info", `Collected ${linodes.length} Linode instances`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode instances", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Kubernetes (LKE) clusters.
   */
  async *_collectKubernetes() {
    try {
      const { getKubernetesClusters, getKubernetesClusterPools } = await import('@linode/api-v4/lib/kubernetes');
      const response = await getKubernetesClusters();
      const clusters = response.data || [];
      for (const cluster of clusters) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: cluster.region,
          service: "kubernetes",
          resourceType: "linode.kubernetes.cluster",
          resourceId: cluster.id?.toString(),
          name: cluster.label,
          tags: cluster.tags || [],
          configuration: this._sanitize(cluster)
        };
        try {
          const poolsResponse = await getKubernetesClusterPools(cluster.id);
          const pools = poolsResponse.data || [];
          for (const pool of pools) {
            yield {
              provider: "linode",
              accountId: this._accountId,
              region: cluster.region,
              service: "kubernetes",
              resourceType: "linode.kubernetes.nodepool",
              resourceId: pool.id?.toString(),
              name: `${cluster.label}-${pool.type}`,
              tags: cluster.tags || [],
              metadata: { clusterId: cluster.id, clusterLabel: cluster.label },
              configuration: this._sanitize(pool)
            };
          }
        } catch (poolErr) {
          this.logger("warn", `Failed to collect node pools for cluster ${cluster.id}`, {
            clusterId: cluster.id,
            error: poolErr.message
          });
        }
      }
      this.logger("info", `Collected ${clusters.length} Linode Kubernetes clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode Kubernetes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Block Storage volumes.
   */
  async *_collectVolumes() {
    try {
      const { getVolumes } = await import('@linode/api-v4/lib/volumes');
      const response = await getVolumes();
      const volumes = response.data || [];
      for (const volume of volumes) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: volume.region,
          service: "volumes",
          resourceType: "linode.volume",
          resourceId: volume.id?.toString(),
          name: volume.label,
          tags: volume.tags || [],
          configuration: this._sanitize(volume)
        };
      }
      this.logger("info", `Collected ${volumes.length} Linode volumes`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode volumes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect NodeBalancers (load balancers).
   */
  async *_collectNodeBalancers() {
    try {
      const { getNodeBalancers } = await import('@linode/api-v4/lib/nodebalancers');
      const response = await getNodeBalancers();
      const nodebalancers = response.data || [];
      for (const nb of nodebalancers) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: nb.region,
          service: "nodebalancers",
          resourceType: "linode.nodebalancer",
          resourceId: nb.id?.toString(),
          name: nb.label,
          tags: nb.tags || [],
          configuration: this._sanitize(nb)
        };
      }
      this.logger("info", `Collected ${nodebalancers.length} Linode NodeBalancers`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode NodeBalancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Firewalls.
   */
  async *_collectFirewalls() {
    try {
      const { getFirewalls } = await import('@linode/api-v4/lib/firewalls');
      const response = await getFirewalls();
      const firewalls = response.data || [];
      for (const firewall of firewalls) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: null,
          // Firewalls are global
          service: "firewalls",
          resourceType: "linode.firewall",
          resourceId: firewall.id?.toString(),
          name: firewall.label,
          tags: firewall.tags || [],
          configuration: this._sanitize(firewall)
        };
      }
      this.logger("info", `Collected ${firewalls.length} Linode firewalls`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode firewalls", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect VLANs.
   */
  async *_collectVLANs() {
    try {
      const { getVLANs } = await import('@linode/api-v4/lib/vlans');
      const response = await getVLANs();
      const vlans = response.data || [];
      for (const vlan of vlans) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: vlan.region,
          service: "vlans",
          resourceType: "linode.vlan",
          resourceId: vlan.label,
          // VLANs use label as ID
          name: vlan.label,
          tags: [],
          configuration: this._sanitize(vlan)
        };
      }
      this.logger("info", `Collected ${vlans.length} Linode VLANs`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode VLANs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS domains and records.
   */
  async *_collectDomains() {
    try {
      const { getDomains, getDomainRecords } = await import('@linode/api-v4/lib/domains');
      const response = await getDomains();
      const domains = response.data || [];
      for (const domain of domains) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: null,
          // DNS is global
          service: "domains",
          resourceType: "linode.dns.domain",
          resourceId: domain.id?.toString(),
          name: domain.domain,
          tags: domain.tags || [],
          configuration: this._sanitize(domain)
        };
        try {
          const recordsResponse = await getDomainRecords(domain.id);
          const records = recordsResponse.data || [];
          for (const record of records) {
            yield {
              provider: "linode",
              accountId: this._accountId,
              region: null,
              service: "domains",
              resourceType: "linode.dns.record",
              resourceId: `${domain.id}/${record.id}`,
              name: `${record.name}.${domain.domain}`,
              tags: [],
              metadata: { domainId: domain.id, domain: domain.domain },
              configuration: this._sanitize(record)
            };
          }
        } catch (recordErr) {
          this.logger("warn", `Failed to collect DNS records for domain ${domain.domain}`, {
            domainId: domain.id,
            error: recordErr.message
          });
        }
      }
      this.logger("info", `Collected ${domains.length} Linode DNS domains`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode domains", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect custom Images.
   */
  async *_collectImages() {
    try {
      const { getImages } = await import('@linode/api-v4/lib/images');
      const response = await getImages();
      const images = response.data || [];
      const customImages = images.filter((img) => img.is_public === false);
      for (const image of customImages) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: image.region || null,
          service: "images",
          resourceType: "linode.image",
          resourceId: image.id,
          name: image.label,
          tags: [],
          configuration: this._sanitize(image)
        };
      }
      this.logger("info", `Collected ${customImages.length} custom Linode images`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode images", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Object Storage buckets.
   */
  async *_collectObjectStorage() {
    try {
      const { getObjectStorageBuckets } = await import('@linode/api-v4/lib/object-storage');
      const response = await getObjectStorageBuckets();
      const buckets = response.data || [];
      for (const bucket of buckets) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: bucket.region,
          service: "objectstorage",
          resourceType: "linode.objectstorage.bucket",
          resourceId: `${bucket.cluster}/${bucket.label}`,
          name: bucket.label,
          tags: [],
          metadata: { cluster: bucket.cluster },
          configuration: this._sanitize(bucket)
        };
      }
      this.logger("info", `Collected ${buckets.length} Linode object storage buckets`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode object storage", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Managed Databases (MySQL, PostgreSQL, MongoDB).
   */
  async *_collectDatabases() {
    try {
      const { getDatabases } = await import('@linode/api-v4/lib/databases');
      const response = await getDatabases();
      const databases = response.data || [];
      for (const db of databases) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: db.region,
          service: "databases",
          resourceType: "linode.database",
          resourceId: db.id?.toString(),
          name: db.label,
          tags: [],
          metadata: {
            engine: db.engine,
            version: db.version,
            status: db.status
          },
          configuration: this._sanitize(db)
        };
      }
      this.logger("info", `Collected ${databases.length} Linode databases`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode databases", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect StackScripts (deployment scripts).
   */
  async *_collectStackScripts() {
    try {
      const { getStackScripts } = await import('@linode/api-v4/lib/stackscripts');
      const response = await getStackScripts({ mine: true });
      const stackScripts = response.data || [];
      for (const script of stackScripts) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: null,
          // StackScripts are global
          service: "stackscripts",
          resourceType: "linode.stackscript",
          resourceId: script.id?.toString(),
          name: script.label,
          tags: [],
          metadata: {
            isPublic: script.is_public,
            deploymentsTotal: script.deployments_total
          },
          configuration: this._sanitize(script)
        };
      }
      this.logger("info", `Collected ${stackScripts.length} Linode StackScripts`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode StackScripts", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Placement Groups (anti-affinity groups).
   */
  async *_collectPlacementGroups() {
    try {
      const { getPlacementGroups } = await import('@linode/api-v4/lib/placement-groups');
      const response = await getPlacementGroups();
      const placementGroups = response.data || [];
      for (const pg of placementGroups) {
        yield {
          provider: "linode",
          accountId: this._accountId,
          region: pg.region,
          service: "placementgroups",
          resourceType: "linode.placementgroup",
          resourceId: pg.id?.toString(),
          name: pg.label,
          tags: [],
          metadata: {
            placementGroupType: pg.placement_group_type,
            placementGroupPolicy: pg.placement_group_policy
          },
          configuration: this._sanitize(pg)
        };
      }
      this.logger("info", `Collected ${placementGroups.length} Linode placement groups`);
    } catch (err) {
      this.logger("error", "Failed to collect Linode placement groups", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "root_pass",
      "password",
      "token",
      "secret",
      "api_key",
      "private_key",
      "public_key"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class HetznerInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "hetzner" });
    this._apiToken = null;
    this._client = null;
    this._accountId = this.config?.accountId || "hetzner";
    this._services = this.config?.services || [
      "servers",
      "volumes",
      "networks",
      "loadbalancers",
      "firewalls",
      "floatingips",
      "sshkeys",
      "images",
      "certificates",
      "primaryips",
      "placementgroups",
      "isos"
    ];
  }
  /**
   * Initialize Hetzner Cloud API client.
   */
  async _initializeClient() {
    if (this._client) return;
    const credentials = this.credentials || {};
    this._apiToken = credentials.token || credentials.apiToken || process.env.HETZNER_TOKEN;
    if (!this._apiToken) {
      throw new Error("Hetzner API token is required. Provide via credentials.token or HETZNER_TOKEN env var.");
    }
    const hcloud = await import('hcloud-js');
    this._client = new hcloud.Client(this._apiToken);
    this.logger("info", "Hetzner Cloud API client initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeClient();
    const serviceCollectors = {
      servers: () => this._collectServers(),
      volumes: () => this._collectVolumes(),
      networks: () => this._collectNetworks(),
      loadbalancers: () => this._collectLoadBalancers(),
      firewalls: () => this._collectFirewalls(),
      floatingips: () => this._collectFloatingIPs(),
      sshkeys: () => this._collectSSHKeys(),
      images: () => this._collectImages(),
      certificates: () => this._collectCertificates(),
      primaryips: () => this._collectPrimaryIPs(),
      placementgroups: () => this._collectPlacementGroups(),
      isos: () => this._collectISOs()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Hetzner service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Hetzner ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Hetzner service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Servers (VPS).
   */
  async *_collectServers() {
    try {
      const response = await this._client.servers.list();
      const servers = response.servers || [];
      for (const server of servers) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: server.datacenter?.location?.name || null,
          service: "servers",
          resourceType: "hetzner.server",
          resourceId: server.id?.toString(),
          name: server.name,
          tags: this._extractLabels(server.labels),
          configuration: this._sanitize(server)
        };
      }
      this.logger("info", `Collected ${servers.length} Hetzner servers`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner servers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Volumes (block storage).
   */
  async *_collectVolumes() {
    try {
      const response = await this._client.volumes.list();
      const volumes = response.volumes || [];
      for (const volume of volumes) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: volume.location?.name || null,
          service: "volumes",
          resourceType: "hetzner.volume",
          resourceId: volume.id?.toString(),
          name: volume.name,
          tags: this._extractLabels(volume.labels),
          configuration: this._sanitize(volume)
        };
      }
      this.logger("info", `Collected ${volumes.length} Hetzner volumes`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner volumes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Networks (private networks/VPC).
   */
  async *_collectNetworks() {
    try {
      const response = await this._client.networks.list();
      const networks = response.networks || [];
      for (const network of networks) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // Networks span multiple locations
          service: "networks",
          resourceType: "hetzner.network",
          resourceId: network.id?.toString(),
          name: network.name,
          tags: this._extractLabels(network.labels),
          configuration: this._sanitize(network)
        };
        if (network.subnets && Array.isArray(network.subnets)) {
          for (const subnet of network.subnets) {
            yield {
              provider: "hetzner",
              accountId: this._accountId,
              region: subnet.network_zone,
              service: "networks",
              resourceType: "hetzner.network.subnet",
              resourceId: `${network.id}/subnet/${subnet.ip_range}`,
              name: `${network.name}-${subnet.type}`,
              tags: {},
              metadata: { networkId: network.id, networkName: network.name },
              configuration: this._sanitize(subnet)
            };
          }
        }
      }
      this.logger("info", `Collected ${networks.length} Hetzner networks`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner networks", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Load Balancers.
   */
  async *_collectLoadBalancers() {
    try {
      const response = await this._client.loadBalancers.list();
      const loadBalancers = response.load_balancers || [];
      for (const lb of loadBalancers) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: lb.location?.name || null,
          service: "loadbalancers",
          resourceType: "hetzner.loadbalancer",
          resourceId: lb.id?.toString(),
          name: lb.name,
          tags: this._extractLabels(lb.labels),
          configuration: this._sanitize(lb)
        };
      }
      this.logger("info", `Collected ${loadBalancers.length} Hetzner load balancers`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner load balancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Firewalls.
   */
  async *_collectFirewalls() {
    try {
      const response = await this._client.firewalls.list();
      const firewalls = response.firewalls || [];
      for (const firewall of firewalls) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // Firewalls are global
          service: "firewalls",
          resourceType: "hetzner.firewall",
          resourceId: firewall.id?.toString(),
          name: firewall.name,
          tags: this._extractLabels(firewall.labels),
          configuration: this._sanitize(firewall)
        };
      }
      this.logger("info", `Collected ${firewalls.length} Hetzner firewalls`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner firewalls", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Floating IPs.
   */
  async *_collectFloatingIPs() {
    try {
      const response = await this._client.floatingIPs.list();
      const floatingIPs = response.floating_ips || [];
      for (const fip of floatingIPs) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: fip.home_location?.name || null,
          service: "floatingips",
          resourceType: "hetzner.floatingip",
          resourceId: fip.id?.toString(),
          name: fip.name || fip.ip,
          tags: this._extractLabels(fip.labels),
          configuration: this._sanitize(fip)
        };
      }
      this.logger("info", `Collected ${floatingIPs.length} Hetzner floating IPs`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner floating IPs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SSH Keys.
   */
  async *_collectSSHKeys() {
    try {
      const response = await this._client.sshKeys.list();
      const sshKeys = response.ssh_keys || [];
      for (const key of sshKeys) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // SSH keys are global
          service: "sshkeys",
          resourceType: "hetzner.sshkey",
          resourceId: key.id?.toString(),
          name: key.name,
          tags: this._extractLabels(key.labels),
          configuration: this._sanitize(key)
        };
      }
      this.logger("info", `Collected ${sshKeys.length} Hetzner SSH keys`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner SSH keys", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect custom Images.
   */
  async *_collectImages() {
    try {
      const response = await this._client.images.list();
      const images = response.images || [];
      const customImages = images.filter((img) => img.type === "snapshot" || img.type === "backup");
      for (const image of customImages) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // Images are global
          service: "images",
          resourceType: "hetzner.image",
          resourceId: image.id?.toString(),
          name: image.description || image.name || image.id?.toString(),
          tags: this._extractLabels(image.labels),
          configuration: this._sanitize(image)
        };
      }
      this.logger("info", `Collected ${customImages.length} custom Hetzner images`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner images", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SSL Certificates.
   */
  async *_collectCertificates() {
    try {
      const response = await this._client.certificates.list();
      const certificates = response.certificates || [];
      for (const cert of certificates) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // Certificates are global
          service: "certificates",
          resourceType: "hetzner.certificate",
          resourceId: cert.id?.toString(),
          name: cert.name,
          tags: this._extractLabels(cert.labels),
          configuration: this._sanitize(cert)
        };
      }
      this.logger("info", `Collected ${certificates.length} Hetzner certificates`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner certificates", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Primary IPs (independent public IPs).
   */
  async *_collectPrimaryIPs() {
    try {
      const response = await this._client.primaryIPs.list();
      const primaryIPs = response.primary_ips || [];
      for (const ip of primaryIPs) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: ip.datacenter?.location?.name || null,
          service: "primaryips",
          resourceType: "hetzner.primaryip",
          resourceId: ip.id?.toString(),
          name: ip.name || ip.ip,
          tags: this._extractLabels(ip.labels),
          metadata: {
            type: ip.type,
            // ipv4 or ipv6
            assignedToId: ip.assignee_id
          },
          configuration: this._sanitize(ip)
        };
      }
      this.logger("info", `Collected ${primaryIPs.length} Hetzner primary IPs`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner primary IPs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Placement Groups (server anti-affinity).
   */
  async *_collectPlacementGroups() {
    try {
      const response = await this._client.placementGroups.list();
      const placementGroups = response.placement_groups || [];
      for (const pg of placementGroups) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // Placement groups are global
          service: "placementgroups",
          resourceType: "hetzner.placementgroup",
          resourceId: pg.id?.toString(),
          name: pg.name,
          tags: this._extractLabels(pg.labels),
          metadata: {
            type: pg.type,
            servers: pg.servers || []
          },
          configuration: this._sanitize(pg)
        };
      }
      this.logger("info", `Collected ${placementGroups.length} Hetzner placement groups`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner placement groups", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect ISOs (custom installation images).
   */
  async *_collectISOs() {
    try {
      const response = await this._client.isos.list();
      const isos = response.isos || [];
      for (const iso of isos) {
        yield {
          provider: "hetzner",
          accountId: this._accountId,
          region: null,
          // ISOs are global
          service: "isos",
          resourceType: "hetzner.iso",
          resourceId: iso.id?.toString(),
          name: iso.name,
          tags: {},
          metadata: {
            type: iso.type,
            deprecated: iso.deprecated,
            deprecation: iso.deprecation
          },
          configuration: this._sanitize(iso)
        };
      }
      this.logger("info", `Collected ${isos.length} Hetzner ISOs`);
    } catch (err) {
      this.logger("error", "Failed to collect Hetzner ISOs", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Extract labels from Hetzner labels object.
   */
  _extractLabels(labels) {
    if (!labels || typeof labels !== "object") return {};
    return { ...labels };
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "root_password",
      "password",
      "token",
      "secret",
      "api_key",
      "private_key",
      "public_key",
      "certificate",
      "private_key"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class AlibabaInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "alibaba" });
    this._accessKeyId = null;
    this._accessKeySecret = null;
    this._accountId = this.config?.accountId || "alibaba";
    this._services = this.config?.services || [
      "ecs",
      "ack",
      "oss",
      "rds",
      "redis",
      "vpc",
      "slb",
      "eip",
      "cdn",
      "dns",
      "securitygroups",
      "snapshots",
      "autoscaling",
      "natgateway",
      "acr"
    ];
    this._regions = this.config?.regions || ["cn-hangzhou", "cn-shanghai", "cn-beijing"];
  }
  /**
   * Initialize Alibaba Cloud credentials.
   */
  async _initializeCredentials() {
    if (this._accessKeyId) return;
    const credentials = this.credentials || {};
    this._accessKeyId = credentials.accessKeyId || process.env.ALIBABA_CLOUD_ACCESS_KEY_ID;
    this._accessKeySecret = credentials.accessKeySecret || process.env.ALIBABA_CLOUD_ACCESS_KEY_SECRET;
    if (!this._accessKeyId || !this._accessKeySecret) {
      throw new Error("Alibaba Cloud AccessKeyId and AccessKeySecret are required. Provide via credentials or env vars.");
    }
    this.logger("info", "Alibaba Cloud credentials initialized", {
      accountId: this._accountId,
      services: this._services.length,
      regions: this._regions.length
    });
  }
  /**
   * Create RPC client for a specific service.
   */
  async _createRPCClient(endpoint, apiVersion) {
    const RPCClient = await import('@alicloud/pop-core');
    return new RPCClient.default({
      accessKeyId: this._accessKeyId,
      accessKeySecret: this._accessKeySecret,
      endpoint,
      apiVersion
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeCredentials();
    const serviceCollectors = {
      ecs: () => this._collectECS(),
      ack: () => this._collectACK(),
      oss: () => this._collectOSS(),
      rds: () => this._collectRDS(),
      redis: () => this._collectRedis(),
      vpc: () => this._collectVPC(),
      slb: () => this._collectSLB(),
      eip: () => this._collectEIP(),
      cdn: () => this._collectCDN(),
      dns: () => this._collectDNS(),
      securitygroups: () => this._collectSecurityGroups(),
      snapshots: () => this._collectSnapshots(),
      autoscaling: () => this._collectAutoScaling(),
      natgateway: () => this._collectNATGateway(),
      acr: () => this._collectACR()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Alibaba Cloud service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Alibaba Cloud ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Alibaba Cloud service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect ECS instances.
   */
  async *_collectECS() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://ecs.${region}.aliyuncs.com`, "2014-05-26");
        const params = {
          RegionId: region,
          PageSize: 100
        };
        const response = await client.request("DescribeInstances", params, { method: "POST" });
        const instances = response.Instances?.Instance || [];
        for (const instance of instances) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "ecs",
            resourceType: "alibaba.ecs.instance",
            resourceId: instance.InstanceId,
            name: instance.InstanceName,
            tags: this._extractTags(instance.Tags?.Tag),
            configuration: this._sanitize(instance)
          };
        }
        this.logger("info", `Collected ${instances.length} ECS instances in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud ECS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect ACK (Container Service for Kubernetes) clusters.
   */
  async *_collectACK() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://cs.${region}.aliyuncs.com`, "2015-12-15");
        try {
          const response = await client.request("DescribeClustersV1", {}, { method: "GET" });
          const clusters = response.clusters || [];
          for (const cluster of clusters) {
            yield {
              provider: "alibaba",
              accountId: this._accountId,
              region,
              service: "ack",
              resourceType: "alibaba.ack.cluster",
              resourceId: cluster.cluster_id,
              name: cluster.name,
              tags: this._extractTags(cluster.tags),
              configuration: this._sanitize(cluster)
            };
          }
          this.logger("info", `Collected ${clusters.length} ACK clusters in ${region}`);
        } catch (regionErr) {
          this.logger("debug", `ACK not available in ${region}`, { region, error: regionErr.message });
        }
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud ACK", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect OSS buckets.
   */
  async *_collectOSS() {
    try {
      const OSS = await import('ali-oss');
      const ossClient = new OSS.default({
        accessKeyId: this._accessKeyId,
        accessKeySecret: this._accessKeySecret,
        region: this._regions[0]
        // Use first region as default
      });
      const response = await ossClient.listBuckets();
      const buckets = response.buckets || [];
      for (const bucket of buckets) {
        yield {
          provider: "alibaba",
          accountId: this._accountId,
          region: bucket.region,
          service: "oss",
          resourceType: "alibaba.oss.bucket",
          resourceId: bucket.name,
          name: bucket.name,
          tags: {},
          configuration: this._sanitize(bucket)
        };
      }
      this.logger("info", `Collected ${buckets.length} OSS buckets`);
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud OSS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect RDS instances.
   */
  async *_collectRDS() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://rds.${region}.aliyuncs.com`, "2014-08-15");
        const params = {
          RegionId: region,
          PageSize: 100
        };
        const response = await client.request("DescribeDBInstances", params, { method: "POST" });
        const instances = response.Items?.DBInstance || [];
        for (const instance of instances) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "rds",
            resourceType: "alibaba.rds.instance",
            resourceId: instance.DBInstanceId,
            name: instance.DBInstanceDescription || instance.DBInstanceId,
            tags: this._extractTags(instance.Tags?.Tag),
            configuration: this._sanitize(instance)
          };
        }
        this.logger("info", `Collected ${instances.length} RDS instances in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud RDS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Redis instances.
   */
  async *_collectRedis() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://r-kvstore.${region}.aliyuncs.com`, "2015-01-01");
        const params = {
          RegionId: region,
          PageSize: 100
        };
        const response = await client.request("DescribeInstances", params, { method: "POST" });
        const instances = response.Instances?.KVStoreInstance || [];
        for (const instance of instances) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "redis",
            resourceType: "alibaba.redis.instance",
            resourceId: instance.InstanceId,
            name: instance.InstanceName,
            tags: this._extractTags(instance.Tags?.Tag),
            configuration: this._sanitize(instance)
          };
        }
        this.logger("info", `Collected ${instances.length} Redis instances in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud Redis", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect VPC resources.
   */
  async *_collectVPC() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://vpc.${region}.aliyuncs.com`, "2016-04-28");
        const vpcParams = {
          RegionId: region,
          PageSize: 50
        };
        const vpcResponse = await client.request("DescribeVpcs", vpcParams, { method: "POST" });
        const vpcs = vpcResponse.Vpcs?.Vpc || [];
        for (const vpc of vpcs) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "vpc",
            resourceType: "alibaba.vpc.network",
            resourceId: vpc.VpcId,
            name: vpc.VpcName,
            tags: this._extractTags(vpc.Tags?.Tag),
            configuration: this._sanitize(vpc)
          };
          try {
            const vswitchParams = {
              VpcId: vpc.VpcId,
              PageSize: 50
            };
            const vswitchResponse = await client.request("DescribeVSwitches", vswitchParams, { method: "POST" });
            const vswitches = vswitchResponse.VSwitches?.VSwitch || [];
            for (const vswitch of vswitches) {
              yield {
                provider: "alibaba",
                accountId: this._accountId,
                region,
                service: "vpc",
                resourceType: "alibaba.vpc.vswitch",
                resourceId: vswitch.VSwitchId,
                name: vswitch.VSwitchName,
                tags: this._extractTags(vswitch.Tags?.Tag),
                metadata: { vpcId: vpc.VpcId, vpcName: vpc.VpcName },
                configuration: this._sanitize(vswitch)
              };
            }
          } catch (vswitchErr) {
            this.logger("warn", `Failed to collect vSwitches for VPC ${vpc.VpcId}`, {
              vpcId: vpc.VpcId,
              error: vswitchErr.message
            });
          }
        }
        this.logger("info", `Collected ${vpcs.length} VPCs in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud VPC", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SLB (Server Load Balancer) instances.
   */
  async *_collectSLB() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://slb.${region}.aliyuncs.com`, "2014-05-15");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeLoadBalancers", params, { method: "POST" });
        const loadBalancers = response.LoadBalancers?.LoadBalancer || [];
        for (const lb of loadBalancers) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "slb",
            resourceType: "alibaba.slb.loadbalancer",
            resourceId: lb.LoadBalancerId,
            name: lb.LoadBalancerName,
            tags: this._extractTags(lb.Tags?.Tag),
            configuration: this._sanitize(lb)
          };
        }
        this.logger("info", `Collected ${loadBalancers.length} SLB instances in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud SLB", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect EIP (Elastic IP) addresses.
   */
  async *_collectEIP() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://vpc.${region}.aliyuncs.com`, "2016-04-28");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeEipAddresses", params, { method: "POST" });
        const eips = response.EipAddresses?.EipAddress || [];
        for (const eip of eips) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "eip",
            resourceType: "alibaba.eip",
            resourceId: eip.AllocationId,
            name: eip.Name || eip.IpAddress,
            tags: this._extractTags(eip.Tags?.Tag),
            configuration: this._sanitize(eip)
          };
        }
        this.logger("info", `Collected ${eips.length} EIPs in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud EIP", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect CDN domains.
   */
  async *_collectCDN() {
    try {
      const client = await this._createRPCClient("https://cdn.aliyuncs.com", "2018-05-10");
      const params = {
        PageSize: 50
      };
      const response = await client.request("DescribeUserDomains", params, { method: "POST" });
      const domains = response.Domains?.PageData || [];
      for (const domain of domains) {
        yield {
          provider: "alibaba",
          accountId: this._accountId,
          region: null,
          // CDN is global
          service: "cdn",
          resourceType: "alibaba.cdn.domain",
          resourceId: domain.DomainName,
          name: domain.DomainName,
          tags: {},
          configuration: this._sanitize(domain)
        };
      }
      this.logger("info", `Collected ${domains.length} CDN domains`);
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud CDN", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect DNS domains.
   */
  async *_collectDNS() {
    try {
      const client = await this._createRPCClient("https://alidns.aliyuncs.com", "2015-01-09");
      const params = {
        PageSize: 100
      };
      const response = await client.request("DescribeDomains", params, { method: "POST" });
      const domains = response.Domains?.Domain || [];
      for (const domain of domains) {
        yield {
          provider: "alibaba",
          accountId: this._accountId,
          region: null,
          // DNS is global
          service: "dns",
          resourceType: "alibaba.dns.domain",
          resourceId: domain.DomainId,
          name: domain.DomainName,
          tags: this._extractTags(domain.Tags?.Tag),
          configuration: this._sanitize(domain)
        };
      }
      this.logger("info", `Collected ${domains.length} DNS domains`);
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud DNS", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Security Groups.
   */
  async *_collectSecurityGroups() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://ecs.${region}.aliyuncs.com`, "2014-05-26");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeSecurityGroups", params, { method: "POST" });
        const securityGroups = response.SecurityGroups?.SecurityGroup || [];
        for (const sg of securityGroups) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "securitygroups",
            resourceType: "alibaba.ecs.securitygroup",
            resourceId: sg.SecurityGroupId,
            name: sg.SecurityGroupName,
            tags: this._extractTags(sg.Tags?.Tag),
            metadata: { vpcId: sg.VpcId },
            configuration: this._sanitize(sg)
          };
        }
        this.logger("info", `Collected ${securityGroups.length} security groups in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud security groups", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Disk Snapshots.
   */
  async *_collectSnapshots() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://ecs.${region}.aliyuncs.com`, "2014-05-26");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeSnapshots", params, { method: "POST" });
        const snapshots = response.Snapshots?.Snapshot || [];
        for (const snapshot of snapshots) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "snapshots",
            resourceType: "alibaba.ecs.snapshot",
            resourceId: snapshot.SnapshotId,
            name: snapshot.SnapshotName || snapshot.SnapshotId,
            tags: this._extractTags(snapshot.Tags?.Tag),
            metadata: { sourceDiskId: snapshot.SourceDiskId },
            configuration: this._sanitize(snapshot)
          };
        }
        this.logger("info", `Collected ${snapshots.length} snapshots in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud snapshots", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Auto Scaling Groups.
   */
  async *_collectAutoScaling() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://ess.${region}.aliyuncs.com`, "2014-08-28");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeScalingGroups", params, { method: "POST" });
        const scalingGroups = response.ScalingGroups?.ScalingGroup || [];
        for (const group of scalingGroups) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "autoscaling",
            resourceType: "alibaba.ess.scalinggroup",
            resourceId: group.ScalingGroupId,
            name: group.ScalingGroupName,
            tags: this._extractTags(group.Tags?.Tag),
            configuration: this._sanitize(group)
          };
          try {
            const configParams = {
              ScalingGroupId: group.ScalingGroupId,
              PageSize: 50
            };
            const configResponse = await client.request("DescribeScalingConfigurations", configParams, { method: "POST" });
            const configurations = configResponse.ScalingConfigurations?.ScalingConfiguration || [];
            for (const config of configurations) {
              yield {
                provider: "alibaba",
                accountId: this._accountId,
                region,
                service: "autoscaling",
                resourceType: "alibaba.ess.scalingconfiguration",
                resourceId: config.ScalingConfigurationId,
                name: config.ScalingConfigurationName,
                tags: {},
                metadata: { scalingGroupId: group.ScalingGroupId },
                configuration: this._sanitize(config)
              };
            }
          } catch (configErr) {
            this.logger("warn", `Failed to collect scaling configurations for group ${group.ScalingGroupId}`, {
              error: configErr.message
            });
          }
        }
        this.logger("info", `Collected ${scalingGroups.length} auto scaling groups in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud auto scaling", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect NAT Gateways.
   */
  async *_collectNATGateway() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://vpc.${region}.aliyuncs.com`, "2016-04-28");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        const response = await client.request("DescribeNatGateways", params, { method: "POST" });
        const natGateways = response.NatGateways?.NatGateway || [];
        for (const nat of natGateways) {
          yield {
            provider: "alibaba",
            accountId: this._accountId,
            region,
            service: "natgateway",
            resourceType: "alibaba.vpc.natgateway",
            resourceId: nat.NatGatewayId,
            name: nat.Name || nat.NatGatewayId,
            tags: this._extractTags(nat.Tags?.Tag),
            metadata: { vpcId: nat.VpcId },
            configuration: this._sanitize(nat)
          };
        }
        this.logger("info", `Collected ${natGateways.length} NAT gateways in ${region}`);
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud NAT gateways", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Container Registry (ACR) repositories.
   */
  async *_collectACR() {
    try {
      for (const region of this._regions) {
        const client = await this._createRPCClient(`https://cr.${region}.aliyuncs.com`, "2018-12-01");
        const params = {
          RegionId: region,
          PageSize: 50
        };
        try {
          const response = await client.request("ListRepository", params, { method: "POST" });
          const repositories = response.Repositories?.Repository || [];
          for (const repo of repositories) {
            yield {
              provider: "alibaba",
              accountId: this._accountId,
              region,
              service: "acr",
              resourceType: "alibaba.acr.repository",
              resourceId: repo.RepoId || `${repo.RepoNamespace}/${repo.RepoName}`,
              name: `${repo.RepoNamespace}/${repo.RepoName}`,
              tags: {},
              configuration: this._sanitize(repo)
            };
          }
          this.logger("info", `Collected ${repositories.length} ACR repositories in ${region}`);
        } catch (regionErr) {
          this.logger("debug", `ACR not available or no repositories in ${region}`, {
            error: regionErr.message
          });
        }
      }
    } catch (err) {
      this.logger("error", "Failed to collect Alibaba Cloud ACR", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Extract tags from Alibaba Cloud tag format.
   */
  _extractTags(tags) {
    if (!tags || !Array.isArray(tags)) return {};
    const tagMap = {};
    for (const tag of tags) {
      if (tag.TagKey) {
        tagMap[tag.TagKey] = tag.TagValue || "";
      }
    }
    return tagMap;
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "Password",
      "MasterUserPassword",
      "AccessKeySecret",
      "SecretAccessKey",
      "PrivateKey",
      "Certificate"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class CloudflareInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "cloudflare" });
    this._apiToken = null;
    this._accountId = null;
    this._client = null;
    this._services = this.config?.services || [
      "workers",
      "r2",
      "pages",
      "d1",
      "kv",
      "durable-objects",
      "zones",
      "loadbalancers",
      "certificates",
      "waf",
      "access"
    ];
  }
  /**
   * Initialize Cloudflare API client.
   */
  async _initializeClient() {
    if (this._client) return;
    const credentials = this.credentials || {};
    this._apiToken = credentials.apiToken || credentials.token || process.env.CLOUDFLARE_API_TOKEN;
    this._accountId = credentials.accountId || this.config?.accountId || process.env.CLOUDFLARE_ACCOUNT_ID;
    if (!this._apiToken) {
      throw new Error("Cloudflare API token is required. Provide via credentials.apiToken or CLOUDFLARE_API_TOKEN env var.");
    }
    const Cloudflare = await import('cloudflare');
    this._client = new Cloudflare.default({
      apiToken: this._apiToken
    });
    this.logger("info", "Cloudflare API client initialized", {
      accountId: this._accountId,
      services: this._services.length
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeClient();
    const serviceCollectors = {
      workers: () => this._collectWorkers(),
      r2: () => this._collectR2(),
      pages: () => this._collectPages(),
      "d1": () => this._collectD1(),
      kv: () => this._collectKV(),
      "durable-objects": () => this._collectDurableObjects(),
      zones: () => this._collectZones(),
      loadbalancers: () => this._collectLoadBalancers(),
      certificates: () => this._collectCertificates(),
      waf: () => this._collectWAF(),
      access: () => this._collectAccess()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown Cloudflare service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting Cloudflare ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `Cloudflare service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Collect Workers scripts.
   */
  async *_collectWorkers() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for Workers collection, skipping");
        return;
      }
      const scripts = await this._client.workers.scripts.list({ account_id: this._accountId });
      for (const script of scripts) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          // Workers are global/edge
          service: "workers",
          resourceType: "cloudflare.workers.script",
          resourceId: script.id,
          name: script.id,
          tags: script.tags || [],
          configuration: this._sanitize(script)
        };
      }
      this.logger("info", `Collected ${scripts.length || 0} Cloudflare Workers scripts`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare Workers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect R2 buckets.
   */
  async *_collectR2() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for R2 collection, skipping");
        return;
      }
      const buckets = await this._client.r2.buckets.list({ account_id: this._accountId });
      for (const bucket of buckets) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: bucket.location || "global",
          service: "r2",
          resourceType: "cloudflare.r2.bucket",
          resourceId: bucket.name,
          name: bucket.name,
          tags: [],
          configuration: this._sanitize(bucket)
        };
      }
      this.logger("info", `Collected ${buckets.length || 0} Cloudflare R2 buckets`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare R2", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Pages projects.
   */
  async *_collectPages() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for Pages collection, skipping");
        return;
      }
      const projects = await this._client.pages.projects.list({ account_id: this._accountId });
      for (const project of projects) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          service: "pages",
          resourceType: "cloudflare.pages.project",
          resourceId: project.id || project.name,
          name: project.name,
          tags: [],
          configuration: this._sanitize(project)
        };
      }
      this.logger("info", `Collected ${projects.length || 0} Cloudflare Pages projects`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare Pages", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect D1 databases.
   */
  async *_collectD1() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for D1 collection, skipping");
        return;
      }
      const databases = await this._client.d1.database.list({ account_id: this._accountId });
      for (const database of databases) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          service: "d1",
          resourceType: "cloudflare.d1.database",
          resourceId: database.uuid,
          name: database.name,
          tags: [],
          configuration: this._sanitize(database)
        };
      }
      this.logger("info", `Collected ${databases.length || 0} Cloudflare D1 databases`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare D1", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect KV namespaces.
   */
  async *_collectKV() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for KV collection, skipping");
        return;
      }
      const namespaces = await this._client.kv.namespaces.list({ account_id: this._accountId });
      for (const namespace of namespaces) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          service: "kv",
          resourceType: "cloudflare.kv.namespace",
          resourceId: namespace.id,
          name: namespace.title,
          tags: [],
          configuration: this._sanitize(namespace)
        };
      }
      this.logger("info", `Collected ${namespaces.length || 0} Cloudflare KV namespaces`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare KV", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Durable Objects namespaces.
   */
  async *_collectDurableObjects() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for Durable Objects collection, skipping");
        return;
      }
      const namespaces = await this._client.durableObjects.namespaces.list({ account_id: this._accountId });
      for (const namespace of namespaces) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          service: "durable-objects",
          resourceType: "cloudflare.durableobjects.namespace",
          resourceId: namespace.id,
          name: namespace.name,
          tags: [],
          configuration: this._sanitize(namespace)
        };
      }
      this.logger("info", `Collected ${namespaces.length || 0} Cloudflare Durable Objects namespaces`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare Durable Objects", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Zones (domains) and DNS records.
   */
  async *_collectZones() {
    try {
      const zones = await this._client.zones.list();
      for (const zone of zones) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId || zone.account?.id,
          region: "global",
          service: "zones",
          resourceType: "cloudflare.zone",
          resourceId: zone.id,
          name: zone.name,
          tags: [],
          configuration: this._sanitize(zone)
        };
        try {
          const records = await this._client.dns.records.list({ zone_id: zone.id });
          for (const record of records) {
            yield {
              provider: "cloudflare",
              accountId: this._accountId || zone.account?.id,
              region: "global",
              service: "zones",
              resourceType: "cloudflare.dns.record",
              resourceId: record.id,
              name: `${record.name} (${record.type})`,
              tags: record.tags || [],
              metadata: { zoneId: zone.id, zoneName: zone.name },
              configuration: this._sanitize(record)
            };
          }
        } catch (recordErr) {
          this.logger("warn", `Failed to collect DNS records for zone ${zone.name}`, {
            zoneId: zone.id,
            error: recordErr.message
          });
        }
      }
      this.logger("info", `Collected ${zones.length || 0} Cloudflare zones`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare zones", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Load Balancers.
   */
  async *_collectLoadBalancers() {
    try {
      const zones = await this._client.zones.list();
      for (const zone of zones) {
        try {
          const loadBalancers = await this._client.loadBalancers.list({ zone_id: zone.id });
          for (const lb of loadBalancers) {
            yield {
              provider: "cloudflare",
              accountId: this._accountId || zone.account?.id,
              region: "global",
              service: "loadbalancers",
              resourceType: "cloudflare.loadbalancer",
              resourceId: lb.id,
              name: lb.name,
              tags: [],
              metadata: { zoneId: zone.id, zoneName: zone.name },
              configuration: this._sanitize(lb)
            };
          }
        } catch (lbErr) {
          this.logger("debug", `No load balancers in zone ${zone.name}`, {
            zoneId: zone.id,
            error: lbErr.message
          });
        }
      }
      this.logger("info", `Collected Cloudflare load balancers`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare load balancers", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect SSL/TLS Certificates.
   */
  async *_collectCertificates() {
    try {
      const zones = await this._client.zones.list();
      for (const zone of zones) {
        try {
          const certificates = await this._client.ssl.certificatePacks.list({ zone_id: zone.id });
          for (const cert of certificates) {
            yield {
              provider: "cloudflare",
              accountId: this._accountId || zone.account?.id,
              region: "global",
              service: "certificates",
              resourceType: "cloudflare.ssl.certificate",
              resourceId: cert.id,
              name: `${zone.name} - ${cert.type}`,
              tags: [],
              metadata: {
                zoneId: zone.id,
                zoneName: zone.name,
                type: cert.type,
                status: cert.status
              },
              configuration: this._sanitize(cert)
            };
          }
        } catch (certErr) {
          this.logger("debug", `No certificates in zone ${zone.name}`, {
            zoneId: zone.id,
            error: certErr.message
          });
        }
      }
      this.logger("info", `Collected Cloudflare certificates`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare certificates", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect WAF (Web Application Firewall) Rulesets via new Rulesets API (2025).
   */
  async *_collectWAF() {
    try {
      const zones = await this._client.zones.list();
      for (const zone of zones) {
        try {
          const rulesets = await this._client.rulesets.list({ zone_id: zone.id });
          for (const ruleset of rulesets) {
            if (ruleset.phase && (ruleset.phase.includes("http_") || ruleset.phase.includes("firewall"))) {
              yield {
                provider: "cloudflare",
                accountId: this._accountId || zone.account?.id,
                region: "global",
                service: "waf",
                resourceType: "cloudflare.waf.ruleset",
                resourceId: ruleset.id,
                name: ruleset.name,
                tags: [],
                metadata: {
                  zoneId: zone.id,
                  zoneName: zone.name,
                  phase: ruleset.phase,
                  kind: ruleset.kind
                },
                configuration: this._sanitize(ruleset)
              };
            }
          }
        } catch (wafErr) {
          this.logger("debug", `No WAF rulesets in zone ${zone.name}`, {
            zoneId: zone.id,
            error: wafErr.message
          });
        }
      }
      this.logger("info", `Collected Cloudflare WAF rulesets`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare WAF", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Cloudflare Access Applications (Zero Trust).
   */
  async *_collectAccess() {
    try {
      if (!this._accountId) {
        this.logger("warn", "Account ID required for Access collection, skipping");
        return;
      }
      const applications = await this._client.access.applications.list({ account_id: this._accountId });
      for (const app of applications) {
        yield {
          provider: "cloudflare",
          accountId: this._accountId,
          region: "global",
          service: "access",
          resourceType: "cloudflare.access.application",
          resourceId: app.id,
          name: app.name,
          tags: [],
          metadata: {
            domain: app.domain,
            type: app.type
          },
          configuration: this._sanitize(app)
        };
        try {
          const policies = await this._client.access.policies.list({
            account_id: this._accountId,
            application_id: app.id
          });
          for (const policy of policies) {
            yield {
              provider: "cloudflare",
              accountId: this._accountId,
              region: "global",
              service: "access",
              resourceType: "cloudflare.access.policy",
              resourceId: policy.id,
              name: policy.name,
              tags: [],
              metadata: {
                applicationId: app.id,
                applicationName: app.name,
                decision: policy.decision
              },
              configuration: this._sanitize(policy)
            };
          }
        } catch (policyErr) {
          this.logger("warn", `Failed to collect policies for Access application ${app.name}`, {
            applicationId: app.id,
            error: policyErr.message
          });
        }
      }
      this.logger("info", `Collected Cloudflare Access applications`);
    } catch (err) {
      this.logger("error", "Failed to collect Cloudflare Access", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "api_token",
      "api_key",
      "token",
      "secret",
      "password",
      "private_key"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

class MongoDBAtlasInventoryDriver extends BaseCloudDriver {
  constructor(options = {}) {
    super({ ...options, driver: options.driver || "mongodb-atlas" });
    this._publicKey = null;
    this._privateKey = null;
    this._baseUrl = "https://cloud.mongodb.com/api/atlas/v2";
    this._organizationId = this.config?.organizationId || null;
    this._services = this.config?.services || [
      "projects",
      "clusters",
      "serverless",
      "users",
      "accesslists",
      "backups",
      "alerts",
      "datalakes",
      "search",
      "customroles",
      "events"
    ];
    this._projectIds = this.config?.projectIds || null;
  }
  /**
   * Initialize MongoDB Atlas credentials.
   */
  async _initializeCredentials() {
    if (this._publicKey) return;
    const credentials = this.credentials || {};
    this._publicKey = credentials.publicKey || process.env.MONGODB_ATLAS_PUBLIC_KEY;
    this._privateKey = credentials.privateKey || process.env.MONGODB_ATLAS_PRIVATE_KEY;
    this._organizationId = credentials.organizationId || this._organizationId;
    if (!this._publicKey || !this._privateKey) {
      throw new Error("MongoDB Atlas API keys are required. Provide via credentials.publicKey/privateKey or env vars.");
    }
    this.logger("info", "MongoDB Atlas credentials initialized", {
      organizationId: this._organizationId || "auto-discover",
      services: this._services.length
    });
  }
  /**
   * Create Atlas API client.
   */
  async _createClient() {
    const AtlasClient = await import('mongodb-atlas-api-client');
    return AtlasClient.default({
      publicKey: this._publicKey,
      privateKey: this._privateKey,
      baseUrl: this._baseUrl
    });
  }
  /**
   * Make authenticated request to Atlas API.
   */
  async _makeRequest(endpoint, options = {}) {
    const crypto = await import('crypto');
    const https = await import('https');
    const url = new URL(endpoint, this._baseUrl);
    const method = options.method || "GET";
    crypto.randomBytes(16).toString("hex");
    (/* @__PURE__ */ new Date()).toISOString();
    return new Promise((resolve, reject) => {
      const req = https.request({
        hostname: url.hostname,
        path: url.pathname + url.search,
        method,
        headers: {
          "Accept": "application/vnd.atlas.2025-03-12+json",
          "Content-Type": "application/json"
        },
        auth: `${this._publicKey}:${this._privateKey}`
      }, (res) => {
        let data = "";
        res.on("data", (chunk) => data += chunk);
        res.on("end", () => {
          try {
            resolve(JSON.parse(data));
          } catch (err) {
            resolve(data);
          }
        });
      });
      req.on("error", reject);
      if (options.body) {
        req.write(JSON.stringify(options.body));
      }
      req.end();
    });
  }
  /**
   * Main entry point - lists all resources from configured services.
   */
  async *listResources(options = {}) {
    await this._initializeCredentials();
    const serviceCollectors = {
      projects: () => this._collectProjects(),
      clusters: () => this._collectClusters(),
      serverless: () => this._collectServerless(),
      users: () => this._collectUsers(),
      accesslists: () => this._collectAccessLists(),
      backups: () => this._collectBackups(),
      alerts: () => this._collectAlerts(),
      datalakes: () => this._collectDataLakes(),
      search: () => this._collectSearchIndexes(),
      customroles: () => this._collectCustomRoles(),
      events: () => this._collectEvents()
    };
    for (const service of this._services) {
      const collector = serviceCollectors[service];
      if (!collector) {
        this.logger("warn", `Unknown MongoDB Atlas service: ${service}`, { service });
        continue;
      }
      try {
        this.logger("info", `Collecting MongoDB Atlas ${service} resources`, { service });
        yield* collector();
      } catch (err) {
        this.logger("error", `MongoDB Atlas service collection failed, skipping to next service`, {
          service,
          error: err.message,
          errorName: err.name,
          stack: err.stack
        });
      }
    }
  }
  /**
   * Get list of projects to iterate.
   */
  async _getProjects() {
    if (this._projectIds) {
      return this._projectIds.map((id) => ({ id }));
    }
    try {
      const response = await this._makeRequest("/groups");
      return response.results || [];
    } catch (err) {
      this.logger("error", "Failed to fetch projects list", { error: err.message });
      return [];
    }
  }
  /**
   * Collect Projects (Groups).
   */
  async *_collectProjects() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        yield {
          provider: "mongodb-atlas",
          accountId: this._organizationId || project.orgId,
          region: null,
          // Projects are global
          service: "projects",
          resourceType: "mongodb-atlas.project",
          resourceId: project.id,
          name: project.name,
          tags: {},
          metadata: {
            orgId: project.orgId,
            clusterCount: project.clusterCount
          },
          configuration: this._sanitize(project)
        };
      }
      this.logger("info", `Collected ${projects.length} MongoDB Atlas projects`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas projects", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Clusters.
   */
  async *_collectClusters() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/clusters`);
          const clusters = response.results || [];
          for (const cluster of clusters) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: cluster.providerSettings?.regionName || null,
              service: "clusters",
              resourceType: "mongodb-atlas.cluster",
              resourceId: cluster.id || cluster.name,
              name: cluster.name,
              tags: cluster.tags || {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                tier: cluster.providerSettings?.instanceSizeName,
                provider: cluster.providerSettings?.providerName,
                mongoDBVersion: cluster.mongoDBVersion,
                clusterType: cluster.clusterType,
                state: cluster.stateName
              },
              configuration: this._sanitize(cluster)
            };
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect clusters for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas clusters`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas clusters", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Serverless Instances.
   */
  async *_collectServerless() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/serverless`);
          const instances = response.results || [];
          for (const instance of instances) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: instance.providerSettings?.regionName || null,
              service: "serverless",
              resourceType: "mongodb-atlas.serverless",
              resourceId: instance.id || instance.name,
              name: instance.name,
              tags: instance.tags || {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                provider: instance.providerSettings?.providerName,
                state: instance.stateName
              },
              configuration: this._sanitize(instance)
            };
          }
        } catch (projectErr) {
          this.logger("debug", `No serverless instances in project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas serverless instances`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas serverless", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Database Users.
   */
  async *_collectUsers() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/databaseUsers`);
          const users = response.results || [];
          for (const user of users) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: null,
              service: "users",
              resourceType: "mongodb-atlas.user",
              resourceId: `${project.id}/${user.username}`,
              name: user.username,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                databaseName: user.databaseName,
                roles: user.roles?.map((r) => r.roleName)
              },
              configuration: this._sanitize(user)
            };
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect users for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas database users`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas users", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect IP Access Lists (Whitelists).
   */
  async *_collectAccessLists() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/accessList`);
          const entries = response.results || [];
          for (const entry of entries) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: null,
              service: "accesslists",
              resourceType: "mongodb-atlas.accesslist",
              resourceId: `${project.id}/${entry.ipAddress || entry.cidrBlock}`,
              name: entry.comment || entry.ipAddress || entry.cidrBlock,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                ipAddress: entry.ipAddress,
                cidrBlock: entry.cidrBlock
              },
              configuration: this._sanitize(entry)
            };
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect access lists for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas IP access lists`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas access lists", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Cloud Backups.
   */
  async *_collectBackups() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const clustersResponse = await this._makeRequest(`/groups/${project.id}/clusters`);
          const clusters = clustersResponse.results || [];
          for (const cluster of clusters) {
            try {
              const response = await this._makeRequest(
                `/groups/${project.id}/clusters/${cluster.name}/backup/snapshots`
              );
              const snapshots = response.results || [];
              for (const snapshot of snapshots) {
                yield {
                  provider: "mongodb-atlas",
                  accountId: this._organizationId || project.orgId,
                  region: cluster.providerSettings?.regionName || null,
                  service: "backups",
                  resourceType: "mongodb-atlas.backup",
                  resourceId: snapshot.id,
                  name: `${cluster.name}-${snapshot.id}`,
                  tags: {},
                  metadata: {
                    projectId: project.id,
                    projectName: project.name,
                    clusterName: cluster.name,
                    type: snapshot.type,
                    status: snapshot.status
                  },
                  configuration: this._sanitize(snapshot)
                };
              }
            } catch (clusterErr) {
              this.logger("debug", `No backups for cluster ${cluster.name}`, {
                clusterName: cluster.name,
                error: clusterErr.message
              });
            }
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect backups for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas backups`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas backups", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Alert Configurations.
   */
  async *_collectAlerts() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/alertConfigs`);
          const alerts = response.results || [];
          for (const alert of alerts) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: null,
              service: "alerts",
              resourceType: "mongodb-atlas.alert",
              resourceId: alert.id,
              name: alert.eventTypeName,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                enabled: alert.enabled,
                eventTypeName: alert.eventTypeName
              },
              configuration: this._sanitize(alert)
            };
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect alerts for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas alerts`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas alerts", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Data Lakes (Federated Database Instances).
   */
  async *_collectDataLakes() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/dataLakes`);
          const dataLakes = response || [];
          for (const lake of dataLakes) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: lake.cloudProviderConfig?.aws?.roleId ? "aws" : null,
              service: "datalakes",
              resourceType: "mongodb-atlas.datalake",
              resourceId: lake.name,
              name: lake.name,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                state: lake.state
              },
              configuration: this._sanitize(lake)
            };
          }
        } catch (projectErr) {
          this.logger("debug", `No data lakes in project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas data lakes`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas data lakes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Atlas Search Indexes.
   */
  async *_collectSearchIndexes() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const clustersResponse = await this._makeRequest(`/groups/${project.id}/clusters`);
          const clusters = clustersResponse.results || [];
          for (const cluster of clusters) {
            try {
              const response = await this._makeRequest(
                `/groups/${project.id}/clusters/${cluster.name}/fts/indexes`
              );
              const indexes = response || [];
              for (const index of indexes) {
                yield {
                  provider: "mongodb-atlas",
                  accountId: this._organizationId || project.orgId,
                  region: cluster.providerSettings?.regionName || null,
                  service: "search",
                  resourceType: "mongodb-atlas.search.index",
                  resourceId: index.indexID,
                  name: index.name,
                  tags: {},
                  metadata: {
                    projectId: project.id,
                    projectName: project.name,
                    clusterName: cluster.name,
                    collectionName: index.collectionName,
                    database: index.database,
                    status: index.status
                  },
                  configuration: this._sanitize(index)
                };
              }
            } catch (clusterErr) {
              this.logger("debug", `No search indexes for cluster ${cluster.name}`, {
                clusterName: cluster.name,
                error: clusterErr.message
              });
            }
          }
        } catch (projectErr) {
          this.logger("warn", `Failed to collect search indexes for project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas search indexes`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas search indexes", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Custom Database Roles.
   */
  async *_collectCustomRoles() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const response = await this._makeRequest(`/groups/${project.id}/customDBRoles/roles`);
          const roles = response || [];
          for (const role of roles) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: null,
              service: "customroles",
              resourceType: "mongodb-atlas.customrole",
              resourceId: `${project.id}/${role.roleName}`,
              name: role.roleName,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name
              },
              configuration: this._sanitize(role)
            };
          }
        } catch (projectErr) {
          this.logger("debug", `No custom roles in project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas custom roles`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas custom roles", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Collect Events (audit logs).
   */
  async *_collectEvents() {
    try {
      const projects = await this._getProjects();
      for (const project of projects) {
        try {
          const minDate = new Date(Date.now() - 7 * 24 * 60 * 60 * 1e3).toISOString();
          const response = await this._makeRequest(
            `/groups/${project.id}/events?minDate=${minDate}&itemsPerPage=100`
          );
          const events = response.results || [];
          for (const event of events) {
            yield {
              provider: "mongodb-atlas",
              accountId: this._organizationId || project.orgId,
              region: null,
              service: "events",
              resourceType: "mongodb-atlas.event",
              resourceId: event.id,
              name: event.eventTypeName,
              tags: {},
              metadata: {
                projectId: project.id,
                projectName: project.name,
                eventTypeName: event.eventTypeName,
                created: event.created
              },
              configuration: this._sanitize(event)
            };
          }
        } catch (projectErr) {
          this.logger("debug", `No recent events in project ${project.id}`, {
            projectId: project.id,
            error: projectErr.message
          });
        }
      }
      this.logger("info", `Collected MongoDB Atlas events`);
    } catch (err) {
      this.logger("error", "Failed to collect MongoDB Atlas events", {
        error: err.message,
        stack: err.stack
      });
      throw err;
    }
  }
  /**
   * Sanitize configuration by removing sensitive data.
   */
  _sanitize(config) {
    if (!config || typeof config !== "object") return config;
    const sanitized = { ...config };
    const sensitiveFields = [
      "password",
      "privateKey",
      "apiKey",
      "connectionStrings",
      "mongoURI",
      "mongoURIUpdated",
      "mongoURIWithOptions"
    ];
    for (const field of sensitiveFields) {
      if (field in sanitized) {
        sanitized[field] = "***REDACTED***";
      }
    }
    return sanitized;
  }
}

const DEFAULT_TAGS = { environment: "mock" };
function cloneValue(value) {
  if (Array.isArray(value)) {
    return value.map(cloneValue);
  }
  if (value && typeof value === "object") {
    return JSON.parse(JSON.stringify(value));
  }
  return value;
}
function mergeWithDefaults(defaults, resource = {}) {
  const merged = {
    ...defaults,
    ...resource
  };
  const baseTags = defaults.tags || null;
  const resourceTags = resource.tags || null;
  merged.tags = baseTags || resourceTags ? { ...baseTags || {}, ...resourceTags || {} } : null;
  const baseLabels = defaults.labels || null;
  const resourceLabels = resource.labels || null;
  merged.labels = baseLabels || resourceLabels ? { ...baseLabels || {}, ...resourceLabels || {} } : null;
  const baseMetadata = defaults.metadata || {};
  const resourceMetadata = resource.metadata || {};
  merged.metadata = { ...baseMetadata, ...resourceMetadata };
  const configuration = resource.configuration ?? defaults.configuration ?? {
    id: merged.resourceId,
    note: `Mock configuration for ${defaults.provider}`
  };
  merged.configuration = cloneValue(configuration);
  return merged;
}
class MockCloudDriver extends BaseCloudDriver {
  constructor(options = {}, defaultsBuilder) {
    super(options);
    this._defaultsBuilder = defaultsBuilder;
  }
  _buildDefaults() {
    return this._defaultsBuilder(this);
  }
  async initialize() {
    this.logger("debug", "Mock cloud driver initialized", {
      cloudId: this.id,
      driver: this.driver
    });
  }
  async listResources() {
    const defaults = this._buildDefaults();
    const samples = Array.isArray(this.config.sampleResources) && this.config.sampleResources.length ? this.config.sampleResources : [defaults];
    return samples.map((entry) => mergeWithDefaults(defaults, entry));
  }
}
function awsDefaults(driver) {
  const accountId = driver.config.accountId || "mock-aws-account";
  const region = driver.config.region || driver.config.regions?.[0] || "us-east-1";
  const resourceId = driver.config.resourceId || `i-${accountId.slice(-6) || "mock"}001`;
  return {
    provider: "aws",
    driver: "aws",
    accountId,
    region,
    service: "ec2",
    resourceType: "ec2.instance",
    resourceId,
    name: "mock-ec2-instance",
    tags: { ...DEFAULT_TAGS, Owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      instanceId: resourceId,
      instanceType: "t3.micro",
      region,
      accountId,
      state: "running",
      tags: { Environment: "mock", Owner: "cloud-inventory" }
    }
  };
}
function gcpDefaults(driver) {
  const projectId = driver.config.projectId || "mock-gcp-project";
  const region = driver.config.region || driver.config.regions?.[0] || "us-central1";
  const zone = driver.config.zone || `${region}-a`;
  const resourceId = driver.config.resourceId || `${projectId}-instance-1`;
  return {
    provider: "gcp",
    driver: "gcp",
    projectId,
    region,
    service: "compute",
    resourceType: "gcp.compute.instance",
    resourceId,
    name: "mock-gce-instance",
    labels: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock", zone },
    configuration: {
      id: resourceId,
      name: "mock-gce-instance",
      machineType: "e2-medium",
      status: "RUNNING",
      projectId,
      zone,
      labels: { environment: "mock", owner: "cloud-inventory" }
    }
  };
}
function digitalOceanDefaults(driver) {
  const accountId = driver.config.accountId || "mock-do-account";
  const region = driver.config.region || driver.config.regions?.[0] || "nyc3";
  const resourceId = driver.config.resourceId || `do-${accountId.slice(-6) || "mock"}-droplet`;
  return {
    provider: "digitalocean",
    driver: "digitalocean",
    accountId,
    region,
    service: "droplet",
    resourceType: "do.droplet",
    resourceId,
    name: "mock-droplet",
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      id: resourceId,
      name: "mock-droplet",
      size: "s-2vcpu-4gb",
      region,
      status: "active",
      tags: ["mock", "cloud-inventory"]
    }
  };
}
function oracleDefaults(driver) {
  const tenancyId = driver.config.tenancyId || driver.config.organizationId || "ocid1.tenancy.oc1..mock";
  const compartmentId = driver.config.compartmentId || "ocid1.compartment.oc1..mock";
  const region = driver.config.region || "us-phoenix-1";
  const resourceId = driver.config.resourceId || "ocid1.instance.oc1..mock";
  return {
    provider: "oracle",
    driver: "oracle",
    organizationId: tenancyId,
    region,
    service: "compute",
    resourceType: "oci.compute.instance",
    resourceId,
    name: "mock-oci-instance",
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: {
      source: "cloud-inventory-mock",
      compartmentId
    },
    configuration: {
      id: resourceId,
      displayName: "mock-oci-instance",
      compartmentId,
      lifecycleState: "RUNNING",
      region,
      shape: "VM.Standard.E4.Flex",
      freeformTags: { Environment: "mock", Owner: "cloud-inventory" }
    }
  };
}
function azureDefaults(driver) {
  const subscriptionId = driver.config.subscriptionId || driver.config.accountId || "00000000-0000-0000-0000-000000000000";
  const resourceGroup = driver.config.resourceGroup || "rg-mock";
  const region = driver.config.region || "eastus";
  const vmName = driver.config.vmName || "mock-azure-vm";
  const resourceId = driver.config.resourceId || `/subscriptions/${subscriptionId}/resourceGroups/${resourceGroup}/providers/Microsoft.Compute/virtualMachines/${vmName}`;
  return {
    provider: "azure",
    driver: "azure",
    subscriptionId,
    region,
    service: "compute",
    resourceType: "azure.vm",
    resourceId,
    name: vmName,
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: {
      source: "cloud-inventory-mock",
      resourceGroup
    },
    configuration: {
      id: resourceId,
      name: vmName,
      location: region,
      resourceGroup,
      subscriptionId,
      hardwareProfile: { vmSize: "Standard_B2s" },
      provisioningState: "Succeeded",
      tags: { Environment: "mock", Owner: "cloud-inventory" }
    }
  };
}
function vultrDefaults(driver) {
  const accountId = driver.config.accountId || "mock-vultr-account";
  const region = driver.config.region || "ewr";
  const resourceId = driver.config.resourceId || `vultr-${accountId.slice(-6) || "mock"}-instance`;
  return {
    provider: "vultr",
    driver: "vultr",
    accountId,
    region,
    service: "compute",
    resourceType: "vultr.instance",
    resourceId,
    name: "mock-vultr-instance",
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      id: resourceId,
      label: "mock-vultr-instance",
      plan: "vc2-1c-1gb",
      region,
      status: "active",
      tags: ["mock", "cloud-inventory"]
    }
  };
}
class AwsMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, awsDefaults);
  }
}
class GcpMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, gcpDefaults);
  }
}
class DigitalOceanMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, digitalOceanDefaults);
  }
}
class OracleMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, oracleDefaults);
  }
}
class AzureMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, azureDefaults);
  }
}
class VultrMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, vultrDefaults);
  }
}
function linodeDefaults(driver) {
  const accountId = driver.config.accountId || "mock-linode-account";
  const region = driver.config.region || driver.config.regions?.[0] || "us-east";
  const resourceId = driver.config.resourceId || `linode-${accountId.slice(-6) || "mock"}-instance`;
  return {
    provider: "linode",
    driver: "linode",
    accountId,
    region,
    service: "linodes",
    resourceType: "linode.compute.instance",
    resourceId,
    name: "mock-linode-instance",
    tags: ["mock", "cloud-inventory"],
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      id: resourceId,
      label: "mock-linode-instance",
      type: "g6-nanode-1",
      region,
      status: "running",
      tags: ["mock", "cloud-inventory"]
    }
  };
}
function hetznerDefaults(driver) {
  const accountId = driver.config.accountId || "mock-hetzner-account";
  const region = driver.config.region || "fsn1";
  const resourceId = driver.config.resourceId || `hetzner-${accountId.slice(-6) || "mock"}-server`;
  return {
    provider: "hetzner",
    driver: "hetzner",
    accountId,
    region,
    service: "servers",
    resourceType: "hetzner.server",
    resourceId,
    name: "mock-hetzner-server",
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      id: resourceId,
      name: "mock-hetzner-server",
      serverType: "cx11",
      datacenter: { location: { name: region } },
      status: "running",
      labels: { environment: "mock", owner: "cloud-inventory" }
    }
  };
}
function alibabaDefaults(driver) {
  const accountId = driver.config.accountId || "mock-alibaba-account";
  const region = driver.config.region || driver.config.regions?.[0] || "cn-hangzhou";
  const resourceId = driver.config.resourceId || `i-${accountId.slice(-6) || "mock"}001`;
  return {
    provider: "alibaba",
    driver: "alibaba",
    accountId,
    region,
    service: "ecs",
    resourceType: "alibaba.ecs.instance",
    resourceId,
    name: "mock-ecs-instance",
    tags: { ...DEFAULT_TAGS, owner: "cloud-inventory" },
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      InstanceId: resourceId,
      InstanceName: "mock-ecs-instance",
      InstanceType: "ecs.t5-lc1m1.small",
      RegionId: region,
      Status: "Running",
      Tags: { Tag: [{ TagKey: "environment", TagValue: "mock" }] }
    }
  };
}
function cloudflareDefaults(driver) {
  const accountId = driver.config.accountId || "mock-cloudflare-account";
  const resourceId = driver.config.resourceId || `cf-worker-${accountId.slice(-6) || "mock"}`;
  return {
    provider: "cloudflare",
    driver: "cloudflare",
    accountId,
    region: "global",
    service: "workers",
    resourceType: "cloudflare.workers.script",
    resourceId,
    name: "mock-worker-script",
    tags: ["mock", "cloud-inventory"],
    metadata: { source: "cloud-inventory-mock" },
    configuration: {
      id: resourceId,
      script: "mock-worker-script",
      etag: "mock-etag",
      created_on: (/* @__PURE__ */ new Date()).toISOString(),
      modified_on: (/* @__PURE__ */ new Date()).toISOString(),
      tags: ["mock", "cloud-inventory"]
    }
  };
}
class LinodeMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, linodeDefaults);
  }
}
class HetznerMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, hetznerDefaults);
  }
}
class AlibabaMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, alibabaDefaults);
  }
}
class CloudflareMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, cloudflareDefaults);
  }
}
function mongodbAtlasDefaults(driver) {
  const organizationId = driver.config.organizationId || "mock-atlas-org";
  const projectId = driver.config.projectId || "mock-atlas-project";
  const resourceId = driver.config.resourceId || `cluster-${projectId.slice(-6) || "mock"}`;
  return {
    provider: "mongodb-atlas",
    driver: "mongodb-atlas",
    accountId: organizationId,
    region: "US_EAST_1",
    service: "clusters",
    resourceType: "mongodb-atlas.cluster",
    resourceId,
    name: "mock-atlas-cluster",
    tags: { ...DEFAULT_TAGS, environment: "development" },
    metadata: {
      source: "cloud-inventory-mock",
      projectId,
      tier: "M10",
      provider: "AWS",
      mongoDBVersion: "7.0"
    },
    configuration: {
      id: resourceId,
      name: "mock-atlas-cluster",
      clusterType: "REPLICASET",
      stateName: "IDLE",
      mongoDBVersion: "7.0.2",
      providerSettings: {
        providerName: "AWS",
        regionName: "US_EAST_1",
        instanceSizeName: "M10"
      },
      tags: { environment: "development", owner: "cloud-inventory" }
    }
  };
}
class MongoDBAtlasMockDriver extends MockCloudDriver {
  constructor(options = {}) {
    super(options, mongodbAtlasDefaults);
  }
}

const CLOUD_DRIVERS = /* @__PURE__ */ new Map();
function registerCloudDriver(name, factory) {
  if (!name || typeof name !== "string") {
    throw new Error("registerCloudDriver: name must be a non-empty string");
  }
  if (typeof factory !== "function") {
    throw new Error(`registerCloudDriver("${name}") expects a factory function`);
  }
  CLOUD_DRIVERS.set(name, factory);
}
function createCloudDriver(name, options) {
  if (!CLOUD_DRIVERS.has(name)) {
    throw new Error(`Cloud driver "${name}" is not registered. Registered drivers: ${[...CLOUD_DRIVERS.keys()].join(", ") || "none"}`);
  }
  const driver = CLOUD_DRIVERS.get(name)(options);
  if (!(driver instanceof BaseCloudDriver)) {
    throw new Error(`Driver "${name}" factory must return an instance of BaseCloudDriver`);
  }
  return driver;
}
function listCloudDrivers() {
  return [...CLOUD_DRIVERS.keys()];
}
function validateCloudDefinition(cloud) {
  if (!cloud || typeof cloud !== "object") {
    throw new Error("Each cloud configuration must be an object");
  }
  const { driver, credentials } = cloud;
  if (!driver || typeof driver !== "string") {
    throw new Error('Cloud configuration requires a "driver" string');
  }
  if (!CLOUD_DRIVERS.has(driver)) {
    throw new Error(`Cloud driver "${driver}" is not registered`);
  }
  if (!credentials || typeof credentials !== "object") {
    throw new Error(`Cloud "${driver}" requires a credentials object`);
  }
}
registerCloudDriver("noop", (options = {}) => {
  class NoopDriver extends BaseCloudDriver {
    async listResources() {
      const { sampleResources = [] } = options.config || {};
      return Array.isArray(sampleResources) ? sampleResources : [];
    }
  }
  return new NoopDriver({
    ...options,
    driver: options.driver || "noop"
  });
});
function registerMockDriver(names, DriverClass) {
  const list = Array.isArray(names) ? names : [names];
  for (const name of list) {
    registerCloudDriver(name, (options = {}) => new DriverClass(options));
  }
}
registerCloudDriver("aws", (options = {}) => new AwsInventoryDriver(options));
registerCloudDriver("gcp", (options = {}) => new GcpInventoryDriver(options));
registerCloudDriver("vultr", (options = {}) => new VultrInventoryDriver(options));
registerCloudDriver("digitalocean", (options = {}) => new DigitalOceanInventoryDriver(options));
registerCloudDriver("do", (options = {}) => new DigitalOceanInventoryDriver(options));
registerCloudDriver("oracle", (options = {}) => new OracleInventoryDriver(options));
registerCloudDriver("oci", (options = {}) => new OracleInventoryDriver(options));
registerCloudDriver("azure", (options = {}) => new AzureInventoryDriver(options));
registerCloudDriver("az", (options = {}) => new AzureInventoryDriver(options));
registerCloudDriver("linode", (options = {}) => new LinodeInventoryDriver(options));
registerCloudDriver("hetzner", (options = {}) => new HetznerInventoryDriver(options));
registerCloudDriver("alibaba", (options = {}) => new AlibabaInventoryDriver(options));
registerCloudDriver("aliyun", (options = {}) => new AlibabaInventoryDriver(options));
registerCloudDriver("cloudflare", (options = {}) => new CloudflareInventoryDriver(options));
registerCloudDriver("cf", (options = {}) => new CloudflareInventoryDriver(options));
registerCloudDriver("mongodb-atlas", (options = {}) => new MongoDBAtlasInventoryDriver(options));
registerCloudDriver("atlas", (options = {}) => new MongoDBAtlasInventoryDriver(options));
registerMockDriver("aws-mock", AwsMockDriver);
registerMockDriver("gcp-mock", GcpMockDriver);
registerMockDriver("vultr-mock", VultrMockDriver);
registerMockDriver(["digitalocean-mock", "do-mock"], DigitalOceanMockDriver);
registerMockDriver(["oracle-mock", "oci-mock"], OracleMockDriver);
registerMockDriver(["azure-mock", "az-mock"], AzureMockDriver);
registerMockDriver("linode-mock", LinodeMockDriver);
registerMockDriver("hetzner-mock", HetznerMockDriver);
registerMockDriver(["alibaba-mock", "aliyun-mock"], AlibabaMockDriver);
registerMockDriver(["cloudflare-mock", "cf-mock"], CloudflareMockDriver);
registerMockDriver(["mongodb-atlas-mock", "atlas-mock"], MongoDBAtlasMockDriver);

const DEFAULT_RESOURCES = {
  snapshots: "plg_cloud_inventory_snapshots",
  versions: "plg_cloud_inventory_versions",
  changes: "plg_cloud_inventory_changes",
  clouds: "plg_cloud_inventory_clouds"
};
const DEFAULT_DISCOVERY = {
  concurrency: 3,
  include: null,
  exclude: [],
  runOnInstall: true,
  dryRun: false
};
const DEFAULT_LOCK = {
  ttl: 300,
  timeout: 0
};
const BASE_SCHEDULE = {
  enabled: false,
  cron: null,
  timezone: void 0,
  runOnStart: false
};
const DEFAULT_TERRAFORM = {
  enabled: false,
  autoExport: false,
  output: null,
  outputType: "file",
  // 'file', 's3', or 'custom'
  filters: {
    providers: [],
    resourceTypes: [],
    cloudId: null
  },
  terraformVersion: "1.5.0",
  serial: 1
};
const INLINE_DRIVER_NAMES = /* @__PURE__ */ new Map();
class CloudInventoryPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    const pendingLogs = [];
    const normalizedClouds = normalizeCloudDefinitions(
      Array.isArray(options.clouds) ? options.clouds : [],
      (level, message, meta) => pendingLogs.push({ level, message, meta })
    );
    this.config = {
      clouds: normalizedClouds,
      discovery: {
        ...DEFAULT_DISCOVERY,
        ...options.discovery || {}
      },
      resources: {
        ...DEFAULT_RESOURCES,
        ...options.resources || {}
      },
      logger: typeof options.logger === "function" ? options.logger : null,
      verbose: options.verbose === true,
      scheduled: normalizeSchedule(options.scheduled),
      lock: {
        ttl: options.lock?.ttl ?? DEFAULT_LOCK.ttl,
        timeout: options.lock?.timeout ?? DEFAULT_LOCK.timeout
      },
      terraform: {
        ...DEFAULT_TERRAFORM,
        ...options.terraform || {},
        filters: {
          ...DEFAULT_TERRAFORM.filters,
          ...options.terraform?.filters || {}
        }
      }
    };
    this.cloudDrivers = /* @__PURE__ */ new Map();
    this._resourceHandles = {};
    this._scheduledJobs = [];
    this._cron = null;
    for (const entry of pendingLogs) {
      this._log(entry.level, entry.message, entry.meta);
    }
  }
  async onInstall() {
    this._validateConfiguration();
    await this._ensureResources();
    await this._initializeDrivers();
    if (this.config.discovery.runOnInstall) {
      await this.syncAll();
    }
  }
  async onStart() {
    await this._setupSchedules();
  }
  async onStop() {
    await this._teardownSchedules();
    await this._destroyDrivers();
  }
  async onUninstall() {
    await this._teardownSchedules();
    await this._destroyDrivers();
  }
  async syncAll(options = {}) {
    const results = [];
    for (const cloud of this.config.clouds) {
      const result = await this.syncCloud(cloud.id, options);
      results.push(result);
    }
    if (this.config.terraform.enabled && this.config.terraform.autoExport && !this.config.terraform.filters.cloudId) {
      await this._autoExportTerraform(null);
    }
    return results;
  }
  async syncCloud(cloudId, options = {}) {
    const driverEntry = this.cloudDrivers.get(cloudId);
    if (!driverEntry) {
      throw new PluginError(`Cloud "${cloudId}" is not registered`, {
        pluginName: "CloudInventoryPlugin",
        operation: "syncCloud",
        statusCode: 404,
        retriable: false,
        suggestion: `Register the cloud definition in CloudInventoryPlugin configuration. Available: ${[...this.cloudDrivers.keys()].join(", ") || "none"}.`,
        cloudId
      });
    }
    const { driver, definition } = driverEntry;
    const summaryResource = this._resourceHandles.clouds;
    const summaryBefore = await summaryResource.getOrNull(cloudId) ?? await this._ensureCloudSummaryRecord(cloudId, definition, definition.scheduled);
    const storage = this.getStorage();
    const lockKey = `cloud-inventory-sync-${cloudId}`;
    const lock = await storage.acquireLock(lockKey, {
      ttl: this.config.lock.ttl,
      timeout: this.config.lock.timeout
    });
    if (!lock) {
      this._log("info", "Cloud sync already running on another worker, skipping", { cloudId });
      return {
        cloudId,
        driver: definition.driver,
        skipped: true,
        reason: "lock-not-acquired"
      };
    }
    const runId = createRunIdentifier();
    const startedAt = (/* @__PURE__ */ new Date()).toISOString();
    await this._updateCloudSummary(cloudId, {
      status: "running",
      lastRunAt: startedAt,
      lastRunId: runId,
      lastError: null,
      progress: null
    });
    let pendingCheckpoint = summaryBefore?.checkpoint ?? null;
    let pendingRateLimit = summaryBefore?.rateLimit ?? null;
    let pendingState = summaryBefore?.state ?? null;
    const runtimeContext = {
      checkpoint: summaryBefore?.checkpoint ?? null,
      state: summaryBefore?.state ?? null,
      emitCheckpoint: (value) => {
        if (value === void 0) return;
        pendingCheckpoint = value;
        this._updateCloudSummary(cloudId, {
          checkpoint: value,
          checkpointUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
        }).catch((err) => this._log("warn", "Failed to persist checkpoint", { cloudId, error: err.message }));
      },
      emitRateLimit: (value) => {
        pendingRateLimit = value;
        this._updateCloudSummary(cloudId, {
          rateLimit: value,
          rateLimitUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
        }).catch((err) => this._log("warn", "Failed to persist rate-limit metadata", { cloudId, error: err.message }));
      },
      emitState: (value) => {
        pendingState = value;
        this._updateCloudSummary(cloudId, {
          state: value,
          stateUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
        }).catch((err) => this._log("warn", "Failed to persist driver state", { cloudId, error: err.message }));
      },
      emitProgress: (value) => {
        this._updateCloudSummary(cloudId, { progress: value }).catch((err) => this._log("warn", "Failed to persist progress", { cloudId, error: err.message }));
      }
    };
    try {
      let items;
      try {
        items = await driver.listResources({
          discovery: this.config.discovery,
          checkpoint: runtimeContext.checkpoint,
          state: runtimeContext.state,
          runtime: runtimeContext,
          ...options
        });
      } catch (err) {
        await this._updateCloudSummary(cloudId, {
          status: "error",
          lastErrorAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastError: err.message || "Driver failure during listResources"
        });
        throw err;
      }
      let countCreated = 0;
      let countUpdated = 0;
      let countUnchanged = 0;
      let processed = 0;
      let errorDuringRun = null;
      const startMs = Date.now();
      const processItem = async (rawItem) => {
        const normalized = this._normalizeResource(definition, rawItem);
        if (!normalized) return;
        const persisted = await this._persistSnapshot(normalized, rawItem);
        processed += 1;
        if (persisted?.status === "created") countCreated += 1;
        else if (persisted?.status === "updated") countUpdated += 1;
        else countUnchanged += 1;
      };
      try {
        if (isAsyncIterable(items)) {
          for await (const item of items) {
            await processItem(item);
          }
        } else if (Array.isArray(items)) {
          for (const item of items) {
            await processItem(item);
          }
        } else if (items) {
          await processItem(items);
        }
      } catch (err) {
        errorDuringRun = err;
      }
      const finishedAt = (/* @__PURE__ */ new Date()).toISOString();
      const durationMs = Date.now() - startMs;
      const summaryPatch = {
        status: errorDuringRun ? "error" : "idle",
        lastRunAt: startedAt,
        lastRunId: runId,
        lastResult: {
          runId,
          startedAt,
          finishedAt,
          durationMs,
          counts: {
            created: countCreated,
            updated: countUpdated,
            unchanged: countUnchanged
          },
          processed,
          checkpoint: pendingCheckpoint
        },
        totalResources: Math.max(0, (summaryBefore?.totalResources ?? 0) + countCreated),
        totalVersions: Math.max(0, (summaryBefore?.totalVersions ?? 0) + countCreated + countUpdated),
        checkpoint: pendingCheckpoint,
        checkpointUpdatedAt: pendingCheckpoint !== summaryBefore?.checkpoint ? finishedAt : summaryBefore?.checkpointUpdatedAt,
        rateLimit: pendingRateLimit,
        rateLimitUpdatedAt: pendingRateLimit !== summaryBefore?.rateLimit ? finishedAt : summaryBefore?.rateLimitUpdatedAt,
        state: pendingState,
        stateUpdatedAt: pendingState !== summaryBefore?.state ? finishedAt : summaryBefore?.stateUpdatedAt,
        progress: null
      };
      if (errorDuringRun) {
        summaryPatch.lastError = errorDuringRun.message;
        summaryPatch.lastErrorAt = finishedAt;
      } else {
        summaryPatch.lastError = null;
        summaryPatch.lastSuccessAt = finishedAt;
      }
      await this._updateCloudSummary(cloudId, summaryPatch);
      if (errorDuringRun) {
        throw errorDuringRun;
      }
      const summary = {
        cloudId,
        driver: definition.driver,
        created: countCreated,
        updated: countUpdated,
        unchanged: countUnchanged,
        processed,
        durationMs
      };
      this._log("info", "Cloud sync finished", summary);
      if (this.config.terraform.enabled && this.config.terraform.autoExport) {
        await this._autoExportTerraform(cloudId);
      }
      return summary;
    } finally {
      try {
        await storage.releaseLock(lock);
      } catch (releaseErr) {
        this._log("warn", "Failed to release sync lock", {
          cloudId,
          lockName: lock?.name ?? lockKey,
          error: releaseErr.message
        });
      }
    }
  }
  _validateConfiguration() {
    if (!Array.isArray(this.config.clouds) || this.config.clouds.length === 0) {
      throw new PluginError('CloudInventoryPlugin requires a "clouds" array in the configuration', {
        pluginName: "CloudInventoryPlugin",
        operation: "validateConfiguration",
        statusCode: 400,
        retriable: false,
        suggestion: `Provide at least one cloud definition. Registered drivers: ${listCloudDrivers().join(", ") || "none"}.`
      });
    }
    for (const cloud of this.config.clouds) {
      validateCloudDefinition(cloud);
      try {
        normalizeSchedule(cloud.scheduled);
      } catch (err) {
        throw new PluginError(`Cloud "${cloud.id}" has an invalid scheduled configuration`, {
          pluginName: "CloudInventoryPlugin",
          operation: "validateConfiguration",
          statusCode: 400,
          retriable: false,
          suggestion: "Provide a valid cron expression and timezone when enabling scheduled discovery.",
          cloudId: cloud.id,
          original: err
        });
      }
    }
  }
  /**
   * Export discovered cloud resources to Terraform/OpenTofu state format
   * @param {Object} options - Export options
   * @param {Array<string>} options.resourceTypes - Filter by cloud resource types (e.g., ['aws.ec2.instance'])
   * @param {Array<string>} options.providers - Filter by provider (e.g., ['aws', 'gcp'])
   * @param {string} options.cloudId - Filter by specific cloud ID
   * @param {string} options.terraformVersion - Terraform version (default: '1.5.0')
   * @param {string} options.lineage - State lineage UUID (default: auto-generated)
   * @param {number} options.serial - State serial number (default: 1)
   * @param {Object} options.outputs - Terraform outputs (default: {})
   * @returns {Promise<Object>} - { state, stats }
   *
   * @example
   * // Export all resources
   * const result = await plugin.exportToTerraformState();
   * console.log(result.state); // Terraform state object
   * console.log(result.stats); // { total, converted, skipped }
   *
   * // Export specific provider
   * const awsOnly = await plugin.exportToTerraformState({ providers: ['aws'] });
   *
   * // Export specific resource types
   * const ec2Only = await plugin.exportToTerraformState({
   *   resourceTypes: ['aws.ec2.instance', 'aws.rds.instance']
   * });
   */
  async exportToTerraformState(options = {}) {
    const { exportToTerraformState: exportFn } = await Promise.resolve().then(function () { return terraformExporter; });
    const {
      resourceTypes = [],
      providers = [],
      cloudId = null,
      ...exportOptions
    } = options;
    const snapshotsResource = this._resourceHandles.snapshots;
    if (!snapshotsResource) {
      throw new PluginError("Snapshots resource not initialized", {
        pluginName: "CloudInventoryPlugin",
        operation: "exportToTerraformState",
        statusCode: 500,
        retriable: false,
        suggestion: "Call database.usePlugin(new CloudInventoryPlugin(...)) and ensure onInstall completed before exporting."
      });
    }
    const queryOptions = {};
    if (cloudId) {
      queryOptions.cloudId = cloudId;
    }
    const snapshots = await snapshotsResource.query(queryOptions);
    this._log("info", "Exporting cloud inventory to Terraform state", {
      totalSnapshots: snapshots.length,
      resourceTypes: resourceTypes.length > 0 ? resourceTypes : "all",
      providers: providers.length > 0 ? providers : "all"
    });
    const result = exportFn(snapshots, {
      ...exportOptions,
      resourceTypes,
      providers
    });
    this._log("info", "Export complete", result.stats);
    return result;
  }
  /**
   * Export cloud inventory to Terraform state file
   * @param {string} filePath - Output file path
   * @param {Object} options - Export options (see exportToTerraformState)
   * @returns {Promise<Object>} - { filePath, stats }
   *
   * @example
   * // Export to file
   * await plugin.exportToTerraformStateFile('./terraform.tfstate');
   *
   * // Export AWS resources only
   * await plugin.exportToTerraformStateFile('./aws-resources.tfstate', {
   *   providers: ['aws']
   * });
   */
  async exportToTerraformStateFile(filePath, options = {}) {
    const { promises: fs } = await import('fs');
    const path = await import('path');
    const result = await this.exportToTerraformState(options);
    const dir = path.dirname(filePath);
    await fs.mkdir(dir, { recursive: true });
    await fs.writeFile(filePath, JSON.stringify(result.state, null, 2), "utf8");
    this._log("info", `Terraform state exported to: ${filePath}`, result.stats);
    return {
      filePath,
      ...result
    };
  }
  /**
   * Export cloud inventory to Terraform state in S3
   * @param {string} bucket - S3 bucket name
   * @param {string} key - S3 object key
   * @param {Object} options - Export options (see exportToTerraformState)
   * @returns {Promise<Object>} - { bucket, key, stats }
   *
   * @example
   * // Export to S3
   * await plugin.exportToTerraformStateToS3('my-bucket', 'terraform/state.tfstate');
   *
   * // Export GCP resources to S3
   * await plugin.exportToTerraformStateToS3('my-bucket', 'terraform/gcp.tfstate', {
   *   providers: ['gcp']
   * });
   */
  async exportToTerraformStateToS3(bucket, key, options = {}) {
    const result = await this.exportToTerraformState(options);
    const s3Client = this.database.client;
    if (!s3Client || typeof s3Client.putObject !== "function") {
      throw new PluginError("S3 client not available. Database must use S3-compatible storage.", {
        pluginName: "CloudInventoryPlugin",
        operation: "exportToTerraformStateToS3",
        statusCode: 500,
        retriable: false,
        suggestion: "Initialize the database with an S3-compatible client before exporting Terraform state to S3."
      });
    }
    await s3Client.putObject({
      Bucket: bucket,
      Key: key,
      Body: JSON.stringify(result.state, null, 2),
      ContentType: "application/json"
    });
    this._log("info", `Terraform state exported to S3: s3://${bucket}/${key}`, result.stats);
    return {
      bucket,
      key,
      ...result
    };
  }
  /**
   * Auto-export Terraform state after discovery (internal)
   * @private
   */
  async _autoExportTerraform(cloudId = null) {
    try {
      const { terraform } = this.config;
      const exportOptions = {
        ...terraform.filters,
        terraformVersion: terraform.terraformVersion,
        serial: terraform.serial
      };
      if (cloudId) {
        exportOptions.cloudId = cloudId;
      }
      this._log("info", "Auto-exporting Terraform state", {
        output: terraform.output,
        outputType: terraform.outputType,
        cloudId: cloudId || "all"
      });
      let result;
      if (terraform.outputType === "s3") {
        const s3Match = terraform.output?.match(/^s3:\/\/([^/]+)\/(.+)$/);
        if (!s3Match) {
          throw new PluginError(`Invalid S3 URL format: ${terraform.output}`, {
            pluginName: "CloudInventoryPlugin",
            operation: "_autoExportTerraform",
            statusCode: 400,
            retriable: false,
            suggestion: "Provide a Terraform export destination using s3://bucket/path/file.tfstate.",
            output: terraform.output
          });
        }
        const [, bucket, key] = s3Match;
        result = await this.exportToTerraformStateToS3(bucket, key, exportOptions);
      } else if (terraform.outputType === "file") {
        if (!terraform.output) {
          throw new PluginError("Terraform output path not configured", {
            pluginName: "CloudInventoryPlugin",
            operation: "_autoExportTerraform",
            statusCode: 400,
            retriable: false,
            suggestion: 'Set terraform.output to a file path (e.g., ./terraform/state.tfstate) when using outputType "file".'
          });
        }
        result = await this.exportToTerraformStateFile(terraform.output, exportOptions);
      } else {
        if (typeof terraform.output === "function") {
          const stateData = await this.exportToTerraformState(exportOptions);
          result = await terraform.output(stateData);
        } else {
          throw new PluginError(`Unknown terraform.outputType: ${terraform.outputType}`, {
            pluginName: "CloudInventoryPlugin",
            operation: "_autoExportTerraform",
            statusCode: 400,
            retriable: false,
            suggestion: 'Use one of the supported output types: "file", "s3", or provide a custom function.',
            outputType: terraform.outputType
          });
        }
      }
      this._log("info", "Terraform state auto-export completed", result.stats);
    } catch (err) {
      this._log("error", "Failed to auto-export Terraform state", {
        error: err.message,
        stack: err.stack
      });
    }
  }
  async _ensureResources() {
    const {
      snapshots,
      versions,
      changes,
      clouds
    } = this.config.resources;
    const resourceDefinitions = [
      {
        name: snapshots,
        attributes: {
          id: "string|required",
          cloudId: "string|required",
          driver: "string|required",
          accountId: "string|optional",
          subscriptionId: "string|optional",
          organizationId: "string|optional",
          projectId: "string|optional",
          region: "string|optional",
          service: "string|optional",
          resourceType: "string|required",
          resourceId: "string|required",
          name: "string|optional",
          tags: "json|optional",
          labels: "json|optional",
          latestDigest: "string|required",
          latestVersion: "number|required",
          latestSnapshotId: "string|required",
          lastSeenAt: "string|required",
          firstSeenAt: "string|required",
          changelogSize: "number|default:0",
          metadata: "json|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        partitions: {
          byCloudId: {
            fields: {
              cloudId: "string|required"
            }
          },
          byResourceType: {
            fields: {
              resourceType: "string|required"
            }
          },
          byCloudAndType: {
            fields: {
              cloudId: "string|required",
              resourceType: "string|required"
            }
          },
          byRegion: {
            fields: {
              region: "string|optional"
            }
          }
        }
      },
      {
        name: versions,
        attributes: {
          id: "string|required",
          resourceKey: "string|required",
          cloudId: "string|required",
          driver: "string|required",
          version: "number|required",
          digest: "string|required",
          capturedAt: "string|required",
          configuration: "json|required",
          summary: "json|optional",
          raw: "json|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        partitions: {
          byResourceKey: {
            fields: {
              resourceKey: "string|required"
            }
          },
          byCloudId: {
            fields: {
              cloudId: "string|required"
            }
          }
        }
      },
      {
        name: changes,
        attributes: {
          id: "string|required",
          resourceKey: "string|required",
          cloudId: "string|required",
          driver: "string|required",
          fromVersion: "number|required",
          toVersion: "number|required",
          fromDigest: "string|required",
          toDigest: "string|required",
          diff: "json|required",
          summary: "json|optional",
          capturedAt: "string|required"
        },
        behavior: "body-overflow",
        timestamps: true,
        partitions: {
          byResourceKey: {
            fields: {
              resourceKey: "string|required"
            }
          },
          byCloudId: {
            fields: {
              cloudId: "string|required"
            }
          }
        }
      },
      {
        name: clouds,
        attributes: {
          id: "string|required",
          driver: "string|required",
          status: "string|default:idle",
          lastRunAt: "string|optional",
          lastRunId: "string|optional",
          lastSuccessAt: "string|optional",
          lastErrorAt: "string|optional",
          lastError: "string|optional",
          totalResources: "number|default:0",
          totalVersions: "number|default:0",
          lastResult: "json|optional",
          tags: "json|optional",
          metadata: "json|optional",
          schedule: "json|optional",
          checkpoint: "json|optional",
          checkpointUpdatedAt: "string|optional",
          rateLimit: "json|optional",
          rateLimitUpdatedAt: "string|optional",
          state: "json|optional",
          stateUpdatedAt: "string|optional",
          progress: "json|optional"
        },
        behavior: "body-overflow",
        timestamps: true
      }
    ];
    for (const definition of resourceDefinitions) {
      const [ok, err] = await tryFn(() => this.database.createResource(definition));
      if (!ok && err?.message?.includes("already exists")) {
        this._log("debug", "Resource already exists, skipping creation", { resource: definition.name });
      } else if (!ok) {
        throw err;
      }
    }
    this._resourceHandles.snapshots = this.database.resources[snapshots];
    this._resourceHandles.versions = this.database.resources[versions];
    this._resourceHandles.changes = this.database.resources[changes];
    this._resourceHandles.clouds = this.database.resources[clouds];
  }
  async _initializeDrivers() {
    for (const cloudDef of this.config.clouds) {
      const driverId = cloudDef.id;
      if (this.cloudDrivers.has(driverId)) continue;
      const schedule = normalizeSchedule(cloudDef.scheduled);
      const summary = await this._ensureCloudSummaryRecord(driverId, cloudDef, schedule);
      const driver = createCloudDriver(cloudDef.driver, {
        ...cloudDef,
        globals: this.config,
        schedule,
        logger: (level, message, meta = {}) => {
          this._log(level, message, { cloudId: driverId, driver: cloudDef.driver, ...meta });
        }
      });
      await driver.initialize();
      this.cloudDrivers.set(driverId, {
        driver,
        definition: { ...cloudDef, scheduled: schedule },
        summary
      });
      this._log("info", "Cloud driver initialized", { cloudId: driverId, driver: cloudDef.driver });
    }
  }
  async _destroyDrivers() {
    for (const [cloudId, { driver }] of this.cloudDrivers.entries()) {
      try {
        await driver.destroy?.();
      } catch (err) {
        this._log("warn", "Failed to destroy cloud driver", { cloudId, error: err.message });
      }
    }
    this.cloudDrivers.clear();
  }
  async _setupSchedules() {
    await this._teardownSchedules();
    const globalSchedule = this.config.scheduled;
    const cloudsWithSchedule = [...this.cloudDrivers.values()].filter((entry) => entry.definition.scheduled?.enabled);
    const needsCron = globalSchedule.enabled || cloudsWithSchedule.length > 0;
    if (!needsCron) return;
    await requirePluginDependency("cloud-inventory-plugin");
    if (!this._cron) {
      const cronModule = await import('node-cron');
      this._cron = cronModule.default || cronModule;
    }
    if (globalSchedule.enabled) {
      this._scheduleJob(globalSchedule, async () => {
        try {
          await this.syncAll({ reason: "scheduled-global" });
        } catch (err) {
          this._log("error", "Scheduled global sync failed", { error: err.message });
        }
      });
      if (globalSchedule.runOnStart) {
        this.syncAll({ reason: "scheduled-global-runOnStart" }).catch((err) => {
          this._log("error", "Initial global scheduled sync failed", { error: err.message });
        });
      }
    }
    for (const { definition } of this.cloudDrivers.values()) {
      const schedule = definition.scheduled;
      if (!schedule?.enabled) continue;
      const cloudId = definition.id;
      this._scheduleJob(schedule, async () => {
        try {
          await this.syncCloud(cloudId, { reason: "scheduled-cloud" });
        } catch (err) {
          this._log("error", "Scheduled cloud sync failed", { cloudId, error: err.message });
        }
      });
      if (schedule.runOnStart) {
        this.syncCloud(cloudId, { reason: "scheduled-cloud-runOnStart" }).catch((err) => {
          this._log("error", "Initial cloud scheduled sync failed", { cloudId, error: err.message });
        });
      }
    }
  }
  _scheduleJob(schedule, handler) {
    if (!this._cron) return;
    const job = this._cron.schedule(
      schedule.cron,
      handler,
      { timezone: schedule.timezone }
    );
    if (job?.start) {
      job.start();
    }
    this._scheduledJobs.push(job);
  }
  async _teardownSchedules() {
    if (!this._scheduledJobs.length) return;
    for (const job of this._scheduledJobs) {
      try {
        job?.stop?.();
        job?.destroy?.();
      } catch (err) {
        this._log("warn", "Failed to teardown scheduled job", { error: err.message });
      }
    }
    this._scheduledJobs = [];
  }
  _normalizeResource(cloudDefinition, entry) {
    if (!entry || typeof entry !== "object") {
      this._log("warn", "Skipping invalid resource entry", { cloudId: cloudDefinition.id });
      return null;
    }
    const configuration = ensureObject(
      entry.configuration ?? entry.state ?? entry.attributes ?? entry
    );
    const normalized = {
      cloudId: cloudDefinition.id,
      driver: cloudDefinition.driver,
      accountId: entry.accountId || cloudDefinition.config?.accountId || null,
      subscriptionId: entry.subscriptionId || null,
      organizationId: entry.organizationId || null,
      projectId: entry.projectId || cloudDefinition.config?.projectId || null,
      region: entry.region || entry.location || null,
      service: entry.service || entry.product || null,
      resourceType: entry.resourceType || entry.type || "unknown",
      resourceId: entry.resourceId || entry.id || configuration.id || configuration.arn || configuration.name,
      name: entry.name || configuration.name || configuration.displayName || null,
      tags: entry.tags || configuration.tags || null,
      labels: entry.labels || configuration.labels || null,
      metadata: entry.metadata || {},
      configuration
    };
    if (!normalized.resourceId) {
      this._log("warn", "Entry missing resource identifier, skipping", {
        cloudId: normalized.cloudId,
        driver: normalized.driver,
        resourceType: normalized.resourceType
      });
      return null;
    }
    normalized.resourceKey = [
      normalized.cloudId,
      normalized.resourceType,
      normalized.resourceId
    ].filter(Boolean).join(":");
    return normalized;
  }
  async _persistSnapshot(normalized, rawItem) {
    const now = (/* @__PURE__ */ new Date()).toISOString();
    const digest = computeDigest(normalized.configuration);
    const resourceKey = normalized.resourceKey;
    const snapshots = this._resourceHandles.snapshots;
    const versions = this._resourceHandles.versions;
    const changes = this._resourceHandles.changes;
    const existing = await snapshots.getOrNull(resourceKey);
    if (!existing) {
      const versionNumber = 1;
      const versionId = buildVersionId(resourceKey, versionNumber);
      await versions.insert({
        id: versionId,
        resourceKey,
        cloudId: normalized.cloudId,
        driver: normalized.driver,
        version: versionNumber,
        digest,
        capturedAt: now,
        configuration: normalized.configuration,
        summary: buildSummary(normalized),
        raw: rawItem
      });
      await snapshots.insert({
        id: resourceKey,
        cloudId: normalized.cloudId,
        driver: normalized.driver,
        accountId: normalized.accountId,
        subscriptionId: normalized.subscriptionId,
        organizationId: normalized.organizationId,
        projectId: normalized.projectId,
        region: normalized.region,
        service: normalized.service,
        resourceType: normalized.resourceType,
        resourceId: normalized.resourceId,
        name: normalized.name,
        tags: normalized.tags,
        labels: normalized.labels,
        metadata: normalized.metadata,
        latestDigest: digest,
        latestVersion: versionNumber,
        latestSnapshotId: versionId,
        firstSeenAt: now,
        lastSeenAt: now,
        changelogSize: 0
      });
      return { status: "created", resourceKey, version: versionNumber };
    }
    if (existing.latestDigest === digest) {
      await snapshots.update(resourceKey, { lastSeenAt: now });
      return { status: "unchanged", resourceKey, version: existing.latestVersion };
    }
    const previousVersionId = existing.latestSnapshotId;
    const previousVersion = await versions.getOrNull(previousVersionId);
    const nextVersionNumber = existing.latestVersion + 1;
    const nextVersionId = buildVersionId(resourceKey, nextVersionNumber);
    await versions.insert({
      id: nextVersionId,
      resourceKey,
      cloudId: normalized.cloudId,
      driver: normalized.driver,
      version: nextVersionNumber,
      digest,
      capturedAt: now,
      configuration: normalized.configuration,
      summary: buildSummary(normalized),
      raw: rawItem
    });
    const diff = computeDiff(previousVersion?.configuration, normalized.configuration);
    await changes.insert({
      id: `${resourceKey}:${existing.latestVersion}->${nextVersionNumber}`,
      resourceKey,
      cloudId: normalized.cloudId,
      driver: normalized.driver,
      fromVersion: existing.latestVersion,
      toVersion: nextVersionNumber,
      fromDigest: existing.latestDigest,
      toDigest: digest,
      diff,
      summary: {
        added: Object.keys(diff.added || {}).length,
        removed: Object.keys(diff.removed || {}).length,
        updated: Object.keys(diff.updated || {}).length
      },
      capturedAt: now
    });
    await snapshots.update(resourceKey, {
      latestDigest: digest,
      latestVersion: nextVersionNumber,
      latestSnapshotId: nextVersionId,
      lastSeenAt: now,
      changelogSize: (existing.changelogSize || 0) + 1,
      metadata: normalized.metadata,
      tags: normalized.tags,
      labels: normalized.labels,
      region: normalized.region,
      service: normalized.service,
      name: normalized.name
    });
    return { status: "updated", resourceKey, version: nextVersionNumber };
  }
  async _ensureCloudSummaryRecord(cloudId, cloudDef, schedule) {
    const clouds = this._resourceHandles.clouds;
    const existing = await clouds.getOrNull(cloudId);
    const payload = {
      driver: cloudDef.driver,
      schedule: schedule.enabled ? schedule : null,
      tags: cloudDef.tags ?? existing?.tags ?? null,
      metadata: cloudDef.metadata ?? existing?.metadata ?? null
    };
    if (!existing) {
      await clouds.insert({
        id: cloudId,
        status: "idle",
        totalResources: 0,
        totalVersions: 0,
        lastResult: null,
        checkpoint: null,
        rateLimit: null,
        ...payload
      });
      return await clouds.get(cloudId);
    }
    await clouds.update(cloudId, payload);
    return await clouds.get(cloudId);
  }
  async _updateCloudSummary(cloudId, patch) {
    const clouds = this._resourceHandles.clouds;
    if (!clouds) return;
    const [ok, err] = await tryFn(() => clouds.update(cloudId, patch));
    if (ok) return;
    if (err?.message?.includes("does not exist")) {
      await tryFn(() => clouds.insert({
        id: cloudId,
        status: "idle",
        totalResources: 0,
        totalVersions: 0,
        ...patch
      }));
    } else {
      this._log("warn", "Failed to update cloud summary", { cloudId, error: err?.message });
    }
  }
  _log(level, message, meta = {}) {
    if (this.config.logger) {
      this.config.logger(level, message, meta);
      return;
    }
    const shouldLog = this.config.verbose || level === "error" || level === "warn";
    if (shouldLog && typeof console[level] === "function") {
      console[level](`[CloudInventoryPlugin] ${message}`, meta);
    }
  }
}
function ensureObject(value) {
  if (value && typeof value === "object") return value;
  return {};
}
function computeDigest(payload) {
  const canonical = jsonStableStringify(payload ?? {});
  return createHash("sha256").update(canonical).digest("hex");
}
function buildVersionId(resourceKey, version) {
  return `${resourceKey}:${String(version).padStart(6, "0")}`;
}
function buildSummary(normalized) {
  return {
    name: normalized.name,
    region: normalized.region,
    service: normalized.service,
    resourceType: normalized.resourceType,
    tags: normalized.tags,
    labels: normalized.labels,
    metadata: normalized.metadata
  };
}
function computeDiff(previousConfig = {}, nextConfig = {}) {
  const prevFlat = flatten(previousConfig, { safe: true }) || {};
  const nextFlat = flatten(nextConfig, { safe: true }) || {};
  const diff = {
    added: {},
    removed: {},
    updated: {}
  };
  for (const key of Object.keys(nextFlat)) {
    if (!(key in prevFlat)) {
      diff.added[key] = nextFlat[key];
    } else if (!isEqual(prevFlat[key], nextFlat[key])) {
      diff.updated[key] = {
        before: prevFlat[key],
        after: nextFlat[key]
      };
    }
  }
  for (const key of Object.keys(prevFlat)) {
    if (!(key in nextFlat)) {
      diff.removed[key] = prevFlat[key];
    }
  }
  if (!Object.keys(diff.added).length) delete diff.added;
  if (!Object.keys(diff.removed).length) delete diff.removed;
  if (!Object.keys(diff.updated).length) delete diff.updated;
  return diff;
}
function isAsyncIterable(obj) {
  return obj?.[Symbol.asyncIterator];
}
function createRunIdentifier() {
  try {
    return randomUUID();
  } catch {
    return `run-${Date.now()}-${Math.random().toString(16).slice(2, 10)}`;
  }
}
function normalizeSchedule(input) {
  const schedule = {
    ...BASE_SCHEDULE,
    ...typeof input === "object" && input !== null ? input : {}
  };
  schedule.enabled = Boolean(schedule.enabled);
  schedule.cron = typeof schedule.cron === "string" && schedule.cron.trim().length > 0 ? schedule.cron.trim() : null;
  schedule.timezone = typeof schedule.timezone === "string" && schedule.timezone.trim().length > 0 ? schedule.timezone.trim() : void 0;
  schedule.runOnStart = Boolean(schedule.runOnStart);
  if (schedule.enabled && !schedule.cron) {
    throw new PluginError("Scheduled configuration requires a valid cron expression when enabled is true", {
      pluginName: "CloudInventoryPlugin",
      operation: "normalizeSchedule",
      statusCode: 400,
      retriable: false,
      suggestion: 'Set scheduled.cron to a valid cron expression (e.g., "0 * * * *") when enabling scheduled discovery.'
    });
  }
  return schedule;
}
function resolveDriverReference(driverInput, logFn) {
  if (typeof driverInput === "string") {
    return driverInput;
  }
  if (typeof driverInput === "function") {
    if (INLINE_DRIVER_NAMES.has(driverInput)) {
      return INLINE_DRIVER_NAMES.get(driverInput);
    }
    const baseName = sanitizeId(driverInput.name || "inline-driver");
    let candidate = `inline-${baseName}`;
    const existing = new Set(listCloudDrivers().concat([...INLINE_DRIVER_NAMES.values()]));
    let attempt = 1;
    while (existing.has(candidate)) {
      attempt += 1;
      candidate = `inline-${baseName}-${attempt}`;
    }
    registerCloudDriver(candidate, (options) => instantiateInlineDriver(driverInput, options));
    INLINE_DRIVER_NAMES.set(driverInput, candidate);
    if (typeof logFn === "function") {
      logFn("info", `Registered inline cloud driver "${candidate}"`, { driver: driverInput.name || "anonymous" });
    }
    return candidate;
  }
  throw new PluginError("Cloud driver must be a string identifier or a factory/class that produces a BaseCloudDriver instance", {
    pluginName: "CloudInventoryPlugin",
    operation: "resolveDriverReference",
    statusCode: 400,
    retriable: false,
    suggestion: "Register the driver name via registerCloudDriver() or supply a factory/class returning BaseCloudDriver."
  });
}
function instantiateInlineDriver(driverInput, options) {
  if (isSubclassOfBase(driverInput)) {
    return new driverInput(options);
  }
  const result = driverInput(options);
  if (result instanceof BaseCloudDriver) {
    return result;
  }
  if (result && typeof result === "object" && typeof result.listResources === "function") {
    return result;
  }
  throw new PluginError("Inline driver factory must return an instance of BaseCloudDriver", {
    pluginName: "CloudInventoryPlugin",
    operation: "instantiateInlineDriver",
    statusCode: 500,
    retriable: false,
    suggestion: "Ensure the inline driver function returns a BaseCloudDriver instance or class."
  });
}
function isSubclassOfBase(fn) {
  return typeof fn === "function" && (fn === BaseCloudDriver || fn.prototype instanceof BaseCloudDriver);
}
function normalizeCloudDefinitions(rawClouds, logFn) {
  const usedIds = /* @__PURE__ */ new Set();
  const results = [];
  const emitLog = (level, message, meta = {}) => {
    if (typeof logFn === "function") {
      logFn(level, message, meta);
    }
  };
  for (const cloud of rawClouds) {
    if (!cloud || typeof cloud !== "object") {
      continue;
    }
    const driverName = resolveDriverReference(cloud.driver, emitLog);
    const cloudWithDriver = { ...cloud, driver: driverName };
    let id = typeof cloudWithDriver.id === "string" && cloudWithDriver.id.trim().length > 0 ? cloudWithDriver.id.trim() : null;
    if (!id) {
      const derived = deriveCloudId(cloudWithDriver);
      let candidate = derived;
      let attempt = 1;
      while (usedIds.has(candidate)) {
        attempt += 1;
        candidate = `${derived}-${attempt}`;
      }
      id = candidate;
      emitLog("info", `Cloud id not provided for driver "${driverName}", using derived id "${id}"`, { driver: driverName });
    } else if (usedIds.has(id)) {
      let candidate = id;
      let attempt = 1;
      while (usedIds.has(candidate)) {
        attempt += 1;
        candidate = `${id}-${attempt}`;
      }
      emitLog("warn", `Duplicated cloud id "${id}" detected, using "${candidate}" instead`, { driver: driverName });
      id = candidate;
    }
    usedIds.add(id);
    results.push({ ...cloudWithDriver, id });
  }
  return results;
}
function deriveCloudId(cloud) {
  const driver = (cloud.driver || "cloud").toString().toLowerCase();
  const hints = extractIdentityHints(cloud);
  const base = hints.length > 0 ? `${driver}-${sanitizeId(hints[0])}` : driver;
  return base || driver;
}
function extractIdentityHints(cloud) {
  const values = [];
  const candidatePaths = [
    ["config", "accountId"],
    ["config", "projectId"],
    ["config", "subscriptionId"],
    ["credentials", "accountId"],
    ["credentials", "accountNumber"],
    ["credentials", "subscriptionId"],
    ["credentials", "tenantId"],
    ["credentials", "email"],
    ["credentials", "user"],
    ["credentials", "profile"],
    ["credentials", "organizationId"]
  ];
  for (const path of candidatePaths) {
    let ref = cloud;
    for (const segment of path) {
      if (ref && typeof ref === "object" && segment in ref) {
        ref = ref[segment];
      } else {
        ref = null;
        break;
      }
    }
    if (typeof ref === "string" && ref.trim().length > 0) {
      values.push(ref.trim());
    }
  }
  return values;
}
function sanitizeId(value) {
  return value.toLowerCase().replace(/[^a-z0-9._-]+/g, "-").replace(/^-+|-+$/g, "").slice(0, 80) || "cloud";
}

class ImporterDriver extends EventEmitter$1 {
  constructor(config) {
    super();
    this.config = config;
  }
  /**
   * Parse file and return records
   * @param {string} filePath - Path to file
   * @param {Object} options - Parser options
   * @returns {AsyncIterator<Object>} - Async iterator of records
   */
  async *parse(filePath, options) {
    throw new PluginError("Importer driver must implement parse()", {
      pluginName: "ImporterPlugin",
      operation: "driver.parse",
      statusCode: 500,
      retriable: false,
      suggestion: "Ensure custom importer drivers override parse(filePath, options)."
    });
  }
  /**
   * Validate file format
   * @param {string} filePath - Path to file
   * @returns {boolean}
   */
  async validate(filePath) {
    return true;
  }
}
class JSONImportDriver extends ImporterDriver {
  async *parse(filePath, options = {}) {
    const isGzipped = filePath.endsWith(".gz");
    let fileStream = fs.createReadStream(filePath);
    if (isGzipped) {
      const gunzip = zlib.createGunzip();
      fileStream = fileStream.pipe(gunzip);
      fileStream.setEncoding("utf8");
    } else {
      fileStream.setEncoding("utf8");
    }
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });
    let buffer = "";
    let inArray = false;
    let lineNumber = 0;
    let firstNonEmpty = true;
    for await (const line of rl) {
      lineNumber++;
      const trimmed = line.trim();
      if (!trimmed) continue;
      if (firstNonEmpty) {
        firstNonEmpty = false;
        if (trimmed.startsWith("[")) {
          inArray = true;
          buffer = trimmed;
          if (trimmed.endsWith("]")) {
            try {
              const array = JSON.parse(buffer);
              if (Array.isArray(array)) {
                for (const record of array) {
                  yield record;
                }
              } else {
                throw new PluginError("JSON import expects an array of objects", {
                  pluginName: "ImporterPlugin",
                  operation: "JSONImportDriver.parse",
                  statusCode: 400,
                  retriable: false,
                  suggestion: "Ensure the JSON file contains an array at the root (e.g., [ {...}, {...} ])."
                });
              }
            } catch (error) {
              throw new PluginError(`Failed to parse JSON array: ${error.message}`, {
                pluginName: "ImporterPlugin",
                operation: "JSONImportDriver.parse",
                statusCode: 400,
                retriable: false,
                suggestion: "Validate JSON syntax; consider using jsonlint before importing.",
                original: error
              });
            }
            buffer = "";
            inArray = false;
          }
          continue;
        }
      }
      if (inArray) {
        buffer += "\n" + trimmed;
        if (trimmed === "]" || trimmed.endsWith("]")) {
          try {
            const array = JSON.parse(buffer);
            if (Array.isArray(array)) {
              for (const record of array) {
                yield record;
              }
            } else {
              throw new PluginError("JSON import expects an array of objects", {
                pluginName: "ImporterPlugin",
                operation: "JSONImportDriver.parse",
                statusCode: 400,
                retriable: false,
                suggestion: "Ensure the JSON file contains an array at the root (e.g., [ {...}, {...} ])."
              });
            }
          } catch (error) {
            throw new PluginError(`Failed to parse JSON array: ${error.message}`, {
              pluginName: "ImporterPlugin",
              operation: "JSONImportDriver.parse",
              statusCode: 400,
              retriable: false,
              suggestion: "Validate JSON syntax; consider using jsonlint before importing.",
              original: error
            });
          }
          buffer = "";
          inArray = false;
        }
      } else {
        try {
          const record = JSON.parse(trimmed);
          yield record;
        } catch (error) {
          if (this.listenerCount("error") > 0) {
            this.emit("error", {
              line: lineNumber,
              message: `Invalid JSON on line ${lineNumber}: ${error.message}`,
              data: trimmed
            });
          }
        }
      }
    }
  }
  async validate(filePath) {
    if (!fs.existsSync(filePath)) {
      throw new PluginError(`File not found: ${filePath}`, {
        pluginName: "ImporterPlugin",
        operation: "JSONImportDriver.validate",
        statusCode: 404,
        retriable: false,
        suggestion: "Verify the file path before importing or ensure the file is accessible to the process.",
        filePath
      });
    }
    const lowerPath = filePath.toLowerCase();
    if (lowerPath.endsWith(".gz")) {
      const parts = lowerPath.split(".");
      if (parts.length < 3) {
        throw new PluginError("Invalid file extension for JSON driver: .gz without format extension", {
          pluginName: "ImporterPlugin",
          operation: "JSONImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Rename the file to include the format before .gz (e.g., data.json.gz).",
          filePath
        });
      }
      const formatExt = parts[parts.length - 2];
      if (!["json", "jsonl", "ndjson"].includes(formatExt)) {
        throw new PluginError(`Invalid file extension for JSON driver: .${formatExt}.gz (expected .json.gz, .jsonl.gz, or .ndjson.gz)`, {
          pluginName: "ImporterPlugin",
          operation: "JSONImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Use supported extensions (.json, .jsonl, .ndjson) before .gz compression.",
          filePath
        });
      }
    } else {
      const ext = lowerPath.split(".").pop();
      if (!["json", "jsonl", "ndjson"].includes(ext)) {
        throw new PluginError(`Invalid file extension for JSON driver: .${ext}`, {
          pluginName: "ImporterPlugin",
          operation: "JSONImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Rename the file to use .json, .jsonl, or .ndjson extensions.",
          filePath
        });
      }
    }
    return true;
  }
}
class CSVImportDriver extends ImporterDriver {
  async *parse(filePath, options = {}) {
    const delimiter = options.delimiter || await this._detectDelimiter(filePath);
    const hasHeader = options.hasHeader !== void 0 ? options.hasHeader : true;
    const isGzipped = filePath.endsWith(".gz");
    let fileStream = fs.createReadStream(filePath);
    if (isGzipped) {
      const gunzip = zlib.createGunzip();
      fileStream = fileStream.pipe(gunzip);
      fileStream.setEncoding("utf8");
    } else {
      fileStream.setEncoding("utf8");
    }
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });
    let headers = null;
    let lineNumber = 0;
    for await (const line of rl) {
      lineNumber++;
      if (!line.trim()) continue;
      const fields = this._parseLine(line, delimiter);
      if (lineNumber === 1 && hasHeader) {
        headers = fields;
        continue;
      }
      let record;
      if (headers) {
        record = {};
        for (let i = 0; i < Math.min(headers.length, fields.length); i++) {
          record[headers[i]] = fields[i];
        }
      } else {
        record = Object.fromEntries(fields.map((val, idx) => [String(idx), val]));
      }
      yield record;
    }
  }
  /**
   * Parse a single CSV line, handling quotes and escaped delimiters
   * @private
   */
  _parseLine(line, delimiter) {
    const fields = [];
    let current = "";
    let inQuotes = false;
    for (let i = 0; i < line.length; i++) {
      const char = line[i];
      const nextChar = line[i + 1];
      if (char === '"') {
        if (inQuotes && nextChar === '"') {
          current += '"';
          i++;
        } else {
          inQuotes = !inQuotes;
        }
      } else if (char === delimiter && !inQuotes) {
        fields.push(current.trim());
        current = "";
      } else {
        current += char;
      }
    }
    fields.push(current.trim());
    return fields;
  }
  /**
   * Auto-detect delimiter from first few lines
   * @private
   */
  async _detectDelimiter(filePath) {
    const isGzipped = filePath.endsWith(".gz");
    let fileStream = fs.createReadStream(filePath);
    if (isGzipped) {
      const gunzip = zlib.createGunzip();
      fileStream = fileStream.pipe(gunzip);
      fileStream.setEncoding("utf8");
    } else {
      fileStream.setEncoding("utf8");
    }
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });
    const delimiters = [",", ";", "	", "|"];
    const counts = {};
    let linesRead = 0;
    for await (const line of rl) {
      if (linesRead >= 5) break;
      linesRead++;
      for (const delimiter of delimiters) {
        counts[delimiter] = (counts[delimiter] || 0) + (line.split(delimiter).length - 1);
      }
    }
    fileStream.destroy();
    let maxCount = 0;
    let bestDelimiter = ",";
    for (const [delimiter, count] of Object.entries(counts)) {
      if (count > maxCount) {
        maxCount = count;
        bestDelimiter = delimiter;
      }
    }
    return bestDelimiter;
  }
  async validate(filePath) {
    if (!fs.existsSync(filePath)) {
      throw new PluginError(`File not found: ${filePath}`, {
        pluginName: "ImporterPlugin",
        operation: "CSVImportDriver.validate",
        statusCode: 404,
        retriable: false,
        suggestion: "Verify the CSV file path or download it locally before importing.",
        filePath
      });
    }
    const lowerPath = filePath.toLowerCase();
    if (lowerPath.endsWith(".gz")) {
      const parts = lowerPath.split(".");
      if (parts.length < 3) {
        throw new PluginError("Invalid file extension for CSV driver: .gz without format extension", {
          pluginName: "ImporterPlugin",
          operation: "CSVImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Rename the file to include .csv or .tsv before .gz (e.g., data.csv.gz).",
          filePath
        });
      }
      const formatExt = parts[parts.length - 2];
      if (!["csv", "tsv", "txt"].includes(formatExt)) {
        throw new PluginError(`Invalid file extension for CSV driver: .${formatExt}.gz (expected .csv.gz or .tsv.gz)`, {
          pluginName: "ImporterPlugin",
          operation: "CSVImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Use supported extensions (.csv, .tsv, .txt) before gzip compression.",
          filePath
        });
      }
    } else {
      const ext = lowerPath.split(".").pop();
      if (!["csv", "tsv", "txt"].includes(ext)) {
        throw new PluginError(`Invalid file extension for CSV driver: .${ext}`, {
          pluginName: "ImporterPlugin",
          operation: "CSVImportDriver.validate",
          statusCode: 400,
          retriable: false,
          suggestion: "Rename the file to use .csv, .tsv, or .txt extensions.",
          filePath
        });
      }
    }
    return true;
  }
}
class ParquetImportDriver extends ImporterDriver {
  async *parse(filePath, options = {}) {
    throw new PluginError("ParquetImportDriver not yet implemented", {
      pluginName: "ImporterPlugin",
      operation: "ParquetImportDriver.parse",
      statusCode: 501,
      retriable: false,
      suggestion: "Parquet import support is under development. Convert data to CSV/JSON or implement a custom driver."
    });
  }
}
class ExcelImportDriver extends ImporterDriver {
  async *parse(filePath, options = {}) {
    throw new PluginError("ExcelImportDriver not yet implemented", {
      pluginName: "ImporterPlugin",
      operation: "ExcelImportDriver.parse",
      statusCode: 501,
      retriable: false,
      suggestion: "Convert Excel files to CSV/JSON or implement a custom Excel driver before importing."
    });
  }
}
class ImporterPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.resourceName = config.resource || config.resourceName;
    this.format = config.format || "json";
    this.mapping = config.mapping || {};
    this.transforms = config.transforms || {};
    this.validate = config.validate || null;
    this.deduplicateBy = config.deduplicateBy || null;
    this.batchSize = config.batchSize || 1e3;
    this.parallelism = config.parallelism || 10;
    this.continueOnError = config.continueOnError !== void 0 ? config.continueOnError : true;
    this.streaming = config.streaming !== void 0 ? config.streaming : true;
    this.driverConfig = config.driverConfig || {};
    this.sheet = config.sheet || 0;
    this.headerRow = config.headerRow || 0;
    this.startRow = config.startRow || 1;
    this.binarySchema = config.binarySchema || null;
    this.recordSize = config.recordSize || null;
    this.resource = null;
    this.driver = null;
    this.seenKeys = /* @__PURE__ */ new Set();
    this.stats = {
      totalProcessed: 0,
      totalInserted: 0,
      totalSkipped: 0,
      totalErrors: 0,
      totalDuplicates: 0,
      startTime: null,
      endTime: null
    };
  }
  /**
   * Install plugin
   */
  async onInstall() {
    try {
      this.resource = this.database.resources[this.resourceName];
      if (this.resource && typeof this.resource.then === "function") {
        this.resource = await this.resource;
      }
    } catch (error) {
      throw new PluginError(`Resource "${this.resourceName}" not found`, {
        pluginName: "ImporterPlugin",
        operation: "onInstall",
        statusCode: 404,
        retriable: false,
        suggestion: "Create the target resource before running ImporterPlugin or update the configuration.",
        resourceName: this.resourceName,
        original: error
      });
    }
    if (!this.resource) {
      throw new PluginError(`Resource "${this.resourceName}" not found`, {
        pluginName: "ImporterPlugin",
        operation: "onInstall",
        statusCode: 404,
        retriable: false,
        suggestion: "Create the target resource before running ImporterPlugin or update the configuration.",
        resourceName: this.resourceName
      });
    }
    this.driver = this._createDriver(this.format);
    this.emit("installed", {
      plugin: "ImporterPlugin",
      resource: this.resourceName,
      format: this.format
    });
  }
  /**
   * Create driver for format
   * @private
   */
  _createDriver(format) {
    switch (format.toLowerCase()) {
      case "json":
      case "jsonl":
      case "ndjson":
        return new JSONImportDriver(this.driverConfig);
      case "csv":
      case "tsv":
        return new CSVImportDriver(this.driverConfig);
      case "parquet":
        return new ParquetImportDriver(this.driverConfig);
      case "excel":
      case "xls":
      case "xlsx":
        return new ExcelImportDriver(this.driverConfig);
      default:
        throw new PluginError(`Unsupported import format: ${format}`, {
          pluginName: "ImporterPlugin",
          operation: "_createDriver",
          statusCode: 400,
          retriable: false,
          suggestion: "Use one of the supported formats: json, jsonl, ndjson, csv, tsv, parquet, excel.",
          format
        });
    }
  }
  /**
   * Import data from file
   * @param {string} filePath - Path to file (local, S3, or URL)
   * @param {Object} options - Import options
   * @returns {Promise<Object>} - Import result
   */
  async import(filePath, options = {}) {
    this.stats.startTime = Date.now();
    this.stats.totalProcessed = 0;
    this.stats.totalInserted = 0;
    this.stats.totalSkipped = 0;
    this.stats.totalErrors = 0;
    this.stats.totalDuplicates = 0;
    this.seenKeys.clear();
    try {
      await this.driver.validate(filePath);
      const records = [];
      let batch = [];
      for await (const record of this.driver.parse(filePath, options)) {
        this.stats.totalProcessed++;
        const transformed = this._transformRecord(record);
        const mapped = this._mapRecord(transformed);
        if (this.validate && !this.validate(mapped)) {
          this.stats.totalSkipped++;
          if (this.listenerCount("error") > 0) {
            this.emit("error", {
              row: this.stats.totalProcessed,
              message: "Validation failed",
              record: mapped
            });
          }
          if (!this.continueOnError) {
            throw new PluginError("Validation failed", {
              pluginName: "ImporterPlugin",
              operation: "import",
              statusCode: 422,
              retriable: false,
              suggestion: "Fix the invalid record or enable continueOnError to skip bad rows.",
              row: this.stats.totalProcessed,
              record: mapped
            });
          }
          continue;
        }
        if (this.deduplicateBy) {
          const key = mapped[this.deduplicateBy];
          if (this.seenKeys.has(key)) {
            this.stats.totalDuplicates++;
            continue;
          }
          this.seenKeys.add(key);
        }
        batch.push(mapped);
        if (batch.length >= this.batchSize) {
          await this._processBatch(batch);
          batch = [];
          this.emit("progress", {
            processed: this.stats.totalProcessed,
            inserted: this.stats.totalInserted,
            skipped: this.stats.totalSkipped,
            errors: this.stats.totalErrors,
            percent: 0
            // Unknown total for streaming
          });
        }
      }
      if (batch.length > 0) {
        await this._processBatch(batch);
      }
      this.stats.endTime = Date.now();
      const result = {
        processed: this.stats.totalProcessed,
        inserted: this.stats.totalInserted,
        skipped: this.stats.totalSkipped,
        errors: this.stats.totalErrors,
        duplicates: this.stats.totalDuplicates,
        duration: this.stats.endTime - this.stats.startTime
      };
      this.emit("complete", result);
      return result;
    } catch (error) {
      if (this.listenerCount("error") > 0) {
        this.emit("error", { message: error.message, error });
      }
      throw error;
    }
  }
  /**
   * Map record fields according to mapping config
   * @private
   */
  _mapRecord(record) {
    if (Object.keys(this.mapping).length === 0) {
      return record;
    }
    const mapped = {};
    for (const [sourceField, targetField] of Object.entries(this.mapping)) {
      if (sourceField in record) {
        mapped[targetField] = record[sourceField];
      }
    }
    return mapped;
  }
  /**
   * Transform record fields according to transforms config
   * @private
   */
  _transformRecord(record, originalRecord = null) {
    if (Object.keys(this.transforms).length === 0) {
      return record;
    }
    const transformed = { ...record };
    const contextRecord = originalRecord || record;
    for (const [field, transformFn] of Object.entries(this.transforms)) {
      if (field in transformed) {
        transformed[field] = transformFn(transformed[field], contextRecord);
      }
    }
    return transformed;
  }
  /**
   * Process batch of records with parallelism
   * @private
   */
  async _processBatch(records) {
    const batches = [];
    for (let i = 0; i < records.length; i += this.parallelism) {
      batches.push(records.slice(i, i + this.parallelism));
    }
    for (const batch of batches) {
      const promises = batch.map(async (record) => {
        const [ok, err] = await tryFn(async () => {
          return await this.resource.insert(record);
        });
        if (ok) {
          this.stats.totalInserted++;
        } else {
          this.stats.totalErrors++;
          if (this.listenerCount("error") > 0) {
            this.emit("error", {
              message: err.message,
              record,
              error: err
            });
          }
          if (!this.continueOnError) throw err;
        }
      });
      await Promise.all(promises);
    }
  }
  /**
   * Get statistics
   */
  getStats() {
    return {
      ...this.stats,
      recordsPerSecond: this.stats.endTime ? Math.round(this.stats.totalProcessed / ((this.stats.endTime - this.stats.startTime) / 1e3)) : 0
    };
  }
}
const Transformers = {
  parseDate: (format) => (value) => {
    return new Date(value).getTime();
  },
  parseFloat: (decimals = 2) => (value) => {
    return parseFloat(parseFloat(value).toFixed(decimals));
  },
  parseInt: () => (value) => {
    return parseInt(value, 10);
  },
  toLowerCase: () => (value) => {
    return String(value).toLowerCase();
  },
  toUpperCase: () => (value) => {
    return String(value).toUpperCase();
  },
  split: (delimiter = ",") => (value) => {
    return String(value).split(delimiter).map((s) => s.trim());
  },
  parseJSON: () => (value) => {
    try {
      return JSON.parse(value);
    } catch {
      return value;
    }
  },
  trim: () => (value) => {
    return String(value).trim();
  }
};

class SqsConsumer {
  constructor({ queueUrl, onMessage, onError, poolingInterval = 5e3, maxMessages = 10, region = "us-east-1", credentials, endpoint, driver = "sqs" }) {
    this.driver = driver;
    this.queueUrl = queueUrl;
    this.onMessage = onMessage;
    this.onError = onError;
    this.poolingInterval = poolingInterval;
    this.maxMessages = maxMessages;
    this.region = region;
    this.credentials = credentials;
    this.endpoint = endpoint;
    this.sqs = null;
    this._stopped = false;
    this._timer = null;
    this._pollPromise = null;
    this._pollResolve = null;
    this._SQSClient = null;
    this._ReceiveMessageCommand = null;
    this._DeleteMessageCommand = null;
  }
  async start() {
    await requirePluginDependency("sqs-consumer");
    const [ok, err, sdk] = await tryFn(() => import('@aws-sdk/client-sqs'));
    if (!ok) {
      throw new PluginError("SqsConsumer requires @aws-sdk/client-sqs", {
        pluginName: "ConsumersPlugin",
        operation: "SqsConsumer.start",
        statusCode: 500,
        retriable: false,
        suggestion: "Install @aws-sdk/client-sqs as a dependency to enable SQS consumption.",
        original: err
      });
    }
    const { SQSClient, ReceiveMessageCommand, DeleteMessageCommand } = sdk;
    this._SQSClient = SQSClient;
    this._ReceiveMessageCommand = ReceiveMessageCommand;
    this._DeleteMessageCommand = DeleteMessageCommand;
    this.sqs = new SQSClient({ region: this.region, credentials: this.credentials, endpoint: this.endpoint });
    this._stopped = false;
    this._pollPromise = new Promise((resolve) => {
      this._pollResolve = resolve;
    });
    this._poll();
  }
  async stop() {
    this._stopped = true;
    if (this._timer) {
      clearTimeout(this._timer);
      this._timer = null;
    }
    if (this._pollResolve) {
      this._pollResolve();
    }
  }
  async _poll() {
    if (this._stopped) {
      if (this._pollResolve) this._pollResolve();
      return;
    }
    const [ok, err, result] = await tryFn(async () => {
      const cmd = new this._ReceiveMessageCommand({
        QueueUrl: this.queueUrl,
        MaxNumberOfMessages: this.maxMessages,
        WaitTimeSeconds: 10,
        MessageAttributeNames: ["All"]
      });
      const { Messages } = await this.sqs.send(cmd);
      if (Messages && Messages.length > 0) {
        for (const msg of Messages) {
          const [okMsg, errMsg] = await tryFn(async () => {
            const parsedMsg = this._parseMessage(msg);
            await this.onMessage(parsedMsg, msg);
            await this.sqs.send(new this._DeleteMessageCommand({
              QueueUrl: this.queueUrl,
              ReceiptHandle: msg.ReceiptHandle
            }));
          });
          if (!okMsg && this.onError) {
            this.onError(errMsg, msg);
          }
        }
      }
    });
    if (!ok && this.onError) {
      this.onError(err);
    }
    this._timer = setTimeout(() => this._poll(), this.poolingInterval);
  }
  _parseMessage(msg) {
    let body;
    const [ok, err, parsed] = tryFn(() => JSON.parse(msg.Body));
    body = ok ? parsed : msg.Body;
    const attributes = {};
    if (msg.MessageAttributes) {
      for (const [k, v] of Object.entries(msg.MessageAttributes)) {
        attributes[k] = v.StringValue;
      }
    }
    return { $body: body, $attributes: attributes, $raw: msg };
  }
}

class RabbitMqConsumer {
  constructor({ amqpUrl, queue, prefetch = 10, reconnectInterval = 2e3, onMessage, onError, driver = "rabbitmq" }) {
    this.amqpUrl = amqpUrl;
    this.queue = queue;
    this.prefetch = prefetch;
    this.reconnectInterval = reconnectInterval;
    this.onMessage = onMessage;
    this.onError = onError;
    this.driver = driver;
    this.connection = null;
    this.channel = null;
    this._stopped = false;
  }
  async start() {
    await requirePluginDependency("rabbitmq-consumer");
    this._stopped = false;
    await this._connect();
  }
  async stop() {
    this._stopped = true;
    if (this.channel) await this.channel.close();
    if (this.connection) await this.connection.close();
  }
  async _connect() {
    const [ok, err] = await tryFn(async () => {
      const amqp = (await import('amqplib')).default;
      this.connection = await amqp.connect(this.amqpUrl);
      this.channel = await this.connection.createChannel();
      await this.channel.assertQueue(this.queue, { durable: true });
      this.channel.prefetch(this.prefetch);
      this.channel.consume(this.queue, async (msg) => {
        if (msg !== null) {
          const [okMsg, errMsg] = await tryFn(async () => {
            const content = JSON.parse(msg.content.toString());
            await this.onMessage({ $body: content, $raw: msg });
            this.channel.ack(msg);
          });
          if (!okMsg) {
            if (this.onError) this.onError(errMsg, msg);
            this.channel.nack(msg, false, false);
          }
        }
      });
    });
    if (!ok) {
      if (this.onError) this.onError(err);
      if (!this._stopped) {
        setTimeout(() => this._connect(), this.reconnectInterval);
      }
    }
  }
}

const CONSUMER_DRIVERS = {
  sqs: SqsConsumer,
  rabbitmq: RabbitMqConsumer
  // kafka: KafkaConsumer, // futuro
};
function createConsumer(driver, config) {
  const ConsumerClass = CONSUMER_DRIVERS[driver];
  if (!ConsumerClass) {
    throw new PluginError(`Unknown consumer driver: ${driver}`, {
      pluginName: "ConsumersPlugin",
      operation: "createConsumer",
      statusCode: 400,
      retriable: false,
      suggestion: `Use one of the available drivers: ${Object.keys(CONSUMER_DRIVERS).join(", ")}`,
      driver
    });
  }
  return new ConsumerClass(config);
}

class QueueConsumerPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.options = options;
    this.driversConfig = Array.isArray(options.consumers) ? options.consumers : [];
    this.consumers = [];
  }
  async onInstall() {
    for (const driverDef of this.driversConfig) {
      const { driver, config: driverConfig = {}, consumers: consumerDefs = [] } = driverDef;
      for (const consumerDef of consumerDefs) {
        const { resources, ...consumerConfig } = consumerDef;
        const resourceList = Array.isArray(resources) ? resources : [resources];
        for (const resource of resourceList) {
          const mergedConfig = { ...driverConfig, ...consumerConfig };
          const consumer = createConsumer(driver, {
            ...mergedConfig,
            onMessage: (msg) => this._handleMessage(msg, resource),
            onError: (err, raw) => this._handleError(err, raw, resource)
          });
          await consumer.start();
          this.consumers.push(consumer);
        }
      }
    }
  }
  async stop() {
    if (!Array.isArray(this.consumers)) this.consumers = [];
    for (const consumer of this.consumers) {
      if (consumer && typeof consumer.stop === "function") {
        await consumer.stop();
      }
    }
    this.consumers = [];
  }
  async _handleMessage(msg, configuredResource) {
    this.options;
    let body = msg.$body || msg;
    if (body.$body && !body.resource && !body.action && !body.data) {
      body = body.$body;
    }
    let resource = body.resource || msg.resource;
    let action = body.action || msg.action;
    let data = body.data || msg.data;
    if (!resource) {
      throw new QueueError("Resource not found in message", {
        operation: "handleMessage",
        queueName: configuredResource,
        messageBody: body,
        suggestion: 'Ensure message includes a "resource" field specifying the target resource name'
      });
    }
    if (!action) {
      throw new QueueError("Action not found in message", {
        operation: "handleMessage",
        queueName: configuredResource,
        resource,
        messageBody: body,
        suggestion: 'Ensure message includes an "action" field (insert, update, or delete)'
      });
    }
    const resourceObj = this.database.resources[resource];
    if (!resourceObj) {
      throw new QueueError(`Resource '${resource}' not found`, {
        operation: "handleMessage",
        queueName: configuredResource,
        resource,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before consuming messages"
      });
    }
    let result;
    const [ok, err, res] = await tryFn(async () => {
      if (action === "insert") {
        result = await resourceObj.insert(data);
      } else if (action === "update") {
        const { id: updateId, ...updateAttributes } = data;
        result = await resourceObj.update(updateId, updateAttributes);
      } else if (action === "delete") {
        result = await resourceObj.delete(data.id);
      } else {
        throw new QueueError(`Unsupported action '${action}'`, {
          operation: "handleMessage",
          queueName: configuredResource,
          resource,
          action,
          supportedActions: ["insert", "update", "delete"],
          suggestion: "Use one of the supported actions: insert, update, or delete"
        });
      }
      return result;
    });
    if (!ok) {
      throw err;
    }
    return res;
  }
  _handleError(err, raw, resourceName) {
  }
}

class RelationError extends PluginError {
  constructor(message, context = {}) {
    const merged = {
      pluginName: context.pluginName || "RelationPlugin",
      operation: context.operation || "unknown",
      statusCode: context.statusCode ?? 500,
      retriable: context.retriable ?? false,
      suggestion: context.suggestion ?? "Inspect relation configuration (type, resource, foreign keys) before retrying.",
      ...context
    };
    super(message, merged);
    this.name = "RelationError";
  }
}
class RelationConfigError extends RelationError {
  constructor(message, context = {}) {
    super(message, {
      statusCode: context.statusCode ?? 400,
      retriable: context.retriable ?? false,
      suggestion: context.suggestion ?? "Review relation configuration fields (type, resource, localKey, foreignKey).",
      ...context
    });
    this.name = "RelationConfigError";
  }
}
class UnsupportedRelationTypeError extends RelationError {
  constructor(type, context = {}) {
    super(`Unsupported relation type: ${type}. Supported types: hasOne, hasMany, belongsTo, belongsToMany`, {
      statusCode: context.statusCode ?? 400,
      retriable: false,
      suggestion: context.suggestion ?? "Use one of the supported relation types or implement a custom handler.",
      relationType: type,
      ...context
    });
    this.name = "UnsupportedRelationTypeError";
    this.relationType = type;
  }
}
class RelatedResourceNotFoundError extends RelationError {
  constructor(resourceName, context = {}) {
    super(`Related resource "${resourceName}" not found`, {
      statusCode: context.statusCode ?? 404,
      retriable: false,
      suggestion: context.suggestion ?? "Ensure the related resource is created and registered before defining the relation.",
      resourceName,
      ...context
    });
    this.name = "RelatedResourceNotFoundError";
    this.resourceName = resourceName;
  }
}
class JunctionTableNotFoundError extends RelationError {
  constructor(junctionTable, context = {}) {
    super(`Junction table "${junctionTable}" not found for belongsToMany relation`, {
      statusCode: context.statusCode ?? 404,
      retriable: false,
      suggestion: context.suggestion ?? "Create the junction resource or update belongsToMany configuration to reference an existing one.",
      junctionTable,
      ...context
    });
    this.name = "JunctionTableNotFoundError";
    this.junctionTable = junctionTable;
  }
}
class CascadeError extends RelationError {
  constructor(operation, resourceName, recordId, originalError, context = {}) {
    super(
      `Cascade ${operation} failed for resource "${resourceName}" record "${recordId}": ${originalError.message}`,
      {
        retriable: context.retriable ?? false,
        suggestion: context.suggestion ?? "Check cascade configuration and ensure dependent records allow deletion/update.",
        operation,
        resourceName,
        recordId,
        originalError,
        ...context
      }
    );
    this.name = "CascadeError";
    this.operation = operation;
    this.resourceName = resourceName;
    this.recordId = recordId;
    this.originalError = originalError;
  }
}
class InvalidIncludePathError extends RelationError {
  constructor(path, reason, context = {}) {
    super(`Invalid include path "${path}": ${reason}`, {
      statusCode: context.statusCode ?? 400,
      retriable: false,
      suggestion: context.suggestion ?? "Verify include syntax (users.posts.comments) and ensure each relation exists.",
      includePath: path,
      reason,
      ...context
    });
    this.name = "InvalidIncludePathError";
    this.includePath = path;
    this.reason = reason;
  }
}

class RelationPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.relations = config.relations || {};
    this.cache = config.cache !== void 0 ? config.cache : true;
    this.batchSize = config.batchSize || 100;
    this.preventN1 = config.preventN1 !== void 0 ? config.preventN1 : true;
    this.verbose = config.verbose || false;
    this.fallbackLimit = config.fallbackLimit !== void 0 ? config.fallbackLimit : null;
    this.cascadeBatchSize = config.cascadeBatchSize || 10;
    this.cascadeTransactions = config.cascadeTransactions !== void 0 ? config.cascadeTransactions : false;
    this._loaderCache = /* @__PURE__ */ new Map();
    this._partitionCache = /* @__PURE__ */ new Map();
    this.stats = {
      totalRelationLoads: 0,
      cachedLoads: 0,
      batchLoads: 0,
      cascadeOperations: 0,
      partitionCacheHits: 0,
      deduplicatedQueries: 0,
      fallbackLimitWarnings: 0
    };
  }
  /**
   * Install the plugin (lifecycle hook)
   * @override
   */
  async onInstall() {
    console.log("[RelationPlugin] onInstall() called");
    console.log("[RelationPlugin] Database connected:", !!this.database);
    console.log("[RelationPlugin] Relations:", Object.keys(this.relations));
    this._validateRelationsConfig();
    for (const [resourceName, relationsDef] of Object.entries(this.relations)) {
      await this._setupResourceRelations(resourceName, relationsDef);
    }
    this.database.addHook("afterCreateResource", async (context) => {
      const { resource } = context;
      const relationsDef = this.relations[resource.name];
      if (relationsDef) {
        await this._setupResourceRelations(resource.name, relationsDef);
      }
    });
    if (this.verbose) {
      console.log(`[RelationPlugin] Installed with ${Object.keys(this.relations).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "RelationPlugin",
      resources: Object.keys(this.relations)
    });
  }
  /**
   * Validate all relations configuration
   * @private
   */
  _validateRelationsConfig() {
    for (const [resourceName, relationsDef] of Object.entries(this.relations)) {
      for (const [relationName, config] of Object.entries(relationsDef)) {
        const validTypes = ["hasOne", "hasMany", "belongsTo", "belongsToMany"];
        if (!validTypes.includes(config.type)) {
          throw new UnsupportedRelationTypeError(config.type, {
            resource: resourceName,
            relation: relationName
          });
        }
        if (!config.resource) {
          throw new RelationConfigError(
            `Relation "${relationName}" on resource "${resourceName}" must have "resource" field`,
            { resource: resourceName, relation: relationName }
          );
        }
        if (!config.foreignKey) {
          throw new RelationConfigError(
            `Relation "${relationName}" on resource "${resourceName}" must have "foreignKey" field`,
            { resource: resourceName, relation: relationName }
          );
        }
        if (config.type === "belongsToMany") {
          if (!config.through) {
            throw new RelationConfigError(
              `belongsToMany relation "${relationName}" must have "through" (junction table) configured`,
              { resource: resourceName, relation: relationName }
            );
          }
          if (!config.otherKey) {
            throw new RelationConfigError(
              `belongsToMany relation "${relationName}" must have "otherKey" configured`,
              { resource: resourceName, relation: relationName }
            );
          }
        }
        config.localKey = config.localKey || "id";
        config.eager = config.eager !== void 0 ? config.eager : false;
        config.cascade = config.cascade || [];
      }
    }
  }
  /**
   * Setup a resource with relation capabilities
   * @private
   */
  async _setupResourceRelations(resourceName, relationsDef) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      if (this.verbose) {
        console.warn(`[RelationPlugin] Resource "${resourceName}" not found, will setup when created`);
      }
      return;
    }
    resource._relations = relationsDef;
    this._interceptGet(resource);
    this._interceptList(resource);
    this._interceptDelete(resource);
    this._interceptUpdate(resource);
    if (this.verbose) {
      console.log(
        `[RelationPlugin] Setup ${Object.keys(relationsDef).length} relations for "${resourceName}"`
      );
    }
  }
  /**
   * Intercept get() to add eager loading support
   * @private
   */
  _interceptGet(resource) {
    if (this.verbose) {
      console.log(`[RelationPlugin] Intercepting get() for resource "${resource.name}"`);
    }
    this.wrapResourceMethod(resource, "get", async (result, args) => {
      const [id, options = {}] = args;
      if (this.verbose) {
        console.log(`[RelationPlugin] get() wrapper called for "${resource.name}" with options:`, options);
      }
      if (!result || !options.include) {
        return result;
      }
      return await this._eagerLoad([result], options.include, resource).then((results) => results[0]);
    });
  }
  /**
   * Intercept list() to add eager loading support
   * @private
   */
  _interceptList(resource) {
    this.wrapResourceMethod(resource, "list", async (result, args) => {
      const [options = {}] = args;
      if (!result || result.length === 0 || !options.include) {
        return result;
      }
      return await this._eagerLoad(result, options.include, resource);
    });
  }
  /**
   * Intercept delete() to add cascade support
   * @private
   */
  _interceptDelete(resource) {
    this.addMiddleware(resource, "delete", async (next, id, options = {}) => {
      const record = await resource.get(id);
      if (!record) {
        return await next(id, options);
      }
      if (resource._relations) {
        for (const [relationName, config] of Object.entries(resource._relations)) {
          if (config.cascade && config.cascade.includes("delete")) {
            await this._cascadeDelete(record, resource, relationName, config);
          }
        }
      }
      return await next(id, options);
    });
  }
  /**
   * Intercept update() to add cascade support (for foreign key updates)
   * @private
   */
  _interceptUpdate(resource) {
    this.wrapResourceMethod(resource, "update", async (result, args) => {
      const [id, changes, options = {}] = args;
      const localKeyChanged = resource._relations && Object.values(resource._relations).some((config) => changes[config.localKey]);
      if (localKeyChanged && !options.skipCascade) {
        for (const [relationName, config] of Object.entries(resource._relations)) {
          if (config.cascade && config.cascade.includes("update") && changes[config.localKey]) {
            await this._cascadeUpdate(result, changes, resource, relationName, config);
          }
        }
      }
      return result;
    });
  }
  /**
   * Eager load relations
   * @private
   */
  async _eagerLoad(records, includes, resource) {
    if (!records || records.length === 0) {
      return records;
    }
    const normalizedIncludes = this._normalizeIncludes(includes);
    for (const [relationName, subIncludes] of Object.entries(normalizedIncludes)) {
      const config = resource._relations?.[relationName];
      if (!config) {
        throw new InvalidIncludePathError(
          relationName,
          `Relation "${relationName}" not defined on resource "${resource.name}"`
        );
      }
      records = await this._loadRelation(records, relationName, config, resource);
      if (subIncludes && typeof subIncludes === "object" && subIncludes !== true) {
        const nestedIncludes = subIncludes.include || subIncludes;
        for (const record of records) {
          const relatedData = record[relationName];
          if (relatedData) {
            const relatedResource = this.database.resources[config.resource];
            const relatedArray = Array.isArray(relatedData) ? relatedData : [relatedData];
            if (relatedArray.length > 0) {
              await this._eagerLoad(relatedArray, nestedIncludes, relatedResource);
            }
          }
        }
      }
    }
    return records;
  }
  /**
   * Normalize includes format
   * @private
   */
  _normalizeIncludes(includes) {
    if (Array.isArray(includes)) {
      return includes.reduce((acc, rel) => ({ ...acc, [rel]: true }), {});
    }
    if (typeof includes === "object") {
      return includes;
    }
    if (typeof includes === "string") {
      return { [includes]: true };
    }
    return {};
  }
  /**
   * Load a relation for an array of records
   * @private
   */
  async _loadRelation(records, relationName, config, sourceResource) {
    this.stats.totalRelationLoads++;
    switch (config.type) {
      case "hasOne":
        return await this._loadHasOne(records, relationName, config, sourceResource);
      case "hasMany":
        return await this._loadHasMany(records, relationName, config, sourceResource);
      case "belongsTo":
        return await this._loadBelongsTo(records, relationName, config, sourceResource);
      case "belongsToMany":
        return await this._loadBelongsToMany(records, relationName, config, sourceResource);
      default:
        throw new UnsupportedRelationTypeError(config.type);
    }
  }
  /**
   * Load hasOne relation (User  Profile)
   * @private
   */
  async _loadHasOne(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = null);
      return records;
    }
    const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.foreignKey);
    let relatedRecords;
    if (partitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        partitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.foreignKey, localKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      relatedMap.set(related[config.foreignKey], related);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      record[relationName] = relatedMap.get(localKeyValue) || null;
    });
    return records;
  }
  /**
   * Load hasMany relation (User  Posts)
   * @private
   */
  async _loadHasMany(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.foreignKey);
    let relatedRecords;
    if (partitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        partitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.foreignKey, localKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      const fkValue = related[config.foreignKey];
      if (!relatedMap.has(fkValue)) {
        relatedMap.set(fkValue, []);
      }
      relatedMap.get(fkValue).push(related);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      record[relationName] = relatedMap.get(localKeyValue) || [];
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Load belongsTo relation (Post  User)
   * @private
   */
  async _loadBelongsTo(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const foreignKeys = [...new Set(records.map((r) => r[config.foreignKey]).filter(Boolean))];
    if (foreignKeys.length === 0) {
      records.forEach((r) => r[relationName] = null);
      return records;
    }
    const [ok, err, parentRecords] = await tryFn(async () => {
      const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.localKey);
      if (partitionName) {
        return await this._batchLoadWithPartitions(
          relatedResource,
          partitionName,
          config.localKey,
          foreignKeys
        );
      } else {
        return await this._fallbackLoad(relatedResource, config.localKey, foreignKeys);
      }
    });
    if (!ok) {
      throw new RelationError(`Failed to load belongsTo relation "${relationName}": ${err.message}`, {
        sourceResource: sourceResource.name,
        relatedResource: config.resource,
        error: err
      });
    }
    const parentMap = /* @__PURE__ */ new Map();
    parentRecords.forEach((parent) => {
      parentMap.set(parent[config.localKey], parent);
    });
    records.forEach((record) => {
      const foreignKeyValue = record[config.foreignKey];
      record[relationName] = parentMap.get(foreignKeyValue) || null;
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Load belongsToMany relation via junction table (Post  Tags)
   * @private
   */
  async _loadBelongsToMany(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const junctionResource = this.database.resources[config.through];
    if (!junctionResource) {
      throw new JunctionTableNotFoundError(config.through, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const junctionPartitionName = config.junctionPartitionHint || this._findPartitionByField(junctionResource, config.foreignKey);
    let junctionRecords;
    if (junctionPartitionName) {
      junctionRecords = await this._batchLoadWithPartitions(
        junctionResource,
        junctionPartitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      junctionRecords = await this._fallbackLoad(junctionResource, config.foreignKey, localKeys);
    }
    if (junctionRecords.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const otherKeys = [...new Set(junctionRecords.map((j) => j[config.otherKey]).filter(Boolean))];
    const relatedPartitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.localKey);
    let relatedRecords;
    if (relatedPartitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        relatedPartitionName,
        config.localKey,
        otherKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.localKey, otherKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      relatedMap.set(related[config.localKey], related);
    });
    const junctionMap = /* @__PURE__ */ new Map();
    junctionRecords.forEach((junction) => {
      const fkValue = junction[config.foreignKey];
      if (!junctionMap.has(fkValue)) {
        junctionMap.set(fkValue, []);
      }
      junctionMap.get(fkValue).push(junction[config.otherKey]);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      const otherKeyValues = junctionMap.get(localKeyValue) || [];
      record[relationName] = otherKeyValues.map((otherKey) => relatedMap.get(otherKey)).filter(Boolean);
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Batch process operations with controlled parallelism
   * @private
   */
  async _batchProcess(items, operation, batchSize = null) {
    if (items.length === 0) return [];
    const actualBatchSize = batchSize || this.cascadeBatchSize;
    const results = [];
    for (let i = 0; i < items.length; i += actualBatchSize) {
      const chunk = items.slice(i, i + actualBatchSize);
      const chunkPromises = chunk.map((item) => operation(item));
      const chunkResults = await Promise.all(chunkPromises);
      results.push(...chunkResults);
    }
    return results;
  }
  /**
   * Load records using fallback (full scan) when no partition is available
   * Issues warnings when limit is reached to prevent silent data loss
   * @private
   */
  async _fallbackLoad(resource, fieldName, filterValues) {
    const options = this.fallbackLimit !== null ? { limit: this.fallbackLimit } : {};
    if (this.verbose) {
      console.log(
        `[RelationPlugin] No partition found for ${resource.name}.${fieldName}, using full scan` + (this.fallbackLimit ? ` (limited to ${this.fallbackLimit} records)` : " (no limit)")
      );
    }
    const allRecords = await resource.list(options);
    const filteredRecords = allRecords.filter((r) => filterValues.includes(r[fieldName]));
    if (this.fallbackLimit && allRecords.length >= this.fallbackLimit) {
      this.stats.fallbackLimitWarnings++;
      console.warn(
        `[RelationPlugin] WARNING: Fallback query for ${resource.name}.${fieldName} hit the limit of ${this.fallbackLimit} records. Some related records may be missing! Consider:
  1. Adding a partition on field "${fieldName}" for better performance
  2. Increasing fallbackLimit in plugin config (or set to null for no limit)
  Partition example: partitions: { by${fieldName.charAt(0).toUpperCase() + fieldName.slice(1)}: { fields: { ${fieldName}: 'string' } } }`
      );
    }
    return filteredRecords;
  }
  /**
   * Find partition by field name (for efficient relation loading)
   * Uses cache to avoid repeated lookups
   * @private
   */
  _findPartitionByField(resource, fieldName) {
    if (!resource.config.partitions) return null;
    const cacheKey = `${resource.name}:${fieldName}`;
    if (this._partitionCache.has(cacheKey)) {
      this.stats.partitionCacheHits++;
      return this._partitionCache.get(cacheKey);
    }
    let bestPartition = null;
    let bestFieldCount = Infinity;
    for (const [partitionName, partitionConfig] of Object.entries(resource.config.partitions)) {
      if (partitionConfig.fields && fieldName in partitionConfig.fields) {
        const fieldCount = Object.keys(partitionConfig.fields).length;
        if (fieldCount < bestFieldCount) {
          bestPartition = partitionName;
          bestFieldCount = fieldCount;
        }
      }
    }
    this._partitionCache.set(cacheKey, bestPartition);
    return bestPartition;
  }
  /**
   * Batch load records using partitions with controlled parallelism
   * Deduplicates keys to avoid redundant queries
   * @private
   */
  async _batchLoadWithPartitions(resource, partitionName, fieldName, keys) {
    if (keys.length === 0) return [];
    const uniqueKeys = [...new Set(keys)];
    const deduplicatedCount = keys.length - uniqueKeys.length;
    if (deduplicatedCount > 0) {
      this.stats.deduplicatedQueries += deduplicatedCount;
      if (this.verbose) {
        console.log(
          `[RelationPlugin] Deduplicated ${deduplicatedCount} queries (${keys.length} -> ${uniqueKeys.length} unique keys)`
        );
      }
    }
    if (uniqueKeys.length === 1) {
      return await resource.list({
        partition: partitionName,
        partitionValues: { [fieldName]: uniqueKeys[0] }
      });
    }
    const chunkSize = this.batchSize || 10;
    const chunks = [];
    for (let i = 0; i < uniqueKeys.length; i += chunkSize) {
      chunks.push(uniqueKeys.slice(i, i + chunkSize));
    }
    if (this.verbose) {
      console.log(
        `[RelationPlugin] Batch loading ${uniqueKeys.length} keys from ${resource.name} using partition ${partitionName} (${chunks.length} batches)`
      );
    }
    const allResults = [];
    for (const chunk of chunks) {
      const chunkPromises = chunk.map(
        (key) => resource.list({
          partition: partitionName,
          partitionValues: { [fieldName]: key }
        })
      );
      const chunkResults = await Promise.all(chunkPromises);
      allResults.push(...chunkResults.flat());
    }
    return allResults;
  }
  /**
   * Cascade delete operation
   * Uses partitions when available for efficient cascade
   * Supports transaction/rollback when enabled
   * @private
   */
  async _cascadeDelete(record, resource, relationName, config) {
    this.stats.cascadeOperations++;
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: resource.name,
        relation: relationName
      });
    }
    const deletedRecords = [];
    config.type === "belongsToMany" ? this.database.resources[config.through] : null;
    try {
      if (config.type === "hasMany") {
        let relatedRecords;
        const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
        if (partitionName) {
          relatedRecords = await relatedResource.list({
            partition: partitionName,
            partitionValues: { [config.foreignKey]: record[config.localKey] }
          });
          if (this.verbose) {
            console.log(
              `[RelationPlugin] Cascade delete using partition ${partitionName} for ${config.foreignKey}`
            );
          }
        } else {
          relatedRecords = await relatedResource.query({
            [config.foreignKey]: record[config.localKey]
          });
        }
        if (this.cascadeTransactions) {
          deletedRecords.push(...relatedRecords.map((r) => ({ type: "delete", resource: relatedResource, record: r })));
        }
        await this._batchProcess(relatedRecords, async (related) => {
          return await relatedResource.delete(related.id);
        });
        if (this.verbose) {
          console.log(
            `[RelationPlugin] Cascade deleted ${relatedRecords.length} ${config.resource} for ${resource.name}:${record.id} (batched in ${Math.ceil(relatedRecords.length / this.cascadeBatchSize)} chunks)`
          );
        }
      } else if (config.type === "hasOne") {
        let relatedRecords;
        const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
        if (partitionName) {
          relatedRecords = await relatedResource.list({
            partition: partitionName,
            partitionValues: { [config.foreignKey]: record[config.localKey] }
          });
        } else {
          relatedRecords = await relatedResource.query({
            [config.foreignKey]: record[config.localKey]
          });
        }
        if (relatedRecords.length > 0) {
          if (this.cascadeTransactions) {
            deletedRecords.push({ type: "delete", resource: relatedResource, record: relatedRecords[0] });
          }
          await relatedResource.delete(relatedRecords[0].id);
        }
      } else if (config.type === "belongsToMany") {
        const junctionResource2 = this.database.resources[config.through];
        if (junctionResource2) {
          let junctionRecords;
          const partitionName = this._findPartitionByField(junctionResource2, config.foreignKey);
          if (partitionName) {
            junctionRecords = await junctionResource2.list({
              partition: partitionName,
              partitionValues: { [config.foreignKey]: record[config.localKey] }
            });
            if (this.verbose) {
              console.log(
                `[RelationPlugin] Cascade delete junction using partition ${partitionName}`
              );
            }
          } else {
            junctionRecords = await junctionResource2.query({
              [config.foreignKey]: record[config.localKey]
            });
          }
          if (this.cascadeTransactions) {
            deletedRecords.push(...junctionRecords.map((j) => ({ type: "delete", resource: junctionResource2, record: j })));
          }
          await this._batchProcess(junctionRecords, async (junction) => {
            return await junctionResource2.delete(junction.id);
          });
          if (this.verbose) {
            console.log(
              `[RelationPlugin] Cascade deleted ${junctionRecords.length} junction records from ${config.through} (batched in ${Math.ceil(junctionRecords.length / this.cascadeBatchSize)} chunks)`
            );
          }
        }
      }
    } catch (error) {
      if (this.cascadeTransactions && deletedRecords.length > 0) {
        console.error(
          `[RelationPlugin] Cascade delete failed, attempting rollback of ${deletedRecords.length} records...`
        );
        const rollbackErrors = [];
        for (const { resource: res, record: rec } of deletedRecords.reverse()) {
          try {
            await res.insert(rec);
          } catch (rollbackError) {
            rollbackErrors.push({ record: rec.id, error: rollbackError.message });
          }
        }
        if (rollbackErrors.length > 0) {
          console.error(
            `[RelationPlugin] Rollback partially failed for ${rollbackErrors.length} records:`,
            rollbackErrors
          );
        } else if (this.verbose) {
          console.log(`[RelationPlugin] Rollback successful, restored ${deletedRecords.length} records`);
        }
      }
      throw new CascadeError("delete", resource.name, record.id, error, {
        relation: relationName,
        relatedResource: config.resource
      });
    }
  }
  /**
   * Cascade update operation (update foreign keys when local key changes)
   * Uses partitions when available for efficient cascade
   * Supports transaction/rollback when enabled
   * @private
   */
  async _cascadeUpdate(record, changes, resource, relationName, config) {
    this.stats.cascadeOperations++;
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      return;
    }
    const updatedRecords = [];
    try {
      const oldLocalKeyValue = record[config.localKey];
      const newLocalKeyValue = changes[config.localKey];
      if (oldLocalKeyValue === newLocalKeyValue) {
        return;
      }
      let relatedRecords;
      const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
      if (partitionName) {
        relatedRecords = await relatedResource.list({
          partition: partitionName,
          partitionValues: { [config.foreignKey]: oldLocalKeyValue }
        });
        if (this.verbose) {
          console.log(
            `[RelationPlugin] Cascade update using partition ${partitionName} for ${config.foreignKey}`
          );
        }
      } else {
        relatedRecords = await relatedResource.query({
          [config.foreignKey]: oldLocalKeyValue
        });
      }
      if (this.cascadeTransactions) {
        updatedRecords.push(...relatedRecords.map((r) => ({
          type: "update",
          resource: relatedResource,
          id: r.id,
          oldValue: r[config.foreignKey],
          newValue: newLocalKeyValue,
          field: config.foreignKey
        })));
      }
      await this._batchProcess(relatedRecords, async (related) => {
        return await relatedResource.update(related.id, {
          [config.foreignKey]: newLocalKeyValue
        }, { skipCascade: true });
      });
      if (this.verbose) {
        console.log(
          `[RelationPlugin] Cascade updated ${relatedRecords.length} ${config.resource} records (batched in ${Math.ceil(relatedRecords.length / this.cascadeBatchSize)} chunks)`
        );
      }
    } catch (error) {
      if (this.cascadeTransactions && updatedRecords.length > 0) {
        console.error(
          `[RelationPlugin] Cascade update failed, attempting rollback of ${updatedRecords.length} records...`
        );
        const rollbackErrors = [];
        for (const { resource: res, id, field, oldValue } of updatedRecords.reverse()) {
          try {
            await res.update(id, { [field]: oldValue }, { skipCascade: true });
          } catch (rollbackError) {
            rollbackErrors.push({ id, error: rollbackError.message });
          }
        }
        if (rollbackErrors.length > 0) {
          console.error(
            `[RelationPlugin] Rollback partially failed for ${rollbackErrors.length} records:`,
            rollbackErrors
          );
        } else if (this.verbose) {
          console.log(`[RelationPlugin] Rollback successful, restored ${updatedRecords.length} records`);
        }
      }
      throw new CascadeError("update", resource.name, record.id, error, {
        relation: relationName,
        relatedResource: config.resource
      });
    }
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      ...this.stats,
      configuredResources: Object.keys(this.relations).length,
      totalRelations: Object.values(this.relations).reduce(
        (sum, rels) => sum + Object.keys(rels).length,
        0
      )
    };
  }
  /**
   * Clear loader cache and partition cache (useful between requests)
   */
  clearCache() {
    this._loaderCache.clear();
    this._partitionCache.clear();
  }
  /**
   * Cleanup on plugin stop
   */
  async onStop() {
    this.clearCache();
  }
  /**
   * Cleanup on plugin uninstall
   */
  async onUninstall() {
    this.clearCache();
  }
}

class ReplicationError extends S3dbError {
  constructor(message, details = {}) {
    const { replicatorClass = "unknown", operation = "unknown", resourceName, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Replication Operation Error

Replicator: ${replicatorClass}
Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}

Common causes:
1. Invalid replicator configuration
2. Target system not accessible
3. Resource not configured for replication
4. Invalid operation type
5. Transformation function errors

Solution:
Check replicator configuration and ensure target system is accessible.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md
`.trim();
    }
    super(message, { ...rest, replicatorClass, operation, resourceName, description });
  }
}

class BaseReplicator extends EventEmitter {
  constructor(config = {}) {
    super();
    this.config = config;
    this.name = this.constructor.name;
    this.enabled = config.enabled !== false;
  }
  /**
   * Initialize the replicator
   * @param {Object} database - The s3db database instance
   * @returns {Promise<void>}
   */
  async initialize(database) {
    this.database = database;
    this.emit("db:plugin:initialized", { replicator: this.name });
  }
  /**
   * Replicate data to the target
   * @param {string} resourceName - Name of the resource being replicated
   * @param {string} operation - Operation type (insert, update, delete)
   * @param {Object} data - The data to replicate
   * @param {string} id - Record ID
   * @returns {Promise<Object>} replicator result
   */
  async replicate(resourceName, operation, data, id) {
    throw new ReplicationError("replicate() method must be implemented by subclass", {
      operation: "replicate",
      replicatorClass: this.name,
      resourceName,
      suggestion: "Extend BaseReplicator and implement the replicate() method"
    });
  }
  /**
   * Replicate multiple records in batch
   * @param {string} resourceName - Name of the resource being replicated
   * @param {Array} records - Array of records to replicate
   * @returns {Promise<Object>} Batch replicator result
   */
  async replicateBatch(resourceName, records) {
    throw new ReplicationError("replicateBatch() method must be implemented by subclass", {
      operation: "replicateBatch",
      replicatorClass: this.name,
      resourceName,
      batchSize: records?.length,
      suggestion: "Extend BaseReplicator and implement the replicateBatch() method"
    });
  }
  /**
   * Test the connection to the target
   * @returns {Promise<boolean>} True if connection is successful
   */
  async testConnection() {
    throw new ReplicationError("testConnection() method must be implemented by subclass", {
      operation: "testConnection",
      replicatorClass: this.name,
      suggestion: "Extend BaseReplicator and implement the testConnection() method"
    });
  }
  /**
   * Get replicator status and statistics
   * @returns {Promise<Object>} Status information
   */
  async getStatus() {
    return {
      name: this.name,
      // Removed: enabled: this.enabled,
      config: this.config,
      connected: false
    };
  }
  /**
   * Cleanup resources
   * @returns {Promise<void>}
   */
  async cleanup() {
    this.emit("cleanup", { replicator: this.name });
  }
  /**
   * Validate replicator configuration
   * @returns {Object} Validation result
   */
  validateConfig() {
    return { isValid: true, errors: [] };
  }
}

function parseFieldType(typeNotation) {
  if (typeof typeNotation !== "string") {
    return { type: "string", required: false, maxLength: null, options: {} };
  }
  const parts = typeNotation.split("|");
  const baseType = parts[0];
  const options = {};
  let required = false;
  let maxLength = null;
  for (const part of parts.slice(1)) {
    if (part === "required") {
      required = true;
    } else if (part.startsWith("maxlength:")) {
      maxLength = parseInt(part.split(":")[1]);
    } else if (part.startsWith("min:")) {
      options.min = parseFloat(part.split(":")[1]);
    } else if (part.startsWith("max:")) {
      options.max = parseFloat(part.split(":")[1]);
    } else if (part.startsWith("length:")) {
      options.length = parseInt(part.split(":")[1]);
    }
  }
  return { type: baseType, required, maxLength, options };
}
function s3dbTypeToPostgres(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      if (maxLength) return `VARCHAR(${maxLength})`;
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INTEGER";
      }
      return "DOUBLE PRECISION";
    case "boolean":
      return "BOOLEAN";
    case "object":
    case "json":
      return "JSONB";
    case "array":
      return "JSONB";
    case "embedding":
      return "JSONB";
    case "ip4":
    case "ip6":
      return "INET";
    case "secret":
      return "TEXT";
    case "uuid":
      return "UUID";
    case "date":
    case "datetime":
      return "TIMESTAMP WITH TIME ZONE";
    default:
      return "TEXT";
  }
}
function s3dbTypeToBigQuery(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      return "STRING";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INT64";
      }
      return "FLOAT64";
    case "boolean":
      return "BOOL";
    case "object":
    case "json":
      return "JSON";
    case "array":
      return "JSON";
    case "embedding":
      return "JSON";
    case "ip4":
    case "ip6":
      return "STRING";
    case "secret":
      return "STRING";
    case "uuid":
      return "STRING";
    case "date":
      return "DATE";
    case "datetime":
      return "TIMESTAMP";
    default:
      return "STRING";
  }
}
function s3dbTypeToMySQL(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      if (maxLength && maxLength <= 255) return `VARCHAR(${maxLength})`;
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INT";
      }
      return "DOUBLE";
    case "boolean":
      return "TINYINT(1)";
    case "object":
    case "json":
    case "array":
      return "JSON";
    case "embedding":
      return "JSON";
    case "ip4":
      return "VARCHAR(15)";
    case "ip6":
      return "VARCHAR(45)";
    case "secret":
      return "TEXT";
    case "uuid":
      return "CHAR(36)";
    case "date":
    case "datetime":
      return "DATETIME";
    default:
      return "TEXT";
  }
}
function generatePostgresCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id VARCHAR(255) PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToPostgres(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`"${fieldName}" ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
)`;
}
function generateMySQLCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id VARCHAR(255) PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToMySQL(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`\`${fieldName}\` ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at DATETIME DEFAULT CURRENT_TIMESTAMP");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci`;
}
async function getPostgresTableSchema(client, tableName) {
  const [ok, err, result] = await tryFn(async () => {
    return await client.query(`
      SELECT column_name, data_type, is_nullable, character_maximum_length
      FROM information_schema.columns
      WHERE table_name = $1
      ORDER BY ordinal_position
    `, [tableName]);
  });
  if (!ok) return null;
  const schema = {};
  for (const row of result.rows) {
    schema[row.column_name] = {
      type: row.data_type,
      nullable: row.is_nullable === "YES",
      maxLength: row.character_maximum_length
    };
  }
  return schema;
}
async function getMySQLTableSchema(connection, tableName) {
  const [ok, err, [rows]] = await tryFn(async () => {
    return await connection.query(`
      SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, CHARACTER_MAXIMUM_LENGTH
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_NAME = ?
      ORDER BY ORDINAL_POSITION
    `, [tableName]);
  });
  if (!ok) return null;
  const schema = {};
  for (const row of rows) {
    schema[row.COLUMN_NAME] = {
      type: row.DATA_TYPE,
      nullable: row.IS_NULLABLE === "YES",
      maxLength: row.CHARACTER_MAXIMUM_LENGTH
    };
  }
  return schema;
}
function generatePostgresAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToPostgres(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN IF NOT EXISTS "${fieldName}" ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}
function generateMySQLAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToMySQL(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN \`${fieldName}\` ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}
function generateBigQuerySchema(attributes, mutability = "append-only") {
  const fields = [];
  fields.push({
    name: "id",
    type: "STRING",
    mode: "REQUIRED"
  });
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const bqType = s3dbTypeToBigQuery(fieldType);
    fields.push({
      name: fieldName,
      type: bqType,
      mode: required ? "REQUIRED" : "NULLABLE"
    });
  }
  if (!attributes.createdAt) {
    fields.push({ name: "created_at", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (!attributes.updatedAt) {
    fields.push({ name: "updated_at", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (mutability === "append-only" || mutability === "immutable") {
    fields.push({ name: "_operation_type", type: "STRING", mode: "NULLABLE" });
    fields.push({ name: "_operation_timestamp", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (mutability === "immutable") {
    fields.push({ name: "_is_deleted", type: "BOOL", mode: "NULLABLE" });
    fields.push({ name: "_version", type: "INT64", mode: "NULLABLE" });
  }
  return fields;
}
async function getBigQueryTableSchema(bigqueryClient, datasetId, tableId) {
  const [ok, err, table] = await tryFn(async () => {
    const dataset = bigqueryClient.dataset(datasetId);
    const table2 = dataset.table(tableId);
    const [metadata] = await table2.getMetadata();
    return metadata;
  });
  if (!ok) return null;
  const schema = {};
  if (table.schema && table.schema.fields) {
    for (const field of table.schema.fields) {
      schema[field.name] = {
        type: field.type,
        mode: field.mode
      };
    }
  }
  return schema;
}
function generateBigQuerySchemaUpdate(attributes, existingSchema, mutability = "append-only") {
  const newFields = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const bqType = s3dbTypeToBigQuery(fieldType);
    newFields.push({
      name: fieldName,
      type: bqType,
      mode: required ? "REQUIRED" : "NULLABLE"
    });
  }
  if (mutability === "append-only" || mutability === "immutable") {
    if (!existingSchema["_operation_type"]) {
      newFields.push({ name: "_operation_type", type: "STRING", mode: "NULLABLE" });
    }
    if (!existingSchema["_operation_timestamp"]) {
      newFields.push({ name: "_operation_timestamp", type: "TIMESTAMP", mode: "NULLABLE" });
    }
  }
  if (mutability === "immutable") {
    if (!existingSchema["_is_deleted"]) {
      newFields.push({ name: "_is_deleted", type: "BOOL", mode: "NULLABLE" });
    }
    if (!existingSchema["_version"]) {
      newFields.push({ name: "_version", type: "INT64", mode: "NULLABLE" });
    }
  }
  return newFields;
}
function s3dbTypeToSQLite(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INTEGER";
      }
      return "REAL";
    case "boolean":
      return "INTEGER";
    // 0 or 1
    case "object":
    case "json":
    case "array":
      return "TEXT";
    // Store as JSON string
    case "embedding":
      return "TEXT";
    // Store as JSON array
    case "ip4":
    case "ip6":
      return "TEXT";
    case "secret":
      return "TEXT";
    case "uuid":
      return "TEXT";
    case "date":
    case "datetime":
      return "TEXT";
    // SQLite stores dates as ISO strings or Unix timestamps
    default:
      return "TEXT";
  }
}
function generateSQLiteCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id TEXT PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToSQLite(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`${fieldName} ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at TEXT DEFAULT (datetime('now'))");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at TEXT DEFAULT (datetime('now'))");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
)`;
}
function generateSQLiteAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToSQLite(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN ${fieldName} ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}

class BigqueryReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.projectId = config.projectId;
    this.datasetId = config.datasetId;
    this.bigqueryClient = null;
    this.credentials = config.credentials;
    this.location = config.location || "US";
    this.logTable = config.logTable;
    this.mutability = config.mutability || "append-only";
    this._validateMutability(this.mutability);
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
    this.versionCounters = /* @__PURE__ */ new Map();
  }
  _validateMutability(mutability) {
    const validModes = ["append-only", "mutable", "immutable"];
    if (!validModes.includes(mutability)) {
      throw new Error(`Invalid mutability mode: ${mutability}. Must be one of: ${validModes.join(", ")}`);
    }
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"],
          transform: null,
          mutability: this.mutability
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"], transform: null, mutability: this.mutability };
          }
          const itemMutability = item.mutability || this.mutability;
          this._validateMutability(itemMutability);
          return {
            table: item.table,
            actions: item.actions || ["insert"],
            transform: item.transform || null,
            mutability: itemMutability
          };
        });
      } else if (typeof config === "object") {
        const configMutability = config.mutability || this.mutability;
        this._validateMutability(configMutability);
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"],
          transform: config.transform || null,
          mutability: configMutability
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.projectId) errors.push("projectId is required");
    if (!this.datasetId) errors.push("datasetId is required");
    if (Object.keys(this.resources).length === 0) errors.push("At least one resource must be configured");
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
        const validActions = ["insert", "update", "delete"];
        const invalidActions = tableConfig.actions.filter((action) => !validActions.includes(action));
        if (invalidActions.length > 0) {
          errors.push(`Invalid actions for resource '${resourceName}': ${invalidActions.join(", ")}. Valid actions: ${validActions.join(", ")}`);
        }
        if (tableConfig.transform && typeof tableConfig.transform !== "function") {
          errors.push(`Transform must be a function for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("bigquery-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@google-cloud/bigquery'));
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[BigqueryReplicator] Failed to import BigQuery SDK: ${err.message}`);
      }
      this.emit("initialization_error", { replicator: this.name, error: err.message });
      throw err;
    }
    const { BigQuery } = sdk;
    this.bigqueryClient = new BigQuery({
      projectId: this.projectId,
      credentials: this.credentials,
      location: this.location
    });
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      projectId: this.projectId,
      datasetId: this.datasetId,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[BigQueryReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.$schema.attributes || {};
      const pluginAttrNames = resource.$schema._pluginAttributes ? Object.values(resource.$schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const mutability = tableConfig.mutability;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes, mutability);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[BigQueryReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema in BigQuery
   */
  async syncTableSchema(tableName, attributes, mutability = "append-only") {
    const dataset = this.bigqueryClient.dataset(this.datasetId);
    const table = dataset.table(tableName);
    const [exists] = await table.exists();
    if (!exists) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const schema = generateBigQuerySchema(attributes, mutability);
      if (this.config.verbose) {
        console.log(`[BigQueryReplicator] Creating table ${tableName} with schema (mutability: ${mutability}):`, schema);
      }
      await dataset.createTable(tableName, { schema });
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes),
        mutability
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[BigQueryReplicator] Dropping and recreating table ${tableName}`);
      }
      await table.delete();
      const schema = generateBigQuerySchema(attributes, mutability);
      await dataset.createTable(tableName, { schema });
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes),
        mutability
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const existingSchema = await getBigQueryTableSchema(this.bigqueryClient, this.datasetId, tableName);
      const newFields = generateBigQuerySchemaUpdate(attributes, existingSchema, mutability);
      if (newFields.length > 0) {
        if (this.config.verbose) {
          console.log(`[BigQueryReplicator] Adding ${newFields.length} field(s) to table ${tableName}:`, newFields);
        }
        const [metadata] = await table.getMetadata();
        const currentSchema = metadata.schema.fields;
        const updatedSchema = [...currentSchema, ...newFields];
        await table.setMetadata({ schema: updatedSchema });
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: newFields.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const existingSchema = await getBigQueryTableSchema(this.bigqueryClient, this.datasetId, tableName);
      const newFields = generateBigQuerySchemaUpdate(attributes, existingSchema, mutability);
      if (newFields.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${newFields.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => ({
      table: tableConfig.table,
      transform: tableConfig.transform,
      mutability: tableConfig.mutability
    }));
  }
  applyTransform(data, transformFn) {
    let cleanData = this._cleanInternalFields(data);
    if (!transformFn) return cleanData;
    let transformedData = JSON.parse(JSON.stringify(cleanData));
    return transformFn(transformedData);
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Add tracking fields for append-only and immutable modes
   * @private
   */
  _addTrackingFields(data, operation, mutability, id) {
    const tracked = { ...data };
    if (mutability === "append-only" || mutability === "immutable") {
      tracked._operation_type = operation;
      tracked._operation_timestamp = (/* @__PURE__ */ new Date()).toISOString();
    }
    if (mutability === "immutable") {
      tracked._is_deleted = operation === "delete";
      tracked._version = this._getNextVersion(id);
    }
    return tracked;
  }
  /**
   * Get next version number for immutable mode
   * @private
   */
  _getNextVersion(id) {
    const current = this.versionCounters.get(id) || 0;
    const next = current + 1;
    this.versionCounters.set(id, next);
    return next;
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tableConfigs = this.getTablesForResource(resourceName, operation);
    if (tableConfigs.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    const [ok, err, result] = await tryFn(async () => {
      const dataset = this.bigqueryClient.dataset(this.datasetId);
      for (const tableConfig of tableConfigs) {
        const [okTable, errTable] = await tryFn(async () => {
          const table = dataset.table(tableConfig.table);
          const mutability = tableConfig.mutability;
          let job;
          const shouldConvertToInsert = (mutability === "append-only" || mutability === "immutable") && (operation === "update" || operation === "delete");
          if (operation === "insert" || shouldConvertToInsert) {
            let transformedData = this.applyTransform(data, tableConfig.transform);
            if (shouldConvertToInsert) {
              transformedData = this._addTrackingFields(transformedData, operation, mutability, id);
            }
            try {
              job = await table.insert([transformedData]);
            } catch (error) {
              const { errors: errors2, response } = error;
              if (this.config.verbose) {
                console.error("[BigqueryReplicator] BigQuery insert error details:");
                if (errors2) console.error(JSON.stringify(errors2, null, 2));
                if (response) console.error(JSON.stringify(response, null, 2));
              }
              throw error;
            }
          } else if (operation === "update" && mutability === "mutable") {
            const transformedData = this.applyTransform(data, tableConfig.transform);
            const keys = Object.keys(transformedData).filter((k) => k !== "id");
            const setClause = keys.map((k) => `${k} = @${k}`).join(", ");
            const params = { id, ...transformedData };
            const query = `UPDATE \`${this.projectId}.${this.datasetId}.${tableConfig.table}\` SET ${setClause} WHERE id = @id`;
            const maxRetries = 2;
            let lastError = null;
            for (let attempt = 1; attempt <= maxRetries; attempt++) {
              const [ok2, error] = await tryFn(async () => {
                const [updateJob] = await this.bigqueryClient.createQueryJob({
                  query,
                  params,
                  location: this.location
                });
                await updateJob.getQueryResults();
                return [updateJob];
              });
              if (ok2) {
                job = ok2;
                break;
              } else {
                lastError = error;
                if (this.config.verbose) {
                  console.warn(`[BigqueryReplicator] Update attempt ${attempt} failed: ${error.message}`);
                  if (error.errors) {
                    console.error("[BigqueryReplicator] BigQuery update error details:");
                    console.error("Errors:", JSON.stringify(error.errors, null, 2));
                  }
                }
                if (error?.message?.includes("streaming buffer") && attempt < maxRetries) {
                  const delaySeconds = 30;
                  if (this.config.verbose) {
                    console.warn(`[BigqueryReplicator] Retrying in ${delaySeconds} seconds due to streaming buffer issue`);
                  }
                  await new Promise((resolve) => setTimeout(resolve, delaySeconds * 1e3));
                  continue;
                }
                throw error;
              }
            }
            if (!job) throw lastError;
          } else if (operation === "delete" && mutability === "mutable") {
            const query = `DELETE FROM \`${this.projectId}.${this.datasetId}.${tableConfig.table}\` WHERE id = @id`;
            try {
              const [deleteJob] = await this.bigqueryClient.createQueryJob({
                query,
                params: { id },
                location: this.location
              });
              await deleteJob.getQueryResults();
              job = [deleteJob];
            } catch (error) {
              if (this.config.verbose) {
                console.error("[BigqueryReplicator] BigQuery delete error details:");
                console.error("Query:", query);
                if (error.errors) console.error("Errors:", JSON.stringify(error.errors, null, 2));
                if (error.response) console.error("Response:", JSON.stringify(error.response, null, 2));
              }
              throw error;
            }
          } else {
            throw new Error(`Unsupported operation: ${operation}`);
          }
          results.push({
            table: tableConfig.table,
            success: true,
            jobId: job[0]?.id
          });
        });
        if (!okTable) {
          errors.push({
            table: tableConfig.table,
            error: errTable.message
          });
        }
      }
      if (this.logTable) {
        const [okLog, errLog] = await tryFn(async () => {
          const logTable = dataset.table(this.logTable);
          await logTable.insert([{
            resource_name: resourceName,
            operation,
            record_id: id,
            data: JSON.stringify(data),
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            source: "s3db-replicator"
          }]);
        });
        if (!okLog) {
        }
      }
      const success = errors.length === 0;
      if (errors.length > 0) {
        console.warn(`[BigqueryReplicator] Replication completed with errors for ${resourceName}:`, errors);
      }
      this.emit("plg:replicator:replicated", {
        replicator: this.name,
        resourceName,
        operation,
        id,
        tables: tableConfigs.map((t) => t.table),
        results,
        errors,
        success
      });
      return {
        success,
        results,
        errors,
        tables: tableConfigs.map((t) => t.table)
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[BigqueryReplicator] Replication failed for ${resourceName}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, res] = await tryFn(() => this.replicate(
        resourceName,
        record.operation,
        record.data,
        record.id,
        record.beforeData
      ));
      if (ok) {
        results.push(res);
      } else {
        if (this.config.verbose) {
          console.warn(`[BigqueryReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[BigqueryReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    return {
      success: errors.length === 0,
      results,
      errors
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.bigqueryClient) await this.initialize();
      const dataset = this.bigqueryClient.dataset(this.datasetId);
      await dataset.getMetadata();
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[BigqueryReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", { replicator: this.name, error: err.message });
    return false;
  }
  async cleanup() {
  }
  getStatus() {
    return {
      ...super.getStatus(),
      projectId: this.projectId,
      datasetId: this.datasetId,
      resources: this.resources,
      logTable: this.logTable,
      schemaSync: this.schemaSync,
      mutability: this.mutability
    };
  }
}

class DynamoDBReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.region = config.region || "us-east-1";
    this.accessKeyId = config.accessKeyId;
    this.secretAccessKey = config.secretAccessKey;
    this.endpoint = config.endpoint;
    this.credentials = config.credentials;
    this.client = null;
    this.docClient = null;
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"],
          primaryKey: "id"
          // Default primary key
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"], primaryKey: "id" };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"],
            primaryKey: item.primaryKey || "id",
            sortKey: item.sortKey
            // Optional sort key
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"],
          primaryKey: config.primaryKey || "id",
          sortKey: config.sortKey
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (this.region === "") {
      errors.push("AWS region is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const { DynamoDBClient } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
    const { DynamoDBDocumentClient, PutCommand, UpdateCommand, DeleteCommand } = requirePluginDependency("@aws-sdk/lib-dynamodb", "DynamoDBReplicator");
    this.PutCommand = PutCommand;
    this.UpdateCommand = UpdateCommand;
    this.DeleteCommand = DeleteCommand;
    const [ok, err] = await tryFn(async () => {
      const clientConfig = {
        region: this.region
      };
      if (this.endpoint) {
        clientConfig.endpoint = this.endpoint;
      }
      if (this.credentials) {
        clientConfig.credentials = this.credentials;
      } else if (this.accessKeyId && this.secretAccessKey) {
        clientConfig.credentials = {
          accessKeyId: this.accessKeyId,
          secretAccessKey: this.secretAccessKey
        };
      }
      this.client = new DynamoDBClient(clientConfig);
      this.docClient = DynamoDBDocumentClient.from(this.client);
      const { ListTablesCommand } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
      await this.client.send(new ListTablesCommand({ Limit: 1 }));
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to DynamoDB", {
        operation: "initialize",
        replicatorClass: "DynamoDBReplicator",
        region: this.region,
        endpoint: this.endpoint,
        original: err,
        suggestion: "Check AWS credentials and ensure DynamoDB is accessible"
      });
    }
    this.emit("connected", {
      replicator: "DynamoDBReplicator",
      region: this.region,
      endpoint: this.endpoint || "default"
    });
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "DynamoDBReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const tableConfig of this.resources[resourceName]) {
      if (!tableConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._putItem(tableConfig.table, data);
          case "update":
            return await this._updateItem(tableConfig.table, id, data, tableConfig);
          case "delete":
            return await this._deleteItem(tableConfig.table, id, tableConfig);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "DynamoDBReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          table: tableConfig.table,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[DynamoDBReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _putItem(table, data) {
    const cleanData = this._cleanInternalFields(data);
    const command = new this.PutCommand({
      TableName: table,
      Item: cleanData
    });
    const result = await this.docClient.send(command);
    return result;
  }
  async _updateItem(table, id, data, tableConfig) {
    const cleanData = this._cleanInternalFields(data);
    const updateExpressions = [];
    const expressionAttributeNames = {};
    const expressionAttributeValues = {};
    let index = 0;
    for (const [key2, value] of Object.entries(cleanData)) {
      if (key2 === tableConfig.primaryKey || key2 === tableConfig.sortKey) {
        continue;
      }
      const attrName = `#attr${index}`;
      const attrValue = `:val${index}`;
      expressionAttributeNames[attrName] = key2;
      expressionAttributeValues[attrValue] = value;
      updateExpressions.push(`${attrName} = ${attrValue}`);
      index++;
    }
    const key = { [tableConfig.primaryKey]: id };
    if (tableConfig.sortKey && cleanData[tableConfig.sortKey]) {
      key[tableConfig.sortKey] = cleanData[tableConfig.sortKey];
    }
    const command = new this.UpdateCommand({
      TableName: table,
      Key: key,
      UpdateExpression: `SET ${updateExpressions.join(", ")}`,
      ExpressionAttributeNames: expressionAttributeNames,
      ExpressionAttributeValues: expressionAttributeValues,
      ReturnValues: "ALL_NEW"
    });
    const result = await this.docClient.send(command);
    return result;
  }
  async _deleteItem(table, id, tableConfig) {
    const key = { [tableConfig.primaryKey]: id };
    const command = new this.DeleteCommand({
      TableName: table,
      Key: key
    });
    const result = await this.docClient.send(command);
    return result;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) {
        throw new Error("Client not initialized");
      }
      const { ListTablesCommand } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
      await this.client.send(new ListTablesCommand({ Limit: 1 }));
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "DynamoDBReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client,
      region: this.region,
      endpoint: this.endpoint || "default",
      resources: Object.keys(this.resources)
    };
  }
  async cleanup() {
    if (this.client) {
      this.client.destroy();
      this.client = null;
      this.docClient = null;
    }
    await super.cleanup();
  }
}

class MongoDBReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host || "localhost";
    this.port = config.port || 27017;
    this.database = config.database;
    this.username = config.username;
    this.password = config.password;
    this.options = config.options || {};
    this.client = null;
    this.db = null;
    this.logCollection = config.logCollection;
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          collection: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { collection: item, actions: ["insert"] };
          }
          return {
            collection: item.collection,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          collection: config.collection,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.connectionString && !this.database) {
      errors.push("Database name or connection string is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, collections] of Object.entries(this.resources)) {
      for (const collectionConfig of collections) {
        if (!collectionConfig.collection) {
          errors.push(`Collection name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(collectionConfig.actions) || collectionConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const { MongoClient } = requirePluginDependency("mongodb", "MongoDBReplicator");
    const [ok, err] = await tryFn(async () => {
      let uri;
      if (this.connectionString) {
        uri = this.connectionString;
      } else {
        const auth = this.username && this.password ? `${encodeURIComponent(this.username)}:${encodeURIComponent(this.password)}@` : "";
        uri = `mongodb://${auth}${this.host}:${this.port}/${this.database}`;
      }
      this.client = new MongoClient(uri, {
        ...this.options,
        useUnifiedTopology: true,
        useNewUrlParser: true
      });
      await this.client.connect();
      this.db = this.client.db(this.database);
      await this.db.admin().ping();
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to MongoDB database", {
        operation: "initialize",
        replicatorClass: "MongoDBReplicator",
        host: this.host,
        port: this.port,
        database: this.database,
        original: err,
        suggestion: "Check MongoDB connection credentials and ensure database is accessible"
      });
    }
    if (this.logCollection) {
      await this._createLogCollection();
    }
    this.emit("connected", {
      replicator: "MongoDBReplicator",
      host: this.host,
      database: this.database
    });
  }
  async _createLogCollection() {
    const [ok] = await tryFn(async () => {
      const collections = await this.db.listCollections({ name: this.logCollection }).toArray();
      if (collections.length === 0) {
        await this.db.createCollection(this.logCollection);
        await this.db.collection(this.logCollection).createIndexes([
          { key: { resource_name: 1 } },
          { key: { timestamp: 1 } }
        ]);
      }
    });
    if (!ok && this.config.verbose) {
      console.warn("[MongoDBReplicator] Failed to create log collection");
    }
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "MongoDBReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const collectionConfig of this.resources[resourceName]) {
      if (!collectionConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._insertDocument(collectionConfig.collection, data);
          case "update":
            return await this._updateDocument(collectionConfig.collection, id, data);
          case "delete":
            return await this._deleteDocument(collectionConfig.collection, id);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "MongoDBReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
        if (this.logCollection) {
          await this._logOperation(resourceName, operation, id, data);
        }
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          collection: collectionConfig.collection,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[MongoDBReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _insertDocument(collectionName, data) {
    const cleanData = this._cleanInternalFields(data);
    const collection = this.db.collection(collectionName);
    const result = await collection.insertOne(cleanData);
    return result;
  }
  async _updateDocument(collectionName, id, data) {
    const cleanData = this._cleanInternalFields(data);
    const collection = this.db.collection(collectionName);
    delete cleanData._id;
    const result = await collection.updateOne(
      { _id: id },
      { $set: cleanData }
    );
    return result;
  }
  async _deleteDocument(collectionName, id) {
    const collection = this.db.collection(collectionName);
    const result = await collection.deleteOne({ _id: id });
    return result;
  }
  async _logOperation(resourceName, operation, id, data) {
    const [ok] = await tryFn(async () => {
      const collection = this.db.collection(this.logCollection);
      await collection.insertOne({
        resource_name: resourceName,
        operation,
        record_id: id,
        data,
        timestamp: /* @__PURE__ */ new Date()
      });
    });
    if (!ok && this.config.verbose) {
      console.warn("[MongoDBReplicator] Failed to log operation");
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key === "_id") {
        return;
      }
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) {
        throw new Error("Client not initialized");
      }
      await this.db.admin().ping();
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "MongoDBReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client && !!this.db,
      host: this.host,
      database: this.database,
      resources: Object.keys(this.resources)
    };
  }
  async cleanup() {
    if (this.client) {
      await this.client.close();
      this.client = null;
      this.db = null;
    }
    await super.cleanup();
  }
}

class MySQLReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host || "localhost";
    this.port = config.port || 3306;
    this.database = config.database;
    this.user = config.user;
    this.password = config.password;
    this.pool = null;
    this.ssl = config.ssl;
    this.connectionLimit = config.connectionLimit || 10;
    this.logTable = config.logTable;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false,
      dropMissingColumns: config.schemaSync?.dropMissingColumns || false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.database) {
      errors.push("Database name is required");
    }
    if (!this.user) {
      errors.push("Database user is required");
    }
    if (!this.password) {
      errors.push("Database password is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok, err] = await tryFn(async () => {
      const poolConfig = {
        host: this.host,
        port: this.port,
        user: this.user,
        password: this.password,
        database: this.database,
        connectionLimit: this.connectionLimit,
        waitForConnections: true,
        queueLimit: 0
      };
      if (this.ssl) {
        poolConfig.ssl = this.ssl;
      }
      this.pool = mysql.createPool(poolConfig);
      const connection = await this.pool.promise().getConnection();
      await connection.ping();
      connection.release();
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to MySQL database", {
        operation: "initialize",
        replicatorClass: "MySQLReplicator",
        host: this.host,
        port: this.port,
        database: this.database,
        original: err,
        suggestion: "Check MySQL connection credentials and ensure database is accessible"
      });
    }
    if (this.logTable) {
      await this._createLogTable();
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "MySQLReplicator",
      host: this.host,
      database: this.database
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[MySQLReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[MySQLReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const connection = await this.pool.promise().getConnection();
    try {
      const existingSchema = await getMySQLTableSchema(connection, tableName);
      if (!existingSchema) {
        if (!this.schemaSync.autoCreateTable) {
          throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
        }
        if (this.schemaSync.strategy === "validate-only") {
          throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
        }
        const createSQL = generateMySQLCreateTable(tableName, attributes);
        if (this.config.verbose) {
          console.log(`[MySQLReplicator] Creating table ${tableName}:
${createSQL}`);
        }
        await connection.query(createSQL);
        this.emit("table_created", {
          replicator: this.name,
          tableName,
          attributes: Object.keys(attributes)
        });
        return;
      }
      if (this.schemaSync.strategy === "drop-create") {
        if (this.config.verbose) {
          console.warn(`[MySQLReplicator] Dropping and recreating table ${tableName}`);
        }
        await connection.query(`DROP TABLE IF EXISTS ${tableName}`);
        const createSQL = generateMySQLCreateTable(tableName, attributes);
        await connection.query(createSQL);
        this.emit("table_recreated", {
          replicator: this.name,
          tableName,
          attributes: Object.keys(attributes)
        });
        return;
      }
      if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
        const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          if (this.config.verbose) {
            console.log(`[MySQLReplicator] Altering table ${tableName}:`, alterStatements);
          }
          for (const stmt of alterStatements) {
            await connection.query(stmt);
          }
          this.emit("table_altered", {
            replicator: this.name,
            tableName,
            addedColumns: alterStatements.length
          });
        }
      }
      if (this.schemaSync.strategy === "validate-only") {
        const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
        }
      }
    } finally {
      connection.release();
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  async _createLogTable() {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok] = await tryFn(async () => {
      await this.pool.promise().query(`
        CREATE TABLE IF NOT EXISTS ${mysql.escapeId(this.logTable)} (
          id INT AUTO_INCREMENT PRIMARY KEY,
          resource_name VARCHAR(255) NOT NULL,
          operation VARCHAR(50) NOT NULL,
          record_id VARCHAR(255),
          data JSON,
          timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          INDEX idx_resource (resource_name),
          INDEX idx_timestamp (timestamp)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
      `);
    });
    if (!ok && this.config.verbose) {
      console.warn("[MySQLReplicator] Failed to create log table");
    }
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "MySQLReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const tableConfig of this.resources[resourceName]) {
      if (!tableConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._insertRecord(tableConfig.table, data);
          case "update":
            return await this._updateRecord(tableConfig.table, id, data);
          case "delete":
            return await this._deleteRecord(tableConfig.table, id);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "MySQLReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
        if (this.logTable) {
          await this._logOperation(resourceName, operation, id, data);
        }
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          table: tableConfig.table,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[MySQLReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _insertRecord(table, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const cleanData = this._cleanInternalFields(data);
    const columns = Object.keys(cleanData);
    const values = Object.values(cleanData);
    const placeholders = values.map(() => "?").join(", ");
    const query = `INSERT INTO ${mysql.escapeId(table)} (${columns.map((c) => mysql.escapeId(c)).join(", ")}) VALUES (${placeholders})`;
    const [result] = await this.pool.promise().query(query, values);
    return result;
  }
  async _updateRecord(table, id, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const cleanData = this._cleanInternalFields(data);
    const updates = Object.keys(cleanData).map((col) => `${mysql.escapeId(col)} = ?`).join(", ");
    const values = [...Object.values(cleanData), id];
    const query = `UPDATE ${mysql.escapeId(table)} SET ${updates} WHERE id = ?`;
    const [result] = await this.pool.promise().query(query, values);
    return result;
  }
  async _deleteRecord(table, id) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const query = `DELETE FROM ${mysql.escapeId(table)} WHERE id = ?`;
    const [result] = await this.pool.promise().query(query, [id]);
    return result;
  }
  async _logOperation(resourceName, operation, id, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok] = await tryFn(async () => {
      const query = `INSERT INTO ${mysql.escapeId(this.logTable)} (resource_name, operation, record_id, data) VALUES (?, ?, ?, ?)`;
      await this.pool.promise().query(query, [resourceName, operation, id, JSON.stringify(data)]);
    });
    if (!ok && this.config.verbose) {
      console.warn("[MySQLReplicator] Failed to log operation");
    }
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.pool) {
        throw new Error("Pool not initialized");
      }
      const connection = await this.pool.promise().getConnection();
      await connection.ping();
      connection.release();
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "MySQLReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.pool,
      host: this.host,
      database: this.database,
      resources: Object.keys(this.resources),
      poolConnections: this.pool ? this.pool.pool.allConnections.length : 0,
      schemaSync: this.schemaSync
    };
  }
  async cleanup() {
    if (this.pool) {
      await this.pool.end();
      this.pool = null;
    }
    await super.cleanup();
  }
}

class PlanetScaleReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.host = config.host;
    this.username = config.username;
    this.password = config.password;
    this.connection = null;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.host) errors.push("Host is required");
    if (!this.username) errors.push("Username is required");
    if (!this.password) errors.push("Password is required");
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("planetscale-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@planetscale/database'));
    if (!ok) {
      throw new ReplicationError("Failed to import PlanetScale SDK", {
        operation: "initialize",
        replicatorClass: "PlanetScaleReplicator",
        original: err,
        suggestion: "Install @planetscale/database: pnpm add @planetscale/database"
      });
    }
    const { connect } = sdk;
    this.connection = connect({
      host: this.host,
      username: this.username,
      password: this.password
    });
    const [okTest, errTest] = await tryFn(async () => {
      await this.connection.execute("SELECT 1");
    });
    if (!okTest) {
      throw new ReplicationError("Failed to connect to PlanetScale database", {
        operation: "initialize",
        replicatorClass: "PlanetScaleReplicator",
        host: this.host,
        original: errTest,
        suggestion: "Check PlanetScale credentials"
      });
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "PlanetScaleReplicator",
      host: this.host
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[PlanetScaleReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[PlanetScaleReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const existingSchema = await getMySQLTableSchema(this.connection, tableName);
    if (!existingSchema) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generateMySQLCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[PlanetScaleReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.connection.execute(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[PlanetScaleReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.connection.execute(`DROP TABLE IF EXISTS ${tableName}`);
      const createSQL = generateMySQLCreateTable(tableName, attributes);
      await this.connection.execute(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        if (this.config.verbose) {
          console.log(`[PlanetScaleReplicator] Altering table ${tableName}:`, alterStatements);
        }
        for (const stmt of alterStatements) {
          await this.connection.execute(stmt);
        }
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: alterStatements.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    for (const table of tables) {
      const [okTable, errTable] = await tryFn(async () => {
        if (operation === "insert") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData);
          const values = keys.map((k) => cleanData[k]);
          const placeholders = keys.map(() => "?").join(", ");
          const sql = `INSERT INTO ${table} (${keys.map((k) => `\`${k}\``).join(", ")}) VALUES (${placeholders}) ON DUPLICATE KEY UPDATE id=id`;
          await this.connection.execute(sql, values);
        } else if (operation === "update") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData).filter((k) => k !== "id");
          const setClause = keys.map((k) => `\`${k}\`=?`).join(", ");
          const values = keys.map((k) => cleanData[k]);
          values.push(id);
          const sql = `UPDATE ${table} SET ${setClause} WHERE id=?`;
          await this.connection.execute(sql, values);
        } else if (operation === "delete") {
          const sql = `DELETE FROM ${table} WHERE id=?`;
          await this.connection.execute(sql, [id]);
        }
        results.push({ table, success: true });
      });
      if (!okTable) {
        errors.push({ table, error: errTable.message });
      }
    }
    const success = errors.length === 0;
    this.emit("plg:replicator:replicated", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      tables,
      results,
      errors,
      success
    });
    return { success, results, errors, tables };
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    this.connection = null;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.connection,
      host: this.host,
      resources: Object.keys(this.resources),
      schemaSync: this.schemaSync
    };
  }
}

class PostgresReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host;
    this.port = config.port || 5432;
    this.database = config.database;
    this.user = config.user;
    this.password = config.password;
    this.client = null;
    this.ssl = config.ssl;
    this.logTable = config.logTable;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false,
      dropMissingColumns: config.schemaSync?.dropMissingColumns || false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.connectionString && (!this.host || !this.database)) {
      errors.push("Either connectionString or host+database must be provided");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
        const validActions = ["insert", "update", "delete"];
        const invalidActions = tableConfig.actions.filter((action) => !validActions.includes(action));
        if (invalidActions.length > 0) {
          errors.push(`Invalid actions for resource '${resourceName}': ${invalidActions.join(", ")}. Valid actions: ${validActions.join(", ")}`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("postgresql-replicator");
    const [ok, err, sdk] = await tryFn(() => import('pg'));
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[PostgresReplicator] Failed to import pg SDK: ${err.message}`);
      }
      this.emit("initialization_error", {
        replicator: this.name,
        error: err.message
      });
      throw err;
    }
    const { Client } = sdk;
    const config = this.connectionString ? {
      connectionString: this.connectionString,
      ssl: this.ssl
    } : {
      host: this.host,
      port: this.port,
      database: this.database,
      user: this.user,
      password: this.password,
      ssl: this.ssl
    };
    this.client = new Client(config);
    await this.client.connect();
    if (this.logTable) {
      await this.createLogTableIfNotExists();
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      database: this.database || "postgres",
      resources: Object.keys(this.resources)
    });
  }
  async createLogTableIfNotExists() {
    const createTableQuery = `
      CREATE TABLE IF NOT EXISTS ${this.logTable} (
        id SERIAL PRIMARY KEY,
        resource_name VARCHAR(255) NOT NULL,
        operation VARCHAR(50) NOT NULL,
        record_id VARCHAR(255) NOT NULL,
        data JSONB,
        timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
        source VARCHAR(100) DEFAULT 's3db-replicator',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
      );
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_resource_name ON ${this.logTable}(resource_name);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_operation ON ${this.logTable}(operation);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_record_id ON ${this.logTable}(record_id);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_timestamp ON ${this.logTable}(timestamp);
    `;
    await this.client.query(createTableQuery);
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[PostgresReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[PostgresReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const existingSchema = await getPostgresTableSchema(this.client, tableName);
    if (!existingSchema) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generatePostgresCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[PostgresReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.client.query(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[PostgresReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.client.query(`DROP TABLE IF EXISTS ${tableName} CASCADE`);
      const createSQL = generatePostgresCreateTable(tableName, attributes);
      await this.client.query(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const alterStatements = generatePostgresAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        if (this.config.verbose) {
          console.log(`[PostgresReplicator] Altering table ${tableName}:`, alterStatements);
        }
        for (const stmt of alterStatements) {
          await this.client.query(stmt);
        }
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: alterStatements.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const alterStatements = generatePostgresAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    const [ok, err, result] = await tryFn(async () => {
      for (const table of tables) {
        const [okTable, errTable] = await tryFn(async () => {
          let result2;
          if (operation === "insert") {
            const cleanData = this._cleanInternalFields(data);
            const keys = Object.keys(cleanData);
            const values = keys.map((k) => cleanData[k]);
            const columns = keys.map((k) => `"${k}"`).join(", ");
            const params = keys.map((_, i) => `$${i + 1}`).join(", ");
            const sql = `INSERT INTO ${table} (${columns}) VALUES (${params}) ON CONFLICT (id) DO NOTHING RETURNING *`;
            result2 = await this.client.query(sql, values);
          } else if (operation === "update") {
            const cleanData = this._cleanInternalFields(data);
            const keys = Object.keys(cleanData).filter((k) => k !== "id");
            const setClause = keys.map((k, i) => `"${k}"=$${i + 1}`).join(", ");
            const values = keys.map((k) => cleanData[k]);
            values.push(id);
            const sql = `UPDATE ${table} SET ${setClause} WHERE id=$${keys.length + 1} RETURNING *`;
            result2 = await this.client.query(sql, values);
          } else if (operation === "delete") {
            const sql = `DELETE FROM ${table} WHERE id=$1 RETURNING *`;
            result2 = await this.client.query(sql, [id]);
          } else {
            throw new Error(`Unsupported operation: ${operation}`);
          }
          results.push({
            table,
            success: true,
            rows: result2.rows,
            rowCount: result2.rowCount
          });
        });
        if (!okTable) {
          errors.push({
            table,
            error: errTable.message
          });
        }
      }
      if (this.logTable) {
        const [okLog, errLog] = await tryFn(async () => {
          await this.client.query(
            `INSERT INTO ${this.logTable} (resource_name, operation, record_id, data, timestamp, source) VALUES ($1, $2, $3, $4, $5, $6)`,
            [resourceName, operation, id, JSON.stringify(data), (/* @__PURE__ */ new Date()).toISOString(), "s3db-replicator"]
          );
        });
        if (!okLog) {
        }
      }
      const success = errors.length === 0;
      if (errors.length > 0) {
        console.warn(`[PostgresReplicator] Replication completed with errors for ${resourceName}:`, errors);
      }
      this.emit("plg:replicator:replicated", {
        replicator: this.name,
        resourceName,
        operation,
        id,
        tables,
        results,
        errors,
        success
      });
      return {
        success,
        results,
        errors,
        tables
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[PostgresReplicator] Replication failed for ${resourceName}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, res] = await tryFn(() => this.replicate(
        resourceName,
        record.operation,
        record.data,
        record.id,
        record.beforeData
      ));
      if (ok) {
        results.push(res);
      } else {
        if (this.config.verbose) {
          console.warn(`[PostgresReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[PostgresReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    return {
      success: errors.length === 0,
      results,
      errors
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) await this.initialize();
      await this.client.query("SELECT 1");
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[PostgresReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", { replicator: this.name, error: err.message });
    return false;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    if (this.client) await this.client.end();
  }
  getStatus() {
    return {
      ...super.getStatus(),
      database: this.database || "postgres",
      resources: this.resources,
      logTable: this.logTable,
      schemaSync: this.schemaSync
    };
  }
}

const S3_DEFAULT_REGION = "us-east-1";
const S3_DEFAULT_ENDPOINT = "https://s3.us-east-1.amazonaws.com";
class ConnectionString {
  constructor(connectionString) {
    let uri;
    const [ok, err, parsed] = tryFn(() => new URL(connectionString));
    if (!ok) {
      throw new ConnectionStringError("Invalid connection string: " + connectionString, { original: err, input: connectionString });
    }
    uri = parsed;
    this.region = S3_DEFAULT_REGION;
    if (uri.protocol === "s3:") this.defineFromS3(uri);
    else this.defineFromCustomUri(uri);
    for (const [k, v] of uri.searchParams.entries()) {
      this[k] = v;
    }
  }
  defineFromS3(uri) {
    const [okBucket, errBucket, bucket] = tryFnSync(() => decodeURIComponent(uri.hostname));
    if (!okBucket) throw new ConnectionStringError("Invalid bucket in connection string", { original: errBucket, input: uri.hostname });
    this.bucket = bucket || "s3db";
    const [okUser, errUser, user] = tryFnSync(() => decodeURIComponent(uri.username));
    if (!okUser) throw new ConnectionStringError("Invalid accessKeyId in connection string", { original: errUser, input: uri.username });
    this.accessKeyId = user;
    const [okPass, errPass, pass] = tryFnSync(() => decodeURIComponent(uri.password));
    if (!okPass) throw new ConnectionStringError("Invalid secretAccessKey in connection string", { original: errPass, input: uri.password });
    this.secretAccessKey = pass;
    this.endpoint = S3_DEFAULT_ENDPOINT;
    if (["/", "", null].includes(uri.pathname)) {
      this.keyPrefix = "";
    } else {
      let [, ...subpath] = uri.pathname.split("/");
      this.keyPrefix = [...subpath || []].join("/");
    }
  }
  defineFromCustomUri(uri) {
    this.forcePathStyle = true;
    this.endpoint = uri.origin;
    const [okUser, errUser, user] = tryFnSync(() => decodeURIComponent(uri.username));
    if (!okUser) throw new ConnectionStringError("Invalid accessKeyId in connection string", { original: errUser, input: uri.username });
    this.accessKeyId = user;
    const [okPass, errPass, pass] = tryFnSync(() => decodeURIComponent(uri.password));
    if (!okPass) throw new ConnectionStringError("Invalid secretAccessKey in connection string", { original: errPass, input: uri.password });
    this.secretAccessKey = pass;
    if (["/", "", null].includes(uri.pathname)) {
      this.bucket = "s3db";
      this.keyPrefix = "";
    } else {
      let [, bucket, ...subpath] = uri.pathname.split("/");
      if (!bucket) {
        this.bucket = "s3db";
      } else {
        const [okBucket, errBucket, bucketDecoded] = tryFnSync(() => decodeURIComponent(bucket));
        if (!okBucket) throw new ConnectionStringError("Invalid bucket in connection string", { original: errBucket, input: bucket });
        this.bucket = bucketDecoded;
      }
      this.keyPrefix = [...subpath || []].join("/");
    }
  }
}

class S3Client extends EventEmitter {
  constructor({
    verbose = false,
    id = null,
    AwsS3Client: AwsS3Client2,
    connectionString,
    parallelism = 10,
    httpClientOptions = {}
  }) {
    super();
    this.verbose = verbose;
    this.id = id ?? idGenerator(77);
    this.parallelism = parallelism;
    this.config = new ConnectionString(connectionString);
    this.httpClientOptions = {
      keepAlive: true,
      // Enabled for better performance
      keepAliveMsecs: 1e3,
      // 1 second keep-alive
      maxSockets: httpClientOptions.maxSockets || 500,
      // High concurrency support
      maxFreeSockets: httpClientOptions.maxFreeSockets || 100,
      // Better connection reuse
      timeout: 6e4,
      // 60 second timeout
      ...httpClientOptions
    };
    this.client = AwsS3Client2 || this.createClient();
  }
  createClient() {
    const httpAgent = new Agent(this.httpClientOptions);
    const httpsAgent = new Agent$1(this.httpClientOptions);
    const httpHandler = new NodeHttpHandler({
      httpAgent,
      httpsAgent
    });
    let options = {
      region: this.config.region,
      endpoint: this.config.endpoint,
      requestHandler: httpHandler
    };
    if (this.config.forcePathStyle) options.forcePathStyle = true;
    if (this.config.accessKeyId) {
      options.credentials = {
        accessKeyId: this.config.accessKeyId,
        secretAccessKey: this.config.secretAccessKey
      };
    }
    const client = new S3Client$1(options);
    client.middlewareStack.add(
      (next, context) => async (args) => {
        if (context.commandName === "DeleteObjectsCommand") {
          const body = args.request.body;
          if (body && typeof body === "string") {
            const contentMd5 = await md5(body);
            args.request.headers["Content-MD5"] = contentMd5;
          }
        }
        return next(args);
      },
      {
        step: "build",
        name: "addContentMd5ForDeleteObjects",
        priority: "high"
      }
    );
    return client;
  }
  async sendCommand(command) {
    this.emit("cl:request", command.constructor.name, command.input);
    const [ok, err, response] = await tryFn(() => this.client.send(command));
    if (!ok) {
      const bucket = this.config.bucket;
      const key = command.input && command.input.Key;
      throw mapAwsError(err, {
        bucket,
        key,
        commandName: command.constructor.name,
        commandInput: command.input
      });
    }
    this.emit("cl:response", command.constructor.name, response, command.input);
    return response;
  }
  async putObject({ key, metadata, contentType, body, contentEncoding, contentLength, ifMatch, ifNoneMatch }) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    keyPrefix ? path.join(keyPrefix, key) : key;
    const stringMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        stringMetadata[validKey] = encoded;
      }
    }
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path.join(keyPrefix, key) : key,
      Metadata: stringMetadata,
      Body: body || Buffer.alloc(0)
    };
    if (contentType !== void 0) options.ContentType = contentType;
    if (contentEncoding !== void 0) options.ContentEncoding = contentEncoding;
    if (contentLength !== void 0) options.ContentLength = contentLength;
    if (ifMatch !== void 0) options.IfMatch = ifMatch;
    if (ifNoneMatch !== void 0) options.IfNoneMatch = ifNoneMatch;
    const [ok, err, response] = await tryFn(() => this.sendCommand(new PutObjectCommand(options)));
    this.emit("cl:PutObject", err || response, { key, metadata, contentType, body, contentEncoding, contentLength });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "PutObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async getObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(async () => {
      const res = await this.sendCommand(new GetObjectCommand(options));
      if (res.Metadata) {
        const decodedMetadata = {};
        for (const [key2, value] of Object.entries(res.Metadata)) {
          decodedMetadata[key2] = metadataDecode(value);
        }
        res.Metadata = decodedMetadata;
      }
      return res;
    });
    this.emit("cl:GetObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "GetObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async headObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(async () => {
      const res = await this.sendCommand(new HeadObjectCommand(options));
      if (res.Metadata) {
        const decodedMetadata = {};
        for (const [key2, value] of Object.entries(res.Metadata)) {
          decodedMetadata[key2] = metadataDecode(value);
        }
        res.Metadata = decodedMetadata;
      }
      return res;
    });
    this.emit("cl:HeadObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "HeadObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async copyObject({ from, to, metadata, metadataDirective, contentType }) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path.join(keyPrefix, to) : to,
      CopySource: path.join(this.config.bucket, keyPrefix ? path.join(keyPrefix, from) : from)
    };
    if (metadataDirective) {
      options.MetadataDirective = metadataDirective;
    }
    if (metadata && typeof metadata === "object") {
      const encodedMetadata = {};
      for (const [key, value] of Object.entries(metadata)) {
        const { encoded } = metadataEncode(value);
        encodedMetadata[key] = encoded;
      }
      options.Metadata = encodedMetadata;
    }
    if (contentType) {
      options.ContentType = contentType;
    }
    const [ok, err, response] = await tryFn(() => this.sendCommand(new CopyObjectCommand(options)));
    this.emit("cl:CopyObject", err || response, { from, to, metadataDirective });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key: to,
        commandName: "CopyObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async exists(key) {
    const [ok, err] = await tryFn(() => this.headObject(key));
    if (ok) return true;
    if (err.name === "NoSuchKey" || err.name === "NotFound") return false;
    throw err;
  }
  async deleteObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    keyPrefix ? path.join(keyPrefix, key) : key;
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(() => this.sendCommand(new DeleteObjectCommand(options)));
    this.emit("cl:DeleteObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "DeleteObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async deleteObjects(keys) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const packages = chunk(keys, 1e3);
    const { results, errors } = await PromisePool.for(packages).withConcurrency(this.parallelism).process(async (keys2) => {
      for (const key of keys2) {
        keyPrefix ? path.join(keyPrefix, key) : key;
        this.config.bucket;
        await this.exists(key);
      }
      const options = {
        Bucket: this.config.bucket,
        Delete: {
          Objects: keys2.map((key) => ({
            Key: keyPrefix ? path.join(keyPrefix, key) : key
          }))
        }
      };
      let response;
      const [ok, err, res] = await tryFn(() => this.sendCommand(new DeleteObjectsCommand(options)));
      if (!ok) throw err;
      response = res;
      if (response && response.Errors && response.Errors.length > 0) ;
      if (response && response.Deleted && response.Deleted.length !== keys2.length) ;
      return response;
    });
    const report = {
      deleted: results,
      notFound: errors
    };
    this.emit("cl:DeleteObjects", report, keys);
    return report;
  }
  /**
   * Delete all objects under a specific prefix using efficient pagination
   * @param {Object} options - Delete options
   * @param {string} options.prefix - S3 prefix to delete
   * @returns {Promise<number>} Number of objects deleted
   */
  async deleteAll({ prefix } = {}) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    let continuationToken;
    let totalDeleted = 0;
    do {
      const listCommand = new ListObjectsV2Command({
        Bucket: this.config.bucket,
        Prefix: keyPrefix ? path.join(keyPrefix, prefix || "") : prefix || "",
        ContinuationToken: continuationToken
      });
      const listResponse = await this.client.send(listCommand);
      if (listResponse.Contents && listResponse.Contents.length > 0) {
        const deleteCommand = new DeleteObjectsCommand({
          Bucket: this.config.bucket,
          Delete: {
            Objects: listResponse.Contents.map((obj) => ({ Key: obj.Key }))
          }
        });
        const deleteResponse = await this.client.send(deleteCommand);
        const deletedCount = deleteResponse.Deleted ? deleteResponse.Deleted.length : 0;
        totalDeleted += deletedCount;
        this.emit("cl:DeleteAll", {
          prefix,
          batch: deletedCount,
          total: totalDeleted
        });
      }
      continuationToken = listResponse.IsTruncated ? listResponse.NextContinuationToken : void 0;
    } while (continuationToken);
    this.emit("cl:DeleteAllComplete", {
      prefix,
      totalDeleted
    });
    return totalDeleted;
  }
  async moveObject({ from, to }) {
    const [ok, err] = await tryFn(async () => {
      await this.copyObject({ from, to });
      await this.deleteObject(from);
    });
    if (!ok) {
      throw new UnknownError("Unknown error in moveObject", { bucket: this.config.bucket, from, to, original: err });
    }
    return true;
  }
  async listObjects({
    prefix,
    maxKeys = 1e3,
    continuationToken
  } = {}) {
    const options = {
      Bucket: this.config.bucket,
      MaxKeys: maxKeys,
      ContinuationToken: continuationToken,
      Prefix: this.config.keyPrefix ? path.join(this.config.keyPrefix, prefix || "") : prefix || ""
    };
    const [ok, err, response] = await tryFn(() => this.sendCommand(new ListObjectsV2Command(options)));
    if (!ok) {
      throw new UnknownError("Unknown error in listObjects", { prefix, bucket: this.config.bucket, original: err });
    }
    this.emit("cl:ListObjects", response, options);
    return response;
  }
  async count({ prefix } = {}) {
    let count = 0;
    let truncated = true;
    let continuationToken;
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const response = await this.listObjects(options);
      count += response.KeyCount || 0;
      truncated = response.IsTruncated || false;
      continuationToken = response.NextContinuationToken;
    }
    this.emit("cl:Count", count, { prefix });
    return count;
  }
  async getAllKeys({ prefix } = {}) {
    let keys = [];
    let truncated = true;
    let continuationToken;
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const response = await this.listObjects(options);
      if (response.Contents) {
        keys = keys.concat(response.Contents.map((x) => x.Key));
      }
      truncated = response.IsTruncated || false;
      continuationToken = response.NextContinuationToken;
    }
    if (this.config.keyPrefix) {
      keys = keys.map((x) => x.replace(this.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x);
    }
    this.emit("cl:GetAllKeys", keys, { prefix });
    return keys;
  }
  async getContinuationTokenAfterOffset(params = {}) {
    const {
      prefix,
      offset = 1e3
    } = params;
    if (offset === 0) return null;
    let truncated = true;
    let continuationToken;
    let skipped = 0;
    while (truncated) {
      let maxKeys = offset < 1e3 ? offset : offset - skipped > 1e3 ? 1e3 : offset - skipped;
      const options = {
        prefix,
        maxKeys,
        continuationToken
      };
      const res = await this.listObjects(options);
      if (res.Contents) {
        skipped += res.Contents.length;
      }
      truncated = res.IsTruncated || false;
      continuationToken = res.NextContinuationToken;
      if (skipped >= offset) {
        break;
      }
    }
    this.emit("cl:GetContinuationTokenAfterOffset", continuationToken || null, params);
    return continuationToken || null;
  }
  async getKeysPage(params = {}) {
    const {
      prefix,
      offset = 0,
      amount = 100
    } = params;
    let keys = [];
    let truncated = true;
    let continuationToken;
    if (offset > 0) {
      continuationToken = await this.getContinuationTokenAfterOffset({
        prefix,
        offset
      });
      if (!continuationToken) {
        this.emit("cl:GetKeysPage", [], params);
        return [];
      }
    }
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const res = await this.listObjects(options);
      if (res.Contents) {
        keys = keys.concat(res.Contents.map((x) => x.Key));
      }
      truncated = res.IsTruncated || false;
      continuationToken = res.NextContinuationToken;
      if (keys.length >= amount) {
        keys = keys.slice(0, amount);
        break;
      }
    }
    if (this.config.keyPrefix) {
      keys = keys.map((x) => x.replace(this.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x);
    }
    this.emit("cl:GetKeysPage", keys, params);
    return keys;
  }
  async moveAllObjects({ prefixFrom, prefixTo }) {
    const keys = await this.getAllKeys({ prefix: prefixFrom });
    const { results, errors } = await PromisePool.for(keys).withConcurrency(this.parallelism).process(async (key) => {
      const to = key.replace(prefixFrom, prefixTo);
      const [ok, err] = await tryFn(async () => {
        await this.moveObject({
          from: key,
          to
        });
      });
      if (!ok) {
        throw new UnknownError("Unknown error in moveAllObjects", { bucket: this.config.bucket, from: key, to, original: err });
      }
      return to;
    });
    this.emit("cl:MoveAllObjects", { results, errors }, { prefixFrom, prefixTo });
    if (errors.length > 0) {
      throw new UnknownError("Some objects could not be moved", {
        bucket: this.config.bucket,
        operation: "moveAllObjects",
        prefixFrom,
        prefixTo,
        totalKeys: keys.length,
        failedCount: errors.length,
        successCount: results.length,
        errors: errors.map((e) => ({ message: e.message, raw: e.raw })),
        suggestion: "Check S3 permissions and retry failed objects individually"
      });
    }
    return results;
  }
}

class Database extends EventEmitter {
  constructor(options) {
    super();
    this.id = (() => {
      const [ok, err, id] = tryFn(() => idGenerator(7));
      return ok && id ? id : `db-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    })();
    this.version = "1";
    this.s3dbVersion = (() => {
      const [ok, err, version] = tryFn(() => true ? "13.6.1" : "latest");
      return ok ? version : "latest";
    })();
    this._resourcesMap = {};
    this.resources = new Proxy(this._resourcesMap, {
      get: (target, prop) => {
        if (typeof prop === "symbol" || prop === "constructor" || prop === "toJSON") {
          return target[prop];
        }
        if (target[prop]) {
          return target[prop];
        }
        return void 0;
      },
      // Support Object.keys(), Object.entries(), etc.
      ownKeys: (target) => {
        return Object.keys(target);
      },
      getOwnPropertyDescriptor: (target, prop) => {
        return Object.getOwnPropertyDescriptor(target, prop);
      }
    });
    this.savedMetadata = null;
    this.options = options;
    this.verbose = options.verbose || false;
    this.parallelism = parseInt(options.parallelism + "") || 10;
    this.pluginList = options.plugins || [];
    this.pluginRegistry = {};
    this.plugins = this.pluginRegistry;
    this.cache = options.cache;
    this.passphrase = options.passphrase || "secret";
    this.bcryptRounds = options.bcryptRounds || 10;
    this.versioningEnabled = options.versioningEnabled || false;
    this.persistHooks = options.persistHooks || false;
    this.strictValidation = options.strictValidation !== false;
    this.strictHooks = options.strictHooks || false;
    this._initHooks();
    let connectionString = options.connectionString;
    if (!connectionString && (options.bucket || options.accessKeyId || options.secretAccessKey)) {
      const { bucket, region, accessKeyId, secretAccessKey, endpoint, forcePathStyle } = options;
      if (endpoint) {
        const url = new URL(endpoint);
        if (accessKeyId) url.username = encodeURIComponent(accessKeyId);
        if (secretAccessKey) url.password = encodeURIComponent(secretAccessKey);
        url.pathname = `/${bucket || "s3db"}`;
        if (forcePathStyle) {
          url.searchParams.set("forcePathStyle", "true");
        }
        connectionString = url.toString();
      } else if (accessKeyId && secretAccessKey) {
        const params = new URLSearchParams();
        params.set("region", region || "us-east-1");
        if (forcePathStyle) {
          params.set("forcePathStyle", "true");
        }
        connectionString = `s3://${encodeURIComponent(accessKeyId)}:${encodeURIComponent(secretAccessKey)}@${bucket || "s3db"}?${params.toString()}`;
      }
    }
    this.client = options.client || new S3Client({
      verbose: this.verbose,
      parallelism: this.parallelism,
      connectionString
    });
    this.connectionString = connectionString;
    this.bucket = this.client.bucket;
    this.keyPrefix = this.client.keyPrefix;
    this._registerExitListener();
  }
  /**
   * Register process exit listener for automatic cleanup
   * @private
   */
  _registerExitListener() {
    if (!this._exitListenerRegistered && typeof process !== "undefined") {
      this._exitListenerRegistered = true;
      this._exitListener = async () => {
        if (this.isConnected()) {
          await tryFn(() => this.disconnect());
        }
      };
      process.on("exit", this._exitListener);
    }
  }
  async connect() {
    this._registerExitListener();
    await this.startPlugins();
    let metadata = null;
    let needsHealing = false;
    let healingLog = [];
    if (await this.client.exists(`s3db.json`)) {
      const [ok, error] = await tryFn(async () => {
        const request = await this.client.getObject(`s3db.json`);
        const rawContent = await streamToString(request?.Body);
        const [parseOk, parseError, parsedData] = tryFn(() => JSON.parse(rawContent));
        if (!parseOk) {
          healingLog.push("JSON parsing failed - attempting recovery");
          needsHealing = true;
          metadata = await this._attemptJsonRecovery(rawContent, healingLog);
          if (!metadata) {
            await this._createCorruptedBackup(rawContent);
            healingLog.push("Created backup of corrupted file - starting with blank metadata");
            metadata = this.blankMetadataStructure();
          }
        } else {
          metadata = parsedData;
        }
        const healedMetadata = await this._validateAndHealMetadata(metadata, healingLog);
        if (healedMetadata !== metadata) {
          metadata = healedMetadata;
          needsHealing = true;
        }
      });
      if (!ok) {
        healingLog.push(`Critical error reading s3db.json: ${error.message}`);
        await this._createCorruptedBackup();
        metadata = this.blankMetadataStructure();
        needsHealing = true;
      }
    } else {
      metadata = this.blankMetadataStructure();
      await this.uploadMetadataFile();
    }
    if (needsHealing) {
      await this._uploadHealedMetadata(metadata, healingLog);
    }
    this.savedMetadata = metadata;
    const definitionChanges = this.detectDefinitionChanges(metadata);
    for (const [name, resourceMetadata] of Object.entries(metadata.resources || {})) {
      const currentVersion = resourceMetadata.currentVersion || "v1";
      const versionData = resourceMetadata.versions?.[currentVersion];
      if (versionData) {
        let restoredIdGenerator, restoredIdSize;
        if (versionData.idGenerator !== void 0) {
          if (versionData.idGenerator === "custom_function") {
            restoredIdGenerator = void 0;
            restoredIdSize = versionData.idSize || 22;
          } else if (typeof versionData.idGenerator === "number") {
            restoredIdGenerator = versionData.idGenerator;
            restoredIdSize = versionData.idSize || versionData.idGenerator;
          }
        } else {
          restoredIdSize = versionData.idSize || 22;
        }
        this._resourcesMap[name] = new Resource({
          name,
          client: this.client,
          database: this,
          // ensure reference
          version: currentVersion,
          attributes: versionData.attributes,
          behavior: versionData.behavior || "user-managed",
          parallelism: this.parallelism,
          passphrase: this.passphrase,
          bcryptRounds: this.bcryptRounds,
          observers: [this],
          cache: this.cache,
          timestamps: versionData.timestamps !== void 0 ? versionData.timestamps : false,
          partitions: resourceMetadata.partitions || versionData.partitions || {},
          paranoid: versionData.paranoid !== void 0 ? versionData.paranoid : true,
          allNestedObjectsOptional: versionData.allNestedObjectsOptional !== void 0 ? versionData.allNestedObjectsOptional : true,
          autoDecrypt: versionData.autoDecrypt !== void 0 ? versionData.autoDecrypt : true,
          asyncEvents: versionData.asyncEvents !== void 0 ? versionData.asyncEvents : true,
          hooks: this.persistHooks ? this._deserializeHooks(versionData.hooks || {}) : versionData.hooks || {},
          versioningEnabled: this.versioningEnabled,
          strictValidation: this.strictValidation,
          map: versionData.map,
          idGenerator: restoredIdGenerator,
          idSize: restoredIdSize
        });
      }
    }
    if (definitionChanges.length > 0) {
      this.emit("db:resource-definitions-changed", {
        changes: definitionChanges,
        metadata: this.savedMetadata
      });
    }
    this.emit("db:connected", /* @__PURE__ */ new Date());
  }
  /**
   * Detect changes in resource definitions compared to saved metadata
   * @param {Object} savedMetadata - The metadata loaded from s3db.json
   * @returns {Array} Array of change objects
   */
  detectDefinitionChanges(savedMetadata) {
    const changes = [];
    for (const [name, currentResource] of Object.entries(this.resources)) {
      const currentHash = this.generateDefinitionHash(currentResource.export());
      const savedResource = savedMetadata.resources?.[name];
      if (!savedResource) {
        changes.push({
          type: "new",
          resourceName: name,
          currentHash,
          savedHash: null
        });
      } else {
        const currentVersion = savedResource.currentVersion || "v1";
        const versionData = savedResource.versions?.[currentVersion];
        const savedHash = versionData?.hash;
        if (savedHash !== currentHash) {
          changes.push({
            type: "changed",
            resourceName: name,
            currentHash,
            savedHash,
            fromVersion: currentVersion,
            toVersion: this.getNextVersion(savedResource.versions)
          });
        }
      }
    }
    for (const [name, savedResource] of Object.entries(savedMetadata.resources || {})) {
      if (!this._resourcesMap[name]) {
        const currentVersion = savedResource.currentVersion || "v1";
        const versionData = savedResource.versions?.[currentVersion];
        changes.push({
          type: "deleted",
          resourceName: name,
          currentHash: null,
          savedHash: versionData?.hash,
          deletedVersion: currentVersion
        });
      }
    }
    return changes;
  }
  /**
   * Generate a consistent hash for a resource definition
   * @param {Object} definition - Resource definition to hash
   * @param {string} behavior - Resource behavior
   * @returns {string} SHA256 hash
   */
  generateDefinitionHash(definition, behavior = void 0) {
    const attributes = definition.attributes;
    const stableAttributes = { ...attributes };
    if (definition.timestamps) {
      delete stableAttributes.createdAt;
      delete stableAttributes.updatedAt;
    }
    const hashObj = {
      attributes: stableAttributes,
      behavior: behavior || definition.behavior || "user-managed",
      partitions: definition.partitions || {}
    };
    const stableString = jsonStableStringify(hashObj);
    return `sha256:${createHash("sha256").update(stableString).digest("hex")}`;
  }
  /**
   * Get the next version number for a resource
   * @param {Object} versions - Existing versions object
   * @returns {string} Next version string (e.g., 'v1', 'v2')
   */
  getNextVersion(versions = {}) {
    const versionNumbers = Object.keys(versions).filter((v) => v.startsWith("v")).map((v) => parseInt(v.substring(1))).filter((n) => !isNaN(n));
    const maxVersion = versionNumbers.length > 0 ? Math.max(...versionNumbers) : 0;
    return `v${maxVersion + 1}`;
  }
  /**
   * Serialize hooks to strings for JSON persistence
   * @param {Object} hooks - Hooks object with event names as keys and function arrays as values
   * @returns {Object} Serialized hooks object
   * @private
   */
  _serializeHooks(hooks) {
    if (!hooks || typeof hooks !== "object") return hooks;
    const serialized = {};
    for (const [event, hookArray] of Object.entries(hooks)) {
      if (Array.isArray(hookArray)) {
        serialized[event] = hookArray.map((hook) => {
          if (typeof hook === "function") {
            const [ok, err, data] = tryFn(() => ({
              __s3db_serialized_function: true,
              code: hook.toString(),
              name: hook.name || "anonymous"
            }));
            if (!ok) {
              if (this.verbose) {
                console.warn(`Failed to serialize hook for event '${event}':`, err.message);
              }
              return null;
            }
            return data;
          }
          return hook;
        });
      } else {
        serialized[event] = hookArray;
      }
    }
    return serialized;
  }
  /**
   * Deserialize hooks from strings back to functions
   * @param {Object} serializedHooks - Serialized hooks object
   * @returns {Object} Deserialized hooks object
   * @private
   */
  _deserializeHooks(serializedHooks) {
    if (!serializedHooks || typeof serializedHooks !== "object") return serializedHooks;
    const deserialized = {};
    for (const [event, hookArray] of Object.entries(serializedHooks)) {
      if (Array.isArray(hookArray)) {
        deserialized[event] = hookArray.map((hook) => {
          if (hook && typeof hook === "object" && hook.__s3db_serialized_function) {
            const [ok, err, fn] = tryFn(() => {
              const func = new Function("return " + hook.code)();
              return typeof func === "function" ? func : null;
            });
            if (!ok || fn === null) {
              if (this.verbose) {
                console.warn(`Failed to deserialize hook '${hook.name}' for event '${event}':`, err?.message || "Invalid function");
              }
              return null;
            }
            return fn;
          }
          return hook;
        }).filter((hook) => hook !== null);
      } else {
        deserialized[event] = hookArray;
      }
    }
    return deserialized;
  }
  async startPlugins() {
    const db = this;
    if (!isEmpty(this.pluginList)) {
      const plugins = this.pluginList.map((p) => isFunction$1(p) ? new p(this) : p);
      const installProms = plugins.map(async (plugin) => {
        const pluginName = this._getPluginName(plugin);
        if (typeof plugin.setInstanceName === "function") {
          plugin.setInstanceName(pluginName);
        } else {
          plugin.instanceName = pluginName;
        }
        await plugin.install(db);
        this.pluginRegistry[pluginName] = plugin;
      });
      await Promise.all(installProms);
      const startProms = plugins.map(async (plugin) => {
        await plugin.start();
      });
      await Promise.all(startProms);
    }
  }
  /**
   * Register and setup a plugin
   * @param {Plugin} plugin - Plugin instance to register
   * @param {string} [name] - Optional name for the plugin (defaults to plugin.constructor.name)
   */
  /**
   * Get the normalized plugin name
   * @private
   */
  _getPluginName(plugin, customName = null) {
    return customName || plugin.constructor.name.replace("Plugin", "").toLowerCase();
  }
  async usePlugin(plugin, name = null) {
    const pluginName = this._getPluginName(plugin, name);
    if (typeof plugin.setInstanceName === "function") {
      plugin.setInstanceName(pluginName);
    } else {
      plugin.instanceName = pluginName;
    }
    this.plugins[pluginName] = plugin;
    if (this.isConnected()) {
      await plugin.install(this);
      await plugin.start();
    }
    return plugin;
  }
  /**
   * Uninstall a plugin and optionally purge its data
   * @param {string} name - Plugin name
   * @param {Object} options - Uninstall options
   * @param {boolean} options.purgeData - Delete all plugin data from S3 (default: false)
   */
  async uninstallPlugin(name, options = {}) {
    const pluginName = name.toLowerCase().replace("plugin", "");
    const plugin = this.plugins[pluginName] || this.pluginRegistry[pluginName];
    if (!plugin) {
      throw new DatabaseError(`Plugin '${name}' not found`, {
        operation: "uninstallPlugin",
        pluginName: name,
        availablePlugins: Object.keys(this.pluginRegistry),
        suggestion: "Check plugin name or list available plugins using Object.keys(db.pluginRegistry)"
      });
    }
    if (plugin.stop) {
      await plugin.stop();
    }
    if (plugin.uninstall) {
      await plugin.uninstall(options);
    }
    delete this.plugins[pluginName];
    delete this.pluginRegistry[pluginName];
    const index = this.pluginList.indexOf(plugin);
    if (index > -1) {
      this.pluginList.splice(index, 1);
    }
    this.emit("db:plugin:uninstalled", { name: pluginName, plugin });
  }
  async uploadMetadataFile() {
    const metadata = {
      version: this.version,
      s3dbVersion: this.s3dbVersion,
      lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
      resources: {}
    };
    Object.entries(this.resources).forEach(([name, resource]) => {
      const resourceDef = resource.export();
      const definitionHash = this.generateDefinitionHash(resourceDef);
      const existingResource = this.savedMetadata?.resources?.[name];
      const currentVersion = existingResource?.currentVersion || "v1";
      const existingVersionData = existingResource?.versions?.[currentVersion];
      let version, isNewVersion;
      if (!existingVersionData || existingVersionData.hash !== definitionHash) {
        version = this.getNextVersion(existingResource?.versions);
        isNewVersion = true;
      } else {
        version = currentVersion;
        isNewVersion = false;
      }
      metadata.resources[name] = {
        currentVersion: version,
        partitions: resource.config.partitions || {},
        createdBy: existingResource?.createdBy || resource.config.createdBy || "user",
        versions: {
          ...existingResource?.versions,
          // Preserve previous versions
          [version]: {
            hash: definitionHash,
            attributes: resourceDef.attributes,
            behavior: resourceDef.behavior || "user-managed",
            timestamps: resource.config.timestamps,
            partitions: resource.config.partitions,
            paranoid: resource.config.paranoid,
            allNestedObjectsOptional: resource.config.allNestedObjectsOptional,
            autoDecrypt: resource.config.autoDecrypt,
            cache: resource.config.cache,
            asyncEvents: resource.config.asyncEvents,
            hooks: this.persistHooks ? this._serializeHooks(resource.config.hooks) : resource.config.hooks,
            idSize: resource.idSize,
            idGenerator: resource.idGeneratorType,
            createdAt: isNewVersion ? (/* @__PURE__ */ new Date()).toISOString() : existingVersionData?.createdAt
          }
        }
      };
      if (resource.version !== version) {
        resource.version = version;
        resource.emit("versionUpdated", { oldVersion: currentVersion, newVersion: version });
      }
    });
    await this.client.putObject({
      key: "s3db.json",
      body: JSON.stringify(metadata, null, 2),
      contentType: "application/json"
    });
    this.savedMetadata = metadata;
    this.emit("db:metadata-uploaded", metadata);
  }
  blankMetadataStructure() {
    return {
      version: `1`,
      s3dbVersion: this.s3dbVersion,
      lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
      resources: {}
    };
  }
  /**
   * Attempt to recover JSON from corrupted content
   */
  async _attemptJsonRecovery(content, healingLog) {
    if (!content || typeof content !== "string") {
      healingLog.push("Content is empty or not a string");
      return null;
    }
    const fixes = [
      // Remove trailing commas
      () => content.replace(/,(\s*[}\]])/g, "$1"),
      // Add missing quotes to keys
      () => content.replace(/([{,]\s*)([a-zA-Z_$][a-zA-Z0-9_$]*)\s*:/g, '$1"$2":'),
      // Fix incomplete objects by adding closing braces
      () => {
        let openBraces = 0;
        let openBrackets = 0;
        let inString = false;
        let escaped = false;
        for (let i = 0; i < content.length; i++) {
          const char = content[i];
          if (escaped) {
            escaped = false;
            continue;
          }
          if (char === "\\") {
            escaped = true;
            continue;
          }
          if (char === '"') {
            inString = !inString;
            continue;
          }
          if (!inString) {
            if (char === "{") openBraces++;
            else if (char === "}") openBraces--;
            else if (char === "[") openBrackets++;
            else if (char === "]") openBrackets--;
          }
        }
        let fixed = content;
        while (openBrackets > 0) {
          fixed += "]";
          openBrackets--;
        }
        while (openBraces > 0) {
          fixed += "}";
          openBraces--;
        }
        return fixed;
      }
    ];
    for (const [index, fix] of fixes.entries()) {
      const [ok, err, parsed] = tryFn(() => {
        const fixedContent = fix();
        return JSON.parse(fixedContent);
      });
      if (ok) {
        healingLog.push(`JSON recovery successful using fix #${index + 1}`);
        return parsed;
      }
    }
    healingLog.push("All JSON recovery attempts failed");
    return null;
  }
  /**
   * Validate and heal metadata structure
   */
  async _validateAndHealMetadata(metadata, healingLog) {
    if (!metadata || typeof metadata !== "object") {
      healingLog.push("Metadata is not an object - using blank structure");
      return this.blankMetadataStructure();
    }
    let healed = { ...metadata };
    let changed = false;
    if (!healed.version || typeof healed.version !== "string") {
      if (healed.version && typeof healed.version === "number") {
        healed.version = String(healed.version);
        healingLog.push("Converted version from number to string");
        changed = true;
      } else {
        healed.version = "1";
        healingLog.push("Added missing or invalid version field");
        changed = true;
      }
    }
    if (!healed.s3dbVersion || typeof healed.s3dbVersion !== "string") {
      if (healed.s3dbVersion && typeof healed.s3dbVersion !== "string") {
        healed.s3dbVersion = String(healed.s3dbVersion);
        healingLog.push("Converted s3dbVersion to string");
        changed = true;
      } else {
        healed.s3dbVersion = this.s3dbVersion;
        healingLog.push("Added missing s3dbVersion field");
        changed = true;
      }
    }
    if (!healed.resources || typeof healed.resources !== "object" || Array.isArray(healed.resources)) {
      healed.resources = {};
      healingLog.push("Fixed invalid resources field");
      changed = true;
    }
    if (!healed.lastUpdated) {
      healed.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
      healingLog.push("Added missing lastUpdated field");
      changed = true;
    }
    const validResources = {};
    for (const [name, resource] of Object.entries(healed.resources)) {
      const healedResource = this._healResourceStructure(name, resource, healingLog);
      if (healedResource) {
        validResources[name] = healedResource;
        if (healedResource !== resource) {
          changed = true;
        }
      } else {
        healingLog.push(`Removed invalid resource: ${name}`);
        changed = true;
      }
    }
    healed.resources = validResources;
    return changed ? healed : metadata;
  }
  /**
   * Heal individual resource structure
   */
  _healResourceStructure(name, resource, healingLog) {
    if (!resource || typeof resource !== "object") {
      healingLog.push(`Resource ${name}: invalid structure`);
      return null;
    }
    let healed = { ...resource };
    let changed = false;
    if (!healed.currentVersion) {
      healed.currentVersion = "v1";
      healingLog.push(`Resource ${name}: added missing currentVersion`);
      changed = true;
    }
    if (!healed.versions || typeof healed.versions !== "object" || Array.isArray(healed.versions)) {
      healed.versions = {};
      healingLog.push(`Resource ${name}: fixed invalid versions object`);
      changed = true;
    }
    if (!healed.partitions || typeof healed.partitions !== "object" || Array.isArray(healed.partitions)) {
      healed.partitions = {};
      healingLog.push(`Resource ${name}: fixed invalid partitions object`);
      changed = true;
    }
    const currentVersion = healed.currentVersion;
    if (!healed.versions[currentVersion]) {
      const availableVersions = Object.keys(healed.versions);
      if (availableVersions.length > 0) {
        healed.currentVersion = availableVersions[0];
        healingLog.push(`Resource ${name}: changed currentVersion from ${currentVersion} to ${healed.currentVersion}`);
        changed = true;
      } else {
        healingLog.push(`Resource ${name}: no valid versions found - removing resource`);
        return null;
      }
    }
    const versionData = healed.versions[healed.currentVersion];
    if (!versionData || typeof versionData !== "object") {
      healingLog.push(`Resource ${name}: invalid version data - removing resource`);
      return null;
    }
    if (!versionData.attributes || typeof versionData.attributes !== "object") {
      healingLog.push(`Resource ${name}: missing or invalid attributes - removing resource`);
      return null;
    }
    if (versionData.hooks) {
      const healedHooks = this._healHooksStructure(versionData.hooks, name, healingLog);
      if (healedHooks !== versionData.hooks) {
        healed.versions[healed.currentVersion].hooks = healedHooks;
        changed = true;
      }
    }
    return changed ? healed : resource;
  }
  /**
   * Heal hooks structure
   */
  _healHooksStructure(hooks, resourceName, healingLog) {
    if (!hooks || typeof hooks !== "object") {
      healingLog.push(`Resource ${resourceName}: invalid hooks structure - using empty hooks`);
      return {};
    }
    const healed = {};
    let changed = false;
    for (const [event, hookArray] of Object.entries(hooks)) {
      if (Array.isArray(hookArray)) {
        const validHooks = hookArray.filter(
          (hook) => hook !== null && hook !== void 0 && hook !== ""
        );
        healed[event] = validHooks;
        if (validHooks.length !== hookArray.length) {
          healingLog.push(`Resource ${resourceName}: cleaned invalid hooks for event ${event}`);
          changed = true;
        }
      } else {
        healingLog.push(`Resource ${resourceName}: hooks for event ${event} is not an array - removing`);
        changed = true;
      }
    }
    return changed ? healed : hooks;
  }
  /**
   * Create backup of corrupted file
   */
  async _createCorruptedBackup(content = null) {
    const [ok, err] = await tryFn(async () => {
      const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
      const backupKey = `s3db.json.corrupted.${timestamp}.backup`;
      if (!content) {
        const [readOk, readErr, readData] = await tryFn(async () => {
          const request = await this.client.getObject(`s3db.json`);
          return await streamToString(request?.Body);
        });
        content = readOk ? readData : "Unable to read corrupted file content";
      }
      await this.client.putObject({
        key: backupKey,
        body: content,
        contentType: "application/json"
      });
      if (this.verbose) {
        console.warn(`S3DB: Created backup of corrupted s3db.json as ${backupKey}`);
      }
    });
    if (!ok && this.verbose) {
      console.warn(`S3DB: Failed to create backup: ${err.message}`);
    }
  }
  /**
   * Upload healed metadata with logging
   */
  async _uploadHealedMetadata(metadata, healingLog) {
    const [ok, err] = await tryFn(async () => {
      if (this.verbose && healingLog.length > 0) {
        console.warn("S3DB Self-Healing Operations:");
        healingLog.forEach((log) => console.warn(`  - ${log}`));
      }
      metadata.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
      await this.client.putObject({
        key: "s3db.json",
        body: JSON.stringify(metadata, null, 2),
        contentType: "application/json"
      });
      this.emit("db:metadata-healed", { healingLog, metadata });
      if (this.verbose) {
        console.warn("S3DB: Successfully uploaded healed metadata");
      }
    });
    if (!ok) {
      if (this.verbose) {
        console.error(`S3DB: Failed to upload healed metadata: ${err.message}`);
      }
      throw err;
    }
  }
  /**
   * Check if a resource exists by name
   * @param {string} name - Resource name
   * @returns {boolean} True if resource exists, false otherwise
   */
  resourceExists(name) {
    return !!this._resourcesMap[name];
  }
  /**
   * Check if a resource exists with the same definition hash
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.attributes - Resource attributes
   * @param {string} [config.behavior] - Resource behavior
   * @returns {Object} Result with exists and hash information
   */
  resourceExistsWithSameHash({ name, attributes, behavior = "user-managed", partitions = {} }) {
    if (!this._resourcesMap[name]) {
      return { exists: false, sameHash: false, hash: null };
    }
    const existingResource = this._resourcesMap[name];
    const existingHash = this.generateDefinitionHash(existingResource.export());
    const mockResource = new Resource({
      name,
      attributes,
      behavior,
      partitions,
      client: this.client,
      version: existingResource.version,
      passphrase: this.passphrase,
      bcryptRounds: this.bcryptRounds,
      versioningEnabled: this.versioningEnabled
    });
    const newHash = this.generateDefinitionHash(mockResource.export());
    return {
      exists: true,
      sameHash: existingHash === newHash,
      hash: newHash,
      existingHash
    };
  }
  /**
   * Create or update a resource in the database
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.attributes - Resource attributes schema
   * @param {string} [config.behavior='user-managed'] - Resource behavior strategy
   * @param {Object} [config.hooks] - Resource hooks
   * @param {boolean} [config.asyncEvents=true] - Whether events should be emitted asynchronously
   * @param {boolean} [config.timestamps=false] - Enable automatic timestamps
   * @param {Object} [config.partitions={}] - Partition definitions
   * @param {boolean} [config.paranoid=true] - Security flag for dangerous operations
   * @param {boolean} [config.cache=false] - Enable caching
   * @param {boolean} [config.autoDecrypt=true] - Auto-decrypt secret fields
   * @param {Function|number} [config.idGenerator] - Custom ID generator or size
   * @param {number} [config.idSize=22] - Size for auto-generated IDs
   * @param {string} [config.createdBy='user'] - Who created this resource ('user', 'plugin', or plugin name)
   * @returns {Promise<Resource>} The created or updated resource
   */
  /**
   * Normalize partitions config from array or object format
   * @param {Array|Object} partitions - Partitions config
   * @param {Object} attributes - Resource attributes
   * @returns {Object} Normalized partitions object
   * @private
   */
  _normalizePartitions(partitions, attributes) {
    if (!Array.isArray(partitions)) {
      return partitions || {};
    }
    const normalized = {};
    for (const fieldName of partitions) {
      if (typeof fieldName !== "string") {
        throw new SchemaError("Invalid partition field type", {
          fieldName,
          receivedType: typeof fieldName,
          retriable: false,
          suggestion: 'Use string field names when declaring partitions (e.g. ["status", "region"]).'
        });
      }
      if (!attributes[fieldName]) {
        throw new SchemaError(`Partition field '${fieldName}' not found in attributes`, {
          fieldName,
          availableFields: Object.keys(attributes),
          retriable: false,
          suggestion: "Ensure the partition field exists in the resource attributes definition."
        });
      }
      const partitionName = `by${fieldName.charAt(0).toUpperCase()}${fieldName.slice(1)}`;
      const fieldDef = attributes[fieldName];
      let fieldType = "string";
      if (typeof fieldDef === "string") {
        fieldType = fieldDef.split("|")[0].trim();
      } else if (typeof fieldDef === "object" && fieldDef.type) {
        fieldType = fieldDef.type;
      }
      normalized[partitionName] = {
        fields: {
          [fieldName]: fieldType
        }
      };
    }
    return normalized;
  }
  async createResource({ name, attributes, behavior = "user-managed", hooks, middlewares, ...config }) {
    const normalizedPartitions = this._normalizePartitions(config.partitions, attributes);
    if (this._resourcesMap[name]) {
      const existingResource = this._resourcesMap[name];
      Object.assign(existingResource.config, {
        cache: this.cache,
        ...config,
        partitions: normalizedPartitions
      });
      if (behavior) {
        existingResource.behavior = behavior;
      }
      existingResource.versioningEnabled = this.versioningEnabled;
      existingResource.updateAttributes(attributes);
      if (hooks) {
        for (const [event, hooksArr] of Object.entries(hooks)) {
          if (Array.isArray(hooksArr) && existingResource.hooks[event]) {
            for (const fn of hooksArr) {
              if (typeof fn === "function") {
                existingResource.hooks[event].push(fn.bind(existingResource));
              }
            }
          }
        }
      }
      if (middlewares) {
        this._applyMiddlewares(existingResource, middlewares);
      }
      const newHash = this.generateDefinitionHash(existingResource.export(), existingResource.behavior);
      const existingMetadata2 = this.savedMetadata?.resources?.[name];
      const currentVersion = existingMetadata2?.currentVersion || "v1";
      const existingVersionData = existingMetadata2?.versions?.[currentVersion];
      if (!existingVersionData || existingVersionData.hash !== newHash) {
        await this.uploadMetadataFile();
      }
      this.emit("db:resource-updated", name);
      return existingResource;
    }
    const existingMetadata = this.savedMetadata?.resources?.[name];
    const version = existingMetadata?.currentVersion || "v1";
    const resource = new Resource({
      name,
      client: this.client,
      version: config.version !== void 0 ? config.version : version,
      attributes,
      behavior,
      parallelism: this.parallelism,
      passphrase: config.passphrase !== void 0 ? config.passphrase : this.passphrase,
      bcryptRounds: config.bcryptRounds !== void 0 ? config.bcryptRounds : this.bcryptRounds,
      observers: [this],
      cache: config.cache !== void 0 ? config.cache : this.cache,
      timestamps: config.timestamps !== void 0 ? config.timestamps : false,
      partitions: normalizedPartitions,
      paranoid: config.paranoid !== void 0 ? config.paranoid : true,
      allNestedObjectsOptional: config.allNestedObjectsOptional !== void 0 ? config.allNestedObjectsOptional : true,
      autoDecrypt: config.autoDecrypt !== void 0 ? config.autoDecrypt : true,
      hooks: hooks || {},
      versioningEnabled: this.versioningEnabled,
      strictValidation: config.strictValidation !== void 0 ? config.strictValidation : this.strictValidation,
      map: config.map,
      idGenerator: config.idGenerator,
      idSize: config.idSize,
      asyncEvents: config.asyncEvents,
      asyncPartitions: config.asyncPartitions !== void 0 ? config.asyncPartitions : true,
      events: config.events || {},
      createdBy: config.createdBy || "user"
    });
    resource.database = this;
    this._resourcesMap[name] = resource;
    if (middlewares) {
      this._applyMiddlewares(resource, middlewares);
    }
    await this.uploadMetadataFile();
    this.emit("db:resource-created", name);
    return resource;
  }
  /**
   * Apply middlewares to a resource
   * @param {Resource} resource - Resource instance
   * @param {Array|Object} middlewares - Middlewares config
   * @private
   */
  _applyMiddlewares(resource, middlewares) {
    if (Array.isArray(middlewares)) {
      const methods = resource._middlewareMethods || [
        "get",
        "list",
        "listIds",
        "getAll",
        "count",
        "page",
        "insert",
        "update",
        "delete",
        "deleteMany",
        "exists",
        "getMany",
        "content",
        "hasContent",
        "query",
        "getFromPartition",
        "setContent",
        "deleteContent",
        "replace",
        "patch"
      ];
      for (const method of methods) {
        for (const middleware of middlewares) {
          if (typeof middleware === "function") {
            resource.useMiddleware(method, middleware);
          }
        }
      }
      return;
    }
    if (typeof middlewares === "object" && middlewares !== null) {
      for (const [method, fns] of Object.entries(middlewares)) {
        if (method === "*") {
          const methods = resource._middlewareMethods || [
            "get",
            "list",
            "listIds",
            "getAll",
            "count",
            "page",
            "insert",
            "update",
            "delete",
            "deleteMany",
            "exists",
            "getMany",
            "content",
            "hasContent",
            "query",
            "getFromPartition",
            "setContent",
            "deleteContent",
            "replace",
            "patch"
          ];
          const middlewareArray = Array.isArray(fns) ? fns : [fns];
          for (const targetMethod of methods) {
            for (const middleware of middlewareArray) {
              if (typeof middleware === "function") {
                resource.useMiddleware(targetMethod, middleware);
              }
            }
          }
        } else {
          const middlewareArray = Array.isArray(fns) ? fns : [fns];
          for (const middleware of middlewareArray) {
            if (typeof middleware === "function") {
              resource.useMiddleware(method, middleware);
            }
          }
        }
      }
    }
  }
  /**
   * List all resource names
   * @returns {Array} Array of resource names
   */
  async listResources() {
    return Object.keys(this.resources).map((name) => ({ name }));
  }
  /**
   * Get a specific resource by name
   * @param {string} name - Resource name
   * @returns {Resource} Resource instance
   */
  async getResource(name) {
    if (!this._resourcesMap[name]) {
      throw new ResourceNotFound({
        bucket: this.client.config.bucket,
        resourceName: name,
        id: name
      });
    }
    return this._resourcesMap[name];
  }
  /**
   * Get database configuration
   * @returns {Object} Configuration object
   */
  get config() {
    return {
      version: this.version,
      s3dbVersion: this.s3dbVersion,
      bucket: this.bucket,
      keyPrefix: this.keyPrefix,
      parallelism: this.parallelism,
      verbose: this.verbose
    };
  }
  isConnected() {
    return !!this.savedMetadata;
  }
  async disconnect() {
    await this.emit("disconnected", /* @__PURE__ */ new Date());
    await tryFn(async () => {
      if (this.pluginList && this.pluginList.length > 0) {
        for (const plugin of this.pluginList) {
          if (plugin && typeof plugin.removeAllListeners === "function") {
            plugin.removeAllListeners();
          }
        }
        const stopProms = this.pluginList.map(async (plugin) => {
          await tryFn(async () => {
            if (plugin && typeof plugin.stop === "function") {
              await plugin.stop();
            }
          });
        });
        await Promise.all(stopProms);
      }
      if (this.resources && Object.keys(this.resources).length > 0) {
        for (const [name, resource] of Object.entries(this.resources)) {
          await tryFn(() => {
            if (resource && typeof resource.removeAllListeners === "function") {
              resource.removeAllListeners();
            }
            if (resource._pluginWrappers) {
              resource._pluginWrappers.clear();
            }
            if (resource._pluginMiddlewares) {
              resource._pluginMiddlewares = {};
            }
            if (resource.observers && Array.isArray(resource.observers)) {
              resource.observers = [];
            }
          });
        }
        Object.keys(this.resources).forEach((k) => delete this._resourcesMap[k]);
      }
      if (this.client && typeof this.client.removeAllListeners === "function") {
        this.client.removeAllListeners();
      }
      await this.emit("db:disconnected", /* @__PURE__ */ new Date());
      this.removeAllListeners();
      if (this._exitListener && typeof process !== "undefined") {
        process.off("exit", this._exitListener);
        this._exitListener = null;
        this._exitListenerRegistered = false;
      }
      this.savedMetadata = null;
      this.plugins = {};
      this.pluginList = [];
    });
  }
  /**
   * Initialize hooks system for database operations
   * @private
   */
  _initHooks() {
    this._hooks = /* @__PURE__ */ new Map();
    this._hookEvents = [
      "beforeConnect",
      "afterConnect",
      "beforeCreateResource",
      "afterCreateResource",
      "beforeUploadMetadata",
      "afterUploadMetadata",
      "beforeDisconnect",
      "afterDisconnect",
      "resourceCreated",
      "resourceUpdated"
    ];
    for (const event of this._hookEvents) {
      this._hooks.set(event, []);
    }
    this._wrapHookableMethods();
  }
  /**
   * Wrap methods that can have hooks
   * @private
   */
  _wrapHookableMethods() {
    if (this._hooksInstalled) return;
    this._originalConnect = this.connect.bind(this);
    this._originalCreateResource = this.createResource.bind(this);
    this._originalUploadMetadataFile = this.uploadMetadataFile.bind(this);
    this._originalDisconnect = this.disconnect.bind(this);
    this.connect = async (...args) => {
      await this._executeHooks("beforeConnect", { args });
      const result = await this._originalConnect(...args);
      await this._executeHooks("afterConnect", { result, args });
      return result;
    };
    this.createResource = async (config) => {
      await this._executeHooks("beforeCreateResource", { config });
      const resource = await this._originalCreateResource(config);
      await this._executeHooks("afterCreateResource", { resource, config });
      return resource;
    };
    this.uploadMetadataFile = async (...args) => {
      await this._executeHooks("beforeUploadMetadata", { args });
      const result = await this._originalUploadMetadataFile(...args);
      await this._executeHooks("afterUploadMetadata", { result, args });
      return result;
    };
    this.disconnect = async (...args) => {
      await this._executeHooks("beforeDisconnect", { args });
      const result = await this._originalDisconnect(...args);
      await this._executeHooks("afterDisconnect", { result, args });
      return result;
    };
    this._hooksInstalled = true;
  }
  /**
   * Add a hook for a specific database event
   * @param {string} event - Hook event name
   * @param {Function} fn - Hook function
   * @example
   * database.addHook('afterCreateResource', async ({ resource }) => {
   *   console.log('Resource created:', resource.name);
   * });
   */
  addHook(event, fn) {
    if (!this._hooks) this._initHooks();
    if (!this._hooks.has(event)) {
      throw new DatabaseError(`Unknown hook event: ${event}`, {
        operation: "addHook",
        invalidEvent: event,
        availableEvents: this._hookEvents,
        suggestion: `Use one of the available hook events: ${this._hookEvents.join(", ")}`
      });
    }
    if (typeof fn !== "function") {
      throw new DatabaseError("Hook function must be a function", {
        operation: "addHook",
        event,
        receivedType: typeof fn,
        suggestion: "Provide a function that will be called when the hook event occurs"
      });
    }
    this._hooks.get(event).push(fn);
  }
  /**
   * Execute hooks for a specific event
   * @param {string} event - Hook event name
   * @param {Object} context - Context data to pass to hooks
   * @private
   */
  async _executeHooks(event, context = {}) {
    if (!this._hooks || !this._hooks.has(event)) return;
    const hooks = this._hooks.get(event);
    for (const hook of hooks) {
      const [ok, error] = await tryFn(() => hook({ database: this, ...context }));
      if (!ok) {
        this.emit("hookError", { event, error, context });
        if (this.strictHooks) {
          throw new DatabaseError(`Hook execution failed for event '${event}': ${error.message}`, {
            event,
            originalError: error,
            context
          });
        }
      }
    }
  }
  /**
   * Remove a hook for a specific event
   * @param {string} event - Hook event name
   * @param {Function} fn - Hook function to remove
   */
  removeHook(event, fn) {
    if (!this._hooks || !this._hooks.has(event)) return;
    const hooks = this._hooks.get(event);
    const index = hooks.indexOf(fn);
    if (index > -1) {
      hooks.splice(index, 1);
    }
  }
  /**
   * Get all hooks for a specific event
   * @param {string} event - Hook event name
   * @returns {Function[]} Array of hook functions
   */
  getHooks(event) {
    if (!this._hooks || !this._hooks.has(event)) return [];
    return [...this._hooks.get(event)];
  }
  /**
   * Clear all hooks for a specific event
   * @param {string} event - Hook event name
   */
  clearHooks(event) {
    if (!this._hooks || !this._hooks.has(event)) return;
    this._hooks.get(event).length = 0;
  }
}
class S3db extends Database {
}

function normalizeResourceName(name) {
  return typeof name === "string" ? name.trim().toLowerCase() : name;
}
class S3dbReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.instanceId = Math.random().toString(36).slice(2, 10);
    this.client = client;
    this.connectionString = config.connectionString;
    let normalizedResources = resources;
    if (!resources) normalizedResources = {};
    else if (Array.isArray(resources)) {
      normalizedResources = {};
      for (const res of resources) {
        if (typeof res === "string") normalizedResources[normalizeResourceName(res)] = res;
      }
    } else if (typeof resources === "string") {
      normalizedResources[normalizeResourceName(resources)] = resources;
    }
    this.resourcesMap = this._normalizeResources(normalizedResources);
  }
  _normalizeResources(resources) {
    if (!resources) return {};
    if (Array.isArray(resources)) {
      const map = {};
      for (const res of resources) {
        if (typeof res === "string") map[normalizeResourceName(res)] = res;
        else if (typeof res === "object" && res.resource) {
          map[normalizeResourceName(res.resource)] = res;
        }
      }
      return map;
    }
    if (typeof resources === "object") {
      const map = {};
      for (const [src, dest] of Object.entries(resources)) {
        const normSrc = normalizeResourceName(src);
        if (typeof dest === "string") map[normSrc] = dest;
        else if (Array.isArray(dest)) {
          map[normSrc] = dest.map((item) => {
            if (typeof item === "string") return item;
            if (typeof item === "object" && item.resource) {
              return item;
            }
            return item;
          });
        } else if (typeof dest === "function") map[normSrc] = dest;
        else if (typeof dest === "object" && dest.resource) {
          map[normSrc] = dest;
        }
      }
      return map;
    }
    if (typeof resources === "function") {
      return resources;
    }
    return {};
  }
  validateConfig() {
    const errors = [];
    if (!this.client && !this.connectionString) {
      errors.push("You must provide a client or a connectionString");
    }
    if (!this.resourcesMap || typeof this.resourcesMap === "object" && Object.keys(this.resourcesMap).length === 0) {
      errors.push("You must provide a resources map or array");
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const [ok, err] = await tryFn(async () => {
      if (this.client) {
        this.targetDatabase = this.client;
      } else if (this.connectionString) {
        const targetConfig = {
          connectionString: this.connectionString,
          region: this.region,
          keyPrefix: this.keyPrefix,
          verbose: this.config.verbose || false
        };
        this.targetDatabase = new S3db(targetConfig);
        await this.targetDatabase.connect();
      } else {
        throw new ReplicationError("S3dbReplicator requires client or connectionString", {
          operation: "initialize",
          replicatorClass: "S3dbReplicator",
          suggestion: 'Provide either a client instance or connectionString in config: { client: db } or { connectionString: "s3://..." }'
        });
      }
      this.emit("connected", {
        replicator: this.name,
        target: this.connectionString || "client-provided"
      });
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[S3dbReplicator] Initialization failed: ${err.message}`);
      }
      throw err;
    }
  }
  // Support both object and parameter signatures for flexibility
  async replicate(resourceOrObj, operation, data, recordId, beforeData) {
    let resource, op, payload, id;
    if (typeof resourceOrObj === "object" && resourceOrObj.resource) {
      resource = resourceOrObj.resource;
      op = resourceOrObj.operation;
      payload = resourceOrObj.data;
      id = resourceOrObj.id;
    } else {
      resource = resourceOrObj;
      op = operation;
      payload = data;
      id = recordId;
    }
    const normResource = normalizeResourceName(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "S3dbReplicator",
        resourceName: resource,
        configuredResources: Object.keys(this.resourcesMap),
        suggestion: 'Add resource to replicator resources map: { resources: { [resourceName]: "destination" } }'
      });
    }
    if (Array.isArray(entry)) {
      const results = [];
      for (const destConfig of entry) {
        const [ok, error, result] = await tryFn(async () => {
          return await this._replicateToSingleDestination(destConfig, normResource, op, payload, id);
        });
        if (!ok) {
          if (this.config && this.config.verbose) {
            console.warn(`[S3dbReplicator] Failed to replicate to destination ${JSON.stringify(destConfig)}: ${error.message}`);
          }
          throw error;
        }
        results.push(result);
      }
      return results;
    } else {
      const [ok, error, result] = await tryFn(async () => {
        return await this._replicateToSingleDestination(entry, normResource, op, payload, id);
      });
      if (!ok) {
        if (this.config && this.config.verbose) {
          console.warn(`[S3dbReplicator] Failed to replicate to destination ${JSON.stringify(entry)}: ${error.message}`);
        }
        throw error;
      }
      return result;
    }
  }
  async _replicateToSingleDestination(destConfig, sourceResource, operation, data, recordId) {
    let destResourceName;
    if (typeof destConfig === "string") {
      destResourceName = destConfig;
    } else if (typeof destConfig === "object" && destConfig.resource) {
      destResourceName = destConfig.resource;
    } else {
      destResourceName = sourceResource;
    }
    if (typeof destConfig === "object" && destConfig.actions && Array.isArray(destConfig.actions)) {
      if (!destConfig.actions.includes(operation)) {
        return { skipped: true, reason: "action_not_supported", action: operation, destination: destResourceName };
      }
    }
    const destResourceObj = this._getDestResourceObj(destResourceName);
    let transformedData;
    if (typeof destConfig === "object" && destConfig.transform && typeof destConfig.transform === "function") {
      transformedData = destConfig.transform(data);
      if (transformedData && data && data.id && !transformedData.id) {
        transformedData.id = data.id;
      }
    } else {
      transformedData = data;
    }
    if (!transformedData && data) transformedData = data;
    let result;
    if (operation === "insert") {
      result = await destResourceObj.insert(transformedData);
    } else if (operation === "update") {
      result = await destResourceObj.update(recordId, transformedData);
    } else if (operation === "delete") {
      result = await destResourceObj.delete(recordId);
    } else {
      throw new ReplicationError(`Invalid replication operation: ${operation}`, {
        operation: "replicate",
        replicatorClass: "S3dbReplicator",
        invalidOperation: operation,
        supportedOperations: ["insert", "update", "delete"],
        resourceName: sourceResource,
        suggestion: "Use one of the supported operations: insert, update, delete"
      });
    }
    return result;
  }
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const normResource = normalizeResourceName(resource);
    const entry = this.resourcesMap[normResource];
    let result;
    if (!entry) return cleanData;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "object" && item.transform && typeof item.transform === "function") {
          result = item.transform(cleanData);
          break;
        }
      }
      if (!result) result = cleanData;
    } else if (typeof entry === "object") {
      if (typeof entry.transform === "function") {
        result = entry.transform(cleanData);
      }
    } else if (typeof entry === "function") {
      result = entry(cleanData);
    } else {
      result = cleanData;
    }
    if (result && cleanData && cleanData.id && !result.id) result.id = cleanData.id;
    if (!result && cleanData) result = cleanData;
    return result;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  _resolveDestResource(resource, data) {
    const normResource = normalizeResourceName(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) return resource;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "string") return item;
        if (typeof item === "object" && item.resource) return item.resource;
      }
      return resource;
    }
    if (typeof entry === "string") return entry;
    if (typeof entry === "function") return resource;
    if (typeof entry === "object" && entry.resource) return entry.resource;
    return resource;
  }
  _getDestResourceObj(resource) {
    const db = this.targetDatabase || this.client;
    const available = Object.keys(db.resources || {});
    const norm = normalizeResourceName(resource);
    const found = available.find((r) => normalizeResourceName(r) === norm);
    if (!found) {
      throw new ReplicationError("Destination resource not found in target database", {
        operation: "_getDestResourceObj",
        replicatorClass: "S3dbReplicator",
        destinationResource: resource,
        availableResources: available,
        suggestion: "Create the resource in target database or check resource name spelling"
      });
    }
    return db.resources[found];
  }
  async replicateBatch(resourceName, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(() => this.replicate({
        resource: resourceName,
        operation: record.operation,
        id: record.id,
        data: record.data,
        beforeData: record.beforeData
      }));
      if (ok) {
        results.push(result);
      } else {
        if (this.config.verbose) {
          console.warn(`[S3dbReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[S3dbReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    this.emit("batch_replicated", {
      replicator: this.name,
      resourceName,
      total: records.length,
      successful: results.length,
      errors: errors.length
    });
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.targetDatabase) {
        throw new ReplicationError("No target database configured for connection test", {
          operation: "testConnection",
          replicatorClass: "S3dbReplicator",
          suggestion: "Initialize replicator with client or connectionString before testing connection"
        });
      }
      if (typeof this.targetDatabase.connect === "function") {
        await this.targetDatabase.connect();
      }
      return true;
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[S3dbReplicator] Connection test failed: ${err.message}`);
      }
      this.emit("connection_error", { replicator: this.name, error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.targetDatabase,
      targetDatabase: this.connectionString || "client-provided",
      resources: Object.keys(this.resourcesMap || {}),
      totalreplicators: this.listenerCount("replicated"),
      totalErrors: this.listenerCount("replicator_error")
    };
  }
  async cleanup() {
    if (this.targetDatabase) {
      this.targetDatabase.removeAllListeners();
    }
    await super.cleanup();
  }
  shouldReplicateResource(resource, action) {
    const normResource = normalizeResourceName(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) return false;
    if (!action) return true;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "object" && item.resource) {
          if (item.actions && Array.isArray(item.actions)) {
            if (item.actions.includes(action)) return true;
          } else {
            return true;
          }
        } else if (typeof item === "string") {
          return true;
        }
      }
      return false;
    }
    if (typeof entry === "object" && entry.resource) {
      if (entry.actions && Array.isArray(entry.actions)) {
        return entry.actions.includes(action);
      }
      return true;
    }
    if (typeof entry === "string" || typeof entry === "function") {
      return true;
    }
    return false;
  }
}

class SqsReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.client = client;
    this.queueUrl = config.queueUrl;
    this.queues = config.queues || {};
    this.defaultQueue = config.defaultQueue || null;
    this.region = config.region || "us-east-1";
    this.sqsClient = client || null;
    this.messageGroupId = config.messageGroupId;
    this.deduplicationId = config.deduplicationId;
    this.resourceQueueMap = config.resourceQueueMap || null;
    if (Array.isArray(resources)) {
      this.resources = {};
      for (const resource of resources) {
        if (typeof resource === "string") {
          this.resources[resource] = true;
        } else if (typeof resource === "object" && resource.name) {
          this.resources[resource.name] = resource;
        }
      }
    } else if (typeof resources === "object") {
      this.resources = resources;
      for (const [resourceName, resourceConfig] of Object.entries(resources)) {
        if (resourceConfig && resourceConfig.queueUrl) {
          this.queues[resourceName] = resourceConfig.queueUrl;
        }
      }
    } else {
      this.resources = {};
    }
  }
  validateConfig() {
    const errors = [];
    if (!this.queueUrl && Object.keys(this.queues).length === 0 && !this.defaultQueue && !this.resourceQueueMap) {
      errors.push("Either queueUrl, queues object, defaultQueue, or resourceQueueMap must be provided");
    }
    return {
      isValid: errors.length === 0,
      errors
    };
  }
  getQueueUrlsForResource(resource) {
    if (this.resourceQueueMap && this.resourceQueueMap[resource]) {
      return this.resourceQueueMap[resource];
    }
    if (this.queues[resource]) {
      return [this.queues[resource]];
    }
    if (this.queueUrl) {
      return [this.queueUrl];
    }
    if (this.defaultQueue) {
      return [this.defaultQueue];
    }
    throw new Error(`No queue URL found for resource '${resource}'`);
  }
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const entry = this.resources[resource];
    let result = cleanData;
    if (!entry) return cleanData;
    if (typeof entry.transform === "function") {
      result = entry.transform(cleanData);
    }
    return result || cleanData;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Create standardized message structure
   */
  createMessage(resource, operation, data, id, beforeData = null) {
    const baseMessage = {
      resource,
      // padronizado para 'resource'
      action: operation,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      source: "s3db-replicator"
    };
    switch (operation) {
      case "insert":
        return {
          ...baseMessage,
          data
        };
      case "update":
        return {
          ...baseMessage,
          before: beforeData,
          data
        };
      case "delete":
        return {
          ...baseMessage,
          data
        };
      default:
        return {
          ...baseMessage,
          data
        };
    }
  }
  async initialize(database, client) {
    await super.initialize(database);
    await requirePluginDependency("sqs-replicator");
    if (!this.sqsClient) {
      const [ok, err, sdk] = await tryFn(() => import('@aws-sdk/client-sqs'));
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[SqsReplicator] Failed to import SQS SDK: ${err.message}`);
        }
        this.emit("initialization_error", {
          replicator: this.name,
          error: err.message
        });
        throw err;
      }
      const { SQSClient } = sdk;
      this.sqsClient = client || new SQSClient({
        region: this.region,
        credentials: this.config.credentials
      });
      this.emit("db:plugin:initialized", {
        replicator: this.name,
        queueUrl: this.queueUrl,
        queues: this.queues,
        defaultQueue: this.defaultQueue
      });
    }
  }
  async replicate(resource, operation, data, id, beforeData = null) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const { SendMessageCommand } = await import('@aws-sdk/client-sqs');
      const queueUrls = this.getQueueUrlsForResource(resource);
      const transformedData = this._applyTransformer(resource, data);
      const message = this.createMessage(resource, operation, transformedData, id, beforeData);
      const results = [];
      for (const queueUrl of queueUrls) {
        const command = new SendMessageCommand({
          QueueUrl: queueUrl,
          MessageBody: JSON.stringify(message),
          MessageGroupId: this.messageGroupId,
          MessageDeduplicationId: this.deduplicationId ? `${resource}:${operation}:${id}` : void 0
        });
        const result2 = await this.sqsClient.send(command);
        results.push({ queueUrl, messageId: result2.MessageId });
        this.emit("plg:replicator:replicated", {
          replicator: this.name,
          resource,
          operation,
          id,
          queueUrl,
          messageId: result2.MessageId,
          success: true
        });
      }
      return { success: true, results };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Replication failed for ${resource}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resource,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resource, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const { SendMessageBatchCommand } = await import('@aws-sdk/client-sqs');
      const queueUrls = this.getQueueUrlsForResource(resource);
      const batchSize = 10;
      const batches = [];
      for (let i = 0; i < records.length; i += batchSize) {
        batches.push(records.slice(i, i + batchSize));
      }
      const results = [];
      const errors = [];
      for (const batch of batches) {
        const [okBatch, errBatch] = await tryFn(async () => {
          const entries = batch.map((record, index) => ({
            Id: `${record.id}-${index}`,
            MessageBody: JSON.stringify(this.createMessage(
              resource,
              record.operation,
              record.data,
              record.id,
              record.beforeData
            )),
            MessageGroupId: this.messageGroupId,
            MessageDeduplicationId: this.deduplicationId ? `${resource}:${record.operation}:${record.id}` : void 0
          }));
          const command = new SendMessageBatchCommand({
            QueueUrl: queueUrls[0],
            // Assuming all queueUrls in a batch are the same for batching
            Entries: entries
          });
          const result2 = await this.sqsClient.send(command);
          results.push(result2);
        });
        if (!okBatch) {
          errors.push({ batch: batch.length, error: errBatch.message });
          if (errBatch.message && (errBatch.message.includes("Batch error") || errBatch.message.includes("Connection") || errBatch.message.includes("Network"))) {
            throw errBatch;
          }
        }
      }
      if (errors.length > 0) {
        console.warn(`[SqsReplicator] Batch replication completed with ${errors.length} error(s) for ${resource}:`, errors);
      }
      this.emit("batch_replicated", {
        replicator: this.name,
        resource,
        queueUrl: queueUrls[0],
        // Assuming all queueUrls in a batch are the same for batching
        total: records.length,
        successful: results.length,
        errors: errors.length
      });
      return {
        success: errors.length === 0,
        results,
        errors,
        total: records.length,
        queueUrl: queueUrls[0]
        // Assuming all queueUrls in a batch are the same for batching
      };
    });
    if (ok) return result;
    const errorMessage = err?.message || err || "Unknown error";
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Batch replication failed for ${resource}: ${errorMessage}`);
    }
    this.emit("batch_replicator_error", {
      replicator: this.name,
      resource,
      error: errorMessage
    });
    return { success: false, error: errorMessage };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.sqsClient) {
        await this.initialize(this.database);
      }
      const { GetQueueAttributesCommand } = await import('@aws-sdk/client-sqs');
      const command = new GetQueueAttributesCommand({
        QueueUrl: this.queueUrl,
        AttributeNames: ["QueueArn"]
      });
      await this.sqsClient.send(command);
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", {
      replicator: this.name,
      error: err.message
    });
    return false;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.sqsClient,
      queueUrl: this.queueUrl,
      region: this.region,
      resources: Object.keys(this.resources || {}),
      totalreplicators: this.listenerCount("replicated"),
      totalErrors: this.listenerCount("replicator_error")
    };
  }
  async cleanup() {
    if (this.sqsClient) {
      this.sqsClient.destroy();
    }
    await super.cleanup();
  }
  shouldReplicateResource(resource) {
    const result = this.resourceQueueMap && Object.keys(this.resourceQueueMap).includes(resource) || this.queues && Object.keys(this.queues).includes(resource) || !!(this.defaultQueue || this.queueUrl) || this.resources && Object.keys(this.resources).includes(resource) || false;
    return result;
  }
}

class TursoReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.url = config.url;
    this.authToken = config.authToken;
    this.client = null;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.url) errors.push("URL is required");
    if (!this.authToken) errors.push("Auth token is required");
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("turso-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@libsql/client'));
    if (!ok) {
      throw new ReplicationError("Failed to import Turso SDK", {
        operation: "initialize",
        replicatorClass: "TursoReplicator",
        original: err,
        suggestion: "Install @libsql/client: pnpm add @libsql/client"
      });
    }
    const { createClient } = sdk;
    this.client = createClient({
      url: this.url,
      authToken: this.authToken
    });
    const [okTest, errTest] = await tryFn(async () => {
      await this.client.execute("SELECT 1");
    });
    if (!okTest) {
      throw new ReplicationError("Failed to connect to Turso database", {
        operation: "initialize",
        replicatorClass: "TursoReplicator",
        url: this.url,
        original: errTest,
        suggestion: "Check Turso URL and auth token"
      });
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "TursoReplicator",
      url: this.url
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[TursoReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[TursoReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const [okCheck, errCheck, result] = await tryFn(async () => {
      return await this.client.execute({
        sql: "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
        args: [tableName]
      });
    });
    const tableExists = okCheck && result.rows.length > 0;
    if (!tableExists) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generateSQLiteCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[TursoReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.client.execute(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[TursoReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.client.execute(`DROP TABLE IF EXISTS ${tableName}`);
      const createSQL = generateSQLiteCreateTable(tableName, attributes);
      await this.client.execute(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const [okPragma, errPragma, pragmaResult] = await tryFn(async () => {
        return await this.client.execute(`PRAGMA table_info(${tableName})`);
      });
      if (okPragma) {
        const existingSchema = {};
        for (const row of pragmaResult.rows) {
          existingSchema[row.name] = { type: row.type };
        }
        const alterStatements = generateSQLiteAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          if (this.config.verbose) {
            console.log(`[TursoReplicator] Altering table ${tableName}:`, alterStatements);
          }
          for (const stmt of alterStatements) {
            await this.client.execute(stmt);
          }
          this.emit("table_altered", {
            replicator: this.name,
            tableName,
            addedColumns: alterStatements.length
          });
        }
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    for (const table of tables) {
      const [okTable, errTable] = await tryFn(async () => {
        if (operation === "insert") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData);
          const values = keys.map((k) => cleanData[k]);
          const placeholders = keys.map((_, i) => `?`).join(", ");
          const sql = `INSERT OR IGNORE INTO ${table} (${keys.join(", ")}) VALUES (${placeholders})`;
          await this.client.execute({ sql, args: values });
        } else if (operation === "update") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData).filter((k) => k !== "id");
          const setClause = keys.map((k) => `${k}=?`).join(", ");
          const values = keys.map((k) => cleanData[k]);
          values.push(id);
          const sql = `UPDATE ${table} SET ${setClause} WHERE id=?`;
          await this.client.execute({ sql, args: values });
        } else if (operation === "delete") {
          const sql = `DELETE FROM ${table} WHERE id=?`;
          await this.client.execute({ sql, args: [id] });
        }
        results.push({ table, success: true });
      });
      if (!okTable) {
        errors.push({ table, error: errTable.message });
      }
    }
    const success = errors.length === 0;
    this.emit("plg:replicator:replicated", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      tables,
      results,
      errors,
      success
    });
    return { success, results, errors, tables };
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    if (this.client) {
      this.client.close();
      this.client = null;
    }
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client,
      url: this.url,
      resources: Object.keys(this.resources),
      schemaSync: this.schemaSync
    };
  }
}

class WebhookReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.url = config.url;
    if (!this.url) {
      throw new Error('WebhookReplicator requires a "url" configuration');
    }
    this.method = (config.method || "POST").toUpperCase();
    this.headers = config.headers || {};
    this.timeout = config.timeout || 5e3;
    this.retries = config.retries ?? 3;
    this.retryDelay = config.retryDelay || 1e3;
    this.retryStrategy = config.retryStrategy || "exponential";
    this.retryOnStatus = config.retryOnStatus || [429, 500, 502, 503, 504];
    this.batch = config.batch || false;
    this.batchSize = config.batchSize || 100;
    this.auth = config.auth || null;
    if (Array.isArray(resources)) {
      this.resources = {};
      for (const resource of resources) {
        if (typeof resource === "string") {
          this.resources[resource] = true;
        } else if (typeof resource === "object" && resource.name) {
          this.resources[resource.name] = resource;
        }
      }
    } else if (typeof resources === "object") {
      this.resources = resources;
    } else {
      this.resources = {};
    }
    this.stats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      retriedRequests: 0,
      totalRetries: 0
    };
  }
  validateConfig() {
    const errors = [];
    if (!this.url) {
      errors.push("URL is required");
    }
    try {
      new URL(this.url);
    } catch (err) {
      errors.push(`Invalid URL format: ${this.url}`);
    }
    if (this.auth) {
      if (!this.auth.type) {
        errors.push("auth.type is required when auth is configured");
      } else if (!["bearer", "basic", "apikey"].includes(this.auth.type)) {
        errors.push("auth.type must be one of: bearer, basic, apikey");
      }
      if (this.auth.type === "bearer" && !this.auth.token) {
        errors.push("auth.token is required for bearer authentication");
      }
      if (this.auth.type === "basic" && (!this.auth.username || !this.auth.password)) {
        errors.push("auth.username and auth.password are required for basic authentication");
      }
      if (this.auth.type === "apikey" && (!this.auth.header || !this.auth.value)) {
        errors.push("auth.header and auth.value are required for API key authentication");
      }
    }
    return {
      isValid: errors.length === 0,
      errors
    };
  }
  /**
   * Build headers with authentication
   * @returns {Object} Headers object
   */
  _buildHeaders() {
    const headers = {
      "Content-Type": "application/json",
      "User-Agent": "s3db-webhook-replicator",
      ...this.headers
    };
    if (this.auth) {
      switch (this.auth.type) {
        case "bearer":
          headers["Authorization"] = `Bearer ${this.auth.token}`;
          break;
        case "basic":
          const credentials = Buffer.from(`${this.auth.username}:${this.auth.password}`).toString("base64");
          headers["Authorization"] = `Basic ${credentials}`;
          break;
        case "apikey":
          headers[this.auth.header] = this.auth.value;
          break;
      }
    }
    return headers;
  }
  /**
   * Apply resource transformer if configured
   * @param {string} resource - Resource name
   * @param {Object} data - Data to transform
   * @returns {Object} Transformed data
   */
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const entry = this.resources[resource];
    let result = cleanData;
    if (!entry) return cleanData;
    if (typeof entry.transform === "function") {
      result = entry.transform(cleanData);
    }
    return result || cleanData;
  }
  /**
   * Remove internal fields from data
   * @param {Object} data - Data object
   * @returns {Object} Cleaned data
   */
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Create standardized webhook payload
   * @param {string} resource - Resource name
   * @param {string} operation - Operation type
   * @param {Object} data - Record data
   * @param {string} id - Record ID
   * @param {Object} beforeData - Before data (for updates)
   * @returns {Object} Webhook payload
   */
  createPayload(resource, operation, data, id, beforeData = null) {
    const basePayload = {
      resource,
      action: operation,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      source: "s3db-webhook-replicator"
    };
    switch (operation) {
      case "insert":
        return {
          ...basePayload,
          data
        };
      case "update":
        return {
          ...basePayload,
          before: beforeData,
          data
        };
      case "delete":
        return {
          ...basePayload,
          data
        };
      default:
        return {
          ...basePayload,
          data
        };
    }
  }
  /**
   * Make HTTP request with retries
   * @param {Object} payload - Request payload
   * @param {number} attempt - Current attempt number
   * @returns {Promise<Object>} Response
   */
  async _makeRequest(payload, attempt = 0) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);
    try {
      const response = await fetch(this.url, {
        method: this.method,
        headers: this._buildHeaders(),
        body: JSON.stringify(payload),
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      this.stats.totalRequests++;
      if (response.ok) {
        this.stats.successfulRequests++;
        return {
          success: true,
          status: response.status,
          statusText: response.statusText
        };
      }
      if (this.retryOnStatus.includes(response.status) && attempt < this.retries) {
        this.stats.retriedRequests++;
        this.stats.totalRetries++;
        const delay = this.retryStrategy === "exponential" ? this.retryDelay * Math.pow(2, attempt) : this.retryDelay;
        if (this.config.verbose) {
          console.log(`[WebhookReplicator] Retrying request (attempt ${attempt + 1}/${this.retries}) after ${delay}ms - Status: ${response.status}`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
        return this._makeRequest(payload, attempt + 1);
      }
      this.stats.failedRequests++;
      const errorText = await response.text().catch(() => "");
      return {
        success: false,
        status: response.status,
        statusText: response.statusText,
        error: errorText || `HTTP ${response.status}: ${response.statusText}`
      };
    } catch (error) {
      clearTimeout(timeoutId);
      if (attempt < this.retries) {
        this.stats.retriedRequests++;
        this.stats.totalRetries++;
        const delay = this.retryStrategy === "exponential" ? this.retryDelay * Math.pow(2, attempt) : this.retryDelay;
        if (this.config.verbose) {
          console.log(`[WebhookReplicator] Retrying request (attempt ${attempt + 1}/${this.retries}) after ${delay}ms - Error: ${error.message}`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
        return this._makeRequest(payload, attempt + 1);
      }
      this.stats.failedRequests++;
      this.stats.totalRequests++;
      return {
        success: false,
        error: error.message
      };
    }
  }
  async initialize(database) {
    await super.initialize(database);
    const validation = this.validateConfig();
    if (!validation.isValid) {
      const error = new Error(`WebhookReplicator configuration is invalid: ${validation.errors.join(", ")}`);
      if (this.config.verbose) {
        console.error(`[WebhookReplicator] ${error.message}`);
      }
      this.emit("initialization_error", {
        replicator: this.name,
        error: error.message,
        errors: validation.errors
      });
      throw error;
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      url: this.url,
      method: this.method,
      authType: this.auth?.type || "none",
      resources: Object.keys(this.resources || {})
    });
  }
  async replicate(resource, operation, data, id, beforeData = null) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const transformedData = this._applyTransformer(resource, data);
      const payload = this.createPayload(resource, operation, transformedData, id, beforeData);
      const response = await this._makeRequest(payload);
      if (response.success) {
        this.emit("plg:replicator:replicated", {
          replicator: this.name,
          resource,
          operation,
          id,
          url: this.url,
          status: response.status,
          success: true
        });
        return { success: true, status: response.status };
      }
      throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Replication failed for ${resource}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resource,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resource, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      if (this.batch) {
        const payloads = records.map(
          (record) => this.createPayload(
            resource,
            record.operation,
            this._applyTransformer(resource, record.data),
            record.id,
            record.beforeData
          )
        );
        const response = await this._makeRequest({ batch: payloads });
        if (response.success) {
          this.emit("batch_replicated", {
            replicator: this.name,
            resource,
            url: this.url,
            total: records.length,
            successful: records.length,
            errors: 0,
            status: response.status
          });
          return {
            success: true,
            total: records.length,
            successful: records.length,
            errors: 0,
            status: response.status
          };
        }
        throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
      }
      const results = await Promise.allSettled(
        records.map(
          (record) => this.replicate(resource, record.operation, record.data, record.id, record.beforeData)
        )
      );
      const successful = results.filter((r) => r.status === "fulfilled" && r.value.success).length;
      const failed = results.length - successful;
      this.emit("batch_replicated", {
        replicator: this.name,
        resource,
        url: this.url,
        total: records.length,
        successful,
        errors: failed
      });
      return {
        success: failed === 0,
        total: records.length,
        successful,
        errors: failed,
        results
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Batch replication failed for ${resource}: ${err.message}`);
    }
    this.emit("batch_replicator_error", {
      replicator: this.name,
      resource,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      const testPayload = {
        test: true,
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        source: "s3db-webhook-replicator"
      };
      const response = await this._makeRequest(testPayload);
      if (!response.success) {
        throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
      }
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", {
      replicator: this.name,
      error: err.message
    });
    return false;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      url: this.url,
      method: this.method,
      authType: this.auth?.type || "none",
      timeout: this.timeout,
      retries: this.retries,
      retryStrategy: this.retryStrategy,
      batchMode: this.batch,
      resources: Object.keys(this.resources || {}),
      stats: { ...this.stats }
    };
  }
  shouldReplicateResource(resource) {
    if (!this.resources || Object.keys(this.resources).length === 0) {
      return true;
    }
    return Object.keys(this.resources).includes(resource);
  }
}

const REPLICATOR_DRIVERS = {
  s3db: S3dbReplicator,
  sqs: SqsReplicator,
  bigquery: BigqueryReplicator,
  postgres: PostgresReplicator,
  mysql: MySQLReplicator,
  mariadb: MySQLReplicator,
  // MariaDB uses the same driver as MySQL
  planetscale: PlanetScaleReplicator,
  turso: TursoReplicator,
  dynamodb: DynamoDBReplicator,
  mongodb: MongoDBReplicator,
  webhook: WebhookReplicator
};
function createReplicator(driver, config = {}, resources = [], client = null) {
  const ReplicatorClass = REPLICATOR_DRIVERS[driver];
  if (!ReplicatorClass) {
    throw new ReplicationError(`Unknown replicator driver: ${driver}`, {
      operation: "createReplicator",
      driver,
      availableDrivers: Object.keys(REPLICATOR_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(REPLICATOR_DRIVERS).join(", ")}`
    });
  }
  return new ReplicatorClass(config, resources, client);
}
function validateReplicatorConfig(driver, config, resources = [], client = null) {
  const replicator = createReplicator(driver, config, resources, client);
  return replicator.validateConfig();
}

class ReplicatorPlugin extends Plugin {
  constructor(options = {}) {
    super();
    if (!options.replicators || !Array.isArray(options.replicators)) {
      throw new ReplicationError("ReplicatorPlugin requires replicators array", {
        operation: "constructor",
        pluginName: "ReplicatorPlugin",
        providedOptions: Object.keys(options),
        suggestion: 'Provide replicators array: new ReplicatorPlugin({ replicators: [{ driver: "s3db", resources: [...] }] })'
      });
    }
    for (const rep of options.replicators) {
      if (!rep.driver) {
        throw new ReplicationError("Each replicator must have a driver", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          replicatorConfig: rep,
          suggestion: 'Each replicator entry must specify a driver: { driver: "s3db", resources: {...} }'
        });
      }
      if (!rep.resources || typeof rep.resources !== "object") {
        throw new ReplicationError("Each replicator must have resources config", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          driver: rep.driver,
          replicatorConfig: rep,
          suggestion: 'Provide resources as object or array: { driver: "s3db", resources: ["users"] } or { resources: { users: "people" } }'
        });
      }
      if (Object.keys(rep.resources).length === 0) {
        throw new ReplicationError("Each replicator must have at least one resource configured", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          driver: rep.driver,
          replicatorConfig: rep,
          suggestion: 'Add at least one resource to replicate: { driver: "s3db", resources: ["users"] }'
        });
      }
    }
    const resourceNamesOption = options.resourceNames || {};
    this.config = {
      replicators: options.replicators || [],
      logErrors: options.logErrors !== false,
      persistReplicatorLog: options.persistReplicatorLog || false,
      enabled: options.enabled !== false,
      batchSize: options.batchSize || 100,
      maxRetries: options.maxRetries || 3,
      timeout: options.timeout || 3e4,
      verbose: options.verbose || false
    };
    this._logResourceDescriptor = {
      defaultName: "plg_replicator_logs",
      override: resourceNamesOption.log || options.replicatorLogResource
    };
    this.logResourceName = this._resolveLogResourceName();
    this.config.logResourceName = this.logResourceName;
    this.replicators = [];
    this.database = null;
    this.eventListenersInstalled = /* @__PURE__ */ new Set();
    this.eventHandlers = /* @__PURE__ */ new Map();
    this.stats = {
      totalReplications: 0,
      totalErrors: 0,
      lastSync: null
    };
    this._afterCreateResourceHook = null;
    this.replicatorLog = null;
  }
  _resolveLogResourceName() {
    return resolveResourceName("replicator", this._logResourceDescriptor, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.logResourceName = this._resolveLogResourceName();
    if (this.config) {
      this.config.logResourceName = this.logResourceName;
    }
  }
  // Helper to filter out internal S3DB fields
  filterInternalFields(obj) {
    if (!obj || typeof obj !== "object") return obj;
    const filtered = {};
    for (const [key, value] of Object.entries(obj)) {
      if (!key.startsWith("_") && key !== "$overflow" && key !== "$before" && key !== "$after") {
        filtered[key] = value;
      }
    }
    return filtered;
  }
  async getCompleteData(resource, data) {
    const [ok, err, completeRecord] = await tryFn(() => resource.get(data.id));
    return ok ? completeRecord : data;
  }
  installEventListeners(resource, database, plugin) {
    if (!resource || this.eventListenersInstalled.has(resource.name) || resource.name === this.logResourceName) {
      return;
    }
    const insertHandler = async (data) => {
      const [ok, error] = await tryFn(async () => {
        const completeData = { ...data, createdAt: (/* @__PURE__ */ new Date()).toISOString() };
        await plugin.processReplicatorEvent("insert", resource.name, completeData.id, completeData);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Insert event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "insert", error: error.message, resource: resource.name });
      }
    };
    const updateHandler = async (data, beforeData) => {
      const [ok, error] = await tryFn(async () => {
        const completeData = await plugin.getCompleteData(resource, data);
        const dataWithTimestamp = { ...completeData, updatedAt: (/* @__PURE__ */ new Date()).toISOString() };
        await plugin.processReplicatorEvent("update", resource.name, completeData.id, dataWithTimestamp, beforeData);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Update event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "update", error: error.message, resource: resource.name });
      }
    };
    const deleteHandler = async (data) => {
      const [ok, error] = await tryFn(async () => {
        await plugin.processReplicatorEvent("delete", resource.name, data.id, data);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Delete event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "delete", error: error.message, resource: resource.name });
      }
    };
    this.eventHandlers.set(resource.name, {
      inserted: insertHandler,
      updated: updateHandler,
      deleted: deleteHandler
    });
    resource.on("inserted", insertHandler);
    resource.on("updated", updateHandler);
    resource.on("deleted", deleteHandler);
    this.eventListenersInstalled.add(resource.name);
  }
  async onInstall() {
    if (this.config.persistReplicatorLog) {
      const logResourceName = this.logResourceName;
      const [ok, err, logResource] = await tryFn(() => this.database.createResource({
        name: logResourceName,
        attributes: {
          id: "string|required",
          resource: "string|required",
          action: "string|required",
          data: "json",
          timestamp: "number|required",
          createdAt: "string|required"
        },
        behavior: "truncate-data"
      }));
      if (ok) {
        this.replicatorLog = logResource;
      } else {
        const existing = this.database.resources[logResourceName];
        if (existing) {
          this.replicatorLog = existing;
        } else {
          throw err;
        }
      }
    }
    await this.initializeReplicators(this.database);
    this.installDatabaseHooks();
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name !== this.logResourceName) {
        this.installEventListeners(resource, this.database, this);
      }
    }
  }
  async start() {
  }
  installDatabaseHooks() {
    this._afterCreateResourceHook = (resource) => {
      if (resource.name !== this.logResourceName) {
        this.installEventListeners(resource, this.database, this);
      }
    };
    this.database.addHook("afterCreateResource", this._afterCreateResourceHook);
  }
  removeDatabaseHooks() {
    if (this._afterCreateResourceHook) {
      this.database.removeHook("afterCreateResource", this._afterCreateResourceHook);
      this._afterCreateResourceHook = null;
    }
  }
  createReplicator(driver, config, resources, client) {
    return createReplicator(driver, config, resources, client);
  }
  async initializeReplicators(database) {
    for (const replicatorConfig of this.config.replicators) {
      const { driver, config = {}, resources, client, ...otherConfig } = replicatorConfig;
      const replicatorResources = resources || config.resources || {};
      const mergedConfig = { ...config, ...otherConfig };
      const replicator = this.createReplicator(driver, mergedConfig, replicatorResources, client);
      if (replicator) {
        await replicator.initialize(database);
        this.replicators.push(replicator);
      }
    }
  }
  async uploadMetadataFile(database) {
    if (typeof this.database.uploadMetadataFile === "function") {
      await this.database.uploadMetadataFile();
    }
  }
  async retryWithBackoff(operation, maxRetries = 3) {
    let lastError;
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      const [ok, error, result] = await tryFn(operation);
      if (ok) {
        return result;
      } else {
        lastError = error;
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Retry attempt ${attempt}/${maxRetries} failed: ${error.message}`);
        }
        if (attempt === maxRetries) {
          throw error;
        }
        const delay = Math.pow(2, attempt - 1) * 1e3;
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Waiting ${delay}ms before retry...`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
    throw lastError;
  }
  async logError(replicator, resourceName, operation, recordId, data, error) {
    const [ok, logError] = await tryFn(async () => {
      if (this.replicatorLog) {
        await this.replicatorLog.insert({
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          data: JSON.stringify(data),
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          status: "error"
        });
      }
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to log error for ${resourceName}: ${logError.message}`);
      }
      this.emit("plg:replicator:log-error", {
        replicator: replicator.name || replicator.id,
        resourceName,
        operation,
        recordId,
        originalError: error.message,
        logError: logError.message
      });
    }
  }
  async processReplicatorEvent(operation, resourceName, recordId, data, beforeData = null) {
    if (!this.config.enabled) return;
    const applicableReplicators = this.replicators.filter((replicator) => {
      const should = replicator.shouldReplicateResource && replicator.shouldReplicateResource(resourceName, operation);
      return should;
    });
    if (applicableReplicators.length === 0) {
      return;
    }
    const promises = applicableReplicators.map(async (replicator) => {
      const [ok, error, result] = await tryFn(async () => {
        const result2 = await this.retryWithBackoff(
          () => replicator.replicate(resourceName, operation, data, recordId, beforeData),
          this.config.maxRetries
        );
        this.emit("plg:replicator:replicated", {
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          result: result2,
          success: true
        });
        return result2;
      });
      if (ok) {
        return result;
      } else {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Replication failed for ${replicator.name || replicator.id} on ${resourceName}: ${error.message}`);
        }
        this.emit("plg:replicator:error", {
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          error: error.message
        });
        if (this.config.logErrors && this.database) {
          await this.logError(replicator, resourceName, operation, recordId, data, error);
        }
        throw error;
      }
    });
    return Promise.allSettled(promises);
  }
  async processReplicatorItem(item) {
    const applicableReplicators = this.replicators.filter((replicator) => {
      const should = replicator.shouldReplicateResource && replicator.shouldReplicateResource(item.resourceName, item.operation);
      return should;
    });
    if (applicableReplicators.length === 0) {
      return;
    }
    const promises = applicableReplicators.map(async (replicator) => {
      const [wrapperOk, wrapperError] = await tryFn(async () => {
        const [ok, err, result] = await tryFn(
          () => replicator.replicate(item.resourceName, item.operation, item.data, item.recordId, item.beforeData)
        );
        if (!ok) {
          if (this.config.verbose) {
            console.warn(`[ReplicatorPlugin] Replicator item processing failed for ${replicator.name || replicator.id} on ${item.resourceName}: ${err.message}`);
          }
          this.emit("plg:replicator:error", {
            replicator: replicator.name || replicator.id,
            resourceName: item.resourceName,
            operation: item.operation,
            recordId: item.recordId,
            error: err.message
          });
          if (this.config.logErrors && this.database) {
            await this.logError(replicator, item.resourceName, item.operation, item.recordId, item.data, err);
          }
          return { success: false, error: err.message };
        }
        this.emit("plg:replicator:replicated", {
          replicator: replicator.name || replicator.id,
          resourceName: item.resourceName,
          operation: item.operation,
          recordId: item.recordId,
          result,
          success: true
        });
        return { success: true, result };
      });
      if (wrapperOk) {
        return wrapperOk;
      } else {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Wrapper processing failed for ${replicator.name || replicator.id} on ${item.resourceName}: ${wrapperError.message}`);
        }
        this.emit("plg:replicator:error", {
          replicator: replicator.name || replicator.id,
          resourceName: item.resourceName,
          operation: item.operation,
          recordId: item.recordId,
          error: wrapperError.message
        });
        if (this.config.logErrors && this.database) {
          await this.logError(replicator, item.resourceName, item.operation, item.recordId, item.data, wrapperError);
        }
        return { success: false, error: wrapperError.message };
      }
    });
    return Promise.allSettled(promises);
  }
  async logReplicator(item) {
    const logRes = this.replicatorLog;
    if (!logRes) {
      this.emit("plg:replicator:log-failed", { error: "replicator log resource not found", item });
      return;
    }
    const logItem = {
      id: item.id || `repl-${Date.now()}-${Math.random().toString(36).slice(2)}`,
      resource: item.resource || item.resourceName || "",
      action: item.operation || item.action || "",
      data: item.data || {},
      timestamp: typeof item.timestamp === "number" ? item.timestamp : Date.now(),
      createdAt: item.createdAt || (/* @__PURE__ */ new Date()).toISOString().slice(0, 10)
    };
    const [ok, err] = await tryFn(async () => {
      await logRes.insert(logItem);
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to log replicator item: ${err.message}`);
      }
      this.emit("plg:replicator:log-failed", { error: err, item });
    }
  }
  async updateReplicatorLog(logId, updates) {
    if (!this.replicatorLog) return;
    const [ok, err] = await tryFn(async () => {
      await this.replicatorLog.patch(logId, {
        ...updates,
        lastAttempt: (/* @__PURE__ */ new Date()).toISOString()
      });
    });
    if (!ok) {
      this.emit("plg:replicator:update-log-failed", { error: err.message, logId, updates });
    }
  }
  // Utility methods
  async getReplicatorStats() {
    const replicatorStats = await Promise.all(
      this.replicators.map(async (replicator) => {
        const status = await replicator.getStatus();
        return {
          id: replicator.id,
          driver: replicator.driver,
          config: replicator.config,
          status
        };
      })
    );
    return {
      replicators: replicatorStats,
      stats: this.stats,
      lastSync: this.stats.lastSync
    };
  }
  async getReplicatorLogs(options = {}) {
    if (!this.replicatorLog) {
      return [];
    }
    const {
      resourceName,
      operation,
      status,
      limit = 100,
      offset = 0
    } = options;
    const filter = {};
    if (resourceName) {
      filter.resourceName = resourceName;
    }
    if (operation) {
      filter.operation = operation;
    }
    if (status) {
      filter.status = status;
    }
    const logs = await this.replicatorLog.query(filter, { limit, offset });
    return logs || [];
  }
  async retryFailedReplicators() {
    if (!this.replicatorLog) {
      return { retried: 0 };
    }
    const failedLogs = await this.replicatorLog.query({
      status: "failed"
    });
    let retried = 0;
    for (const log of failedLogs || []) {
      const [ok, err] = await tryFn(async () => {
        await this.processReplicatorEvent(
          log.operation,
          log.resourceName,
          log.recordId,
          log.data
        );
      });
      if (ok) {
        retried++;
      }
    }
    return { retried };
  }
  async syncAllData(replicatorId) {
    const replicator = this.replicators.find((r) => r.id === replicatorId);
    if (!replicator) {
      throw new ReplicationError("Replicator not found", {
        operation: "syncAllData",
        pluginName: "ReplicatorPlugin",
        replicatorId,
        availableReplicators: this.replicators.map((r) => r.id),
        suggestion: "Check replicator ID or use getReplicatorStats() to list available replicators"
      });
    }
    this.stats.lastSync = (/* @__PURE__ */ new Date()).toISOString();
    for (const resourceName in this.database.resources) {
      if (resourceName === this.logResourceName) continue;
      if (replicator.shouldReplicateResource(resourceName)) {
        this.emit("plg:replicator:sync-resource", { resourceName, replicatorId });
        const resource = this.database.resources[resourceName];
        let offset = 0;
        const pageSize = this.config.batchSize || 100;
        while (true) {
          const [ok, err, page] = await tryFn(() => resource.page({ offset, size: pageSize }));
          if (!ok || !page) break;
          const records = Array.isArray(page) ? page : page.items || [];
          if (records.length === 0) break;
          for (const record of records) {
            await replicator.replicate(resourceName, "insert", record, record.id);
          }
          offset += pageSize;
        }
      }
    }
    this.emit("plg:replicator:sync-completed", { replicatorId, stats: this.stats });
  }
  async stop() {
    const [ok, error] = await tryFn(async () => {
      if (this.replicators && this.replicators.length > 0) {
        const cleanupPromises = this.replicators.map(async (replicator) => {
          const [replicatorOk, replicatorError] = await tryFn(async () => {
            if (replicator && typeof replicator.stop === "function") {
              await replicator.stop();
            }
          });
          if (!replicatorOk) {
            if (this.config.verbose) {
              console.warn(`[ReplicatorPlugin] Failed to stop replicator ${replicator.name || replicator.id}: ${replicatorError.message}`);
            }
            this.emit("plg:replicator:stop-error", {
              replicator: replicator.name || replicator.id || "unknown",
              driver: replicator.driver || "unknown",
              error: replicatorError.message
            });
          }
        });
        await Promise.allSettled(cleanupPromises);
      }
      this.removeDatabaseHooks();
      if (this.database && this.database.resources) {
        for (const resourceName of this.eventListenersInstalled) {
          const resource = this.database.resources[resourceName];
          const handlers = this.eventHandlers.get(resourceName);
          if (resource && handlers) {
            resource.off("inserted", handlers.inserted);
            resource.off("updated", handlers.updated);
            resource.off("deleted", handlers.deleted);
          }
        }
      }
      this.replicators = [];
      this.database = null;
      this.eventListenersInstalled.clear();
      this.eventHandlers.clear();
      this.removeAllListeners();
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to stop plugin: ${error.message}`);
      }
      this.emit("plg:replicator:plugin-stop-error", {
        error: error.message
      });
    }
  }
}

class SchedulerError extends S3dbError {
  constructor(message, details = {}) {
    const { taskId, operation = "unknown", cronExpression, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Scheduler Operation Error

Operation: ${operation}
${taskId ? `Task ID: ${taskId}` : ""}
${cronExpression ? `Cron: ${cronExpression}` : ""}

Common causes:
1. Invalid cron expression format
2. Task not found or already exists
3. Scheduler not properly initialized
4. Job execution failure
5. Resource conflicts

Solution:
Check task configuration and ensure scheduler is properly initialized.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/scheduler.md
`.trim();
    }
    super(message, { ...rest, taskId, operation, cronExpression, description });
  }
}

class SchedulerPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      timezone: options.timezone || "UTC",
      jobs: options.jobs || {},
      defaultTimeout: options.defaultTimeout || 3e5,
      // 5 minutes
      defaultRetries: options.defaultRetries || 1,
      jobHistoryResource: options.jobHistoryResource || "plg_job_executions",
      persistJobs: options.persistJobs !== false,
      verbose: options.verbose || false,
      onJobStart: options.onJobStart || null,
      onJobComplete: options.onJobComplete || null,
      onJobError: options.onJobError || null,
      ...options
    };
    this.database = null;
    this.jobs = /* @__PURE__ */ new Map();
    this.activeJobs = /* @__PURE__ */ new Map();
    this.timers = /* @__PURE__ */ new Map();
    this.statistics = /* @__PURE__ */ new Map();
    this._validateConfiguration();
  }
  /**
   * Helper to detect test environment
   * @private
   */
  _isTestEnvironment() {
    return process.env.NODE_ENV === "test" || process.env.JEST_WORKER_ID !== void 0 || global.expect !== void 0;
  }
  _validateConfiguration() {
    if (Object.keys(this.config.jobs).length === 0) {
      throw new SchedulerError("At least one job must be defined", {
        operation: "validateConfiguration",
        jobCount: 0,
        suggestion: 'Provide at least one job in the jobs configuration: { jobs: { myJob: { schedule: "* * * * *", action: async () => {...} } } }'
      });
    }
    for (const [jobName, job] of Object.entries(this.config.jobs)) {
      if (!job.schedule) {
        throw new SchedulerError(`Job '${jobName}' must have a schedule`, {
          operation: "validateConfiguration",
          taskId: jobName,
          providedConfig: Object.keys(job),
          suggestion: 'Add a schedule property with a valid cron expression: { schedule: "0 * * * *", action: async () => {...} }'
        });
      }
      if (!job.action || typeof job.action !== "function") {
        throw new SchedulerError(`Job '${jobName}' must have an action function`, {
          operation: "validateConfiguration",
          taskId: jobName,
          actionType: typeof job.action,
          suggestion: 'Provide an action function: { schedule: "...", action: async (db, ctx) => {...} }'
        });
      }
      if (!this._isValidCronExpression(job.schedule)) {
        throw new SchedulerError(`Job '${jobName}' has invalid cron expression`, {
          operation: "validateConfiguration",
          taskId: jobName,
          cronExpression: job.schedule,
          suggestion: "Use valid cron format (5 fields: minute hour day month weekday) or shortcuts (@hourly, @daily, @weekly, @monthly, @yearly)"
        });
      }
    }
  }
  _isValidCronExpression(expr) {
    if (typeof expr !== "string") return false;
    const shortcuts = ["@yearly", "@annually", "@monthly", "@weekly", "@daily", "@hourly"];
    if (shortcuts.includes(expr)) return true;
    const parts = expr.trim().split(/\s+/);
    if (parts.length !== 5) return false;
    return true;
  }
  async onInstall() {
    if (this.config.persistJobs) {
      await this._createJobHistoryResource();
    }
    for (const [jobName, jobConfig] of Object.entries(this.config.jobs)) {
      this.jobs.set(jobName, {
        ...jobConfig,
        enabled: jobConfig.enabled !== false,
        retries: jobConfig.retries || this.config.defaultRetries,
        timeout: jobConfig.timeout || this.config.defaultTimeout,
        lastRun: null,
        nextRun: null,
        runCount: 0,
        successCount: 0,
        errorCount: 0
      });
      this.statistics.set(jobName, {
        totalRuns: 0,
        totalSuccesses: 0,
        totalErrors: 0,
        avgDuration: 0,
        lastRun: null,
        lastSuccess: null,
        lastError: null
      });
    }
    await this._startScheduling();
    this.emit("db:plugin:initialized", { jobs: this.jobs.size });
  }
  async _createJobHistoryResource() {
    const [ok] = await tryFn(() => this.database.createResource({
      name: this.config.jobHistoryResource,
      attributes: {
        id: "string|required",
        jobName: "string|required",
        status: "string|required",
        // success, error, timeout
        startTime: "number|required",
        endTime: "number",
        duration: "number",
        result: "json|default:null",
        error: "string|default:null",
        retryCount: "number|default:0",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      partitions: {
        byJob: { fields: { jobName: "string" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
  }
  async _startScheduling() {
    for (const [jobName, job] of this.jobs) {
      if (job.enabled) {
        this._scheduleNextExecution(jobName);
      }
    }
  }
  _scheduleNextExecution(jobName) {
    const job = this.jobs.get(jobName);
    if (!job || !job.enabled) return;
    const nextRun = this._calculateNextRun(job.schedule);
    job.nextRun = nextRun;
    const delay = nextRun.getTime() - Date.now();
    if (delay > 0) {
      const timer = setTimeout(() => {
        this._executeJob(jobName);
      }, delay);
      this.timers.set(jobName, timer);
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Scheduled job '${jobName}' for ${nextRun.toISOString()}`);
      }
    }
  }
  _calculateNextRun(schedule) {
    const now = /* @__PURE__ */ new Date();
    if (schedule === "@yearly" || schedule === "@annually") {
      const next2 = new Date(now);
      next2.setFullYear(next2.getFullYear() + 1);
      next2.setMonth(0, 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@monthly") {
      const next2 = new Date(now);
      next2.setMonth(next2.getMonth() + 1, 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@weekly") {
      const next2 = new Date(now);
      next2.setDate(next2.getDate() + (7 - next2.getDay()));
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@daily") {
      const next2 = new Date(now);
      next2.setDate(next2.getDate() + 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@hourly") {
      const next2 = new Date(now);
      next2.setHours(next2.getHours() + 1, 0, 0, 0);
      return next2;
    }
    const [minute, hour, day, month, weekday] = schedule.split(/\s+/);
    const next = new Date(now);
    next.setMinutes(parseInt(minute) || 0);
    next.setSeconds(0);
    next.setMilliseconds(0);
    if (hour !== "*") {
      next.setHours(parseInt(hour));
    }
    if (next <= now) {
      if (hour !== "*") {
        next.setDate(next.getDate() + 1);
      } else {
        next.setHours(next.getHours() + 1);
      }
    }
    if (this._isTestEnvironment()) {
      next.setTime(next.getTime() + 1e3);
    }
    return next;
  }
  async _executeJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      return;
    }
    if (this.activeJobs.has(jobName)) {
      return;
    }
    this.activeJobs.set(jobName, "acquiring-lock");
    const storage = this.getStorage();
    const lockName = `job-${jobName}`;
    const lock = await storage.acquireLock(lockName, {
      ttl: Math.ceil(job.timeout / 1e3) + 60,
      // Job timeout + 60 seconds buffer
      timeout: 0,
      // Don't wait if locked
      workerId: process.pid ? String(process.pid) : "unknown"
    });
    if (!lock) {
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Job '${jobName}' already running on another instance`);
      }
      this.activeJobs.delete(jobName);
      return;
    }
    const executionId = `${jobName}_${idGenerator()}`;
    const startTime = Date.now();
    const context = {
      jobName,
      executionId,
      scheduledTime: new Date(startTime),
      database: this.database
    };
    this.activeJobs.set(jobName, executionId);
    try {
      if (this.config.onJobStart) {
        await this._executeHook(this.config.onJobStart, jobName, context);
      }
      this.emit("plg:scheduler:job-start", { jobName, executionId, startTime });
      let attempt = 0;
      let lastError = null;
      let result = null;
      let status = "success";
      const isTestEnvironment = this._isTestEnvironment();
      while (attempt <= job.retries) {
        try {
          const actualTimeout = isTestEnvironment ? Math.min(job.timeout, 1e3) : job.timeout;
          let timeoutId;
          const timeoutPromise = new Promise((_, reject) => {
            timeoutId = setTimeout(() => reject(new Error("Job execution timeout")), actualTimeout);
          });
          const jobPromise = job.action(this.database, context, this);
          try {
            result = await Promise.race([jobPromise, timeoutPromise]);
            clearTimeout(timeoutId);
          } catch (raceError) {
            clearTimeout(timeoutId);
            throw raceError;
          }
          status = "success";
          break;
        } catch (error) {
          lastError = error;
          attempt++;
          if (attempt <= job.retries) {
            if (this.config.verbose) {
              console.warn(`[SchedulerPlugin] Job '${jobName}' failed (attempt ${attempt + 1}):`, error.message);
            }
            const baseDelay = Math.min(Math.pow(2, attempt) * 1e3, 5e3);
            const delay = isTestEnvironment ? 1 : baseDelay;
            await new Promise((resolve) => setTimeout(resolve, delay));
          }
        }
      }
      const endTime = Date.now();
      const duration = Math.max(1, endTime - startTime);
      if (lastError && attempt > job.retries) {
        status = lastError.message.includes("timeout") ? "timeout" : "error";
      }
      job.lastRun = new Date(endTime);
      job.runCount++;
      if (status === "success") {
        job.successCount++;
      } else {
        job.errorCount++;
      }
      const stats = this.statistics.get(jobName);
      stats.totalRuns++;
      stats.lastRun = new Date(endTime);
      if (status === "success") {
        stats.totalSuccesses++;
        stats.lastSuccess = new Date(endTime);
      } else {
        stats.totalErrors++;
        stats.lastError = { time: new Date(endTime), message: lastError?.message };
      }
      stats.avgDuration = (stats.avgDuration * (stats.totalRuns - 1) + duration) / stats.totalRuns;
      if (this.config.persistJobs) {
        await this._persistJobExecution(jobName, executionId, startTime, endTime, duration, status, result, lastError, attempt);
      }
      if (status === "success" && this.config.onJobComplete) {
        await this._executeHook(this.config.onJobComplete, jobName, result, duration);
      } else if (status !== "success" && this.config.onJobError) {
        await this._executeHook(this.config.onJobError, jobName, lastError, attempt);
      }
      this.emit("plg:scheduler:job-complete", {
        jobName,
        executionId,
        status,
        duration,
        result,
        error: lastError?.message,
        retryCount: attempt
      });
      this.activeJobs.delete(jobName);
      if (job.enabled) {
        this._scheduleNextExecution(jobName);
      }
      if (lastError && status !== "success") {
        throw lastError;
      }
    } finally {
      if (lock) {
        await tryFn(() => storage.releaseLock(lock));
      }
    }
  }
  async _persistJobExecution(jobName, executionId, startTime, endTime, duration, status, result, error, retryCount) {
    const [ok, err] = await tryFn(
      () => this.database.resources[this.config.jobHistoryResource].insert({
        id: executionId,
        jobName,
        status,
        startTime,
        endTime,
        duration,
        result: result ? JSON.stringify(result) : null,
        error: error?.message || null,
        retryCount,
        createdAt: new Date(startTime).toISOString().slice(0, 10)
      })
    );
    if (!ok && this.config.verbose) {
      console.warn("[SchedulerPlugin] Failed to persist job execution:", err.message);
    }
  }
  async _executeHook(hook, ...args) {
    if (typeof hook === "function") {
      const [ok, err] = await tryFn(() => hook(...args));
      if (!ok && this.config.verbose) {
        console.warn("[SchedulerPlugin] Hook execution failed:", err.message);
      }
    }
  }
  /**
   * Manually trigger a job execution
   * Note: Race conditions are prevented by distributed locking in _executeJob()
   */
  async runJob(jobName, context = {}) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "runJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    if (this.activeJobs.has(jobName)) {
      throw new SchedulerError(`Job '${jobName}' is already running`, {
        operation: "runJob",
        taskId: jobName,
        executionId: this.activeJobs.get(jobName),
        suggestion: "Wait for current execution to complete or check job status with getJobStatus()"
      });
    }
    await this._executeJob(jobName);
  }
  /**
   * Enable a job
   */
  enableJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "enableJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    job.enabled = true;
    this._scheduleNextExecution(jobName);
    this.emit("plg:scheduler:job-enabled", { jobName });
  }
  /**
   * Disable a job
   */
  disableJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "disableJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    job.enabled = false;
    const timer = this.timers.get(jobName);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(jobName);
    }
    this.emit("plg:scheduler:job-disabled", { jobName });
  }
  /**
   * Get job status and statistics
   */
  getJobStatus(jobName) {
    const job = this.jobs.get(jobName);
    const stats = this.statistics.get(jobName);
    if (!job || !stats) {
      return null;
    }
    return {
      name: jobName,
      enabled: job.enabled,
      schedule: job.schedule,
      description: job.description,
      lastRun: job.lastRun,
      nextRun: job.nextRun,
      isRunning: this.activeJobs.has(jobName),
      statistics: {
        totalRuns: stats.totalRuns,
        totalSuccesses: stats.totalSuccesses,
        totalErrors: stats.totalErrors,
        successRate: stats.totalRuns > 0 ? stats.totalSuccesses / stats.totalRuns * 100 : 0,
        avgDuration: Math.round(stats.avgDuration),
        lastSuccess: stats.lastSuccess,
        lastError: stats.lastError
      }
    };
  }
  /**
   * Get all jobs status
   */
  getAllJobsStatus() {
    const jobs = [];
    for (const jobName of this.jobs.keys()) {
      jobs.push(this.getJobStatus(jobName));
    }
    return jobs;
  }
  /**
   * Get job execution history
   */
  async getJobHistory(jobName, options = {}) {
    if (!this.config.persistJobs) {
      return [];
    }
    const { limit = 50, status = null } = options;
    const queryParams = {
      jobName
      // Uses byJob partition for efficient lookup
    };
    if (status) {
      queryParams.status = status;
    }
    const [ok, err, history] = await tryFn(
      () => this.database.resources[this.config.jobHistoryResource].query(queryParams)
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[SchedulerPlugin] Failed to get job history:`, err.message);
      }
      return [];
    }
    let filtered = history.sort((a, b) => b.startTime - a.startTime).slice(0, limit);
    return filtered.map((h) => {
      let result = null;
      if (h.result) {
        try {
          result = JSON.parse(h.result);
        } catch (e) {
          result = h.result;
        }
      }
      return {
        id: h.id,
        status: h.status,
        startTime: new Date(h.startTime),
        endTime: h.endTime ? new Date(h.endTime) : null,
        duration: h.duration,
        result,
        error: h.error,
        retryCount: h.retryCount
      };
    });
  }
  /**
   * Add a new job at runtime
   */
  addJob(jobName, jobConfig) {
    if (this.jobs.has(jobName)) {
      throw new SchedulerError(`Job '${jobName}' already exists`, {
        operation: "addJob",
        taskId: jobName,
        existingJobs: Array.from(this.jobs.keys()),
        suggestion: "Use a different job name or remove the existing job first with removeJob()"
      });
    }
    if (!jobConfig.schedule || !jobConfig.action) {
      throw new SchedulerError("Job must have schedule and action", {
        operation: "addJob",
        taskId: jobName,
        providedConfig: Object.keys(jobConfig),
        suggestion: 'Provide both schedule and action: { schedule: "0 * * * *", action: async (db, ctx) => {...} }'
      });
    }
    if (!this._isValidCronExpression(jobConfig.schedule)) {
      throw new SchedulerError("Invalid cron expression", {
        operation: "addJob",
        taskId: jobName,
        cronExpression: jobConfig.schedule,
        suggestion: "Use valid cron format (5 fields) or shortcuts (@hourly, @daily, @weekly, @monthly, @yearly)"
      });
    }
    const job = {
      ...jobConfig,
      enabled: jobConfig.enabled !== false,
      retries: jobConfig.retries || this.config.defaultRetries,
      timeout: jobConfig.timeout || this.config.defaultTimeout,
      lastRun: null,
      nextRun: null,
      runCount: 0,
      successCount: 0,
      errorCount: 0
    };
    this.jobs.set(jobName, job);
    this.statistics.set(jobName, {
      totalRuns: 0,
      totalSuccesses: 0,
      totalErrors: 0,
      avgDuration: 0,
      lastRun: null,
      lastSuccess: null,
      lastError: null
    });
    if (job.enabled) {
      this._scheduleNextExecution(jobName);
    }
    this.emit("plg:scheduler:job-added", { jobName });
  }
  /**
   * Remove a job
   */
  removeJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "removeJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    const timer = this.timers.get(jobName);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(jobName);
    }
    this.jobs.delete(jobName);
    this.statistics.delete(jobName);
    this.activeJobs.delete(jobName);
    this.emit("plg:scheduler:job-removed", { jobName });
  }
  /**
   * Get plugin instance by name (for job actions that need other plugins)
   */
  getPlugin(pluginName) {
    return null;
  }
  async start() {
    if (this.config.verbose) {
      console.log(`[SchedulerPlugin] Started with ${this.jobs.size} jobs`);
    }
  }
  async stop() {
    for (const timer of this.timers.values()) {
      clearTimeout(timer);
    }
    this.timers.clear();
    if (!this._isTestEnvironment() && this.activeJobs.size > 0) {
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Waiting for ${this.activeJobs.size} active jobs to complete...`);
      }
      const timeout = 5e3;
      const start = Date.now();
      while (this.activeJobs.size > 0 && Date.now() - start < timeout) {
        await new Promise((resolve) => setTimeout(resolve, 100));
      }
      if (this.activeJobs.size > 0) {
        console.warn(`[SchedulerPlugin] ${this.activeJobs.size} jobs still running after timeout`);
      }
    }
    if (this._isTestEnvironment()) {
      this.activeJobs.clear();
    }
    this.jobs.clear();
    this.statistics.clear();
    this.activeJobs.clear();
    this.removeAllListeners();
  }
}

var scheduler_plugin = /*#__PURE__*/Object.freeze({
  __proto__: null,
  SchedulerPlugin: SchedulerPlugin
});

class StateMachineError extends S3dbError {
  constructor(message, details = {}) {
    const { currentState, targetState, resourceName, operation = "unknown", retriable, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
State Machine Operation Error

Operation: ${operation}
${currentState ? `Current State: ${currentState}` : ""}
${targetState ? `Target State: ${targetState}` : ""}
${resourceName ? `Resource: ${resourceName}` : ""}

Common causes:
1. Invalid state transition
2. State machine not configured
3. Transition conditions not met
4. State not defined in configuration
5. Missing transition handler

Solution:
Check state machine configuration and valid transitions.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/state-machine.md
`.trim();
    }
    super(message, { ...rest, currentState, targetState, resourceName, operation, description });
    if (retriable !== void 0) {
      this.retriable = retriable;
    }
  }
}

const RETRIABLE = "RETRIABLE";
const NON_RETRIABLE = "NON_RETRIABLE";
const RETRIABLE_NETWORK_CODES = /* @__PURE__ */ new Set([
  "ECONNREFUSED",
  "ETIMEDOUT",
  "ECONNRESET",
  "EPIPE",
  "ENOTFOUND",
  "NetworkError",
  "NETWORK_ERROR",
  "TimeoutError",
  "TIMEOUT"
]);
const RETRIABLE_AWS_CODES = /* @__PURE__ */ new Set([
  "ThrottlingException",
  "TooManyRequestsException",
  "RequestLimitExceeded",
  "ProvisionedThroughputExceededException",
  "RequestThrottledException",
  "SlowDown",
  "ServiceUnavailable"
]);
const RETRIABLE_AWS_CONFLICTS = /* @__PURE__ */ new Set([
  "ConditionalCheckFailedException",
  "TransactionConflictException"
]);
const RETRIABLE_STATUS_CODES = /* @__PURE__ */ new Set([
  429,
  // Too Many Requests
  500,
  // Internal Server Error
  502,
  // Bad Gateway
  503,
  // Service Unavailable
  504,
  // Gateway Timeout
  507,
  // Insufficient Storage
  509
  // Bandwidth Limit Exceeded
]);
const NON_RETRIABLE_ERROR_NAMES = /* @__PURE__ */ new Set([
  "ValidationError",
  "StateMachineError",
  "SchemaError",
  "AuthenticationError",
  "PermissionError",
  "BusinessLogicError",
  "InvalidStateTransition"
]);
const NON_RETRIABLE_STATUS_CODES = /* @__PURE__ */ new Set([
  400,
  // Bad Request
  401,
  // Unauthorized
  403,
  // Forbidden
  404,
  // Not Found
  405,
  // Method Not Allowed
  406,
  // Not Acceptable
  409,
  // Conflict
  410,
  // Gone
  422
  // Unprocessable Entity
]);
class ErrorClassifier {
  /**
   * Classify an error as RETRIABLE or NON_RETRIABLE
   *
   * @param {Error} error - The error to classify
   * @param {Object} options - Classification options
   * @param {Array<string>} options.retryableErrors - Custom retriable error names/codes
   * @param {Array<string>} options.nonRetriableErrors - Custom non-retriable error names/codes
   * @returns {string} 'RETRIABLE' or 'NON_RETRIABLE'
   */
  static classify(error, options = {}) {
    if (!error) return NON_RETRIABLE;
    const {
      retryableErrors = [],
      nonRetriableErrors = []
    } = options;
    if (retryableErrors.length > 0) {
      const isCustomRetriable = retryableErrors.some(
        (errType) => error.code === errType || error.name === errType || error.message?.includes(errType)
      );
      if (isCustomRetriable) return RETRIABLE;
    }
    if (nonRetriableErrors.length > 0) {
      const isCustomNonRetriable = nonRetriableErrors.some(
        (errType) => error.code === errType || error.name === errType || error.message?.includes(errType)
      );
      if (isCustomNonRetriable) return NON_RETRIABLE;
    }
    if (error.retriable === false) return NON_RETRIABLE;
    if (error.retriable === true) return RETRIABLE;
    if (NON_RETRIABLE_ERROR_NAMES.has(error.name)) {
      return NON_RETRIABLE;
    }
    if (error.statusCode && NON_RETRIABLE_STATUS_CODES.has(error.statusCode)) {
      return NON_RETRIABLE;
    }
    if (error.code && RETRIABLE_NETWORK_CODES.has(error.code)) {
      return RETRIABLE;
    }
    if (error.code && RETRIABLE_AWS_CODES.has(error.code)) {
      return RETRIABLE;
    }
    if (error.code && RETRIABLE_AWS_CONFLICTS.has(error.code)) {
      return RETRIABLE;
    }
    if (error.statusCode && RETRIABLE_STATUS_CODES.has(error.statusCode)) {
      return RETRIABLE;
    }
    if (error.message && typeof error.message === "string") {
      const lowerMessage = error.message.toLowerCase();
      if (lowerMessage.includes("timeout") || lowerMessage.includes("timed out") || lowerMessage.includes("network") || lowerMessage.includes("connection")) {
        return RETRIABLE;
      }
    }
    return RETRIABLE;
  }
  /**
   * Check if an error is retriable
   *
   * @param {Error} error - The error to check
   * @param {Object} options - Classification options
   * @returns {boolean} true if retriable
   */
  static isRetriable(error, options = {}) {
    return this.classify(error, options) === RETRIABLE;
  }
  /**
   * Check if an error is non-retriable
   *
   * @param {Error} error - The error to check
   * @param {Object} options - Classification options
   * @returns {boolean} true if non-retriable
   */
  static isNonRetriable(error, options = {}) {
    return this.classify(error, options) === NON_RETRIABLE;
  }
}

class StateMachinePlugin extends Plugin {
  constructor(options = {}) {
    super();
    const resourceNamesOption = options.resourceNames || {};
    this._resourceDescriptors = {
      transitionLog: {
        defaultName: "plg_state_transitions",
        override: resourceNamesOption.transitionLog || options.transitionLogResource
      },
      states: {
        defaultName: "plg_entity_states",
        override: resourceNamesOption.states || options.stateResource
      }
    };
    this.resourceNames = this._resolveResourceNames();
    this.config = {
      stateMachines: options.stateMachines || {},
      actions: options.actions || {},
      guards: options.guards || {},
      persistTransitions: options.persistTransitions !== false,
      transitionLogResource: this.resourceNames.transitionLog,
      stateResource: this.resourceNames.states,
      retryAttempts: options.retryAttempts || 3,
      retryDelay: options.retryDelay || 100,
      verbose: options.verbose || false,
      // Distributed lock configuration (prevents concurrent transitions)
      workerId: options.workerId || "default",
      lockTimeout: options.lockTimeout || 1e3,
      // Wait up to 1s for lock
      lockTTL: options.lockTTL || 5,
      // Lock expires after 5s (prevent deadlock)
      // Global retry configuration for action execution
      retryConfig: options.retryConfig || null,
      // Trigger system configuration
      enableScheduler: options.enableScheduler || false,
      schedulerConfig: options.schedulerConfig || {},
      enableDateTriggers: options.enableDateTriggers !== false,
      enableFunctionTriggers: options.enableFunctionTriggers !== false,
      enableEventTriggers: options.enableEventTriggers !== false,
      triggerCheckInterval: options.triggerCheckInterval || 6e4
      // Check triggers every 60s by default
    };
    this.database = null;
    this.machines = /* @__PURE__ */ new Map();
    this.triggerIntervals = [];
    this.schedulerPlugin = null;
    this._pendingEventHandlers = /* @__PURE__ */ new Set();
    this._validateConfiguration();
  }
  _resolveResourceNames() {
    return resolveResourceNames("state_machine", this._resourceDescriptors, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    this.resourceNames = this._resolveResourceNames();
    if (this.config) {
      this.config.transitionLogResource = this.resourceNames.transitionLog;
      this.config.stateResource = this.resourceNames.states;
    }
  }
  /**
   * Wait for all pending event handlers to complete
   * Useful when working with async events (asyncEvents: true)
   * @param {number} timeout - Maximum time to wait in milliseconds (default: 5000)
   * @returns {Promise<void>}
   */
  async waitForPendingEvents(timeout = 5e3) {
    if (this._pendingEventHandlers.size === 0) {
      return;
    }
    const startTime = Date.now();
    while (this._pendingEventHandlers.size > 0) {
      if (Date.now() - startTime > timeout) {
        throw new StateMachineError(
          `Timeout waiting for ${this._pendingEventHandlers.size} pending event handlers`,
          {
            operation: "waitForPendingEvents",
            pendingCount: this._pendingEventHandlers.size,
            timeout
          }
        );
      }
      if (this._pendingEventHandlers.size > 0) {
        await Promise.race(Array.from(this._pendingEventHandlers));
      }
      await new Promise((resolve) => setImmediate(resolve));
    }
  }
  _validateConfiguration() {
    if (!this.config.stateMachines || Object.keys(this.config.stateMachines).length === 0) {
      throw new StateMachineError("At least one state machine must be defined", {
        operation: "validateConfiguration",
        machineCount: 0,
        suggestion: "Provide at least one state machine in the stateMachines configuration"
      });
    }
    for (const [machineName, machine] of Object.entries(this.config.stateMachines)) {
      if (!machine.states || Object.keys(machine.states).length === 0) {
        throw new StateMachineError(`Machine '${machineName}' must have states defined`, {
          operation: "validateConfiguration",
          machineId: machineName,
          suggestion: "Define at least one state in the states configuration"
        });
      }
      if (!machine.initialState) {
        throw new StateMachineError(`Machine '${machineName}' must have an initialState`, {
          operation: "validateConfiguration",
          machineId: machineName,
          availableStates: Object.keys(machine.states),
          suggestion: "Specify an initialState property matching one of the defined states"
        });
      }
      if (!machine.states[machine.initialState]) {
        throw new StateMachineError(`Initial state '${machine.initialState}' not found in machine '${machineName}'`, {
          operation: "validateConfiguration",
          machineId: machineName,
          initialState: machine.initialState,
          availableStates: Object.keys(machine.states),
          suggestion: "Set initialState to one of the defined states"
        });
      }
    }
  }
  async onInstall() {
    if (this.config.persistTransitions) {
      await this._createStateResources();
    }
    for (const [machineName, machineConfig] of Object.entries(this.config.stateMachines)) {
      this.machines.set(machineName, {
        config: machineConfig,
        currentStates: /* @__PURE__ */ new Map()
        // entityId -> currentState
      });
    }
    await this._attachStateMachinesToResources();
    await this._setupTriggers();
    this.emit("db:plugin:initialized", { machines: Array.from(this.machines.keys()) });
  }
  async _createStateResources() {
    const [logOk] = await tryFn(() => this.database.createResource({
      name: this.config.transitionLogResource,
      attributes: {
        id: "string|required",
        machineId: "string|required",
        entityId: "string|required",
        fromState: "string",
        toState: "string|required",
        event: "string|required",
        context: "json",
        timestamp: "number|required",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      partitions: {
        byMachine: { fields: { machineId: "string" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
    const [stateOk] = await tryFn(() => this.database.createResource({
      name: this.config.stateResource,
      attributes: {
        id: "string|required",
        machineId: "string|required",
        entityId: "string|required",
        currentState: "string|required",
        context: "json|default:{}",
        lastTransition: "string|default:null",
        triggerCounts: "json|default:{}",
        // Track trigger execution counts
        updatedAt: "string|required"
      },
      behavior: "body-overflow"
    }));
  }
  /**
   * Send an event to trigger a state transition
   */
  async send(machineId, entityId, event, context = {}) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "send",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    const lock = await this._acquireTransitionLock(machineId, entityId);
    try {
      const currentState = await this.getState(machineId, entityId);
      const stateConfig = machine.config.states[currentState];
      if (!stateConfig || !stateConfig.on || !stateConfig.on[event]) {
        throw new StateMachineError(`Event '${event}' not valid for state '${currentState}' in machine '${machineId}'`, {
          operation: "send",
          machineId,
          entityId,
          event,
          currentState,
          validEvents: stateConfig && stateConfig.on ? Object.keys(stateConfig.on) : [],
          suggestion: "Use getValidEvents() to check which events are valid for the current state"
        });
      }
      const targetState = stateConfig.on[event];
      if (stateConfig.guards && stateConfig.guards[event]) {
        const guardName = stateConfig.guards[event];
        const guard = this.config.guards[guardName];
        if (guard) {
          const [guardOk, guardErr, guardResult] = await tryFn(
            () => guard(context, event, { database: this.database, machineId, entityId })
          );
          if (!guardOk || !guardResult) {
            throw new StateMachineError(`Transition blocked by guard '${guardName}'`, {
              operation: "send",
              machineId,
              entityId,
              event,
              currentState,
              guardName,
              guardError: guardErr?.message || "Guard returned false",
              suggestion: "Check guard conditions or modify the context to satisfy guard requirements"
            });
          }
        }
      }
      if (stateConfig.exit) {
        await this._executeAction(stateConfig.exit, context, event, machineId, entityId);
      }
      await this._transition(machineId, entityId, currentState, targetState, event, context);
      const targetStateConfig = machine.config.states[targetState];
      if (targetStateConfig && targetStateConfig.entry) {
        await this._executeAction(targetStateConfig.entry, context, event, machineId, entityId);
      }
      this.emit("plg:state-machine:transition", {
        machineId,
        entityId,
        from: currentState,
        to: targetState,
        event,
        context
      });
      return {
        from: currentState,
        to: targetState,
        event,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      };
    } finally {
      await this._releaseTransitionLock(lock);
    }
  }
  async _executeAction(actionName, context, event, machineId, entityId) {
    const action = this.config.actions[actionName];
    if (!action) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Action '${actionName}' not found`);
      }
      return;
    }
    const machine = this.machines.get(machineId);
    const currentState = await this.getState(machineId, entityId);
    const stateConfig = machine?.config?.states?.[currentState];
    const retryConfig = {
      ...this.config.retryConfig || {},
      ...machine?.config?.retryConfig || {},
      ...stateConfig?.retryConfig || {}
    };
    const maxAttempts = retryConfig.maxAttempts ?? 0;
    const retryEnabled = maxAttempts > 0;
    let attempt = 0;
    while (attempt <= maxAttempts) {
      try {
        const result = await action(context, event, { database: this.database, machineId, entityId });
        if (attempt > 0) {
          this.emit("plg:state-machine:action-retry-success", {
            machineId,
            entityId,
            action: actionName,
            attempts: attempt + 1,
            state: currentState
          });
          if (this.config.verbose) {
            console.log(`[StateMachinePlugin] Action '${actionName}' succeeded after ${attempt + 1} attempts`);
          }
        }
        return result;
      } catch (error) {
        if (!retryEnabled) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed:`, error.message);
          }
          this.emit("plg:state-machine:action-error", { actionName, error: error.message, machineId, entityId });
          return;
        }
        const classification = ErrorClassifier.classify(error, {
          retryableErrors: retryConfig.retryableErrors,
          nonRetriableErrors: retryConfig.nonRetriableErrors
        });
        if (classification === "NON_RETRIABLE") {
          this.emit("plg:state-machine:action-error-non-retriable", {
            machineId,
            entityId,
            action: actionName,
            error: error.message,
            state: currentState
          });
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed with non-retriable error:`, error.message);
          }
          throw error;
        }
        if (attempt >= maxAttempts) {
          this.emit("plg:state-machine:action-retry-exhausted", {
            machineId,
            entityId,
            action: actionName,
            attempts: attempt + 1,
            error: error.message,
            state: currentState
          });
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed after ${attempt + 1} attempts:`, error.message);
          }
          throw error;
        }
        attempt++;
        const delay = this._calculateBackoff(attempt, retryConfig);
        if (retryConfig.onRetry) {
          try {
            await retryConfig.onRetry(attempt, error, context);
          } catch (hookError) {
            if (this.config.verbose) {
              console.warn(`[StateMachinePlugin] onRetry hook failed:`, hookError.message);
            }
          }
        }
        this.emit("plg:state-machine:action-retry-attempt", {
          machineId,
          entityId,
          action: actionName,
          attempt,
          delay,
          error: error.message,
          state: currentState
        });
        if (this.config.verbose) {
          console.warn(`[StateMachinePlugin] Action '${actionName}' failed (attempt ${attempt + 1}/${maxAttempts + 1}), retrying in ${delay}ms:`, error.message);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }
  async _transition(machineId, entityId, fromState, toState, event, context) {
    const timestamp = Date.now();
    const now = (/* @__PURE__ */ new Date()).toISOString();
    const machine = this.machines.get(machineId);
    machine.currentStates.set(entityId, toState);
    if (this.config.persistTransitions) {
      const transitionId = `${machineId}_${entityId}_${timestamp}`;
      let logOk = false;
      let lastLogErr;
      for (let attempt = 0; attempt < this.config.retryAttempts; attempt++) {
        const [ok, err] = await tryFn(
          () => this.database.resources[this.config.transitionLogResource].insert({
            id: transitionId,
            machineId,
            entityId,
            fromState,
            toState,
            event,
            context,
            timestamp,
            createdAt: now.slice(0, 10)
            // YYYY-MM-DD for partitioning
          })
        );
        if (ok) {
          logOk = true;
          break;
        }
        lastLogErr = err;
        if (attempt < this.config.retryAttempts - 1) {
          const delay = this.config.retryDelay * Math.pow(2, attempt);
          await new Promise((resolve) => setTimeout(resolve, delay));
        }
      }
      if (!logOk && this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to log transition after ${this.config.retryAttempts} attempts:`, lastLogErr.message);
      }
      const stateId = `${machineId}_${entityId}`;
      const stateData = {
        machineId,
        entityId,
        currentState: toState,
        context,
        lastTransition: transitionId,
        updatedAt: now
      };
      const [updateOk] = await tryFn(
        () => this.database.resources[this.config.stateResource].update(stateId, stateData)
      );
      if (!updateOk) {
        const [insertOk, insertErr] = await tryFn(
          () => this.database.resources[this.config.stateResource].insert({ id: stateId, ...stateData })
        );
        if (!insertOk && this.config.verbose) {
          console.warn(`[StateMachinePlugin] Failed to upsert state:`, insertErr.message);
        }
      }
    }
  }
  /**
   * Acquire distributed lock for transition
   * Prevents concurrent transitions for the same entity
   * @private
   */
  async _acquireTransitionLock(machineId, entityId) {
    const storage = this.getStorage();
    const lockName = `transition-${machineId}-${entityId}`;
    const lock = await storage.acquireLock(lockName, {
      ttl: this.config.lockTTL,
      timeout: this.config.lockTimeout,
      workerId: this.config.workerId
    });
    if (!lock) {
      throw new StateMachineError("Could not acquire transition lock - concurrent transition in progress", {
        operation: "send",
        machineId,
        entityId,
        lockTimeout: this.config.lockTimeout,
        workerId: this.config.workerId,
        suggestion: "Wait for current transition to complete or increase lockTimeout"
      });
    }
    return lock;
  }
  /**
   * Release distributed lock for transition
   * @private
   */
  async _releaseTransitionLock(lock) {
    if (!lock) return;
    const storage = this.getStorage();
    const [ok, err] = await tryFn(() => storage.releaseLock(lock));
    if (!ok && this.config.verbose) {
      console.warn(`[StateMachinePlugin] Failed to release lock '${lock?.name}':`, err.message);
    }
  }
  /**
   * Calculate backoff delay for retry attempts
   * @private
   */
  _calculateBackoff(attempt, retryConfig) {
    const {
      backoffStrategy = "exponential",
      baseDelay = 1e3,
      maxDelay = 3e4
    } = retryConfig || {};
    let delay;
    if (backoffStrategy === "exponential") {
      delay = Math.min(baseDelay * Math.pow(2, attempt - 1), maxDelay);
    } else if (backoffStrategy === "linear") {
      delay = Math.min(baseDelay * attempt, maxDelay);
    } else {
      delay = baseDelay;
    }
    const jitter = delay * 0.2 * (Math.random() - 0.5);
    return Math.round(delay + jitter);
  }
  /**
   * Get current state for an entity
   */
  async getState(machineId, entityId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "getState",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    if (machine.currentStates.has(entityId)) {
      return machine.currentStates.get(entityId);
    }
    if (this.config.persistTransitions) {
      const stateId = `${machineId}_${entityId}`;
      const [ok, err, stateRecord] = await tryFn(
        () => this.database.resources[this.config.stateResource].get(stateId)
      );
      if (ok && stateRecord) {
        machine.currentStates.set(entityId, stateRecord.currentState);
        return stateRecord.currentState;
      }
    }
    const initialState = machine.config.initialState;
    machine.currentStates.set(entityId, initialState);
    return initialState;
  }
  /**
   * Get valid events for current state
   * Can accept either a state name (sync) or entityId (async to fetch latest state)
   */
  async getValidEvents(machineId, stateOrEntityId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "getValidEvents",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    let state;
    if (machine.config.states[stateOrEntityId]) {
      state = stateOrEntityId;
    } else {
      state = await this.getState(machineId, stateOrEntityId);
    }
    const stateConfig = machine.config.states[state];
    return stateConfig && stateConfig.on ? Object.keys(stateConfig.on) : [];
  }
  /**
   * Get transition history for an entity
   */
  async getTransitionHistory(machineId, entityId, options = {}) {
    if (!this.config.persistTransitions) {
      return [];
    }
    const { limit = 50, offset = 0 } = options;
    const [ok, err, transitions] = await tryFn(
      () => this.database.resources[this.config.transitionLogResource].query({
        machineId,
        entityId
      }, {
        limit,
        offset
      })
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to get transition history:`, err.message);
      }
      return [];
    }
    const sorted = (transitions || []).sort((a, b) => b.timestamp - a.timestamp);
    return sorted.map((t) => ({
      from: t.fromState,
      to: t.toState,
      event: t.event,
      context: t.context,
      timestamp: new Date(t.timestamp).toISOString()
    }));
  }
  /**
   * Initialize entity state (useful for new entities)
   */
  async initializeEntity(machineId, entityId, context = {}) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "initializeEntity",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    const initialState = machine.config.initialState;
    machine.currentStates.set(entityId, initialState);
    if (this.config.persistTransitions) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      const stateId = `${machineId}_${entityId}`;
      const [ok, err] = await tryFn(
        () => this.database.resources[this.config.stateResource].insert({
          id: stateId,
          machineId,
          entityId,
          currentState: initialState,
          context,
          lastTransition: null,
          updatedAt: now
        })
      );
      if (!ok && err && !err.message?.includes("already exists")) {
        throw new StateMachineError("Failed to initialize entity state", {
          operation: "initializeEntity",
          machineId,
          entityId,
          initialState,
          original: err,
          suggestion: "Check state resource configuration and database permissions"
        });
      }
    }
    const initialStateConfig = machine.config.states[initialState];
    if (initialStateConfig && initialStateConfig.entry) {
      await this._executeAction(initialStateConfig.entry, context, "INIT", machineId, entityId);
    }
    this.emit("plg:state-machine:entity-initialized", { machineId, entityId, initialState });
    return initialState;
  }
  /**
   * Get machine definition
   */
  getMachineDefinition(machineId) {
    const machine = this.machines.get(machineId);
    return machine ? machine.config : null;
  }
  /**
   * Get all available machines
   */
  getMachines() {
    return Array.from(this.machines.keys());
  }
  /**
   * Visualize state machine (returns DOT format for graphviz)
   */
  visualize(machineId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "visualize",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    let dot = `digraph ${machineId} {
`;
    dot += `  rankdir=LR;
`;
    dot += `  node [shape=circle];
`;
    for (const [stateName, stateConfig] of Object.entries(machine.config.states)) {
      const shape = stateConfig.type === "final" ? "doublecircle" : "circle";
      const color = stateConfig.meta?.color || "lightblue";
      dot += `  ${stateName} [shape=${shape}, fillcolor=${color}, style=filled];
`;
    }
    for (const [stateName, stateConfig] of Object.entries(machine.config.states)) {
      if (stateConfig.on) {
        for (const [event, targetState] of Object.entries(stateConfig.on)) {
          dot += `  ${stateName} -> ${targetState} [label="${event}"];
`;
        }
      }
    }
    dot += `  start [shape=point];
`;
    dot += `  start -> ${machine.config.initialState};
`;
    dot += `}
`;
    return dot;
  }
  /**
   * Get all entities currently in a specific state
   * @private
   */
  async _getEntitiesInState(machineId, stateName) {
    if (!this.config.persistTransitions) {
      const machine = this.machines.get(machineId);
      if (!machine) return [];
      const entities = [];
      for (const [entityId, currentState] of machine.currentStates) {
        if (currentState === stateName) {
          entities.push({ entityId, currentState, context: {}, triggerCounts: {} });
        }
      }
      return entities;
    }
    const [ok, err, records] = await tryFn(
      () => this.database.resources[this.config.stateResource].query({
        machineId,
        currentState: stateName
      })
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to query entities in state '${stateName}':`, err.message);
      }
      return [];
    }
    return records || [];
  }
  /**
   * Increment trigger execution count for an entity
   * @private
   */
  async _incrementTriggerCount(machineId, entityId, triggerName) {
    if (!this.config.persistTransitions) {
      return;
    }
    const stateId = `${machineId}_${entityId}`;
    const [ok, err, stateRecord] = await tryFn(
      () => this.database.resources[this.config.stateResource].get(stateId)
    );
    if (ok && stateRecord) {
      const triggerCounts = stateRecord.triggerCounts || {};
      triggerCounts[triggerName] = (triggerCounts[triggerName] || 0) + 1;
      await tryFn(
        () => this.database.resources[this.config.stateResource].patch(stateId, { triggerCounts })
      );
    }
  }
  /**
   * Setup trigger system for all state machines
   * @private
   */
  async _setupTriggers() {
    if (!this.config.enableScheduler && !this.config.enableDateTriggers && !this.config.enableFunctionTriggers && !this.config.enableEventTriggers) {
      return;
    }
    const cronJobs = {};
    for (const [machineId, machineData] of this.machines) {
      const machineConfig = machineData.config;
      for (const [stateName, stateConfig] of Object.entries(machineConfig.states)) {
        const triggers = stateConfig.triggers || [];
        for (let i = 0; i < triggers.length; i++) {
          const trigger = triggers[i];
          const triggerName = `${trigger.action}_${i}`;
          if (trigger.type === "cron" && this.config.enableScheduler) {
            const jobName = `${machineId}_${stateName}_${triggerName}`;
            cronJobs[jobName] = await this._createCronJob(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "date" && this.config.enableDateTriggers) {
            await this._setupDateTrigger(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "function" && this.config.enableFunctionTriggers) {
            await this._setupFunctionTrigger(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "event" && this.config.enableEventTriggers) {
            await this._setupEventTrigger(machineId, stateName, trigger, triggerName);
          }
        }
      }
    }
    if (Object.keys(cronJobs).length > 0 && this.config.enableScheduler) {
      const { SchedulerPlugin } = await Promise.resolve().then(function () { return scheduler_plugin; });
      this.schedulerPlugin = new SchedulerPlugin({
        jobs: cronJobs,
        persistJobs: false,
        // Don't persist trigger jobs
        verbose: this.config.verbose,
        ...this.config.schedulerConfig
      });
      await this.database.usePlugin(this.schedulerPlugin);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Installed SchedulerPlugin with ${Object.keys(cronJobs).length} cron triggers`);
      }
    }
  }
  /**
   * Create a SchedulerPlugin job for a cron trigger
   * @private
   */
  async _createCronJob(machineId, stateName, trigger, triggerName) {
    return {
      schedule: trigger.schedule,
      description: `Trigger '${triggerName}' for ${machineId}.${stateName}`,
      action: async (database, context) => {
        const entities = await this._getEntitiesInState(machineId, stateName);
        let executedCount = 0;
        for (const entity of entities) {
          try {
            if (trigger.condition) {
              const shouldTrigger = await trigger.condition(entity.context, entity.entityId);
              if (!shouldTrigger) continue;
            }
            if (trigger.maxTriggers !== void 0) {
              const triggerCount = entity.triggerCounts?.[triggerName] || 0;
              if (triggerCount >= trigger.maxTriggers) {
                if (trigger.onMaxTriggersReached) {
                  await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
                }
                continue;
              }
            }
            const result = await this._executeAction(
              trigger.action,
              entity.context,
              "TRIGGER",
              machineId,
              entity.entityId
            );
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            executedCount++;
            if (trigger.eventOnSuccess) {
              await this.send(machineId, entity.entityId, trigger.eventOnSuccess, {
                ...entity.context,
                triggerResult: result
              });
            } else if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "cron"
            });
          } catch (error) {
            if (trigger.event) {
              await tryFn(() => this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerError: error.message
              }));
            }
            if (this.config.verbose) {
              console.error(`[StateMachinePlugin] Trigger '${triggerName}' failed for entity ${entity.entityId}:`, error.message);
            }
          }
        }
        return { processed: entities.length, executed: executedCount };
      }
    };
  }
  /**
   * Setup a date-based trigger
   * @private
   */
  async _setupDateTrigger(machineId, stateName, trigger, triggerName) {
    const checkInterval = setInterval(async () => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          const triggerDateValue = entity.context?.[trigger.field];
          if (!triggerDateValue) continue;
          const triggerDate = new Date(triggerDateValue);
          const now = /* @__PURE__ */ new Date();
          if (now >= triggerDate) {
            if (trigger.maxTriggers !== void 0) {
              const triggerCount = entity.triggerCounts?.[triggerName] || 0;
              if (triggerCount >= trigger.maxTriggers) {
                if (trigger.onMaxTriggersReached) {
                  await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
                }
                continue;
              }
            }
            const result = await this._executeAction(trigger.action, entity.context, "TRIGGER", machineId, entity.entityId);
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "date"
            });
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Date trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    }, this.config.triggerCheckInterval);
    this.triggerIntervals.push(checkInterval);
  }
  /**
   * Setup a function-based trigger
   * @private
   */
  async _setupFunctionTrigger(machineId, stateName, trigger, triggerName) {
    const interval = trigger.interval || this.config.triggerCheckInterval;
    const checkInterval = setInterval(async () => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          if (trigger.maxTriggers !== void 0) {
            const triggerCount = entity.triggerCounts?.[triggerName] || 0;
            if (triggerCount >= trigger.maxTriggers) {
              if (trigger.onMaxTriggersReached) {
                await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
              }
              continue;
            }
          }
          const shouldTrigger = await trigger.condition(entity.context, entity.entityId);
          if (shouldTrigger) {
            const result = await this._executeAction(trigger.action, entity.context, "TRIGGER", machineId, entity.entityId);
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "function"
            });
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Function trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    }, interval);
    this.triggerIntervals.push(checkInterval);
  }
  /**
   * Setup an event-based trigger
   * Supports both old API (trigger.event) and new API (trigger.eventName + eventSource)
   * @private
   */
  async _setupEventTrigger(machineId, stateName, trigger, triggerName) {
    const baseEventName = trigger.eventName || trigger.event;
    const eventSource = trigger.eventSource;
    if (!baseEventName) {
      throw new StateMachineError(`Event trigger '${triggerName}' must have either 'event' or 'eventName' property`, {
        operation: "_setupEventTrigger",
        machineId,
        stateName,
        triggerName
      });
    }
    const eventHandler = async (eventData) => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          let resolvedEventName;
          if (typeof baseEventName === "function") {
            resolvedEventName = baseEventName(entity.context);
          } else {
            resolvedEventName = baseEventName;
          }
          if (eventSource && typeof baseEventName === "function") {
            const eventIdMatch = eventData?.id || eventData?.entityId;
            if (eventIdMatch && entity.entityId !== eventIdMatch) {
              continue;
            }
          }
          if (trigger.condition) {
            const shouldTrigger = await trigger.condition(entity.context, entity.entityId, eventData);
            if (!shouldTrigger) continue;
          }
          if (trigger.maxTriggers !== void 0) {
            const triggerCount = entity.triggerCounts?.[triggerName] || 0;
            if (triggerCount >= trigger.maxTriggers) {
              if (trigger.onMaxTriggersReached) {
                await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
              }
              continue;
            }
          }
          if (trigger.targetState) {
            await this._transition(
              machineId,
              entity.entityId,
              stateName,
              trigger.targetState,
              "TRIGGER",
              { ...entity.context, eventData, triggerName }
            );
            const machine = this.machines.get(machineId);
            const resourceConfig = machine.config;
            if (resourceConfig.resource && resourceConfig.stateField) {
              let resource;
              if (typeof resourceConfig.resource === "string") {
                resource = await this.database.getResource(resourceConfig.resource);
              } else {
                resource = resourceConfig.resource;
              }
              if (resource) {
                const [ok] = await tryFn(
                  () => resource.patch(entity.entityId, { [resourceConfig.stateField]: trigger.targetState })
                );
                if (!ok && this.config.verbose) {
                  console.warn(`[StateMachinePlugin] Failed to update resource stateField for entity ${entity.entityId}`);
                }
              }
            }
            const targetStateConfig = machine.config.states[trigger.targetState];
            if (targetStateConfig?.entry) {
              await this._executeAction(
                targetStateConfig.entry,
                { ...entity.context, eventData },
                "TRIGGER",
                machineId,
                entity.entityId
              );
            }
            this.emit("plg:state-machine:transition", {
              machineId,
              entityId: entity.entityId,
              from: stateName,
              to: trigger.targetState,
              event: "TRIGGER",
              context: { ...entity.context, eventData, triggerName }
            });
          } else if (trigger.action) {
            const result = await this._executeAction(
              trigger.action,
              { ...entity.context, eventData },
              "TRIGGER",
              machineId,
              entity.entityId
            );
            if (trigger.sendEvent) {
              await this.send(machineId, entity.entityId, trigger.sendEvent, {
                ...entity.context,
                triggerResult: result,
                eventData
              });
            }
          }
          await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
          this.emit("plg:state-machine:trigger-executed", {
            machineId,
            entityId: entity.entityId,
            state: stateName,
            trigger: triggerName,
            type: "event",
            eventName: resolvedEventName,
            targetState: trigger.targetState
          });
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Event trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    };
    if (eventSource) {
      const baseEvent = typeof baseEventName === "function" ? "updated" : baseEventName;
      const wrappedHandler = async (...args) => {
        const handlerPromise = eventHandler(...args);
        if (!this._pendingEventHandlers) {
          this._pendingEventHandlers = /* @__PURE__ */ new Set();
        }
        this._pendingEventHandlers.add(handlerPromise);
        try {
          await handlerPromise;
        } finally {
          this._pendingEventHandlers.delete(handlerPromise);
        }
      };
      eventSource.on(baseEvent, wrappedHandler);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Listening to resource event '${baseEvent}' from '${eventSource.name}' for trigger '${triggerName}' (async-safe)`);
      }
    } else {
      const staticEventName = typeof baseEventName === "function" ? "updated" : baseEventName;
      if (staticEventName.startsWith("db:")) {
        const dbEventName = staticEventName.substring(3);
        this.database.on(dbEventName, eventHandler);
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Listening to database event '${dbEventName}' for trigger '${triggerName}'`);
        }
      } else {
        this.on(staticEventName, eventHandler);
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Listening to plugin event '${staticEventName}' for trigger '${triggerName}'`);
        }
      }
    }
  }
  /**
   * Attach state machine instances to their associated resources
   * This enables the resource API: resource.state(id, event)
   * @private
   */
  async _attachStateMachinesToResources() {
    for (const [machineName, machineConfig] of Object.entries(this.config.stateMachines)) {
      const resourceConfig = machineConfig.config || machineConfig;
      if (!resourceConfig.resource) {
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Machine '${machineName}' has no resource configured, skipping attachment`);
        }
        continue;
      }
      let resource;
      if (typeof resourceConfig.resource === "string") {
        resource = this.database.resources[resourceConfig.resource];
        if (!resource) {
          console.warn(
            `[StateMachinePlugin] Resource '${resourceConfig.resource}' not found for machine '${machineName}'. Resource API will not be available.`
          );
          continue;
        }
      } else {
        resource = resourceConfig.resource;
      }
      const machineProxy = {
        send: async (id, event, eventData) => {
          return this.send(machineName, id, event, eventData);
        },
        getState: async (id) => {
          return this.getState(machineName, id);
        },
        canTransition: async (id, event) => {
          return this.canTransition(machineName, id, event);
        },
        getValidEvents: async (id) => {
          return this.getValidEvents(machineName, id);
        },
        initializeEntity: async (id, context) => {
          return this.initializeEntity(machineName, id, context);
        },
        getTransitionHistory: async (id, options) => {
          return this.getTransitionHistory(machineName, id, options);
        }
      };
      resource._attachStateMachine(machineProxy);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Attached machine '${machineName}' to resource '${resource.name}'`);
      }
    }
  }
  async start() {
    if (this.config.verbose) {
      console.log(`[StateMachinePlugin] Started with ${this.machines.size} state machines`);
    }
  }
  async stop() {
    for (const interval of this.triggerIntervals) {
      clearInterval(interval);
    }
    this.triggerIntervals = [];
    if (this.schedulerPlugin) {
      await this.schedulerPlugin.stop();
      this.schedulerPlugin = null;
    }
    this.machines.clear();
    this.removeAllListeners();
  }
}

class TfStateError extends PluginError {
  constructor(message, context = {}) {
    const merged = {
      pluginName: context.pluginName || "TfStatePlugin",
      operation: context.operation || "unknown",
      statusCode: context.statusCode ?? 500,
      retriable: context.retriable ?? false,
      suggestion: context.suggestion ?? "Verify Terraform/OpenTofu configuration and state storage before retrying.",
      ...context
    };
    super(message, merged);
    this.name = "TfStateError";
  }
}
class InvalidStateFileError extends TfStateError {
  constructor(filePath, reason, context = {}) {
    super(`Invalid Tfstate file "${filePath}": ${reason}`, {
      statusCode: context.statusCode ?? 422,
      retriable: false,
      suggestion: context.suggestion ?? "Validate Terraform state integrity or re-run terraform state pull.",
      filePath,
      reason,
      ...context
    });
    this.name = "InvalidStateFileError";
    this.filePath = filePath;
    this.reason = reason;
  }
}
class UnsupportedStateVersionError extends TfStateError {
  constructor(version, supportedVersions, context = {}) {
    super(
      `Tfstate version ${version} is not supported. Supported versions: ${supportedVersions.join(", ")}`,
      {
        statusCode: context.statusCode ?? 400,
        retriable: false,
        suggestion: context.suggestion ?? `Upgrade/downgrade Terraform state to one of the supported versions: ${supportedVersions.join(", ")}.`,
        version,
        supportedVersions,
        ...context
      }
    );
    this.name = "UnsupportedStateVersionError";
    this.version = version;
    this.supportedVersions = supportedVersions;
  }
}
class StateFileNotFoundError extends TfStateError {
  constructor(filePath, context = {}) {
    super(`Tfstate file not found: ${filePath}`, {
      statusCode: context.statusCode ?? 404,
      retriable: false,
      suggestion: context.suggestion ?? "Ensure the state file exists at the configured path/bucket.",
      filePath,
      ...context
    });
    this.name = "StateFileNotFoundError";
    this.filePath = filePath;
  }
}
class ResourceExtractionError extends TfStateError {
  constructor(resourceAddress, originalError, context = {}) {
    super(
      `Failed to extract resource "${resourceAddress}": ${originalError.message}`,
      {
        retriable: context.retriable ?? false,
        suggestion: context.suggestion ?? "Check resource address and state structure; rerun extraction after fixing the state.",
        resourceAddress,
        originalError,
        ...context
      }
    );
    this.name = "ResourceExtractionError";
    this.resourceAddress = resourceAddress;
    this.originalError = originalError;
  }
}
class StateDiffError extends TfStateError {
  constructor(oldSerial, newSerial, originalError, context = {}) {
    super(
      `Failed to calculate diff between state serials ${oldSerial} and ${newSerial}: ${originalError.message}`,
      {
        retriable: context.retriable ?? true,
        suggestion: context.suggestion ?? "Refresh the latest state snapshots and retry the diff operation.",
        oldSerial,
        newSerial,
        originalError,
        ...context
      }
    );
    this.name = "StateDiffError";
    this.oldSerial = oldSerial;
    this.newSerial = newSerial;
    this.originalError = originalError;
  }
}
class FileWatchError extends TfStateError {
  constructor(path, originalError, context = {}) {
    super(`Failed to watch path "${path}": ${originalError.message}`, {
      retriable: context.retriable ?? true,
      suggestion: context.suggestion ?? "Verify filesystem permissions and that the watch path exists.",
      path,
      originalError,
      ...context
    });
    this.name = "FileWatchError";
    this.path = path;
    this.originalError = originalError;
  }
}

class TfStateDriver {
  constructor(config = {}) {
    this.config = config;
    this.selector = config.selector || "**/*.tfstate";
  }
  /**
   * Initialize the driver
   * Called during plugin installation
   */
  async initialize() {
    throw new TfStateError("Driver must implement initialize()", {
      operation: "initialize",
      statusCode: 501,
      retriable: false,
      suggestion: "Extend TfStateDriver and implement initialize() to configure backend connections."
    });
  }
  /**
   * List all state files matching the selector
   * @returns {Promise<Array>} Array of state file metadata { path, lastModified, size }
   */
  async listStateFiles() {
    throw new TfStateError("Driver must implement listStateFiles()", {
      operation: "listStateFiles",
      statusCode: 501,
      retriable: false,
      suggestion: "Override listStateFiles() to return available Terraform state metadata."
    });
  }
  /**
   * Read a state file content
   * @param {string} path - Path to the state file
   * @returns {Promise<Object>} Parsed state file content
   */
  async readStateFile(path) {
    throw new TfStateError("Driver must implement readStateFile()", {
      operation: "readStateFile",
      statusCode: 501,
      retriable: false,
      suggestion: "Override readStateFile(path) to load and parse the Terraform state JSON.",
      path
    });
  }
  /**
   * Get state file metadata
   * @param {string} path - Path to the state file
   * @returns {Promise<Object>} Metadata { path, lastModified, size, etag }
   */
  async getStateFileMetadata(path) {
    throw new TfStateError("Driver must implement getStateFileMetadata()", {
      operation: "getStateFileMetadata",
      statusCode: 501,
      retriable: false,
      suggestion: "Override getStateFileMetadata(path) to return lastModified, size, and ETag information.",
      path
    });
  }
  /**
   * Check if a state file has been modified since last check
   * @param {string} path - Path to the state file
   * @param {Date} since - Check modifications since this date
   * @returns {Promise<boolean>} True if modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    return new Date(metadata.lastModified) > new Date(since);
  }
  /**
   * Match a path against the selector pattern
   * @param {string} path - Path to check
   * @returns {boolean} True if matches
   */
  matchesSelector(path) {
    const pattern = this.selector.replace(/\*\*/g, "__DOUBLE_STAR__").replace(/\*/g, "[^/]*").replace(/__DOUBLE_STAR__/g, ".*").replace(/\?/g, ".").replace(/\[([^\]]+)\]/g, "[$1]");
    const regex = new RegExp(`^${pattern}$`);
    return regex.test(path);
  }
  /**
   * Close/cleanup driver resources
   */
  async close() {
  }
}

class S3TfStateDriver extends TfStateDriver {
  constructor(config = {}) {
    super(config);
    if (config.connectionString) {
      this.connectionConfig = this._parseConnectionString(config.connectionString);
    } else {
      this.connectionConfig = {
        bucket: config.bucket,
        prefix: config.prefix || "",
        credentials: config.credentials,
        region: config.region
      };
    }
    this.client = null;
  }
  /**
   * Parse S3 connection string
   * Format: s3://accessKey:secretKey@bucket/prefix
   * @private
   */
  _parseConnectionString(connectionString) {
    try {
      const url = new URL(connectionString);
      if (url.protocol !== "s3:") {
        throw new TfStateError("Connection string must use s3:// protocol", {
          operation: "parseConnectionString",
          statusCode: 400,
          retriable: false,
          suggestion: "Use format s3://accessKey:secretKey@bucket/prefix?region=us-east-1",
          connectionString
        });
      }
      const credentials = {};
      if (url.username) {
        credentials.accessKeyId = decodeURIComponent(url.username);
      }
      if (url.password) {
        credentials.secretAccessKey = decodeURIComponent(url.password);
      }
      const bucket = url.hostname;
      const prefix = url.pathname ? url.pathname.substring(1) : "";
      const region = url.searchParams.get("region") || "us-east-1";
      return {
        bucket,
        prefix,
        credentials: Object.keys(credentials).length > 0 ? credentials : void 0,
        region
      };
    } catch (error) {
      throw new TfStateError("Invalid S3 connection string", {
        operation: "parseConnectionString",
        statusCode: 400,
        retriable: false,
        suggestion: "Ensure the connection string follows s3://accessKey:secretKey@bucket/prefix?region=REGION.",
        connectionString,
        original: error
      });
    }
  }
  /**
   * Initialize S3 client
   */
  async initialize() {
    const { bucket, credentials, region } = this.connectionConfig;
    this.client = new S3Client({
      bucketName: bucket,
      credentials,
      region
    });
    await this.client.connect();
  }
  /**
   * List all state files in S3 matching the selector
   */
  async listStateFiles() {
    const { bucket, prefix } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.listObjectsV2({
        Bucket: bucket,
        Prefix: prefix
      });
    });
    if (!ok) {
      throw new TfStateError("Failed to list Terraform state objects from S3", {
        operation: "listStateFiles",
        retriable: false,
        suggestion: "Validate S3 permissions (s3:ListBucket) and prefix configuration.",
        bucket,
        prefix,
        original: err
      });
    }
    const objects = data.Contents || [];
    const stateFiles = objects.filter((obj) => {
      const relativePath = obj.Key.startsWith(prefix) ? obj.Key.substring(prefix.length) : obj.Key;
      return this.matchesSelector(relativePath) && relativePath.endsWith(".tfstate");
    }).map((obj) => ({
      path: obj.Key,
      lastModified: obj.LastModified,
      size: obj.Size,
      etag: obj.ETag
    }));
    return stateFiles;
  }
  /**
   * Read a state file from S3
   */
  async readStateFile(path) {
    const { bucket } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.getObject({
        Bucket: bucket,
        Key: path
      });
    });
    if (!ok) {
      if (err?.$metadata?.httpStatusCode === 404) {
        throw new StateFileNotFoundError(path, {
          operation: "readStateFile",
          retriable: false,
          suggestion: "Ensure the state file exists in S3 and the IAM role can access it.",
          bucket,
          original: err
        });
      }
      throw new TfStateError(`Failed to read state file ${path}`, {
        operation: "readStateFile",
        retriable: false,
        suggestion: "Verify S3 permissions (s3:GetObject) and network connectivity.",
        bucket,
        path,
        original: err
      });
    }
    try {
      const content = data.Body.toString("utf-8");
      return JSON.parse(content);
    } catch (parseError) {
      throw new InvalidStateFileError(path, parseError.message, {
        operation: "readStateFile",
        retriable: false,
        suggestion: "Check if the state file contains valid JSON exported by Terraform.",
        original: parseError
      });
    }
  }
  /**
   * Get state file metadata from S3
   */
  async getStateFileMetadata(path) {
    const { bucket } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.headObject({
        Bucket: bucket,
        Key: path
      });
    });
    if (!ok) {
      if (err?.$metadata?.httpStatusCode === 404) {
        throw new StateFileNotFoundError(path, {
          operation: "getStateFileMetadata",
          retriable: false,
          suggestion: "Ensure the state file exists in S3 and the IAM role can access it.",
          bucket,
          original: err
        });
      }
      throw new TfStateError(`Failed to get metadata for ${path}`, {
        operation: "getStateFileMetadata",
        retriable: false,
        suggestion: "Verify S3 permissions (s3:HeadObject) and bucket configuration.",
        bucket,
        path,
        original: err
      });
    }
    return {
      path,
      lastModified: data.LastModified,
      size: data.ContentLength,
      etag: data.ETag
    };
  }
  /**
   * Check if state file has been modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    const lastModified = new Date(metadata.lastModified);
    const sinceDate = new Date(since);
    return lastModified > sinceDate;
  }
  /**
   * Close S3 client
   */
  async close() {
    if (this.client) {
      await this.client.disconnect();
      this.client = null;
    }
  }
}

class FilesystemTfStateDriver extends TfStateDriver {
  constructor(config = {}) {
    super(config);
    this.basePath = config.basePath || config.path || process.cwd();
  }
  /**
   * Initialize filesystem driver
   */
  async initialize() {
    try {
      const stats = await stat(this.basePath);
      if (!stats.isDirectory()) {
        throw new TfStateError(`Base path is not a directory: ${this.basePath}`, {
          operation: "initialize",
          statusCode: 400,
          retriable: false,
          suggestion: "Update the TfState filesystem driver configuration to point to a directory containing .tfstate files.",
          basePath: this.basePath
        });
      }
    } catch (error) {
      throw new TfStateError(`Invalid base path: ${this.basePath}`, {
        operation: "initialize",
        statusCode: 400,
        retriable: false,
        suggestion: "Ensure the basePath exists and is readable by the current process.",
        basePath: this.basePath,
        original: error
      });
    }
  }
  /**
   * List all state files matching the selector
   */
  async listStateFiles() {
    const pattern = join(this.basePath, this.selector);
    try {
      const files = await glob(pattern, {
        nodir: true,
        absolute: false,
        cwd: this.basePath
      });
      const stateFiles = await Promise.all(
        files.map(async (file) => {
          const fullPath = join(this.basePath, file);
          const stats = await stat(fullPath);
          return {
            path: file,
            fullPath,
            lastModified: stats.mtime,
            size: stats.size,
            etag: `${stats.mtime.getTime()}-${stats.size}`
            // Pseudo-etag
          };
        })
      );
      return stateFiles;
    } catch (error) {
      throw new TfStateError("Failed to list Terraform state files", {
        operation: "listStateFiles",
        statusCode: 500,
        retriable: false,
        suggestion: "Verify filesystem permissions and glob selector pattern.",
        selector: this.selector,
        basePath: this.basePath,
        original: error
      });
    }
  }
  /**
   * Read a state file from filesystem
   */
  async readStateFile(path) {
    const fullPath = path.startsWith(this.basePath) ? path : join(this.basePath, path);
    try {
      const content = await readFile(fullPath, "utf-8");
      return JSON.parse(content);
    } catch (error) {
      if (error.code === "ENOENT") {
        throw new StateFileNotFoundError(path, {
          operation: "readStateFile",
          retriable: false,
          suggestion: "Ensure the Terraform state file exists at the specified path.",
          original: error
        });
      }
      throw new TfStateError(`Failed to read state file ${path}`, {
        operation: "readStateFile",
        retriable: false,
        suggestion: "Validate file permissions and state file contents (must be valid JSON).",
        path,
        original: error
      });
    }
  }
  /**
   * Get state file metadata from filesystem
   */
  async getStateFileMetadata(path) {
    const fullPath = path.startsWith(this.basePath) ? path : join(this.basePath, path);
    try {
      const stats = await stat(fullPath);
      return {
        path,
        fullPath,
        lastModified: stats.mtime,
        size: stats.size,
        etag: `${stats.mtime.getTime()}-${stats.size}`
      };
    } catch (error) {
      if (error.code === "ENOENT") {
        throw new StateFileNotFoundError(path, {
          operation: "getStateFileMetadata",
          retriable: false,
          suggestion: "Ensure the Terraform state file exists at the specified path.",
          original: error
        });
      }
      throw new TfStateError(`Failed to get metadata for ${path}`, {
        operation: "getStateFileMetadata",
        retriable: false,
        suggestion: "Check filesystem permissions and path configuration for TfStatePlugin.",
        path,
        original: error
      });
    }
  }
  /**
   * Check if state file has been modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    const lastModified = new Date(metadata.lastModified);
    const sinceDate = new Date(since);
    return lastModified > sinceDate;
  }
  /**
   * Close filesystem driver (no-op)
   */
  async close() {
  }
}

class TfStatePlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.driverType = config.driver || null;
    this.driverConfig = config.config || {};
    const resourcesConfig = config.resources || {};
    const resourceNamesOption = config.resourceNames || {};
    this._resourceDescriptors = {
      resources: {
        defaultName: "plg_tfstate_resources",
        override: resourceNamesOption.resources || resourcesConfig.resources || config.resourceName
      },
      stateFiles: {
        defaultName: "plg_tfstate_state_files",
        override: resourceNamesOption.stateFiles || resourcesConfig.stateFiles || config.stateFilesName
      },
      diffs: {
        defaultName: "plg_tfstate_state_diffs",
        override: resourceNamesOption.diffs || resourcesConfig.diffs || config.diffsName
      },
      lineages: {
        defaultName: "plg_tfstate_lineages",
        override: resourceNamesOption.lineages || resourcesConfig.lineages
      }
    };
    const resolvedNames = this._resolveResourceNames();
    this.resourceName = resolvedNames.resources;
    this.stateFilesName = resolvedNames.stateFiles;
    this.diffsName = resolvedNames.diffs;
    this.lineagesName = resolvedNames.lineages;
    const monitor = config.monitor || {};
    this.monitorEnabled = monitor.enabled || false;
    this.monitorCron = monitor.cron || "*/5 * * * *";
    const diffs = config.diffs || {};
    this.trackDiffs = diffs.enabled !== void 0 ? diffs.enabled : config.trackDiffs !== void 0 ? config.trackDiffs : true;
    this.diffsLookback = diffs.lookback || 10;
    this.asyncPartitions = config.asyncPartitions !== void 0 ? config.asyncPartitions : true;
    this.autoSync = config.autoSync || false;
    this.watchPaths = config.watchPaths || [];
    this.filters = config.filters || {};
    this.verbose = config.verbose || false;
    this.supportedVersions = [3, 4];
    this.driver = null;
    this.resource = null;
    this.stateFilesResource = null;
    this.diffsResource = null;
    this.watchers = [];
    this.cronTask = null;
    this.lastProcessedSerial = null;
    this._partitionCache = /* @__PURE__ */ new Map();
    this.stats = {
      statesProcessed: 0,
      resourcesExtracted: 0,
      resourcesInserted: 0,
      diffsCalculated: 0,
      errors: 0,
      lastProcessedSerial: null,
      partitionCacheHits: 0,
      partitionQueriesOptimized: 0
    };
  }
  _resolveResourceNames() {
    return resolveResourceNames("tfstate", this._resourceDescriptors, {
      namespace: this.namespace
    });
  }
  onNamespaceChanged() {
    const names = this._resolveResourceNames();
    this.resourceName = names.resources;
    this.stateFilesName = names.stateFiles;
    this.diffsName = names.diffs;
    this.lineagesName = names.lineages;
  }
  /**
   * Install the plugin
   * @override
   */
  async onInstall() {
    if (this.verbose) {
      console.log("[TfStatePlugin] Installing...");
    }
    if (this.driverType) {
      if (this.verbose) {
        console.log(`[TfStatePlugin] Initializing ${this.driverType} driver...`);
      }
      if (this.driverType === "s3") {
        this.driver = new S3TfStateDriver(this.driverConfig);
      } else if (this.driverType === "filesystem") {
        this.driver = new FilesystemTfStateDriver(this.driverConfig);
      } else {
        throw new TfStateError(`Unsupported driver type: ${this.driverType}`);
      }
      await this.driver.initialize();
      if (this.verbose) {
        console.log(`[TfStatePlugin] Driver initialized successfully`);
      }
    }
    {
      const [created, createErr, resource] = await tryFn(() => this.database.createResource({
        name: this.lineagesName,
        attributes: {
          id: "string|required",
          latestSerial: "number",
          latestStateId: "string",
          totalStates: "number",
          firstImportedAt: "number",
          lastImportedAt: "number",
          metadata: "json"
        },
        timestamps: true,
        asyncPartitions: this.asyncPartitions,
        partitions: {},
        createdBy: "TfStatePlugin"
      }));
      if (created) {
        this.lineagesResource = resource;
      } else {
        this.lineagesResource = this.database.resources?.[this.lineagesName];
        if (!this.lineagesResource) {
          throw createErr;
        }
      }
    }
    {
      const [created, createErr, resource] = await tryFn(() => this.database.createResource({
        name: this.stateFilesName,
        attributes: {
          id: "string|required",
          lineageId: "string|required",
          sourceFile: "string|required",
          serial: "number|required",
          lineage: "string|required",
          terraformVersion: "string",
          stateVersion: "number|required",
          resourceCount: "number",
          sha256Hash: "string|required",
          importedAt: "number|required"
        },
        timestamps: true,
        asyncPartitions: this.asyncPartitions,
        partitions: {
          byLineage: { fields: { lineageId: "string" } },
          byLineageSerial: { fields: { lineageId: "string", serial: "number" } },
          bySourceFile: { fields: { sourceFile: "string" } },
          bySerial: { fields: { serial: "number" } },
          bySha256: { fields: { sha256Hash: "string" } }
        },
        createdBy: "TfStatePlugin"
      }));
      if (created) {
        this.stateFilesResource = resource;
      } else {
        this.stateFilesResource = this.database.resources?.[this.stateFilesName];
        if (!this.stateFilesResource) {
          throw createErr;
        }
      }
    }
    {
      const [created, createErr, resource] = await tryFn(() => this.database.createResource({
        name: this.resourceName,
        attributes: {
          id: "string|required",
          stateFileId: "string|required",
          lineageId: "string|required",
          stateSerial: "number|required",
          sourceFile: "string|required",
          resourceType: "string|required",
          resourceName: "string|required",
          resourceAddress: "string|required",
          providerName: "string|required",
          mode: "string",
          attributes: "json",
          dependencies: "array",
          importedAt: "number|required"
        },
        timestamps: true,
        asyncPartitions: this.asyncPartitions,
        partitions: {
          byLineageSerial: { fields: { lineageId: "string", stateSerial: "number" } },
          byLineage: { fields: { lineageId: "string" } },
          byType: { fields: { resourceType: "string" } },
          byProvider: { fields: { providerName: "string" } },
          bySerial: { fields: { stateSerial: "number" } },
          bySourceFile: { fields: { sourceFile: "string" } },
          byProviderAndType: { fields: { providerName: "string", resourceType: "string" } },
          byLineageType: { fields: { lineageId: "string", resourceType: "string" } }
        },
        createdBy: "TfStatePlugin"
      }));
      if (created) {
        this.resource = resource;
      } else {
        this.resource = this.database.resources?.[this.resourceName];
        if (!this.resource) {
          throw createErr;
        }
      }
    }
    if (this.trackDiffs) {
      const [created, createErr, resource] = await tryFn(() => this.database.createResource({
        name: this.diffsName,
        attributes: {
          id: "string|required",
          lineageId: "string|required",
          oldSerial: "number|required",
          newSerial: "number|required",
          oldStateId: "string",
          newStateId: "string|required",
          calculatedAt: "number|required",
          summary: {
            type: "object",
            props: {
              addedCount: "number",
              modifiedCount: "number",
              deletedCount: "number"
            }
          },
          changes: {
            type: "object",
            props: {
              added: "array",
              modified: "array",
              deleted: "array"
            }
          }
        },
        behavior: "body-only",
        timestamps: true,
        asyncPartitions: this.asyncPartitions,
        partitions: {
          byLineage: { fields: { lineageId: "string" } },
          byLineageNewSerial: { fields: { lineageId: "string", newSerial: "number" } },
          byNewSerial: { fields: { newSerial: "number" } },
          byOldSerial: { fields: { oldSerial: "number" } }
        },
        createdBy: "TfStatePlugin"
      }));
      if (created) {
        this.diffsResource = resource;
      } else {
        this.diffsResource = this.database.resources?.[this.diffsName];
        if (!this.diffsResource) {
          throw createErr;
        }
      }
    }
    if (this.verbose) {
      const resourcesCreated = [this.lineagesName, this.stateFilesName, this.resourceName];
      if (this.trackDiffs) resourcesCreated.push(this.diffsName);
      console.log(`[TfStatePlugin] Created resources: ${resourcesCreated.join(", ")}`);
    }
    if (this.autoSync && this.watchPaths.length > 0) {
      await this._setupFileWatchers();
    }
    if (this.monitorEnabled && this.driver) {
      await this._setupCronMonitoring();
    }
    this.emit("installed", {
      plugin: "TfStatePlugin",
      stateFilesName: this.stateFilesName,
      resourceName: this.resourceName,
      diffsName: this.diffsName,
      monitorEnabled: this.monitorEnabled,
      driverType: this.driverType
    });
  }
  /**
   * Start the plugin
   * @override
   */
  async onStart() {
    if (this.verbose) {
      console.log("[TfStatePlugin] Started");
    }
  }
  /**
   * Stop the plugin
   * @override
   */
  async onStop() {
    if (this.cronTask) {
      this.cronTask.stop();
      this.cronTask = null;
      if (this.verbose) {
        console.log("[TfStatePlugin] Stopped cron monitoring");
      }
    }
    for (const watcher of this.watchers) {
      try {
        if (watcher && typeof watcher.return === "function") {
          await watcher.return();
        } else if (watcher && typeof watcher.close === "function") {
          await watcher.close();
        }
      } catch (error) {
        if (this.verbose) {
          console.warn("[TfStatePlugin] Error closing watcher:", error.message);
        }
      }
    }
    this.watchers = [];
    if (this.driver) {
      await this.driver.close();
      this.driver = null;
      if (this.verbose) {
        console.log("[TfStatePlugin] Driver closed");
      }
    }
    if (this.verbose) {
      console.log("[TfStatePlugin] Stopped");
    }
  }
  /**
   * Import multiple Terraform/OpenTofu states from local filesystem using glob pattern
   * @param {string} pattern - Glob pattern for matching state files
   * @param {Object} options - Optional parallelism settings
   * @returns {Promise<Object>} Consolidated import result with statistics
   *
   * @example
   * await plugin.importStatesGlob('./terraform/ ** /*.tfstate');
   * await plugin.importStatesGlob('./environments/ * /terraform.tfstate', { parallelism: 10 });
   */
  async importStatesGlob(pattern, options = {}) {
    const startTime = Date.now();
    const parallelism = options.parallelism || 5;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Finding local files matching: ${pattern}`);
    }
    try {
      const matchingFiles = await this._findFilesGlob(pattern);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${matchingFiles.length} matching files`);
      }
      if (matchingFiles.length === 0) {
        return {
          filesProcessed: 0,
          totalResourcesExtracted: 0,
          totalResourcesInserted: 0,
          files: [],
          duration: Date.now() - startTime
        };
      }
      const results = [];
      const files = [];
      for (let i = 0; i < matchingFiles.length; i += parallelism) {
        const batch = matchingFiles.slice(i, i + parallelism);
        const batchPromises = batch.map(async (filePath) => {
          try {
            const result = await this.importState(filePath);
            return { success: true, file: filePath, result };
          } catch (error) {
            if (this.verbose) {
              console.error(`[TfStatePlugin] Failed to import ${filePath}:`, error.message);
            }
            return { success: false, file: filePath, error: error.message };
          }
        });
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      const successful = results.filter((r) => r.success);
      const failed = results.filter((r) => !r.success);
      successful.forEach((r) => {
        if (!r.result.skipped) {
          files.push({
            file: r.file,
            serial: r.result.serial,
            resourcesExtracted: r.result.resourcesExtracted,
            resourcesInserted: r.result.resourcesInserted
          });
        }
      });
      const totalResourcesExtracted = successful.filter((r) => !r.result.skipped).reduce((sum, r) => sum + (r.result.resourcesExtracted || 0), 0);
      const totalResourcesInserted = successful.filter((r) => !r.result.skipped).reduce((sum, r) => sum + (r.result.resourcesInserted || 0), 0);
      const duration = Date.now() - startTime;
      const consolidatedResult = {
        filesProcessed: successful.length,
        filesFailed: failed.length,
        totalResourcesExtracted,
        totalResourcesInserted,
        files,
        failedFiles: failed.map((f) => ({ file: f.file, error: f.error })),
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Glob import completed:`, consolidatedResult);
      }
      this.emit("globImportCompleted", consolidatedResult);
      return consolidatedResult;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] Glob import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Find files matching glob pattern
   * @private
   */
  async _findFilesGlob(pattern) {
    const files = [];
    const baseMatch = pattern.match(/^([^*?[\]]+)/);
    const baseDir = baseMatch ? baseMatch[1] : ".";
    pattern.slice(baseDir.length);
    const findFiles = async (dir) => {
      try {
        const entries = await readdir(dir, { withFileTypes: true });
        for (const entry of entries) {
          const fullPath = join(dir, entry.name);
          if (entry.isDirectory()) {
            await findFiles(fullPath);
          } else if (entry.isFile() && entry.name.endsWith(".tfstate")) {
            if (this._matchesGlobPattern(fullPath, pattern)) {
              files.push(fullPath);
            }
          }
        }
      } catch (error) {
        if (error.code !== "EACCES" && error.code !== "EPERM") {
          throw error;
        }
      }
    };
    await findFiles(baseDir);
    return files;
  }
  /**
   * Import Terraform/OpenTofu state from remote S3 bucket
   * @param {string} bucket - S3 bucket name
   * @param {string} key - S3 object key (path to .tfstate file)
   * @param {Object} options - Optional S3 client override
   * @returns {Promise<Object>} Import result with statistics
   */
  async importStateFromS3(bucket, key, options = {}) {
    const startTime = Date.now();
    const sourceFile = `s3://${bucket}/${key}`;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Importing from S3: ${sourceFile}`);
    }
    try {
      const client = options.client || this.database.client;
      const [ok, err, data] = await tryFn(async () => {
        return await client.getObject(key);
      });
      if (!ok) {
        throw new StateFileNotFoundError(sourceFile, {
          originalError: err
        });
      }
      const stateContent = data.Body.toString("utf-8");
      let state;
      try {
        state = JSON.parse(stateContent);
      } catch (parseError) {
        throw new InvalidStateFileError(sourceFile, "Invalid JSON", {
          originalError: parseError
        });
      }
      this._validateState(state, sourceFile);
      this._validateStateVersion(state);
      const sha256Hash = this._calculateSHA256(state);
      const partitionName = this._findPartitionByField(this.stateFilesResource, "sha256Hash");
      let existingByHash;
      if (partitionName) {
        this.stats.partitionQueriesOptimized++;
        existingByHash = await this.stateFilesResource.list({
          partition: partitionName,
          partitionValues: { sha256Hash },
          limit: 1
        });
      } else {
        existingByHash = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
      }
      if (existingByHash.length > 0) {
        const existing = existingByHash[0];
        if (this.verbose) {
          console.log(`[TfStatePlugin] State already imported (SHA256 match), skipping`);
        }
        return {
          skipped: true,
          reason: "duplicate",
          serial: state.serial,
          stateFileId: existing.id,
          sha256Hash,
          source: sourceFile
        };
      }
      const currentTime = Date.now();
      const stateFileRecord = {
        id: idGenerator(),
        sourceFile,
        serial: state.serial,
        lineage: state.lineage,
        terraformVersion: state.terraform_version,
        stateVersion: state.version,
        resourceCount: (state.resources || []).length,
        sha256Hash,
        importedAt: currentTime
      };
      const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
        return await this.stateFilesResource.insert(stateFileRecord);
      });
      if (!insertOk) {
        throw new TfStateError(`Failed to save state file metadata: ${insertErr.message}`, {
          originalError: insertErr
        });
      }
      const stateFileId = stateFileResult.id;
      const resources = await this._extractResources(state, sourceFile, stateFileId);
      let diff = null;
      let diffRecord = null;
      if (this.trackDiffs) {
        diff = await this._calculateDiff(state, sourceFile, stateFileId);
        if (diff && !diff.isFirst) {
          diffRecord = await this._saveDiff(diff, sourceFile, stateFileId);
        }
      }
      const inserted = await this._insertResources(resources);
      this.lastProcessedSerial = state.serial;
      this.stats.statesProcessed++;
      this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
      this.stats.resourcesInserted += inserted.length;
      this.stats.lastProcessedSerial = state.serial;
      if (diff && !diff.isFirst) this.stats.diffsCalculated++;
      const duration = Date.now() - startTime;
      const result = {
        serial: state.serial,
        lineage: state.lineage,
        terraformVersion: state.terraform_version,
        resourcesExtracted: resources.totalExtracted || resources.length,
        resourcesInserted: inserted.length,
        stateFileId,
        sha256Hash,
        source: sourceFile,
        diff: diff ? {
          added: diff.added.length,
          modified: diff.modified.length,
          deleted: diff.deleted.length,
          isFirst: diff.isFirst || false
        } : null,
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] S3 import completed:`, result);
      }
      this.emit("stateImported", result);
      return result;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] S3 import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Import multiple Terraform/OpenTofu states from S3 using glob pattern
   * @param {string} bucket - S3 bucket name
   * @param {string} pattern - Glob pattern for matching state files
   * @param {Object} options - Optional S3 client override and parallelism settings
   * @returns {Promise<Object>} Consolidated import result with statistics
   */
  async importStatesFromS3Glob(bucket, pattern, options = {}) {
    const startTime = Date.now();
    const client = options.client || this.database.client;
    const parallelism = options.parallelism || 5;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Listing S3 objects: s3://${bucket}/${pattern}`);
    }
    try {
      const [ok, err, data] = await tryFn(async () => {
        const params = {};
        const prefixMatch = pattern.match(/^([^*?[\]]+)/);
        if (prefixMatch) {
          params.prefix = prefixMatch[1];
        }
        return await client.listObjects(params);
      });
      if (!ok) {
        throw new TfStateError(`Failed to list objects in s3://${bucket}`, {
          originalError: err
        });
      }
      const allObjects = data.Contents || [];
      const matchingObjects = allObjects.filter((obj) => {
        return this._matchesGlobPattern(obj.Key, pattern);
      });
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${matchingObjects.length} matching files`);
      }
      if (matchingObjects.length === 0) {
        return {
          filesProcessed: 0,
          totalResourcesExtracted: 0,
          totalResourcesInserted: 0,
          files: [],
          duration: Date.now() - startTime
        };
      }
      const results = [];
      const files = [];
      for (let i = 0; i < matchingObjects.length; i += parallelism) {
        const batch = matchingObjects.slice(i, i + parallelism);
        const batchPromises = batch.map(async (obj) => {
          try {
            const result = await this.importStateFromS3(bucket, obj.Key, options);
            return { success: true, key: obj.Key, result };
          } catch (error) {
            if (this.verbose) {
              console.error(`[TfStatePlugin] Failed to import ${obj.Key}:`, error.message);
            }
            return { success: false, key: obj.Key, error: error.message };
          }
        });
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      const successful = results.filter((r) => r.success);
      const failed = results.filter((r) => !r.success);
      successful.forEach((r) => {
        files.push({
          file: r.key,
          serial: r.result.serial,
          resourcesExtracted: r.result.resourcesExtracted,
          resourcesInserted: r.result.resourcesInserted
        });
      });
      const totalResourcesExtracted = successful.reduce((sum, r) => sum + r.result.resourcesExtracted, 0);
      const totalResourcesInserted = successful.reduce((sum, r) => sum + r.result.resourcesInserted, 0);
      const duration = Date.now() - startTime;
      const consolidatedResult = {
        filesProcessed: successful.length,
        filesFailed: failed.length,
        totalResourcesExtracted,
        totalResourcesInserted,
        files,
        failedFiles: failed.map((f) => ({ file: f.key, error: f.error })),
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Glob import completed:`, consolidatedResult);
      }
      this.emit("globImportCompleted", consolidatedResult);
      return consolidatedResult;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] Glob import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Match S3 key against glob pattern
   * Simple glob matching supporting *, **, ?, and []
   * @private
   */
  _matchesGlobPattern(key, pattern) {
    let regexPattern = pattern.replace(/\*\*/g, "\0\0").replace(/\*/g, "\0").replace(/\?/g, "");
    regexPattern = regexPattern.replace(/[.+^${}()|\\]/g, "\\$&");
    regexPattern = regexPattern.replace(/\x00\x00/g, "__DOUBLE_STAR__").replace(/\x00/g, "[^/]*").replace(/\x01/g, ".");
    regexPattern = regexPattern.replace(/__DOUBLE_STAR__\//g, "(?:.*/)?");
    regexPattern = regexPattern.replace(/__DOUBLE_STAR__/g, ".*");
    const regex = new RegExp(`^${regexPattern}$`);
    return regex.test(key);
  }
  /**
   * Ensure lineage record exists and is up-to-date
   * Creates or updates the lineage tracking record
   * @private
   */
  async _ensureLineage(lineageUuid, stateMeta) {
    if (!lineageUuid) {
      throw new TfStateError("Lineage UUID is required for state tracking");
    }
    const [getOk, getErr, existingLineage] = await tryFn(async () => {
      return await this.lineagesResource.get(lineageUuid);
    });
    const currentTime = Date.now();
    if (existingLineage) {
      const updates = {
        lastImportedAt: currentTime
      };
      if (stateMeta.serial > (existingLineage.latestSerial || 0)) {
        updates.latestSerial = stateMeta.serial;
        updates.latestStateId = stateMeta.stateFileId;
      }
      if (existingLineage.totalStates !== void 0) {
        updates.totalStates = existingLineage.totalStates + 1;
      } else {
        updates.totalStates = 1;
      }
      await this.lineagesResource.update(lineageUuid, updates);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Updated lineage: ${lineageUuid} (serial ${stateMeta.serial})`);
      }
      return { ...existingLineage, ...updates };
    } else {
      const lineageRecord = {
        id: lineageUuid,
        latestSerial: stateMeta.serial,
        latestStateId: stateMeta.stateFileId,
        totalStates: 1,
        firstImportedAt: currentTime,
        lastImportedAt: currentTime,
        metadata: {}
      };
      await this.lineagesResource.insert(lineageRecord);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Created new lineage: ${lineageUuid}`);
      }
      return lineageRecord;
    }
  }
  /**
   * Import Terraform/OpenTofu state from file
   * @param {string} filePath - Path to .tfstate file
   * @returns {Promise<Object>} Import result with statistics
   */
  async importState(filePath) {
    const startTime = Date.now();
    if (this.verbose) {
      console.log(`[TfStatePlugin] Importing state from: ${filePath}`);
    }
    const state = await this._readStateFile(filePath);
    this._validateStateVersion(state);
    const sha256Hash = this._calculateSHA256(state);
    const existingByHash = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
    if (existingByHash.length > 0) {
      const existing = existingByHash[0];
      if (this.verbose) {
        console.log(`[TfStatePlugin] State already imported (SHA256 match), skipping`);
      }
      return {
        skipped: true,
        reason: "duplicate",
        serial: state.serial,
        stateFileId: existing.id,
        sha256Hash
      };
    }
    const currentTime = Date.now();
    const lineageUuid = state.lineage;
    if (!lineageUuid) {
      throw new TfStateError("State file missing lineage field - cannot track state progression", {
        filePath,
        serial: state.serial
      });
    }
    const stateFileRecord = {
      id: idGenerator(),
      lineageId: lineageUuid,
      // NEW: FK to lineages
      sourceFile: filePath,
      serial: state.serial,
      lineage: state.lineage,
      // Denormalized for queries
      terraformVersion: state.terraform_version,
      stateVersion: state.version,
      resourceCount: (state.resources || []).length,
      sha256Hash,
      importedAt: currentTime
    };
    const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
      return await this.stateFilesResource.insert(stateFileRecord);
    });
    if (!insertOk) {
      throw new TfStateError(`Failed to save state file metadata: ${insertErr.message}`, {
        originalError: insertErr
      });
    }
    const stateFileId = stateFileResult.id;
    await this._ensureLineage(lineageUuid, {
      serial: state.serial,
      stateFileId
    });
    const resources = await this._extractResources(state, filePath, stateFileId, lineageUuid);
    const inserted = await this._insertResources(resources);
    let diff = null;
    if (this.trackDiffs) {
      diff = await this._calculateDiff(state, lineageUuid, stateFileId);
      if (diff && !diff.isFirst) {
        await this._saveDiff(diff, lineageUuid, stateFileId);
      }
    }
    this.lastProcessedSerial = state.serial;
    this.stats.statesProcessed++;
    this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
    this.stats.resourcesInserted += inserted.length;
    this.stats.lastProcessedSerial = state.serial;
    if (diff && !diff.isFirst) this.stats.diffsCalculated++;
    const duration = Date.now() - startTime;
    const result = {
      serial: state.serial,
      lineage: state.lineage,
      terraformVersion: state.terraform_version,
      resourcesExtracted: resources.totalExtracted || resources.length,
      resourcesInserted: inserted.length,
      stateFileId,
      sha256Hash,
      diff: diff ? {
        added: diff.added.length,
        modified: diff.modified.length,
        deleted: diff.deleted.length,
        isFirst: diff.isFirst || false
      } : null,
      duration
    };
    if (this.verbose) {
      console.log(`[TfStatePlugin] Import completed:`, result);
    }
    this.emit("stateImported", result);
    return result;
  }
  /**
   * Read and parse Tfstate file
   * @private
   */
  async _readStateFile(filePath) {
    if (!existsSync(filePath)) {
      throw new StateFileNotFoundError(filePath);
    }
    const [ok, err, content] = await tryFn(async () => {
      return await readFile(filePath, "utf-8");
    });
    if (!ok) {
      throw new InvalidStateFileError(filePath, `Failed to read file: ${err.message}`);
    }
    const [parseOk, parseErr, state] = await tryFn(async () => {
      return JSON.parse(content);
    });
    if (!parseOk) {
      throw new InvalidStateFileError(filePath, `Invalid JSON: ${parseErr.message}`);
    }
    return state;
  }
  /**
   * Validate basic state structure
   * @private
   */
  _validateState(state, filePath) {
    if (!state || typeof state !== "object") {
      throw new InvalidStateFileError(filePath, "State must be a valid JSON object");
    }
    if (!state.version) {
      throw new InvalidStateFileError(filePath, "Missing version field");
    }
    if (state.serial === void 0) {
      throw new InvalidStateFileError(filePath, "Missing serial field");
    }
  }
  /**
   * Validate Tfstate version
   * @private
   */
  _validateStateVersion(state) {
    const version = state.version;
    if (!version) {
      throw new InvalidStateFileError("unknown", "Missing version field");
    }
    if (!this.supportedVersions.includes(version)) {
      throw new UnsupportedStateVersionError(version, this.supportedVersions);
    }
  }
  /**
   * Extract resources from Tfstate
   * @private
   */
  async _extractResources(state, filePath, stateFileId, lineageId) {
    const resources = [];
    let totalExtracted = 0;
    const stateSerial = state.serial;
    const stateVersion = state.version;
    const importedAt = Date.now();
    const stateResources = state.resources || [];
    for (const resource of stateResources) {
      try {
        const instances = resource.instances || [resource];
        for (const instance of instances) {
          totalExtracted++;
          const extracted = this._extractResourceInstance(
            resource,
            instance,
            stateSerial,
            stateVersion,
            importedAt,
            filePath,
            // Pass source file path
            stateFileId,
            // Pass state file ID (foreign key)
            lineageId
            // NEW: Pass lineage ID (foreign key)
          );
          if (this._shouldIncludeResource(extracted)) {
            resources.push(extracted);
          }
        }
      } catch (error) {
        this.stats.errors++;
        if (this.verbose) {
          console.error(`[TfStatePlugin] Failed to extract resource:`, error);
        }
        throw new ResourceExtractionError(resource.name || "unknown", error);
      }
    }
    resources.totalExtracted = totalExtracted;
    return resources;
  }
  /**
   * Extract single resource instance
   * @private
   */
  _extractResourceInstance(resource, instance, stateSerial, stateVersion, importedAt, sourceFile, stateFileId, lineageId) {
    const resourceType = resource.type;
    const resourceName = resource.name;
    const mode = resource.mode || "managed";
    const providerName = this._detectProvider(resourceType);
    const resourceAddress = mode === "data" ? `data.${resourceType}.${resourceName}` : `${resourceType}.${resourceName}`;
    const attributes = instance.attributes || instance.attributes_flat || {};
    const dependencies = resource.depends_on || instance.depends_on || [];
    return {
      id: idGenerator(),
      stateFileId,
      // Foreign key to state_files
      lineageId,
      // NEW: Foreign key to lineages
      stateSerial,
      // Denormalized for fast queries
      sourceFile: sourceFile || null,
      // Denormalized for informational purposes
      resourceType,
      resourceName,
      resourceAddress,
      providerName,
      mode,
      attributes,
      dependencies,
      importedAt
    };
  }
  /**
   * Detect provider from resource type
   * @private
   */
  _detectProvider(resourceType) {
    if (!resourceType) return "unknown";
    const prefix = resourceType.split("_")[0];
    const providerMap = {
      "aws": "aws",
      "google": "google",
      "azurerm": "azure",
      "azuread": "azure",
      "azuredevops": "azure",
      "kubernetes": "kubernetes",
      "helm": "kubernetes",
      "random": "random",
      "null": "null",
      "local": "local",
      "time": "time",
      "tls": "tls",
      "http": "http",
      "external": "external",
      "terraform": "terraform",
      "datadog": "datadog",
      "cloudflare": "cloudflare",
      "github": "github",
      "gitlab": "gitlab",
      "vault": "vault"
    };
    return providerMap[prefix] || "unknown";
  }
  /**
   * Check if resource should be included based on filters
   * @private
   */
  _shouldIncludeResource(resource) {
    const { types, providers, exclude, include } = this.filters;
    if (include && include.length > 0) {
      const matches = include.some((pattern) => {
        return this._matchesPattern(resource.resourceAddress, pattern);
      });
      if (!matches) return false;
    }
    if (types && types.length > 0) {
      if (!types.includes(resource.resourceType)) {
        return false;
      }
    }
    if (providers && providers.length > 0) {
      if (!providers.includes(resource.providerName)) {
        return false;
      }
    }
    if (exclude && exclude.length > 0) {
      const matches = exclude.some((pattern) => {
        return this._matchesPattern(resource.resourceAddress, pattern);
      });
      if (matches) return false;
    }
    return true;
  }
  /**
   * Match resource address against pattern (supports wildcards)
   * @private
   */
  _matchesPattern(address, pattern) {
    const regexPattern = pattern.replace(/\.\*/g, "___WILDCARD___").replace(/\*/g, "[^.]*").replace(/\./g, "\\.").replace(/___WILDCARD___/g, ".*");
    const regex = new RegExp(`^${regexPattern}$`);
    return regex.test(address);
  }
  /**
   * Calculate diff between current and previous state
   * NEW: Uses lineage-based tracking for O(1) lookup
   * @private
   */
  async _calculateDiff(currentState, lineageId, currentStateFileId) {
    if (!this.diffsResource) return null;
    const currentSerial = currentState.serial;
    const previousStateFiles = await this.stateFilesResource.listPartition({
      partition: "byLineageSerial",
      partitionValues: { lineageId, serial: currentSerial - 1 }
    });
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Diff calculation (lineage-based): found ${previousStateFiles.length} previous states for lineage=${lineageId}, serial=${currentSerial - 1}`
      );
    }
    if (previousStateFiles.length === 0) {
      if (this.verbose) {
        console.log(`[TfStatePlugin] First state for lineage ${lineageId}, no previous state`);
      }
      return {
        added: [],
        modified: [],
        deleted: [],
        isFirst: true,
        oldSerial: null,
        newSerial: currentSerial,
        oldStateId: null,
        newStateId: currentStateFileId,
        lineageId
      };
    }
    const previousStateFile = previousStateFiles[0];
    const previousSerial = previousStateFile.serial;
    const previousStateFileId = previousStateFile.id;
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Using previous state: serial ${previousSerial} (id: ${previousStateFileId})`
      );
    }
    const [ok, err, diff] = await tryFn(async () => {
      return await this._computeDiff(previousSerial, currentSerial, lineageId);
    });
    if (!ok) {
      throw new StateDiffError(previousSerial, currentSerial, err);
    }
    diff.oldSerial = previousSerial;
    diff.newSerial = currentSerial;
    diff.oldStateId = previousStateFileId;
    diff.newStateId = currentStateFileId;
    diff.lineageId = lineageId;
    return diff;
  }
  /**
   * Compute diff between two state serials
   * NEW: Uses lineage-based partition for efficient resource lookup
   * @private
   */
  async _computeDiff(oldSerial, newSerial, lineageId) {
    const partitionName = "byLineageSerial";
    let oldResources, newResources;
    this.stats.partitionQueriesOptimized += 2;
    [oldResources, newResources] = await Promise.all([
      this.resource.listPartition({
        partition: partitionName,
        partitionValues: { lineageId, stateSerial: oldSerial }
      }),
      this.resource.listPartition({
        partition: partitionName,
        partitionValues: { lineageId, stateSerial: newSerial }
      })
    ]);
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Diff computation using lineage partition: ${oldResources.length} old + ${newResources.length} new resources`
      );
    }
    if (oldResources.length === 0 && newResources.length === 0) {
      if (this.verbose) {
        console.log("[TfStatePlugin] No resources found for either serial");
      }
      return {
        added: [],
        modified: [],
        deleted: []
      };
    }
    const oldMap = new Map(oldResources.map((r) => [r.resourceAddress, r]));
    const newMap = new Map(newResources.map((r) => [r.resourceAddress, r]));
    const added = [];
    const modified = [];
    const deleted = [];
    for (const [address, newResource] of newMap) {
      if (!oldMap.has(address)) {
        added.push({
          address,
          type: newResource.resourceType,
          name: newResource.resourceName
        });
      } else {
        const oldResource = oldMap.get(address);
        if (JSON.stringify(oldResource.attributes) !== JSON.stringify(newResource.attributes)) {
          modified.push({
            address,
            type: newResource.resourceType,
            name: newResource.resourceName,
            changes: this._computeAttributeChanges(oldResource.attributes, newResource.attributes)
          });
        }
      }
    }
    for (const [address, oldResource] of oldMap) {
      if (!newMap.has(address)) {
        deleted.push({
          address,
          type: oldResource.resourceType,
          name: oldResource.resourceName
        });
      }
    }
    return { added, modified, deleted, oldSerial, newSerial };
  }
  /**
   * Compute changes between old and new attributes
   * @private
   */
  _computeAttributeChanges(oldAttrs, newAttrs) {
    const changes = [];
    const allKeys = /* @__PURE__ */ new Set([...Object.keys(oldAttrs || {}), ...Object.keys(newAttrs || {})]);
    for (const key of allKeys) {
      const oldValue = oldAttrs?.[key];
      const newValue = newAttrs?.[key];
      if (JSON.stringify(oldValue) !== JSON.stringify(newValue)) {
        changes.push({
          field: key,
          oldValue,
          newValue
        });
      }
    }
    return changes;
  }
  /**
   * Save diff to diffsResource
   * NEW: Includes lineage-based fields for efficient querying
   * @private
   */
  async _saveDiff(diff, lineageId, newStateFileId) {
    const diffRecord = {
      id: idGenerator(),
      lineageId: diff.lineageId || lineageId,
      // NEW: FK to lineages
      oldSerial: diff.oldSerial,
      newSerial: diff.newSerial,
      oldStateId: diff.oldStateId,
      // NEW: FK to state_files
      newStateId: diff.newStateId || newStateFileId,
      // NEW: FK to state_files
      calculatedAt: Date.now(),
      summary: {
        addedCount: diff.added.length,
        modifiedCount: diff.modified.length,
        deletedCount: diff.deleted.length
      },
      changes: {
        added: diff.added,
        modified: diff.modified,
        deleted: diff.deleted
      }
    };
    const [ok, err, result] = await tryFn(async () => {
      return await this.diffsResource.insert(diffRecord);
    });
    if (!ok) {
      if (this.verbose) {
        console.error(`[TfStatePlugin] Failed to save diff:`, err);
      }
      throw new TfStateError(`Failed to save diff: ${err.message}`, {
        originalError: err
      });
    }
    return result;
  }
  /**
   * Calculate SHA256 hash of state content
   * @private
   */
  _calculateSHA256(state) {
    const stateString = JSON.stringify(state);
    return createHash("sha256").update(stateString).digest("hex");
  }
  /**
   * Insert resources into database with controlled parallelism
   * @private
   */
  async _insertResources(resources) {
    if (resources.length === 0) return [];
    const inserted = [];
    const parallelism = this.database.parallelism || 10;
    for (let i = 0; i < resources.length; i += parallelism) {
      const batch = resources.slice(i, i + parallelism);
      const batchPromises = batch.map(async (resource) => {
        const [ok, err, result] = await tryFn(async () => {
          return await this.resource.insert(resource);
        });
        if (ok) {
          return { success: true, result };
        } else {
          this.stats.errors++;
          if (this.verbose) {
            console.error(`[TfStatePlugin] Failed to insert resource ${resource.resourceAddress}:`, err);
          }
          return { success: false, error: err };
        }
      });
      const batchResults = await Promise.all(batchPromises);
      batchResults.forEach((br) => {
        if (br.success) {
          inserted.push(br.result);
        }
      });
    }
    if (this.verbose && resources.length > parallelism) {
      console.log(`[TfStatePlugin] Batch inserted ${inserted.length}/${resources.length} resources (parallelism: ${parallelism})`);
    }
    return inserted;
  }
  /**
   * Setup cron-based monitoring for state file changes
   * @private
   */
  async _setupCronMonitoring() {
    if (!this.driver) {
      throw new TfStateError("Cannot setup monitoring without a driver");
    }
    if (this.verbose) {
      console.log(`[TfStatePlugin] Setting up cron monitoring: ${this.monitorCron}`);
    }
    await requirePluginDependency("tfstate-plugin");
    const [ok, err, cronModule] = await tryFn(() => import('node-cron'));
    if (!ok) {
      throw new TfStateError(`Failed to import node-cron: ${err.message}`);
    }
    const cron = cronModule.default;
    if (!cron.validate(this.monitorCron)) {
      throw new TfStateError(`Invalid cron expression: ${this.monitorCron}`);
    }
    this.cronTask = cron.schedule(this.monitorCron, async () => {
      try {
        await this._monitorStateFiles();
      } catch (error) {
        this.stats.errors++;
        if (this.verbose) {
          console.error("[TfStatePlugin] Monitoring error:", error);
        }
        this.emit("monitoringError", { error: error.message });
      }
    });
    if (this.verbose) {
      console.log("[TfStatePlugin] Cron monitoring started");
    }
    this.emit("monitoringStarted", { cron: this.monitorCron });
  }
  /**
   * Monitor state files for changes
   * Called by cron task
   * @private
   */
  async _monitorStateFiles() {
    if (!this.driver) return;
    if (this.verbose) {
      console.log("[TfStatePlugin] Checking for state file changes...");
    }
    const startTime = Date.now();
    try {
      const stateFiles = await this.driver.listStateFiles();
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${stateFiles.length} state files`);
      }
      let changedFiles = 0;
      let newFiles = 0;
      for (const fileMetadata of stateFiles) {
        try {
          const existing = await this.stateFilesResource.query({
            sourceFile: fileMetadata.path
          }, { limit: 1, sort: { serial: -1 } });
          let shouldProcess = false;
          if (existing.length === 0) {
            shouldProcess = true;
            newFiles++;
          } else {
            const lastImported = existing[0].importedAt;
            const hasChanged = await this.driver.hasBeenModified(
              fileMetadata.path,
              new Date(lastImported)
            );
            if (hasChanged) {
              shouldProcess = true;
              changedFiles++;
            }
          }
          if (shouldProcess) {
            const state = await this.driver.readStateFile(fileMetadata.path);
            this._validateState(state, fileMetadata.path);
            this._validateStateVersion(state);
            const sha256Hash = this._calculateSHA256(state);
            const duplicates = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
            if (duplicates.length > 0) {
              if (this.verbose) {
                console.log(`[TfStatePlugin] Skipped duplicate: ${fileMetadata.path}`);
              }
              continue;
            }
            const currentTime = Date.now();
            const stateFileRecord = {
              id: idGenerator(),
              sourceFile: fileMetadata.path,
              serial: state.serial,
              lineage: state.lineage,
              terraformVersion: state.terraform_version,
              stateVersion: state.version,
              resourceCount: (state.resources || []).length,
              sha256Hash,
              importedAt: currentTime
            };
            const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
              return await this.stateFilesResource.insert(stateFileRecord);
            });
            if (!insertOk) {
              throw new TfStateError(`Failed to save state file: ${insertErr.message}`);
            }
            const stateFileId = stateFileResult.id;
            const resources = await this._extractResources(state, fileMetadata.path, stateFileId);
            if (this.trackDiffs) {
              const diff = await this._calculateDiff(state, fileMetadata.path, stateFileId);
              if (diff && !diff.isFirst) {
                await this._saveDiff(diff, fileMetadata.path, stateFileId);
                this.stats.diffsCalculated++;
              }
            }
            const inserted = await this._insertResources(resources);
            this.stats.statesProcessed++;
            this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
            this.stats.resourcesInserted += inserted.length;
            this.stats.lastProcessedSerial = state.serial;
            if (this.verbose) {
              console.log(`[TfStatePlugin] Processed ${fileMetadata.path}: ${resources.totalExtracted || resources.length} resources`);
            }
            this.emit("stateFileProcessed", {
              path: fileMetadata.path,
              serial: state.serial,
              resourcesExtracted: resources.totalExtracted || resources.length,
              resourcesInserted: inserted.length
            });
          }
        } catch (error) {
          this.stats.errors++;
          if (this.verbose) {
            console.error(`[TfStatePlugin] Failed to process ${fileMetadata.path}:`, error);
          }
          this.emit("processingError", {
            path: fileMetadata.path,
            error: error.message
          });
        }
      }
      const duration = Date.now() - startTime;
      const result = {
        totalFiles: stateFiles.length,
        newFiles,
        changedFiles,
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Monitoring completed:`, result);
      }
      this.emit("monitoringCompleted", result);
      return result;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error("[TfStatePlugin] Monitoring failed:", error);
      }
      throw error;
    }
  }
  /**
   * Setup file watchers for auto-sync
   * @private
   */
  async _setupFileWatchers() {
    for (const path of this.watchPaths) {
      try {
        const watcher = watch(path);
        (async () => {
          for await (const event of watcher) {
            if (event.eventType === "change" && event.filename.endsWith(".tfstate")) {
              const filePath = `${path}/${event.filename}`;
              if (this.verbose) {
                console.log(`[TfStatePlugin] Detected change: ${filePath}`);
              }
              try {
                await this.importState(filePath);
              } catch (error) {
                this.stats.errors++;
                console.error(`[TfStatePlugin] Auto-import failed:`, error);
                this.emit("importError", { filePath, error });
              }
            }
          }
        })();
        this.watchers.push(watcher);
        if (this.verbose) {
          console.log(`[TfStatePlugin] Watching: ${path}`);
        }
      } catch (error) {
        throw new FileWatchError(path, error);
      }
    }
  }
  /**
   * Export resources to Tfstate format
   * @param {Object} options - Export options
   * @param {number} options.serial - Specific serial to export (default: latest)
   * @param {string[]} options.resourceTypes - Filter by resource types
   * @param {string} options.terraformVersion - Terraform version for output (default: '1.5.0')
   * @param {string} options.lineage - State lineage (default: auto-generated)
   * @param {Object} options.outputs - Terraform outputs to include
   * @returns {Promise<Object>} Tfstate object
   *
   * @example
   * // Export latest state
   * const state = await plugin.exportState();
   *
   * // Export specific serial
   * const state = await plugin.exportState({ serial: 5 });
   *
   * // Export only EC2 instances
   * const state = await plugin.exportState({
   *   resourceTypes: ['aws_instance']
   * });
   */
  async exportState(options = {}) {
    const {
      serial,
      resourceTypes,
      terraformVersion = "1.5.0",
      lineage,
      outputs = {},
      sourceFile
      // Optional: export from specific source file
    } = options;
    let targetSerial = serial;
    if (!targetSerial) {
      const queryFilter = sourceFile ? { sourceFile } : {};
      const latestStateFiles = await this.stateFilesResource.query(queryFilter, {
        limit: 1,
        sort: { serial: -1 }
      });
      if (latestStateFiles.length > 0) {
        targetSerial = latestStateFiles[0].serial;
      }
      if (!targetSerial) {
        targetSerial = this.lastProcessedSerial || 1;
      }
    }
    const partitionName = this._findPartitionByField(this.resource, "stateSerial");
    let resources;
    if (partitionName) {
      this.stats.partitionQueriesOptimized++;
      resources = await this.resource.list({
        partition: partitionName,
        partitionValues: { stateSerial: targetSerial }
      });
      if (this.verbose) {
        console.log(`[TfStatePlugin] Export using partition ${partitionName}: ${resources.length} resources`);
      }
      if (resourceTypes && resourceTypes.length > 0) {
        resources = resources.filter((r) => resourceTypes.includes(r.resourceType));
      }
    } else {
      if (this.verbose) {
        console.log("[TfStatePlugin] No partition found for stateSerial, using full scan");
      }
      const allResources = await this.resource.list({ limit: 1e5 });
      resources = allResources.filter((r) => {
        if (r.stateSerial !== targetSerial) return false;
        if (resourceTypes && resourceTypes.length > 0) {
          return resourceTypes.includes(r.resourceType);
        }
        return true;
      });
    }
    if (this.verbose) {
      console.log(`[TfStatePlugin] Exporting ${resources.length} resources from serial ${targetSerial}`);
    }
    const resourceMap = /* @__PURE__ */ new Map();
    for (const resource of resources) {
      const key = `${resource.mode}.${resource.resourceType}.${resource.resourceName}`;
      if (!resourceMap.has(key)) {
        resourceMap.set(key, {
          mode: resource.mode || "managed",
          type: resource.resourceType,
          name: resource.resourceName,
          provider: resource.providerName,
          instances: []
        });
      }
      resourceMap.get(key).instances.push({
        attributes: resource.attributes,
        dependencies: resource.dependencies || []
      });
    }
    for (const resourceGroup of resourceMap.values()) {
      resourceGroup.instances.sort((a, b) => {
        const aId = a.attributes?.id;
        const bId = b.attributes?.id;
        if (aId && bId) {
          return String(aId).localeCompare(String(bId));
        }
        return JSON.stringify(a.attributes).localeCompare(JSON.stringify(b.attributes));
      });
    }
    const terraformResources = Array.from(resourceMap.values());
    const stateLineage = lineage || `s3db-export-${Date.now()}`;
    const state = {
      version: 4,
      terraform_version: terraformVersion,
      serial: targetSerial,
      lineage: stateLineage,
      outputs,
      resources: terraformResources
    };
    if (this.verbose) {
      console.log(`[TfStatePlugin] Export complete:`, {
        serial: targetSerial,
        resourceCount: resources.length,
        groupedResourceCount: terraformResources.length
      });
    }
    this.emit("stateExported", { serial: targetSerial, resourceCount: resources.length });
    return state;
  }
  /**
   * Export state to local file
   * @param {string} filePath - Output file path
   * @param {Object} options - Export options (see exportState)
   * @returns {Promise<Object>} Export result with file path and stats
   *
   * @example
   * // Export to file
   * await plugin.exportStateToFile('./exported-state.tfstate');
   *
   * // Export specific serial
   * await plugin.exportStateToFile('./state-v5.tfstate', { serial: 5 });
   */
  async exportStateToFile(filePath, options = {}) {
    const state = await this.exportState(options);
    const { writeFileSync } = await import('fs');
    writeFileSync(filePath, JSON.stringify(state, null, 2));
    if (this.verbose) {
      console.log(`[TfStatePlugin] State exported to file: ${filePath}`);
    }
    return {
      filePath,
      serial: state.serial,
      resourceCount: state.resources.reduce((sum, r) => sum + r.instances.length, 0),
      groupedResourceCount: state.resources.length
    };
  }
  /**
   * Export state to S3
   * @param {string} bucket - S3 bucket name
   * @param {string} key - S3 object key
   * @param {Object} options - Export options (see exportState)
   * @param {Object} options.client - Optional S3 client override
   * @returns {Promise<Object>} Export result with S3 location and stats
   *
   * @example
   * // Export to S3
   * await plugin.exportStateToS3('my-bucket', 'terraform/exported.tfstate');
   *
   * // Export with custom options
   * await plugin.exportStateToS3('my-bucket', 'terraform/prod.tfstate', {
   *   serial: 10,
   *   terraformVersion: '1.6.0',
   *   lineage: 'prod-infrastructure'
   * });
   */
  async exportStateToS3(bucket, key, options = {}) {
    const state = await this.exportState(options);
    const client = options.client || this.database.client;
    await client.putObject({
      key,
      body: JSON.stringify(state, null, 2),
      contentType: "application/json"
    });
    if (this.verbose) {
      console.log(`[TfStatePlugin] State exported to S3: s3://${bucket}/${key}`);
    }
    this.emit("stateExportedToS3", { bucket, key, serial: state.serial });
    return {
      bucket,
      key,
      location: `s3://${bucket}/${key}`,
      serial: state.serial,
      resourceCount: state.resources.reduce((sum, r) => sum + r.instances.length, 0),
      groupedResourceCount: state.resources.length
    };
  }
  /**
   * Get diffs with lookback support
   * Retrieves the last N diffs for a given state file
   * @param {string} sourceFile - Source file path
   * @param {Object} options - Query options
   * @param {number} options.lookback - Number of historical diffs to retrieve (default: this.diffsLookback)
   * @param {boolean} options.includeDetails - Include detailed changes (default: false, only summary)
   * @returns {Promise<Array>} Array of diffs ordered by serial (newest first)
   *
   * @example
   * // Get last 10 diffs
   * const diffs = await plugin.getDiffsWithLookback('terraform.tfstate');
   *
   * // Get last 5 diffs with details
   * const diffs = await plugin.getDiffsWithLookback('terraform.tfstate', {
   *   lookback: 5,
   *   includeDetails: true
   * });
   */
  async getDiffsWithLookback(sourceFile, options = {}) {
    if (!this.diffsResource) {
      throw new TfStateError("Diff tracking is not enabled for this plugin");
    }
    const lookback = options.lookback || this.diffsLookback;
    const includeDetails = options.includeDetails || false;
    const diffs = await this.diffsResource.query(
      { sourceFile },
      {
        limit: lookback,
        sort: { newSerial: -1 }
        // Newest first
      }
    );
    if (!includeDetails) {
      return diffs.map((diff) => ({
        id: diff.id,
        oldSerial: diff.oldSerial,
        newSerial: diff.newSerial,
        calculatedAt: diff.calculatedAt,
        summary: diff.summary
      }));
    }
    return diffs;
  }
  /**
   * Get diff timeline for a state file
   * Shows progression of changes over time
   * @param {string} sourceFile - Source file path
   * @param {Object} options - Query options
   * @param {number} options.lookback - Number of diffs to include in timeline
   * @returns {Promise<Object>} Timeline with statistics and diff history
   *
   * @example
   * const timeline = await plugin.getDiffTimeline('terraform.tfstate', { lookback: 20 });
   * console.log(timeline.summary); // Overall statistics
   * console.log(timeline.diffs); // Chronological diff history
   */
  async getDiffTimeline(sourceFile, options = {}) {
    const diffs = await this.getDiffsWithLookback(sourceFile, {
      ...options,
      includeDetails: false
    });
    const timeline = {
      sourceFile,
      totalDiffs: diffs.length,
      summary: {
        totalAdded: 0,
        totalModified: 0,
        totalDeleted: 0,
        serialRange: {
          oldest: diffs.length > 0 ? Math.min(...diffs.map((d) => d.oldSerial)) : null,
          newest: diffs.length > 0 ? Math.max(...diffs.map((d) => d.newSerial)) : null
        },
        timeRange: {
          first: diffs.length > 0 ? Math.min(...diffs.map((d) => d.calculatedAt)) : null,
          last: diffs.length > 0 ? Math.max(...diffs.map((d) => d.calculatedAt)) : null
        }
      },
      diffs: diffs.reverse()
      // Oldest first for timeline view
    };
    for (const diff of diffs) {
      if (diff.summary) {
        timeline.summary.totalAdded += diff.summary.addedCount || 0;
        timeline.summary.totalModified += diff.summary.modifiedCount || 0;
        timeline.summary.totalDeleted += diff.summary.deletedCount || 0;
      }
    }
    return timeline;
  }
  /**
   * Compare two specific state serials
   * @param {string} sourceFile - Source file path
   * @param {number} oldSerial - Old state serial
   * @param {number} newSerial - New state serial
   * @returns {Promise<Object>} Diff object or null if not found
   *
   * @example
   * const diff = await plugin.compareStates('terraform.tfstate', 5, 10);
   */
  async compareStates(sourceFile, oldSerial, newSerial) {
    if (!this.diffsResource) {
      throw new TfStateError("Diff tracking is not enabled for this plugin");
    }
    const diffs = await this.diffsResource.query({
      sourceFile,
      oldSerial,
      newSerial
    }, { limit: 1 });
    if (diffs.length === 0) {
      const [ok, err, result] = await tryFn(async () => {
        return await this._computeDiff(oldSerial, newSerial);
      });
      if (!ok) {
        throw new StateDiffError(oldSerial, newSerial, err);
      }
      result.sourceFile = sourceFile;
      result.oldSerial = oldSerial;
      result.newSerial = newSerial;
      return result;
    }
    return diffs[0];
  }
  /**
   * Trigger monitoring check manually
   * Useful for testing or on-demand synchronization
   * @returns {Promise<Object>} Monitoring result
   *
   * @example
   * const result = await plugin.triggerMonitoring();
   * console.log(`Processed ${result.newFiles} new files`);
   */
  async triggerMonitoring() {
    if (!this.driver) {
      throw new TfStateError("Driver not initialized. Use driver-based configuration to enable monitoring.");
    }
    return await this._monitorStateFiles();
  }
  /**
   * Get resources by type (uses partition for fast queries)
   * @param {string} type - Resource type (e.g., 'aws_instance')
   * @returns {Promise<Array>} Resources of the specified type
   *
   * @example
   * const ec2Instances = await plugin.getResourcesByType('aws_instance');
   */
  async getResourcesByType(type) {
    return await this.resource.listPartition({
      partition: "byType",
      partitionValues: { resourceType: type }
    });
  }
  /**
   * Get resources by provider (uses partition for fast queries)
   * @param {string} provider - Provider name (e.g., 'aws', 'google', 'azure')
   * @returns {Promise<Array>} Resources from the specified provider
   *
   * @example
   * const awsResources = await plugin.getResourcesByProvider('aws');
   */
  async getResourcesByProvider(provider) {
    return await this.resource.listPartition({
      partition: "byProvider",
      partitionValues: { providerName: provider }
    });
  }
  /**
   * Get resources by provider and type (uses partition for ultra-fast queries)
   * @param {string} provider - Provider name (e.g., 'aws')
   * @param {string} type - Resource type (e.g., 'aws_instance')
   * @returns {Promise<Array>} Resources matching both provider and type
   *
   * @example
   * const awsRds = await plugin.getResourcesByProviderAndType('aws', 'aws_db_instance');
   */
  async getResourcesByProviderAndType(provider, type) {
    return await this.resource.listPartition({
      partition: "byProviderAndType",
      partitionValues: {
        providerName: provider,
        resourceType: type
      }
    });
  }
  /**
   * Get diff between two state serials
   * Alias for compareStates() for API consistency
   * @param {string} sourceFile - Source file path
   * @param {number} oldSerial - Old state serial
   * @param {number} newSerial - New state serial
   * @returns {Promise<Object>} Diff object
   *
   * @example
   * const diff = await plugin.getDiff('terraform.tfstate', 1, 2);
   */
  async getDiff(sourceFile, oldSerial, newSerial) {
    return await this.compareStates(sourceFile, oldSerial, newSerial);
  }
  /**
   * Get statistics by provider
   * @returns {Promise<Object>} Provider counts { aws: 150, google: 30, ... }
   *
   * @example
   * const stats = await plugin.getStatsByProvider();
   * console.log(`AWS resources: ${stats.aws}`);
   */
  async getStatsByProvider() {
    const allResources = await this.resource.list({ limit: 1e5 });
    const providerCounts = {};
    for (const resource of allResources) {
      const provider = resource.providerName || "unknown";
      providerCounts[provider] = (providerCounts[provider] || 0) + 1;
    }
    return providerCounts;
  }
  /**
   * Get statistics by resource type
   * @returns {Promise<Object>} Type counts { aws_instance: 20, aws_s3_bucket: 50, ... }
   *
   * @example
   * const stats = await plugin.getStatsByType();
   * console.log(`EC2 instances: ${stats.aws_instance}`);
   */
  async getStatsByType() {
    const allResources = await this.resource.list({ limit: 1e5 });
    const typeCounts = {};
    for (const resource of allResources) {
      const type = resource.resourceType;
      typeCounts[type] = (typeCounts[type] || 0) + 1;
    }
    return typeCounts;
  }
  /**
   * Find partition by field name (for efficient queries)
   * Uses cache to avoid repeated lookups
   * @private
   */
  _findPartitionByField(resource, fieldName) {
    if (!resource.config.partitions) return null;
    const cacheKey = `${resource.name}:${fieldName}`;
    if (this._partitionCache.has(cacheKey)) {
      this.stats.partitionCacheHits++;
      return this._partitionCache.get(cacheKey);
    }
    let bestPartition = null;
    let bestFieldCount = Infinity;
    for (const [partitionName, partitionConfig] of Object.entries(resource.config.partitions)) {
      if (partitionConfig.fields && fieldName in partitionConfig.fields) {
        const fieldCount = Object.keys(partitionConfig.fields).length;
        if (fieldCount < bestFieldCount) {
          bestPartition = partitionName;
          bestFieldCount = fieldCount;
        }
      }
    }
    this._partitionCache.set(cacheKey, bestPartition);
    return bestPartition;
  }
  /**
   * Get plugin statistics
   * @returns {Promise<Object>} Statistics with provider/type breakdowns
   *
   * @example
   * const stats = await plugin.getStats();
   * console.log(`Total: ${stats.totalResources} resources`);
   * console.log(`Providers:`, stats.providers);
   */
  async getStats() {
    const stateFiles = await this.stateFilesResource.list({ limit: 1e5 });
    const allResources = await this.resource.list({ limit: 1e5 });
    const providers = {};
    const types = {};
    for (const resource of allResources) {
      const provider = resource.providerName || "unknown";
      const type = resource.resourceType;
      providers[provider] = (providers[provider] || 0) + 1;
      types[type] = (types[type] || 0) + 1;
    }
    const latestSerial = stateFiles.length > 0 ? Math.max(...stateFiles.map((sf) => sf.serial)) : null;
    const diffsCount = this.trackDiffs && this.diffsResource ? (await this.diffsResource.list({ limit: 1e5 })).length : 0;
    return {
      totalStates: stateFiles.length,
      totalResources: allResources.length,
      totalDiffs: diffsCount,
      latestSerial,
      providers,
      types,
      // Runtime stats
      statesProcessed: this.stats.statesProcessed,
      resourcesExtracted: this.stats.resourcesExtracted,
      resourcesInserted: this.stats.resourcesInserted,
      diffsCalculated: this.stats.diffsCalculated,
      errors: this.stats.errors,
      partitionCacheHits: this.stats.partitionCacheHits,
      partitionQueriesOptimized: this.stats.partitionQueriesOptimized
    };
  }
}

function cosineDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let dotProduct2 = 0;
  let normA = 0;
  let normB = 0;
  for (let i = 0; i < a.length; i++) {
    dotProduct2 += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  const denominator = Math.sqrt(normA) * Math.sqrt(normB);
  if (denominator === 0) {
    return a.every((v) => v === 0) && b.every((v) => v === 0) ? 0 : 1;
  }
  const similarity = dotProduct2 / denominator;
  return 1 - similarity;
}
function euclideanDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = a[i] - b[i];
    sum += diff * diff;
  }
  return Math.sqrt(sum);
}
function manhattanDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    sum += Math.abs(a[i] - b[i]);
  }
  return sum;
}
function dotProduct(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    sum += a[i] * b[i];
  }
  return sum;
}
function normalize(vector) {
  const magnitude2 = Math.sqrt(
    vector.reduce((sum, val) => sum + val * val, 0)
  );
  if (magnitude2 === 0) {
    return vector.slice();
  }
  return vector.map((val) => val / magnitude2);
}

function kmeans(vectors, k, options = {}) {
  const {
    maxIterations = 100,
    tolerance = 1e-4,
    distanceFn = euclideanDistance,
    seed = null,
    onIteration = null
  } = options;
  if (vectors.length === 0) {
    throw new Error("Cannot cluster empty vector array");
  }
  if (k < 1) {
    throw new Error(`k must be at least 1, got ${k}`);
  }
  if (k > vectors.length) {
    throw new Error(`k (${k}) cannot be greater than number of vectors (${vectors.length})`);
  }
  const dimensions = vectors[0].length;
  for (let i = 1; i < vectors.length; i++) {
    if (vectors[i].length !== dimensions) {
      throw new Error(`All vectors must have same dimensions. Expected ${dimensions}, got ${vectors[i].length} at index ${i}`);
    }
  }
  const centroids = initializeCentroidsKMeansPlusPlus(vectors, k, distanceFn, seed);
  let assignments = new Array(vectors.length);
  let iterations = 0;
  let converged = false;
  let previousInertia = Infinity;
  while (!converged && iterations < maxIterations) {
    const newAssignments = vectors.map((vector) => {
      let minDist = Infinity;
      let nearestCluster = 0;
      for (let i = 0; i < k; i++) {
        const dist = distanceFn(vector, centroids[i]);
        if (dist < minDist) {
          minDist = dist;
          nearestCluster = i;
        }
      }
      return nearestCluster;
    });
    let inertia2 = 0;
    vectors.forEach((vector, i) => {
      const dist = distanceFn(vector, centroids[newAssignments[i]]);
      inertia2 += dist * dist;
    });
    const inertiaChange = Math.abs(previousInertia - inertia2);
    converged = inertiaChange < tolerance;
    assignments = newAssignments;
    previousInertia = inertia2;
    if (onIteration) {
      onIteration(iterations + 1, inertia2, converged);
    }
    if (!converged) {
      const clusterSums = Array(k).fill(null).map(() => new Array(dimensions).fill(0));
      const clusterCounts = new Array(k).fill(0);
      vectors.forEach((vector, i) => {
        const cluster = assignments[i];
        clusterCounts[cluster]++;
        vector.forEach((val, j) => {
          clusterSums[cluster][j] += val;
        });
      });
      for (let i = 0; i < k; i++) {
        if (clusterCounts[i] > 0) {
          centroids[i] = clusterSums[i].map((sum) => sum / clusterCounts[i]);
        } else {
          const randomIdx = Math.floor(Math.random() * vectors.length);
          centroids[i] = [...vectors[randomIdx]];
        }
      }
    }
    iterations++;
  }
  let inertia = 0;
  vectors.forEach((vector, i) => {
    const dist = distanceFn(vector, centroids[assignments[i]]);
    inertia += dist * dist;
  });
  return {
    centroids,
    assignments,
    iterations,
    converged,
    inertia
  };
}
function initializeCentroidsKMeansPlusPlus(vectors, k, distanceFn, seed) {
  const centroids = [];
  const n = vectors.length;
  const firstIndex = seed !== null ? seed % n : Math.floor(Math.random() * n);
  centroids.push([...vectors[firstIndex]]);
  for (let i = 1; i < k; i++) {
    const distances = vectors.map((vector) => {
      return Math.min(...centroids.map((c) => distanceFn(vector, c)));
    });
    const squaredDistances = distances.map((d) => d * d);
    const totalSquared = squaredDistances.reduce((a, b) => a + b, 0);
    if (totalSquared === 0) {
      const randomIdx = Math.floor(Math.random() * n);
      centroids.push([...vectors[randomIdx]]);
      continue;
    }
    let threshold = Math.random() * totalSquared;
    let cumulativeSum = 0;
    for (let j = 0; j < n; j++) {
      cumulativeSum += squaredDistances[j];
      if (cumulativeSum >= threshold) {
        centroids.push([...vectors[j]]);
        break;
      }
    }
  }
  return centroids;
}
async function findOptimalK(vectors, options = {}) {
  const {
    minK = 2,
    maxK = Math.min(10, Math.floor(Math.sqrt(vectors.length / 2))),
    distanceFn = euclideanDistance,
    nReferences = 10,
    stabilityRuns = 5,
    ...kmeansOptions
  } = options;
  const metricsModule = await Promise.resolve().then(function () { return metrics; });
  const {
    silhouetteScore,
    daviesBouldinIndex,
    calinskiHarabaszIndex,
    gapStatistic,
    clusteringStability
  } = metricsModule;
  const results = [];
  for (let k = minK; k <= maxK; k++) {
    const kmeansResult = kmeans(vectors, k, { ...kmeansOptions, distanceFn });
    const silhouette = silhouetteScore(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const daviesBouldin = daviesBouldinIndex(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const calinskiHarabasz = calinskiHarabaszIndex(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const gap = await gapStatistic(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn,
      nReferences
    );
    const stability = clusteringStability(
      vectors,
      k,
      { ...kmeansOptions, distanceFn, nRuns: stabilityRuns }
    );
    results.push({
      k,
      inertia: kmeansResult.inertia,
      silhouette,
      daviesBouldin,
      calinskiHarabasz,
      gap: gap.gap,
      gapSk: gap.sk,
      stability: stability.stability,
      cvInertia: stability.cvInertia,
      iterations: kmeansResult.iterations,
      converged: kmeansResult.converged
    });
  }
  const elbowK = findElbowPoint(results.map((r) => r.inertia));
  const recommendations = {
    elbow: minK + elbowK,
    silhouette: results.reduce(
      (best, curr) => curr.silhouette > best.silhouette ? curr : best
    ).k,
    daviesBouldin: results.reduce(
      (best, curr) => curr.daviesBouldin < best.daviesBouldin ? curr : best
    ).k,
    calinskiHarabasz: results.reduce(
      (best, curr) => curr.calinskiHarabasz > best.calinskiHarabasz ? curr : best
    ).k,
    gap: results.reduce(
      (best, curr) => curr.gap > best.gap ? curr : best
    ).k,
    stability: results.reduce(
      (best, curr) => curr.stability > best.stability ? curr : best
    ).k
  };
  const votes = Object.values(recommendations);
  const consensus = votes.reduce((acc, k) => {
    acc[k] = (acc[k] || 0) + 1;
    return acc;
  }, {});
  const consensusK = parseInt(
    Object.entries(consensus).reduce((a, b) => b[1] > a[1] ? b : a)[0]
  );
  return {
    results,
    recommendations,
    consensus: consensusK,
    summary: {
      analysisRange: `${minK}-${maxK}`,
      totalVectors: vectors.length,
      dimensions: vectors[0].length,
      recommendation: consensusK,
      confidence: consensus[consensusK] / votes.length
    }
  };
}
function findElbowPoint(inertias) {
  const n = inertias.length;
  if (n < 3) return 0;
  let maxCurvature = -Infinity;
  let elbowIndex = 0;
  for (let i = 1; i < n - 1; i++) {
    const curvature = inertias[i - 1] - 2 * inertias[i] + inertias[i + 1];
    if (curvature > maxCurvature) {
      maxCurvature = curvature;
      elbowIndex = i;
    }
  }
  return elbowIndex;
}

class VectorError extends PluginError {
  constructor(message, details = {}) {
    super(message, {
      pluginName: "VectorPlugin",
      ...details,
      description: details.description || `
Vector Plugin Error

Operation: ${details.operation || "unknown"}

Common causes:
1. Vector dimension mismatch between vectors
2. Invalid distance metric specified (must be: cosine, euclidean, manhattan)
3. Empty vector array provided for clustering
4. k value larger than number of available vectors
5. Vector field not found or invalid in resource
6. Large vectors without proper behavior (use 'body-overflow' or 'body-only')

Available distance metrics:
- cosine: Best for normalized vectors, semantic similarity. Range: [0, 2]
- euclidean: Standard L2 distance, geometric proximity. Range: [0, \u221E)
- manhattan: L1 distance, faster computation. Range: [0, \u221E)

Storage considerations:
- Vectors > 250 dimensions may exceed S3 metadata limit (2KB)
- Use behavior: 'body-overflow' or 'body-only' for large vectors
- OpenAI ada-002 (1536 dims): ~10KB, requires body storage
- Sentence Transformers (384 dims): ~2.7KB, requires body storage
      `.trim()
    });
  }
}

class VectorPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      dimensions: 1536,
      // Default to OpenAI text-embedding-3-small/3-large
      distanceMetric: "cosine",
      // Default metric
      storageThreshold: 1500,
      // Bytes - warn if vectors exceed this
      autoFixBehavior: false,
      // Automatically set body-overflow
      autoDetectVectorField: true,
      // Auto-detect embedding:XXX fields
      emitEvents: true,
      // Emit events for monitoring
      verboseEvents: false,
      // Emit detailed progress events
      eventThrottle: 100,
      // Throttle progress events (ms)
      ...options
    };
    this.distanceFunctions = {
      cosine: cosineDistance,
      euclidean: euclideanDistance,
      manhattan: manhattanDistance
    };
    this._vectorFieldCache = /* @__PURE__ */ new Map();
    this._throttleState = /* @__PURE__ */ new Map();
  }
  async onInstall() {
    this.emit("db:plugin:installed", { plugin: "VectorPlugin" });
    this.validateVectorStorage();
    this.installResourceMethods();
  }
  async onStart() {
    this.emit("db:plugin:started", { plugin: "VectorPlugin" });
  }
  async onStop() {
    this.emit("db:plugin:stopped", { plugin: "VectorPlugin" });
  }
  async onUninstall(options) {
    for (const resource of Object.values(this.database.resources)) {
      delete resource.vectorSearch;
      delete resource.cluster;
      delete resource.vectorDistance;
      delete resource.similarTo;
      delete resource.findSimilar;
      delete resource.distance;
    }
    this.emit("db:plugin:uninstalled", { plugin: "VectorPlugin" });
  }
  /**
   * Validate vector storage configuration for all resources
   *
   * Detects large vector fields and warns if proper behavior is not set.
   * Can optionally auto-fix by setting body-overflow behavior.
   * Auto-creates partitions for optional embedding fields to enable O(1) filtering.
   */
  validateVectorStorage() {
    for (const resource of Object.values(this.database.resources)) {
      const vectorFields = this.findVectorFields(resource.schema.attributes);
      if (vectorFields.length === 0) continue;
      const totalVectorSize = vectorFields.reduce((sum, f) => sum + f.estimatedBytes, 0);
      if (totalVectorSize > this.config.storageThreshold) {
        const hasCorrectBehavior = ["body-overflow", "body-only"].includes(resource.behavior);
        if (!hasCorrectBehavior) {
          const warning = {
            resource: resource.name,
            vectorFields: vectorFields.map((f) => ({
              field: f.name,
              dimensions: f.length,
              estimatedBytes: f.estimatedBytes
            })),
            totalEstimatedBytes: totalVectorSize,
            metadataLimit: 2047,
            currentBehavior: resource.behavior || "default",
            recommendation: "body-overflow"
          };
          this.emit("plg:vector:storage-warning", warning);
          if (this.config.autoFixBehavior) {
            resource.behavior = "body-overflow";
            this.emit("plg:vector:behavior-fixed", {
              resource: resource.name,
              newBehavior: "body-overflow"
            });
          } else {
            console.warn(`\u26A0\uFE0F  VectorPlugin: Resource '${resource.name}' has large vector fields (${totalVectorSize} bytes estimated)`);
            console.warn(`   Current behavior: '${resource.behavior || "default"}'`);
            console.warn(`   Recommendation: Add behavior: 'body-overflow' or 'body-only' to resource configuration`);
            console.warn(`   Large vectors will exceed S3 metadata limit (2047 bytes) and cause errors.`);
          }
        }
      }
      this.setupEmbeddingPartitions(resource, vectorFields);
    }
  }
  /**
   * Setup automatic partitions for optional embedding fields
   *
   * Creates a partition that separates records with embeddings from those without.
   * This enables O(1) filtering instead of O(n) full scans when searching/clustering.
   *
   * @param {Resource} resource - Resource instance
   * @param {Array} vectorFields - Detected vector fields with metadata
   */
  setupEmbeddingPartitions(resource, vectorFields) {
    if (!resource.config) return;
    for (const vectorField of vectorFields) {
      const isOptional = this.isFieldOptional(resource.schema.attributes, vectorField.name);
      if (!isOptional) continue;
      const partitionName = `byHas${this.capitalize(vectorField.name.replace(/\./g, "_"))}`;
      const trackingFieldName = `_has${this.capitalize(vectorField.name.replace(/\./g, "_"))}`;
      if (resource.config.partitions && resource.config.partitions[partitionName]) {
        this.emit("plg:vector:partition-exists", {
          resource: resource.name,
          vectorField: vectorField.name,
          partition: partitionName,
          timestamp: Date.now()
        });
        continue;
      }
      if (!resource.config.partitions) {
        resource.config.partitions = {};
      }
      resource.config.partitions[partitionName] = {
        fields: {
          [trackingFieldName]: "boolean"
        }
      };
      if (!resource.schema.attributes[trackingFieldName]) {
        resource.addPluginAttribute(trackingFieldName, {
          type: "boolean",
          optional: true,
          default: false
        }, "VectorPlugin");
      }
      this.emit("plg:vector:partition-created", {
        resource: resource.name,
        vectorField: vectorField.name,
        partition: partitionName,
        trackingField: trackingFieldName,
        timestamp: Date.now()
      });
      console.log(`\u2705 VectorPlugin: Created partition '${partitionName}' for optional embedding field '${vectorField.name}' in resource '${resource.name}'`);
      this.installEmbeddingHooks(resource, vectorField.name, trackingFieldName);
    }
  }
  /**
   * Check if a field is optional in the schema
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} fieldPath - Field path (supports dot notation)
   * @returns {boolean} True if field is optional
   */
  isFieldOptional(attributes, fieldPath) {
    const parts = fieldPath.split(".");
    let current = attributes;
    for (let i = 0; i < parts.length; i++) {
      const part = parts[i];
      const attr = current[part];
      if (!attr) return true;
      if (typeof attr === "string") {
        const flags = attr.split("|");
        if (flags.includes("required")) return false;
        if (flags.includes("optional") || flags.some((f) => f.startsWith("optional:"))) return true;
        return !flags.includes("required");
      }
      if (typeof attr === "object") {
        if (i === parts.length - 1) {
          if (attr.optional === true) return true;
          if (attr.optional === false) return false;
          return attr.optional !== false;
        }
        if (attr.type === "object" && attr.props) {
          current = attr.props;
        } else {
          return true;
        }
      }
    }
    return true;
  }
  /**
   * Capitalize first letter of string
   *
   * @param {string} str - Input string
   * @returns {string} Capitalized string
   */
  capitalize(str) {
    return str.charAt(0).toUpperCase() + str.slice(1);
  }
  /**
   * Install hooks to maintain embedding partition tracking field
   *
   * @param {Resource} resource - Resource instance
   * @param {string} vectorField - Vector field name
   * @param {string} trackingField - Tracking field name
   */
  installEmbeddingHooks(resource, vectorField, trackingField) {
    resource.registerHook("beforeInsert", async (data) => {
      const hasVector = this.hasVectorValue(data, vectorField);
      this.setNestedValue(data, trackingField, hasVector);
      return data;
    });
    resource.registerHook("beforeUpdate", async (id, updates) => {
      if (vectorField in updates || this.hasNestedKey(updates, vectorField)) {
        const hasVector = this.hasVectorValue(updates, vectorField);
        this.setNestedValue(updates, trackingField, hasVector);
      }
      return updates;
    });
    this.emit("plg:vector:hooks-installed", {
      resource: resource.name,
      vectorField,
      trackingField,
      hooks: ["beforeInsert", "beforeUpdate"],
      timestamp: Date.now()
    });
  }
  /**
   * Check if data has a valid vector value for the given field
   *
   * @param {Object} data - Data object
   * @param {string} fieldPath - Field path (supports dot notation)
   * @returns {boolean} True if vector exists and is valid
   */
  hasVectorValue(data, fieldPath) {
    const value = this.getNestedValue(data, fieldPath);
    return value != null && Array.isArray(value) && value.length > 0;
  }
  /**
   * Check if object has a nested key
   *
   * @param {Object} obj - Object to check
   * @param {string} path - Dot-notation path
   * @returns {boolean} True if key exists
   */
  hasNestedKey(obj, path) {
    const parts = path.split(".");
    let current = obj;
    for (const part of parts) {
      if (current == null || typeof current !== "object") return false;
      if (!(part in current)) return false;
      current = current[part];
    }
    return true;
  }
  /**
   * Get nested value from object using dot notation
   *
   * @param {Object} obj - Object to traverse
   * @param {string} path - Dot-notation path
   * @returns {*} Value at path or undefined
   */
  getNestedValue(obj, path) {
    const parts = path.split(".");
    let current = obj;
    for (const part of parts) {
      if (current == null || typeof current !== "object") return void 0;
      current = current[part];
    }
    return current;
  }
  /**
   * Set nested value in object using dot notation
   *
   * @param {Object} obj - Object to modify
   * @param {string} path - Dot-notation path
   * @param {*} value - Value to set
   */
  setNestedValue(obj, path, value) {
    const parts = path.split(".");
    let current = obj;
    for (let i = 0; i < parts.length - 1; i++) {
      const part = parts[i];
      if (!(part in current) || typeof current[part] !== "object") {
        current[part] = {};
      }
      current = current[part];
    }
    current[parts[parts.length - 1]] = value;
  }
  /**
   * Get auto-created embedding partition for a vector field
   *
   * Returns partition configuration if an auto-partition exists for the given vector field.
   * Auto-partitions enable O(1) filtering to only records with embeddings.
   *
   * @param {Resource} resource - Resource instance
   * @param {string} vectorField - Vector field name
   * @returns {Object|null} Partition config or null
   */
  getAutoEmbeddingPartition(resource, vectorField) {
    if (!resource.config) return null;
    const partitionName = `byHas${this.capitalize(vectorField.replace(/\./g, "_"))}`;
    const trackingFieldName = `_has${this.capitalize(vectorField.replace(/\./g, "_"))}`;
    if (resource.config.partitions && resource.config.partitions[partitionName]) {
      return {
        partitionName,
        partitionValues: { [trackingFieldName]: true }
      };
    }
    return null;
  }
  /**
   * Auto-detect vector field from resource schema
   *
   * Looks for fields with type 'embedding:XXX' pattern.
   * Caches result per resource for performance.
   *
   * @param {Resource} resource - Resource instance
   * @returns {string|null} Detected vector field name or null
   */
  detectVectorField(resource) {
    if (this._vectorFieldCache.has(resource.name)) {
      return this._vectorFieldCache.get(resource.name);
    }
    const vectorField = this._findEmbeddingField(resource.schema.attributes);
    this._vectorFieldCache.set(resource.name, vectorField);
    if (vectorField && this.config.emitEvents) {
      this.emit("plg:vector:field-detected", {
        resource: resource.name,
        vectorField,
        timestamp: Date.now()
      });
    }
    return vectorField;
  }
  /**
   * Recursively find embedding:XXX field in attributes
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} path - Current path (for nested objects)
   * @returns {string|null} Field path or null
   */
  _findEmbeddingField(attributes, path = "") {
    for (const [key, attr] of Object.entries(attributes)) {
      const fullPath = path ? `${path}.${key}` : key;
      if (typeof attr === "string" && attr.startsWith("embedding:")) {
        return fullPath;
      }
      if (attr.type === "array" && attr.items === "number" && attr.length) {
        return fullPath;
      }
      if (attr.type === "object" && attr.props) {
        const nested = this._findEmbeddingField(attr.props, fullPath);
        if (nested) return nested;
      }
    }
    return null;
  }
  /**
   * Emit event with throttling support
   *
   * @param {string} eventName - Event name
   * @param {Object} data - Event data
   * @param {string} throttleKey - Unique key for throttling (optional)
   */
  _emitEvent(eventName, data, throttleKey = null) {
    if (!this.config.emitEvents) return;
    if (throttleKey) {
      const now = Date.now();
      const lastEmit = this._throttleState.get(throttleKey);
      if (lastEmit && now - lastEmit < this.config.eventThrottle) {
        return;
      }
      this._throttleState.set(throttleKey, now);
    }
    this.emit(eventName, data);
  }
  /**
   * Find vector fields in resource attributes
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} path - Current path (for nested objects)
   * @returns {Array} Array of vector field info
   */
  findVectorFields(attributes, path = "") {
    const vectors = [];
    for (const [key, attr] of Object.entries(attributes)) {
      const fullPath = path ? `${path}.${key}` : key;
      if (attr.type === "array" && attr.items === "number" && attr.length) {
        vectors.push({
          name: fullPath,
          length: attr.length,
          estimatedBytes: this.estimateVectorBytes(attr.length)
        });
      }
      if (attr.type === "object" && attr.props) {
        vectors.push(...this.findVectorFields(attr.props, fullPath));
      }
    }
    return vectors;
  }
  /**
   * Estimate bytes required to store a vector in JSON format
   *
   * Conservative estimate: ~7 bytes per number + array overhead
   *
   * @param {number} dimensions - Number of dimensions
   * @returns {number} Estimated bytes
   */
  estimateVectorBytes(dimensions) {
    return dimensions * 7 + 50;
  }
  /**
   * Install vector methods on all resources
   */
  installResourceMethods() {
    for (const resource of Object.values(this.database.resources)) {
      const searchMethod = this.createVectorSearchMethod(resource);
      const clusterMethod = this.createClusteringMethod(resource);
      const distanceMethod = this.createDistanceMethod();
      resource.vectorSearch = searchMethod;
      resource.cluster = clusterMethod;
      resource.vectorDistance = distanceMethod;
      resource.similarTo = searchMethod;
      resource.findSimilar = searchMethod;
      resource.distance = distanceMethod;
    }
  }
  /**
   * Create vector search method for a resource
   *
   * Performs K-nearest neighbors search to find similar vectors.
   *
   * @param {Resource} resource - Resource instance
   * @returns {Function} Vector search method
   */
  createVectorSearchMethod(resource) {
    return async (queryVector, options = {}) => {
      const startTime = Date.now();
      let vectorField = options.vectorField;
      if (!vectorField && this.config.autoDetectVectorField) {
        vectorField = this.detectVectorField(resource);
        if (!vectorField) {
          vectorField = "vector";
        }
      } else if (!vectorField) {
        vectorField = "vector";
      }
      let {
        limit = 10,
        distanceMetric = this.config.distanceMetric,
        threshold = null,
        partition = null,
        partitionValues = null
      } = options;
      const distanceFn = this.distanceFunctions[distanceMetric];
      if (!distanceFn) {
        const error = new VectorError(`Invalid distance metric: ${distanceMetric}`, {
          operation: "vectorSearch",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: distanceMetric
        });
        this._emitEvent("vector:search-error", {
          resource: resource.name,
          error: error.message,
          timestamp: Date.now()
        });
        throw error;
      }
      if (!partition) {
        const autoPartition = this.getAutoEmbeddingPartition(resource, vectorField);
        if (autoPartition) {
          partition = autoPartition.partitionName;
          partitionValues = autoPartition.partitionValues;
          this._emitEvent("vector:auto-partition-used", {
            resource: resource.name,
            vectorField,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
        }
      }
      this._emitEvent("vector:search-start", {
        resource: resource.name,
        vectorField,
        limit,
        distanceMetric,
        partition,
        partitionValues,
        threshold,
        queryDimensions: queryVector.length,
        timestamp: startTime
      });
      try {
        let allRecords;
        if (partition && partitionValues) {
          this._emitEvent("vector:partition-filter", {
            resource: resource.name,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
          allRecords = await resource.list({ partition, partitionValues });
        } else {
          allRecords = resource.getAll ? await resource.getAll() : await resource.list();
        }
        const totalRecords = allRecords.length;
        let processedRecords = 0;
        let dimensionMismatches = 0;
        if (!partition && totalRecords > 1e3) {
          const warning = {
            resource: resource.name,
            operation: "vectorSearch",
            totalRecords,
            vectorField,
            recommendation: "Use partitions to filter data before vector search for better performance"
          };
          this._emitEvent("vector:performance-warning", warning);
          console.warn(`\u26A0\uFE0F  VectorPlugin: Performing vectorSearch on ${totalRecords} records without partition filter`);
          console.warn(`   Resource: '${resource.name}'`);
          console.warn(`   Recommendation: Use partition parameter to reduce search space`);
          console.warn(`   Example: resource.vectorSearch(vector, { partition: 'byCategory', partitionValues: { category: 'books' } })`);
        }
        const results = allRecords.filter((record) => record[vectorField] && Array.isArray(record[vectorField])).map((record, index) => {
          try {
            const distance = distanceFn(queryVector, record[vectorField]);
            processedRecords++;
            if (this.config.verboseEvents && processedRecords % 100 === 0) {
              this._emitEvent("vector:search-progress", {
                resource: resource.name,
                processed: processedRecords,
                total: totalRecords,
                progress: processedRecords / totalRecords * 100,
                timestamp: Date.now()
              }, `search-${resource.name}`);
            }
            return { record, distance };
          } catch (err) {
            dimensionMismatches++;
            if (this.config.verboseEvents) {
              this._emitEvent("vector:dimension-mismatch", {
                resource: resource.name,
                recordIndex: index,
                expected: queryVector.length,
                got: record[vectorField]?.length,
                timestamp: Date.now()
              });
            }
            return null;
          }
        }).filter((result) => result !== null).filter((result) => threshold === null || result.distance <= threshold).sort((a, b) => a.distance - b.distance).slice(0, limit);
        const duration = Date.now() - startTime;
        const throughput = totalRecords / (duration / 1e3);
        this._emitEvent("vector:search-complete", {
          resource: resource.name,
          vectorField,
          resultsCount: results.length,
          totalRecords,
          processedRecords,
          dimensionMismatches,
          duration,
          throughput: throughput.toFixed(2),
          timestamp: Date.now()
        });
        if (this.config.verboseEvents) {
          this._emitEvent("vector:performance", {
            operation: "search",
            resource: resource.name,
            duration,
            throughput: throughput.toFixed(2),
            recordsPerSecond: (processedRecords / (duration / 1e3)).toFixed(2),
            timestamp: Date.now()
          });
        }
        return results;
      } catch (error) {
        this._emitEvent("vector:search-error", {
          resource: resource.name,
          error: error.message,
          stack: error.stack,
          timestamp: Date.now()
        });
        throw error;
      }
    };
  }
  /**
   * Create clustering method for a resource
   *
   * Performs k-means clustering on resource vectors.
   *
   * @param {Resource} resource - Resource instance
   * @returns {Function} Clustering method
   */
  createClusteringMethod(resource) {
    return async (options = {}) => {
      const startTime = Date.now();
      let vectorField = options.vectorField;
      if (!vectorField && this.config.autoDetectVectorField) {
        vectorField = this.detectVectorField(resource);
        if (!vectorField) {
          vectorField = "vector";
        }
      } else if (!vectorField) {
        vectorField = "vector";
      }
      let {
        k = 5,
        distanceMetric = this.config.distanceMetric,
        partition = null,
        partitionValues = null,
        ...kmeansOptions
      } = options;
      const distanceFn = this.distanceFunctions[distanceMetric];
      if (!distanceFn) {
        const error = new VectorError(`Invalid distance metric: ${distanceMetric}`, {
          operation: "cluster",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: distanceMetric
        });
        this._emitEvent("vector:cluster-error", {
          resource: resource.name,
          error: error.message,
          timestamp: Date.now()
        });
        throw error;
      }
      if (!partition) {
        const autoPartition = this.getAutoEmbeddingPartition(resource, vectorField);
        if (autoPartition) {
          partition = autoPartition.partitionName;
          partitionValues = autoPartition.partitionValues;
          this._emitEvent("vector:auto-partition-used", {
            resource: resource.name,
            vectorField,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
        }
      }
      this._emitEvent("vector:cluster-start", {
        resource: resource.name,
        vectorField,
        k,
        distanceMetric,
        partition,
        partitionValues,
        maxIterations: kmeansOptions.maxIterations || 100,
        timestamp: startTime
      });
      try {
        let allRecords;
        if (partition && partitionValues) {
          this._emitEvent("vector:partition-filter", {
            resource: resource.name,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
          allRecords = await resource.list({ partition, partitionValues });
        } else {
          allRecords = resource.getAll ? await resource.getAll() : await resource.list();
        }
        const recordsWithVectors = allRecords.filter(
          (record) => record[vectorField] && Array.isArray(record[vectorField])
        );
        if (!partition && allRecords.length > 1e3) {
          const warning = {
            resource: resource.name,
            operation: "cluster",
            totalRecords: allRecords.length,
            recordsWithVectors: recordsWithVectors.length,
            vectorField,
            recommendation: "Use partitions to filter data before clustering for better performance"
          };
          this._emitEvent("vector:performance-warning", warning);
          console.warn(`\u26A0\uFE0F  VectorPlugin: Performing clustering on ${allRecords.length} records without partition filter`);
          console.warn(`   Resource: '${resource.name}'`);
          console.warn(`   Records with vectors: ${recordsWithVectors.length}`);
          console.warn(`   Recommendation: Use partition parameter to reduce clustering space`);
          console.warn(`   Example: resource.cluster({ k: 5, partition: 'byCategory', partitionValues: { category: 'books' } })`);
        }
        if (recordsWithVectors.length === 0) {
          const error = new VectorError("No vectors found in resource", {
            operation: "cluster",
            resourceName: resource.name,
            vectorField
          });
          this._emitEvent("vector:empty-dataset", {
            resource: resource.name,
            vectorField,
            totalRecords: allRecords.length,
            timestamp: Date.now()
          });
          throw error;
        }
        const vectors = recordsWithVectors.map((record) => record[vectorField]);
        const result = kmeans(vectors, k, {
          ...kmeansOptions,
          distanceFn,
          onIteration: this.config.verboseEvents ? (iteration, inertia, converged) => {
            this._emitEvent("vector:cluster-iteration", {
              resource: resource.name,
              k,
              iteration,
              inertia,
              converged,
              timestamp: Date.now()
            }, `cluster-${resource.name}`);
          } : void 0
        });
        if (result.converged) {
          this._emitEvent("vector:cluster-converged", {
            resource: resource.name,
            k,
            iterations: result.iterations,
            inertia: result.inertia,
            timestamp: Date.now()
          });
        }
        const clusters = Array(k).fill(null).map(() => []);
        recordsWithVectors.forEach((record, i) => {
          const clusterIndex = result.assignments[i];
          clusters[clusterIndex].push(record);
        });
        const duration = Date.now() - startTime;
        const clusterSizes = clusters.map((c) => c.length);
        this._emitEvent("vector:cluster-complete", {
          resource: resource.name,
          vectorField,
          k,
          vectorCount: vectors.length,
          iterations: result.iterations,
          converged: result.converged,
          inertia: result.inertia,
          clusterSizes,
          duration,
          timestamp: Date.now()
        });
        if (this.config.verboseEvents) {
          this._emitEvent("vector:performance", {
            operation: "clustering",
            resource: resource.name,
            k,
            duration,
            iterationsPerSecond: (result.iterations / (duration / 1e3)).toFixed(2),
            vectorsPerSecond: (vectors.length / (duration / 1e3)).toFixed(2),
            timestamp: Date.now()
          });
        }
        return {
          clusters,
          centroids: result.centroids,
          inertia: result.inertia,
          iterations: result.iterations,
          converged: result.converged
        };
      } catch (error) {
        this._emitEvent("vector:cluster-error", {
          resource: resource.name,
          error: error.message,
          stack: error.stack,
          timestamp: Date.now()
        });
        throw error;
      }
    };
  }
  /**
   * Create distance calculation method
   *
   * @returns {Function} Distance method
   */
  createDistanceMethod() {
    return (vector1, vector2, metric = this.config.distanceMetric) => {
      const distanceFn = this.distanceFunctions[metric];
      if (!distanceFn) {
        throw new VectorError(`Invalid distance metric: ${metric}`, {
          operation: "vectorDistance",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: metric
        });
      }
      return distanceFn(vector1, vector2);
    };
  }
  /**
   * Static utility: Normalize vector
   *
   * @param {number[]} vector - Input vector
   * @returns {number[]} Normalized vector
   */
  static normalize(vector) {
    return normalize(vector);
  }
  /**
   * Static utility: Calculate dot product
   *
   * @param {number[]} vector1 - First vector
   * @param {number[]} vector2 - Second vector
   * @returns {number} Dot product
   */
  static dotProduct(vector1, vector2) {
    return dotProduct(vector1, vector2);
  }
  /**
   * Static utility: Find optimal K for clustering
   *
   * Analyzes clustering quality across a range of K values using
   * multiple evaluation metrics.
   *
   * @param {number[][]} vectors - Vectors to analyze
   * @param {Object} options - Configuration options
   * @returns {Promise<Object>} Analysis results with recommendations
   */
  static async findOptimalK(vectors, options) {
    return findOptimalK(vectors, options);
  }
}

class MemoryStorage {
  constructor(config = {}) {
    this.objects = /* @__PURE__ */ new Map();
    this.bucket = config.bucket || "s3db";
    this.enforceLimits = config.enforceLimits || false;
    this.metadataLimit = config.metadataLimit || 2048;
    this.maxObjectSize = config.maxObjectSize || 5 * 1024 * 1024 * 1024;
    this.persistPath = config.persistPath;
    this.autoPersist = config.autoPersist || false;
    this.verbose = config.verbose || false;
  }
  /**
   * Generate ETag (MD5 hash) for object body
   */
  _generateETag(body) {
    const buffer = Buffer.isBuffer(body) ? body : Buffer.from(body || "");
    return createHash("md5").update(buffer).digest("hex");
  }
  /**
   * Calculate metadata size in bytes
   */
  _calculateMetadataSize(metadata) {
    if (!metadata) return 0;
    let size = 0;
    for (const [key, value] of Object.entries(metadata)) {
      size += Buffer.byteLength(key, "utf8");
      size += Buffer.byteLength(String(value), "utf8");
    }
    return size;
  }
  /**
   * Validate limits if enforceLimits is enabled
   */
  _validateLimits(body, metadata) {
    if (!this.enforceLimits) return;
    const metadataSize = this._calculateMetadataSize(metadata);
    if (metadataSize > this.metadataLimit) {
      throw new MetadataLimitError("Metadata limit exceeded in memory storage", {
        bucket: this.bucket,
        totalSize: metadataSize,
        effectiveLimit: this.metadataLimit,
        operation: "put",
        retriable: false,
        suggestion: "Reduce metadata size or disable enforceLimits in MemoryClient configuration."
      });
    }
    const bodySize = Buffer.isBuffer(body) ? body.length : Buffer.byteLength(body || "", "utf8");
    if (bodySize > this.maxObjectSize) {
      throw new ResourceError("Object size exceeds in-memory limit", {
        bucket: this.bucket,
        operation: "put",
        size: bodySize,
        maxObjectSize: this.maxObjectSize,
        statusCode: 413,
        retriable: false,
        suggestion: "Store smaller objects or increase maxObjectSize when instantiating MemoryClient."
      });
    }
  }
  /**
   * Store an object
   */
  async put(key, { body, metadata, contentType, contentEncoding, contentLength, ifMatch, ifNoneMatch }) {
    this._validateLimits(body, metadata);
    const existing = this.objects.get(key);
    if (ifMatch !== void 0) {
      if (!existing || existing.etag !== ifMatch) {
        throw new ResourceError(`Precondition failed: ETag mismatch for key "${key}"`, {
          bucket: this.bucket,
          key,
          code: "PreconditionFailed",
          statusCode: 412,
          retriable: false,
          suggestion: "Fetch the latest object and retry with the current ETag in options.ifMatch."
        });
      }
    }
    if (ifNoneMatch !== void 0) {
      const targetValue = existing ? existing.etag : null;
      const shouldFail = ifNoneMatch === "*" && existing || ifNoneMatch !== "*" && existing && targetValue === ifNoneMatch;
      if (shouldFail) {
        throw new ResourceError(`Precondition failed: object already exists for key "${key}"`, {
          bucket: this.bucket,
          key,
          code: "PreconditionFailed",
          statusCode: 412,
          retriable: false,
          suggestion: 'Use ifNoneMatch: "*" only when the object should not exist or remove the conditional header.'
        });
      }
    }
    const buffer = Buffer.isBuffer(body) ? body : Buffer.from(body || "");
    const etag = this._generateETag(buffer);
    const lastModified = (/* @__PURE__ */ new Date()).toISOString();
    const size = buffer.length;
    const objectData = {
      body: buffer,
      metadata: metadata || {},
      contentType: contentType || "application/octet-stream",
      etag,
      lastModified,
      size,
      contentEncoding,
      contentLength: contentLength || size
    };
    this.objects.set(key, objectData);
    if (this.verbose) {
      console.log(`[MemoryStorage] PUT ${key} (${size} bytes, etag: ${etag})`);
    }
    if (this.autoPersist && this.persistPath) {
      await this.saveToDisk();
    }
    return {
      ETag: etag,
      VersionId: null,
      // Memory storage doesn't support versioning
      ServerSideEncryption: null,
      Location: `/${this.bucket}/${key}`
    };
  }
  /**
   * Retrieve an object
   */
  async get(key) {
    const obj = this.objects.get(key);
    if (!obj) {
      throw new ResourceError(`Object not found: ${key}`, {
        bucket: this.bucket,
        key,
        code: "NoSuchKey",
        statusCode: 404,
        retriable: false,
        suggestion: "Ensure the key exists before attempting to read it."
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] GET ${key} (${obj.size} bytes)`);
    }
    const bodyStream = Readable.from(obj.body);
    return {
      Body: bodyStream,
      Metadata: { ...obj.metadata },
      ContentType: obj.contentType,
      ContentLength: obj.size,
      ETag: obj.etag,
      LastModified: new Date(obj.lastModified),
      ContentEncoding: obj.contentEncoding
    };
  }
  /**
   * Get object metadata only (like S3 HeadObject)
   */
  async head(key) {
    const obj = this.objects.get(key);
    if (!obj) {
      throw new ResourceError(`Object not found: ${key}`, {
        bucket: this.bucket,
        key,
        code: "NoSuchKey",
        statusCode: 404,
        retriable: false,
        suggestion: "Ensure the key exists before attempting to read it."
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] HEAD ${key}`);
    }
    return {
      Metadata: { ...obj.metadata },
      ContentType: obj.contentType,
      ContentLength: obj.size,
      ETag: obj.etag,
      LastModified: new Date(obj.lastModified),
      ContentEncoding: obj.contentEncoding
    };
  }
  /**
   * Copy an object
   */
  async copy(from, to, { metadata, metadataDirective, contentType }) {
    const source = this.objects.get(from);
    if (!source) {
      throw new ResourceError(`Source object not found: ${from}`, {
        bucket: this.bucket,
        key: from,
        code: "NoSuchKey",
        statusCode: 404,
        retriable: false,
        suggestion: "Copy requires an existing source object. Verify the source key before retrying."
      });
    }
    let finalMetadata = { ...source.metadata };
    if (metadataDirective === "REPLACE" && metadata) {
      finalMetadata = metadata;
    } else if (metadata) {
      finalMetadata = { ...finalMetadata, ...metadata };
    }
    const result = await this.put(to, {
      body: source.body,
      metadata: finalMetadata,
      contentType: contentType || source.contentType,
      contentEncoding: source.contentEncoding
    });
    if (this.verbose) {
      console.log(`[MemoryStorage] COPY ${from} \u2192 ${to}`);
    }
    return result;
  }
  /**
   * Check if object exists
   */
  exists(key) {
    return this.objects.has(key);
  }
  /**
   * Delete an object
   */
  async delete(key) {
    const existed = this.objects.has(key);
    this.objects.delete(key);
    if (this.verbose) {
      console.log(`[MemoryStorage] DELETE ${key} (existed: ${existed})`);
    }
    if (this.autoPersist && this.persistPath) {
      await this.saveToDisk();
    }
    return {
      DeleteMarker: false,
      VersionId: null
    };
  }
  /**
   * Delete multiple objects (batch)
   */
  async deleteMultiple(keys) {
    const deleted = [];
    const errors = [];
    for (const key of keys) {
      try {
        await this.delete(key);
        deleted.push({ Key: key });
      } catch (error) {
        errors.push({
          Key: key,
          Code: error.name || "InternalError",
          Message: error.message
        });
      }
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] DELETE BATCH (${deleted.length} deleted, ${errors.length} errors)`);
    }
    return { Deleted: deleted, Errors: errors };
  }
  /**
   * List objects with prefix/delimiter support
   */
  async list({ prefix = "", delimiter = null, maxKeys = 1e3, continuationToken = null }) {
    const allKeys = Array.from(this.objects.keys());
    let filteredKeys = prefix ? allKeys.filter((key) => key.startsWith(prefix)) : allKeys;
    filteredKeys.sort();
    let startIndex = 0;
    if (continuationToken) {
      startIndex = parseInt(continuationToken) || 0;
    }
    const paginatedKeys = filteredKeys.slice(startIndex, startIndex + maxKeys);
    const isTruncated = startIndex + maxKeys < filteredKeys.length;
    const nextContinuationToken = isTruncated ? String(startIndex + maxKeys) : null;
    const commonPrefixes = /* @__PURE__ */ new Set();
    const contents = [];
    for (const key of paginatedKeys) {
      if (delimiter && prefix) {
        const suffix = key.substring(prefix.length);
        const delimiterIndex = suffix.indexOf(delimiter);
        if (delimiterIndex !== -1) {
          const commonPrefix = prefix + suffix.substring(0, delimiterIndex + 1);
          commonPrefixes.add(commonPrefix);
          continue;
        }
      }
      const obj = this.objects.get(key);
      contents.push({
        Key: key,
        Size: obj.size,
        LastModified: new Date(obj.lastModified),
        ETag: obj.etag,
        StorageClass: "STANDARD"
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] LIST prefix="${prefix}" (${contents.length} objects, ${commonPrefixes.size} prefixes)`);
    }
    return {
      Contents: contents,
      CommonPrefixes: Array.from(commonPrefixes).map((prefix2) => ({ Prefix: prefix2 })),
      IsTruncated: isTruncated,
      NextContinuationToken: nextContinuationToken,
      KeyCount: contents.length + commonPrefixes.size,
      MaxKeys: maxKeys,
      Prefix: prefix,
      Delimiter: delimiter
    };
  }
  /**
   * Create a snapshot of current state
   */
  snapshot() {
    const snapshot = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      bucket: this.bucket,
      objectCount: this.objects.size,
      objects: {}
    };
    for (const [key, obj] of this.objects.entries()) {
      snapshot.objects[key] = {
        body: obj.body.toString("base64"),
        metadata: obj.metadata,
        contentType: obj.contentType,
        etag: obj.etag,
        lastModified: obj.lastModified,
        size: obj.size,
        contentEncoding: obj.contentEncoding,
        contentLength: obj.contentLength
      };
    }
    return snapshot;
  }
  /**
   * Restore from a snapshot
   */
  restore(snapshot) {
    if (!snapshot || !snapshot.objects) {
      throw new ValidationError("Invalid snapshot format", {
        field: "snapshot",
        retriable: false,
        suggestion: "Provide the snapshot returned by MemoryStorage.snapshot() before calling restore()."
      });
    }
    this.objects.clear();
    for (const [key, obj] of Object.entries(snapshot.objects)) {
      this.objects.set(key, {
        body: Buffer.from(obj.body, "base64"),
        metadata: obj.metadata,
        contentType: obj.contentType,
        etag: obj.etag,
        lastModified: obj.lastModified,
        size: obj.size,
        contentEncoding: obj.contentEncoding,
        contentLength: obj.contentLength
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] Restored snapshot with ${this.objects.size} objects`);
    }
  }
  /**
   * Save current state to disk
   */
  async saveToDisk(customPath) {
    const path = customPath || this.persistPath;
    if (!path) {
      throw new ValidationError("No persist path configured", {
        field: "persistPath",
        retriable: false,
        suggestion: "Provide a persistPath when creating MemoryClient or pass a custom path to saveToDisk()."
      });
    }
    const snapshot = this.snapshot();
    const json = JSON.stringify(snapshot, null, 2);
    const [ok, err] = await tryFn(() => writeFile(path, json, "utf-8"));
    if (!ok) {
      throw new ResourceError(`Failed to save to disk: ${err.message}`, {
        bucket: this.bucket,
        operation: "saveToDisk",
        statusCode: 500,
        retriable: false,
        suggestion: "Check filesystem permissions and available disk space, then retry.",
        original: err
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] Saved ${this.objects.size} objects to ${path}`);
    }
    return path;
  }
  /**
   * Load state from disk
   */
  async loadFromDisk(customPath) {
    const path = customPath || this.persistPath;
    if (!path) {
      throw new ValidationError("No persist path configured", {
        field: "persistPath",
        retriable: false,
        suggestion: "Provide a persistPath when creating MemoryClient or pass a custom path to loadFromDisk()."
      });
    }
    const [ok, err, json] = await tryFn(() => readFile(path, "utf-8"));
    if (!ok) {
      throw new ResourceError(`Failed to load from disk: ${err.message}`, {
        bucket: this.bucket,
        operation: "loadFromDisk",
        statusCode: 500,
        retriable: false,
        suggestion: "Verify the file exists and is readable, then retry.",
        original: err
      });
    }
    const snapshot = JSON.parse(json);
    this.restore(snapshot);
    if (this.verbose) {
      console.log(`[MemoryStorage] Loaded ${this.objects.size} objects from ${path}`);
    }
    return snapshot;
  }
  /**
   * Get storage statistics
   */
  getStats() {
    let totalSize = 0;
    const keys = [];
    for (const [key, obj] of this.objects.entries()) {
      totalSize += obj.size;
      keys.push(key);
    }
    return {
      objectCount: this.objects.size,
      totalSize,
      totalSizeFormatted: this._formatBytes(totalSize),
      keys: keys.sort(),
      bucket: this.bucket
    };
  }
  /**
   * Format bytes for human reading
   */
  _formatBytes(bytes) {
    if (bytes === 0) return "0 Bytes";
    const k = 1024;
    const sizes = ["Bytes", "KB", "MB", "GB"];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return Math.round(bytes / Math.pow(k, i) * 100) / 100 + " " + sizes[i];
  }
  /**
   * Clear all objects
   */
  clear() {
    this.objects.clear();
    if (this.verbose) {
      console.log(`[MemoryStorage] Cleared all objects`);
    }
  }
}

class MemoryClient extends EventEmitter {
  constructor(config = {}) {
    super();
    this.id = config.id || idGenerator(77);
    this.verbose = config.verbose || false;
    this.parallelism = config.parallelism || 10;
    this.bucket = config.bucket || "s3db";
    this.keyPrefix = config.keyPrefix || "";
    this.region = config.region || "us-east-1";
    this.storage = new MemoryStorage({
      bucket: this.bucket,
      enforceLimits: config.enforceLimits || false,
      metadataLimit: config.metadataLimit || 2048,
      maxObjectSize: config.maxObjectSize || 5 * 1024 * 1024 * 1024,
      persistPath: config.persistPath,
      autoPersist: config.autoPersist || false,
      verbose: this.verbose
    });
    this.config = {
      bucket: this.bucket,
      keyPrefix: this.keyPrefix,
      region: this.region,
      endpoint: "memory://localhost",
      forcePathStyle: true
    };
    if (this.verbose) {
      console.log(`[MemoryClient] Initialized (id: ${this.id}, bucket: ${this.bucket})`);
    }
  }
  /**
   * Simulate sendCommand from AWS SDK
   * Used by Database/Resource to send AWS SDK commands
   */
  async sendCommand(command) {
    const commandName = command.constructor.name;
    const input = command.input || {};
    this.emit("cl:request", commandName, input);
    this.emit("command.request", commandName, input);
    let response;
    try {
      switch (commandName) {
        case "PutObjectCommand":
          response = await this._handlePutObject(input);
          break;
        case "GetObjectCommand":
          response = await this._handleGetObject(input);
          break;
        case "HeadObjectCommand":
          response = await this._handleHeadObject(input);
          break;
        case "CopyObjectCommand":
          response = await this._handleCopyObject(input);
          break;
        case "DeleteObjectCommand":
          response = await this._handleDeleteObject(input);
          break;
        case "DeleteObjectsCommand":
          response = await this._handleDeleteObjects(input);
          break;
        case "ListObjectsV2Command":
          response = await this._handleListObjects(input);
          break;
        default:
          throw new DatabaseError(`Unsupported command: ${commandName}`, {
            operation: "sendCommand",
            statusCode: 400,
            retriable: false,
            suggestion: "Use one of the supported commands: PutObject, GetObject, HeadObject, CopyObject, DeleteObject, DeleteObjects, or ListObjectsV2."
          });
      }
      this.emit("cl:response", commandName, response, input);
      this.emit("command.response", commandName, response, input);
      return response;
    } catch (error) {
      if (error instanceof BaseError) {
        throw error;
      }
      const mappedError = mapAwsError(error, {
        bucket: this.bucket,
        key: input.Key,
        commandName,
        commandInput: input
      });
      throw mappedError;
    }
  }
  /**
   * PutObjectCommand handler
   */
  async _handlePutObject(input) {
    const key = input.Key;
    const metadata = input.Metadata || {};
    const contentType = input.ContentType;
    const body = input.Body;
    const contentEncoding = input.ContentEncoding;
    const contentLength = input.ContentLength;
    const ifMatch = input.IfMatch;
    const ifNoneMatch = input.IfNoneMatch;
    return await this.storage.put(key, {
      body,
      metadata,
      contentType,
      contentEncoding,
      contentLength,
      ifMatch,
      ifNoneMatch
    });
  }
  /**
   * GetObjectCommand handler
   */
  async _handleGetObject(input) {
    const key = input.Key;
    return await this.storage.get(key);
  }
  /**
   * HeadObjectCommand handler
   */
  async _handleHeadObject(input) {
    const key = input.Key;
    return await this.storage.head(key);
  }
  /**
   * CopyObjectCommand handler
   */
  async _handleCopyObject(input) {
    const copySource = input.CopySource;
    const parts = copySource.split("/");
    const sourceKey = parts.slice(1).join("/");
    const destinationKey = input.Key;
    const metadata = input.Metadata;
    const metadataDirective = input.MetadataDirective;
    const contentType = input.ContentType;
    return await this.storage.copy(sourceKey, destinationKey, {
      metadata,
      metadataDirective,
      contentType
    });
  }
  /**
   * DeleteObjectCommand handler
   */
  async _handleDeleteObject(input) {
    const key = input.Key;
    return await this.storage.delete(key);
  }
  /**
   * DeleteObjectsCommand handler
   */
  async _handleDeleteObjects(input) {
    const objects = input.Delete?.Objects || [];
    const keys = objects.map((obj) => obj.Key);
    return await this.storage.deleteMultiple(keys);
  }
  /**
   * ListObjectsV2Command handler
   */
  async _handleListObjects(input) {
    const fullPrefix = this.keyPrefix && input.Prefix ? path.join(this.keyPrefix, input.Prefix) : this.keyPrefix || input.Prefix || "";
    return await this.storage.list({
      prefix: fullPrefix,
      delimiter: input.Delimiter,
      maxKeys: input.MaxKeys,
      continuationToken: input.ContinuationToken
    });
  }
  /**
   * Put an object (Client interface method)
   */
  async putObject({ key, metadata, contentType, body, contentEncoding, contentLength, ifMatch, ifNoneMatch }) {
    const fullKey = this.keyPrefix ? path.join(this.keyPrefix, key) : key;
    const stringMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        stringMetadata[validKey] = encoded;
      }
    }
    const response = await this.storage.put(fullKey, {
      body,
      metadata: stringMetadata,
      contentType,
      contentEncoding,
      contentLength,
      ifMatch,
      ifNoneMatch
    });
    this.emit("cl:PutObject", null, { key, metadata, contentType, body, contentEncoding, contentLength });
    return response;
  }
  /**
   * Get an object (Client interface method)
   */
  async getObject(key) {
    const fullKey = this.keyPrefix ? path.join(this.keyPrefix, key) : key;
    const response = await this.storage.get(fullKey);
    const decodedMetadata = {};
    if (response.Metadata) {
      for (const [k, v] of Object.entries(response.Metadata)) {
        decodedMetadata[k] = metadataDecode(v);
      }
    }
    this.emit("cl:GetObject", null, { key });
    return {
      ...response,
      Metadata: decodedMetadata
    };
  }
  /**
   * Head object (get metadata only)
   */
  async headObject(key) {
    const fullKey = this.keyPrefix ? path.join(this.keyPrefix, key) : key;
    const response = await this.storage.head(fullKey);
    const decodedMetadata = {};
    if (response.Metadata) {
      for (const [k, v] of Object.entries(response.Metadata)) {
        decodedMetadata[k] = metadataDecode(v);
      }
    }
    this.emit("cl:HeadObject", null, { key });
    return {
      ...response,
      Metadata: decodedMetadata
    };
  }
  /**
   * Copy an object
   */
  async copyObject({ from, to, metadata, metadataDirective, contentType }) {
    const fullFrom = this.keyPrefix ? path.join(this.keyPrefix, from) : from;
    const fullTo = this.keyPrefix ? path.join(this.keyPrefix, to) : to;
    const encodedMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        encodedMetadata[validKey] = encoded;
      }
    }
    const response = await this.storage.copy(fullFrom, fullTo, {
      metadata: encodedMetadata,
      metadataDirective,
      contentType
    });
    this.emit("cl:CopyObject", null, { from, to, metadata, metadataDirective });
    return response;
  }
  /**
   * Check if object exists
   */
  async exists(key) {
    const fullKey = this.keyPrefix ? path.join(this.keyPrefix, key) : key;
    return this.storage.exists(fullKey);
  }
  /**
   * Delete an object
   */
  async deleteObject(key) {
    const fullKey = this.keyPrefix ? path.join(this.keyPrefix, key) : key;
    const response = await this.storage.delete(fullKey);
    this.emit("cl:DeleteObject", null, { key });
    return response;
  }
  /**
   * Delete multiple objects (batch)
   */
  async deleteObjects(keys) {
    const fullKeys = keys.map(
      (key) => this.keyPrefix ? path.join(this.keyPrefix, key) : key
    );
    const batches = chunk(fullKeys, this.parallelism);
    const allResults = { Deleted: [], Errors: [] };
    const { results } = await PromisePool.withConcurrency(this.parallelism).for(batches).process(async (batch) => {
      return await this.storage.deleteMultiple(batch);
    });
    for (const result of results) {
      allResults.Deleted.push(...result.Deleted);
      allResults.Errors.push(...result.Errors);
    }
    this.emit("deleteObjects", null, { keys, count: allResults.Deleted.length });
    return allResults;
  }
  /**
   * List objects with pagination support
   */
  async listObjects({ prefix = "", delimiter = null, maxKeys = 1e3, continuationToken = null }) {
    const fullPrefix = this.keyPrefix ? path.join(this.keyPrefix, prefix) : prefix;
    const response = await this.storage.list({
      prefix: fullPrefix,
      delimiter,
      maxKeys,
      continuationToken
    });
    this.emit("cl:ListObjects", null, { prefix, count: response.Contents.length });
    return response;
  }
  /**
   * Get a page of keys with offset/limit pagination
   */
  async getKeysPage(params = {}) {
    const { prefix = "", offset = 0, amount = 100 } = params;
    let keys = [];
    let truncated = true;
    let continuationToken;
    if (offset > 0) {
      const fullPrefix = this.keyPrefix ? path.join(this.keyPrefix, prefix) : prefix;
      const response = await this.storage.list({
        prefix: fullPrefix,
        maxKeys: offset + amount
      });
      keys = response.Contents.map((x) => x.Key).slice(offset, offset + amount);
    } else {
      while (truncated) {
        const options = {
          prefix,
          continuationToken,
          maxKeys: amount - keys.length
        };
        const res = await this.listObjects(options);
        if (res.Contents) {
          keys = keys.concat(res.Contents.map((x) => x.Key));
        }
        truncated = res.IsTruncated || false;
        continuationToken = res.NextContinuationToken;
        if (keys.length >= amount) {
          keys = keys.slice(0, amount);
          break;
        }
      }
    }
    if (this.keyPrefix) {
      keys = keys.map((x) => x.replace(this.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace("/", "") : x);
    }
    this.emit("cl:GetKeysPage", keys, params);
    return keys;
  }
  /**
   * Get all keys with a given prefix
   */
  async getAllKeys({ prefix = "" }) {
    const fullPrefix = this.keyPrefix ? path.join(this.keyPrefix, prefix) : prefix;
    const response = await this.storage.list({
      prefix: fullPrefix,
      maxKeys: 1e5
      // Large number to get all
    });
    let keys = response.Contents.map((x) => x.Key);
    if (this.keyPrefix) {
      keys = keys.map((x) => x.replace(this.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace("/", "") : x);
    }
    this.emit("cl:GetAllKeys", keys, { prefix });
    return keys;
  }
  /**
   * Count total objects under a prefix
   */
  async count({ prefix = "" } = {}) {
    const keys = await this.getAllKeys({ prefix });
    const count = keys.length;
    this.emit("cl:Count", count, { prefix });
    return count;
  }
  /**
   * Delete all objects under a prefix
   */
  async deleteAll({ prefix = "" } = {}) {
    const keys = await this.getAllKeys({ prefix });
    let totalDeleted = 0;
    if (keys.length > 0) {
      const result = await this.deleteObjects(keys);
      totalDeleted = result.Deleted.length;
      this.emit("deleteAll", {
        prefix,
        batch: totalDeleted,
        total: totalDeleted
      });
    }
    this.emit("deleteAllComplete", {
      prefix,
      totalDeleted
    });
    return totalDeleted;
  }
  /**
   * Get continuation token after skipping offset items
   */
  async getContinuationTokenAfterOffset({ prefix = "", offset = 1e3 } = {}) {
    if (offset === 0) return null;
    const keys = await this.getAllKeys({ prefix });
    if (offset >= keys.length) {
      this.emit("cl:GetContinuationTokenAfterOffset", null, { prefix, offset });
      return null;
    }
    const token = keys[offset];
    this.emit("cl:GetContinuationTokenAfterOffset", token, { prefix, offset });
    return token;
  }
  /**
   * Move an object from one key to another
   */
  async moveObject({ from, to }) {
    await this.copyObject({ from, to, metadataDirective: "COPY" });
    await this.deleteObject(from);
  }
  /**
   * Move all objects from one prefix to another
   */
  async moveAllObjects({ prefixFrom, prefixTo }) {
    const keys = await this.getAllKeys({ prefix: prefixFrom });
    const results = [];
    const errors = [];
    for (const key of keys) {
      try {
        const to = key.replace(prefixFrom, prefixTo);
        await this.moveObject({ from: key, to });
        results.push(to);
      } catch (error) {
        errors.push({
          message: error.message,
          raw: error,
          key
        });
      }
    }
    this.emit("moveAllObjects", { results, errors });
    if (errors.length > 0) {
      const error = new Error("Some objects could not be moved");
      error.context = {
        bucket: this.bucket,
        operation: "moveAllObjects",
        prefixFrom,
        prefixTo,
        totalKeys: keys.length,
        failedCount: errors.length,
        successCount: results.length,
        errors
      };
      throw error;
    }
    return results;
  }
  /**
   * Create a snapshot of current storage state
   */
  snapshot() {
    return this.storage.snapshot();
  }
  /**
   * Restore from a snapshot
   */
  restore(snapshot) {
    return this.storage.restore(snapshot);
  }
  /**
   * Save current state to disk (persistence)
   */
  async saveToDisk(path2) {
    return await this.storage.saveToDisk(path2);
  }
  /**
   * Load state from disk
   */
  async loadFromDisk(path2) {
    return await this.storage.loadFromDisk(path2);
  }
  /**
   * Export to BackupPlugin-compatible format (s3db.json + JSONL files)
   * Compatible with BackupPlugin for easy migration
   *
   * @param {string} outputDir - Output directory path
   * @param {Object} options - Export options
   * @param {Array<string>} options.resources - Resource names to export (default: all)
   * @param {boolean} options.compress - Use gzip compression (default: true)
   * @param {Object} options.database - Database instance for schema metadata
   * @returns {Promise<Object>} Export manifest with file paths and stats
   */
  async exportBackup(outputDir, options = {}) {
    const { mkdir, writeFile } = await import('fs/promises');
    const zlib = await import('zlib');
    const { promisify } = await import('util');
    const gzip = promisify(zlib.gzip);
    await mkdir(outputDir, { recursive: true });
    const compress = options.compress !== false;
    const database = options.database;
    const resourceFilter = options.resources;
    const allKeys = await this.getAllKeys({});
    const resourceMap = /* @__PURE__ */ new Map();
    for (const key of allKeys) {
      const match = key.match(/^resource=([^/]+)\//);
      if (match) {
        const resourceName = match[1];
        if (!resourceFilter || resourceFilter.includes(resourceName)) {
          if (!resourceMap.has(resourceName)) {
            resourceMap.set(resourceName, []);
          }
          resourceMap.get(resourceName).push(key);
        }
      }
    }
    const exportedFiles = {};
    const resourceStats = {};
    for (const [resourceName, keys] of resourceMap.entries()) {
      const records = [];
      const resource = database && database.resources && database.resources[resourceName];
      for (const key of keys) {
        const idMatch = key.match(/\/id=([^/]+)/);
        const recordId = idMatch ? idMatch[1] : null;
        let record;
        if (resource && recordId) {
          try {
            record = await resource.get(recordId);
          } catch (err) {
            console.warn(`Failed to get record ${recordId} from resource ${resourceName}, using fallback`);
            record = null;
          }
        }
        if (!record) {
          const obj = await this.getObject(key);
          record = { ...obj.Metadata };
          if (recordId && !record.id) {
            record.id = recordId;
          }
          if (obj.Body) {
            const chunks = [];
            for await (const chunk2 of obj.Body) {
              chunks.push(chunk2);
            }
            const bodyBuffer = Buffer.concat(chunks);
            const bodyStr = bodyBuffer.toString("utf-8");
            if (bodyStr.startsWith("{") || bodyStr.startsWith("[")) {
              try {
                const bodyData = JSON.parse(bodyStr);
                Object.assign(record, bodyData);
              } catch {
                record._body = bodyStr;
              }
            } else if (bodyStr) {
              record._body = bodyStr;
            }
          }
        }
        records.push(record);
      }
      const jsonl = records.map((r) => JSON.stringify(r)).join("\n");
      const filename = compress ? `${resourceName}.jsonl.gz` : `${resourceName}.jsonl`;
      const filePath = `${outputDir}/${filename}`;
      if (compress) {
        const compressed = await gzip(jsonl);
        await writeFile(filePath, compressed);
      } else {
        await writeFile(filePath, jsonl, "utf-8");
      }
      exportedFiles[resourceName] = filePath;
      resourceStats[resourceName] = {
        recordCount: records.length,
        fileSize: compress ? (await gzip(jsonl)).length : Buffer.byteLength(jsonl)
      };
    }
    const s3dbMetadata = {
      version: "1.0",
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      bucket: this.bucket,
      keyPrefix: this.keyPrefix || "",
      compressed: compress,
      resources: {},
      totalRecords: 0,
      totalSize: 0
    };
    if (database && database.resources) {
      for (const [resourceName, resource] of Object.entries(database.resources)) {
        if (resourceMap.has(resourceName)) {
          s3dbMetadata.resources[resourceName] = {
            schema: resource.schema ? {
              attributes: resource.schema.attributes,
              partitions: resource.schema.partitions,
              behavior: resource.schema.behavior,
              timestamps: resource.schema.timestamps
            } : null,
            stats: resourceStats[resourceName]
          };
        }
      }
    } else {
      for (const [resourceName, stats] of Object.entries(resourceStats)) {
        s3dbMetadata.resources[resourceName] = { stats };
      }
    }
    for (const stats of Object.values(resourceStats)) {
      s3dbMetadata.totalRecords += stats.recordCount;
      s3dbMetadata.totalSize += stats.fileSize;
    }
    const s3dbPath = `${outputDir}/s3db.json`;
    await writeFile(s3dbPath, JSON.stringify(s3dbMetadata, null, 2), "utf-8");
    return {
      manifest: s3dbPath,
      files: exportedFiles,
      stats: s3dbMetadata,
      resourceCount: resourceMap.size,
      totalRecords: s3dbMetadata.totalRecords,
      totalSize: s3dbMetadata.totalSize
    };
  }
  /**
   * Import from BackupPlugin-compatible format
   * Loads data from s3db.json + JSONL files created by BackupPlugin or exportBackup()
   *
   * @param {string} backupDir - Backup directory path containing s3db.json
   * @param {Object} options - Import options
   * @param {Array<string>} options.resources - Resource names to import (default: all)
   * @param {boolean} options.clear - Clear existing data first (default: false)
   * @param {Object} options.database - Database instance to recreate schemas
   * @returns {Promise<Object>} Import stats
   */
  async importBackup(backupDir, options = {}) {
    const { readFile, readdir } = await import('fs/promises');
    const zlib = await import('zlib');
    const { promisify } = await import('util');
    const gunzip = promisify(zlib.gunzip);
    if (options.clear) {
      this.clear();
    }
    const s3dbPath = `${backupDir}/s3db.json`;
    const s3dbContent = await readFile(s3dbPath, "utf-8");
    const metadata = JSON.parse(s3dbContent);
    const database = options.database;
    const resourceFilter = options.resources;
    const importStats = {
      resourcesImported: 0,
      recordsImported: 0,
      errors: []
    };
    if (database && metadata.resources) {
      for (const [resourceName, resourceMeta] of Object.entries(metadata.resources)) {
        if (resourceFilter && !resourceFilter.includes(resourceName)) continue;
        if (resourceMeta.schema) {
          try {
            await database.createResource({
              name: resourceName,
              ...resourceMeta.schema
            });
          } catch (error) {
          }
        }
      }
    }
    const files = await readdir(backupDir);
    for (const file of files) {
      if (!file.endsWith(".jsonl") && !file.endsWith(".jsonl.gz")) continue;
      const resourceName = file.replace(/\.jsonl(\.gz)?$/, "");
      if (resourceFilter && !resourceFilter.includes(resourceName)) continue;
      const filePath = `${backupDir}/${file}`;
      let content = await readFile(filePath);
      if (file.endsWith(".gz")) {
        content = await gunzip(content);
      }
      const jsonl = content.toString("utf-8");
      const lines = jsonl.split("\n").filter((line) => line.trim());
      for (const line of lines) {
        try {
          const record = JSON.parse(line);
          const id = record.id || record._id || `imported_${Date.now()}_${Math.random()}`;
          const { _body, id: _, _id: __, ...metadata2 } = record;
          await this.putObject({
            key: `resource=${resourceName}/id=${id}`,
            metadata: metadata2,
            body: _body ? Buffer.from(_body) : void 0
          });
          importStats.recordsImported++;
        } catch (error) {
          importStats.errors.push({
            resource: resourceName,
            error: error.message,
            line
          });
        }
      }
      importStats.resourcesImported++;
    }
    return importStats;
  }
  /**
   * Get storage statistics
   */
  getStats() {
    return this.storage.getStats();
  }
  /**
   * Clear all objects
   */
  clear() {
    this.storage.clear();
  }
}

function mapFieldTypeToTypeScript(fieldType) {
  const baseType = fieldType.split("|")[0].trim();
  const typeMap = {
    "string": "string",
    "number": "number",
    "integer": "number",
    "boolean": "boolean",
    "array": "any[]",
    "object": "Record<string, any>",
    "json": "Record<string, any>",
    "secret": "string",
    "email": "string",
    "url": "string",
    "date": "string",
    // ISO date string
    "datetime": "string",
    // ISO datetime string
    "ip4": "string",
    "ip6": "string"
  };
  if (baseType.startsWith("embedding:")) {
    const dimensions = parseInt(baseType.split(":")[1]);
    return `number[] /* ${dimensions} dimensions */`;
  }
  return typeMap[baseType] || "any";
}
function isFieldRequired(fieldDef) {
  if (typeof fieldDef === "string") {
    return fieldDef.includes("|required");
  }
  if (typeof fieldDef === "object" && fieldDef.required) {
    return true;
  }
  return false;
}
function generateResourceInterface(resourceName, attributes, timestamps = false) {
  const interfaceName = toPascalCase(resourceName);
  const lines = [];
  lines.push(`export interface ${interfaceName} {`);
  lines.push(`  /** Resource ID (auto-generated) */`);
  lines.push(`  id: string;`);
  lines.push("");
  for (const [fieldName, fieldDef] of Object.entries(attributes)) {
    const required = isFieldRequired(fieldDef);
    const optional = required ? "" : "?";
    let tsType;
    if (typeof fieldDef === "string") {
      tsType = mapFieldTypeToTypeScript(fieldDef);
    } else if (typeof fieldDef === "object" && fieldDef.type) {
      tsType = mapFieldTypeToTypeScript(fieldDef.type);
      if (fieldDef.type === "object" && fieldDef.props) {
        tsType = "{\n";
        for (const [propName, propDef] of Object.entries(fieldDef.props)) {
          const propType = typeof propDef === "string" ? mapFieldTypeToTypeScript(propDef) : mapFieldTypeToTypeScript(propDef.type);
          const propRequired = isFieldRequired(propDef);
          tsType += `    ${propName}${propRequired ? "" : "?"}: ${propType};
`;
        }
        tsType += "  }";
      }
      if (fieldDef.type === "array" && fieldDef.items) {
        const itemType = mapFieldTypeToTypeScript(fieldDef.items);
        tsType = `Array<${itemType}>`;
      }
    } else {
      tsType = "any";
    }
    if (fieldDef.description) {
      lines.push(`  /** ${fieldDef.description} */`);
    }
    lines.push(`  ${fieldName}${optional}: ${tsType};`);
  }
  if (timestamps) {
    lines.push("");
    lines.push(`  /** Creation timestamp (ISO 8601) */`);
    lines.push(`  createdAt: string;`);
    lines.push(`  /** Last update timestamp (ISO 8601) */`);
    lines.push(`  updatedAt: string;`);
  }
  lines.push("}");
  lines.push("");
  return lines.join("\n");
}
function toPascalCase(str) {
  return str.split(/[_-]/).map((word) => word.charAt(0).toUpperCase() + word.slice(1)).join("");
}
async function generateTypes(database, options = {}) {
  const {
    outputPath = "./types/database.d.ts",
    moduleName = "s3db.js",
    includeResource = true
  } = options;
  const lines = [];
  lines.push("/**");
  lines.push(" * Auto-generated TypeScript definitions for s3db.js resources");
  lines.push(" * Generated at: " + (/* @__PURE__ */ new Date()).toISOString());
  lines.push(" * DO NOT EDIT - This file is auto-generated");
  lines.push(" */");
  lines.push("");
  if (includeResource) {
    lines.push(`import { Resource, Database } from '${moduleName}';`);
    lines.push("");
  }
  const resourceInterfaces = [];
  for (const [name, resource] of Object.entries(database.resources)) {
    const allAttributes = resource.config?.attributes || resource.attributes || {};
    const timestamps = resource.config?.timestamps || false;
    const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
    const userAttributes = Object.fromEntries(
      Object.entries(allAttributes).filter(([name2]) => !pluginAttrNames.includes(name2))
    );
    const interfaceDef = generateResourceInterface(name, userAttributes, timestamps);
    lines.push(interfaceDef);
    resourceInterfaces.push({
      name,
      interfaceName: toPascalCase(name),
      resource
    });
  }
  lines.push("/**");
  lines.push(" * Typed resource map for property access");
  lines.push(" * @example");
  lines.push(" * const users = db.resources.users; // Type-safe!");
  lines.push(' * const user = await users.get("id"); // Autocomplete works!');
  lines.push(" */");
  lines.push("export interface ResourceMap {");
  for (const { name, interfaceName } of resourceInterfaces) {
    lines.push(`  /** ${interfaceName} resource */`);
    if (includeResource) {
      lines.push(`  ${name}: Resource<${interfaceName}>;`);
    } else {
      lines.push(`  ${name}: any;`);
    }
  }
  lines.push("}");
  lines.push("");
  if (includeResource) {
    lines.push("/**");
    lines.push(" * Extended Database class with typed resources");
    lines.push(" */");
    lines.push("declare module 's3db.js' {");
    lines.push("  interface Database {");
    lines.push("    resources: ResourceMap;");
    lines.push("  }");
    lines.push("");
    lines.push("  interface Resource<T = any> {");
    lines.push("    get(id: string): Promise<T>;");
    lines.push("    getOrNull(id: string): Promise<T | null>;");
    lines.push("    getOrThrow(id: string): Promise<T>;");
    lines.push("    insert(data: Partial<T>): Promise<T>;");
    lines.push("    update(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    patch(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    replace(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    delete(id: string): Promise<void>;");
    lines.push("    list(options?: any): Promise<T[]>;");
    lines.push("    query(filters: Partial<T>, options?: any): Promise<T[]>;");
    lines.push("    validate(data: Partial<T>, options?: any): Promise<{ valid: boolean; errors: any[]; data: T | null }>;");
    lines.push("  }");
    lines.push("}");
  }
  const content = lines.join("\n");
  if (outputPath) {
    await mkdir(dirname(outputPath), { recursive: true });
    await writeFile(outputPath, content, "utf-8");
  }
  return content;
}
async function printTypes(database, options = {}) {
  const types = await generateTypes(database, { ...options, outputPath: null });
  console.log(types);
  return types;
}

class Factory {
  /**
   * Global sequence counter
   * @private
   */
  static _sequences = /* @__PURE__ */ new Map();
  /**
   * Registered factories
   * @private
   */
  static _factories = /* @__PURE__ */ new Map();
  /**
   * Database instance (set globally)
   * @private
   */
  static _database = null;
  /**
   * Create a new factory definition
   * @param {string} resourceName - Resource name
   * @param {Object|Function} definition - Field definitions or function
   * @param {Object} options - Factory options
   * @returns {Factory} Factory instance
   */
  static define(resourceName, definition, options = {}) {
    const factory = new Factory(resourceName, definition, options);
    Factory._factories.set(resourceName, factory);
    return factory;
  }
  /**
   * Set global database instance
   * @param {Database} database - s3db.js Database instance
   */
  static setDatabase(database) {
    Factory._database = database;
  }
  /**
   * Get factory by resource name
   * @param {string} resourceName - Resource name
   * @returns {Factory} Factory instance
   */
  static get(resourceName) {
    return Factory._factories.get(resourceName);
  }
  /**
   * Reset all sequences
   */
  static resetSequences() {
    Factory._sequences.clear();
  }
  /**
   * Reset all factories
   */
  static reset() {
    Factory._sequences.clear();
    Factory._factories.clear();
    Factory._database = null;
  }
  /**
   * Constructor
   * @param {string} resourceName - Resource name
   * @param {Object|Function} definition - Field definitions
   * @param {Object} options - Factory options
   */
  constructor(resourceName, definition, options = {}) {
    this.resourceName = resourceName;
    this.definition = definition;
    this.options = options;
    this.traits = /* @__PURE__ */ new Map();
    this.afterCreateCallbacks = [];
    this.beforeCreateCallbacks = [];
  }
  /**
   * Get next sequence number
   * @param {string} name - Sequence name (default: factory name)
   * @returns {number} Next sequence number
   */
  sequence(name = this.resourceName) {
    const current = Factory._sequences.get(name) || 0;
    const next = current + 1;
    Factory._sequences.set(name, next);
    return next;
  }
  /**
   * Define a trait (state variation)
   * @param {string} name - Trait name
   * @param {Object|Function} attributes - Trait attributes
   * @returns {Factory} This factory (for chaining)
   */
  trait(name, attributes) {
    this.traits.set(name, attributes);
    return this;
  }
  /**
   * Register after create callback
   * @param {Function} callback - Callback function
   * @returns {Factory} This factory (for chaining)
   */
  afterCreate(callback) {
    this.afterCreateCallbacks.push(callback);
    return this;
  }
  /**
   * Register before create callback
   * @param {Function} callback - Callback function
   * @returns {Factory} This factory (for chaining)
   */
  beforeCreate(callback) {
    this.beforeCreateCallbacks.push(callback);
    return this;
  }
  /**
   * Build attributes without creating in database
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object>} Built attributes
   */
  async build(overrides = {}, options = {}) {
    const { traits = [] } = options;
    const seq = this.sequence();
    let attributes = typeof this.definition === "function" ? await this.definition({ seq, factory: this }) : { ...this.definition };
    for (const traitName of traits) {
      const trait = this.traits.get(traitName);
      if (!trait) {
        throw new ValidationError(`Trait '${traitName}' not found in factory '${this.resourceName}'`, {
          field: "trait",
          value: traitName,
          resourceName: this.resourceName,
          retriable: false,
          suggestion: `Define the trait with Factory.define('${this.resourceName}').trait('${traitName}', ...) before using it.`
        });
      }
      const traitAttrs = typeof trait === "function" ? await trait({ seq, factory: this }) : trait;
      attributes = { ...attributes, ...traitAttrs };
    }
    attributes = { ...attributes, ...overrides };
    for (const [key, value] of Object.entries(attributes)) {
      if (typeof value === "function") {
        attributes[key] = await value({ seq, factory: this });
      }
    }
    return attributes;
  }
  /**
   * Create resource in database
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object>} Created resource
   */
  async create(overrides = {}, options = {}) {
    const { database = Factory._database } = options;
    if (!database) {
      throw new ValidationError("Database not set for factory", {
        field: "database",
        retriable: false,
        suggestion: "Call Factory.setDatabase(db) globally or pass { database } when invoking create()."
      });
    }
    let attributes = await this.build(overrides, options);
    for (const callback of this.beforeCreateCallbacks) {
      attributes = await callback(attributes) || attributes;
    }
    const resource = database.resources[this.resourceName];
    if (!resource) {
      throw new ValidationError(`Resource '${this.resourceName}' not found in database`, {
        field: "resourceName",
        value: this.resourceName,
        retriable: false,
        suggestion: `Ensure the resource is created in the database before using Factory '${this.resourceName}'.`
      });
    }
    let created = await resource.insert(attributes);
    for (const callback of this.afterCreateCallbacks) {
      created = await callback(created, { database }) || created;
    }
    return created;
  }
  /**
   * Create multiple resources
   * @param {number} count - Number of resources to create
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object[]>} Created resources
   */
  async createMany(count, overrides = {}, options = {}) {
    const resources = [];
    for (let i = 0; i < count; i++) {
      const resource = await this.create(overrides, options);
      resources.push(resource);
    }
    return resources;
  }
  /**
   * Build multiple resources without creating
   * @param {number} count - Number of resources to build
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object[]>} Built resources
   */
  async buildMany(count, overrides = {}, options = {}) {
    const resources = [];
    for (let i = 0; i < count; i++) {
      const resource = await this.build(overrides, options);
      resources.push(resource);
    }
    return resources;
  }
  /**
   * Create with specific traits
   * @param {string|string[]} traits - Trait name(s)
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object>} Created resource
   */
  async createWithTraits(traits, overrides = {}, options = {}) {
    const traitArray = Array.isArray(traits) ? traits : [traits];
    return this.create(overrides, { ...options, traits: traitArray });
  }
  /**
   * Build with specific traits
   * @param {string|string[]} traits - Trait name(s)
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object>} Built resource
   */
  async buildWithTraits(traits, overrides = {}, options = {}) {
    const traitArray = Array.isArray(traits) ? traits : [traits];
    return this.build(overrides, { ...options, traits: traitArray });
  }
}

class Seeder {
  /**
   * Constructor
   * @param {Database} database - s3db.js Database instance
   * @param {Object} options - Seeder options
   */
  constructor(database, options = {}) {
    this.database = database;
    this.options = options;
    this.verbose = options.verbose !== false;
  }
  /**
   * Log message (if verbose)
   * @param {string} message - Message to log
   * @private
   */
  log(message) {
    if (this.verbose) {
      console.log(`[Seeder] ${message}`);
    }
  }
  /**
   * Seed resources using factories
   * @param {Object} specs - Seed specifications { resourceName: count }
   * @returns {Promise<Object>} Created resources by resource name
   *
   * @example
   * const created = await seeder.seed({
   *   users: 10,
   *   posts: 50
   * });
   */
  async seed(specs) {
    const created = {};
    for (const [resourceName, count] of Object.entries(specs)) {
      this.log(`Seeding ${count} ${resourceName}...`);
      const factory = Factory.get(resourceName);
      if (!factory) {
        throw new ValidationError(`Factory for '${resourceName}' not found`, {
          field: "resourceName",
          value: resourceName,
          retriable: false,
          suggestion: `Register a factory with Factory.define('${resourceName}', ...) before seeding.`
        });
      }
      created[resourceName] = await factory.createMany(count, {}, { database: this.database });
      this.log(`\u2705 Created ${count} ${resourceName}`);
    }
    return created;
  }
  /**
   * Seed with custom callback
   * @param {Function} callback - Seeding callback
   * @returns {Promise<any>} Result of callback
   *
   * @example
   * await seeder.call(async (db) => {
   *   const user = await UserFactory.create();
   *   const posts = await PostFactory.createMany(5, { userId: user.id });
   *   return { user, posts };
   * });
   */
  async call(callback) {
    this.log("Running custom seeder...");
    const result = await callback(this.database);
    this.log("\u2705 Custom seeder completed");
    return result;
  }
  /**
   * Truncate resources (delete all data)
   * @param {string[]} resourceNames - Resource names to truncate
   * @returns {Promise<void>}
   *
   * @example
   * await seeder.truncate(['users', 'posts']);
   */
  async truncate(resourceNames) {
    for (const resourceName of resourceNames) {
      this.log(`Truncating ${resourceName}...`);
      const resource = this.database.resources[resourceName];
      if (!resource) {
        this.log(`\u26A0\uFE0F  Resource '${resourceName}' not found, skipping`);
        continue;
      }
      const ids = await resource.listIds();
      if (ids.length > 0) {
        await resource.deleteMany(ids);
        this.log(`\u2705 Deleted ${ids.length} ${resourceName}`);
      } else {
        this.log(`\u2705 ${resourceName} already empty`);
      }
    }
  }
  /**
   * Truncate all resources
   * @returns {Promise<void>}
   */
  async truncateAll() {
    const resourceNames = Object.keys(this.database.resources);
    await this.truncate(resourceNames);
  }
  /**
   * Run multiple seeders in order
   * @param {Function[]} seeders - Array of seeder functions
   * @returns {Promise<Object[]>} Results of each seeder
   *
   * @example
   * await seeder.run([
   *   async (db) => await UserFactory.createMany(10),
   *   async (db) => await PostFactory.createMany(50)
   * ]);
   */
  async run(seeders) {
    const results = [];
    for (const seederFn of seeders) {
      this.log(`Running seeder ${seederFn.name || "anonymous"}...`);
      const result = await seederFn(this.database);
      results.push(result);
      this.log(`\u2705 Completed ${seederFn.name || "anonymous"}`);
    }
    return results;
  }
  /**
   * Seed and return specific resources
   * @param {Object} specs - Seed specifications
   * @returns {Promise<Object>} Created resources
   *
   * @example
   * const { users, posts } = await seeder.seedAndReturn({
   *   users: 5,
   *   posts: 10
   * });
   */
  async seedAndReturn(specs) {
    return await this.seed(specs);
  }
  /**
   * Reset database (truncate all and reset sequences)
   * @returns {Promise<void>}
   */
  async reset() {
    this.log("Resetting database...");
    await this.truncateAll();
    Factory.resetSequences();
    this.log("\u2705 Database reset complete");
  }
}

// src/middleware/cors/index.ts
var cors = (options) => {
  const defaults = {
    origin: "*",
    allowMethods: ["GET", "HEAD", "PUT", "POST", "DELETE", "PATCH"],
    allowHeaders: [],
    exposeHeaders: []
  };
  const opts = {
    ...defaults,
    ...options
  };
  const findAllowOrigin = ((optsOrigin) => {
    if (typeof optsOrigin === "string") {
      if (optsOrigin === "*") {
        return () => optsOrigin;
      } else {
        return (origin) => optsOrigin === origin ? origin : null;
      }
    } else if (typeof optsOrigin === "function") {
      return optsOrigin;
    } else {
      return (origin) => optsOrigin.includes(origin) ? origin : null;
    }
  })(opts.origin);
  const findAllowMethods = ((optsAllowMethods) => {
    if (typeof optsAllowMethods === "function") {
      return optsAllowMethods;
    } else if (Array.isArray(optsAllowMethods)) {
      return () => optsAllowMethods;
    } else {
      return () => [];
    }
  })(opts.allowMethods);
  return async function cors2(c, next) {
    function set(key, value) {
      c.res.headers.set(key, value);
    }
    const allowOrigin = await findAllowOrigin(c.req.header("origin") || "", c);
    if (allowOrigin) {
      set("Access-Control-Allow-Origin", allowOrigin);
    }
    if (opts.credentials) {
      set("Access-Control-Allow-Credentials", "true");
    }
    if (opts.exposeHeaders?.length) {
      set("Access-Control-Expose-Headers", opts.exposeHeaders.join(","));
    }
    if (c.req.method === "OPTIONS") {
      if (opts.origin !== "*") {
        set("Vary", "Origin");
      }
      if (opts.maxAge != null) {
        set("Access-Control-Max-Age", opts.maxAge.toString());
      }
      const allowMethods = await findAllowMethods(c.req.header("origin") || "", c);
      if (allowMethods.length) {
        set("Access-Control-Allow-Methods", allowMethods.join(","));
      }
      let headers = opts.allowHeaders;
      if (!headers?.length) {
        const requestHeaders = c.req.header("Access-Control-Request-Headers");
        if (requestHeaders) {
          headers = requestHeaders.split(/\s*,\s*/);
        }
      }
      if (headers?.length) {
        set("Access-Control-Allow-Headers", headers.join(","));
        c.res.headers.append("Vary", "Access-Control-Request-Headers");
      }
      c.res.headers.delete("Content-Length");
      c.res.headers.delete("Content-Type");
      return new Response(null, {
        headers: c.res.headers,
        status: 204,
        statusText: "No Content"
      });
    }
    await next();
    if (opts.origin !== "*") {
      c.header("Vary", "Origin", { append: true });
    }
  };
};

var index = /*#__PURE__*/Object.freeze({
  __proto__: null,
  cors: cors
});

function generateToken(bytes = 32, encoding = "hex") {
  const buffer = randomBytes(bytes);
  switch (encoding) {
    case "hex":
      return buffer.toString("hex");
    case "base64":
      return buffer.toString("base64");
    case "base64url":
      return buffer.toString("base64url");
    default:
      throw new Error(`Invalid encoding: ${encoding}. Use 'hex', 'base64', or 'base64url'.`);
  }
}
function generatePasswordResetToken() {
  return generateToken(32, "hex");
}
function generateSessionId() {
  return idGenerator();
}
function calculateExpiration(duration) {
  let ms;
  if (typeof duration === "number") {
    ms = duration;
  } else if (typeof duration === "string") {
    const match = duration.match(/^(\d+)([smhd])$/);
    if (!match) {
      throw new Error(`Invalid duration format: ${duration}. Use '15m', '1h', '7d', etc.`);
    }
    const value = parseInt(match[1], 10);
    const unit = match[2];
    switch (unit) {
      case "s":
        ms = value * 1e3;
        break;
      // seconds
      case "m":
        ms = value * 60 * 1e3;
        break;
      // minutes
      case "h":
        ms = value * 60 * 60 * 1e3;
        break;
      // hours
      case "d":
        ms = value * 24 * 60 * 60 * 1e3;
        break;
      // days
      default:
        throw new Error(`Invalid duration unit: ${unit}`);
    }
  } else {
    throw new Error("Duration must be a string or number");
  }
  return Date.now() + ms;
}
function isExpired(expiresAt) {
  if (!expiresAt) {
    return true;
  }
  const timestamp = typeof expiresAt === "string" ? new Date(expiresAt).getTime() : expiresAt;
  return Date.now() > timestamp;
}

const DEFAULT_CONFIG = {
  sessionExpiry: "24h",
  // Default: 24 hours
  cookieName: "s3db_session",
  // Cookie name
  cookiePath: "/",
  // Cookie path
  cookieHttpOnly: true,
  // HTTP-only cookie (no JS access)
  cookieSecure: false,
  // Secure cookie (HTTPS only) - set to true in production
  cookieSameSite: "Lax",
  // SameSite attribute ('Strict', 'Lax', 'None')
  cleanupInterval: 36e5,
  // Cleanup interval: 1 hour (in ms)
  enableCleanup: true
  // Enable automatic cleanup
};
class SessionManager {
  /**
   * Create Session Manager
   * @param {Object} options - Configuration options
   * @param {Object} options.sessionResource - S3DB sessions resource
   * @param {Object} [options.config] - Session configuration
   */
  constructor(options = {}) {
    this.sessionResource = options.sessionResource;
    this.config = { ...DEFAULT_CONFIG, ...options.config };
    this.cleanupTimer = null;
    if (!this.sessionResource) {
      throw new PluginError("SessionManager requires a sessionResource", {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.constructor",
        statusCode: 400,
        retriable: false,
        suggestion: "Pass { sessionResource } when initializing IdentityPlugin or SessionManager."
      });
    }
    if (this.config.enableCleanup) {
      this._startCleanup();
    }
  }
  /**
   * Create a new session
   * @param {Object} data - Session data
   * @param {string} data.userId - User ID
   * @param {Object} [data.metadata] - Additional session metadata
   * @param {string} [data.ipAddress] - Client IP address
   * @param {string} [data.userAgent] - Client user agent
   * @param {string} [duration] - Session duration (overrides default)
   * @returns {Promise<{sessionId: string, expiresAt: number, session: Object}>}
   */
  async createSession(data) {
    const { userId, metadata = {}, ipAddress, userAgent, duration } = data;
    if (!userId) {
      throw new PluginError("userId is required to create a session", {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.createSession",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide data.userId when calling createSession()."
      });
    }
    generateSessionId();
    const expiresAt = calculateExpiration(duration || this.config.sessionExpiry);
    const sessionData = {
      userId,
      expiresAt: new Date(expiresAt).toISOString(),
      ipAddress: ipAddress || null,
      userAgent: userAgent || null,
      metadata,
      createdAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    const [ok, err, session] = await tryFn(
      () => this.sessionResource.insert(sessionData)
    );
    if (!ok) {
      throw new PluginError(`Failed to create session: ${err.message}`, {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.createSession",
        statusCode: 500,
        retriable: false,
        suggestion: "Check session resource permissions and database connectivity.",
        original: err
      });
    }
    return {
      sessionId: session.id,
      // S3DB auto-generated ID
      expiresAt,
      session
    };
  }
  /**
   * Validate a session
   * @param {string} sessionId - Session ID to validate
   * @returns {Promise<{valid: boolean, session: Object|null, reason: string|null}>}
   */
  async validateSession(sessionId) {
    if (!sessionId) {
      return { valid: false, session: null, reason: "No session ID provided" };
    }
    const [ok, err, session] = await tryFn(
      () => this.sessionResource.get(sessionId)
    );
    if (!ok || !session) {
      return { valid: false, session: null, reason: "Session not found" };
    }
    if (isExpired(session.expiresAt)) {
      await this.destroySession(sessionId);
      return { valid: false, session: null, reason: "Session expired" };
    }
    return { valid: true, session, reason: null };
  }
  /**
   * Get session data without validation
   * @param {string} sessionId - Session ID
   * @returns {Promise<Object|null>} Session object or null
   */
  async getSession(sessionId) {
    if (!sessionId) {
      return null;
    }
    const [ok, , session] = await tryFn(
      () => this.sessionResource.get(sessionId)
    );
    return ok ? session : null;
  }
  /**
   * Update session metadata
   * @param {string} sessionId - Session ID
   * @param {Object} metadata - New metadata to merge
   * @returns {Promise<Object>} Updated session
   */
  async updateSession(sessionId, metadata) {
    if (!sessionId) {
      throw new PluginError("sessionId is required", {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.updateSession",
        statusCode: 400,
        retriable: false,
        suggestion: "Provide a sessionId when calling updateSession()."
      });
    }
    const session = await this.getSession(sessionId);
    if (!session) {
      throw new PluginError("Session not found", {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.updateSession",
        statusCode: 404,
        retriable: false,
        suggestion: "Ensure the session exists before updating metadata.",
        sessionId
      });
    }
    const updatedMetadata = { ...session.metadata, ...metadata };
    const [ok, err, updated] = await tryFn(
      () => this.sessionResource.update(sessionId, {
        metadata: updatedMetadata
      })
    );
    if (!ok) {
      throw new PluginError(`Failed to update session: ${err.message}`, {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.updateSession",
        statusCode: 500,
        retriable: false,
        suggestion: "Check session resource permissions and database connectivity.",
        original: err
      });
    }
    return updated;
  }
  /**
   * Destroy a session (logout)
   * @param {string} sessionId - Session ID to destroy
   * @returns {Promise<boolean>} True if session was destroyed
   */
  async destroySession(sessionId) {
    if (!sessionId) {
      return false;
    }
    const [ok] = await tryFn(
      () => this.sessionResource.delete(sessionId)
    );
    return ok;
  }
  /**
   * Destroy all sessions for a user (logout all devices)
   * @param {string} userId - User ID
   * @returns {Promise<number>} Number of sessions destroyed
   */
  async destroyUserSessions(userId) {
    if (!userId) {
      return 0;
    }
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.query({ userId })
    );
    if (!ok || !sessions || sessions.length === 0) {
      return 0;
    }
    let count = 0;
    for (const session of sessions) {
      const destroyed = await this.destroySession(session.id);
      if (destroyed) count++;
    }
    return count;
  }
  /**
   * Get all active sessions for a user
   * @param {string} userId - User ID
   * @returns {Promise<Array>} Array of active sessions
   */
  async getUserSessions(userId) {
    if (!userId) {
      return [];
    }
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.query({ userId })
    );
    if (!ok || !sessions) {
      return [];
    }
    const activeSessions = [];
    for (const session of sessions) {
      if (!isExpired(session.expiresAt)) {
        activeSessions.push(session);
      } else {
        await this.destroySession(session.id);
      }
    }
    return activeSessions;
  }
  /**
   * Set session cookie in HTTP response
   * @param {Object} res - HTTP response object (Express/Hono style)
   * @param {string} sessionId - Session ID
   * @param {number} expiresAt - Expiration timestamp (Unix ms)
   */
  setSessionCookie(res, sessionId, expiresAt) {
    const expires = new Date(expiresAt);
    const cookieOptions = [
      `${this.config.cookieName}=${sessionId}`,
      `Path=${this.config.cookiePath}`,
      `Expires=${expires.toUTCString()}`,
      `Max-Age=${Math.floor((expiresAt - Date.now()) / 1e3)}`
    ];
    if (this.config.cookieHttpOnly) {
      cookieOptions.push("HttpOnly");
    }
    if (this.config.cookieSecure) {
      cookieOptions.push("Secure");
    }
    if (this.config.cookieSameSite) {
      cookieOptions.push(`SameSite=${this.config.cookieSameSite}`);
    }
    const cookieValue = cookieOptions.join("; ");
    if (typeof res.setHeader === "function") {
      res.setHeader("Set-Cookie", cookieValue);
    } else if (typeof res.header === "function") {
      res.header("Set-Cookie", cookieValue);
    } else {
      throw new PluginError("Unsupported response object for session cookies", {
        pluginName: "IdentityPlugin",
        operation: "SessionManager.setSessionCookie",
        statusCode: 400,
        retriable: false,
        suggestion: "Pass an HTTP response object that implements setHeader() or header()."
      });
    }
  }
  /**
   * Clear session cookie in HTTP response
   * @param {Object} res - HTTP response object
   */
  clearSessionCookie(res) {
    const cookieOptions = [
      `${this.config.cookieName}=`,
      `Path=${this.config.cookiePath}`,
      "Expires=Thu, 01 Jan 1970 00:00:00 GMT",
      "Max-Age=0"
    ];
    if (this.config.cookieHttpOnly) {
      cookieOptions.push("HttpOnly");
    }
    if (this.config.cookieSecure) {
      cookieOptions.push("Secure");
    }
    if (this.config.cookieSameSite) {
      cookieOptions.push(`SameSite=${this.config.cookieSameSite}`);
    }
    const cookieValue = cookieOptions.join("; ");
    if (typeof res.setHeader === "function") {
      res.setHeader("Set-Cookie", cookieValue);
    } else if (typeof res.header === "function") {
      res.header("Set-Cookie", cookieValue);
    }
  }
  /**
   * Get session ID from HTTP request cookies
   * @param {Object} req - HTTP request object
   * @returns {string|null} Session ID or null
   */
  getSessionIdFromRequest(req) {
    const cookieHeader = req.headers?.cookie || req.header?.("cookie");
    if (!cookieHeader) {
      return null;
    }
    const cookies = cookieHeader.split(";").reduce((acc, cookie) => {
      const [key, value] = cookie.trim().split("=");
      acc[key] = value;
      return acc;
    }, {});
    return cookies[this.config.cookieName] || null;
  }
  /**
   * Cleanup expired sessions
   * @returns {Promise<number>} Number of sessions cleaned up
   */
  async cleanupExpiredSessions() {
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.list({ limit: 1e3 })
    );
    if (!ok || !sessions) {
      return 0;
    }
    let count = 0;
    for (const session of sessions) {
      if (isExpired(session.expiresAt)) {
        const destroyed = await this.destroySession(session.id);
        if (destroyed) count++;
      }
    }
    return count;
  }
  /**
   * Start automatic cleanup of expired sessions
   * @private
   */
  _startCleanup() {
    if (this.cleanupTimer) {
      return;
    }
    this.cleanupTimer = setInterval(async () => {
      try {
        const count = await this.cleanupExpiredSessions();
        if (count > 0) {
          console.log(`[SessionManager] Cleaned up ${count} expired sessions`);
        }
      } catch (error) {
        console.error("[SessionManager] Cleanup error:", error.message);
      }
    }, this.config.cleanupInterval);
  }
  /**
   * Stop automatic cleanup
   */
  stopCleanup() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
  }
  /**
   * Get session statistics
   * @returns {Promise<Object>} Session statistics
   */
  async getStatistics() {
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.list({ limit: 1e4 })
    );
    if (!ok || !sessions) {
      return {
        total: 0,
        active: 0,
        expired: 0,
        users: 0
      };
    }
    let active = 0;
    let expired = 0;
    const uniqueUsers = /* @__PURE__ */ new Set();
    for (const session of sessions) {
      if (isExpired(session.expiresAt)) {
        expired++;
      } else {
        active++;
        uniqueUsers.add(session.userId);
      }
    }
    return {
      total: sessions.length,
      active,
      expired,
      users: uniqueUsers.size
    };
  }
}

var sessionManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  SessionManager: SessionManager
});

class EmailService {
  /**
   * Create Email Service instance
   * @param {Object} options - Email service configuration
   */
  constructor(options = {}) {
    this.config = {
      enabled: options.enabled !== false,
      from: options.from || "noreply@s3db.identity",
      replyTo: options.replyTo || null,
      // SMTP configuration
      smtp: {
        host: options.smtp?.host || "localhost",
        port: options.smtp?.port || 587,
        secure: options.smtp?.secure || false,
        // true for 465, false for other ports
        auth: {
          user: options.smtp?.auth?.user || "",
          pass: options.smtp?.auth?.pass || ""
        },
        // Optional TLS options
        tls: {
          rejectUnauthorized: options.smtp?.tls?.rejectUnauthorized !== false
        }
      },
      // Template configuration
      templates: {
        baseUrl: options.templates?.baseUrl || "http://localhost:4000",
        brandName: options.templates?.brandName || "S3DB Identity",
        brandLogo: options.templates?.brandLogo || null,
        brandColor: options.templates?.brandColor || "#007bff",
        supportEmail: options.templates?.supportEmail || null,
        customFooter: options.templates?.customFooter || null
      },
      verbose: options.verbose || false
    };
    this.transporter = null;
    this.initialized = false;
  }
  /**
   * Initialize email service (lazy initialization)
   * @private
   */
  async _initialize() {
    if (this.initialized || !this.config.enabled) {
      return;
    }
    try {
      const nodemailer = await import('nodemailer');
      this.transporter = nodemailer.default.createTransport({
        host: this.config.smtp.host,
        port: this.config.smtp.port,
        secure: this.config.smtp.secure,
        auth: this.config.smtp.auth,
        tls: this.config.smtp.tls
      });
      if (this.config.verbose) {
        await this.transporter.verify();
        console.log("[EmailService] SMTP connection verified");
      }
      this.initialized = true;
    } catch (error) {
      console.error("[EmailService] Failed to initialize:", error);
      throw new Error(`Failed to initialize email service: ${error.message}`);
    }
  }
  /**
   * Send an email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email address
   * @param {string} options.subject - Email subject
   * @param {string} options.html - HTML email body
   * @param {string} [options.text] - Plain text email body (fallback)
   * @param {string} [options.from] - Override sender address
   * @param {string} [options.replyTo] - Reply-to address
   * @returns {Promise<Object>} Send result
   */
  async sendEmail(options) {
    if (!this.config.enabled) {
      if (this.config.verbose) {
        console.log("[EmailService] Email service disabled, skipping send");
      }
      return { success: false, reason: "disabled" };
    }
    if (!this.initialized) {
      await this._initialize();
    }
    const { to, subject, html, text, from, replyTo } = options;
    if (!to || !subject || !html) {
      throw new Error("Email requires to, subject, and html fields");
    }
    try {
      const info = await this.transporter.sendMail({
        from: from || this.config.from,
        to,
        subject,
        text: text || this._htmlToText(html),
        html,
        replyTo: replyTo || this.config.replyTo
      });
      if (this.config.verbose) {
        console.log("[EmailService] Email sent successfully:", info.messageId);
      }
      return {
        success: true,
        messageId: info.messageId,
        accepted: info.accepted,
        rejected: info.rejected
      };
    } catch (error) {
      console.error("[EmailService] Failed to send email:", error);
      return {
        success: false,
        error: error.message
      };
    }
  }
  /**
   * Convert HTML to plain text (simple implementation)
   * @param {string} html - HTML content
   * @returns {string} Plain text
   * @private
   */
  _htmlToText(html) {
    return html.replace(/<br\s*\/?>/gi, "\n").replace(/<\/p>/gi, "\n\n").replace(/<[^>]+>/g, "").replace(/&nbsp;/g, " ").replace(/&amp;/g, "&").replace(/&lt;/g, "<").replace(/&gt;/g, ">").replace(/&quot;/g, '"').trim();
  }
  /**
   * Base email template wrapper
   * @param {Object} options - Template options
   * @param {string} options.title - Email title
   * @param {string} options.preheader - Email preheader (preview text)
   * @param {string} options.content - Email content (HTML)
   * @returns {string} HTML email
   * @private
   */
  _baseTemplate({ title, preheader, content }) {
    const { brandName, brandLogo, brandColor, supportEmail, customFooter } = this.config.templates;
    return `<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${title}</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      line-height: 1.6;
      color: #333;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
    }
    .email-wrapper {
      max-width: 600px;
      margin: 0 auto;
      background-color: #ffffff;
    }
    .email-header {
      background-color: ${brandColor};
      padding: 30px 20px;
      text-align: center;
    }
    .email-header h1 {
      color: #ffffff;
      margin: 0;
      font-size: 24px;
    }
    .email-body {
      padding: 40px 20px;
    }
    .email-footer {
      background-color: #f8f9fa;
      padding: 20px;
      text-align: center;
      font-size: 12px;
      color: #6c757d;
      border-top: 1px solid #dee2e6;
    }
    .button {
      display: inline-block;
      padding: 12px 30px;
      background-color: ${brandColor};
      color: #ffffff !important;
      text-decoration: none;
      border-radius: 4px;
      font-weight: 500;
      margin: 20px 0;
    }
    .button:hover {
      background-color: ${brandColor}dd;
    }
    .info-box {
      background-color: #f8f9fa;
      border-left: 4px solid ${brandColor};
      padding: 15px;
      margin: 20px 0;
    }
    .preheader {
      display: none;
      font-size: 1px;
      color: #ffffff;
      line-height: 1px;
      max-height: 0;
      max-width: 0;
      opacity: 0;
      overflow: hidden;
    }
  </style>
</head>
<body>
  <span class="preheader">${preheader || ""}</span>
  <div class="email-wrapper">
    <div class="email-header">
      ${brandLogo ? `<img src="${brandLogo}" alt="${brandName}" height="40" style="margin-bottom: 10px;">` : ""}
      <h1>${brandName}</h1>
    </div>
    <div class="email-body">
      ${content}
    </div>
    <div class="email-footer">
      ${customFooter || `
        <p>This email was sent from ${brandName}</p>
        ${supportEmail ? `<p>Need help? Contact us at <a href="mailto:${supportEmail}">${supportEmail}</a></p>` : ""}
        <p>&copy; ${(/* @__PURE__ */ new Date()).getFullYear()} ${brandName}. All rights reserved.</p>
      `}
    </div>
  </div>
</body>
</html>`;
  }
  /**
   * Send password reset email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @param {string} options.resetToken - Password reset token
   * @param {number} [options.expiresIn] - Token expiration in minutes (default: 60)
   * @returns {Promise<Object>} Send result
   */
  async sendPasswordResetEmail({ to, name, resetToken, expiresIn = 60 }) {
    const { baseUrl } = this.config.templates;
    const resetUrl = `${baseUrl}/reset-password?token=${resetToken}`;
    const content = `
      <h2>Password Reset Request</h2>
      <p>Hi ${name},</p>
      <p>We received a request to reset your password. If you didn't make this request, you can safely ignore this email.</p>
      <p>To reset your password, click the button below:</p>
      <p style="text-align: center;">
        <a href="${resetUrl}" class="button">Reset Password</a>
      </p>
      <div class="info-box">
        <p><strong>\u23F0 This link will expire in ${expiresIn} minutes.</strong></p>
        <p>If the button doesn't work, copy and paste this link into your browser:</p>
        <p style="word-break: break-all;"><a href="${resetUrl}">${resetUrl}</a></p>
      </div>
      <p>If you didn't request a password reset, please ignore this email or contact support if you have concerns.</p>
      <p>Best regards,<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Reset Your Password",
      preheader: "Click here to reset your password",
      content
    });
    return this.sendEmail({
      to,
      subject: "Reset Your Password",
      html
    });
  }
  /**
   * Send email verification email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @param {string} options.verificationToken - Email verification token
   * @param {number} [options.expiresIn] - Token expiration in hours (default: 24)
   * @returns {Promise<Object>} Send result
   */
  async sendEmailVerificationEmail({ to, name, verificationToken, expiresIn = 24 }) {
    const { baseUrl } = this.config.templates;
    const verifyUrl = `${baseUrl}/verify-email?token=${verificationToken}`;
    const content = `
      <h2>Verify Your Email Address</h2>
      <p>Hi ${name},</p>
      <p>Thank you for creating an account with ${this.config.templates.brandName}! To complete your registration, please verify your email address.</p>
      <p style="text-align: center;">
        <a href="${verifyUrl}" class="button">Verify Email Address</a>
      </p>
      <div class="info-box">
        <p><strong>\u23F0 This link will expire in ${expiresIn} hours.</strong></p>
        <p>If the button doesn't work, copy and paste this link into your browser:</p>
        <p style="word-break: break-all;"><a href="${verifyUrl}">${verifyUrl}</a></p>
      </div>
      <p>If you didn't create an account with us, you can safely ignore this email.</p>
      <p>Welcome aboard!<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Verify Your Email",
      preheader: "Verify your email address to get started",
      content
    });
    return this.sendEmail({
      to,
      subject: "Verify Your Email Address",
      html
    });
  }
  /**
   * Send welcome email after successful registration
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @returns {Promise<Object>} Send result
   */
  async sendWelcomeEmail({ to, name }) {
    const { baseUrl } = this.config.templates;
    const content = `
      <h2>Welcome to ${this.config.templates.brandName}!</h2>
      <p>Hi ${name},</p>
      <p>Your account is now active and you're ready to get started.</p>
      <p style="text-align: center;">
        <a href="${baseUrl}/profile" class="button">Go to Your Profile</a>
      </p>
      <p>If you have any questions or need help, don't hesitate to reach out to our support team.</p>
      <p>Best regards,<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Welcome!",
      preheader: "Your account is ready",
      content
    });
    return this.sendEmail({
      to,
      subject: `Welcome to ${this.config.templates.brandName}!`,
      html
    });
  }
  /**
   * Test email service connection
   * @returns {Promise<boolean>} True if connection is valid
   */
  async testConnection() {
    if (!this.config.enabled) {
      return false;
    }
    try {
      await this._initialize();
      await this.transporter.verify();
      return true;
    } catch (error) {
      console.error("[EmailService] Connection test failed:", error);
      return false;
    }
  }
  /**
   * Close transporter connection
   */
  async close() {
    if (this.transporter) {
      this.transporter.close();
      this.transporter = null;
      this.initialized = false;
    }
  }
}

var emailService = /*#__PURE__*/Object.freeze({
  __proto__: null,
  EmailService: EmailService
});

class MFAManager {
  constructor(options = {}) {
    this.options = {
      issuer: options.issuer || "S3DB Identity",
      algorithm: options.algorithm || "SHA1",
      // SHA1, SHA256, SHA512
      digits: options.digits || 6,
      // 6 or 8 digits
      period: options.period || 30,
      // 30 seconds
      window: options.window || 1,
      // Allow 1 time step (90s total)
      backupCodesCount: options.backupCodesCount || 10,
      backupCodeLength: options.backupCodeLength || 8
    };
    this.OTPAuth = null;
  }
  /**
   * Initialize MFA Manager (load otpauth library)
   */
  async initialize() {
    this.OTPAuth = await requirePluginDependency(
      "otpauth",
      "IdentityPlugin (MFA)");
  }
  /**
   * Generate MFA enrollment data for a user
   * @param {string} accountName - User email or username
   * @returns {Object} Enrollment data with secret, QR code URL, and backup codes
   */
  generateEnrollment(accountName) {
    if (!this.OTPAuth) {
      throw new Error("[MFA] OTPAuth library not initialized");
    }
    const totp = new this.OTPAuth.TOTP({
      issuer: this.options.issuer,
      label: accountName,
      algorithm: this.options.algorithm,
      digits: this.options.digits,
      period: this.options.period,
      secret: this.OTPAuth.Secret.fromBase32(
        this.OTPAuth.Secret.generate().base32
      )
    });
    const qrCodeUrl = totp.toString();
    const backupCodes = this.generateBackupCodes(this.options.backupCodesCount);
    return {
      secret: totp.secret.base32,
      // For manual entry
      qrCodeUrl,
      // For QR code scanning
      backupCodes,
      // Emergency access codes
      algorithm: this.options.algorithm,
      digits: this.options.digits,
      period: this.options.period
    };
  }
  /**
   * Verify a TOTP token
   * @param {string} secret - Base32 encoded secret
   * @param {string} token - 6-digit token from authenticator app
   * @returns {boolean} True if valid
   */
  verifyTOTP(secret, token) {
    if (!this.OTPAuth) {
      throw new Error("[MFA] OTPAuth library not initialized");
    }
    try {
      const totp = new this.OTPAuth.TOTP({
        issuer: this.options.issuer,
        algorithm: this.options.algorithm,
        digits: this.options.digits,
        period: this.options.period,
        secret: this.OTPAuth.Secret.fromBase32(secret)
      });
      const delta = totp.validate({
        token,
        window: this.options.window
      });
      return delta !== null;
    } catch (error) {
      console.error("[MFA] TOTP verification error:", error.message);
      return false;
    }
  }
  /**
   * Generate backup codes for emergency access
   * @param {number} count - Number of codes to generate
   * @returns {Array<string>} Array of backup codes
   */
  generateBackupCodes(count = 10) {
    const codes = [];
    const length = this.options.backupCodeLength;
    for (let i = 0; i < count; i++) {
      const code = idGenerator().replace(/[^a-zA-Z0-9]/g, "").substring(0, length).toUpperCase();
      codes.push(code);
    }
    return codes;
  }
  /**
   * Hash backup codes for storage
   * @param {Array<string>} codes - Backup codes
   * @returns {Array<string>} Hashed codes
   */
  async hashBackupCodes(codes) {
    const crypto = await import('crypto');
    return codes.map((code) => {
      return crypto.createHash("sha256").update(code).digest("hex");
    });
  }
  /**
   * Verify a backup code
   * @param {string} code - Backup code to verify
   * @param {Array<string>} hashedCodes - Array of hashed backup codes
   * @returns {number|null} Index of matched code, or null if not found
   */
  async verifyBackupCode(code, hashedCodes) {
    const crypto = await import('crypto');
    const hashedInput = crypto.createHash("sha256").update(code.toUpperCase()).digest("hex");
    return hashedCodes.findIndex((hash) => hash === hashedInput);
  }
  /**
   * Generate QR code data URL for display
   * @param {string} qrCodeUrl - OTP auth URL
   * @returns {Promise<string>} Data URL for QR code image
   */
  async generateQRCodeDataURL(qrCodeUrl) {
    try {
      const QRCode = await requirePluginDependency(
        "qrcode",
        "IdentityPlugin (MFA)",
        "QR code generation for MFA enrollment"
      );
      return await QRCode.toDataURL(qrCodeUrl);
    } catch (error) {
      console.error("[MFA] QR code generation error:", error.message);
      return null;
    }
  }
}

var mfaManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  MFAManager: MFAManager
});

function createCorsMiddleware(config = {}) {
  const {
    origin = "*",
    methods = ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
    allowedHeaders = ["Content-Type", "Authorization", "X-API-Key"],
    exposedHeaders = ["X-Total-Count", "X-Page-Count"],
    credentials = true,
    maxAge = 86400
  } = config;
  return async (c, next) => {
    c.header("Access-Control-Allow-Origin", origin);
    c.header("Access-Control-Allow-Methods", methods.join(", "));
    c.header("Access-Control-Allow-Headers", allowedHeaders.join(", "));
    c.header("Access-Control-Expose-Headers", exposedHeaders.join(", "));
    if (credentials) {
      c.header("Access-Control-Allow-Credentials", "true");
    }
    c.header("Access-Control-Max-Age", maxAge.toString());
    if (c.req.method === "OPTIONS") {
      return c.body(null, 204);
    }
    await next();
  };
}

function createLoggingMiddleware(config = {}) {
  const {
    format = ":method :path :status :response-time ms",
    verbose = false
  } = config;
  return async (c, next) => {
    const start = Date.now();
    const method = c.req.method;
    const path = c.req.path;
    const requestId = c.get("requestId");
    await next();
    const duration = Date.now() - start;
    const status = c.res.status;
    const user = c.get("user")?.username || c.get("user")?.email || "anonymous";
    let logMessage = format.replace(":method", method).replace(":path", path).replace(":status", status).replace(":response-time", duration).replace(":user", user).replace(":requestId", requestId);
    console.log(`[HTTP] ${logMessage}`);
  };
}

promisify$1(gzip$1);
promisify$1(brotliCompress);

function createSecurityMiddleware(config = {}) {
  const {
    contentSecurityPolicy = {
      enabled: true,
      directives: {
        "default-src": ["'self'"],
        "script-src": ["'self'", "'unsafe-inline'"],
        "style-src": ["'self'", "'unsafe-inline'"],
        "img-src": ["'self'", "data:", "https:"]
      },
      reportOnly: false,
      reportUri: null
    },
    frameguard = { action: "deny" },
    noSniff = true,
    hsts = {
      maxAge: 15552e3,
      // 180 days
      includeSubDomains: true,
      preload: false
    },
    referrerPolicy = { policy: "no-referrer" },
    dnsPrefetchControl = { allow: false },
    ieNoOpen = true,
    permittedCrossDomainPolicies = { policy: "none" },
    xssFilter = { mode: "block" },
    permissionsPolicy = {
      features: {
        geolocation: [],
        microphone: [],
        camera: [],
        payment: [],
        usb: []
      }
    }
  } = config;
  return async (c, next) => {
    if (noSniff) {
      c.header("X-Content-Type-Options", "nosniff");
    }
    if (frameguard) {
      const action = frameguard.action.toUpperCase();
      if (action === "DENY") {
        c.header("X-Frame-Options", "DENY");
      } else if (action === "SAMEORIGIN") {
        c.header("X-Frame-Options", "SAMEORIGIN");
      }
    }
    if (hsts) {
      const parts = [`max-age=${hsts.maxAge}`];
      if (hsts.includeSubDomains) {
        parts.push("includeSubDomains");
      }
      if (hsts.preload) {
        parts.push("preload");
      }
      c.header("Strict-Transport-Security", parts.join("; "));
    }
    if (referrerPolicy) {
      c.header("Referrer-Policy", referrerPolicy.policy);
    }
    if (dnsPrefetchControl) {
      const value = dnsPrefetchControl.allow ? "on" : "off";
      c.header("X-DNS-Prefetch-Control", value);
    }
    if (ieNoOpen) {
      c.header("X-Download-Options", "noopen");
    }
    if (permittedCrossDomainPolicies) {
      c.header("X-Permitted-Cross-Domain-Policies", permittedCrossDomainPolicies.policy);
    }
    if (xssFilter) {
      const mode = xssFilter.mode;
      c.header("X-XSS-Protection", mode === "block" ? "1; mode=block" : "0");
    }
    if (permissionsPolicy && permissionsPolicy.features) {
      const features = permissionsPolicy.features;
      const policies = [];
      for (const [feature, allowList] of Object.entries(features)) {
        if (Array.isArray(allowList)) {
          const value = allowList.length === 0 ? `${feature}=()` : `${feature}=(${allowList.join(" ")})`;
          policies.push(value);
        }
      }
      if (policies.length > 0) {
        c.header("Permissions-Policy", policies.join(", "));
      }
    }
    if (contentSecurityPolicy && contentSecurityPolicy.enabled !== false && contentSecurityPolicy.directives) {
      const cspParts = [];
      for (const [directive, values] of Object.entries(contentSecurityPolicy.directives)) {
        if (Array.isArray(values) && values.length > 0) {
          cspParts.push(`${directive} ${values.join(" ")}`);
        } else if (typeof values === "string") {
          cspParts.push(`${directive} ${values}`);
        }
      }
      if (contentSecurityPolicy.reportUri) {
        cspParts.push(`report-uri ${contentSecurityPolicy.reportUri}`);
      }
      if (cspParts.length > 0) {
        const cspValue = cspParts.join("; ");
        const headerName = contentSecurityPolicy.reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
        c.header(headerName, cspValue);
      }
    }
    await next();
  };
}

function createExpressStyleResponse(c) {
  let statusCode = 200;
  const response = {
    status(code) {
      statusCode = code;
      return this;
    },
    json(data) {
      return c.json(data, statusCode);
    },
    header(name, value) {
      c.header(name, value);
      return this;
    },
    setHeader(name, value) {
      c.header(name, value);
      return this;
    },
    send(data) {
      if (data === void 0 || data === null) {
        return c.body("", statusCode);
      }
      if (typeof data === "string" || data instanceof Uint8Array) {
        return c.body(data, statusCode);
      }
      return c.json(data, statusCode);
    },
    redirect(url, code = 302) {
      return c.redirect(url, code);
    }
  };
  return response;
}
function parseCookies(cookieHeader) {
  if (!cookieHeader) {
    return {};
  }
  return cookieHeader.split(";").map((part) => part.trim()).filter(Boolean).reduce((acc, part) => {
    const [key, ...rest] = part.split("=");
    acc[key] = decodeURIComponent(rest.join("=") || "");
    return acc;
  }, {});
}
async function createExpressStyleRequest(c) {
  const cached = c.get("expressStyleRequest");
  if (cached) {
    return cached;
  }
  const raw = c.req.raw;
  const headers = {};
  raw.headers.forEach((value, key) => {
    headers[key.toLowerCase()] = value;
  });
  const url = new URL(raw.url);
  let body = void 0;
  const contentType = headers["content-type"]?.split(";")[0].trim();
  try {
    if (contentType === "application/json") {
      body = await c.req.json();
    } else if (contentType === "application/x-www-form-urlencoded" || contentType === "multipart/form-data") {
      body = await c.req.parseBody();
    }
  } catch {
    body = void 0;
  }
  const query = Object.fromEntries(url.searchParams.entries());
  const cookies = parseCookies(headers.cookie);
  const clientIp = c.get("clientIp") || c.req.header("x-forwarded-for")?.split(",")[0]?.trim() || c.req.header("x-real-ip") || "unknown";
  const expressReq = {
    method: raw.method,
    url: raw.url,
    originalUrl: raw.url,
    path: url.pathname,
    headers,
    query,
    body: body ?? {},
    cookies,
    ip: clientIp,
    protocol: url.protocol.replace(":", ""),
    get(name) {
      return headers[name.toLowerCase()];
    }
  };
  c.set("expressStyleRequest", expressReq);
  return expressReq;
}
class IdentityServer {
  /**
   * Create Identity server
   * @param {Object} options - Server options
   */
  constructor(options = {}) {
    this.options = {
      port: options.port || 4e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      issuer: options.issuer,
      oauth2Server: options.oauth2Server,
      sessionManager: options.sessionManager || null,
      usersResource: options.usersResource || null,
      identityPlugin: options.identityPlugin || null,
      failbanManager: options.failbanManager || null,
      failbanConfig: options.failbanConfig || {},
      cors: options.cors || {},
      security: options.security || {},
      logging: options.logging || {}
    };
    this.app = null;
    this.server = null;
    this.isRunning = false;
    this.initialized = false;
  }
  /**
   * Setup failban middleware for brute force protection
   * @private
   */
  _setupFailbanMiddleware() {
    const { failbanManager } = this.options;
    this.app.use("*", async (c, next) => {
      const ip = this._extractClientIp(c);
      c.set("clientIp", ip);
      if (failbanManager.isBlacklisted(ip)) {
        c.header("X-Ban-Status", "blacklisted");
        c.header("X-Ban-Reason", "IP is permanently blacklisted");
        if (this.options.verbose) {
          console.log(`[Failban] Blocked blacklisted IP: ${ip}`);
        }
        return c.json({
          error: "Forbidden",
          message: "Your IP address has been permanently blocked",
          ip
        }, 403);
      }
      if (this.options.failbanConfig.geo?.enabled) {
        const countryBlock = failbanManager.checkCountryBlock(ip);
        if (countryBlock) {
          c.header("X-Ban-Status", "country_blocked");
          c.header("X-Ban-Reason", countryBlock.reason);
          c.header("X-Country-Code", countryBlock.country);
          if (this.options.verbose) {
            console.log(`[Failban] Blocked country ${countryBlock.country} for IP: ${ip}`);
          }
          return c.json({
            error: "Forbidden",
            message: "Access from your country is not allowed",
            country: countryBlock.country,
            ip
          }, 403);
        }
      }
      if (failbanManager.isBanned(ip)) {
        const ban = await failbanManager.getBan(ip);
        if (ban) {
          const expiresAt = new Date(ban.expiresAt);
          const retryAfter = Math.ceil((expiresAt.getTime() - Date.now()) / 1e3);
          c.header("Retry-After", String(retryAfter));
          c.header("X-Ban-Status", "banned");
          c.header("X-Ban-Reason", ban.reason);
          c.header("X-Ban-Expires", ban.expiresAt);
          if (this.options.verbose) {
            console.log(`[Failban] Blocked banned IP: ${ip} (expires in ${retryAfter}s)`);
          }
          return c.json({
            error: "Forbidden",
            message: "Your IP address has been temporarily banned due to security violations",
            reason: ban.reason,
            expiresAt: ban.expiresAt,
            retryAfter
          }, 403);
        }
      }
      await next();
    });
    if (this.options.verbose) {
      console.log("[Identity Server] Failban middleware enabled (global ban check)");
    }
  }
  /**
   * Extract client IP from request
   * @param {import('hono').Context} c
   * @returns {string}
   * @private
   */
  _extractClientIp(c) {
    return c.get("clientIp") || c.req.header("x-forwarded-for")?.split(",")[0]?.trim() || c.req.header("x-real-ip") || c.env?.ip || "unknown";
  }
  /**
   * Create rate limit middleware for API endpoints
   * @param {RateLimiter} limiter
   * @returns {Function}
   * @private
   */
  _createRateLimitMiddleware(limiter) {
    return createJsonRateLimitMiddleware(limiter, (c) => this._extractClientIp(c));
  }
  /**
   * Setup all routes
   * @private
   */
  _setupRoutes() {
    this.app.use("*", async (c, next) => {
      c.set("requestId", idGenerator());
      c.set("verbose", this.options.verbose);
      await next();
    });
    if (this.options.cors.enabled) {
      const corsMiddleware = createCorsMiddleware(this.options.cors);
      this.app.use("*", corsMiddleware);
    }
    if (this.options.security.enabled) {
      const securityMiddleware = createSecurityMiddleware(this.options.security);
      this.app.use("*", securityMiddleware);
    }
    if (this.options.failbanManager && this.options.failbanConfig.enabled) {
      this._setupFailbanMiddleware();
    }
    if (this.options.logging.enabled) {
      const loggingMiddleware = createLoggingMiddleware(this.options.logging);
      this.app.use("*", loggingMiddleware);
    }
    this.app.get("/health", (c) => {
      const response = success({
        status: "ok",
        service: "identity-provider",
        uptime: process.uptime(),
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/live", (c) => {
      const response = success({
        status: "alive",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/ready", (c) => {
      const isReady = this.options.oauth2Server !== null;
      if (!isReady) {
        const response2 = error("Service not ready", {
          status: 503,
          code: "NOT_READY"
        });
        return c.json(response2, 503);
      }
      const response = success({
        status: "ready",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/", (c) => {
      return c.redirect("/.well-known/openid-configuration", 302);
    });
    this._setupOAuth2Routes();
    this._setupUIRoutes();
    this.app.onError((err, c) => {
      return errorHandler(err, c);
    });
    this.app.notFound((c) => {
      const response = error("Route not found", {
        status: 404,
        code: "NOT_FOUND",
        details: {
          path: c.req.path,
          method: c.req.method
        }
      });
      return c.json(response, 404);
    });
  }
  /**
   * Setup OAuth2/OIDC routes
   * @private
   */
  _setupOAuth2Routes() {
    const { oauth2Server } = this.options;
    if (!oauth2Server) {
      console.error("[Identity Server] OAuth2 Server not provided");
      return;
    }
    const rateLimiters = this.options.identityPlugin?.rateLimiters || {};
    const wrap = (handler) => async (c) => {
      const req = await createExpressStyleRequest(c);
      const res = createExpressStyleResponse(c);
      return await handler.call(oauth2Server, req, res);
    };
    this.app.get("/.well-known/openid-configuration", wrap(oauth2Server.discoveryHandler));
    this.app.get("/.well-known/jwks.json", wrap(oauth2Server.jwksHandler));
    const tokenHandler = wrap(oauth2Server.tokenHandler);
    if (rateLimiters.token) {
      this.app.post("/oauth/token", this._createRateLimitMiddleware(rateLimiters.token), tokenHandler);
    } else {
      this.app.post("/oauth/token", tokenHandler);
    }
    this.app.get("/oauth/userinfo", wrap(oauth2Server.userinfoHandler));
    this.app.post("/oauth/introspect", wrap(oauth2Server.introspectHandler));
    const authorizeGet = wrap(oauth2Server.authorizeHandler);
    const authorizePost = wrap(oauth2Server.authorizePostHandler);
    if (rateLimiters.authorize) {
      const middleware = this._createRateLimitMiddleware(rateLimiters.authorize);
      this.app.get("/oauth/authorize", middleware, authorizeGet);
      this.app.post("/oauth/authorize", middleware, authorizePost);
    } else {
      this.app.get("/oauth/authorize", authorizeGet);
      this.app.post("/oauth/authorize", authorizePost);
    }
    this.app.post("/oauth/register", wrap(oauth2Server.registerClientHandler));
    this.app.post("/oauth/revoke", wrap(oauth2Server.revokeHandler));
    if (this.options.verbose) {
      console.log("[Identity Server] Mounted OAuth2/OIDC routes:");
      console.log("[Identity Server]   GET  /.well-known/openid-configuration (OIDC Discovery)");
      console.log("[Identity Server]   GET  /.well-known/jwks.json (JWKS)");
      console.log("[Identity Server]   GET  /oauth/authorize (Authorization UI)");
      console.log("[Identity Server]   POST /oauth/authorize (Process Login)");
      console.log("[Identity Server]   POST /oauth/token (Token)");
      console.log("[Identity Server]   GET  /oauth/userinfo (UserInfo)");
      console.log("[Identity Server]   POST /oauth/introspect (Introspection)");
      console.log("[Identity Server]   POST /oauth/register (Client Registration)");
      console.log("[Identity Server]   POST /oauth/revoke (Token Revocation)");
    }
  }
  /**
   * Setup UI routes (login, register, profile, etc.)
   * @private
   */
  async _setupUIRoutes() {
    const { sessionManager, identityPlugin } = this.options;
    if (!sessionManager || !identityPlugin) {
      if (this.options.verbose) {
        console.log("[Identity Server] SessionManager or IdentityPlugin not provided, skipping UI routes");
      }
      return;
    }
    try {
      const { registerUIRoutes } = await Promise.resolve().then(function () { return routes; });
      registerUIRoutes(this.app, identityPlugin);
      if (this.options.verbose) {
        console.log("[Identity Server] Mounted UI routes:");
        console.log("[Identity Server]   GET  /login (Login Form)");
        console.log("[Identity Server]   POST /login (Process Login)");
        console.log("[Identity Server]   GET  /register (Registration Form)");
        console.log("[Identity Server]   POST /register (Process Registration)");
        console.log("[Identity Server]   GET  /logout (Logout)");
        console.log("[Identity Server]   POST /logout (Logout)");
        console.log("[Identity Server]   GET  /forgot-password (Forgot Password Form)");
        console.log("[Identity Server]   POST /forgot-password (Process Forgot Password)");
        console.log("[Identity Server]   GET  /reset-password (Reset Password Form)");
        console.log("[Identity Server]   POST /reset-password (Process Password Reset)");
        console.log("[Identity Server]   GET  /profile (User Profile - Protected)");
        console.log("[Identity Server]   POST /profile/update (Update Profile)");
        console.log("[Identity Server]   POST /profile/change-password (Change Password)");
        console.log("[Identity Server]   POST /profile/logout-session (Logout Specific Session)");
        console.log("[Identity Server]   POST /profile/logout-all-sessions (Logout All Other Sessions)");
        console.log("[Identity Server]   GET  /admin (Admin Dashboard - Protected)");
        console.log("[Identity Server]   GET  /admin/clients (List OAuth2 Clients)");
        console.log("[Identity Server]   GET  /admin/clients/new (New Client Form)");
        console.log("[Identity Server]   POST /admin/clients/create (Create Client)");
        console.log("[Identity Server]   GET  /admin/clients/:id/edit (Edit Client Form)");
        console.log("[Identity Server]   POST /admin/clients/:id/update (Update Client)");
        console.log("[Identity Server]   POST /admin/clients/:id/delete (Delete Client)");
        console.log("[Identity Server]   POST /admin/clients/:id/rotate-secret (Rotate Client Secret)");
        console.log("[Identity Server]   POST /admin/clients/:id/toggle-active (Toggle Client Active)");
        console.log("[Identity Server]   GET  /admin/users (List Users - Protected)");
        console.log("[Identity Server]   GET  /admin/users/:id/edit (Edit User Form)");
        console.log("[Identity Server]   POST /admin/users/:id/update (Update User)");
        console.log("[Identity Server]   POST /admin/users/:id/delete (Delete User)");
        console.log("[Identity Server]   POST /admin/users/:id/change-status (Change User Status)");
        console.log("[Identity Server]   POST /admin/users/:id/verify-email (Mark Email Verified)");
        console.log("[Identity Server]   POST /admin/users/:id/reset-password (Send Password Reset)");
        console.log("[Identity Server]   POST /admin/users/:id/toggle-admin (Toggle Admin Role)");
        console.log("[Identity Server]   GET  /oauth/authorize (OAuth2 Consent Screen - Overrides OAuth2Server)");
        console.log("[Identity Server]   POST /oauth/consent (Process OAuth2 Consent Decision)");
        console.log("[Identity Server]   GET  /verify-email (Verify Email with Token)");
        console.log("[Identity Server]   POST /verify-email/resend (Resend Verification Email)");
      }
    } catch (error) {
      console.error("[Identity Server] Failed to setup UI routes:", error);
    }
  }
  /**
   * Start the server
   * @returns {Promise<void>}
   */
  async start() {
    if (this.isRunning) {
      console.warn("[Identity Server] Server is already running");
      return;
    }
    if (!this.initialized) {
      const { Hono } = await import('hono');
      const { serve } = await import('@hono/node-server');
      this.Hono = Hono;
      this.serve = serve;
      this.app = new Hono();
      this._setupRoutes();
      this.initialized = true;
    }
    const { port, host } = this.options;
    return new Promise((resolve, reject) => {
      try {
        this.server = this.serve({
          fetch: this.app.fetch,
          port,
          hostname: host
        }, (info) => {
          this.isRunning = true;
          console.log(`[Identity Server] Server listening on http://${info.address}:${info.port}`);
          console.log(`[Identity Server] Issuer: ${this.options.issuer}`);
          console.log(`[Identity Server] Discovery: ${this.options.issuer}/.well-known/openid-configuration`);
          resolve();
        });
      } catch (err) {
        reject(err);
      }
    });
  }
  /**
   * Stop the server
   * @returns {Promise<void>}
   */
  async stop() {
    if (!this.isRunning) {
      console.warn("[Identity Server] Server is not running");
      return;
    }
    if (this.server && typeof this.server.close === "function") {
      await new Promise((resolve) => {
        this.server.close(() => {
          this.isRunning = false;
          console.log("[Identity Server] Server stopped");
          resolve();
        });
      });
    } else {
      this.isRunning = false;
      console.log("[Identity Server] Server stopped");
    }
  }
  /**
   * Get server info
   * @returns {Object} Server information
   */
  getInfo() {
    return {
      isRunning: this.isRunning,
      port: this.options.port,
      host: this.options.host,
      issuer: this.options.issuer
    };
  }
  /**
   * Get Hono app instance
   * @returns {Hono} Hono app
   */
  getApp() {
    return this.app;
  }
}

var server = /*#__PURE__*/Object.freeze({
  __proto__: null,
  IdentityServer: IdentityServer
});

class PuppeteerError extends PluginError {
  constructor(message, details = {}) {
    const merged = {
      pluginName: details.pluginName || "PuppeteerPlugin",
      operation: details.operation || "unknown",
      statusCode: details.statusCode ?? 500,
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Review PuppeteerPlugin configuration (proxies, sessions, scripts) and retry.",
      ...details
    };
    super(message, merged);
    this.name = "PuppeteerError";
  }
}
class BrowserPoolError extends PuppeteerError {
  constructor(message, details = {}) {
    super(message, {
      code: "BROWSER_POOL_ERROR",
      retriable: details.retriable ?? true,
      suggestion: details.suggestion ?? "Verify browser instances are healthy and increase pool size or restart browsers.",
      docs: details.docs || "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/puppeteer.md#browser-pool",
      ...details
    });
    this.name = "BrowserPoolError";
  }
}
class CookieManagerError extends PuppeteerError {
  constructor(message, details = {}) {
    super(message, {
      code: "COOKIE_MANAGER_ERROR",
      retriable: details.retriable ?? false,
      suggestion: details.suggestion ?? "Check cookie storage configuration and ensure persona sessions are valid.",
      ...details
    });
    this.name = "CookieManagerError";
  }
}
class NavigationError extends PuppeteerError {
  constructor(message, details = {}) {
    super(message, {
      code: "NAVIGATION_ERROR",
      retriable: details.retriable ?? true,
      suggestion: details.suggestion ?? "Validate target URLs, network access, and waitFor options before retrying.",
      ...details
    });
    this.name = "NavigationError";
  }
}

class ProxyManager {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.proxy;
    this.storage = null;
    this.proxies = [];
    this.proxyStats = /* @__PURE__ */ new Map();
    this.sessionProxyMap = /* @__PURE__ */ new Map();
    this.selectionStrategy = this.config.selectionStrategy || "round-robin";
    this.currentProxyIndex = 0;
  }
  /**
   * Initialize proxy manager
   */
  async initialize() {
    if (this.config.enabled && this.config.list && this.config.list.length > 0) {
      this.proxies = this.config.list.map((proxy, index) => ({
        id: `proxy_${index}`,
        ...this._parseProxy(proxy)
      }));
      for (const proxy of this.proxies) {
        this.proxyStats.set(proxy.id, {
          requests: 0,
          failures: 0,
          successRate: 1,
          lastUsed: 0,
          healthy: true,
          createdAt: Date.now()
        });
      }
      this.plugin.emit("proxyManager.initialized", {
        count: this.proxies.length,
        strategy: this.selectionStrategy
      });
    }
    if (this.plugin.cookieManager && this.plugin.cookieManager.storage) {
      await this._loadSessionProxyBindings();
    }
  }
  /**
   * Parse proxy string or object
   * @private
   */
  _parseProxy(proxy) {
    if (typeof proxy === "string") {
      const url = new URL(proxy);
      return {
        protocol: url.protocol.replace(":", ""),
        host: url.hostname,
        port: parseInt(url.port) || (url.protocol === "https:" ? 443 : 80),
        username: url.username || null,
        password: url.password || null,
        url: proxy
      };
    } else {
      const protocol = proxy.protocol || "http";
      const host = proxy.host;
      const port = proxy.port || (protocol === "https" ? 443 : 80);
      const username = proxy.username || null;
      const password = proxy.password || null;
      let url = `${protocol}://`;
      if (username && password) {
        url += `${username}:${password}@`;
      }
      url += `${host}:${port}`;
      return {
        protocol,
        host,
        port,
        username,
        password,
        url
      };
    }
  }
  /**
   * Load session-proxy bindings from storage
   * @private
   */
  async _loadSessionProxyBindings() {
    const storage = this.plugin.cookieManager.storage;
    const sessions = await storage.list({ limit: 1e3 });
    for (const session of sessions) {
      if (session.proxyId) {
        this.sessionProxyMap.set(session.sessionId, session.proxyId);
      }
    }
    this.plugin.emit("proxyManager.bindingsLoaded", {
      count: this.sessionProxyMap.size
    });
  }
  /**
   * Get proxy for a session (respecting immutable binding)
   * @param {string} sessionId - Session identifier
   * @param {boolean} createIfMissing - Create new binding if session is new
   * @returns {Object|null} - Proxy config or null
   */
  getProxyForSession(sessionId, createIfMissing = true) {
    if (!this.config.enabled || this.proxies.length === 0) {
      return null;
    }
    if (this.sessionProxyMap.has(sessionId)) {
      const proxyId = this.sessionProxyMap.get(sessionId);
      const proxy = this.proxies.find((p) => p.id === proxyId);
      if (!proxy) {
        throw new BrowserPoolError(`Proxy ${proxyId} bound to session ${sessionId} not found in pool`, {
          operation: "getProxyForSession",
          retriable: false,
          suggestion: "Ensure proxies remain registered while sessions are active.",
          proxyId,
          sessionId
        });
      }
      const stats = this.proxyStats.get(proxyId);
      if (!stats || !stats.healthy) {
        throw new BrowserPoolError(`Proxy ${proxyId} bound to session ${sessionId} is unhealthy`, {
          operation: "getProxyForSession",
          retriable: true,
          suggestion: "Rebind the session to a healthy proxy or refresh the proxy pool.",
          proxyId,
          sessionId
        });
      }
      return proxy;
    }
    if (createIfMissing) {
      const proxy = this._selectProxy();
      if (proxy) {
        this.sessionProxyMap.set(sessionId, proxy.id);
        this.plugin.emit("proxyManager.sessionBound", {
          sessionId,
          proxyId: proxy.id,
          proxyUrl: this._maskProxyUrl(proxy.url)
        });
        return proxy;
      }
    }
    return null;
  }
  /**
   * Select proxy based on strategy
   * @private
   */
  _selectProxy() {
    const healthyProxies = this.proxies.filter((proxy) => {
      const stats = this.proxyStats.get(proxy.id);
      return stats ? stats.healthy : false;
    });
    if (healthyProxies.length === 0) {
      throw new BrowserPoolError("No healthy proxies available", {
        operation: "_selectProxy",
        retriable: true,
        suggestion: "Add healthy proxies to the configuration or allow existing proxies to recover.",
        available: this.proxies.length
      });
    }
    let selectedProxy;
    switch (this.selectionStrategy) {
      case "round-robin":
        selectedProxy = healthyProxies[this.currentProxyIndex % healthyProxies.length];
        this.currentProxyIndex++;
        break;
      case "random":
        selectedProxy = healthyProxies[Math.floor(Math.random() * healthyProxies.length)];
        break;
      case "least-used":
        selectedProxy = healthyProxies.reduce((min, proxy) => {
          const proxyStats = this.proxyStats.get(proxy.id);
          const minStats = this.proxyStats.get(min.id);
          return proxyStats.requests < minStats.requests ? proxy : min;
        });
        break;
      case "best-performance":
        selectedProxy = healthyProxies.reduce((best, proxy) => {
          const proxyStats = this.proxyStats.get(proxy.id);
          const bestStats = this.proxyStats.get(best.id);
          return proxyStats.successRate > bestStats.successRate ? proxy : best;
        });
        break;
      default:
        selectedProxy = healthyProxies[0];
    }
    return selectedProxy;
  }
  /**
   * Record proxy usage
   * @param {string} proxyId - Proxy identifier
   * @param {boolean} success - Whether request succeeded
   */
  recordProxyUsage(proxyId, success = true) {
    const stats = this.proxyStats.get(proxyId);
    if (!stats) return;
    stats.requests++;
    stats.lastUsed = Date.now();
    if (success) {
      stats.successRate = stats.successRate * 0.9 + 0.1;
    } else {
      stats.failures++;
      stats.successRate = stats.successRate * 0.9;
      const threshold = this.config.healthCheck?.successRateThreshold || 0.3;
      if (stats.successRate < threshold) {
        stats.healthy = false;
        this.plugin.emit("proxyManager.proxyUnhealthy", {
          proxyId,
          successRate: stats.successRate
        });
      }
    }
  }
  /**
   * Get proxy statistics
   * @returns {Array}
   */
  getProxyStats() {
    return this.proxies.map((proxy) => {
      const stats = this.proxyStats.get(proxy.id);
      return {
        proxyId: proxy.id,
        url: this._maskProxyUrl(proxy.url),
        ...stats,
        boundSessions: Array.from(this.sessionProxyMap.entries()).filter(([_, proxyId]) => proxyId === proxy.id).length
      };
    });
  }
  /**
   * Get session-proxy bindings
   * @returns {Array}
   */
  getSessionBindings() {
    return Array.from(this.sessionProxyMap.entries()).map(([sessionId, proxyId]) => {
      const proxy = this.proxies.find((p) => p.id === proxyId);
      return {
        sessionId,
        proxyId,
        proxyUrl: proxy ? this._maskProxyUrl(proxy.url) : "unknown"
      };
    });
  }
  /**
   * Verify session-proxy binding integrity
   * @param {string} sessionId - Session identifier
   * @param {string} proxyId - Proxy identifier
   * @returns {boolean}
   */
  verifyBinding(sessionId, proxyId) {
    if (!this.sessionProxyMap.has(sessionId)) {
      return false;
    }
    const boundProxyId = this.sessionProxyMap.get(sessionId);
    return boundProxyId === proxyId;
  }
  /**
   * Get proxy config for browser launch
   * @param {Object} proxy - Proxy object
   * @returns {Object} - Puppeteer proxy config
   */
  getProxyLaunchArgs(proxy) {
    if (!proxy) return [];
    const args = [`--proxy-server=${proxy.url}`];
    if (this.config.bypassList && this.config.bypassList.length > 0) {
      args.push(`--proxy-bypass-list=${this.config.bypassList.join(";")}`);
    }
    return args;
  }
  /**
   * Authenticate proxy on page
   * @param {Page} page - Puppeteer page
   * @param {Object} proxy - Proxy object
   */
  async authenticateProxy(page, proxy) {
    if (proxy.username && proxy.password) {
      await page.authenticate({
        username: proxy.username,
        password: proxy.password
      });
    }
  }
  /**
   * Check proxy health
   * @param {string} proxyId - Proxy identifier
   * @returns {Promise<boolean>}
   */
  async checkProxyHealth(proxyId) {
    const proxy = this.proxies.find((p) => p.id === proxyId);
    if (!proxy) return false;
    const stats = this.proxyStats.get(proxyId);
    if (!stats) return false;
    try {
      const browser = await this.plugin.puppeteer.launch({
        ...this.plugin.config.launch,
        args: [
          ...this.plugin.config.launch.args,
          ...this.getProxyLaunchArgs(proxy)
        ]
      });
      const page = await browser.newPage();
      await this.authenticateProxy(page, proxy);
      const testUrl = this.config.healthCheck?.testUrl || "https://www.google.com";
      const timeout = this.config.healthCheck?.timeout || 1e4;
      await page.goto(testUrl, { timeout });
      await browser.close();
      stats.healthy = true;
      stats.successRate = Math.min(stats.successRate + 0.1, 1);
      this.plugin.emit("proxyManager.healthCheckPassed", {
        proxyId,
        url: this._maskProxyUrl(proxy.url)
      });
      return true;
    } catch (err) {
      stats.healthy = false;
      stats.failures++;
      this.plugin.emit("proxyManager.healthCheckFailed", {
        proxyId,
        url: this._maskProxyUrl(proxy.url),
        error: err.message
      });
      return false;
    }
  }
  /**
   * Run health checks on all proxies
   * @returns {Promise<Object>}
   */
  async checkAllProxies() {
    const results = {
      total: this.proxies.length,
      healthy: 0,
      unhealthy: 0,
      checks: []
    };
    for (const proxy of this.proxies) {
      const isHealthy = await this.checkProxyHealth(proxy.id);
      results.checks.push({
        proxyId: proxy.id,
        url: this._maskProxyUrl(proxy.url),
        healthy: isHealthy
      });
      if (isHealthy) {
        results.healthy++;
      } else {
        results.unhealthy++;
      }
    }
    return results;
  }
  /**
   * Mask proxy URL for logging (hide credentials)
   * @private
   */
  _maskProxyUrl(url) {
    try {
      const parsed = new URL(url);
      if (parsed.username) {
        return `${parsed.protocol}//${parsed.username}:***@${parsed.host}`;
      }
      return url;
    } catch {
      return url;
    }
  }
  /**
   * Remove session-proxy binding (only for cleanup/testing)
   * WARNING: This breaks immutability! Only use when deleting sessions.
   * @param {string} sessionId - Session identifier
   */
  _removeBinding(sessionId) {
    this.sessionProxyMap.delete(sessionId);
    this.plugin.emit("proxyManager.bindingRemoved", { sessionId });
  }
}

var proxyManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  ProxyManager: ProxyManager
});

class CookieManager {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.cookies;
    this.storage = null;
    this.cookiePool = /* @__PURE__ */ new Map();
  }
  /**
   * Initialize cookie manager
   */
  async initialize() {
    this.storage = await this.plugin.database.getResource(this.config.storage.resource);
    if (this.config.farming.enabled) {
      await this._loadCookiePool();
    }
  }
  /**
   * Load cookie pool from storage
   * @private
   */
  async _loadCookiePool() {
    const limit = this.config.farming.rotation.poolSize;
    const cookies = await this.storage.list({ limit });
    for (const cookie of cookies) {
      this.cookiePool.set(cookie.sessionId, cookie);
    }
    this.plugin.emit("cookieManager.poolLoaded", {
      size: this.cookiePool.size
    });
  }
  /**
   * Load cookies into page
   * @param {Page} page - Puppeteer page
   * @param {string} sessionId - Session identifier
   */
  async loadSession(page, sessionId) {
    let session = this.cookiePool.get(sessionId);
    if (!session) {
      try {
        session = await this.storage.get(sessionId);
        this.cookiePool.set(sessionId, session);
      } catch (err) {
        return;
      }
    }
    if (session.cookies && session.cookies.length > 0) {
      await page.setCookie(...session.cookies);
    }
    if (session.userAgent) {
      await page.setUserAgent(session.userAgent);
    }
    if (session.viewport) {
      await page.setViewport(session.viewport);
    }
    session.metadata.lastUsed = Date.now();
    session.metadata.requestCount = (session.metadata.requestCount || 0) + 1;
    this.plugin.emit("cookieManager.sessionLoaded", {
      sessionId,
      cookieCount: session.cookies.length
    });
  }
  /**
   * Save cookies from page
   * @param {Page} page - Puppeteer page
   * @param {string} sessionId - Session identifier
   * @param {Object} options - Save options
   */
  async saveSession(page, sessionId, options = {}) {
    const { success = true } = options;
    const cookies = await page.cookies();
    let session = this.cookiePool.get(sessionId) || {
      sessionId,
      cookies: [],
      userAgent: page._userAgent,
      viewport: page._viewport,
      proxyId: page._proxyId || null,
      // IMMUTABLE: Proxy binding
      domain: this._extractMainDomain(cookies),
      date: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
      // YYYY-MM-DD
      reputation: {
        successCount: 0,
        failCount: 0,
        successRate: 1,
        lastUsed: Date.now()
      },
      metadata: {
        createdAt: Date.now(),
        expiresAt: Date.now() + this.config.farming.rotation.maxAge,
        requestCount: 0,
        age: 0
      }
    };
    session.cookies = cookies;
    session.domain = this._extractMainDomain(cookies);
    session.date = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
    if (this.config.farming.reputation.enabled && this.config.farming.reputation.trackSuccess) {
      if (success) {
        session.reputation.successCount++;
      } else {
        session.reputation.failCount++;
      }
      const total = session.reputation.successCount + session.reputation.failCount;
      session.reputation.successRate = session.reputation.successCount / total;
    }
    session.metadata.age = Date.now() - session.metadata.createdAt;
    if (this.config.storage.autoSave) {
      try {
        const existing = await this.storage.get(sessionId);
        await this.storage.update(sessionId, session);
      } catch (err) {
        await this.storage.insert(session);
      }
    }
    this.cookiePool.set(sessionId, session);
    this.plugin.emit("cookieManager.sessionSaved", {
      sessionId,
      cookieCount: cookies.length,
      reputation: session.reputation
    });
  }
  /**
   * Farm cookies for a session
   * @param {string} sessionId - Session identifier
   * @returns {Promise<void>}
   */
  async farmCookies(sessionId) {
    if (!this.config.farming.enabled || !this.config.farming.warmup.enabled) {
      throw new CookieManagerError("Cookie farming is not enabled", {
        operation: "farmCookies",
        retriable: false,
        suggestion: "Enable config.farming.enabled and config.farming.warmup.enabled to farm cookies."
      });
    }
    const warmupConfig = this.config.farming.warmup;
    const pages = [...warmupConfig.pages];
    if (warmupConfig.randomOrder) {
      pages.sort(() => Math.random() - 0.5);
    }
    this.plugin.emit("cookieManager.farmingStarted", {
      sessionId,
      pages: pages.length
    });
    for (const url of pages) {
      try {
        const page = await this.plugin.navigate(url, { useSession: sessionId });
        const timeOnPage = warmupConfig.timePerPage.min + Math.random() * (warmupConfig.timePerPage.max - warmupConfig.timePerPage.min);
        if (warmupConfig.interactions.scroll) {
          await this._randomScroll(page);
        }
        if (warmupConfig.interactions.hover) {
          await this._randomHover(page);
        }
        if (warmupConfig.interactions.click) {
          await this._randomClick(page);
        }
        await this._delay(timeOnPage);
        await this.saveSession(page, sessionId, { success: true });
        await page.close();
        this.plugin.emit("cookieManager.warmupPageCompleted", {
          sessionId,
          url
        });
      } catch (err) {
        this.plugin.emit("cookieManager.warmupPageFailed", {
          sessionId,
          url,
          error: err.message
        });
      }
    }
    this.plugin.emit("cookieManager.farmingCompleted", { sessionId });
  }
  /**
   * Get best cookie from pool based on reputation
   * @param {Object} options - Selection options
   * @returns {Promise<Object>}
   */
  async getBestCookie(options = {}) {
    if (!this.config.farming.enabled || !this.config.farming.reputation.enabled) {
      throw new CookieManagerError("Cookie farming reputation must be enabled to select best cookies", {
        operation: "getBestCookie",
        retriable: false,
        suggestion: "Enable config.farming.reputation.enabled before calling getBestCookie()."
      });
    }
    const candidates = Array.from(this.cookiePool.values()).filter((session) => {
      if (session.reputation.successRate < this.config.farming.reputation.retireThreshold) {
        return false;
      }
      if (Date.now() > session.metadata.expiresAt) {
        return false;
      }
      if (session.metadata.requestCount >= this.config.farming.rotation.requestsPerCookie) {
        return false;
      }
      return true;
    });
    if (candidates.length === 0) {
      return null;
    }
    const scored = candidates.map((session) => {
      let score = session.reputation.successRate;
      if (this.config.farming.reputation.ageBoost) {
        const ageInHours = session.metadata.age / (1e3 * 60 * 60);
        const ageBoost = Math.min(ageInHours / 24, 1) * 0.2;
        score += ageBoost;
      }
      return { session, score };
    });
    scored.sort((a, b) => b.score - a.score);
    return scored[0].session;
  }
  /**
   * Rotate cookies - remove expired/overused cookies
   * @returns {Promise<number>}
   */
  async rotateCookies() {
    if (!this.config.farming.enabled || !this.config.farming.rotation.enabled) {
      return 0;
    }
    let removed = 0;
    const now = Date.now();
    for (const [sessionId, session] of this.cookiePool.entries()) {
      let shouldRemove = false;
      if (now > session.metadata.expiresAt) {
        shouldRemove = true;
      }
      if (session.metadata.requestCount >= this.config.farming.rotation.requestsPerCookie) {
        shouldRemove = true;
      }
      if (this.config.farming.reputation.enabled && session.reputation.successRate < this.config.farming.reputation.retireThreshold) {
        shouldRemove = true;
      }
      if (shouldRemove) {
        this.cookiePool.delete(sessionId);
        try {
          await this.storage.remove(sessionId);
        } catch (err) {
        }
        removed++;
      }
    }
    if (removed > 0) {
      this.plugin.emit("cookieManager.cookiesRotated", { removed });
    }
    return removed;
  }
  /**
   * Get cookie pool statistics
   * @returns {Promise<Object>}
   */
  async getStats() {
    const sessions = Array.from(this.cookiePool.values());
    const stats = {
      total: sessions.length,
      healthy: 0,
      expired: 0,
      overused: 0,
      lowReputation: 0,
      averageAge: 0,
      averageSuccessRate: 0,
      averageRequestCount: 0
    };
    if (sessions.length === 0) {
      return stats;
    }
    const now = Date.now();
    let totalAge = 0;
    let totalSuccessRate = 0;
    let totalRequestCount = 0;
    for (const session of sessions) {
      if (now > session.metadata.expiresAt) {
        stats.expired++;
        continue;
      }
      if (session.metadata.requestCount >= this.config.farming.rotation.requestsPerCookie) {
        stats.overused++;
        continue;
      }
      if (session.reputation.successRate < this.config.farming.reputation.retireThreshold) {
        stats.lowReputation++;
        continue;
      }
      stats.healthy++;
      totalAge += session.metadata.age;
      totalSuccessRate += session.reputation.successRate;
      totalRequestCount += session.metadata.requestCount;
    }
    stats.averageAge = totalAge / stats.healthy || 0;
    stats.averageSuccessRate = totalSuccessRate / stats.healthy || 0;
    stats.averageRequestCount = totalRequestCount / stats.healthy || 0;
    return stats;
  }
  /**
   * Random scroll helper
   * @private
   */
  async _randomScroll(page) {
    const scrollDistance = Math.floor(Math.random() * 500) + 200;
    await page.evaluate((distance) => {
      window.scrollBy(0, distance);
    }, scrollDistance);
  }
  /**
   * Random hover helper
   * @private
   */
  async _randomHover(page) {
    try {
      const elements = await page.$$("a, button");
      if (elements.length > 0) {
        const randomElement = elements[Math.floor(Math.random() * elements.length)];
        await randomElement.hover();
      }
    } catch (err) {
    }
  }
  /**
   * Random click helper
   * @private
   */
  async _randomClick(page) {
    try {
      const elements = await page.$$('button:not([type="submit"]), div[role="button"]');
      if (elements.length > 0) {
        const randomElement = elements[Math.floor(Math.random() * elements.length)];
        await randomElement.click();
      }
    } catch (err) {
    }
  }
  /**
   * Extract main domain from cookies
   * @private
   */
  _extractMainDomain(cookies) {
    if (!cookies || cookies.length === 0) {
      return "unknown";
    }
    const domains = {};
    cookies.forEach((cookie) => {
      const domain = cookie.domain || "unknown";
      domains[domain] = (domains[domain] || 0) + 1;
    });
    return Object.entries(domains).sort((a, b) => b[1] - a[1])[0][0].replace(/^\./, "");
  }
  /**
   * Delay helper
   * @private
   */
  async _delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}

var cookieManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  CookieManager: CookieManager
});

class PerformanceManager {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.performance || {};
    this.thresholds = {
      lcp: { good: 2500, needsImprovement: 4e3 },
      // Largest Contentful Paint (ms)
      fid: { good: 100, needsImprovement: 300 },
      // First Input Delay (ms)
      cls: { good: 0.1, needsImprovement: 0.25 },
      // Cumulative Layout Shift (score)
      ttfb: { good: 800, needsImprovement: 1800 },
      // Time to First Byte (ms)
      fcp: { good: 1800, needsImprovement: 3e3 },
      // First Contentful Paint (ms)
      inp: { good: 200, needsImprovement: 500 },
      // Interaction to Next Paint (ms)
      si: { good: 3400, needsImprovement: 5800 },
      // Speed Index (ms)
      tbt: { good: 200, needsImprovement: 600 },
      // Total Blocking Time (ms)
      tti: { good: 3800, needsImprovement: 7300 }
      // Time to Interactive (ms)
    };
    this.weights = {
      lcp: 0.25,
      fid: 0.1,
      cls: 0.15,
      ttfb: 0.1,
      fcp: 0.1,
      inp: 0.1,
      tbt: 0.1,
      tti: 0.1
    };
  }
  /**
   * Collect all performance metrics from page
   * @param {Page} page - Puppeteer page
   * @param {Object} options - Collection options
   * @returns {Promise<Object>} Performance report
   */
  async collectMetrics(page, options = {}) {
    const {
      waitForLoad = true,
      collectResources = true,
      collectMemory = true,
      collectScreenshots = false,
      customMetrics = null
    } = options;
    const startTime = Date.now();
    try {
      if (waitForLoad) {
        await page.waitForLoadState("load", { timeout: 3e4 }).catch(() => {
        });
      }
      await this._injectWebVitalsScript(page);
      await this._delay(1e3);
      const [
        coreWebVitals,
        navigationTiming,
        resourceTiming,
        paintTiming,
        memoryInfo
      ] = await Promise.all([
        this._collectCoreWebVitals(page),
        this._collectNavigationTiming(page),
        collectResources ? this._collectResourceTiming(page) : null,
        this._collectPaintTiming(page),
        collectMemory ? this._collectMemoryInfo(page) : null
      ]);
      let customMetricsData = null;
      if (customMetrics && typeof customMetrics === "function") {
        customMetricsData = await customMetrics(page);
      }
      const derivedMetrics = this._calculateDerivedMetrics(navigationTiming, resourceTiming);
      const scores = this._calculateScores({
        ...coreWebVitals,
        ...derivedMetrics
      });
      let screenshots = null;
      if (collectScreenshots) {
        screenshots = await this._collectScreenshots(page);
      }
      const collectionTime = Date.now() - startTime;
      const report = {
        url: page.url(),
        timestamp: Date.now(),
        collectionTime,
        // Overall score (0-100)
        score: scores.overall,
        // Individual scores
        scores: scores.individual,
        // Core Web Vitals
        coreWebVitals,
        // Timing APIs
        navigationTiming,
        paintTiming,
        // Resource data
        resources: resourceTiming ? {
          summary: this._summarizeResources(resourceTiming),
          details: resourceTiming
        } : null,
        // Memory usage
        memory: memoryInfo,
        // Derived metrics
        derived: derivedMetrics,
        // Custom metrics
        custom: customMetricsData,
        // Screenshots
        screenshots,
        // Recommendations
        recommendations: this._generateRecommendations({
          ...coreWebVitals,
          ...derivedMetrics
        }, resourceTiming)
      };
      this.plugin.emit("performance.metricsCollected", {
        url: page.url(),
        score: report.score,
        collectionTime
      });
      return report;
    } catch (err) {
      this.plugin.emit("performance.collectionFailed", {
        url: page.url(),
        error: err.message
      });
      throw err;
    }
  }
  /**
   * Inject Web Vitals measurement script
   * @private
   */
  async _injectWebVitalsScript(page) {
    await page.evaluateOnNewDocument(() => {
      window.__WEB_VITALS__ = {
        lcp: null,
        fid: null,
        cls: null,
        inp: null,
        fcp: null,
        ttfb: null
      };
      const lcpObserver = new PerformanceObserver((list) => {
        const entries = list.getEntries();
        const lastEntry = entries[entries.length - 1];
        window.__WEB_VITALS__.lcp = lastEntry.renderTime || lastEntry.loadTime;
      });
      lcpObserver.observe({ type: "largest-contentful-paint", buffered: true });
      const fidObserver = new PerformanceObserver((list) => {
        const entries = list.getEntries();
        entries.forEach((entry) => {
          if (!window.__WEB_VITALS__.fid) {
            window.__WEB_VITALS__.fid = entry.processingStart - entry.startTime;
          }
        });
      });
      fidObserver.observe({ type: "first-input", buffered: true });
      let clsValue = 0;
      const clsObserver = new PerformanceObserver((list) => {
        for (const entry of list.getEntries()) {
          if (!entry.hadRecentInput) {
            clsValue += entry.value;
          }
        }
        window.__WEB_VITALS__.cls = clsValue;
      });
      clsObserver.observe({ type: "layout-shift", buffered: true });
      const inpObserver = new PerformanceObserver((list) => {
        const entries = list.getEntries();
        entries.forEach((entry) => {
          const duration = entry.processingEnd - entry.startTime;
          if (!window.__WEB_VITALS__.inp || duration > window.__WEB_VITALS__.inp) {
            window.__WEB_VITALS__.inp = duration;
          }
        });
      });
      inpObserver.observe({ type: "event", buffered: true, durationThreshold: 16 });
      window.addEventListener("load", () => {
        const navTiming = performance.getEntriesByType("navigation")[0];
        if (navTiming) {
          window.__WEB_VITALS__.ttfb = navTiming.responseStart - navTiming.requestStart;
        }
        const fcpEntry = performance.getEntriesByName("first-contentful-paint")[0];
        if (fcpEntry) {
          window.__WEB_VITALS__.fcp = fcpEntry.startTime;
        }
      });
    });
  }
  /**
   * Collect Core Web Vitals
   * @private
   */
  async _collectCoreWebVitals(page) {
    const vitals = await page.evaluate(() => {
      return window.__WEB_VITALS__ || {};
    });
    return {
      lcp: vitals.lcp || null,
      fid: vitals.fid || null,
      cls: vitals.cls || null,
      inp: vitals.inp || null,
      fcp: vitals.fcp || null,
      ttfb: vitals.ttfb || null
    };
  }
  /**
   * Collect Navigation Timing API metrics
   * @private
   */
  async _collectNavigationTiming(page) {
    return await page.evaluate(() => {
      const nav = performance.getEntriesByType("navigation")[0];
      if (!nav) return null;
      return {
        // DNS
        dnsStart: nav.domainLookupStart,
        dnsEnd: nav.domainLookupEnd,
        dnsDuration: nav.domainLookupEnd - nav.domainLookupStart,
        // TCP
        tcpStart: nav.connectStart,
        tcpEnd: nav.connectEnd,
        tcpDuration: nav.connectEnd - nav.connectStart,
        // TLS/SSL
        tlsStart: nav.secureConnectionStart,
        tlsDuration: nav.secureConnectionStart > 0 ? nav.connectEnd - nav.secureConnectionStart : 0,
        // Request/Response
        requestStart: nav.requestStart,
        responseStart: nav.responseStart,
        responseEnd: nav.responseEnd,
        requestDuration: nav.responseStart - nav.requestStart,
        responseDuration: nav.responseEnd - nav.responseStart,
        // DOM Processing
        domInteractive: nav.domInteractive,
        domContentLoaded: nav.domContentLoadedEventEnd,
        domComplete: nav.domComplete,
        // Load Events
        loadEventStart: nav.loadEventStart,
        loadEventEnd: nav.loadEventEnd,
        loadEventDuration: nav.loadEventEnd - nav.loadEventStart,
        // Total times
        redirectTime: nav.redirectEnd - nav.redirectStart,
        fetchTime: nav.responseEnd - nav.fetchStart,
        totalTime: nav.loadEventEnd - nav.fetchStart,
        // Transfer size
        transferSize: nav.transferSize,
        encodedBodySize: nav.encodedBodySize,
        decodedBodySize: nav.decodedBodySize
      };
    });
  }
  /**
   * Collect Resource Timing API metrics
   * @private
   */
  async _collectResourceTiming(page) {
    return await page.evaluate(() => {
      const resources = performance.getEntriesByType("resource");
      return resources.map((resource) => ({
        name: resource.name,
        type: resource.initiatorType,
        startTime: resource.startTime,
        duration: resource.duration,
        transferSize: resource.transferSize,
        encodedBodySize: resource.encodedBodySize,
        decodedBodySize: resource.decodedBodySize,
        // Timing breakdown
        dns: resource.domainLookupEnd - resource.domainLookupStart,
        tcp: resource.connectEnd - resource.connectStart,
        tls: resource.secureConnectionStart > 0 ? resource.connectEnd - resource.secureConnectionStart : 0,
        request: resource.responseStart - resource.requestStart,
        response: resource.responseEnd - resource.responseStart,
        // Caching
        cached: resource.transferSize === 0 && resource.decodedBodySize > 0
      }));
    });
  }
  /**
   * Collect Paint Timing API metrics
   * @private
   */
  async _collectPaintTiming(page) {
    return await page.evaluate(() => {
      const paintEntries = performance.getEntriesByType("paint");
      const result = {};
      paintEntries.forEach((entry) => {
        result[entry.name] = entry.startTime;
      });
      return result;
    });
  }
  /**
   * Collect memory information
   * @private
   */
  async _collectMemoryInfo(page) {
    try {
      const memoryInfo = await page.evaluate(() => {
        if (performance.memory) {
          return {
            usedJSHeapSize: performance.memory.usedJSHeapSize,
            totalJSHeapSize: performance.memory.totalJSHeapSize,
            jsHeapSizeLimit: performance.memory.jsHeapSizeLimit,
            usedPercent: performance.memory.usedJSHeapSize / performance.memory.jsHeapSizeLimit * 100
          };
        }
        return null;
      });
      return memoryInfo;
    } catch (err) {
      return null;
    }
  }
  /**
   * Calculate derived metrics
   * @private
   */
  _calculateDerivedMetrics(navigationTiming, resourceTiming) {
    if (!navigationTiming) return {};
    const derived = {
      // Time to Interactive (simplified calculation)
      tti: navigationTiming.domInteractive,
      // Total Blocking Time (simplified - would need long task API)
      tbt: Math.max(0, navigationTiming.domContentLoaded - navigationTiming.domInteractive - 50),
      // Speed Index (simplified approximation)
      si: navigationTiming.domContentLoaded
    };
    if (resourceTiming && resourceTiming.length > 0) {
      const totalSize = resourceTiming.reduce((sum, r) => sum + (r.transferSize || 0), 0);
      const totalRequests = resourceTiming.length;
      const cachedRequests = resourceTiming.filter((r) => r.cached).length;
      const avgDuration = resourceTiming.reduce((sum, r) => sum + r.duration, 0) / totalRequests;
      derived.resources = {
        totalRequests,
        totalSize,
        cachedRequests,
        cacheRate: cachedRequests / totalRequests,
        avgDuration
      };
      const byType = {};
      resourceTiming.forEach((r) => {
        if (!byType[r.type]) {
          byType[r.type] = { count: 0, size: 0, duration: 0 };
        }
        byType[r.type].count++;
        byType[r.type].size += r.transferSize || 0;
        byType[r.type].duration += r.duration;
      });
      derived.resourcesByType = Object.entries(byType).map(([type, data]) => ({
        type,
        count: data.count,
        totalSize: data.size,
        avgDuration: data.duration / data.count
      }));
    }
    return derived;
  }
  /**
   * Calculate performance scores
   * @private
   */
  _calculateScores(metrics) {
    const individual = {};
    let weightedSum = 0;
    let totalWeight = 0;
    Object.keys(this.thresholds).forEach((metric) => {
      const value = metrics[metric];
      const threshold = this.thresholds[metric];
      const weight = this.weights[metric] || 0;
      if (value === null || value === void 0) {
        individual[metric] = null;
        return;
      }
      let score;
      if (metric === "cls") {
        if (value <= threshold.good) {
          score = 100;
        } else if (value <= threshold.needsImprovement) {
          score = 50 + 50 * (threshold.needsImprovement - value) / (threshold.needsImprovement - threshold.good);
        } else {
          score = Math.max(0, 50 * (1 - (value - threshold.needsImprovement) / threshold.needsImprovement));
        }
      } else {
        if (value <= threshold.good) {
          score = 100;
        } else if (value <= threshold.needsImprovement) {
          score = 50 + 50 * (threshold.needsImprovement - value) / (threshold.needsImprovement - threshold.good);
        } else {
          score = Math.max(0, 50 * (1 - (value - threshold.needsImprovement) / threshold.needsImprovement));
        }
      }
      individual[metric] = Math.round(score);
      if (weight > 0) {
        weightedSum += score * weight;
        totalWeight += weight;
      }
    });
    const overall = totalWeight > 0 ? Math.round(weightedSum / totalWeight) : null;
    return {
      overall,
      individual
    };
  }
  /**
   * Summarize resource timing data
   * @private
   */
  _summarizeResources(resources) {
    const summary = {
      total: resources.length,
      byType: {},
      totalSize: 0,
      totalDuration: 0,
      cached: 0,
      slowest: []
    };
    resources.forEach((resource) => {
      const type = resource.type || "other";
      if (!summary.byType[type]) {
        summary.byType[type] = { count: 0, size: 0, duration: 0 };
      }
      summary.byType[type].count++;
      summary.byType[type].size += resource.transferSize || 0;
      summary.byType[type].duration += resource.duration;
      summary.totalSize += resource.transferSize || 0;
      summary.totalDuration += resource.duration;
      if (resource.cached) summary.cached++;
    });
    summary.slowest = resources.sort((a, b) => b.duration - a.duration).slice(0, 10).map((r) => ({
      name: r.name,
      type: r.type,
      duration: Math.round(r.duration),
      size: r.transferSize
    }));
    return summary;
  }
  /**
   * Generate performance recommendations
   * @private
   */
  _generateRecommendations(metrics, resources) {
    const recommendations = [];
    if (metrics.lcp && metrics.lcp > this.thresholds.lcp.needsImprovement) {
      recommendations.push({
        metric: "lcp",
        severity: "high",
        message: `LCP is ${Math.round(metrics.lcp)}ms (target: <${this.thresholds.lcp.good}ms)`,
        suggestions: [
          "Optimize largest image/element loading",
          "Use lazy loading for below-the-fold content",
          "Reduce server response times",
          "Use CDN for static assets"
        ]
      });
    }
    if (metrics.fid && metrics.fid > this.thresholds.fid.needsImprovement) {
      recommendations.push({
        metric: "fid",
        severity: "high",
        message: `FID is ${Math.round(metrics.fid)}ms (target: <${this.thresholds.fid.good}ms)`,
        suggestions: [
          "Break up long JavaScript tasks",
          "Use web workers for heavy computations",
          "Defer non-critical JavaScript",
          "Reduce JavaScript execution time"
        ]
      });
    }
    if (metrics.cls && metrics.cls > this.thresholds.cls.needsImprovement) {
      recommendations.push({
        metric: "cls",
        severity: "high",
        message: `CLS is ${metrics.cls.toFixed(3)} (target: <${this.thresholds.cls.good})`,
        suggestions: [
          "Set explicit width/height on images and videos",
          "Reserve space for ads and embeds",
          "Avoid inserting content above existing content",
          "Use transform animations instead of layout-triggering properties"
        ]
      });
    }
    if (metrics.ttfb && metrics.ttfb > this.thresholds.ttfb.needsImprovement) {
      recommendations.push({
        metric: "ttfb",
        severity: "medium",
        message: `TTFB is ${Math.round(metrics.ttfb)}ms (target: <${this.thresholds.ttfb.good}ms)`,
        suggestions: [
          "Optimize server processing time",
          "Use server-side caching",
          "Use a CDN",
          "Reduce server redirects"
        ]
      });
    }
    if (resources && resources.length > 0) {
      const totalSize = resources.reduce((sum, r) => sum + (r.transferSize || 0), 0);
      resources.filter((r) => !r.cached).reduce((sum, r) => sum + (r.transferSize || 0), 0);
      if (totalSize > 5 * 1024 * 1024) {
        recommendations.push({
          metric: "resources",
          severity: "medium",
          message: `Total page size is ${(totalSize / 1024 / 1024).toFixed(2)}MB`,
          suggestions: [
            "Compress images and use modern formats (WebP, AVIF)",
            "Minify CSS and JavaScript",
            "Remove unused code",
            "Use code splitting"
          ]
        });
      }
      const cacheRate = (resources.length - resources.filter((r) => !r.cached).length) / resources.length;
      if (cacheRate < 0.5) {
        recommendations.push({
          metric: "caching",
          severity: "low",
          message: `Only ${(cacheRate * 100).toFixed(0)}% of resources are cached`,
          suggestions: [
            "Set appropriate cache headers",
            "Use service workers for offline caching",
            "Implement browser caching strategy"
          ]
        });
      }
    }
    return recommendations;
  }
  /**
   * Collect screenshots at key moments
   * @private
   */
  async _collectScreenshots(page) {
    try {
      const screenshots = {
        final: await page.screenshot({ encoding: "base64" })
      };
      return screenshots;
    } catch (err) {
      return null;
    }
  }
  /**
   * Compare two performance reports
   * @param {Object} baseline - Baseline report
   * @param {Object} current - Current report
   * @returns {Object} Comparison result
   */
  compareReports(baseline, current) {
    const comparison = {
      timestamp: Date.now(),
      baseline: {
        url: baseline.url,
        timestamp: baseline.timestamp,
        score: baseline.score
      },
      current: {
        url: current.url,
        timestamp: current.timestamp,
        score: current.score
      },
      scoreDelta: current.score - baseline.score,
      improvements: [],
      regressions: []
    };
    Object.keys(baseline.coreWebVitals).forEach((metric) => {
      const baselineValue = baseline.coreWebVitals[metric];
      const currentValue = current.coreWebVitals[metric];
      if (baselineValue && currentValue) {
        const delta = currentValue - baselineValue;
        const percentChange = delta / baselineValue * 100;
        const change = {
          metric,
          baseline: baselineValue,
          current: currentValue,
          delta,
          percentChange: percentChange.toFixed(2)
        };
        if (delta < 0) {
          comparison.improvements.push(change);
        } else if (delta > 0) {
          comparison.regressions.push(change);
        }
      }
    });
    return comparison;
  }
  /**
   * Delay helper
   * @private
   */
  async _delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}

var performanceManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  PerformanceManager: PerformanceManager
});

class NetworkMonitor {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.networkMonitor || {
      enabled: false,
      persist: false,
      filters: {
        types: null,
        // ['image', 'script', 'stylesheet'] or null for all
        statuses: null,
        // [404, 500] or null for all
        minSize: null,
        // Only requests >= this size (bytes)
        maxSize: null,
        // Only requests <= this size (bytes)
        saveErrors: true,
        // Always save failed requests
        saveLargeAssets: true
        // Always save assets > 1MB
      },
      compression: {
        enabled: true,
        threshold: 10240
        // Compress payloads > 10KB
      }
    };
    this.sessionsResource = null;
    this.requestsResource = null;
    this.errorsResource = null;
    this.resourceTypes = {
      "Document": "document",
      "Stylesheet": "stylesheet",
      "Image": "image",
      "Media": "media",
      "Font": "font",
      "Script": "script",
      "TextTrack": "texttrack",
      "XHR": "xhr",
      "Fetch": "fetch",
      "EventSource": "eventsource",
      "WebSocket": "websocket",
      "Manifest": "manifest",
      "SignedExchange": "signedexchange",
      "Ping": "ping",
      "CSPViolationReport": "cspviolation",
      "Preflight": "preflight",
      "Other": "other"
    };
  }
  /**
   * Initialize network monitoring resources
   */
  async initialize() {
    if (!this.config.persist) {
      return;
    }
    const resourceNames = this.plugin.resourceNames || {};
    const sessionsName = resourceNames.networkSessions || "plg_puppeteer_network_sessions";
    const requestsName = resourceNames.networkRequests || "plg_puppeteer_network_requests";
    const errorsName = resourceNames.networkErrors || "plg_puppeteer_network_errors";
    const [sessionsCreated, sessionsErr, sessionsResource] = await tryFn(() => this.plugin.database.createResource({
      name: sessionsName,
      attributes: {
        sessionId: "string|required",
        url: "string|required",
        domain: "string|required",
        date: "string|required",
        // YYYY-MM-DD for partitioning
        startTime: "number|required",
        endTime: "number",
        duration: "number",
        // Summary statistics
        totalRequests: "number",
        successfulRequests: "number",
        failedRequests: "number",
        totalBytes: "number",
        transferredBytes: "number",
        cachedBytes: "number",
        // By type
        byType: "object",
        // { image: { count, size }, script: {...} }
        // Performance metrics
        performance: "object",
        // From PerformanceManager
        // User agent
        userAgent: "string"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        byUrl: { fields: { url: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (sessionsCreated) {
      this.sessionsResource = sessionsResource;
    } else if (this.plugin.database.resources?.[sessionsName]) {
      this.sessionsResource = this.plugin.database.resources[sessionsName];
    } else {
      throw sessionsErr;
    }
    const [requestsCreated, requestsErr, requestsResource] = await tryFn(() => this.plugin.database.createResource({
      name: requestsName,
      attributes: {
        requestId: "string|required",
        sessionId: "string|required",
        url: "string|required",
        domain: "string|required",
        path: "string",
        // Type and categorization
        type: "string|required",
        // image, script, stylesheet, xhr, etc.
        statusCode: "number",
        statusText: "string",
        method: "string",
        // GET, POST, etc.
        // Size information
        size: "number",
        // Total size (bytes)
        transferredSize: "number",
        // Bytes transferred (after compression)
        resourceSize: "number",
        // Uncompressed size
        fromCache: "boolean",
        // Timing information (ms)
        timing: "object",
        // { dns, tcp, ssl, request, response, total }
        startTime: "number",
        endTime: "number",
        duration: "number",
        // Headers (compressed if large)
        requestHeaders: "object",
        responseHeaders: "object",
        // Compression
        compression: "string",
        // gzip, br (brotli), deflate, none
        // Cache
        cacheControl: "string",
        expires: "string",
        // Error information (if failed)
        failed: "boolean",
        errorText: "string",
        blockedReason: "string",
        // CSP, mixed-content, etc.
        // Redirects
        redirected: "boolean",
        redirectUrl: "string",
        // CDN detection
        cdn: "string",
        // cloudflare, cloudfront, fastly, etc.
        cdnDetected: "boolean",
        // Metadata
        mimeType: "string",
        priority: "string"
        // VeryHigh, High, Medium, Low, VeryLow
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        bySession: { fields: { sessionId: "string" } },
        byType: { fields: { type: "string" } },
        byStatus: { fields: { statusCode: "number" } },
        bySize: { fields: { size: "number" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (requestsCreated) {
      this.requestsResource = requestsResource;
    } else if (this.plugin.database.resources?.[requestsName]) {
      this.requestsResource = this.plugin.database.resources[requestsName];
    } else {
      throw requestsErr;
    }
    const [errorsCreated, errorsErr, errorsResource] = await tryFn(() => this.plugin.database.createResource({
      name: errorsName,
      attributes: {
        errorId: "string|required",
        sessionId: "string|required",
        requestId: "string|required",
        url: "string|required",
        domain: "string|required",
        date: "string|required",
        // YYYY-MM-DD
        // Error details
        errorType: "string|required",
        // net::ERR_*, failed, timeout, blocked
        errorText: "string",
        statusCode: "number",
        // Context
        type: "string",
        // Resource type
        method: "string",
        timing: "object",
        // Additional info
        blockedReason: "string",
        consoleMessages: "array"
        // Related console errors
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        bySession: { fields: { sessionId: "string" } },
        byErrorType: { fields: { errorType: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (errorsCreated) {
      this.errorsResource = errorsResource;
    } else if (this.plugin.database.resources?.[errorsName]) {
      this.errorsResource = this.plugin.database.resources[errorsName];
    } else {
      throw errorsErr;
    }
    this.plugin.emit("networkMonitor.initialized", {
      persist: this.config.persist
    });
  }
  /**
   * Start monitoring network activity for a page
   * @param {Page} page - Puppeteer page
   * @param {Object} options - Monitoring options
   * @returns {Object} Session object with methods
   */
  async startMonitoring(page, options = {}) {
    const {
      sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      persist = this.config.persist,
      filters = this.config.filters
    } = options;
    const session = {
      sessionId,
      url: page.url(),
      domain: this._extractDomain(page.url()),
      date: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
      startTime: Date.now(),
      endTime: null,
      duration: null,
      // Tracked data
      requests: /* @__PURE__ */ new Map(),
      // requestId -> request data
      responses: /* @__PURE__ */ new Map(),
      // requestId -> response data
      failures: [],
      consoleMessages: [],
      // Statistics
      stats: {
        totalRequests: 0,
        successfulRequests: 0,
        failedRequests: 0,
        totalBytes: 0,
        transferredBytes: 0,
        cachedBytes: 0,
        byType: {}
      }
    };
    const client = await page.target().createCDPSession();
    await client.send("Network.enable");
    client.on("Network.requestWillBeSent", (params) => {
      const requestData = {
        requestId: params.requestId,
        url: params.request.url,
        domain: this._extractDomain(params.request.url),
        path: this._extractPath(params.request.url),
        type: this.resourceTypes[params.type] || "other",
        method: params.request.method,
        requestHeaders: params.request.headers,
        priority: params.request.initialPriority,
        startTime: params.timestamp * 1e3,
        // Convert to ms
        redirected: !!params.redirectResponse,
        redirectUrl: params.redirectResponse?.url || null
      };
      session.requests.set(params.requestId, requestData);
      session.stats.totalRequests++;
    });
    client.on("Network.responseReceived", (params) => {
      const responseData = {
        requestId: params.requestId,
        statusCode: params.response.status,
        statusText: params.response.statusText,
        mimeType: params.response.mimeType,
        responseHeaders: params.response.headers,
        fromCache: params.response.fromDiskCache || params.response.fromServiceWorker,
        compression: this._detectCompression(params.response.headers),
        cacheControl: params.response.headers["cache-control"] || params.response.headers["Cache-Control"],
        expires: params.response.headers["expires"] || params.response.headers["Expires"],
        timing: params.response.timing ? this._parseTiming(params.response.timing) : null,
        cdn: this._detectCDN(params.response.headers),
        cdnDetected: !!this._detectCDN(params.response.headers)
      };
      session.responses.set(params.requestId, responseData);
    });
    client.on("Network.loadingFinished", (params) => {
      const request = session.requests.get(params.requestId);
      const response = session.responses.get(params.requestId);
      if (request && response) {
        const endTime = params.timestamp * 1e3;
        const duration = endTime - request.startTime;
        const combined = {
          ...request,
          ...response,
          endTime,
          duration,
          size: params.encodedDataLength,
          transferredSize: params.encodedDataLength,
          resourceSize: params.decodedBodyLength || params.encodedDataLength,
          failed: false
        };
        if (this._passesFilters(combined, filters)) {
          session.requests.set(params.requestId, combined);
          session.stats.successfulRequests++;
          session.stats.totalBytes += combined.resourceSize || 0;
          session.stats.transferredBytes += combined.transferredSize || 0;
          if (combined.fromCache) {
            session.stats.cachedBytes += combined.resourceSize || 0;
          }
          const type = combined.type;
          if (!session.stats.byType[type]) {
            session.stats.byType[type] = { count: 0, size: 0, transferredSize: 0 };
          }
          session.stats.byType[type].count++;
          session.stats.byType[type].size += combined.resourceSize || 0;
          session.stats.byType[type].transferredSize += combined.transferredSize || 0;
        } else {
          session.requests.delete(params.requestId);
        }
      }
    });
    client.on("Network.loadingFailed", (params) => {
      const request = session.requests.get(params.requestId);
      if (request) {
        const errorData = {
          ...request,
          failed: true,
          errorText: params.errorText,
          blockedReason: params.blockedReason,
          endTime: params.timestamp * 1e3,
          duration: params.timestamp * 1e3 - request.startTime
        };
        session.failures.push(errorData);
        session.stats.failedRequests++;
        if (!filters.saveErrors) {
          session.requests.delete(params.requestId);
        } else {
          session.requests.set(params.requestId, errorData);
        }
      }
    });
    page.on("console", (msg) => {
      if (msg.type() === "error" || msg.type() === "warning") {
        session.consoleMessages.push({
          type: msg.type(),
          text: msg.text(),
          timestamp: Date.now()
        });
      }
    });
    session._cdpSession = client;
    session._persist = persist;
    session._page = page;
    this.plugin.emit("networkMonitor.sessionStarted", {
      sessionId,
      url: page.url()
    });
    return session;
  }
  /**
   * Stop monitoring and optionally persist data
   * @param {Object} session - Session object from startMonitoring
   * @param {Object} options - Stop options
   * @returns {Object} Final session data
   */
  async stopMonitoring(session, options = {}) {
    const {
      persist = session._persist,
      includePerformance = true
    } = options;
    session.endTime = Date.now();
    session.duration = session.endTime - session.startTime;
    if (includePerformance && this.plugin.performanceManager && session._page) {
      try {
        session.performance = await this.plugin.performanceManager.collectMetrics(session._page, {
          waitForLoad: false,
          collectResources: false,
          // We already have this from CDP
          collectMemory: true
        });
      } catch (err) {
        this.plugin.emit("networkMonitor.performanceCollectionFailed", {
          sessionId: session.sessionId,
          error: err.message
        });
      }
    }
    if (session._cdpSession) {
      try {
        await session._cdpSession.send("Network.disable");
        await session._cdpSession.detach();
      } catch (err) {
      }
    }
    const requestsArray = Array.from(session.requests.values());
    if (persist && this.sessionsResource) {
      try {
        await this._persistSession(session, requestsArray);
      } catch (err) {
        this.plugin.emit("networkMonitor.persistFailed", {
          sessionId: session.sessionId,
          error: err.message
        });
      }
    }
    this.plugin.emit("networkMonitor.sessionStopped", {
      sessionId: session.sessionId,
      duration: session.duration,
      totalRequests: session.stats.totalRequests,
      failedRequests: session.stats.failedRequests
    });
    delete session._cdpSession;
    delete session._page;
    return {
      ...session,
      requests: requestsArray
    };
  }
  /**
   * Persist session data to S3DB
   * @private
   */
  async _persistSession(session, requests) {
    const startPersist = Date.now();
    await this.sessionsResource.insert({
      sessionId: session.sessionId,
      url: session.url,
      domain: session.domain,
      date: session.date,
      startTime: session.startTime,
      endTime: session.endTime,
      duration: session.duration,
      totalRequests: session.stats.totalRequests,
      successfulRequests: session.stats.successfulRequests,
      failedRequests: session.stats.failedRequests,
      totalBytes: session.stats.totalBytes,
      transferredBytes: session.stats.transferredBytes,
      cachedBytes: session.stats.cachedBytes,
      byType: session.stats.byType,
      performance: session.performance ? {
        score: session.performance.score,
        lcp: session.performance.coreWebVitals.lcp,
        cls: session.performance.coreWebVitals.cls,
        fcp: session.performance.coreWebVitals.fcp
      } : null,
      userAgent: session._page?._userAgent || null
    });
    if (requests.length > 0) {
      const requestInserts = requests.map((req) => ({
        requestId: req.requestId,
        sessionId: session.sessionId,
        url: req.url,
        domain: req.domain,
        path: req.path,
        type: req.type,
        statusCode: req.statusCode,
        statusText: req.statusText,
        method: req.method,
        size: req.resourceSize,
        transferredSize: req.transferredSize,
        resourceSize: req.resourceSize,
        fromCache: req.fromCache,
        timing: req.timing,
        startTime: req.startTime,
        endTime: req.endTime,
        duration: req.duration,
        requestHeaders: this._compressHeaders(req.requestHeaders),
        responseHeaders: this._compressHeaders(req.responseHeaders),
        compression: req.compression,
        cacheControl: req.cacheControl,
        expires: req.expires,
        failed: req.failed,
        errorText: req.errorText,
        blockedReason: req.blockedReason,
        redirected: req.redirected,
        redirectUrl: req.redirectUrl,
        cdn: req.cdn,
        cdnDetected: req.cdnDetected,
        mimeType: req.mimeType,
        priority: req.priority
      }));
      for (const request of requestInserts) {
        await this.requestsResource.insert(request);
      }
    }
    if (session.failures.length > 0) {
      for (const failure of session.failures) {
        await this.errorsResource.insert({
          errorId: `error_${failure.requestId}`,
          sessionId: session.sessionId,
          requestId: failure.requestId,
          url: failure.url,
          domain: failure.domain,
          date: session.date,
          errorType: this._categorizeError(failure.errorText),
          errorText: failure.errorText,
          statusCode: failure.statusCode,
          type: failure.type,
          method: failure.method,
          timing: failure.timing,
          blockedReason: failure.blockedReason,
          consoleMessages: session.consoleMessages.filter((msg) => Math.abs(msg.timestamp - failure.endTime) < 1e3).map((msg) => msg.text)
        });
      }
    }
    const persistDuration = Date.now() - startPersist;
    this.plugin.emit("networkMonitor.persisted", {
      sessionId: session.sessionId,
      requests: requests.length,
      errors: session.failures.length,
      duration: persistDuration
    });
  }
  /**
   * Check if request passes filters
   * @private
   */
  _passesFilters(request, filters) {
    if (filters.types && !filters.types.includes(request.type)) {
      return false;
    }
    if (filters.statuses && !filters.statuses.includes(request.statusCode)) {
      return false;
    }
    if (filters.minSize && (request.resourceSize || 0) < filters.minSize) {
      return false;
    }
    if (filters.maxSize && (request.resourceSize || 0) > filters.maxSize) {
      return false;
    }
    if (filters.saveLargeAssets && (request.resourceSize || 0) > 1024 * 1024) {
      return true;
    }
    return true;
  }
  /**
   * Extract domain from URL
   * @private
   */
  _extractDomain(url) {
    try {
      return new URL(url).hostname;
    } catch {
      return "unknown";
    }
  }
  /**
   * Extract path from URL
   * @private
   */
  _extractPath(url) {
    try {
      return new URL(url).pathname;
    } catch {
      return "";
    }
  }
  /**
   * Detect compression algorithm
   * @private
   */
  _detectCompression(headers) {
    const encoding = headers["content-encoding"] || headers["Content-Encoding"] || "";
    if (encoding.includes("br")) return "brotli";
    if (encoding.includes("gzip")) return "gzip";
    if (encoding.includes("deflate")) return "deflate";
    return "none";
  }
  /**
   * Detect CDN provider
   * @private
   */
  _detectCDN(headers) {
    const server = headers["server"] || headers["Server"] || "";
    const via = headers["via"] || headers["Via"] || "";
    const cfRay = headers["cf-ray"] || headers["CF-Ray"];
    const xCache = headers["x-cache"] || headers["X-Cache"] || "";
    if (cfRay || server.includes("cloudflare")) return "cloudflare";
    if (xCache.includes("cloudfront") || headers["x-amz-cf-id"]) return "cloudfront";
    if (server.includes("fastly") || via.includes("fastly")) return "fastly";
    if (headers["x-akamai-transformed"] || headers["x-akamai-staging"]) return "akamai";
    if (headers["x-cdn"] || headers["X-CDN"]) return headers["x-cdn"] || headers["X-CDN"];
    return null;
  }
  /**
   * Parse timing data
   * @private
   */
  _parseTiming(timing) {
    if (!timing) return null;
    return {
      dns: timing.dnsEnd - timing.dnsStart,
      tcp: timing.connectEnd - timing.connectStart,
      ssl: timing.sslEnd - timing.sslStart,
      request: timing.sendEnd - timing.sendStart,
      response: timing.receiveHeadersEnd - timing.sendEnd,
      total: timing.receiveHeadersEnd
    };
  }
  /**
   * Compress headers (remove unnecessary data)
   * @private
   */
  _compressHeaders(headers) {
    if (!headers) return {};
    const compressed = { ...headers };
    const toRemove = ["cookie", "Cookie", "set-cookie", "Set-Cookie"];
    toRemove.forEach((key) => delete compressed[key]);
    return compressed;
  }
  /**
   * Categorize error type
   * @private
   */
  _categorizeError(errorText) {
    if (!errorText) return "unknown";
    if (errorText.includes("ERR_NAME_NOT_RESOLVED")) return "dns";
    if (errorText.includes("ERR_CONNECTION")) return "connection";
    if (errorText.includes("ERR_TIMED_OUT")) return "timeout";
    if (errorText.includes("ERR_SSL")) return "ssl";
    if (errorText.includes("ERR_CERT")) return "certificate";
    if (errorText.includes("ERR_BLOCKED")) return "blocked";
    if (errorText.includes("ERR_FAILED")) return "failed";
    if (errorText.includes("ERR_ABORTED")) return "aborted";
    return "other";
  }
  /**
   * Get session statistics
   * @param {string} sessionId - Session ID
   * @returns {Promise<Object>} Statistics
   */
  async getSessionStats(sessionId) {
    if (!this.sessionsResource) {
      throw new PuppeteerError("Network monitoring persistence not enabled", {
        operation: "getSessionStats",
        retriable: false,
        suggestion: "Enable persistence in NetworkMonitor configuration to query stored stats."
      });
    }
    const session = await this.sessionsResource.get(sessionId);
    return session;
  }
  /**
   * Query requests for a session
   * @param {string} sessionId - Session ID
   * @param {Object} filters - Query filters
   * @returns {Promise<Array>} Requests
   */
  async getSessionRequests(sessionId, filters = {}) {
    if (!this.requestsResource) {
      throw new PuppeteerError("Network monitoring persistence not enabled", {
        operation: "getSessionRequests",
        retriable: false,
        suggestion: "Enable persistence in NetworkMonitor configuration to query stored requests."
      });
    }
    return await this.requestsResource.listPartition("bySession", { sessionId }, filters);
  }
  /**
   * Query errors for a session
   * @param {string} sessionId - Session ID
   * @returns {Promise<Array>} Errors
   */
  async getSessionErrors(sessionId) {
    if (!this.errorsResource) {
      throw new PuppeteerError("Network monitoring persistence not enabled", {
        operation: "getSessionErrors",
        retriable: false,
        suggestion: "Enable persistence in NetworkMonitor configuration to query stored errors."
      });
    }
    return await this.errorsResource.listPartition("bySession", { sessionId });
  }
}

var networkMonitor = /*#__PURE__*/Object.freeze({
  __proto__: null,
  NetworkMonitor: NetworkMonitor
});

class ConsoleMonitor {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.consoleMonitor || {
      enabled: false,
      persist: false,
      filters: {
        levels: null,
        // ['error', 'warning'] or null for all
        excludePatterns: [],
        // Regex patterns to exclude
        includeStackTraces: true,
        includeSourceLocation: true,
        captureNetwork: false
        // Also capture network errors from console
      }
    };
    this.sessionsResource = null;
    this.messagesResource = null;
    this.errorsResource = null;
    this.messageTypes = {
      "log": "log",
      "debug": "debug",
      "info": "info",
      "error": "error",
      "warning": "warning",
      "warn": "warning",
      // Alias
      "dir": "dir",
      "dirxml": "dirxml",
      "table": "table",
      "trace": "trace",
      "clear": "clear",
      "startGroup": "group",
      "startGroupCollapsed": "groupCollapsed",
      "endGroup": "groupEnd",
      "assert": "assert",
      "profile": "profile",
      "profileEnd": "profileEnd",
      "count": "count",
      "timeEnd": "timeEnd",
      "verbose": "verbose"
    };
  }
  /**
   * Initialize console monitoring resources
   */
  async initialize() {
    if (!this.config.persist) {
      return;
    }
    const resourceNames = this.plugin.resourceNames || {};
    const sessionsName = resourceNames.consoleSessions || "plg_puppeteer_console_sessions";
    const messagesName = resourceNames.consoleMessages || "plg_puppeteer_console_messages";
    const errorsName = resourceNames.consoleErrors || "plg_puppeteer_console_errors";
    const [sessionsCreated, sessionsErr, sessionsResource] = await tryFn(() => this.plugin.database.createResource({
      name: sessionsName,
      attributes: {
        sessionId: "string|required",
        url: "string|required",
        domain: "string|required",
        date: "string|required",
        // YYYY-MM-DD
        startTime: "number|required",
        endTime: "number",
        duration: "number",
        // Statistics
        totalMessages: "number",
        errorCount: "number",
        warningCount: "number",
        logCount: "number",
        infoCount: "number",
        debugCount: "number",
        // By type breakdown
        byType: "object",
        // { error: 5, warning: 3, log: 20 }
        // User agent
        userAgent: "string"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        byUrl: { fields: { url: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (sessionsCreated) {
      this.sessionsResource = sessionsResource;
    } else if (this.plugin.database.resources?.[sessionsName]) {
      this.sessionsResource = this.plugin.database.resources[sessionsName];
    } else {
      throw sessionsErr;
    }
    const [messagesCreated, messagesErr, messagesResource] = await tryFn(() => this.plugin.database.createResource({
      name: messagesName,
      attributes: {
        messageId: "string|required",
        sessionId: "string|required",
        timestamp: "number|required",
        date: "string|required",
        // Message details
        type: "string|required",
        // error, warning, log, info, debug, etc.
        text: "string|required",
        args: "array",
        // Console.log arguments
        // Source location
        source: "object",
        // { url, lineNumber, columnNumber }
        // Stack trace (for errors)
        stackTrace: "object",
        // Context
        url: "string",
        // Page URL when message occurred
        domain: "string"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        bySession: { fields: { sessionId: "string" } },
        byType: { fields: { type: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (messagesCreated) {
      this.messagesResource = messagesResource;
    } else if (this.plugin.database.resources?.[messagesName]) {
      this.messagesResource = this.plugin.database.resources[messagesName];
    } else {
      throw messagesErr;
    }
    const [errorsCreated, errorsErr, errorsResource] = await tryFn(() => this.plugin.database.createResource({
      name: errorsName,
      attributes: {
        errorId: "string|required",
        sessionId: "string|required",
        messageId: "string|required",
        timestamp: "number|required",
        date: "string|required",
        // Error details
        errorType: "string",
        // TypeError, ReferenceError, etc.
        message: "string|required",
        stackTrace: "object",
        // Source location
        url: "string",
        // Script URL
        lineNumber: "number",
        columnNumber: "number",
        // Context
        pageUrl: "string",
        // Page URL when error occurred
        domain: "string",
        // Classification
        isUncaught: "boolean",
        isPromiseRejection: "boolean",
        isNetworkError: "boolean",
        isSyntaxError: "boolean"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: {
        bySession: { fields: { sessionId: "string" } },
        byErrorType: { fields: { errorType: "string" } },
        byDate: { fields: { date: "string" } },
        byDomain: { fields: { domain: "string" } }
      }
    }));
    if (errorsCreated) {
      this.errorsResource = errorsResource;
    } else if (this.plugin.database.resources?.[errorsName]) {
      this.errorsResource = this.plugin.database.resources[errorsName];
    } else {
      throw errorsErr;
    }
    this.plugin.emit("consoleMonitor.initialized", {
      persist: this.config.persist
    });
  }
  /**
   * Start monitoring console messages for a page
   * @param {Page} page - Puppeteer page
   * @param {Object} options - Monitoring options
   * @returns {Object} Session object
   */
  async startMonitoring(page, options = {}) {
    const {
      sessionId = `console_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      persist = this.config.persist,
      filters = this.config.filters
    } = options;
    const session = {
      sessionId,
      url: page.url(),
      domain: this._extractDomain(page.url()),
      date: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
      startTime: Date.now(),
      endTime: null,
      duration: null,
      // Tracked data
      messages: [],
      errors: [],
      exceptions: [],
      promiseRejections: [],
      // Statistics
      stats: {
        totalMessages: 0,
        errorCount: 0,
        warningCount: 0,
        logCount: 0,
        infoCount: 0,
        debugCount: 0,
        byType: {}
      }
    };
    const consoleHandler = (msg) => {
      const type = this.messageTypes[msg.type()] || msg.type();
      if (filters.levels && !filters.levels.includes(type)) {
        return;
      }
      const text = msg.text();
      if (filters.excludePatterns && filters.excludePatterns.length > 0) {
        for (const pattern of filters.excludePatterns) {
          if (new RegExp(pattern).test(text)) {
            return;
          }
        }
      }
      const message = {
        messageId: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        timestamp: Date.now(),
        type,
        text,
        args: msg.args().length > 0 ? msg.args().map((arg) => this._serializeArg(arg)) : [],
        url: page.url()
      };
      if (filters.includeSourceLocation && msg.location()) {
        message.source = {
          url: msg.location().url,
          lineNumber: msg.location().lineNumber,
          columnNumber: msg.location().columnNumber
        };
      }
      if (filters.includeStackTraces && (type === "error" || type === "warning")) {
        message.stackTrace = msg.stackTrace();
      }
      session.messages.push(message);
      session.stats.totalMessages++;
      if (!session.stats.byType[type]) {
        session.stats.byType[type] = 0;
      }
      session.stats.byType[type]++;
      switch (type) {
        case "error":
          session.stats.errorCount++;
          session.errors.push(message);
          break;
        case "warning":
          session.stats.warningCount++;
          break;
        case "log":
          session.stats.logCount++;
          break;
        case "info":
          session.stats.infoCount++;
          break;
        case "debug":
          session.stats.debugCount++;
          break;
      }
    };
    const pageErrorHandler = (error) => {
      const errorData = {
        errorId: `error_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        timestamp: Date.now(),
        errorType: error.name || "Error",
        message: error.message,
        stack: error.stack,
        isUncaught: true,
        url: page.url()
      };
      session.exceptions.push(errorData);
      session.stats.errorCount++;
      session.messages.push({
        messageId: errorData.errorId,
        timestamp: errorData.timestamp,
        type: "error",
        text: `Uncaught: ${error.message}`,
        stackTrace: error.stack,
        url: page.url()
      });
    };
    const pageerrorHandler = (error) => {
      const errorData = {
        errorId: `rejection_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        timestamp: Date.now(),
        errorType: "UnhandledPromiseRejection",
        message: error.message || String(error),
        stack: error.stack,
        isPromiseRejection: true,
        url: page.url()
      };
      session.promiseRejections.push(errorData);
      session.stats.errorCount++;
      session.messages.push({
        messageId: errorData.errorId,
        timestamp: errorData.timestamp,
        type: "error",
        text: `Unhandled Promise Rejection: ${errorData.message}`,
        stackTrace: error.stack,
        url: page.url()
      });
    };
    page.on("console", consoleHandler);
    page.on("pageerror", pageErrorHandler);
    page.on("pageerror", pageerrorHandler);
    session._handlers = {
      console: consoleHandler,
      pageerror: pageErrorHandler,
      pageerror2: pageerrorHandler
    };
    session._page = page;
    session._persist = persist;
    this.plugin.emit("consoleMonitor.sessionStarted", {
      sessionId,
      url: page.url()
    });
    return session;
  }
  /**
   * Stop monitoring and optionally persist data
   * @param {Object} session - Session object from startMonitoring
   * @param {Object} options - Stop options
   * @returns {Object} Final session data
   */
  async stopMonitoring(session, options = {}) {
    const { persist = session._persist } = options;
    session.endTime = Date.now();
    session.duration = session.endTime - session.startTime;
    if (session._page && session._handlers) {
      session._page.off("console", session._handlers.console);
      session._page.off("pageerror", session._handlers.pageerror);
      session._page.off("pageerror", session._handlers.pageerror2);
    }
    if (persist && this.sessionsResource) {
      try {
        await this._persistSession(session);
      } catch (err) {
        this.plugin.emit("consoleMonitor.persistFailed", {
          sessionId: session.sessionId,
          error: err.message
        });
      }
    }
    this.plugin.emit("consoleMonitor.sessionStopped", {
      sessionId: session.sessionId,
      duration: session.duration,
      totalMessages: session.stats.totalMessages,
      errorCount: session.stats.errorCount
    });
    delete session._handlers;
    delete session._page;
    return session;
  }
  /**
   * Persist session data to S3DB
   * @private
   */
  async _persistSession(session) {
    const startPersist = Date.now();
    await this.sessionsResource.insert({
      sessionId: session.sessionId,
      url: session.url,
      domain: session.domain,
      date: session.date,
      startTime: session.startTime,
      endTime: session.endTime,
      duration: session.duration,
      totalMessages: session.stats.totalMessages,
      errorCount: session.stats.errorCount,
      warningCount: session.stats.warningCount,
      logCount: session.stats.logCount,
      infoCount: session.stats.infoCount,
      debugCount: session.stats.debugCount,
      byType: session.stats.byType,
      userAgent: session._page?._userAgent || null
    });
    if (session.messages.length > 0) {
      for (const msg of session.messages) {
        await this.messagesResource.insert({
          messageId: msg.messageId,
          sessionId: session.sessionId,
          timestamp: msg.timestamp,
          date: session.date,
          type: msg.type,
          text: msg.text,
          args: msg.args,
          source: msg.source || null,
          stackTrace: msg.stackTrace || null,
          url: msg.url,
          domain: this._extractDomain(msg.url)
        });
      }
    }
    const allErrors = [
      ...session.exceptions.map((e) => ({ ...e, isUncaught: true })),
      ...session.promiseRejections.map((e) => ({ ...e, isPromiseRejection: true }))
    ];
    if (allErrors.length > 0) {
      for (const error of allErrors) {
        const errorType = this._extractErrorType(error.message);
        const sourceLocation = this._parseStackTrace(error.stack);
        await this.errorsResource.insert({
          errorId: error.errorId,
          sessionId: session.sessionId,
          messageId: error.errorId,
          timestamp: error.timestamp,
          date: session.date,
          errorType: error.errorType || errorType,
          message: error.message,
          stackTrace: this._formatStackTrace(error.stack),
          url: sourceLocation?.url || null,
          lineNumber: sourceLocation?.lineNumber || null,
          columnNumber: sourceLocation?.columnNumber || null,
          pageUrl: error.url,
          domain: this._extractDomain(error.url),
          isUncaught: error.isUncaught || false,
          isPromiseRejection: error.isPromiseRejection || false,
          isNetworkError: this._isNetworkError(error.message),
          isSyntaxError: errorType === "SyntaxError"
        });
      }
    }
    const persistDuration = Date.now() - startPersist;
    this.plugin.emit("consoleMonitor.persisted", {
      sessionId: session.sessionId,
      messages: session.messages.length,
      errors: allErrors.length,
      duration: persistDuration
    });
  }
  /**
   * Extract domain from URL
   * @private
   */
  _extractDomain(url) {
    try {
      return new URL(url).hostname;
    } catch {
      return "unknown";
    }
  }
  /**
   * Serialize console.log argument
   * @private
   */
  _serializeArg(arg) {
    try {
      return arg.toString();
    } catch {
      return "[Object]";
    }
  }
  /**
   * Extract error type from message
   * @private
   */
  _extractErrorType(message) {
    const errorTypes = [
      "TypeError",
      "ReferenceError",
      "SyntaxError",
      "RangeError",
      "URIError",
      "EvalError",
      "SecurityError",
      "NetworkError"
    ];
    for (const type of errorTypes) {
      if (message.includes(type)) {
        return type;
      }
    }
    return "Error";
  }
  /**
   * Parse stack trace to extract source location
   * @private
   */
  _parseStackTrace(stack) {
    if (!stack) return null;
    try {
      const lines = stack.split("\n");
      const firstLine = lines[0] || "";
      const match = firstLine.match(/at\s+(.+?):(\d+):(\d+)/) || firstLine.match(/(.+?):(\d+):(\d+)/) || firstLine.match(/@(.+?):(\d+):(\d+)/);
      if (match) {
        return {
          url: match[1],
          lineNumber: parseInt(match[2], 10),
          columnNumber: parseInt(match[3], 10)
        };
      }
    } catch {
    }
    return null;
  }
  /**
   * Format stack trace for storage
   * @private
   */
  _formatStackTrace(stack) {
    if (!stack) return null;
    try {
      const lines = stack.split("\n").slice(0, 10);
      return {
        raw: stack.substring(0, 2e3),
        // Limit to 2KB
        frames: lines.map((line) => line.trim())
      };
    } catch {
      return { raw: stack.substring(0, 2e3) };
    }
  }
  /**
   * Check if error is network-related
   * @private
   */
  _isNetworkError(message) {
    const networkKeywords = [
      "net::ERR_",
      "NetworkError",
      "Failed to fetch",
      "fetch failed",
      "XMLHttpRequest",
      "CORS",
      "Network request failed"
    ];
    return networkKeywords.some((keyword) => message.includes(keyword));
  }
  /**
   * Get session statistics
   * @param {string} sessionId - Session ID
   * @returns {Promise<Object>} Statistics
   */
  async getSessionStats(sessionId) {
    if (!this.sessionsResource) {
      throw new PuppeteerError("Console monitoring persistence not enabled", {
        operation: "getSessionStats",
        retriable: false,
        suggestion: "Enable persistence in ConsoleMonitor configuration to query stored sessions."
      });
    }
    return await this.sessionsResource.get(sessionId);
  }
  /**
   * Query messages for a session
   * @param {string} sessionId - Session ID
   * @param {Object} filters - Query filters
   * @returns {Promise<Array>} Messages
   */
  async getSessionMessages(sessionId, filters = {}) {
    if (!this.messagesResource) {
      throw new PuppeteerError("Console monitoring persistence not enabled", {
        operation: "getSessionMessages",
        retriable: false,
        suggestion: "Enable persistence in ConsoleMonitor configuration to query stored messages."
      });
    }
    return await this.messagesResource.listPartition("bySession", { sessionId }, filters);
  }
  /**
   * Query errors for a session
   * @param {string} sessionId - Session ID
   * @returns {Promise<Array>} Errors
   */
  async getSessionErrors(sessionId) {
    if (!this.errorsResource) {
      throw new PuppeteerError("Console monitoring persistence not enabled", {
        operation: "getSessionErrors",
        retriable: false,
        suggestion: "Enable persistence in ConsoleMonitor configuration to query stored errors."
      });
    }
    return await this.errorsResource.listPartition("bySession", { sessionId });
  }
  /**
   * Query all errors by type
   * @param {string} errorType - Error type
   * @returns {Promise<Array>} Errors
   */
  async getErrorsByType(errorType) {
    if (!this.errorsResource) {
      throw new PuppeteerError("Console monitoring persistence not enabled", {
        operation: "getErrorsByType",
        retriable: false,
        suggestion: "Enable persistence in ConsoleMonitor configuration to query stored errors."
      });
    }
    return await this.errorsResource.listPartition("byErrorType", { errorType });
  }
}

var consoleMonitor = /*#__PURE__*/Object.freeze({
  __proto__: null,
  ConsoleMonitor: ConsoleMonitor
});

class StealthManager {
  constructor(plugin) {
    this.plugin = plugin;
    this.config = plugin.config.stealth || {};
    this.timingProfiles = {
      "very-slow": { min: 5e3, max: 15e3, jitter: 2e3 },
      "slow": { min: 3e3, max: 8e3, jitter: 1500 },
      "normal": { min: 1e3, max: 5e3, jitter: 1e3 },
      "fast": { min: 500, max: 2e3, jitter: 500 }
    };
    this.geoData = {
      "US": { timezones: ["America/New_York", "America/Chicago", "America/Los_Angeles"], languages: ["en-US"] },
      "BR": { timezones: ["America/Sao_Paulo"], languages: ["pt-BR", "en-US"] },
      "GB": { timezones: ["Europe/London"], languages: ["en-GB", "en-US"] },
      "DE": { timezones: ["Europe/Berlin"], languages: ["de-DE", "en-US"] },
      "FR": { timezones: ["Europe/Paris"], languages: ["fr-FR", "en-US"] },
      "JP": { timezones: ["Asia/Tokyo"], languages: ["ja-JP", "en-US"] },
      "CN": { timezones: ["Asia/Shanghai"], languages: ["zh-CN", "en-US"] }
    };
  }
  /**
   * Create a stealth-optimized persona profile
   * Ensures all fingerprint components are consistent
   */
  async createStealthProfile(options = {}) {
    const {
      proxy = null,
      country = null,
      // Target country (if known from proxy)
      timingProfile = "normal",
      screenResolution = null
    } = options;
    const geoProfile = this._selectGeoProfile(country);
    const userAgent = this._generateConsistentUserAgent();
    const viewport = this._generateConsistentViewport(screenResolution);
    const profile = {
      // Core identity
      userAgent,
      viewport,
      timezone: geoProfile.timezone,
      language: geoProfile.language,
      // Consistency markers
      acceptLanguage: `${geoProfile.language},en;q=0.9`,
      acceptEncoding: "gzip, deflate, br",
      accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
      // Platform consistency
      platform: this._getPlatformFromUA(userAgent),
      hardwareConcurrency: this._getHardwareConcurrency(userAgent),
      deviceMemory: this._getDeviceMemory(userAgent),
      // Timing behavior
      timingProfile: this.timingProfiles[timingProfile],
      // Proxy binding
      proxyId: proxy?.id || null,
      proxyCountry: country,
      // Behavioral markers
      behavioral: {
        typingSpeed: { min: 100, max: 300 },
        // ms per character
        mouseMovements: true,
        scrollBehavior: "smooth",
        clickDelay: { min: 200, max: 800 }
      }
    };
    return profile;
  }
  /**
   * Select geo profile (timezone + language) based on country
   * @private
   */
  _selectGeoProfile(country) {
    if (country && this.geoData[country]) {
      const data = this.geoData[country];
      const timezone = data.timezones[Math.floor(Math.random() * data.timezones.length)];
      const language = data.languages[0];
      return { timezone, language };
    }
    return {
      timezone: "America/New_York",
      language: "en-US"
    };
  }
  /**
   * Generate consistent user agent (avoid churn)
   * @private
   */
  _generateConsistentUserAgent() {
    const stableUserAgents = [
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ];
    return stableUserAgents[Math.floor(Math.random() * stableUserAgents.length)];
  }
  /**
   * Generate viewport consistent with screen resolution
   * @private
   */
  _generateConsistentViewport(screenResolution) {
    const commonResolutions = [
      { width: 1920, height: 1080, deviceScaleFactor: 1 },
      // Full HD
      { width: 1680, height: 1050, deviceScaleFactor: 1 },
      // WSXGA+
      { width: 1440, height: 900, deviceScaleFactor: 1 },
      // WXGA+
      { width: 1366, height: 768, deviceScaleFactor: 1 },
      // HD
      { width: 2560, height: 1440, deviceScaleFactor: 1 }
      // QHD
    ];
    if (screenResolution) {
      return screenResolution;
    }
    return commonResolutions[Math.floor(Math.random() * commonResolutions.length)];
  }
  /**
   * Get platform from user agent
   * @private
   */
  _getPlatformFromUA(userAgent) {
    if (userAgent.includes("Windows")) return "Win32";
    if (userAgent.includes("Mac")) return "MacIntel";
    if (userAgent.includes("Linux")) return "Linux x86_64";
    return "Win32";
  }
  /**
   * Get hardware concurrency (CPU cores) from user agent
   * @private
   */
  _getHardwareConcurrency(userAgent) {
    return [4, 6, 8][Math.floor(Math.random() * 3)];
  }
  /**
   * Get device memory from user agent
   * @private
   */
  _getDeviceMemory(userAgent) {
    return [4, 8, 16][Math.floor(Math.random() * 3)];
  }
  /**
   * Apply stealth profile to page
   * Overrides navigator properties to match profile
   */
  async applyStealthProfile(page, profile) {
    await page.emulateTimezone(profile.timezone);
    await page.evaluateOnNewDocument((profile2) => {
      Object.defineProperty(navigator, "platform", {
        get: () => profile2.platform
      });
      Object.defineProperty(navigator, "hardwareConcurrency", {
        get: () => profile2.hardwareConcurrency
      });
      Object.defineProperty(navigator, "deviceMemory", {
        get: () => profile2.deviceMemory
      });
      Object.defineProperty(navigator, "languages", {
        get: () => [profile2.language, "en"]
      });
      Object.defineProperty(navigator, "webdriver", {
        get: () => false
      });
      if (!window.chrome) {
        window.chrome = {
          runtime: {}
        };
      }
      const originalQuery = window.navigator.permissions.query;
      window.navigator.permissions.query = (parameters) => parameters.name === "notifications" ? Promise.resolve({ state: Notification.permission }) : originalQuery(parameters);
    }, profile);
    await page.setExtraHTTPHeaders({
      "Accept-Language": profile.acceptLanguage,
      "Accept-Encoding": profile.acceptEncoding,
      "Accept": profile.accept
    });
  }
  /**
   * Execute JS challenges automatically
   * Simulates human JS execution
   */
  async executeJSChallenges(page) {
    try {
      await page.waitForFunction(() => document.readyState === "complete", {
        timeout: 1e4
      });
      await page.evaluate(() => {
        if (!document.cookie.includes("js_ok")) {
          document.cookie = "js_ok=1; path=/";
        }
        if (window.__JS_CHALLENGE_INIT) {
          window.__JS_CHALLENGE_INIT();
        }
        window.dispatchEvent(new Event("load"));
        document.dispatchEvent(new Event("DOMContentLoaded"));
      });
      await this._loadPageResources(page);
      await page.evaluate(async () => {
        try {
          const response = await fetch("/.js-challenge", {
            method: "GET",
            credentials: "include"
          });
          if (response.ok) {
            const data = await response.json();
            if (data.token) {
              window.__JS_CHALLENGE_TOKEN = data.token;
            }
          }
        } catch (err) {
        }
      });
    } catch (err) {
      this.plugin.emit("stealth.jsChallengeWarning", {
        error: err.message
      });
    }
  }
  /**
   * Load page resources to simulate real browser
   * @private
   */
  async _loadPageResources(page) {
    try {
      await page.evaluate(() => {
        const images = Array.from(document.querySelectorAll("img"));
        images.forEach((img) => {
          if (!img.complete) {
            img.dispatchEvent(new Event("load"));
          }
        });
      });
      await page.evaluateHandle(() => document.fonts.ready);
    } catch (err) {
    }
  }
  /**
   * Add human-like delay between actions
   * Uses timing profile from persona
   */
  async humanDelay(profile, action = "default") {
    const timing = profile.timingProfile;
    const baseDelay = timing.min + Math.random() * (timing.max - timing.min);
    const jitter = (Math.random() - 0.5) * timing.jitter;
    const totalDelay = Math.max(100, baseDelay + jitter);
    await this._delay(totalDelay);
  }
  /**
   * Simulate human typing with profile-specific speed
   */
  async humanType(page, selector, text, profile) {
    const element = await page.$(selector);
    if (!element) {
      throw new NavigationError(`Element not found: ${selector}`, {
        operation: "humanType",
        retriable: false,
        suggestion: "Verify the selector exists on the target page before invoking humanType.",
        selector
      });
    }
    await element.click();
    for (const char of text) {
      await page.keyboard.type(char);
      const { min, max } = profile.behavioral.typingSpeed;
      const charDelay = min + Math.random() * (max - min);
      await this._delay(charDelay);
      if ([".", ",", "!", "?"].includes(char)) {
        await this._delay(200 + Math.random() * 300);
      }
    }
  }
  /**
   * Simulate realistic request pacing
   * Prevents rate limiting / velocity detection
   */
  async paceRequests(persona, requestCount) {
    const maxRequestsPerMinute = 30;
    const minDelayMs = 60 * 1e3 / maxRequestsPerMinute;
    const jitter = minDelayMs * (0.5 + Math.random() * 0.5);
    const totalDelay = minDelayMs + jitter;
    await this._delay(totalDelay);
    persona.metadata.lastRequestTime = Date.now();
  }
  /**
   * Check if persona should "rest" (cooldown)
   * Prevents velocity/concurrent use detection
   */
  shouldRest(persona) {
    const now = Date.now();
    const lastUsed = persona.metadata.lastUsed || 0;
    const timeSinceLastUse = now - lastUsed;
    if (timeSinceLastUse < 5e3) {
      return true;
    }
    const requestsInLastMinute = persona.metadata.recentRequests || 0;
    if (requestsInLastMinute > 20) {
      return true;
    }
    return false;
  }
  /**
   * Simulate mouse movements and scrolling
   * Generates behavioral fingerprint
   */
  async simulateHumanBehavior(page, profile) {
    try {
      const scrollDistance = Math.floor(Math.random() * 500) + 200;
      await page.evaluate((distance) => {
        window.scrollBy({
          top: distance,
          behavior: "smooth"
        });
      }, scrollDistance);
      await this._delay(1e3 + Math.random() * 1e3);
      if (page._cursor) {
        try {
          const viewport = await page.viewport();
          const x = Math.floor(Math.random() * viewport.width);
          const y = Math.floor(Math.random() * viewport.height);
          await page._cursor.move({ x, y });
          await this._delay(500);
        } catch (err) {
        }
      }
      const elements = await page.$$("a, button, input");
      if (elements.length > 0) {
        const randomElement = elements[Math.floor(Math.random() * elements.length)];
        await randomElement.hover().catch(() => {
        });
        await this._delay(300 + Math.random() * 500);
      }
    } catch (err) {
    }
  }
  /**
   * Validate persona consistency before use
   * Ensures no fingerprint leakage
   */
  validatePersonaConsistency(persona, currentContext) {
    const warnings = [];
    if (persona.proxyId && currentContext.proxyId !== persona.proxyId) {
      warnings.push({
        type: "PROXY_MISMATCH",
        message: `Persona ${persona.personaId} bound to ${persona.proxyId} but using ${currentContext.proxyId}`,
        severity: "HIGH"
      });
    }
    if (currentContext.userAgent && currentContext.userAgent !== persona.userAgent) {
      warnings.push({
        type: "UA_MISMATCH",
        message: "User agent changed",
        severity: "HIGH"
      });
    }
    if (currentContext.viewport) {
      if (currentContext.viewport.width !== persona.viewport.width || currentContext.viewport.height !== persona.viewport.height) {
        warnings.push({
          type: "VIEWPORT_MISMATCH",
          message: "Viewport changed",
          severity: "MEDIUM"
        });
      }
    }
    if (this.shouldRest(persona)) {
      warnings.push({
        type: "HIGH_VELOCITY",
        message: "Persona used too frequently",
        severity: "MEDIUM"
      });
    }
    return warnings;
  }
  /**
   * Generate realistic browsing session
   * Visits pages with human-like patterns
   */
  async generateBrowsingSession(page, profile, urls) {
    for (let i = 0; i < urls.length; i++) {
      const url = urls[i];
      await page.goto(url, { waitUntil: "networkidle2" });
      await this.executeJSChallenges(page);
      await this.simulateHumanBehavior(page, profile);
      await this.humanDelay(profile);
      if (i > 0 && Math.random() < 0.1) {
        await page.goBack();
        await this._delay(1e3);
        await page.goForward();
      }
    }
  }
  /**
   * Delay helper
   * @private
   */
  async _delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}

var stealthManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  StealthManager: StealthManager
});

function sanitizeLabel(value) {
  if (typeof value !== "string") {
    value = String(value);
  }
  return value.replace(/\\/g, "\\\\").replace(/"/g, '\\"').replace(/\n/g, "\\n");
}
function sanitizeMetricName(name) {
  let sanitized = name.replace(/[^a-zA-Z0-9_]/g, "_");
  if (/^\d/.test(sanitized)) {
    sanitized = "_" + sanitized;
  }
  return sanitized;
}
function formatLabels(labels) {
  if (!labels || Object.keys(labels).length === 0) {
    return "";
  }
  const labelPairs = Object.entries(labels).map(([key, value]) => `${key}="${sanitizeLabel(value)}"`).join(",");
  return `{${labelPairs}}`;
}
function formatMetric(name, type, help, values) {
  const lines = [];
  lines.push(`# HELP ${name} ${help}`);
  lines.push(`# TYPE ${name} ${type}`);
  for (const { labels, value } of values) {
    const labelsStr = formatLabels(labels);
    lines.push(`${name}${labelsStr} ${value}`);
  }
  return lines.join("\n");
}
function formatPrometheusMetrics(metricsPlugin) {
  const lines = [];
  const metrics = metricsPlugin.metrics;
  const operationsTotalValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.count > 0) {
      operationsTotalValues.push({
        labels: { operation, resource: "_global" },
        value: data.count
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.count > 0) {
        operationsTotalValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: data.count
        });
      }
    }
  }
  if (operationsTotalValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operations_total",
      "counter",
      "Total number of operations by type and resource",
      operationsTotalValues
    ));
    lines.push("");
  }
  const durationValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.count > 0) {
      const avgSeconds = data.totalTime / data.count / 1e3;
      durationValues.push({
        labels: { operation, resource: "_global" },
        value: avgSeconds.toFixed(6)
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.count > 0) {
        const avgSeconds = data.totalTime / data.count / 1e3;
        durationValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: avgSeconds.toFixed(6)
        });
      }
    }
  }
  if (durationValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operation_duration_seconds",
      "gauge",
      "Average operation duration in seconds",
      durationValues
    ));
    lines.push("");
  }
  const errorsValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.errors > 0) {
      errorsValues.push({
        labels: { operation, resource: "_global" },
        value: data.errors
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.errors > 0) {
        errorsValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: data.errors
        });
      }
    }
  }
  if (errorsValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operation_errors_total",
      "counter",
      "Total number of operation errors",
      errorsValues
    ));
    lines.push("");
  }
  const startTime = new Date(metrics.startTime);
  const uptimeSeconds = (Date.now() - startTime.getTime()) / 1e3;
  lines.push(formatMetric(
    "s3db_uptime_seconds",
    "gauge",
    "Process uptime in seconds",
    [{ labels: {}, value: uptimeSeconds.toFixed(2) }]
  ));
  lines.push("");
  const resourcesCount = Object.keys(metrics.resources).length;
  lines.push(formatMetric(
    "s3db_resources_total",
    "gauge",
    "Total number of tracked resources",
    [{ labels: {}, value: resourcesCount }]
  ));
  lines.push("");
  const nodeVersion = process.version || "unknown";
  const s3dbVersion = "1.0.0";
  lines.push(formatMetric(
    "s3db_info",
    "gauge",
    "Build and runtime information",
    [{
      labels: {
        version: s3dbVersion,
        node_version: nodeVersion
      },
      value: 1
    }]
  ));
  return lines.join("\n") + "\n";
}

var prometheusFormatter = /*#__PURE__*/Object.freeze({
  __proto__: null,
  formatPrometheusMetrics: formatPrometheusMetrics
});

const RESOURCE_TYPE_MAP = {
  // AWS
  "aws.ec2.instance": "aws_instance",
  "aws.s3.bucket": "aws_s3_bucket",
  "aws.rds.instance": "aws_db_instance",
  "aws.dynamodb.table": "aws_dynamodb_table",
  "aws.lambda.function": "aws_lambda_function",
  "aws.vpc.vpc": "aws_vpc",
  "aws.vpc.subnet": "aws_subnet",
  "aws.vpc.securitygroup": "aws_security_group",
  "aws.vpc.routetable": "aws_route_table",
  "aws.vpc.internetgateway": "aws_internet_gateway",
  "aws.vpc.natgateway": "aws_nat_gateway",
  "aws.elb.loadbalancer": "aws_elb",
  "aws.elbv2.loadbalancer": "aws_lb",
  "aws.elbv2.targetgroup": "aws_lb_target_group",
  "aws.iam.user": "aws_iam_user",
  "aws.iam.role": "aws_iam_role",
  "aws.iam.policy": "aws_iam_policy",
  "aws.kms.key": "aws_kms_key",
  "aws.secretsmanager.secret": "aws_secretsmanager_secret",
  "aws.ecs.cluster": "aws_ecs_cluster",
  "aws.ecs.service": "aws_ecs_service",
  "aws.ecs.taskdefinition": "aws_ecs_task_definition",
  "aws.eks.cluster": "aws_eks_cluster",
  "aws.eks.nodegroup": "aws_eks_node_group",
  "aws.ecr.repository": "aws_ecr_repository",
  "aws.route53.hostedzone": "aws_route53_zone",
  "aws.cloudfront.distribution": "aws_cloudfront_distribution",
  "aws.sqs.queue": "aws_sqs_queue",
  "aws.sns.topic": "aws_sns_topic",
  "aws.kinesis.stream": "aws_kinesis_stream",
  "aws.ebs.volume": "aws_ebs_volume",
  "aws.ebs.snapshot": "aws_ebs_snapshot",
  "aws.efs.filesystem": "aws_efs_file_system",
  "aws.elasticache.cluster": "aws_elasticache_cluster",
  // GCP
  "gcp.compute.instance": "google_compute_instance",
  "gcp.storage.bucket": "google_storage_bucket",
  "gcp.sql.instance": "google_sql_database_instance",
  "gcp.gke.cluster": "google_container_cluster",
  "gcp.compute.network": "google_compute_network",
  "gcp.compute.subnetwork": "google_compute_subnetwork",
  "gcp.compute.firewall": "google_compute_firewall",
  "gcp.bigquery.dataset": "google_bigquery_dataset",
  "gcp.pubsub.topic": "google_pubsub_topic",
  "gcp.pubsub.subscription": "google_pubsub_subscription",
  "gcp.functions.function": "google_cloudfunctions_function",
  "gcp.run.service": "google_cloud_run_service",
  "gcp.iam.serviceaccount": "google_service_account",
  "gcp.kms.keyring": "google_kms_key_ring",
  "gcp.secretmanager.secret": "google_secret_manager_secret",
  // Azure
  "azure.vm": "azurerm_virtual_machine",
  "azure.vm.vmss": "azurerm_virtual_machine_scale_set",
  "azure.storage.account": "azurerm_storage_account",
  "azure.sql.server": "azurerm_sql_server",
  "azure.sql.database": "azurerm_sql_database",
  "azure.aks.cluster": "azurerm_kubernetes_cluster",
  "azure.network.vnet": "azurerm_virtual_network",
  "azure.network.subnet": "azurerm_subnet",
  "azure.network.nsg": "azurerm_network_security_group",
  "azure.network.loadbalancer": "azurerm_lb",
  "azure.network.publicip": "azurerm_public_ip",
  "azure.containerregistry": "azurerm_container_registry",
  "azure.cosmosdb.account": "azurerm_cosmosdb_account",
  "azure.identity.userassigned": "azurerm_user_assigned_identity",
  "azure.dns.zone": "azurerm_dns_zone",
  // DigitalOcean
  "do.droplet": "digitalocean_droplet",
  "do.kubernetes.cluster": "digitalocean_kubernetes_cluster",
  "do.volume": "digitalocean_volume",
  "do.loadbalancer": "digitalocean_loadbalancer",
  "do.firewall": "digitalocean_firewall",
  "do.vpc": "digitalocean_vpc",
  "do.spaces.bucket": "digitalocean_spaces_bucket",
  "do.database.cluster": "digitalocean_database_cluster",
  "do.domain": "digitalocean_domain",
  "do.cdn": "digitalocean_cdn",
  "do.registry": "digitalocean_container_registry",
  // Alibaba Cloud
  "alibaba.ecs.instance": "alicloud_instance",
  "alibaba.oss.bucket": "alicloud_oss_bucket",
  "alibaba.rds.instance": "alicloud_db_instance",
  "alibaba.ack.cluster": "alicloud_cs_kubernetes",
  "alibaba.vpc.vpc": "alicloud_vpc",
  "alibaba.vpc.vswitch": "alicloud_vswitch",
  "alibaba.slb.loadbalancer": "alicloud_slb",
  "alibaba.redis.instance": "alicloud_kvstore_instance",
  "alibaba.cdn.distribution": "alicloud_cdn_domain",
  "alibaba.dns.domain": "alicloud_dns",
  "alibaba.ecs.securitygroup": "alicloud_security_group",
  "alibaba.ecs.snapshot": "alicloud_snapshot",
  "alibaba.ess.scalinggroup": "alicloud_ess_scaling_group",
  "alibaba.ess.scalingconfiguration": "alicloud_ess_scaling_configuration",
  "alibaba.natgateway": "alicloud_nat_gateway",
  "alibaba.acr.repository": "alicloud_cr_repo",
  // Linode
  "linode.compute.instance": "linode_instance",
  "linode.lke.cluster": "linode_lke_cluster",
  "linode.volume": "linode_volume",
  "linode.nodebalancer": "linode_nodebalancer",
  "linode.firewall": "linode_firewall",
  "linode.domain": "linode_domain",
  "linode.objectstorage.bucket": "linode_object_storage_bucket",
  "linode.database": "linode_database_mysql",
  // or postgresql, mongodb
  // Hetzner
  "hetzner.server": "hetzner_server",
  "hetzner.volume": "hetzner_volume",
  "hetzner.network": "hetzner_network",
  "hetzner.loadbalancer": "hetzner_load_balancer",
  "hetzner.firewall": "hetzner_firewall",
  "hetzner.floatingip": "hetzner_floating_ip",
  "hetzner.primaryip": "hetzner_primary_ip",
  "hetzner.sshkey": "hetzner_ssh_key",
  "hetzner.placementgroup": "hetzner_placement_group",
  // Vultr
  "vultr.instance": "vultr_instance",
  "vultr.kubernetes.cluster": "vultr_kubernetes",
  "vultr.blockstorage": "vultr_block_storage",
  "vultr.loadbalancer": "vultr_load_balancer",
  "vultr.firewall.group": "vultr_firewall_group",
  "vultr.vpc": "vultr_vpc",
  "vultr.objectstorage": "vultr_object_storage",
  "vultr.database": "vultr_database",
  // Oracle Cloud
  "oci.compute.instance": "oci_core_instance",
  "oci.objectstorage.bucket": "oci_objectstorage_bucket",
  "oci.database.autonomousdatabase": "oci_database_autonomous_database",
  "oci.database.dbsystem": "oci_database_db_system",
  "oci.kubernetes.cluster": "oci_containerengine_cluster",
  "oci.vcn": "oci_core_vcn",
  "oci.vcn.subnet": "oci_core_subnet",
  "oci.compute.volume": "oci_core_volume",
  "oci.filestorage.filesystem": "oci_file_storage_file_system",
  "oci.loadbalancer": "oci_load_balancer",
  "oci.dns.zone": "oci_dns_zone",
  // Cloudflare
  "cloudflare.workers.script": "cloudflare_worker_script",
  "cloudflare.r2.bucket": "cloudflare_r2_bucket",
  "cloudflare.pages.project": "cloudflare_pages_project",
  "cloudflare.d1.database": "cloudflare_d1_database",
  "cloudflare.kv.namespace": "cloudflare_workers_kv_namespace",
  "cloudflare.durable-objects.namespace": "cloudflare_workers_durable_object_namespace",
  "cloudflare.zone": "cloudflare_zone",
  "cloudflare.dns.record": "cloudflare_record",
  "cloudflare.loadbalancer": "cloudflare_load_balancer",
  "cloudflare.ssl.certificate": "cloudflare_origin_ca_certificate",
  "cloudflare.waf.ruleset": "cloudflare_ruleset",
  "cloudflare.access.application": "cloudflare_access_application",
  "cloudflare.access.policy": "cloudflare_access_policy",
  // MongoDB Atlas
  "mongodb-atlas.project": "mongodbatlas_project",
  "mongodb-atlas.cluster": "mongodbatlas_cluster",
  "mongodb-atlas.serverless": "mongodbatlas_serverless_instance",
  "mongodb-atlas.user": "mongodbatlas_database_user",
  "mongodb-atlas.accesslist": "mongodbatlas_project_ip_access_list",
  "mongodb-atlas.backup": "mongodbatlas_cloud_backup_snapshot",
  "mongodb-atlas.alert": "mongodbatlas_alert_configuration",
  "mongodb-atlas.datalake": "mongodbatlas_data_lake",
  "mongodb-atlas.search.index": "mongodbatlas_search_index",
  "mongodb-atlas.customrole": "mongodbatlas_custom_db_role",
  "mongodb-atlas.event": "mongodbatlas_event_trigger"
};
function getProviderConfig(resourceType) {
  const provider = resourceType.split(".")[0];
  const providerMap = {
    "aws": "registry.terraform.io/hashicorp/aws",
    "gcp": "registry.terraform.io/hashicorp/google",
    "azure": "registry.terraform.io/hashicorp/azurerm",
    "do": "registry.terraform.io/digitalocean/digitalocean",
    "alibaba": "registry.terraform.io/aliyun/alicloud",
    "linode": "registry.terraform.io/linode/linode",
    "hetzner": "registry.terraform.io/hetznercloud/hetzner",
    "vultr": "registry.terraform.io/vultr/vultr",
    "oci": "registry.terraform.io/hashicorp/oci",
    "oracle": "registry.terraform.io/hashicorp/oci",
    "cloudflare": "registry.terraform.io/cloudflare/cloudflare",
    "mongodb-atlas": "registry.terraform.io/mongodb/mongodbatlas"
  };
  return providerMap[provider] || `registry.terraform.io/hashicorp/${provider}`;
}
function convertToTerraformResource(resource) {
  const { resourceType, resourceId, configuration } = resource;
  const tfType = RESOURCE_TYPE_MAP[resourceType];
  if (!tfType) {
    return null;
  }
  const resourceName = sanitizeResourceName(resourceId);
  const providerFqn = getProviderConfig(resourceType);
  return {
    mode: "managed",
    type: tfType,
    name: resourceName,
    provider: providerFqn,
    instances: [
      {
        schema_version: 0,
        attributes: configuration || {},
        private: "bnVsbA==",
        // base64("null")
        dependencies: []
      }
    ]
  };
}
function sanitizeResourceName(resourceId) {
  let name = String(resourceId).toLowerCase().replace(/[^a-z0-9_-]/g, "_").replace(/^[^a-z]+/, "").replace(/_+/g, "_").replace(/^_+|_+$/g, "");
  if (!name || !/^[a-z]/.test(name)) {
    name = `resource_${name}`;
  }
  return name.slice(0, 64) || "resource";
}
function exportToTerraformState(snapshots, options = {}) {
  const {
    terraformVersion = "1.5.0",
    lineage = generateLineage(),
    serial = 1,
    outputs = {},
    resourceTypes = [],
    providers = []
  } = options;
  let filteredSnapshots = snapshots;
  if (resourceTypes.length > 0) {
    filteredSnapshots = filteredSnapshots.filter(
      (s) => resourceTypes.includes(s.resourceType)
    );
  }
  if (providers.length > 0) {
    filteredSnapshots = filteredSnapshots.filter((s) => {
      const provider = s.resourceType.split(".")[0];
      return providers.includes(provider);
    });
  }
  const tfResources = [];
  const skipped = [];
  for (const snapshot of filteredSnapshots) {
    const tfResource = convertToTerraformResource(snapshot);
    if (tfResource) {
      tfResources.push(tfResource);
    } else {
      skipped.push(snapshot.resourceType);
    }
  }
  const state = {
    version: 4,
    terraform_version: terraformVersion,
    serial,
    lineage,
    outputs,
    resources: tfResources
  };
  return {
    state,
    stats: {
      total: snapshots.length,
      converted: tfResources.length,
      skipped: skipped.length,
      skippedTypes: [...new Set(skipped)]
    }
  };
}
function generateLineage() {
  return "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g, (c) => {
    const r = Math.random() * 16 | 0;
    const v = c === "x" ? r : r & 3 | 8;
    return v.toString(16);
  });
}

var terraformExporter = /*#__PURE__*/Object.freeze({
  __proto__: null,
  convertToTerraformResource: convertToTerraformResource,
  exportToTerraformState: exportToTerraformState
});

function silhouetteScore(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const k = centroids.length;
  const n = vectors.length;
  const clusters = Array(k).fill(null).map(() => []);
  vectors.forEach((vector, i) => {
    clusters[assignments[i]].push(i);
  });
  let totalScore = 0;
  let validPoints = 0;
  if (clusters.every((c) => c.length <= 1)) {
    return 0;
  }
  for (let i = 0; i < n; i++) {
    const clusterIdx = assignments[i];
    const cluster = clusters[clusterIdx];
    if (cluster.length === 1) continue;
    let a = 0;
    for (const j of cluster) {
      if (i !== j) {
        a += distanceFn(vectors[i], vectors[j]);
      }
    }
    a /= cluster.length - 1;
    let b = Infinity;
    for (let otherCluster = 0; otherCluster < k; otherCluster++) {
      if (otherCluster === clusterIdx) continue;
      const otherPoints = clusters[otherCluster];
      if (otherPoints.length === 0) continue;
      let avgDist = 0;
      for (const j of otherPoints) {
        avgDist += distanceFn(vectors[i], vectors[j]);
      }
      avgDist /= otherPoints.length;
      b = Math.min(b, avgDist);
    }
    if (b === Infinity) continue;
    const maxAB = Math.max(a, b);
    const s = maxAB === 0 ? 0 : (b - a) / maxAB;
    totalScore += s;
    validPoints++;
  }
  return validPoints > 0 ? totalScore / validPoints : 0;
}
function daviesBouldinIndex(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const k = centroids.length;
  const scatters = new Array(k).fill(0);
  const clusterCounts = new Array(k).fill(0);
  vectors.forEach((vector, i) => {
    const cluster = assignments[i];
    scatters[cluster] += distanceFn(vector, centroids[cluster]);
    clusterCounts[cluster]++;
  });
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] > 0) {
      scatters[i] /= clusterCounts[i];
    }
  }
  let dbIndex = 0;
  let validClusters = 0;
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] === 0) continue;
    let maxRatio = 0;
    for (let j = 0; j < k; j++) {
      if (i === j || clusterCounts[j] === 0) continue;
      const centroidDist = distanceFn(centroids[i], centroids[j]);
      if (centroidDist === 0) continue;
      const ratio = (scatters[i] + scatters[j]) / centroidDist;
      maxRatio = Math.max(maxRatio, ratio);
    }
    dbIndex += maxRatio;
    validClusters++;
  }
  return validClusters > 0 ? dbIndex / validClusters : 0;
}
function calinskiHarabaszIndex(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const n = vectors.length;
  const k = centroids.length;
  if (k === 1 || k === n) return 0;
  const dimensions = vectors[0].length;
  const overallCentroid = new Array(dimensions).fill(0);
  vectors.forEach((vector) => {
    vector.forEach((val, dim) => {
      overallCentroid[dim] += val;
    });
  });
  overallCentroid.forEach((val, dim, arr) => {
    arr[dim] = val / n;
  });
  const clusterCounts = new Array(k).fill(0);
  vectors.forEach((vector, i) => {
    clusterCounts[assignments[i]]++;
  });
  let bgss = 0;
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] === 0) continue;
    const dist = distanceFn(centroids[i], overallCentroid);
    bgss += clusterCounts[i] * dist * dist;
  }
  let wcss = 0;
  vectors.forEach((vector, i) => {
    const cluster = assignments[i];
    const dist = distanceFn(vector, centroids[cluster]);
    wcss += dist * dist;
  });
  if (wcss === 0) return 0;
  return bgss / (k - 1) / (wcss / (n - k));
}
async function gapStatistic(vectors, assignments, centroids, distanceFn = euclideanDistance, nReferences = 10) {
  const n = vectors.length;
  const k = centroids.length;
  const dimensions = vectors[0].length;
  let wk = 0;
  vectors.forEach((vector, i) => {
    const dist = distanceFn(vector, centroids[assignments[i]]);
    wk += dist * dist;
  });
  wk = Math.log(wk + 1e-10);
  const referenceWks = [];
  const mins = new Array(dimensions).fill(Infinity);
  const maxs = new Array(dimensions).fill(-Infinity);
  vectors.forEach((vector) => {
    vector.forEach((val, dim) => {
      mins[dim] = Math.min(mins[dim], val);
      maxs[dim] = Math.max(maxs[dim], val);
    });
  });
  for (let ref = 0; ref < nReferences; ref++) {
    const refVectors = [];
    for (let i = 0; i < n; i++) {
      const refVector = new Array(dimensions);
      for (let dim = 0; dim < dimensions; dim++) {
        refVector[dim] = mins[dim] + Math.random() * (maxs[dim] - mins[dim]);
      }
      refVectors.push(refVector);
    }
    const refResult = kmeans(refVectors, k, { maxIterations: 50, distanceFn });
    let refWk = 0;
    refVectors.forEach((vector, i) => {
      const dist = distanceFn(vector, refResult.centroids[refResult.assignments[i]]);
      refWk += dist * dist;
    });
    referenceWks.push(Math.log(refWk + 1e-10));
  }
  const expectedWk = referenceWks.reduce((a, b) => a + b, 0) / nReferences;
  const gap = expectedWk - wk;
  const sdk = Math.sqrt(
    referenceWks.reduce((sum, wk2) => sum + Math.pow(wk2 - expectedWk, 2), 0) / nReferences
  );
  const sk = sdk * Math.sqrt(1 + 1 / nReferences);
  return { gap, sk, expectedWk, actualWk: wk };
}
function clusteringStability(vectors, k, options = {}) {
  const {
    nRuns = 10,
    distanceFn = euclideanDistance,
    ...kmeansOptions
  } = options;
  const inertias = [];
  const allAssignments = [];
  for (let run = 0; run < nRuns; run++) {
    const result = kmeans(vectors, k, {
      ...kmeansOptions,
      distanceFn,
      seed: run
      // Different seed for each run
    });
    inertias.push(result.inertia);
    allAssignments.push(result.assignments);
  }
  const assignmentSimilarities = [];
  for (let i = 0; i < nRuns - 1; i++) {
    for (let j = i + 1; j < nRuns; j++) {
      const similarity = calculateAssignmentSimilarity(allAssignments[i], allAssignments[j]);
      assignmentSimilarities.push(similarity);
    }
  }
  const avgInertia = inertias.reduce((a, b) => a + b, 0) / nRuns;
  const stdInertia = Math.sqrt(
    inertias.reduce((sum, val) => sum + Math.pow(val - avgInertia, 2), 0) / nRuns
  );
  const avgSimilarity = assignmentSimilarities.length > 0 ? assignmentSimilarities.reduce((a, b) => a + b, 0) / assignmentSimilarities.length : 1;
  return {
    avgInertia,
    stdInertia,
    cvInertia: avgInertia !== 0 ? stdInertia / avgInertia : 0,
    // Coefficient of variation
    avgSimilarity,
    stability: avgSimilarity
    // Higher is more stable
  };
}
function calculateAssignmentSimilarity(assignments1, assignments2) {
  const n = assignments1.length;
  let matches = 0;
  for (let i = 0; i < n; i++) {
    for (let j = i + 1; j < n; j++) {
      const sameCluster1 = assignments1[i] === assignments1[j];
      const sameCluster2 = assignments2[i] === assignments2[j];
      if (sameCluster1 === sameCluster2) {
        matches++;
      }
    }
  }
  const totalPairs = n * (n - 1) / 2;
  return totalPairs > 0 ? matches / totalPairs : 1;
}

var metrics = /*#__PURE__*/Object.freeze({
  __proto__: null,
  calinskiHarabaszIndex: calinskiHarabaszIndex,
  clusteringStability: clusteringStability,
  daviesBouldinIndex: daviesBouldinIndex,
  gapStatistic: gapStatistic,
  silhouetteScore: silhouetteScore
});

// src/utils/html.ts
var HtmlEscapedCallbackPhase = {
  Stringify: 1};
var raw = (value, callbacks) => {
  const escapedString = new String(value);
  escapedString.isEscaped = true;
  escapedString.callbacks = callbacks;
  return escapedString;
};
var escapeRe = /[&<>'"]/;
var stringBufferToString = async (buffer, callbacks) => {
  let str = "";
  callbacks ||= [];
  const resolvedBuffer = await Promise.all(buffer);
  for (let i = resolvedBuffer.length - 1; ; i--) {
    str += resolvedBuffer[i];
    i--;
    if (i < 0) {
      break;
    }
    let r = resolvedBuffer[i];
    if (typeof r === "object") {
      callbacks.push(...r.callbacks || []);
    }
    const isEscaped = r.isEscaped;
    r = await (typeof r === "object" ? r.toString() : r);
    if (typeof r === "object") {
      callbacks.push(...r.callbacks || []);
    }
    if (r.isEscaped ?? isEscaped) {
      str += r;
    } else {
      const buf = [str];
      escapeToBuffer(r, buf);
      str = buf[0];
    }
  }
  return raw(str, callbacks);
};
var escapeToBuffer = (str, buffer) => {
  const match = str.search(escapeRe);
  if (match === -1) {
    buffer[0] += str;
    return;
  }
  let escape;
  let index;
  let lastIndex = 0;
  for (index = match; index < str.length; index++) {
    switch (str.charCodeAt(index)) {
      case 34:
        escape = "&quot;";
        break;
      case 39:
        escape = "&#39;";
        break;
      case 38:
        escape = "&amp;";
        break;
      case 60:
        escape = "&lt;";
        break;
      case 62:
        escape = "&gt;";
        break;
      default:
        continue;
    }
    buffer[0] += str.substring(lastIndex, index) + escape;
    lastIndex = index + 1;
  }
  buffer[0] += str.substring(lastIndex, index);
};
var resolveCallbackSync = (str) => {
  const callbacks = str.callbacks;
  if (!callbacks?.length) {
    return str;
  }
  const buffer = [str];
  const context = {};
  callbacks.forEach((c) => c({ phase: HtmlEscapedCallbackPhase.Stringify, buffer, context }));
  return buffer[0];
};

// src/helper/html/index.ts
var html = (strings, ...values) => {
  const buffer = [""];
  for (let i = 0, len = strings.length - 1; i < len; i++) {
    buffer[0] += strings[i];
    const children = Array.isArray(values[i]) ? values[i].flat(Infinity) : [values[i]];
    for (let i2 = 0, len2 = children.length; i2 < len2; i2++) {
      const child = children[i2];
      if (typeof child === "string") {
        escapeToBuffer(child, buffer);
      } else if (typeof child === "number") {
        buffer[0] += child;
      } else if (typeof child === "boolean" || child === null || child === void 0) {
        continue;
      } else if (typeof child === "object" && child.isEscaped) {
        if (child.callbacks) {
          buffer.unshift("", child);
        } else {
          const tmp = child.toString();
          if (tmp instanceof Promise) {
            buffer.unshift("", tmp);
          } else {
            buffer[0] += tmp;
          }
        }
      } else if (child instanceof Promise) {
        buffer.unshift("", child);
      } else {
        escapeToBuffer(child.toString(), buffer);
      }
    }
  }
  buffer[0] += strings.at(-1);
  return buffer.length === 1 ? "callbacks" in buffer ? raw(resolveCallbackSync(raw(buffer[0], buffer.callbacks))) : raw(buffer[0]) : stringBufferToString(buffer, buffer.callbacks);
};

var __freeze$4 = Object.freeze;
var __defProp$4 = Object.defineProperty;
var __template$4 = (cooked, raw) => __freeze$4(__defProp$4(cooked, "raw", { value: __freeze$4(cooked.slice()) }));
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const cssPath = join(__dirname, "../styles/main.css");
let cachedCSS = null;
function getCSS() {
  if (!cachedCSS) {
    cachedCSS = readFileSync(cssPath, "utf-8");
  }
  return cachedCSS;
}
function hexToRgba(hex, alpha = 1) {
  if (!hex || typeof hex !== "string") {
    return `rgba(0, 0, 0, ${alpha})`;
  }
  const normalized = hex.replace("#", "");
  if (![3, 6].includes(normalized.length)) {
    return `rgba(0, 0, 0, ${alpha})`;
  }
  const full = normalized.length === 3 ? normalized.split("").map((char) => `${char}${char}`).join("") : normalized;
  const r = parseInt(full.slice(0, 2), 16);
  const g = parseInt(full.slice(2, 4), 16);
  const b = parseInt(full.slice(4, 6), 16);
  if (Number.isNaN(r) || Number.isNaN(g) || Number.isNaN(b)) {
    return `rgba(0, 0, 0, ${alpha})`;
  }
  return `rgba(${r}, ${g}, ${b}, ${alpha})`;
}
var _a$4;
function BaseLayout(props) {
  const {
    title = "Identity Provider",
    content = "",
    user = null,
    config = {},
    error = null,
    success = null
  } = props;
  const theme = {
    title: config.title || "S3DB Identity",
    logo: config.logo || null,
    logoUrl: config.logoUrl || null,
    favicon: config.favicon || null,
    registrationEnabled: config.registrationEnabled !== false,
    // Show register link
    // Colors
    primaryColor: config.primaryColor || "#007bff",
    secondaryColor: config.secondaryColor || "#6c757d",
    successColor: config.successColor || "#28a745",
    dangerColor: config.dangerColor || "#dc3545",
    warningColor: config.warningColor || "#ffc107",
    infoColor: config.infoColor || "#17a2b8",
    // Text colors
    textColor: config.textColor || "#212529",
    textMuted: config.textMuted || "#6c757d",
    // Background colors
    backgroundColor: config.backgroundColor || "#ffffff",
    backgroundLight: config.backgroundLight || "#f8f9fa",
    borderColor: config.borderColor || "#dee2e6",
    // Typography
    fontFamily: config.fontFamily || '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif',
    fontSize: config.fontSize || "16px",
    // Layout
    borderRadius: config.borderRadius || "0.375rem",
    boxShadow: config.boxShadow || "0 0.125rem 0.25rem rgba(0, 0, 0, 0.075)",
    // Company info
    companyName: config.companyName || "S3DB",
    legalName: config.legalName || config.companyName || "S3DB Corp",
    tagline: config.tagline || "Secure Identity & Access Management",
    welcomeMessage: config.welcomeMessage || "Welcome back!",
    footerText: config.footerText || null,
    supportEmail: config.supportEmail || null,
    privacyUrl: config.privacyUrl || "/privacy",
    termsUrl: config.termsUrl || "/terms",
    // Social links
    socialLinks: config.socialLinks || null,
    // Custom CSS
    customCSS: config.customCSS || null
  };
  const primaryGlow = hexToRgba(theme.primaryColor, 0.28);
  const secondaryGlow = hexToRgba(theme.secondaryColor, 0.22);
  const surfaceGlow = hexToRgba(theme.backgroundLight, 0.65);
  const themeCSS = `
    :root {
      --color-primary: ${theme.primaryColor};
      --color-secondary: ${theme.secondaryColor};
      --color-success: ${theme.successColor};
      --color-danger: ${theme.dangerColor};
      --color-warning: ${theme.warningColor};
      --color-info: ${theme.infoColor};

      --color-text: ${theme.textColor};
      --color-text-muted: ${theme.textMuted};

      --color-bg: ${theme.backgroundColor};
      --color-light: ${theme.backgroundLight};
      --color-border: ${theme.borderColor};
      --color-card-bg: ${theme.backgroundLight};
      --color-primary-glow: ${primaryGlow};
      --color-secondary-glow: ${secondaryGlow};
      --color-surface-glow: ${surfaceGlow};

      --font-family: ${theme.fontFamily};
      --font-size-base: ${theme.fontSize};

      --border-radius: ${theme.borderRadius};
      --box-shadow: ${theme.boxShadow};
    }
  `;
  const backgroundGradient = `
    radial-gradient(circle at 12% 18%, ${primaryGlow} 0%, transparent 52%),
    radial-gradient(circle at 88% 16%, ${secondaryGlow} 0%, transparent 55%),
    linear-gradient(160deg, ${theme.backgroundColor} 0%, ${theme.backgroundLight} 55%, ${theme.backgroundColor} 100%)
  `;
  const flashContainer = error || success ? html`
    <div class="mx-auto mb-8 w-full max-w-3xl space-y-3">
      ${error ? html`
        <div class="rounded-2xl border border-red-500/40 bg-red-500/15 px-4 py-3 text-sm leading-6 text-red-100 shadow-lg shadow-red-900/30 backdrop-blur">
          ${error}
        </div>
      ` : ""}
      ${success ? html`
        <div class="rounded-2xl border border-emerald-400/40 bg-emerald-500/15 px-4 py-3 text-sm leading-6 text-emerald-100 shadow-lg shadow-emerald-900/25 backdrop-blur">
          ${success}
        </div>
      ` : ""}
    </div>
  ` : "";
  return html(_a$4 || (_a$4 = __template$4(['<!DOCTYPE html>\n<html lang="en">\n<head>\n  <meta charset="utf-8">\n  <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">\n  <meta http-equiv="x-ua-compatible" content="ie=edge">\n  <meta name="description" content="', '">\n  <title>', " - ", "</title>\n\n  ", `

  <script>
    window.tailwind = window.tailwind || {};
    window.tailwind.config = {
      darkMode: 'class',
      theme: {
        extend: {
          colors: {
            primary: 'var(--color-primary)',
            secondary: 'var(--color-secondary)',
            surface: 'var(--color-card-bg)'
          },
          fontFamily: {
            display: ['var(--font-family)'],
            body: ['var(--font-family)']
          },
          boxShadow: {
            surface: 'var(--box-shadow)'
          }
        }
      }
    };
  <\/script>
  <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"><\/script>

  <!-- Custom Styles -->
  <style>`, "</style>\n  <style>", "</style>\n  ", '\n</head>\n<body class="min-h-screen bg-slate-950 antialiased text-white">\n  <div\n    class="relative flex min-h-screen flex-col overflow-hidden"\n    style="\n      background-image: ', ";\n      background-attachment: fixed;\n      background-size: cover;\n      color: ", ";\n      font-family: ", ";\n      font-size: ", ';\n    "\n  >\n    <div class="pointer-events-none absolute inset-0 overflow-hidden">\n      <div class="absolute -left-20 top-[10%] h-64 w-64 rounded-full blur-[120px]" style="background: ', '; opacity: 0.85;"></div>\n      <div class="absolute right-[-15%] top-[5%] h-72 w-72 rounded-full blur-[120px]" style="background: ', '; opacity: 0.65;"></div>\n      <div class="absolute left-1/2 top-[65%] h-96 w-[36rem] -translate-x-1/2 rounded-[200px] blur-[160px]" style="background: ', '; opacity: 0.35;"></div>\n    </div>\n\n    <main class="relative z-10 flex flex-1 items-stretch justify-center">\n      ', "\n      ", "\n    </main>\n  </div>\n</body>\n</html>"])), theme.tagline, title, theme.title, theme.favicon ? html`
    <link rel="shortcut icon" href="${theme.favicon}">
    <link rel="icon" href="${theme.favicon}">
  ` : "", themeCSS, getCSS(), theme.customCSS ? html`<style>${theme.customCSS}</style>` : "", backgroundGradient, theme.textColor, theme.fontFamily, theme.fontSize, primaryGlow, secondaryGlow, surfaceGlow, flashContainer, content);
}

function LoginPage(props = {}) {
  const { error = null, success = null, email = "", config = {} } = props;
  const companyName = config.companyName || "S3DB";
  const legalName = config.legalName || config.companyName || "S3DB Corp";
  const heroTitle = config.heroTitle || companyName;
  const heroSubtitle = config.welcomeMessage || config.heroSubtitle || "Welcome back!";
  const currentYear = (/* @__PURE__ */ new Date()).getFullYear();
  const heroFooter = config.heroFooter || `\xA9 ${currentYear} ${legalName} \u2022 All rights reserved`;
  const content = html`
    <section class="identity-login">
      <aside class="identity-login__panel">
        <div class="identity-login__panel-content">
          <div class="identity-login__brand">
            ${config.logoUrl ? html`
              <img src="${config.logoUrl}" alt="${config.title || "Identity Logo"}" class="identity-login__brand-logo" />
            ` : ""}
            <span class="identity-login__badge">
              Identity
            </span>
          </div>

          <div class="identity-login__panel-main">
            <h1 class="identity-login__panel-title">${heroTitle}</h1>
            <p class="identity-login__panel-text">
              ${heroSubtitle}
            </p>
          </div>
        </div>

        <footer class="identity-login__panel-footer">
          ${heroFooter}
        </footer>
      </aside>

      <div class="identity-login__form">
        <header class="identity-login__form-header">
          <h2>Sign in to your account</h2>
          <p>Enter your credentials to access your workspace.</p>
        </header>

        ${error ? html`
          <div class="identity-login__alert identity-login__alert--error">
            ${error}
          </div>
        ` : ""}

        <form method="POST" action="/login" class="identity-login__form-body">
          <div class="identity-login__group">
            <label for="email">Email Address</label>
            <input
              type="email"
              class="identity-login__input"
              id="email"
              name="email"
              value="${email}"
              required
              autofocus
              autocomplete="email"
              placeholder="you@example.com"
            />
          </div>

          <div class="identity-login__group">
            <label for="password">Password</label>
            <input
              type="password"
              class="identity-login__input"
              id="password"
              name="password"
              required
              autocomplete="current-password"
              placeholder="Enter your password"
            />
          </div>

          <div class="identity-login__options">
            <label class="identity-login__checkbox">
              <input
                type="checkbox"
                id="remember"
                name="remember"
                value="1"
              />
              <span>Remember me</span>
            </label>
            <a href="/forgot-password" class="identity-login__forgot">
              Forgot password?
            </a>
          </div>

          <button
            type="submit"
            class="identity-login__submit"
          >
            Sign In
          </button>
        </form>

        <div class="identity-login__divider"><span>or</span></div>

        ${config.registrationEnabled !== false ? html`
          <p class="identity-login__meta">
            Don't have an account?
            <a href="/register">Sign up</a>
          </p>
        ` : ""}

        ${config.supportEmail ? html`
          <p class="identity-login__support">
            Need help? <a href="mailto:${config.supportEmail}">${config.supportEmail}</a>
          </p>
        ` : ""}
      </div>
    </section>
  `;
  return BaseLayout({
    title: "Sign In",
    content,
    config,
    error: null,
    // Error shown in form
    success
    // Success shown at top
  });
}

function RegisterPage(props = {}) {
  const { error = null, email = "", name = "", passwordPolicy = {}, config = {} } = props;
  const companyName = config.companyName || "S3DB";
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const inputClasses = [
    "block w-full rounded-2xl border bg-white/[0.08] px-4 py-3 text-base text-white",
    "shadow-[0_1px_0_rgba(255,255,255,0.06)] transition placeholder:text-slate-300/70 focus:outline-none focus:ring-2",
    error ? "border-red-400/70 focus:border-red-400 focus:ring-red-400/40" : "border-white/10 focus:border-white/40 focus:ring-white/30"
  ].join(" ");
  const checkboxClasses = [
    "h-5 w-5 rounded border-white/30 bg-slate-900/70 text-primary",
    "focus:ring-2 focus:ring-primary/40 focus:ring-offset-0 focus:outline-none"
  ].join(" ");
  const content = html`
    <section class="mx-auto flex w-full max-w-5xl flex-col items-center gap-12 text-slate-100 md:flex-row md:items-start md:justify-between">
      <div class="order-2 w-full max-w-xl md:order-1">
        <div class="relative isolate overflow-hidden rounded-3xl border border-white/10 bg-slate-900/60 p-10 shadow-2xl shadow-slate-900/60 backdrop-blur">
          <div class="pointer-events-none absolute -right-24 -top-28 h-64 w-64 rounded-full bg-primary/25 blur-3xl"></div>
          <div class="pointer-events-none absolute -bottom-28 -left-24 h-56 w-56 rounded-full bg-secondary/20 blur-[120px]"></div>

          <div class="relative z-10 space-y-8">
            <header class="space-y-2 text-center">
              <h2 class="text-2xl font-semibold tracking-tight text-white">
                Create Account
              </h2>
              <p class="text-sm text-slate-300">
                Join ${companyName} Identity to access all secure services.
              </p>
            </header>

            ${error ? html`
              <div class="rounded-xl border border-red-500/40 bg-red-500/10 px-4 py-3 text-sm leading-6 text-red-100 shadow-md shadow-red-900/30">
                ${error}
              </div>
            ` : ""}

            <form method="POST" action="/register" class="space-y-6">
              <div class="space-y-2">
                <label for="name" class="text-sm font-semibold text-slate-200">
                  Full Name
                </label>
                <input
                  type="text"
                  class="${inputClasses}"
                  id="name"
                  name="name"
                  value="${name}"
                  required
                  autofocus
                  autocomplete="name"
                  minlength="2"
                  maxlength="100"
                />
              </div>

              <div class="space-y-2">
                <label for="email" class="text-sm font-semibold text-slate-200">
                  Email address
                </label>
                <input
                  type="email"
                  class="${inputClasses}"
                  id="email"
                  name="email"
                  value="${email}"
                  required
                  autocomplete="email"
                />
                <p class="text-xs text-slate-400">
                  We'll send you a verification email to confirm your account.
                </p>
              </div>

              <div class="space-y-2">
                <label for="password" class="text-sm font-semibold text-slate-200">
                  Password
                </label>
                <input
                  type="password"
                  class="${inputClasses}"
                  id="password"
                  name="password"
                  required
                  autocomplete="new-password"
                  minlength="${minLength}"
                  maxlength="${maxLength}"
                />
                <div class="rounded-2xl border border-white/5 bg-white/[0.06] px-4 py-3 text-xs leading-5 text-slate-200">
                  <span class="font-semibold text-white/80">Must include:</span>
                  <ul class="mt-2 list-disc space-y-1 pl-5 text-slate-300">
                    ${requirements.map((req) => html`<li>${req}</li>`)}
                  </ul>
                </div>
              </div>

              <div class="space-y-2">
                <label for="confirm_password" class="text-sm font-semibold text-slate-200">
                  Confirm Password
                </label>
                <input
                  type="password"
                  class="${inputClasses}"
                  id="confirm_password"
                  name="confirm_password"
                  required
                  autocomplete="new-password"
                />
              </div>

              <label class="flex items-start gap-3 text-sm text-slate-300">
                <input
                  type="checkbox"
                  class="${checkboxClasses} mt-0.5"
                  id="agree_terms"
                  name="agree_terms"
                  value="1"
                  required
                />
                <span>
                  I agree to the
                  <a href="/terms" class="font-semibold text-primary transition hover:text-white" target="_blank">Terms of Service</a>
                  and
                  <a href="/privacy" class="font-semibold text-primary transition hover:text-white" target="_blank">Privacy Policy</a>.
                </span>
              </label>

              <button
                type="submit"
                class="inline-flex w-full items-center justify-center rounded-2xl bg-gradient-to-r from-primary via-primary to-secondary px-4 py-3 text-base font-semibold text-white transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
                style="box-shadow: 0 18px 45px var(--color-primary-glow);"
              >
                Create Account
              </button>
            </form>

            <p class="text-center text-sm text-slate-300">
              Already have an account?
              <a href="/login" class="font-semibold text-primary transition hover:text-white">
                Sign in
              </a>
            </p>
          </div>
        </div>
      </div>

      <div class="order-1 max-w-xl text-center md:order-2 md:text-left">
        ${config.logoUrl ? html`
          <div class="mb-6 flex justify-center md:justify-start">
            <img src="${config.logoUrl}" alt="${config.title || "Identity Logo"}" class="h-12 w-auto" />
          </div>
        ` : ""}
        <h1 class="text-3xl font-semibold tracking-tight text-white md:text-4xl">
          Welcome to ${config.title || "S3DB Identity"}
        </h1>
        <p class="mt-4 text-base text-slate-300 md:text-lg">
          ${config.tagline || "Create a secure identity to access your workspace and applications."}
        </p>
        <div class="mt-8 grid gap-4 text-left text-sm text-slate-300">
          <div class="rounded-2xl border border-white/5 bg-white/[0.04] px-4 py-3">
            <span class="font-semibold text-white"> Fast onboarding</span>
            <p class="mt-1 text-slate-300">
              Start collaborating in minutes with instant verification.
            </p>
          </div>
          <div class="rounded-2xl border border-white/5 bg-white/[0.04] px-4 py-3">
            <span class="font-semibold text-white"> Enterprise-grade security</span>
            <p class="mt-1 text-slate-300">
              Backed by multi-layer encryption and continuous monitoring.
            </p>
          </div>
          <div class="rounded-2xl border border-white/5 bg-white/[0.04] px-4 py-3">
            <span class="font-semibold text-white"> Live support</span>
            <p class="mt-1 text-slate-300">
              Our team is ready to help you with any registration issues.
            </p>
          </div>
        </div>
      </div>
    </section>
  `;
  return BaseLayout({
    title: "Create Account",
    content,
    config,
    error: null
    // Error shown in form
  });
}

function ForgotPasswordPage(props = {}) {
  const { error = null, success = null, email = "", config = {} } = props;
  const inputClasses = [
    "block w-full rounded-2xl border bg-white/[0.08] px-4 py-3 text-base text-white",
    "shadow-[0_1px_0_rgba(255,255,255,0.06)] transition placeholder:text-slate-300/70 focus:outline-none focus:ring-2",
    error ? "border-red-400/70 focus:border-red-400 focus:ring-red-400/40" : "border-white/10 focus:border-white/40 focus:ring-white/30"
  ].join(" ");
  const content = html`
    <section class="mx-auto w-full max-w-lg text-slate-100">
      <div class="relative isolate overflow-hidden rounded-3xl border border-white/10 bg-slate-900/60 p-10 shadow-2xl shadow-slate-900/60 backdrop-blur">
        <div class="pointer-events-none absolute -right-24 -top-24 h-56 w-56 rounded-full bg-primary/25 blur-3xl"></div>
        <div class="pointer-events-none absolute -bottom-20 -left-28 h-52 w-52 rounded-full bg-secondary/20 blur-[120px]"></div>

        <div class="relative z-10 space-y-6">
          <header class="space-y-2 text-center">
            <h2 class="text-2xl font-semibold tracking-tight text-white">
              Reset Password
            </h2>
            <p class="text-sm text-slate-300">
              Enter your email and we'll send instructions to reset your password.
            </p>
          </header>

          ${success ? html`
            <div class="space-y-6">
              <div class="rounded-2xl border border-emerald-400/40 bg-emerald-500/10 px-4 py-4 text-sm leading-6 text-emerald-100 shadow-lg shadow-emerald-900/30">
                ${success}
              </div>
              <div class="text-center text-sm text-slate-300">
                <a href="/login" class="font-semibold text-primary transition hover:text-white">
                  Back to Sign In
                </a>
              </div>
            </div>
          ` : html`
            <form method="POST" action="/forgot-password" class="space-y-6">
              <div class="space-y-2">
                <label for="email" class="text-sm font-semibold text-slate-200">
                  Email address
                </label>
                <input
                  type="email"
                  class="${inputClasses}"
                  id="email"
                  name="email"
                  value="${email}"
                  required
                  autofocus
                  autocomplete="email"
                />
                ${error ? html`
                  <p class="text-xs text-red-200">${error}</p>
                ` : ""}
              </div>

              <button
                type="submit"
                class="inline-flex w-full items-center justify-center rounded-2xl bg-gradient-to-r from-primary via-primary to-secondary px-4 py-3 text-base font-semibold text-white transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
                style="box-shadow: 0 18px 45px var(--color-primary-glow);"
              >
                Send Reset Link
              </button>
            </form>

            <p class="text-center text-sm text-slate-300">
              Remember your password?
              <a href="/login" class="font-semibold text-primary transition hover:text-white">
                Sign in
              </a>
            </p>
          `}
        </div>
      </div>
    </section>
  `;
  return BaseLayout({
    title: "Reset Password",
    content,
    config,
    error: null,
    // Error shown in form
    success: null
    // Success shown in form
  });
}

function ResetPasswordPage(props = {}) {
  const { error = null, token = "", passwordPolicy = {}, config = {} } = props;
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const inputClasses = [
    "block w-full rounded-2xl border bg-white/[0.08] px-4 py-3 text-base text-white",
    "shadow-[0_1px_0_rgba(255,255,255,0.06)] transition placeholder:text-slate-300/70 focus:outline-none focus:ring-2",
    error ? "border-red-400/70 focus:border-red-400 focus:ring-red-400/40" : "border-white/10 focus:border-white/40 focus:ring-white/30"
  ].join(" ");
  const content = html`
    <section class="mx-auto w-full max-w-lg text-slate-100">
      <div class="relative isolate overflow-hidden rounded-3xl border border-white/10 bg-slate-900/60 p-10 shadow-2xl shadow-slate-900/60 backdrop-blur">
        <div class="pointer-events-none absolute -right-20 -top-28 h-60 w-60 rounded-full bg-primary/25 blur-3xl"></div>
        <div class="pointer-events-none absolute -bottom-24 -left-28 h-56 w-56 rounded-full bg-secondary/20 blur-[120px]"></div>

        <div class="relative z-10 space-y-6">
          <header class="space-y-2 text-center">
            <h2 class="text-2xl font-semibold tracking-tight text-white">
              Set New Password
            </h2>
            <p class="text-sm text-slate-300">
              Choose a strong password to secure your account.
            </p>
          </header>

          <form method="POST" action="/reset-password" class="space-y-6">
            <input type="hidden" name="token" value="${token}" />

            <div class="space-y-2">
              <label for="password" class="text-sm font-semibold text-slate-200">
                New Password
              </label>
              <input
                type="password"
                class="${inputClasses}"
                id="password"
                name="password"
                required
                autofocus
                autocomplete="new-password"
                minlength="${minLength}"
                maxlength="${maxLength}"
              />
              <div class="rounded-2xl border border-white/5 bg-white/[0.06] px-4 py-3 text-xs leading-5 text-slate-200">
                <span class="font-semibold text-white/80">Must include:</span>
                <ul class="mt-2 list-disc space-y-1 pl-5 text-slate-300">
                  ${requirements.map((req) => html`<li>${req}</li>`)}
                </ul>
              </div>
            </div>

            <div class="space-y-2">
              <label for="confirm_password" class="text-sm font-semibold text-slate-200">
                Confirm New Password
              </label>
              <input
                type="password"
                class="${inputClasses}"
                id="confirm_password"
                name="confirm_password"
                required
                autocomplete="new-password"
              />
              ${error ? html`<p class="text-xs text-red-200">${error}</p>` : ""}
            </div>

            <button
              type="submit"
              class="inline-flex w-full items-center justify-center rounded-2xl bg-gradient-to-r from-primary via-primary to-secondary px-4 py-3 text-base font-semibold text-white transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
              style="box-shadow: 0 18px 45px var(--color-primary-glow);"
            >
              Reset Password
            </button>
          </form>

          <p class="text-center text-sm text-slate-300">
            Remember your password?
            <a href="/login" class="font-semibold text-primary transition hover:text-white">
              Sign in
            </a>
          </p>
        </div>
      </div>
    </section>
  `;
  return BaseLayout({
    title: "Set New Password",
    content,
    config,
    error: null,
    // Error shown in form
    success: null
  });
}

function ProfilePage(props = {}) {
  const { user = {}, sessions = [], error = null, success = null, passwordPolicy = {}, config = {} } = props;
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const inputClasses = [
    "block w-full rounded-2xl border border-white/10 bg-white/[0.08] px-4 py-3 text-sm text-white",
    "shadow-[0_1px_0_rgba(255,255,255,0.05)] transition placeholder:text-slate-300/70 focus:border-white/40 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const primaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-5 py-2.5 text-sm font-semibold text-white",
    "transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const dangerButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-4 py-2 text-xs font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const dangerButtonLargeClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-5 py-2.5 text-sm font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const panelClasses = "rounded-3xl border border-white/10 bg-white/[0.05] p-8 shadow-xl shadow-black/30 backdrop-blur";
  const accountRows = [];
  accountRows.push({
    label: "Account Status",
    value: user.status === "active" ? html`<span class="text-emerald-300"> Active</span>` : user.status === "pending_verification" ? html`<span class="text-amber-300"> Pending Verification</span>` : user.status === "suspended" ? html`<span class="text-red-300"> Suspended</span>` : html`<span class="text-slate-300">Unknown</span>`
  });
  if (user.isAdmin) {
    accountRows.push({
      label: "Role",
      value: html`<span class="font-semibold text-primary"> Administrator</span>`
    });
  }
  if (user.lastLoginAt) {
    accountRows.push({
      label: "Last Login",
      value: html`${new Date(user.lastLoginAt).toLocaleString()}`
    });
  }
  if (user.lastLoginIp) {
    accountRows.push({
      label: "Last Login IP",
      value: html`${user.lastLoginIp}`
    });
  }
  if (user.createdAt) {
    accountRows.push({
      label: "Member Since",
      value: html`${new Date(user.createdAt).toLocaleDateString()}`
    });
  }
  const sessionCards = sessions.map((session) => {
    const isCurrentSession = session.isCurrent;
    const createdAt = session.createdAt ? new Date(session.createdAt) : null;
    const expiresAt = session.expiresAt ? new Date(session.expiresAt) : null;
    const sessionClasses = [
      "rounded-2xl border border-white/10 px-5 py-4 transition",
      isCurrentSession ? "bg-primary/10 ring-1 ring-primary/40" : "bg-white/[0.05] hover:bg-white/[0.08]"
    ].join(" ");
    return html`
      <div class="${sessionClasses}">
        <div class="flex flex-col gap-4 sm:flex-row sm:items-start sm:justify-between">
          <div class="space-y-3">
            <div class="flex flex-wrap items-center gap-3 text-sm font-semibold text-white">
              <span>${session.userAgent || "Unknown device"}</span>
              ${isCurrentSession ? html`
                <span class="rounded-full bg-emerald-500/20 px-3 py-1 text-xs font-semibold text-emerald-200">
                  Current
                </span>
              ` : ""}
            </div>
            <dl class="grid gap-2 text-xs text-slate-300">
              <div class="flex gap-3">
                <dt class="w-24 text-slate-400">IP</dt>
                <dd class="flex-1">${session.ipAddress || "Unknown"}</dd>
              </div>
              <div class="flex gap-3">
                <dt class="w-24 text-slate-400">Created</dt>
                <dd class="flex-1">${createdAt ? createdAt.toLocaleString() : "Unknown"}</dd>
              </div>
              <div class="flex gap-3">
                <dt class="w-24 text-slate-400">Expires</dt>
                <dd class="flex-1">${expiresAt ? expiresAt.toLocaleString() : "Unknown"}</dd>
              </div>
            </dl>
          </div>
          ${!isCurrentSession ? html`
            <form method="POST" action="/profile/logout-session" class="shrink-0 self-start">
              <input type="hidden" name="session_id" value="${session.id}" />
              <button type="submit" class="${dangerButtonClass}">
                Logout
              </button>
            </form>
          ` : html`
            <span class="shrink-0 rounded-full border border-emerald-400/30 bg-emerald-500/10 px-3 py-1 text-xs font-semibold text-emerald-200">
              Active Session
            </span>
          `}
        </div>
      </div>
    `;
  });
  const sessionsSection = sessions.length === 0 ? html`<p class="text-sm text-slate-300">No active sessions</p>` : html`
      <div class="space-y-4">
        <p class="text-sm text-slate-300">
          You are currently logged in on these devices. If you see a session you don't recognize, log it out immediately.
        </p>
        ${sessionCards}
        ${sessions.length > 1 ? html`
          <form method="POST" action="/profile/logout-all-sessions" class="pt-2">
            <button type="submit" class="${dangerButtonLargeClass}">
              Logout All Other Sessions
            </button>
          </form>
        ` : ""}
      </div>
    `;
  const content = html`
    <section class="mx-auto w-full max-w-6xl space-y-8 text-slate-100">
      <header class="flex flex-col gap-4 sm:flex-row sm:items-end sm:justify-between">
        <div>
          <h1 class="text-3xl font-semibold text-white md:text-4xl">My Profile</h1>
          <p class="mt-1 text-sm text-slate-300">
            Manage your personal information, security preferences, and connected sessions.
          </p>
        </div>
        <div class="flex items-center gap-3 self-start rounded-2xl border border-white/15 bg-white/[0.06] px-4 py-3 text-xs text-slate-300">
          <span class="text-sm font-semibold text-white">${user.email || "Unknown email"}</span>
          <span class="${user.emailVerified ? "rounded-full bg-emerald-500/20 px-3 py-1 text-xs font-semibold text-emerald-200" : "rounded-full bg-amber-500/20 px-3 py-1 text-xs font-semibold text-amber-200"}">
            ${user.emailVerified ? "Verified" : "Not verified"}
          </span>
        </div>
      </header>

      <div class="grid gap-8 lg:grid-cols-[1.1fr_0.9fr]">
        <div class="space-y-8">
          <div class="${panelClasses}">
            <div class="flex items-start justify-between gap-4">
              <div>
                <h2 class="text-xl font-semibold text-white">Profile Information</h2>
                <p class="text-sm text-slate-300">
                  Update your personal details and contact email.
                </p>
              </div>
            </div>
            <form method="POST" action="/profile/update" class="mt-6 space-y-6">
              <div class="space-y-2">
                <label for="name" class="text-sm font-semibold text-slate-200">
                  Full Name
                </label>
                <input
                  type="text"
                  class="${inputClasses}"
                  id="name"
                  name="name"
                  value="${user.name || ""}"
                  required
                  minlength="2"
                  maxlength="100"
                />
              </div>

              <div class="space-y-2">
                <label for="email" class="text-sm font-semibold text-slate-200">
                  Email Address
                </label>
                <input
                  type="email"
                  class="${inputClasses}"
                  id="email"
                  name="email"
                  value="${user.email || ""}"
                  required
                  autocomplete="email"
                />
                ${user.emailVerified ? html`<p class="text-xs font-medium text-emerald-300"> Verified email address</p>` : html`<p class="text-xs text-amber-200">
                       Not verified 
                      <a href="/verify-email/resend" class="font-semibold text-primary transition hover:text-white">
                        Resend verification email
                      </a>
                    </p>`}
              </div>

              <button type="submit" class="${primaryButtonClass} w-full sm:w-auto" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
                Save Changes
              </button>
            </form>
          </div>

          <div class="${panelClasses}">
            <h2 class="text-xl font-semibold text-white">Change Password</h2>
            <p class="text-sm text-slate-300">
              Keep your account secure with a strong password.
            </p>

            <form method="POST" action="/profile/change-password" class="mt-6 space-y-6">
              <div class="space-y-2">
                <label for="current_password" class="text-sm font-semibold text-slate-200">
                  Current Password
                </label>
                <input
                  type="password"
                  class="${inputClasses}"
                  id="current_password"
                  name="current_password"
                  required
                  autocomplete="current-password"
                />
              </div>

              <div class="space-y-2">
                <label for="new_password" class="text-sm font-semibold text-slate-200">
                  New Password
                </label>
                <input
                  type="password"
                  class="${inputClasses}"
                  id="new_password"
                  name="new_password"
                  required
                  autocomplete="new-password"
                  minlength="${minLength}"
                  maxlength="${maxLength}"
                />
                <div class="rounded-2xl border border-white/10 bg-white/[0.06] px-4 py-3 text-xs text-slate-200">
                  <span class="font-semibold text-white/80">Must include:</span>
                  <ul class="mt-2 list-disc space-y-1 pl-5 text-slate-300">
                    ${requirements.map((req) => html`<li>${req}</li>`)}
                  </ul>
                </div>
              </div>

              <div class="space-y-2">
                <label for="confirm_new_password" class="text-sm font-semibold text-slate-200">
                  Confirm New Password
                </label>
                <input
                  type="password"
                  class="${inputClasses}"
                  id="confirm_new_password"
                  name="confirm_new_password"
                  required
                  autocomplete="new-password"
                />
              </div>

              <button type="submit" class="${primaryButtonClass} w-full sm:w-auto" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
                Change Password
              </button>
            </form>
          </div>
        </div>

        <div class="space-y-8">
          <div class="${panelClasses}">
            <h2 class="text-xl font-semibold text-white">Account Overview</h2>
            <p class="text-sm text-slate-300">
              Key information about your account and access.
            </p>
            <dl class="mt-6 space-y-4">
              ${accountRows.map((row) => html`
                <div class="flex flex-col gap-2 border-b border-white/10 pb-4 last:border-b-0 last:pb-0 sm:flex-row sm:items-start sm:gap-6">
                  <dt class="text-xs font-semibold uppercase tracking-wide text-slate-400 sm:w-40">${row.label}</dt>
                  <dd class="text-sm text-slate-200 sm:flex-1">${row.value}</dd>
                </div>
              `)}
            </dl>
          </div>
        </div>
      </div>

      <div class="${panelClasses}">
        <div class="flex items-center justify-between">
          <div>
            <h2 class="text-xl font-semibold text-white">Active Sessions</h2>
            <p class="text-sm text-slate-300">
              Review and manage the devices currently connected to your account.
            </p>
          </div>
          <span class="rounded-full bg-primary/20 px-3 py-1 text-sm font-semibold text-primary">
            ${sessions.length} active
          </span>
        </div>
        <div class="mt-6 space-y-4">
          ${sessionsSection}
        </div>
      </div>
    </section>
  `;
  return BaseLayout({
    title: "My Profile",
    content,
    config,
    user,
    error,
    success
  });
}

function AdminDashboardPage(props = {}) {
  const { stats = {}, user = {}, config = {} } = props;
  const formatNumber = (value) => Number(value || 0).toLocaleString();
  const statCards = [
    {
      title: "Total Users",
      value: formatNumber(stats.totalUsers),
      description: `${formatNumber(stats.activeUsers)} active \xB7 ${formatNumber(stats.pendingUsers)} pending`,
      gradient: "from-sky-500/90 via-blue-500/80 to-indigo-500/80"
    },
    {
      title: "OAuth2 Clients",
      value: formatNumber(stats.totalClients),
      description: `${formatNumber(stats.activeClients)} active`,
      gradient: "from-fuchsia-500/90 via-rose-500/80 to-orange-500/80"
    },
    {
      title: "Active Sessions",
      value: formatNumber(stats.activeSessions),
      description: `${formatNumber(stats.uniqueUsers)} unique users`,
      gradient: "from-cyan-400/90 via-blue-400/80 to-sky-400/80"
    },
    {
      title: "Auth Codes",
      value: formatNumber(stats.totalAuthCodes),
      description: `${formatNumber(stats.unusedAuthCodes)} unused`,
      gradient: "from-emerald-400/90 via-teal-400/80 to-green-400/80"
    }
  ];
  const quickLinks = [
    { href: "/admin/clients", label: "\u{1F4F1} Manage Clients" },
    { href: "/admin/users", label: "\u{1F465} Manage Users" },
    { href: "/admin/sessions", label: "\u{1F510} View Sessions" },
    { href: "/admin/auth-codes", label: "\u{1F3AB} Auth Codes" }
  ];
  const recentUsers = Array.isArray(stats.recentUsers) ? stats.recentUsers : [];
  const content = html`
    <section class="mx-auto w-full max-w-6xl space-y-8 text-slate-100">
      <header class="flex flex-col gap-4 sm:flex-row sm:items-end sm:justify-between">
        <div>
          <h1 class="text-3xl font-semibold text-white md:text-4xl">Admin Dashboard</h1>
          <p class="mt-1 text-sm text-slate-300">
            Overview of identity activity, clients, and health metrics.
          </p>
        </div>
        <div class="rounded-2xl border border-white/15 bg-white/[0.06] px-4 py-3 text-xs text-slate-300">
          <div class="text-sm font-semibold text-white">${user.email || "admin@s3db.identity"}</div>
          <div class="mt-1 flex flex-wrap items-center gap-2">
            <span class="rounded-full bg-emerald-500/20 px-3 py-1 text-xs font-semibold text-emerald-200">
              Administrator
            </span>
            ${stats.serverUptime ? html`
              <span class="text-xs text-slate-400">
                Uptime: ${stats.serverUptime}
              </span>
            ` : ""}
          </div>
        </div>
      </header>

      <div class="grid gap-6 sm:grid-cols-2 xl:grid-cols-4">
        ${statCards.map((card) => html`
          <div class="rounded-3xl border border-white/10 bg-gradient-to-br ${card.gradient} p-6 shadow-xl shadow-black/30 backdrop-blur">
            <div class="text-xs uppercase tracking-wide text-white/80">${card.title}</div>
            <div class="mt-3 text-3xl font-semibold text-white">${card.value}</div>
            <div class="mt-2 text-sm text-white/80">${card.description}</div>
          </div>
        `)}
      </div>

      <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
        <h2 class="text-lg font-semibold text-white">Quick Actions</h2>
        <div class="mt-4 grid gap-3 sm:grid-cols-2 lg:grid-cols-4">
          ${quickLinks.map((link) => html`
            <a
              href="${link.href}"
              class="flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06] px-4 py-3 text-sm font-semibold text-white transition hover:-translate-y-0.5 hover:bg-white/[0.12] focus:outline-none focus:ring-2 focus:ring-white/20"
            >
              ${link.label}
            </a>
          `)}
        </div>
      </div>

      ${recentUsers.length > 0 ? html`
        <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
          <h2 class="text-lg font-semibold text-white">Recent Users</h2>
          <div class="mt-4 overflow-hidden rounded-2xl border border-white/10">
            <table class="min-w-full divide-y divide-white/10 text-left text-sm text-slate-200">
              <thead class="bg-white/[0.04] text-xs uppercase tracking-wide text-slate-400">
                <tr>
                  <th class="px-4 py-3 font-medium">Email</th>
                  <th class="px-4 py-3 font-medium">Name</th>
                  <th class="px-4 py-3 font-medium">Status</th>
                  <th class="px-4 py-3 font-medium">Created</th>
                </tr>
              </thead>
              <tbody class="divide-y divide-white/5">
                ${recentUsers.map((recentUser) => {
    const statusClass = recentUser.status === "active" ? "bg-emerald-500/20 text-emerald-200" : recentUser.status === "suspended" ? "bg-red-500/20 text-red-200" : "bg-amber-500/20 text-amber-200";
    return html`
                    <tr class="hover:bg-white/[0.04]">
                      <td class="px-4 py-3">${recentUser.email}</td>
                      <td class="px-4 py-3">${recentUser.name}</td>
                      <td class="px-4 py-3">
                        <span class="rounded-full px-3 py-1 text-xs font-semibold ${statusClass}">
                          ${recentUser.status}
                        </span>
                      </td>
                      <td class="px-4 py-3 text-slate-400">
                        ${new Date(recentUser.createdAt).toLocaleDateString()}
                      </td>
                    </tr>
                  `;
  })}
              </tbody>
            </table>
          </div>
        </div>
      ` : ""}

      <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
        <h2 class="text-lg font-semibold text-white">System Information</h2>
        <dl class="mt-4 divide-y divide-white/10 text-sm text-slate-200">
          <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
            <dt class="text-slate-400">Identity Provider</dt>
            <dd class="font-medium text-white">${config.title || "S3DB Identity"}</dd>
          </div>
          <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
            <dt class="text-slate-400">Your Role</dt>
            <dd class="font-medium text-primary">Administrator</dd>
          </div>
          ${stats.serverUptime ? html`
            <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
              <dt class="text-slate-400">Server Uptime</dt>
              <dd>${stats.serverUptime}</dd>
            </div>
          ` : ""}
          <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
            <dt class="text-slate-400">Database Type</dt>
            <dd>S3DB (S3-based Document Database)</dd>
          </div>
        </dl>
      </div>
    </section>
  `;
  return BaseLayout({
    title: "Admin Dashboard",
    content,
    config,
    user
  });
}

function AdminClientsPage(props = {}) {
  const { clients = [], user = {}, error = null, success = null, config = {} } = props;
  const primaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-4 py-2.5 text-sm font-semibold text-white",
    "transition hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const secondaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-4 py-2.5 text-sm font-semibold text-white transition hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const dangerButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-4 py-2.5 text-sm font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const successButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-emerald-400/40 bg-emerald-500/10",
    "px-4 py-2.5 text-sm font-semibold text-emerald-100 transition hover:bg-emerald-500/15 focus:outline-none focus:ring-2 focus:ring-emerald-400/40"
  ].join(" ");
  const codeChipClass = "rounded-xl border border-white/10 bg-white/[0.08] px-3 py-1 text-xs text-slate-200";
  const badgeClass = "rounded-full bg-primary/20 px-3 py-1 text-xs font-semibold text-primary";
  const content = html`
    <section class="mx-auto w-full max-w-6xl space-y-8 text-slate-100">
      <header class="flex flex-col gap-4 sm:flex-row sm:items-center sm:justify-between">
        <div>
          <h1 class="text-3xl font-semibold text-white md:text-4xl">OAuth2 Clients</h1>
          <p class="mt-1 text-sm text-slate-300">
            Manage client credentials, redirect URIs, and allowed scopes.
          </p>
        </div>
        <a href="/admin/clients/new" class="${primaryButtonClass}">
          + New Client
        </a>
      </header>

      ${clients.length === 0 ? html`
        <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-10 text-center shadow-xl shadow-black/30 backdrop-blur">
          <p class="text-sm text-slate-300">
            No OAuth2 clients registered yet. Create your first client to start integrating applications.
          </p>
          <a href="/admin/clients/new" class="${primaryButtonClass} mt-6 inline-flex" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
            Create Your First Client
          </a>
        </div>
      ` : html`
        <div class="grid gap-6">
          ${clients.map((client) => {
    const grantTypes = Array.isArray(client.grantTypes) ? client.grantTypes : [];
    const allowedScopes = Array.isArray(client.allowedScopes) ? client.allowedScopes : [];
    const redirectUris = Array.isArray(client.redirectUris) ? client.redirectUris : [];
    return html`
              <article class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
                <div class="flex flex-col gap-4 border-b border-white/10 pb-4 sm:flex-row sm:items-center sm:justify-between">
                  <div class="flex flex-wrap items-center gap-3">
                    <h2 class="text-lg font-semibold text-white">${client.name}</h2>
                    ${client.active ? "" : html`
                      <span class="rounded-full bg-red-500/20 px-3 py-1 text-xs font-semibold text-red-200">
                        Inactive
                      </span>
                    `}
                  </div>
                  <div class="flex flex-wrap items-center gap-2">
                    <a href="/admin/clients/${client.id}/edit" class="${secondaryButtonClass}">
                      Edit
                    </a>
                    <form method="POST" action="/admin/clients/${client.id}/delete" class="inline-flex" onsubmit="return confirm('Are you sure you want to delete this client? This action cannot be undone.')">
                      <button type="submit" class="${dangerButtonClass}">
                        Delete
                      </button>
                    </form>
                  </div>
                </div>

                <div class="mt-4 space-y-6 text-sm text-slate-200">
                  <div>
                    <div class="text-xs uppercase tracking-wide text-slate-400">Client ID</div>
                    <code class="${codeChipClass} mt-2 block">${client.clientId}</code>
                  </div>

                  ${redirectUris.length > 0 ? html`
                    <div>
                      <div class="text-xs uppercase tracking-wide text-slate-400">
                        Redirect URIs (${redirectUris.length})
                      </div>
                      <div class="mt-2 flex flex-wrap gap-2">
                        ${redirectUris.map((uri) => html`<code class="${codeChipClass}">${uri}</code>`)}
                      </div>
                    </div>
                  ` : ""}

                  ${grantTypes.length > 0 ? html`
                    <div>
                      <div class="text-xs uppercase tracking-wide text-slate-400">Grant Types</div>
                      <div class="mt-2 flex flex-wrap gap-2">
                        ${grantTypes.map((type) => html`
                          <span class="${badgeClass}">
                            ${type}
                          </span>
                        `)}
                      </div>
                    </div>
                  ` : ""}

                  ${allowedScopes.length > 0 ? html`
                    <div>
                      <div class="text-xs uppercase tracking-wide text-slate-400">Allowed Scopes</div>
                      <div class="mt-2 flex flex-wrap gap-2">
                        ${allowedScopes.map((scope) => html`
                          <span class="rounded-full bg-emerald-500/20 px-3 py-1 text-xs font-semibold text-emerald-200">
                            ${scope}
                          </span>
                        `)}
                      </div>
                    </div>
                  ` : ""}

                  ${client.createdAt ? html`
                    <div class="text-xs text-slate-400">
                      Created ${new Date(client.createdAt).toLocaleString()}
                    </div>
                  ` : ""}
                </div>

                <div class="mt-6 flex flex-wrap gap-3 border-t border-white/10 pt-4">
                  <form method="POST" action="/admin/clients/${client.id}/rotate-secret" class="inline-flex">
                    <button type="submit" class="${secondaryButtonClass}">
                       Rotate Secret
                    </button>
                  </form>
                  <form method="POST" action="/admin/clients/${client.id}/toggle-active" class="inline-flex">
                    <button type="submit" class="${client.active ? dangerButtonClass : successButtonClass}">
                      ${client.active ? "\u{1F534} Deactivate" : "\u{1F7E2} Activate"}
                    </button>
                  </form>
                </div>
              </article>
            `;
  })}
        </div>
      `}
    </section>
  `;
  return BaseLayout({
    title: "OAuth2 Clients - Admin",
    content,
    config,
    user,
    error,
    success
  });
}

var __freeze$3 = Object.freeze;
var __defProp$3 = Object.defineProperty;
var __template$3 = (cooked, raw) => __freeze$3(__defProp$3(cooked, "raw", { value: __freeze$3(cooked.slice()) }));
var _a$3;
function AdminClientFormPage(props = {}) {
  const {
    client = null,
    user = {},
    error = null,
    availableScopes = [],
    availableGrantTypes = [],
    config = {}
  } = props;
  const isEditMode = !!client;
  const clientData = client || {
    name: "",
    redirectUris: [""],
    grantTypes: ["authorization_code", "refresh_token"],
    allowedScopes: ["openid", "profile", "email"],
    active: true
  };
  const inputClasses = [
    "block w-full rounded-2xl border border-white/10 bg-white/[0.08]",
    "px-4 py-2.5 text-sm text-white placeholder:text-slate-300/70",
    "shadow-[0_1px_0_rgba(255,255,255,0.05)] transition focus:border-white/40 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const checkboxClasses = [
    "h-4 w-4 rounded border-white/30 bg-slate-900/70 text-primary",
    "focus:ring-2 focus:ring-primary/40 focus:ring-offset-0 focus:outline-none"
  ].join(" ");
  const primaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-5 py-2.5 text-sm font-semibold text-white",
    "transition hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const secondaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-4 py-2.5 text-sm font-semibold text-white transition hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const dangerButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-4 py-2 text-sm font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const content = html(_a$3 || (_a$3 = __template$3(['\n    <section class="mx-auto w-full max-w-4xl space-y-8 text-slate-100">\n      <header>\n        <a href="/admin/clients" class="text-sm font-semibold text-primary transition hover:text-white">\n          \u2190 Back to Clients\n        </a>\n        <h1 class="mt-3 text-3xl font-semibold text-white md:text-4xl">\n          ', ' OAuth2 Client\n        </h1>\n        <p class="mt-2 text-sm text-slate-300">\n          Configure redirect URIs, grant types, and scopes available for this client.\n        </p>\n      </header>\n\n      <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-8 shadow-xl shadow-black/30 backdrop-blur">\n        <form method="POST" action="', '" class="space-y-6">\n          <div class="space-y-2">\n            <label for="name" class="text-sm font-semibold text-slate-200">Client Name</label>\n            <input\n              type="text"\n              class="', " ", '"\n              id="name"\n              name="name"\n              value="', '"\n              required\n              autofocus\n              placeholder="My Application"\n            />\n            <p class="text-xs text-slate-400">A friendly name for this OAuth2 client</p>\n            ', '\n          </div>\n\n          <div class="space-y-3">\n            <label class="text-sm font-semibold text-slate-200">Redirect URIs</label>\n            <div id="redirect-uris-container" class="space-y-2">\n              ', '\n            </div>\n            <button type="button" class="', '" onclick="addRedirectUri()">\n              + Add Another URI\n            </button>\n            <p class="text-xs text-slate-400">\n              Where users will be redirected after authorization.\n            </p>\n          </div>\n\n          <div class="space-y-2">\n            <label class="text-sm font-semibold text-slate-200">Grant Types</label>\n            <div class="grid gap-2 sm:grid-cols-2">\n              ', '\n            </div>\n            <p class="text-xs text-slate-400">OAuth2 grant types this client can use.</p>\n          </div>\n\n          <div class="space-y-2">\n            <label class="text-sm font-semibold text-slate-200">Allowed Scopes</label>\n            <div class="grid gap-2 sm:grid-cols-2">\n              ', '\n            </div>\n            <p class="text-xs text-slate-400">Scopes this client is allowed to request.</p>\n          </div>\n\n          <label class="flex items-start gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">\n            <input\n              type="checkbox"\n              class="', ' mt-1"\n              id="active"\n              name="active"\n              value="1"\n              ', '\n            />\n            <span>\n              <strong class="text-white">Active</strong>\n              <br>\n              Client can authenticate and receive tokens.\n            </span>\n          </label>\n\n          <div class="flex flex-col gap-3 sm:flex-row sm:items-center sm:justify-start">\n            <button type="submit" class="', ' sm:w-auto" style="box-shadow: 0 18px 45px var(--color-primary-glow);">\n              ', '\n            </button>\n            <a href="/admin/clients" class="', '">\n              Cancel\n            </a>\n          </div>\n        </form>\n      </div>\n\n      ', "\n    </section>\n\n    <script>\n      const redirectInputClasses = ", ";\n      const dangerButtonClasses = ", ";\n\n      function addRedirectUri() {\n        const container = document.getElementById('redirect-uris-container');\n        const wrapper = document.createElement('div');\n        wrapper.className = 'flex flex-col gap-2 sm:flex-row sm:items-start sm:gap-3';\n\n        const input = document.createElement('input');\n        input.type = 'url';\n        input.name = 'redirectUris[]';\n        input.required = true;\n        input.placeholder = 'https://example.com/callback';\n        input.className = redirectInputClasses;\n\n        const button = document.createElement('button');\n        button.type = 'button';\n        button.className = dangerButtonClasses + ' shrink-0';\n        button.textContent = '\u2715';\n        button.addEventListener('click', () => wrapper.remove());\n\n        wrapper.appendChild(input);\n        wrapper.appendChild(button);\n        container.appendChild(wrapper);\n      }\n    <\/script>\n  "])), isEditMode ? "Edit" : "Create", isEditMode ? `/admin/clients/${client.id}/update` : "/admin/clients/create", inputClasses, error ? "border-red-400/60 focus:border-red-400 focus:ring-red-400/40" : "", clientData.name, error ? html`<p class="text-xs text-red-200">${error}</p>` : "", (Array.isArray(clientData.redirectUris) ? clientData.redirectUris : [""]).map((uri, index) => html`
                <div class="flex flex-col gap-2 sm:flex-row sm:items-start sm:gap-3">
                  <input
                    type="url"
                    class="${inputClasses}"
                    name="redirectUris[]"
                    value="${uri}"
                    required
                    placeholder="https://example.com/callback"
                  />
                  ${index > 0 ? html`
                    <button type="button" class="${dangerButtonClass} shrink-0" onclick="this.parentElement.remove()">
                      
                    </button>
                  ` : ""}
                </div>
              `), secondaryButtonClass, (availableGrantTypes.length > 0 ? availableGrantTypes : ["authorization_code", "refresh_token", "client_credentials"]).map((type) => {
    const isChecked = Array.isArray(clientData.grantTypes) && clientData.grantTypes.includes(type);
    return html`
                  <label class="flex items-center gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">
                    <input
                      type="checkbox"
                      class="${checkboxClasses}"
                      id="grant_${type}"
                      name="grantTypes[]"
                      value="${type}"
                      ${isChecked ? "checked" : ""}
                    />
                    <span><code>${type}</code></span>
                  </label>
                `;
  }), (availableScopes.length > 0 ? availableScopes : ["openid", "profile", "email", "offline_access"]).map((scope) => {
    const isChecked = Array.isArray(clientData.allowedScopes) && clientData.allowedScopes.includes(scope);
    return html`
                  <label class="flex items-center gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">
                    <input
                      type="checkbox"
                      class="${checkboxClasses}"
                      id="scope_${scope}"
                      name="allowedScopes[]"
                      value="${scope}"
                      ${isChecked ? "checked" : ""}
                    />
                    <span><code>${scope}</code></span>
                  </label>
                `;
  }), checkboxClasses, clientData.active !== false ? "checked" : "", primaryButtonClass, isEditMode ? "Update Client" : "Create Client", secondaryButtonClass, isEditMode ? html`
        <div class="rounded-3xl border border-white/15 bg-white/[0.06] px-6 py-4 text-sm text-slate-200 shadow-inner shadow-black/20">
          <strong class="text-white">Note:</strong>
          The client secret cannot be displayed again after creation. If you need a new secret, use the "Rotate Secret"
          action on the clients list page.
        </div>
      ` : "", JSON.stringify(inputClasses), JSON.stringify(dangerButtonClass));
  return BaseLayout({
    title: `${isEditMode ? "Edit" : "Create"} OAuth2 Client - Admin`,
    content,
    config,
    user,
    error: null
    // Error shown in form
  });
}

const STATUS_STYLES = {
  active: "bg-emerald-500/20 text-emerald-200",
  suspended: "bg-red-500/20 text-red-200",
  pending_verification: "bg-amber-500/20 text-amber-200"
};
function AdminUsersPage(props = {}) {
  const { users = [], user = {}, error = null, success = null, config = {} } = props;
  const secondaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-4 py-2 text-xs font-semibold text-white transition hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const dangerButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-4 py-2 text-xs font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const successButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-emerald-400/40 bg-emerald-500/10",
    "px-4 py-2 text-xs font-semibold text-emerald-100 transition hover:bg-emerald-500/15 focus:outline-none focus:ring-2 focus:ring-emerald-400/40"
  ].join(" ");
  const primaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-4 py-2 text-xs font-semibold text-white",
    "transition hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const headerSecondaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-4 py-2.5 text-sm font-semibold text-white transition hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const summaryCards = [
    {
      label: "Total Users",
      value: users.length,
      gradient: "from-sky-500/90 via-blue-500/80 to-indigo-500/80"
    },
    {
      label: "Active",
      value: users.filter((u) => u.status === "active").length,
      gradient: "from-emerald-400/90 via-green-400/80 to-teal-400/80"
    },
    {
      label: "Pending",
      value: users.filter((u) => u.status === "pending_verification").length,
      gradient: "from-amber-400/90 via-orange-400/80 to-yellow-400/80"
    },
    {
      label: "Verified Emails",
      value: users.filter((u) => u.emailVerified).length,
      gradient: "from-fuchsia-500/90 via-rose-500/80 to-purple-500/80"
    }
  ];
  const tableRows = users.map((current) => {
    const statusClass = STATUS_STYLES[current.status] || "bg-white/10 text-slate-200";
    const isCurrentUser = current.id === user.id;
    const actions = [];
    actions.push(html`
      <a href="/admin/users/${current.id}/edit" class="${secondaryButtonClass}">
        Edit
      </a>
    `);
    if (!isCurrentUser) {
      actions.push(html`
        <form method="POST" action="/admin/users/${current.id}/delete" onsubmit="return confirm('Delete user ${current.email}? This cannot be undone.')">
          <button type="submit" class="${dangerButtonClass}">
            Delete
          </button>
        </form>
      `);
      actions.push(html`
        <form method="POST" action="/admin/users/${current.id}/toggle-status">
          <button type="submit" class="${current.status === "active" ? dangerButtonClass : successButtonClass}">
            ${current.status === "active" ? "\u{1F534} Suspend" : "\u{1F7E2} Activate"}
          </button>
        </form>
      `);
      if (!current.emailVerified) {
        actions.push(html`
          <form method="POST" action="/admin/users/${current.id}/verify-email">
            <button type="submit" class="${secondaryButtonClass}">
               Mark Verified
            </button>
          </form>
        `);
      }
      if (current.lockedUntil || current.failedLoginAttempts > 0) {
        const isLocked = current.lockedUntil && new Date(current.lockedUntil) > /* @__PURE__ */ new Date();
        const lockInfo = isLocked ? `Locked until ${new Date(current.lockedUntil).toLocaleString()}` : `${current.failedLoginAttempts} failed attempts`;
        actions.push(html`
          <form method="POST" action="/admin/users/${current.id}/unlock-account" onsubmit="return confirm('Unlock account for ${current.email}?\\n\\n${lockInfo}')">
            <button type="submit" class="${successButtonClass}">
               Unlock Account
            </button>
          </form>
        `);
      }
      actions.push(html`
        <form method="POST" action="/admin/users/${current.id}/reset-password" onsubmit="return confirm('Send password reset email to ${current.email}?')">
          <button type="submit" class="${secondaryButtonClass}">
             Send Reset
          </button>
        </form>
      `);
      actions.push(html`
        <form method="POST" action="/admin/users/${current.id}/toggle-admin" onsubmit="return confirm('${current.role === "admin" ? "Remove admin privileges from" : "Grant admin privileges to"} ${current.name}?')">
          <button type="submit" class="${current.role === "admin" ? dangerButtonClass : primaryButtonClass}">
            ${current.role === "admin" ? "\u{1F464} Remove Admin" : "\u26A1 Make Admin"}
          </button>
        </form>
      `);
    }
    return html`
      <tr class="border-b border-white/10 hover:bg-white/[0.04]">
        <td class="px-4 py-3 align-top">
          <div class="flex flex-wrap items-center gap-2">
            <span class="font-semibold text-white">${current.name}</span>
            ${isCurrentUser ? html`
              <span class="rounded-full bg-primary/20 px-3 py-1 text-xs font-semibold text-primary">
                You
              </span>
            ` : ""}
          </div>
        </td>
        <td class="px-4 py-3 align-top">
          <code class="rounded-xl border border-white/10 bg-white/[0.08] px-3 py-1 text-xs text-slate-200">
            ${current.email}
          </code>
        </td>
        <td class="px-4 py-3 align-top">
          <span class="inline-flex rounded-full px-3 py-1 text-xs font-semibold ${statusClass}">
            ${current.status.replace("_", " ")}
          </span>
        </td>
        <td class="px-4 py-3 align-top">
          ${current.role === "admin" ? html`
            <span class="rounded-full bg-red-500/20 px-3 py-1 text-xs font-semibold text-red-200">
              Admin
            </span>
          ` : html`
            <span class="text-xs text-slate-300">User</span>
          `}
        </td>
        <td class="px-4 py-3 align-top">
          ${current.emailVerified ? html`
            <span class="text-emerald-300"></span>
          ` : html`
            <span class="text-slate-400"></span>
          `}
        </td>
        <td class="px-4 py-3 align-top text-xs text-slate-400">
          ${current.createdAt ? new Date(current.createdAt).toLocaleDateString() : "Unknown"}
        </td>
        <td class="px-4 py-3 align-top">
          <div class="flex flex-wrap justify-end gap-2">
            ${actions}
          </div>
        </td>
      </tr>
    `;
  });
  const content = html`
    <section class="mx-auto w-full max-w-7xl space-y-8 text-slate-100">
      <header class="flex flex-col gap-4 md:flex-row md:items-center md:justify-between">
        <div>
          <h1 class="text-3xl font-semibold text-white md:text-4xl">User Management</h1>
          <p class="mt-1 text-sm text-slate-300">
            Audit user accounts, toggle access, and elevate permissions.
          </p>
        </div>
        <a href="/admin" class="${headerSecondaryButtonClass}">
           Back to Dashboard
        </a>
      </header>

      ${users.length === 0 ? html`
        <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-10 text-center shadow-xl shadow-black/30 backdrop-blur">
          <p class="text-sm text-slate-300">
            No users found.
          </p>
        </div>
      ` : html`
        <div class="rounded-3xl border border-white/10 bg-white/[0.05] shadow-xl shadow-black/30 backdrop-blur">
          <div class="overflow-x-auto">
            <table class="min-w-full divide-y divide-white/10 text-left text-sm text-slate-200">
              <thead class="bg-white/[0.04] text-xs uppercase tracking-wide text-slate-400">
                <tr>
                  <th class="px-4 py-3 font-medium">Name</th>
                  <th class="px-4 py-3 font-medium">Email</th>
                  <th class="px-4 py-3 font-medium">Status</th>
                  <th class="px-4 py-3 font-medium">Role</th>
                  <th class="px-4 py-3 font-medium">Verified</th>
                  <th class="px-4 py-3 font-medium">Joined</th>
                  <th class="px-4 py-3 text-right font-medium">Actions</th>
                </tr>
              </thead>
              <tbody class="divide-y divide-white/10">
                ${tableRows}
              </tbody>
            </table>
          </div>
        </div>
      `}

      <div class="grid gap-6 sm:grid-cols-2 xl:grid-cols-4">
        ${summaryCards.map((card) => html`
          <div class="rounded-3xl border border-white/10 bg-gradient-to-br ${card.gradient} p-6 text-center shadow-xl shadow-black/30 backdrop-blur">
            <div class="text-xs uppercase tracking-wide text-white/80">${card.label}</div>
            <div class="mt-3 text-3xl font-semibold text-white">${card.value}</div>
          </div>
        `)}
      </div>
    </section>
  `;
  return BaseLayout({
    title: "User Management - Admin",
    content,
    config,
    user,
    error,
    success
  });
}

function AdminUserFormPage(props = {}) {
  const { editUser = {}, user = {}, error = null, config = {} } = props;
  const isCurrentUser = editUser.id === user.id;
  const inputClasses = [
    "block w-full rounded-2xl border border-white/10 bg-white/[0.08]",
    "px-4 py-2.5 text-sm text-white placeholder:text-slate-300/70",
    "shadow-[0_1px_0_rgba(255,255,255,0.05)] transition focus:border-white/40 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const checkboxClasses = [
    "h-4 w-4 rounded border-white/30 bg-slate-900/70 text-primary",
    "focus:ring-2 focus:ring-primary/40 focus:ring-offset-0 focus:outline-none"
  ].join(" ");
  const radioClasses = [
    "h-4 w-4 border-white/30 text-primary focus:ring-2 focus:ring-primary/40 focus:ring-offset-0 focus:outline-none"
  ].join(" ");
  const primaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-5 py-2.5 text-sm font-semibold text-white",
    "transition hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const secondaryButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-4 py-2.5 text-sm font-semibold text-white transition hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const dangerButtonClass = [
    "inline-flex items-center justify-center rounded-2xl border border-red-400/40 bg-red-500/10",
    "px-4 py-2.5 text-sm font-semibold text-red-100 transition hover:bg-red-500/15 focus:outline-none focus:ring-2 focus:ring-red-400/40"
  ].join(" ");
  const statusOptions = [
    {
      value: "active",
      title: "Active",
      description: "User can log in and access services."
    },
    {
      value: "suspended",
      title: "Suspended",
      description: "User cannot log in."
    },
    {
      value: "pending_verification",
      title: "Pending Verification",
      description: "Awaiting email verification."
    }
  ];
  const roleOptions = [
    {
      value: "user",
      title: "User",
      description: "Standard access to identity provider services."
    },
    {
      value: "admin",
      title: "Administrator",
      description: "Full administrative access."
    }
  ];
  const content = html`
    <section class="mx-auto w-full max-w-4xl space-y-8 text-slate-100">
      <header>
        <a href="/admin/users" class="text-sm font-semibold text-primary transition hover:text-white">
           Back to Users
        </a>
        <h1 class="mt-3 text-3xl font-semibold text-white md:text-4xl">
          Edit User: ${editUser.name}
        </h1>
        <p class="mt-2 text-sm text-slate-300">
          Update profile details, status, and permissions for this user.
        </p>
      </header>

      <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-8 shadow-xl shadow-black/30 backdrop-blur">
        <form method="POST" action="/admin/users/${editUser.id}/update" class="space-y-6">
          <div class="space-y-2">
            <label for="name" class="text-sm font-semibold text-slate-200">Full Name</label>
            <input
              type="text"
              class="${inputClasses} ${error ? "border-red-400/60 focus:border-red-400 focus:ring-red-400/40" : ""}"
              id="name"
              name="name"
              value="${editUser.name}"
              required
              autofocus
              placeholder="John Doe"
            />
            <p class="text-xs text-slate-400">User's display name.</p>
            ${error ? html`<p class="text-xs text-red-200">${error}</p>` : ""}
          </div>

          <div class="space-y-2">
            <label for="email" class="text-sm font-semibold text-slate-200">Email Address</label>
            <input
              type="email"
              class="${inputClasses}"
              id="email"
              name="email"
              value="${editUser.email}"
              required
              placeholder="user@example.com"
            />
            <p class="text-xs text-slate-400">Email address used for login and notifications.</p>
          </div>

          <div class="space-y-3">
            <span class="text-sm font-semibold text-slate-200">Account Status</span>
            <div class="grid gap-3">
              ${statusOptions.map((option) => html`
                <label class="flex items-start gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">
                  <input
                    type="radio"
                    class="${radioClasses} mt-1"
                    id="status_${option.value}"
                    name="status"
                    value="${option.value}"
                    ${editUser.status === option.value ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <span>
                    <strong class="text-white">${option.title}</strong><br>
                    <span class="text-xs text-slate-400">${option.description}</span>
                  </span>
                </label>
              `)}
            </div>
            ${isCurrentUser ? html`
              <p class="text-xs text-amber-300">You cannot change your own status.</p>
            ` : ""}
          </div>

          <div class="space-y-3">
            <span class="text-sm font-semibold text-slate-200">Role</span>
            <div class="grid gap-3">
              ${roleOptions.map((option) => html`
                <label class="flex items-start gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">
                  <input
                    type="radio"
                    class="${radioClasses} mt-1"
                    id="role_${option.value}"
                    name="role"
                    value="${option.value}"
                    ${editUser.role === option.value ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <span>
                    <strong class="text-white">${option.title}</strong><br>
                    <span class="text-xs text-slate-400">${option.description}</span>
                  </span>
                </label>
              `)}
            </div>
            ${isCurrentUser ? html`
              <p class="text-xs text-amber-300">You cannot change your own role.</p>
            ` : ""}
          </div>

          <label class="flex items-start gap-3 rounded-2xl border border-white/10 bg-white/[0.04] px-4 py-3 text-sm text-slate-200">
            <input
              type="checkbox"
              class="${checkboxClasses} mt-1"
              id="emailVerified"
              name="emailVerified"
              value="1"
              ${editUser.emailVerified ? "checked" : ""}
            />
            <span>
              <strong class="text-white">Email Verified</strong><br>
              <span class="text-xs text-slate-400">User has confirmed their email address.</span>
            </span>
          </label>

          <div class="flex flex-col gap-3 sm:flex-row sm:items-center sm:justify-start">
            <button type="submit" class="${primaryButtonClass} sm:w-auto" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
              Update User
            </button>
            <a href="/admin/users" class="${secondaryButtonClass}">
              Cancel
            </a>
          </div>
        </form>
      </div>

      <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
        <h2 class="text-lg font-semibold text-white">User Information</h2>
        <dl class="mt-4 divide-y divide-white/10 text-sm text-slate-200">
          <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
            <dt class="text-slate-400">User ID</dt>
            <dd>
              <code class="rounded-xl border border-white/10 bg-white/[0.08] px-3 py-1 text-xs text-slate-200">
                ${editUser.id}
              </code>
            </dd>
          </div>
          ${editUser.createdAt ? html`
            <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
              <dt class="text-slate-400">Joined</dt>
              <dd>${new Date(editUser.createdAt).toLocaleString()}</dd>
            </div>
          ` : ""}
          ${editUser.updatedAt ? html`
            <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
              <dt class="text-slate-400">Last Updated</dt>
              <dd>${new Date(editUser.updatedAt).toLocaleString()}</dd>
            </div>
          ` : ""}
          <div class="flex flex-col gap-1 py-3 sm:flex-row sm:items-center sm:justify-between">
            <dt class="text-slate-400">Last Login</dt>
            <dd>${editUser.lastLoginAt ? new Date(editUser.lastLoginAt).toLocaleString() : html`<span class="text-slate-400">Never</span>`}</dd>
          </div>
        </dl>
      </div>

      ${!isCurrentUser ? html`
        <div class="rounded-3xl border border-red-500/40 bg-red-500/5 shadow-xl shadow-black/30 backdrop-blur">
          <div class="rounded-t-3xl border-b border-red-500/40 bg-red-500/20 px-6 py-4 text-white">
            <h2 class="text-lg font-semibold">Danger Zone</h2>
          </div>
          <div class="space-y-6 px-6 py-6 text-sm text-slate-100">
            <div>
              <h3 class="text-base font-semibold text-white">Send Password Reset Email</h3>
              <p class="mt-2 text-xs text-red-100">
                Send a password reset link to ${editUser.email}.
              </p>
              <form method="POST" action="/admin/users/${editUser.id}/reset-password" onsubmit="return confirm('Send password reset email to ${editUser.email}?')">
                <button type="submit" class="${secondaryButtonClass} mt-3">
                   Send Password Reset
                </button>
              </form>
            </div>

            <div class="border-t border-red-500/30 pt-6">
              <h3 class="text-base font-semibold text-white">Delete User Account</h3>
              <p class="mt-2 text-xs text-red-100">
                Permanently delete this user account. This action cannot be undone.
              </p>
              <form method="POST" action="/admin/users/${editUser.id}/delete" onsubmit="return confirm('Are you sure you want to delete ${editUser.name}? This action cannot be undone.')">
                <button type="submit" class="${dangerButtonClass} mt-3">
                   Delete User
                </button>
              </form>
            </div>
          </div>
        </div>
      ` : ""}
    </section>
  `;
  return BaseLayout({
    title: `Edit User: ${editUser.name} - Admin`,
    content,
    config,
    user,
    error: null
    // Error shown in form
  });
}

const SCOPE_DESCRIPTIONS = {
  openid: {
    name: "OpenID Connect",
    description: "Sign in using your identity",
    icon: "\u{1F510}"
  },
  profile: {
    name: "Profile Information",
    description: "Access your basic profile information (name, picture)",
    icon: "\u{1F464}"
  },
  email: {
    name: "Email Address",
    description: "Access your email address",
    icon: "\u{1F4E7}"
  },
  offline_access: {
    name: "Offline Access",
    description: "Maintain access when you are not using the app",
    icon: "\u{1F504}"
  },
  phone: {
    name: "Phone Number",
    description: "Access your phone number",
    icon: "\u{1F4F1}"
  },
  address: {
    name: "Address",
    description: "Access your address information",
    icon: "\u{1F3E0}"
  }
};
function ConsentPage(props = {}) {
  const {
    client = {},
    scopes = [],
    user = {},
    responseType,
    redirectUri,
    state = "",
    codeChallenge = "",
    codeChallengeMethod = "plain",
    error = null,
    config = {}
  } = props;
  const scopeDetails = scopes.map((scope) => ({
    scope,
    ...SCOPE_DESCRIPTIONS[scope],
    unknown: !SCOPE_DESCRIPTIONS[scope]
  })).filter((s) => !s.unknown);
  const checkboxClasses = [
    "h-5 w-5 rounded border-white/30 bg-slate-900/70 text-primary",
    "focus:ring-2 focus:ring-primary/40 focus:ring-offset-0 focus:outline-none"
  ].join(" ");
  const primaryButtonClasses = [
    "inline-flex w-full items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-5 py-3 text-sm font-semibold text-white",
    "transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const secondaryButtonClasses = [
    "inline-flex w-full items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-5 py-3 text-sm font-semibold text-white transition duration-200 hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const content = html`
    <section class="mx-auto w-full max-w-5xl space-y-8 text-slate-100">
      <header class="space-y-4 text-center">
        ${config.logoUrl ? html`
          <div class="flex justify-center">
            <img src="${config.logoUrl}" alt="${config.title || "Identity Logo"}" class="h-14 w-auto" />
          </div>
        ` : ""}
        <div>
          <h1 class="text-3xl font-semibold text-white md:text-4xl">Authorize Application</h1>
          <p class="mt-2 text-sm text-slate-300 md:text-base">
            <span class="font-semibold text-white">${client.name || "Application"}</span>
            is requesting access to your account.
          </p>
        </div>
      </header>

      ${error ? html`
        <div class="rounded-2xl border border-red-400/40 bg-red-500/10 px-4 py-3 text-sm leading-6 text-red-100 shadow-md shadow-red-900/30">
          ${error}
        </div>
      ` : ""}

      <div class="grid gap-6 lg:grid-cols-[1.1fr_0.9fr]">
        <div class="space-y-6">
          <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
            <h2 class="text-lg font-semibold text-white">Application Information</h2>
            <dl class="mt-4 space-y-4 text-sm text-slate-200">
              <div class="flex flex-col gap-1">
                <dt class="text-xs uppercase tracking-wide text-slate-400">Application Name</dt>
                <dd class="text-base font-semibold text-white">${client.name || "Unknown Application"}</dd>
              </div>

              ${client.description ? html`
                <div class="flex flex-col gap-1">
                  <dt class="text-xs uppercase tracking-wide text-slate-400">Description</dt>
                  <dd>${client.description}</dd>
                </div>
              ` : ""}

              <div class="flex flex-col gap-1">
                <dt class="text-xs uppercase tracking-wide text-slate-400">Client ID</dt>
                <dd>
                  <code class="rounded-xl border border-white/10 bg-white/[0.08] px-3 py-2 text-xs text-slate-200">
                    ${client.clientId}
                  </code>
                </dd>
              </div>

              <div class="flex flex-col gap-1">
                <dt class="text-xs uppercase tracking-wide text-slate-400">Will Redirect To</dt>
                <dd>
                  <code class="rounded-xl border border-white/10 bg-white/[0.08] px-3 py-2 text-xs text-slate-200">
                    ${redirectUri}
                  </code>
                </dd>
              </div>
            </dl>
          </div>

          <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
            <h2 class="text-lg font-semibold text-white">Requested Permissions</h2>
            <div class="mt-4 space-y-4">
              ${scopeDetails.length === 0 ? html`
                <p class="text-sm italic text-slate-300">
                  This application is not requesting any specific permissions.
                </p>
              ` : scopeDetails.map((s) => html`
                <div class="flex gap-4 rounded-2xl border border-white/5 bg-white/[0.03] p-4">
                  <div class="text-3xl leading-none">${s.icon}</div>
                  <div class="space-y-1">
                    <div class="text-sm font-semibold text-white">${s.name}</div>
                    <p class="text-xs text-slate-300">${s.description}</p>
                  </div>
                </div>
              `)}
            </div>
          </div>
        </div>

        <div class="space-y-6">
          <div class="rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
            <div class="flex gap-4">
              <div class="text-2xl"></div>
              <div class="space-y-3 text-sm text-slate-200">
                <p class="text-base font-semibold text-white">
                  Signed in as ${user.name}
                </p>
                <p>
                  By clicking <strong>Allow</strong>, you authorize
                  <strong>${client.name || "this application"}</strong> to access your information as described above.
                </p>
                <p>
                  You can revoke this access at any time from your
                  <a href="/profile" class="font-semibold text-primary transition hover:text-white">profile settings</a>.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <form method="POST" action="/oauth/consent" class="space-y-6 rounded-3xl border border-white/10 bg-white/[0.05] p-6 shadow-xl shadow-black/30 backdrop-blur">
        <input type="hidden" name="response_type" value="${responseType}" />
        <input type="hidden" name="client_id" value="${client.clientId}" />
        <input type="hidden" name="redirect_uri" value="${redirectUri}" />
        <input type="hidden" name="scope" value="${scopes.join(" ")}" />
        ${state ? html`<input type="hidden" name="state" value="${state}" />` : ""}
        ${codeChallenge ? html`<input type="hidden" name="code_challenge" value="${codeChallenge}" />` : ""}
        ${codeChallengeMethod ? html`<input type="hidden" name="code_challenge_method" value="${codeChallengeMethod}" />` : ""}

        <label class="flex items-start gap-3 text-sm text-slate-300">
          <input
            type="checkbox"
            class="${checkboxClasses} mt-0.5"
            id="trust_application"
            name="trust_application"
            value="1"
          />
          <span>
            Trust this application (don't ask again)<br>
            <span class="text-xs text-slate-400">
              You won't be asked for permission next time this application requests access with the same permissions.
            </span>
          </span>
        </label>

        <div class="grid gap-3 sm:grid-cols-2">
          <button
            type="submit"
            name="decision"
            value="deny"
            class="${secondaryButtonClasses}"
          >
            Deny
          </button>
          <button
            type="submit"
            name="decision"
            value="allow"
            class="${primaryButtonClasses}"
            style="box-shadow: 0 18px 45px var(--color-primary-glow);"
          >
            Allow
          </button>
        </div>
      </form>

      <p class="text-center text-sm text-slate-300">
        Not ${user.name}? <a href="/logout" class="font-semibold text-primary transition hover:text-white">Sign out</a>
      </p>
    </section>
  `;
  return BaseLayout({
    title: `Authorize ${client.name || "Application"}`,
    content,
    config,
    user,
    error: null
    // Error shown in page
  });
}

function VerifyEmailPage(props = {}) {
  const { status = "pending", email = "", message = "", config = {} } = props;
  const statusConfig = {
    success: {
      icon: "\u2705",
      title: "Email Verified!",
      color: "var(--color-success)",
      defaultMessage: "Your email address has been successfully verified."
    },
    error: {
      icon: "\u274C",
      title: "Verification Failed",
      color: "var(--color-danger)",
      defaultMessage: "The verification link is invalid or has already been used."
    },
    expired: {
      icon: "\u23F0",
      title: "Link Expired",
      color: "var(--color-warning)",
      defaultMessage: "This verification link has expired. Please request a new one."
    },
    pending: {
      icon: "\u{1F4E7}",
      title: "Verify Your Email",
      color: "var(--color-primary)",
      defaultMessage: "Please check your email for a verification link."
    }
  };
  const currentStatus = statusConfig[status] || statusConfig.pending;
  const displayMessage = message || currentStatus.defaultMessage;
  const primaryButtonClasses = [
    "inline-flex items-center justify-center rounded-2xl bg-gradient-to-r",
    "from-primary via-primary to-secondary px-6 py-3 text-sm font-semibold text-white",
    "transition duration-200 hover:-translate-y-0.5 focus:outline-none focus:ring-2 focus:ring-white/30"
  ].join(" ");
  const secondaryButtonClasses = [
    "inline-flex items-center justify-center rounded-2xl border border-white/15 bg-white/[0.06]",
    "px-6 py-3 text-sm font-semibold text-white transition duration-200 hover:bg-white/[0.12]",
    "focus:outline-none focus:ring-2 focus:ring-white/20"
  ].join(" ");
  const content = html`
    <section class="mx-auto w-full max-w-3xl text-slate-100">
      <div class="flex flex-col items-center gap-4 pb-8 text-center">
        ${config.logoUrl ? html`
          <img src="${config.logoUrl}" alt="${config.title || "Identity Logo"}" class="h-14 w-auto" />
        ` : ""}
        <h1 class="text-3xl font-semibold tracking-tight text-white md:text-4xl">
          ${currentStatus.title}
        </h1>
      </div>

      <div class="relative isolate overflow-hidden rounded-3xl border border-white/10 bg-slate-900/60 px-10 py-12 text-center shadow-2xl shadow-slate-900/60 backdrop-blur">
        <div class="pointer-events-none absolute -left-24 top-10 h-64 w-64 rounded-full bg-primary/25 blur-3xl"></div>
        <div class="pointer-events-none absolute -right-16 -top-20 h-56 w-56 rounded-full bg-secondary/25 blur-[120px]"></div>

        <div class="relative z-10 space-y-8">
          <div class="mx-auto flex h-20 w-20 items-center justify-center rounded-full border border-white/10 bg-white/[0.08] text-4xl">
            ${currentStatus.icon}
          </div>

          <p class="text-base text-slate-200 md:text-lg" style="color: ${currentStatus.color};">
            ${displayMessage}
          </p>

          ${status === "success" ? html`
            <div class="space-y-4">
              <a href="/login" class="${primaryButtonClasses}" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
                Sign In
              </a>
              <div class="text-sm text-slate-300">
                <a href="/profile" class="font-semibold text-primary transition hover:text-white">
                  Go to your profile
                </a>
              </div>
            </div>
          ` : status === "error" || status === "expired" ? html`
            <div class="space-y-6">
              ${email ? html`
                <form method="POST" action="/verify-email/resend">
                  <input type="hidden" name="email" value="${email}" />
                  <button type="submit" class="${primaryButtonClasses}" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
                    Send New Verification Email
                  </button>
                </form>
              ` : html`
                <a href="/login" class="${primaryButtonClasses}" style="box-shadow: 0 18px 45px var(--color-primary-glow);">
                  Sign In to Resend
                </a>
              `}
              <div class="text-sm text-slate-300">
                <a href="/login" class="font-semibold text-primary transition hover:text-white">
                  Sign in
                </a>
              </div>
            </div>
          ` : html`
            <div class="space-y-6">
              <div class="rounded-2xl border border-white/10 bg-white/[0.06] px-6 py-5 text-left text-sm text-slate-200">
                <p class="mb-2 font-semibold text-white/90">
                  Didn't receive the email?
                </p>
                <ul class="list-disc space-y-1 pl-5 text-slate-300">
                  <li>Check your spam or junk folder</li>
                  <li>Make sure the email address is correct</li>
                  <li>Wait a few minutes and check again</li>
                </ul>
              </div>

              ${email ? html`
                <form method="POST" action="/verify-email/resend">
                  <input type="hidden" name="email" value="${email}" />
                  <button type="submit" class="${secondaryButtonClasses}">
                    Resend Verification Email
                  </button>
                </form>
              ` : html`
                <a href="/login" class="${secondaryButtonClasses}">
                  Sign In to Resend
                </a>
              `}

              <div class="text-sm text-slate-300">
                <a href="/login" class="font-semibold text-primary transition hover:text-white">
                  Back to sign in
                </a>
              </div>
            </div>
          `}
        </div>
      </div>

      ${status === "success" ? html`
        <div class="mt-6 rounded-2xl border border-emerald-400/40 bg-emerald-500/10 px-6 py-5 text-center text-sm leading-6 text-emerald-100 shadow-lg shadow-emerald-900/30">
          <strong>Your account is now fully activated!</strong><br>
          You can now access all features and services.
        </div>
      ` : ""}
    </section>
  `;
  return BaseLayout({
    title: currentStatus.title,
    content,
    config,
    user: null,
    error: null,
    success: null
  });
}

var __freeze$2 = Object.freeze;
var __defProp$2 = Object.defineProperty;
var __template$2 = (cooked, raw) => __freeze$2(__defProp$2(cooked, "raw", { value: __freeze$2(cooked.slice()) }));
var _a$2;
function MFAVerificationPage(props = {}) {
  const {
    error = null,
    email = "",
    remember = "0",
    challenge,
    config = {}
  } = props;
  const rememberValue = remember === "1" ? "1" : "0";
  const content = html(_a$2 || (_a$2 = __template$2(['\n    <section class="identity-login">\n      <!-- Left panel with branding -->\n      <aside class="identity-login__panel">\n        <div class="identity-login__panel-content">\n          <div class="identity-login__brand">\n            ', '\n            <span class="identity-login__badge">\n              Identity\n            </span>\n          </div>\n\n          <div class="identity-login__panel-main">\n            <h1 class="identity-login__panel-title">\u{1F510} Two-Factor Authentication</h1>\n            <p class="identity-login__panel-text">\n              An extra layer of security to keep your account safe.\n            </p>\n          </div>\n        </div>\n\n        <footer class="identity-login__panel-footer">\n          ', '\n        </footer>\n      </aside>\n\n      <!-- Right form area -->\n      <div class="identity-login__form">\n        <header class="identity-login__form-header">\n          <h2>Verify Your Identity</h2>\n          <p>Enter the 6-digit code from your authenticator app.</p>\n          ', "\n        </header>\n\n        ", '\n\n        <!-- TOTP Token Form -->\n        <form method="POST" action="/login" class="identity-login__form-body" id="mfa-form">\n\n          <div class="identity-login__group">\n            <label for="mfa_token">Verification Code</label>\n            <input\n              type="text"\n              class="identity-login__input text-center text-2xl tracking-widest"\n              id="mfa_token"\n              name="mfa_token"\n              pattern="[0-9]{6}"\n              maxlength="6"\n              inputmode="numeric"\n              autocomplete="one-time-code"\n              placeholder="000000"\n              required\n              autofocus\n            />\n            <p class="mt-2 text-sm text-slate-400">\n              The code refreshes every 30 seconds\n            </p>\n          </div>\n          <input type="hidden" name="email" value="', '" />\n          <input type="hidden" name="remember" value="', '" />\n          <input type="hidden" name="mfa_challenge" value="', '" />\n\n          <button type="submit" class="identity-login__submit">\n            Verify\n          </button>\n        </form>\n\n        <!-- Backup Code Link -->\n        <div class="identity-login__divider"><span>or</span></div>\n\n        <button\n          type="button"\n          onclick="showBackupCodeForm()"\n          class="w-full rounded-xl border border-slate-700/50 bg-slate-800/30 px-4 py-3 text-sm font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n        >\n          Lost your device? Use backup code\n        </button>\n\n        <!-- Backup Code Form (hidden by default) -->\n        <form method="POST" action="/login" class="identity-login__form-body mt-6 hidden" id="backup-code-form">\n          <input type="hidden" name="email" value="', '" />\n          <input type="hidden" name="remember" value="', '" />\n          <input type="hidden" name="mfa_challenge" value="', `" />

          <div class="identity-login__group">
            <label for="backup_code">Backup Code</label>
            <input
              type="text"
              class="identity-login__input text-center uppercase tracking-wider"
              id="backup_code"
              name="backup_code"
              maxlength="16"
              autocomplete="off"
              placeholder="XXXXXXXX"
              style="text-transform: uppercase;"
            />
            <p class="mt-2 text-sm text-slate-400">
              Enter one of your 8-character backup codes
            </p>
          </div>

          <button type="submit" class="identity-login__submit">
            Verify with Backup Code
          </button>

          <button
            type="button"
            onclick="showMFAForm()"
            class="mt-3 w-full rounded-xl border border-slate-700/50 bg-transparent px-4 py-3 text-sm font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/30"
          >
            \u2190 Back to authenticator
          </button>
        </form>

        <!-- Back to Login Link -->
        <p class="identity-login__meta mt-6">
          <a href="/login">\u2190 Back to login</a>
        </p>
      </div>
    </section>

    <script>
      function showBackupCodeForm() {
        document.getElementById('mfa-form').classList.add('hidden');
        document.getElementById('backup-code-form').classList.remove('hidden');
        document.getElementById('backup_code').focus();
      }

      function showMFAForm() {
        document.getElementById('mfa-form').classList.remove('hidden');
        document.getElementById('backup-code-form').classList.add('hidden');
        document.getElementById('mfa_token').focus();
      }
    <\/script>
  `])), config.logoUrl ? html`
              <img src="${config.logoUrl}" alt="${config.title || "Identity Logo"}" class="identity-login__brand-logo" />
            ` : "", config.footerText || `\xA9 ${(/* @__PURE__ */ new Date()).getFullYear()} ${config.legalName || config.companyName || "S3DB Corp"} \u2022 All rights reserved`, email ? html`<p class="identity-login__meta text-sm text-slate-400 mt-2">Signing in as <strong>${email}</strong></p>` : "", error ? html`
          <div class="identity-login__alert identity-login__alert--error">
            ${error}
          </div>
        ` : "", email, rememberValue, challenge, email, rememberValue, challenge);
  return BaseLayout({
    title: "Two-Factor Authentication",
    content,
    config,
    error: null,
    // Error shown in form
    success: null
  });
}

var __freeze$1 = Object.freeze;
var __defProp$1 = Object.defineProperty;
var __template$1 = (cooked, raw) => __freeze$1(__defProp$1(cooked, "raw", { value: __freeze$1(raw || cooked.slice()) }));
var _a$1;
function MFAEnrollmentPage(props = {}) {
  const { qrCodeDataUrl, secret, backupCodes = [], config = {} } = props;
  const content = html(_a$1 || (_a$1 = __template$1(['\n    <div class="mx-auto w-full max-w-2xl px-4 py-12">\n      <div class="rounded-3xl border border-slate-700/50 bg-slate-900/50 p-8 shadow-2xl backdrop-blur-xl md:p-12">\n        <!-- Header -->\n        <div class="mb-8 text-center">\n          <div class="mb-4 inline-flex h-16 w-16 items-center justify-center rounded-2xl bg-gradient-to-br from-blue-500 to-purple-600 text-3xl shadow-lg shadow-blue-500/30">\n            \u{1F510}\n          </div>\n          <h1 class="mb-2 text-3xl font-bold text-white">\n            Enable Two-Factor Authentication\n          </h1>\n          <p class="text-slate-400">\n            Scan the QR code below with your authenticator app\n          </p>\n        </div>\n\n        <!-- QR Code Section -->\n        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">\n          <h2 class="mb-4 text-center text-lg font-semibold text-white">\n            Step 1: Scan QR Code\n          </h2>\n\n          <div class="mb-4 flex justify-center">\n            <div class="rounded-2xl border-4 border-white bg-white p-4">\n              <img src="', `" alt="QR Code" class="h-64 w-64" />
            </div>
          </div>

          <p class="text-center text-sm text-slate-400">
            Use Google Authenticator, Authy, Microsoft Authenticator,<br/>
            1Password, or any TOTP-compatible app
          </p>
        </div>

        <!-- Manual Entry Section -->
        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
          <h2 class="mb-3 text-center text-lg font-semibold text-white">
            Can't scan? Enter manually
          </h2>

          <div class="rounded-xl bg-slate-900/50 px-4 py-3">
            <code class="block text-center font-mono text-lg tracking-wider text-blue-400">
              `, '\n            </code>\n          </div>\n\n          <p class="mt-3 text-center text-sm text-slate-400">\n            Copy this key into your authenticator app\n          </p>\n        </div>\n\n        <!-- Backup Codes Section -->\n        <div class="mb-8 rounded-2xl border border-amber-500/30 bg-amber-500/10 p-6">\n          <div class="mb-4 flex items-start gap-3">\n            <div class="flex h-10 w-10 flex-shrink-0 items-center justify-center rounded-xl bg-amber-500/20 text-xl">\n              \u26A0\uFE0F\n            </div>\n            <div>\n              <h2 class="mb-1 text-lg font-semibold text-amber-200">\n                Save These Backup Codes\n              </h2>\n              <p class="text-sm text-amber-300/80">\n                You can use these codes to access your account if you lose your authenticator device. Each code can only be used once.\n              </p>\n            </div>\n          </div>\n\n          <div class="mb-4 grid grid-cols-2 gap-3">\n            ', '\n          </div>\n\n          <button\n            type="button"\n            onclick="downloadBackupCodes()"\n            class="w-full rounded-xl border border-amber-500/50 bg-amber-500/20 px-4 py-3 font-medium text-amber-200 transition-all hover:border-amber-500/70 hover:bg-amber-500/30"\n          >\n            \u{1F4BE} Download Backup Codes\n          </button>\n        </div>\n\n        <!-- Verification Form -->\n        <form method="POST" action="/profile/mfa/enroll" class="space-y-4">\n          <input type="hidden" name="enrollment_secret" value="', '" />\n          <input type="hidden" name="enrollment_backup_codes" value="', '" />\n\n          <div>\n            <label for="token" class="mb-2 block text-center text-lg font-semibold text-white">\n              Step 2: Verify Setup\n            </label>\n            <p class="mb-3 text-center text-sm text-slate-400">\n              Enter the 6-digit code from your authenticator app\n            </p>\n            <input\n              type="text"\n              id="token"\n              name="token"\n              pattern="[0-9]{6}"\n              maxlength="6"\n              inputmode="numeric"\n              autocomplete="one-time-code"\n              placeholder="000000"\n              required\n              autofocus\n              class="w-full rounded-xl border border-slate-700/50 bg-slate-800/50 px-6 py-4 text-center text-2xl tracking-widest text-white placeholder-slate-500 outline-none transition-all focus:border-blue-500/50 focus:bg-slate-800/70 focus:ring-4 focus:ring-blue-500/20"\n            />\n          </div>\n\n          <div class="flex gap-3">\n            <button\n              type="submit"\n              class="flex-1 rounded-xl bg-gradient-to-r from-blue-600 to-purple-600 px-6 py-3.5 font-semibold text-white shadow-lg shadow-blue-500/30 transition-all hover:shadow-xl hover:shadow-blue-500/40"\n            >\n              \u2713 Verify and Enable MFA\n            </button>\n            <a\n              href="/profile"\n              class="flex items-center justify-center rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n            >\n              Cancel\n            </a>\n          </div>\n        </form>\n\n        <!-- Help Text -->\n        <p class="mt-6 text-center text-sm text-slate-500">\n          Need help? Check our <a href="#" class="text-blue-400 hover:text-blue-300">MFA setup guide</a>\n        </p>\n      </div>\n    </div>\n\n    <script>\n      function downloadBackupCodes() {\n        const codes = ', ";\n        const title = '", "';\n        const text = 'MFA Backup Codes - ' + title + '\\n\\n' +\n                     'Generated: ' + new Date().toISOString() + '\\n\\n' +\n                     codes.join('\\n') + '\\n\\n' +\n                     '\u26A0\uFE0F  IMPORTANT:\\n' +\n                     '- Keep these codes in a safe place\\n' +\n                     '- Each code can only be used once\\n' +\n                     '- You can regenerate codes anytime from your profile\\n';\n\n        const blob = new Blob([text], { type: 'text/plain' });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement('a');\n        a.href = url;\n        a.download = 'mfa-backup-codes-' + new Date().toISOString().split('T')[0] + '.txt';\n        a.click();\n        URL.revokeObjectURL(url);\n      }\n    <\/script>\n  "], ['\n    <div class="mx-auto w-full max-w-2xl px-4 py-12">\n      <div class="rounded-3xl border border-slate-700/50 bg-slate-900/50 p-8 shadow-2xl backdrop-blur-xl md:p-12">\n        <!-- Header -->\n        <div class="mb-8 text-center">\n          <div class="mb-4 inline-flex h-16 w-16 items-center justify-center rounded-2xl bg-gradient-to-br from-blue-500 to-purple-600 text-3xl shadow-lg shadow-blue-500/30">\n            \u{1F510}\n          </div>\n          <h1 class="mb-2 text-3xl font-bold text-white">\n            Enable Two-Factor Authentication\n          </h1>\n          <p class="text-slate-400">\n            Scan the QR code below with your authenticator app\n          </p>\n        </div>\n\n        <!-- QR Code Section -->\n        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">\n          <h2 class="mb-4 text-center text-lg font-semibold text-white">\n            Step 1: Scan QR Code\n          </h2>\n\n          <div class="mb-4 flex justify-center">\n            <div class="rounded-2xl border-4 border-white bg-white p-4">\n              <img src="', `" alt="QR Code" class="h-64 w-64" />
            </div>
          </div>

          <p class="text-center text-sm text-slate-400">
            Use Google Authenticator, Authy, Microsoft Authenticator,<br/>
            1Password, or any TOTP-compatible app
          </p>
        </div>

        <!-- Manual Entry Section -->
        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
          <h2 class="mb-3 text-center text-lg font-semibold text-white">
            Can't scan? Enter manually
          </h2>

          <div class="rounded-xl bg-slate-900/50 px-4 py-3">
            <code class="block text-center font-mono text-lg tracking-wider text-blue-400">
              `, '\n            </code>\n          </div>\n\n          <p class="mt-3 text-center text-sm text-slate-400">\n            Copy this key into your authenticator app\n          </p>\n        </div>\n\n        <!-- Backup Codes Section -->\n        <div class="mb-8 rounded-2xl border border-amber-500/30 bg-amber-500/10 p-6">\n          <div class="mb-4 flex items-start gap-3">\n            <div class="flex h-10 w-10 flex-shrink-0 items-center justify-center rounded-xl bg-amber-500/20 text-xl">\n              \u26A0\uFE0F\n            </div>\n            <div>\n              <h2 class="mb-1 text-lg font-semibold text-amber-200">\n                Save These Backup Codes\n              </h2>\n              <p class="text-sm text-amber-300/80">\n                You can use these codes to access your account if you lose your authenticator device. Each code can only be used once.\n              </p>\n            </div>\n          </div>\n\n          <div class="mb-4 grid grid-cols-2 gap-3">\n            ', '\n          </div>\n\n          <button\n            type="button"\n            onclick="downloadBackupCodes()"\n            class="w-full rounded-xl border border-amber-500/50 bg-amber-500/20 px-4 py-3 font-medium text-amber-200 transition-all hover:border-amber-500/70 hover:bg-amber-500/30"\n          >\n            \u{1F4BE} Download Backup Codes\n          </button>\n        </div>\n\n        <!-- Verification Form -->\n        <form method="POST" action="/profile/mfa/enroll" class="space-y-4">\n          <input type="hidden" name="enrollment_secret" value="', '" />\n          <input type="hidden" name="enrollment_backup_codes" value="', '" />\n\n          <div>\n            <label for="token" class="mb-2 block text-center text-lg font-semibold text-white">\n              Step 2: Verify Setup\n            </label>\n            <p class="mb-3 text-center text-sm text-slate-400">\n              Enter the 6-digit code from your authenticator app\n            </p>\n            <input\n              type="text"\n              id="token"\n              name="token"\n              pattern="[0-9]{6}"\n              maxlength="6"\n              inputmode="numeric"\n              autocomplete="one-time-code"\n              placeholder="000000"\n              required\n              autofocus\n              class="w-full rounded-xl border border-slate-700/50 bg-slate-800/50 px-6 py-4 text-center text-2xl tracking-widest text-white placeholder-slate-500 outline-none transition-all focus:border-blue-500/50 focus:bg-slate-800/70 focus:ring-4 focus:ring-blue-500/20"\n            />\n          </div>\n\n          <div class="flex gap-3">\n            <button\n              type="submit"\n              class="flex-1 rounded-xl bg-gradient-to-r from-blue-600 to-purple-600 px-6 py-3.5 font-semibold text-white shadow-lg shadow-blue-500/30 transition-all hover:shadow-xl hover:shadow-blue-500/40"\n            >\n              \u2713 Verify and Enable MFA\n            </button>\n            <a\n              href="/profile"\n              class="flex items-center justify-center rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n            >\n              Cancel\n            </a>\n          </div>\n        </form>\n\n        <!-- Help Text -->\n        <p class="mt-6 text-center text-sm text-slate-500">\n          Need help? Check our <a href="#" class="text-blue-400 hover:text-blue-300">MFA setup guide</a>\n        </p>\n      </div>\n    </div>\n\n    <script>\n      function downloadBackupCodes() {\n        const codes = ', ";\n        const title = '", "';\n        const text = 'MFA Backup Codes - ' + title + '\\\\n\\\\n' +\n                     'Generated: ' + new Date().toISOString() + '\\\\n\\\\n' +\n                     codes.join('\\\\n') + '\\\\n\\\\n' +\n                     '\u26A0\uFE0F  IMPORTANT:\\\\n' +\n                     '- Keep these codes in a safe place\\\\n' +\n                     '- Each code can only be used once\\\\n' +\n                     '- You can regenerate codes anytime from your profile\\\\n';\n\n        const blob = new Blob([text], { type: 'text/plain' });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement('a');\n        a.href = url;\n        a.download = 'mfa-backup-codes-' + new Date().toISOString().split('T')[0] + '.txt';\n        a.click();\n        URL.revokeObjectURL(url);\n      }\n    <\/script>\n  "])), qrCodeDataUrl, secret, backupCodes.map((code) => html`
              <div class="rounded-lg bg-slate-900/50 px-4 py-2 text-center">
                <code class="font-mono text-sm text-slate-200">${code}</code>
              </div>
            `), secret, JSON.stringify(backupCodes), JSON.stringify(backupCodes), config.title || "S3DB Identity");
  return BaseLayout({
    title: "Enable Two-Factor Authentication",
    content,
    config,
    error: null,
    success: null
  });
}

var __freeze = Object.freeze;
var __defProp = Object.defineProperty;
var __template = (cooked, raw) => __freeze(__defProp(cooked, "raw", { value: __freeze(raw || cooked.slice()) }));
var _a;
function MFABackupCodesPage(props = {}) {
  const { backupCodes = [], config = {} } = props;
  const content = html(_a || (_a = __template([`
    <div class="mx-auto w-full max-w-2xl px-4 py-12">
      <div class="rounded-3xl border border-slate-700/50 bg-slate-900/50 p-8 shadow-2xl backdrop-blur-xl md:p-12">
        <!-- Header -->
        <div class="mb-8 text-center">
          <div class="mb-4 inline-flex h-16 w-16 items-center justify-center rounded-2xl bg-gradient-to-br from-emerald-500 to-teal-600 text-3xl shadow-lg shadow-emerald-500/30">
            \u2705
          </div>
          <h1 class="mb-2 text-3xl font-bold text-white">
            New Backup Codes Generated
          </h1>
          <p class="text-slate-400">
            Your old backup codes have been invalidated
          </p>
        </div>

        <!-- Warning Section -->
        <div class="mb-8 rounded-2xl border border-amber-500/30 bg-amber-500/10 p-6">
          <div class="flex items-start gap-3">
            <div class="flex h-10 w-10 flex-shrink-0 items-center justify-center rounded-xl bg-amber-500/20 text-xl">
              \u26A0\uFE0F
            </div>
            <div>
              <h2 class="mb-1 text-lg font-semibold text-amber-200">
                Important: Save These Codes
              </h2>
              <p class="text-sm text-amber-300/80">
                These codes replace your previous backup codes. Save them in a secure location now - you won't be able to see them again.
              </p>
            </div>
          </div>
        </div>

        <!-- Backup Codes Grid -->
        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
          <h2 class="mb-4 text-center text-lg font-semibold text-white">
            Your New Backup Codes
          </h2>

          <div class="mb-6 grid grid-cols-2 gap-3">
            `, '\n          </div>\n\n          <div class="space-y-3">\n            <button\n              type="button"\n              onclick="downloadBackupCodes()"\n              class="w-full rounded-xl bg-gradient-to-r from-blue-600 to-purple-600 px-6 py-3.5 font-semibold text-white shadow-lg shadow-blue-500/30 transition-all hover:shadow-xl hover:shadow-blue-500/40"\n            >\n              \u{1F4BE} Download Backup Codes\n            </button>\n\n            <button\n              type="button"\n              onclick="copyAllCodes()"\n              class="w-full rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n              id="copy-button"\n            >\n              \u{1F4CB} Copy to Clipboard\n            </button>\n          </div>\n        </div>\n\n        <!-- Instructions -->\n        <div class="mb-8 rounded-2xl border border-blue-500/30 bg-blue-500/10 p-6">\n          <h3 class="mb-3 text-lg font-semibold text-blue-200">\n            How to Use Backup Codes\n          </h3>\n          <ul class="space-y-2 text-sm text-blue-300/80">\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Each code can only be used once for login</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Use them if you lose access to your authenticator app</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Store them in a secure password manager like 1Password</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>You can regenerate codes anytime from your profile</span>\n            </li>\n          </ul>\n        </div>\n\n        <!-- Actions -->\n        <div class="flex gap-3">\n          <a\n            href="/profile"\n            class="flex-1 rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 text-center font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n          >\n            \u2190 Back to Profile\n          </a>\n        </div>\n\n        <!-- Footer Warning -->\n        <div class="mt-6 rounded-xl border border-red-500/30 bg-red-500/10 px-4 py-3">\n          <p class="text-center text-sm text-red-300">\n            \u26A0\uFE0F Your previous backup codes are no longer valid\n          </p>\n        </div>\n      </div>\n    </div>\n\n    <script>\n      const codes = ', ";\n      const title = '", "';\n\n      function downloadBackupCodes() {\n        const text = 'MFA Backup Codes - ' + title + '\\n\\n' +\n                     'Generated: ' + new Date().toISOString() + '\\n\\n' +\n                     codes.join('\\n') + '\\n\\n' +\n                     '\u26A0\uFE0F  IMPORTANT:\\n' +\n                     '- Keep these codes in a safe place\\n' +\n                     '- Each code can only be used once\\n' +\n                     '- Previous backup codes are now invalid\\n' +\n                     '- You can regenerate codes anytime from your profile\\n';\n\n        const blob = new Blob([text], { type: 'text/plain' });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement('a');\n        a.href = url;\n        a.download = 'mfa-backup-codes-' + new Date().toISOString().split('T')[0] + '.txt';\n        a.click();\n        URL.revokeObjectURL(url);\n      }\n\n      function copyAllCodes() {\n        const text = codes.join('\\n');\n        navigator.clipboard.writeText(text).then(() => {\n          const button = document.getElementById('copy-button');\n          const originalText = button.innerHTML;\n          button.innerHTML = '\u2713 Copied to Clipboard!';\n          button.classList.add('bg-emerald-500/20', 'border-emerald-500/50', 'text-emerald-300');\n          setTimeout(() => {\n            button.innerHTML = originalText;\n            button.classList.remove('bg-emerald-500/20', 'border-emerald-500/50', 'text-emerald-300');\n          }, 2000);\n        }).catch(err => {\n          alert('Failed to copy codes. Please download them instead.');\n        });\n      }\n    <\/script>\n  "], [`
    <div class="mx-auto w-full max-w-2xl px-4 py-12">
      <div class="rounded-3xl border border-slate-700/50 bg-slate-900/50 p-8 shadow-2xl backdrop-blur-xl md:p-12">
        <!-- Header -->
        <div class="mb-8 text-center">
          <div class="mb-4 inline-flex h-16 w-16 items-center justify-center rounded-2xl bg-gradient-to-br from-emerald-500 to-teal-600 text-3xl shadow-lg shadow-emerald-500/30">
            \u2705
          </div>
          <h1 class="mb-2 text-3xl font-bold text-white">
            New Backup Codes Generated
          </h1>
          <p class="text-slate-400">
            Your old backup codes have been invalidated
          </p>
        </div>

        <!-- Warning Section -->
        <div class="mb-8 rounded-2xl border border-amber-500/30 bg-amber-500/10 p-6">
          <div class="flex items-start gap-3">
            <div class="flex h-10 w-10 flex-shrink-0 items-center justify-center rounded-xl bg-amber-500/20 text-xl">
              \u26A0\uFE0F
            </div>
            <div>
              <h2 class="mb-1 text-lg font-semibold text-amber-200">
                Important: Save These Codes
              </h2>
              <p class="text-sm text-amber-300/80">
                These codes replace your previous backup codes. Save them in a secure location now - you won't be able to see them again.
              </p>
            </div>
          </div>
        </div>

        <!-- Backup Codes Grid -->
        <div class="mb-8 rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
          <h2 class="mb-4 text-center text-lg font-semibold text-white">
            Your New Backup Codes
          </h2>

          <div class="mb-6 grid grid-cols-2 gap-3">
            `, '\n          </div>\n\n          <div class="space-y-3">\n            <button\n              type="button"\n              onclick="downloadBackupCodes()"\n              class="w-full rounded-xl bg-gradient-to-r from-blue-600 to-purple-600 px-6 py-3.5 font-semibold text-white shadow-lg shadow-blue-500/30 transition-all hover:shadow-xl hover:shadow-blue-500/40"\n            >\n              \u{1F4BE} Download Backup Codes\n            </button>\n\n            <button\n              type="button"\n              onclick="copyAllCodes()"\n              class="w-full rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n              id="copy-button"\n            >\n              \u{1F4CB} Copy to Clipboard\n            </button>\n          </div>\n        </div>\n\n        <!-- Instructions -->\n        <div class="mb-8 rounded-2xl border border-blue-500/30 bg-blue-500/10 p-6">\n          <h3 class="mb-3 text-lg font-semibold text-blue-200">\n            How to Use Backup Codes\n          </h3>\n          <ul class="space-y-2 text-sm text-blue-300/80">\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Each code can only be used once for login</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Use them if you lose access to your authenticator app</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>Store them in a secure password manager like 1Password</span>\n            </li>\n            <li class="flex items-start gap-2">\n              <span class="mt-0.5 flex-shrink-0">\u2022</span>\n              <span>You can regenerate codes anytime from your profile</span>\n            </li>\n          </ul>\n        </div>\n\n        <!-- Actions -->\n        <div class="flex gap-3">\n          <a\n            href="/profile"\n            class="flex-1 rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 text-center font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"\n          >\n            \u2190 Back to Profile\n          </a>\n        </div>\n\n        <!-- Footer Warning -->\n        <div class="mt-6 rounded-xl border border-red-500/30 bg-red-500/10 px-4 py-3">\n          <p class="text-center text-sm text-red-300">\n            \u26A0\uFE0F Your previous backup codes are no longer valid\n          </p>\n        </div>\n      </div>\n    </div>\n\n    <script>\n      const codes = ', ";\n      const title = '", "';\n\n      function downloadBackupCodes() {\n        const text = 'MFA Backup Codes - ' + title + '\\\\n\\\\n' +\n                     'Generated: ' + new Date().toISOString() + '\\\\n\\\\n' +\n                     codes.join('\\\\n') + '\\\\n\\\\n' +\n                     '\u26A0\uFE0F  IMPORTANT:\\\\n' +\n                     '- Keep these codes in a safe place\\\\n' +\n                     '- Each code can only be used once\\\\n' +\n                     '- Previous backup codes are now invalid\\\\n' +\n                     '- You can regenerate codes anytime from your profile\\\\n';\n\n        const blob = new Blob([text], { type: 'text/plain' });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement('a');\n        a.href = url;\n        a.download = 'mfa-backup-codes-' + new Date().toISOString().split('T')[0] + '.txt';\n        a.click();\n        URL.revokeObjectURL(url);\n      }\n\n      function copyAllCodes() {\n        const text = codes.join('\\\\n');\n        navigator.clipboard.writeText(text).then(() => {\n          const button = document.getElementById('copy-button');\n          const originalText = button.innerHTML;\n          button.innerHTML = '\u2713 Copied to Clipboard!';\n          button.classList.add('bg-emerald-500/20', 'border-emerald-500/50', 'text-emerald-300');\n          setTimeout(() => {\n            button.innerHTML = originalText;\n            button.classList.remove('bg-emerald-500/20', 'border-emerald-500/50', 'text-emerald-300');\n          }, 2000);\n        }).catch(err => {\n          alert('Failed to copy codes. Please download them instead.');\n        });\n      }\n    <\/script>\n  "])), backupCodes.map((code) => html`
              <div class="rounded-lg bg-slate-900/50 px-4 py-3 text-center">
                <code class="font-mono text-base text-slate-200">${code}</code>
              </div>
            `), JSON.stringify(backupCodes), config.title || "S3DB Identity");
  return BaseLayout({
    title: "New Backup Codes Generated",
    content,
    config,
    error: null,
    success: null
  });
}

function OAuthErrorPage(props = {}) {
  const {
    error = "server_error",
    errorDescription = "An error occurred during OAuth authorization.",
    errorUri = null,
    config = {}
  } = props;
  const errorInfo = {
    invalid_request: {
      icon: "\u26A0\uFE0F",
      title: "Invalid Request",
      color: "amber"
    },
    unauthorized_client: {
      icon: "\u{1F6AB}",
      title: "Unauthorized Client",
      color: "red"
    },
    access_denied: {
      icon: "\u{1F512}",
      title: "Access Denied",
      color: "red"
    },
    unsupported_response_type: {
      icon: "\u274C",
      title: "Unsupported Response Type",
      color: "orange"
    },
    invalid_scope: {
      icon: "\u26D4",
      title: "Invalid Scope",
      color: "red"
    },
    server_error: {
      icon: "\u{1F4A5}",
      title: "Server Error",
      color: "red"
    },
    temporarily_unavailable: {
      icon: "\u23F8\uFE0F",
      title: "Temporarily Unavailable",
      color: "yellow"
    },
    invalid_client: {
      icon: "\u{1F511}",
      title: "Invalid Client",
      color: "red"
    },
    invalid_grant: {
      icon: "\u26A0\uFE0F",
      title: "Invalid Grant",
      color: "amber"
    }
  };
  const info = errorInfo[error] || errorInfo.server_error;
  const content = html`
    <div class="mx-auto w-full max-w-2xl px-4 py-12">
      <div class="rounded-3xl border border-slate-700/50 bg-slate-900/50 p-8 shadow-2xl backdrop-blur-xl md:p-12">
        <!-- Error Icon & Title -->
        <div class="mb-8 text-center">
          <div class="mb-4 inline-flex h-20 w-20 items-center justify-center rounded-2xl bg-red-500/20 text-4xl shadow-lg shadow-red-500/30">
            ${info.icon}
          </div>
          <h1 class="mb-2 text-3xl font-bold text-white">
            ${info.title}
          </h1>
          <p class="text-lg text-slate-400">
            OAuth Authorization Error
          </p>
        </div>

        <!-- Error Details -->
        <div class="mb-8 space-y-4">
          <!-- Error Code -->
          <div class="rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
            <h2 class="mb-2 text-sm font-semibold uppercase tracking-wide text-slate-400">
              Error Code
            </h2>
            <code class="block rounded-lg bg-slate-900/50 px-4 py-3 font-mono text-red-400">
              ${error}
            </code>
          </div>

          <!-- Error Description -->
          ${errorDescription ? html`
            <div class="rounded-2xl border border-slate-700/30 bg-slate-800/30 p-6">
              <h2 class="mb-2 text-sm font-semibold uppercase tracking-wide text-slate-400">
                Description
              </h2>
              <p class="text-slate-200">
                ${errorDescription}
              </p>
            </div>
          ` : ""}

          <!-- Common Causes -->
          <div class="rounded-2xl border border-blue-500/30 bg-blue-500/10 p-6">
            <h2 class="mb-3 text-lg font-semibold text-blue-200">
              Common Causes
            </h2>
            <ul class="space-y-2 text-sm text-blue-300/80">
              ${error === "invalid_request" ? html`
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Missing required parameters (client_id, redirect_uri, etc.)</span>
                </li>
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Malformed request parameters</span>
                </li>
              ` : ""}
              ${error === "unauthorized_client" || error === "invalid_client" ? html`
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Client ID not found or inactive</span>
                </li>
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Invalid client credentials</span>
                </li>
              ` : ""}
              ${error === "invalid_scope" ? html`
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Requested scopes not allowed for this client</span>
                </li>
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Unknown or unsupported scope requested</span>
                </li>
              ` : ""}
              ${error === "access_denied" ? html`
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>User denied authorization request</span>
                </li>
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Insufficient permissions for requested scopes</span>
                </li>
              ` : ""}
              ${error === "server_error" ? html`
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Internal server error occurred</span>
                </li>
                <li class="flex items-start gap-2">
                  <span class="mt-0.5 flex-shrink-0"></span>
                  <span>Temporary service disruption</span>
                </li>
              ` : ""}
            </ul>
          </div>
        </div>

        <!-- Actions -->
        <div class="space-y-3">
          ${errorUri ? html`
            <a
              href="${errorUri}"
              target="_blank"
              rel="noopener noreferrer"
              class="flex w-full items-center justify-center gap-2 rounded-xl bg-gradient-to-r from-blue-600 to-purple-600 px-6 py-3.5 font-semibold text-white shadow-lg shadow-blue-500/30 transition-all hover:shadow-xl hover:shadow-blue-500/40"
            >
               View Documentation
              <svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14" />
              </svg>
            </a>
          ` : ""}

          <a
            href="/login"
            class="flex w-full items-center justify-center rounded-xl border border-slate-700/50 bg-slate-800/30 px-6 py-3.5 font-medium text-slate-300 transition-all hover:border-slate-600/50 hover:bg-slate-800/50"
          >
             Back to Login
          </a>
        </div>

        <!-- Help Section -->
        ${config.supportEmail ? html`
          <div class="mt-8 rounded-xl border border-slate-700/30 bg-slate-800/20 px-6 py-4 text-center">
            <p class="text-sm text-slate-400">
              Need help?
              <a href="mailto:${config.supportEmail}" class="font-medium text-blue-400 hover:text-blue-300">
                Contact Support
              </a>
            </p>
          </div>
        ` : ""}
      </div>
    </div>
  `;
  return BaseLayout({
    title: `OAuth Error: ${info.title}`,
    content,
    config,
    error: null,
    success: null
  });
}

function sessionAuth(sessionManager, options = {}) {
  const {
    required = false,
    requireAdmin = false,
    redirectTo = "/login"
  } = options;
  return async (c, next) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    let user = null;
    let session = null;
    if (sessionId) {
      const { valid, session: validSession, reason } = await sessionManager.validateSession(sessionId);
      if (valid) {
        session = validSession;
        user = validSession.metadata || null;
      } else {
        sessionManager.clearSessionCookie(c);
        if (required) {
          const currentUrl = c.req.url;
          return c.redirect(`${redirectTo}?redirect=${encodeURIComponent(currentUrl)}&error=${encodeURIComponent("Your session has expired. Please log in again.")}`);
        }
      }
    }
    if (required && !user) {
      const currentUrl = c.req.url;
      return c.redirect(`${redirectTo}?redirect=${encodeURIComponent(currentUrl)}`);
    }
    if (requireAdmin && (!user || !user.isAdmin)) {
      return c.html("<h1>403 Forbidden</h1><p>You do not have permission to access this page.</p>", 403);
    }
    c.set("user", user);
    c.set("session", session);
    c.set("isAuthenticated", !!user);
    c.set("isAdmin", user?.isAdmin || false);
    await next();
  };
}
function adminOnly(sessionManager) {
  return sessionAuth(sessionManager, {
    required: true,
    requireAdmin: true
  });
}

function getPageComponent(customPages, pageName, defaultPage) {
  return customPages[pageName] || defaultPage;
}
function registerUIRoutes(app, plugin) {
  const { sessionManager, usersResource, config, failbanManager } = plugin;
  const customPages = config.ui.customPages || {};
  const failbanConfig = config.failban || {};
  const accountLockoutConfig = config.accountLockout || {};
  const userAttributes = plugin.config?.resources?.users?.mergedConfig?.attributes || {};
  const supportsStatusField = Object.prototype.hasOwnProperty.call(userAttributes, "status");
  const keyManager = plugin.oauth2Server?.keyManager || null;
  const createMfaChallengeToken = (user, rememberFlag) => {
    if (!keyManager) {
      return null;
    }
    return keyManager.createToken({
      type: "mfa_challenge",
      userId: user.id,
      email: user.email,
      remember: rememberFlag === "1"
    }, "5m");
  };
  const verifyMfaChallengeToken = async (token) => {
    if (!keyManager || !token) {
      return null;
    }
    try {
      const verified = await keyManager.verifyToken(token);
      if (!verified || verified.payload?.type !== "mfa_challenge") {
        return null;
      }
      return verified.payload;
    } catch {
      return null;
    }
  };
  const uiConfig = {
    ...config.ui,
    registrationEnabled: config.registration.enabled
  };
  const logAudit = async (event, data) => {
    if (plugin._logAuditEvent) {
      await plugin._logAuditEvent(event, data);
    }
  };
  app.get("/", async (c) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      const { valid } = await sessionManager.validateSession(sessionId);
      if (valid) {
        return c.redirect("/profile");
      }
    }
    return c.redirect("/login");
  });
  app.get("/login", async (c) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      const { valid } = await sessionManager.validateSession(sessionId);
      if (valid) {
        return c.redirect("/profile");
      }
    }
    const error = c.req.query("error");
    const success = c.req.query("success");
    const email = c.req.query("email") || "";
    const PageComponent = getPageComponent(customPages, "login", LoginPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      success: success ? decodeURIComponent(success) : null,
      email,
      config: uiConfig
    }));
  });
  const getClientIp = (c) => c.get("clientIp") || c.req.header("x-forwarded-for")?.split(",")[0]?.trim() || c.req.header("x-real-ip") || "unknown";
  const buildRateLimitRedirect = (retryAfter) => {
    const seconds = Math.max(retryAfter, 1);
    const message = seconds > 60 ? `Too many login attempts. Please wait ${Math.ceil(seconds / 60)} minute(s) and try again.` : `Too many login attempts. Please wait ${seconds} second(s) and try again.`;
    return `/login?error=${encodeURIComponent(message)}`;
  };
  const loginHandler = async (c) => {
    try {
      const body = await c.req.parseBody();
      const {
        email,
        password,
        remember,
        mfa_token,
        backup_code,
        mfa_challenge
      } = body;
      const clientIp = getClientIp(c);
      const userAgent = c.req.header("user-agent") || "unknown";
      const usingChallenge = Boolean(mfa_challenge);
      let normalizedEmail = email ? email.toLowerCase().trim() : "";
      let rememberChoice = remember === "1" ? "1" : "0";
      let challengePayload = null;
      if (usingChallenge) {
        challengePayload = await verifyMfaChallengeToken(mfa_challenge);
        if (!challengePayload) {
          return c.redirect(`/login?error=${encodeURIComponent("Your login session expired. Please sign in again.")}`);
        }
        normalizedEmail = (challengePayload.email || "").toLowerCase();
        rememberChoice = challengePayload.remember ? "1" : "0";
      }
      if (!normalizedEmail) {
        if (failbanManager && failbanConfig.endpoints.login) {
          await failbanManager.recordViolation(clientIp, "invalid_login_request", {
            path: "/login",
            userAgent
          });
        }
        return c.redirect(`/login?error=${encodeURIComponent("Email and password are required")}`);
      }
      let user = null;
      if (usingChallenge) {
        const [okUser, errUser, challengeUser] = await tryFn(
          () => usersResource.get(challengePayload.userId)
        );
        if (!okUser || !challengeUser || challengeUser.email.toLowerCase() !== normalizedEmail) {
          if (config.verbose) {
            console.error("[Identity Plugin] MFA challenge verification failed:", errUser?.message || "challenge mismatch");
          }
          return c.redirect(`/login?error=${encodeURIComponent("Your login session expired. Please sign in again.")}`);
        }
        user = challengeUser;
      } else {
        const [okQuery, errQuery, users] = await tryFn(
          () => usersResource.query({ email: normalizedEmail })
        );
        if (!okQuery || users.length === 0) {
          await new Promise((resolve) => setTimeout(resolve, 100));
          if (failbanManager && failbanConfig.endpoints.login) {
            await failbanManager.recordViolation(clientIp, "failed_login", {
              path: "/login",
              userAgent,
              email
            });
          }
          await logAudit("login_failed", {
            email,
            reason: "user_not_found",
            ipAddress: clientIp,
            userAgent
          });
          return c.redirect(`/login?error=${encodeURIComponent("Invalid email or password")}&email=${encodeURIComponent(email || "")}`);
        }
        user = users[0];
      }
      if (accountLockoutConfig.enabled && user.lockedUntil) {
        const now = Date.now();
        const lockedUntilTime = new Date(user.lockedUntil).getTime();
        if (lockedUntilTime > now) {
          const remainingMinutes = Math.ceil((lockedUntilTime - now) / 6e4);
          const message = `Your account has been locked due to too many failed login attempts. Please try again in ${remainingMinutes} minute${remainingMinutes > 1 ? "s" : ""} or contact support.`;
          return c.redirect(`/login?error=${encodeURIComponent(message)}&email=${encodeURIComponent(normalizedEmail)}`);
        }
        await usersResource.update(user.id, {
          lockedUntil: null,
          failedLoginAttempts: 0,
          lastFailedLogin: null
        });
      }
      if (!usingChallenge) {
        if (!password) {
          if (failbanManager && failbanConfig.endpoints.login) {
            await failbanManager.recordViolation(clientIp, "invalid_login_request", {
              path: "/login",
              userAgent,
              email
            });
          }
          return c.redirect(`/login?error=${encodeURIComponent("Email and password are required")}&email=${encodeURIComponent(email || "")}`);
        }
        const [okVerify, errVerify, isValid] = await tryFn(
          () => verifyPassword(password, user.password)
        );
        if (!okVerify) {
          if (config.verbose) {
            console.error("[Identity Plugin] Password verification error:", errVerify?.message);
          }
        }
        if (!okVerify || !isValid) {
          if (accountLockoutConfig.enabled) {
            const failedAttempts = (user.failedLoginAttempts || 0) + 1;
            const nowIso = (/* @__PURE__ */ new Date()).toISOString();
            if (failedAttempts >= accountLockoutConfig.maxAttempts) {
              const lockoutUntil = new Date(Date.now() + accountLockoutConfig.lockoutDuration).toISOString();
              await usersResource.update(user.id, {
                failedLoginAttempts: failedAttempts,
                lockedUntil: lockoutUntil,
                lastFailedLogin: nowIso
              });
              const lockoutMinutes = Math.ceil(accountLockoutConfig.lockoutDuration / 6e4);
              const message = `Too many failed login attempts. Your account has been locked for ${lockoutMinutes} minutes. Please contact support if you need assistance.`;
              return c.redirect(`/login?error=${encodeURIComponent(message)}&email=${encodeURIComponent(normalizedEmail)}`);
            }
            await usersResource.update(user.id, {
              failedLoginAttempts: failedAttempts,
              lastFailedLogin: nowIso
            });
          }
          if (failbanManager && failbanConfig.endpoints.login) {
            await failbanManager.recordViolation(clientIp, "failed_login", {
              path: "/login",
              userAgent,
              email: normalizedEmail,
              userId: user.id
            });
          }
          return c.redirect(`/login?error=${encodeURIComponent("Invalid email or password")}&email=${encodeURIComponent(normalizedEmail)}`);
        }
        if (accountLockoutConfig.enabled && accountLockoutConfig.resetOnSuccess) {
          if (user.failedLoginAttempts > 0 || user.lockedUntil) {
            await usersResource.update(user.id, {
              failedLoginAttempts: 0,
              lockedUntil: null,
              lastFailedLogin: null
            });
          }
        }
      }
      if (supportsStatusField && user.status && user.status !== "active") {
        const message = user.status === "suspended" ? "Your account has been suspended. Please contact support." : "Your account is inactive. Please contact support.";
        return c.redirect(`/login?error=${encodeURIComponent(message)}&email=${encodeURIComponent(normalizedEmail)}`);
      }
      if (!supportsStatusField && user.active === false) {
        return c.redirect(`/login?error=${encodeURIComponent("Your account is inactive. Please contact support.")}&email=${encodeURIComponent(normalizedEmail)}`);
      }
      if (config.registration.requireEmailVerification && !user.emailVerified) {
        const message = "Please verify your email address before signing in.";
        return c.redirect(`/login?error=${encodeURIComponent(message)}&email=${encodeURIComponent(normalizedEmail)}`);
      }
      let hasMFA = false;
      let mfaDevices = [];
      if (config.mfa.enabled && plugin.mfaDevicesResource) {
        const [okMFA, errMFA, devices] = await tryFn(
          () => plugin.mfaDevicesResource.query({ userId: user.id, verified: true })
        );
        if (!okMFA && config.verbose) {
          console.error("[Identity Plugin] Failed to load MFA devices:", errMFA);
        }
        if (okMFA && devices && devices.length > 0) {
          hasMFA = true;
          mfaDevices = devices;
        }
      }
      if (config.mfa.required && !hasMFA) {
        return c.redirect(`/login?error=${encodeURIComponent("Multi-factor authentication is required for your account. Please contact support to complete enrollment.")}&email=${encodeURIComponent(normalizedEmail)}`);
      }
      const needsMfa = hasMFA || config.mfa.required;
      if (!usingChallenge && needsMfa) {
        const challengeToken = createMfaChallengeToken(user, rememberChoice);
        if (!challengeToken) {
          return c.redirect(`/login?error=${encodeURIComponent("Unable to start MFA verification. Please contact support.")}`);
        }
        const params = new URLSearchParams({ challenge: challengeToken });
        if (rememberChoice === "1") {
          params.set("remember", "1");
        }
        return c.redirect(`/login/mfa?${params.toString()}`);
      }
      if (usingChallenge && needsMfa) {
        if (!mfa_token && !backup_code) {
          const retryChallenge = createMfaChallengeToken(user, rememberChoice) || mfa_challenge;
          const params = new URLSearchParams({ challenge: retryChallenge });
          params.set("error", "Multi-factor authentication is required.");
          if (rememberChoice === "1") {
            params.set("remember", "1");
          }
          return c.redirect(`/login/mfa?${params.toString()}`);
        }
        let mfaVerified = false;
        if (mfa_token && hasMFA) {
          mfaVerified = plugin.mfaManager.verifyTOTP(mfaDevices[0].secret, mfa_token);
          if (mfaVerified) {
            await plugin.mfaDevicesResource.patch(mfaDevices[0].id, {
              lastUsedAt: (/* @__PURE__ */ new Date()).toISOString()
            });
            await logAudit("mfa_verified", { userId: user.id, method: "totp" });
          }
        }
        if (!mfaVerified && backup_code && hasMFA) {
          const matchIndex = await plugin.mfaManager.verifyBackupCode(
            backup_code,
            mfaDevices[0].backupCodes
          );
          if (matchIndex !== null && matchIndex >= 0) {
            const updatedCodes = [...mfaDevices[0].backupCodes];
            updatedCodes.splice(matchIndex, 1);
            await plugin.mfaDevicesResource.patch(mfaDevices[0].id, {
              backupCodes: updatedCodes,
              lastUsedAt: (/* @__PURE__ */ new Date()).toISOString()
            });
            mfaVerified = true;
            await logAudit("mfa_verified", { userId: user.id, method: "backup_code" });
          }
        }
        if (!mfaVerified) {
          await logAudit("mfa_failed", { userId: user.id, reason: "invalid_token" });
          if (failbanManager && failbanConfig.endpoints.login) {
            await failbanManager.recordViolation(clientIp, "failed_mfa", {
              path: "/login",
              userAgent,
              email: normalizedEmail,
              userId: user.id
            });
          }
          const retryChallenge = createMfaChallengeToken(user, rememberChoice) || mfa_challenge;
          const params = new URLSearchParams({
            challenge: retryChallenge,
            error: "Invalid MFA code. Please try again."
          });
          if (rememberChoice === "1") {
            params.set("remember", "1");
          }
          return c.redirect(`/login/mfa?${params.toString()}`);
        }
      }
      const sessionDuration = rememberChoice === "1" ? "30d" : config.session.sessionExpiry;
      const [okSession, errSession, session] = await tryFn(
        () => sessionManager.createSession({
          userId: user.id,
          metadata: {
            email: user.email,
            name: user.name,
            isAdmin: user.isAdmin || false
          },
          ipAddress: clientIp,
          userAgent,
          duration: sessionDuration
        })
      );
      if (!okSession) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create session:", errSession);
        }
        return c.redirect(`/login?error=${encodeURIComponent("Failed to create session. Please try again.")}&email=${encodeURIComponent(normalizedEmail)}`);
      }
      sessionManager.setSessionCookie(c, session.sessionId, session.expiresAt);
      await tryFn(
        () => usersResource.patch(user.id, {
          lastLoginAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastLoginIp: clientIp
        })
      );
      const redirectTo = c.req.query("redirect") || "/profile";
      return c.redirect(redirectTo);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Login error:", error);
      }
      return c.redirect(`/login?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  };
  const loginLimiter = plugin.rateLimiters?.login;
  if (loginLimiter) {
    const loginRateMiddleware = createRedirectRateLimitMiddleware(
      loginLimiter,
      getClientIp,
      buildRateLimitRedirect
    );
    app.post("/login", loginRateMiddleware, loginHandler);
  } else {
    app.post("/login", loginHandler);
  }
  app.get("/login/mfa", async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/login?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    try {
      const challenge = c.req.query("challenge");
      const remember = c.req.query("remember");
      const error = c.req.query("error");
      if (!challenge) {
        return c.redirect(`/login?error=${encodeURIComponent("Invalid MFA session")}`);
      }
      const payload = await verifyMfaChallengeToken(challenge);
      if (!payload) {
        return c.redirect(`/login?error=${encodeURIComponent("MFA session expired. Please login again.")}`);
      }
      const [okUser, , challengeUser] = await tryFn(
        () => usersResource.get(payload.userId)
      );
      if (!okUser || !challengeUser) {
        return c.redirect(`/login?error=${encodeURIComponent("Your account could not be found. Please login again.")}`);
      }
      const effectiveRemember = payload.remember || remember === "1";
      return c.html(MFAVerificationPage({
        error: error ? decodeURIComponent(error) : null,
        email: challengeUser.email,
        remember: effectiveRemember ? "1" : "0",
        challenge,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] MFA verification page error:", error);
      }
      return c.redirect(`/login?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/register", async (c) => {
    if (!config.registration.enabled) {
      const message = config.registration.customMessage || "Registration is currently disabled. Please contact an administrator for access.";
      return c.redirect(`/login?error=${encodeURIComponent(message)}`);
    }
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      const { valid } = await sessionManager.validateSession(sessionId);
      if (valid) {
        return c.redirect("/profile");
      }
    }
    const error = c.req.query("error");
    const email = c.req.query("email") || "";
    const name = c.req.query("name") || "";
    const PageComponent = getPageComponent(customPages, "register", RegisterPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      email,
      name,
      passwordPolicy: config.passwordPolicy,
      config: uiConfig
    }));
  });
  app.post("/register", async (c) => {
    if (!config.registration.enabled) {
      const message = config.registration.customMessage || "Registration is currently disabled. Please contact an administrator for access.";
      return c.redirect(`/login?error=${encodeURIComponent(message)}`);
    }
    try {
      const body = await c.req.parseBody();
      const { name, email, password, confirm_password, agree_terms } = body;
      if (!name || !email || !password || !confirm_password) {
        return c.redirect(`/register?error=${encodeURIComponent("All fields are required")}&email=${encodeURIComponent(email || "")}&name=${encodeURIComponent(name || "")}`);
      }
      if (!agree_terms || agree_terms !== "1") {
        return c.redirect(`/register?error=${encodeURIComponent("You must agree to the Terms of Service and Privacy Policy")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      if (password !== confirm_password) {
        return c.redirect(`/register?error=${encodeURIComponent("Passwords do not match")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const passwordValidation = validatePassword(password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/register?error=${encodeURIComponent(errorMsg)}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const emailDomain = normalizedEmail.split("@")[1];
      if (config.registration.blockedDomains && config.registration.blockedDomains.length > 0) {
        if (config.registration.blockedDomains.includes(emailDomain)) {
          return c.redirect(`/register?error=${encodeURIComponent("Registration with this email domain is not allowed")}&name=${encodeURIComponent(name)}`);
        }
      }
      if (config.registration.allowedDomains && config.registration.allowedDomains.length > 0) {
        if (!config.registration.allowedDomains.includes(emailDomain)) {
          return c.redirect(`/register?error=${encodeURIComponent("Registration is restricted to specific email domains")}&name=${encodeURIComponent(name)}`);
        }
      }
      const [okCheck, errCheck, existingUsers] = await tryFn(
        () => usersResource.query({ email: normalizedEmail })
      );
      if (okCheck && existingUsers && existingUsers.length > 0) {
        return c.redirect(`/register?error=${encodeURIComponent("An account with this email already exists")}&name=${encodeURIComponent(name)}`);
      }
      const ipAddress = getClientIp(c);
      const initialActive = !config.registration.requireEmailVerification;
      const userRecord = {
        email: normalizedEmail,
        name: name.trim(),
        password,
        // Auto-encrypted with 'password' type
        isAdmin: false,
        emailVerified: config.registration.requireEmailVerification ? false : true,
        active: initialActive,
        registrationIp: ipAddress,
        lastLoginAt: null,
        lastLoginIp: null
      };
      if (supportsStatusField) {
        userRecord.status = initialActive ? "active" : "pending_verification";
      }
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.insert(userRecord)
      );
      if (!okUser) {
        if (config.verbose) {
          console.error("[Identity Plugin] User creation failed:", errUser);
        }
        return c.redirect(`/register?error=${encodeURIComponent("Failed to create account. Please try again.")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      let successMessage = "Account created successfully! You can sign in now.";
      if (config.registration.requireEmailVerification) {
        const verificationToken = generatePasswordResetToken();
        const verificationExpiry = calculateExpiration("24h");
        await usersResource.update(user.id, {
          emailVerificationToken: verificationToken,
          emailVerificationExpiry: verificationExpiry
        });
        if (plugin.emailService) {
          try {
            await plugin.emailService.sendEmailVerificationEmail({
              to: normalizedEmail,
              name: name.trim(),
              verificationToken
            });
          } catch (emailError) {
            if (config.verbose) {
              console.error("[Identity Plugin] Failed to send verification email:", emailError);
            }
          }
        }
        successMessage = "Account created successfully! Please check your email to verify your account.";
      }
      return c.redirect(`/login?success=${encodeURIComponent(successMessage)}&email=${encodeURIComponent(normalizedEmail)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Registration error:", error);
      }
      return c.redirect(`/register?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/logout", async (c) => {
    try {
      const sessionId = sessionManager.getSessionIdFromRequest(c.req);
      if (sessionId) {
        await sessionManager.destroySession(sessionId);
      }
      sessionManager.clearSessionCookie(c);
      return c.redirect("/login?success=You have been logged out successfully");
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout error:", error);
      }
      sessionManager.clearSessionCookie(c);
      return c.redirect("/login");
    }
  });
  app.get("/logout", async (c) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      await sessionManager.destroySession(sessionId);
    }
    sessionManager.clearSessionCookie(c);
    return c.redirect("/login?success=You have been logged out successfully");
  });
  app.get("/forgot-password", async (c) => {
    const error = c.req.query("error");
    const success = c.req.query("success");
    const email = c.req.query("email") || "";
    const PageComponent = getPageComponent(customPages, "forgotPassword", ForgotPasswordPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      success: success ? decodeURIComponent(success) : null,
      email,
      config: uiConfig
    }));
  });
  app.post("/forgot-password", async (c) => {
    try {
      const body = await c.req.parseBody();
      const { email } = body;
      if (!email) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Email is required")}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const [okQuery, errQuery, users] = await tryFn(
        () => usersResource.query({ email: normalizedEmail })
      );
      const successMessage = "If an account exists with this email, you will receive password reset instructions.";
      if (!okQuery || users.length === 0) {
        await new Promise((resolve) => setTimeout(resolve, 500));
        return c.redirect(`/forgot-password?success=${encodeURIComponent(successMessage)}`);
      }
      const user = users[0];
      const resetToken = generatePasswordResetToken();
      const expiresAt = calculateExpiration("1h");
      const [okToken, errToken] = await tryFn(
        () => plugin.passwordResetTokensResource.insert({
          userId: user.id,
          token: resetToken,
          expiresAt,
          used: false
        })
      );
      if (!okToken) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create reset token:", errToken);
        }
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Failed to process request. Please try again.")}&email=${encodeURIComponent(email)}`);
      }
      if (plugin.emailService && plugin.emailService.config.enabled) {
        await plugin.emailService.sendPasswordResetEmail({
          to: user.email,
          name: user.name,
          resetToken,
          expiresIn: 60
          // minutes
        });
      } else if (config.verbose) {
        console.log("[Identity Plugin] Email service disabled. Reset token:", resetToken);
        console.log("[Identity Plugin] Reset URL:", `${config.ui.baseUrl || "http://localhost:4000"}/reset-password?token=${resetToken}`);
      }
      return c.redirect(`/forgot-password?success=${encodeURIComponent(successMessage)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Forgot password error:", error);
      }
      return c.redirect(`/forgot-password?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/reset-password", async (c) => {
    const token = c.req.query("token");
    const error = c.req.query("error");
    if (!token) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid or missing reset token")}`);
    }
    const [okQuery, errQuery, tokens] = await tryFn(
      () => plugin.passwordResetTokensResource.query({ token })
    );
    if (!okQuery || tokens.length === 0) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid reset token")}`);
    }
    const resetToken = tokens[0];
    if (isExpired(resetToken.expiresAt)) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has expired. Please request a new one.")}`);
    }
    if (resetToken.used) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has already been used. Please request a new one.")}`);
    }
    const PageComponent = getPageComponent(customPages, "resetPassword", ResetPasswordPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      token,
      passwordPolicy: config.passwordPolicy,
      config: uiConfig
    }));
  });
  app.post("/reset-password", async (c) => {
    try {
      const body = await c.req.parseBody();
      const { token, password, confirm_password } = body;
      if (!token || !password || !confirm_password) {
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("All fields are required")}`);
      }
      if (password !== confirm_password) {
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("Passwords do not match")}`);
      }
      const passwordValidation = validatePassword(password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent(errorMsg)}`);
      }
      const [okQuery, errQuery, tokens] = await tryFn(
        () => plugin.passwordResetTokensResource.query({ token })
      );
      if (!okQuery || tokens.length === 0) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid reset token")}`);
      }
      const resetToken = tokens[0];
      if (isExpired(resetToken.expiresAt)) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has expired. Please request a new one.")}`);
      }
      if (resetToken.used) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has already been used.")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(resetToken.userId, {
          password
          // Auto-encrypted with 'secret' type
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password update failed:", errUpdate);
        }
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("Failed to reset password. Please try again.")}`);
      }
      await tryFn(
        () => plugin.passwordResetTokensResource.patch(resetToken.id, { used: true })
      );
      await sessionManager.destroyUserSessions(resetToken.userId);
      return c.redirect(`/login?success=${encodeURIComponent("Your password has been reset successfully. Please log in with your new password.")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Reset password error:", error);
      }
      return c.redirect(`/forgot-password?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/profile", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to load user:", errUser);
        }
        return c.redirect(`/login?error=${encodeURIComponent("Failed to load profile. Please try again.")}`);
      }
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(userData.id)
      );
      const sessions = okSessions ? allSessions.map((session) => ({
        ...session,
        isCurrent: session.id === currentSessionId
      })) : [];
      const error = c.req.query("error");
      const success = c.req.query("success");
      const PageComponent = getPageComponent(customPages, "profile", ProfilePage);
      return c.html(PageComponent({
        user: userData,
        sessions,
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        passwordPolicy: config.passwordPolicy,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Profile page error:", error);
      }
      return c.redirect(`/login?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/update", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { name, email } = body;
      const user = c.get("user");
      if (!name || !email) {
        return c.redirect(`/profile?error=${encodeURIComponent("Name and email are required")}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      if (normalizedEmail !== userData.email) {
        const [okCheck, errCheck, existingUsers] = await tryFn(
          () => usersResource.query({ email: normalizedEmail })
        );
        if (okCheck && existingUsers.length > 0) {
          return c.redirect(`/profile?error=${encodeURIComponent("Email address is already in use")}`);
        }
        const [okUpdate, errUpdate] = await tryFn(
          () => usersResource.patch(userData.id, {
            name: name.trim(),
            email: normalizedEmail,
            emailVerified: false
          })
        );
        if (!okUpdate) {
          if (config.verbose) {
            console.error("[Identity Plugin] Profile update failed:", errUpdate);
          }
          return c.redirect(`/profile?error=${encodeURIComponent("Failed to update profile. Please try again.")}`);
        }
        return c.redirect(`/profile?success=${encodeURIComponent("Profile updated successfully. Please verify your new email address.")}`);
      } else {
        const [okUpdate, errUpdate] = await tryFn(
          () => usersResource.patch(userData.id, {
            name: name.trim()
          })
        );
        if (!okUpdate) {
          if (config.verbose) {
            console.error("[Identity Plugin] Profile update failed:", errUpdate);
          }
          return c.redirect(`/profile?error=${encodeURIComponent("Failed to update profile. Please try again.")}`);
        }
        return c.redirect(`/profile?success=${encodeURIComponent("Profile updated successfully")}`);
      }
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Profile update error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/change-password", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { current_password, new_password, confirm_new_password } = body;
      const user = c.get("user");
      if (!current_password || !new_password || !confirm_new_password) {
        return c.redirect(`/profile?error=${encodeURIComponent("All password fields are required")}`);
      }
      if (new_password !== confirm_new_password) {
        return c.redirect(`/profile?error=${encodeURIComponent("New passwords do not match")}`);
      }
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const [okVerify, errVerify, isValid] = await tryFn(
        () => verifyPassword(current_password, userData.password)
      );
      if (!okVerify || !isValid) {
        return c.redirect(`/profile?error=${encodeURIComponent("Current password is incorrect")}`);
      }
      const passwordValidation = validatePassword(new_password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/profile?error=${encodeURIComponent(errorMsg)}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userData.id, {
          password: new_password
          // Auto-encrypted with 'secret' type
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password update failed:", errUpdate);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to change password. Please try again.")}`);
      }
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(userData.id)
      );
      if (okSessions) {
        for (const session of allSessions) {
          if (session.id !== currentSessionId) {
            await sessionManager.destroySession(session.id);
          }
        }
      }
      return c.redirect(`/profile?success=${encodeURIComponent("Password changed successfully. All other sessions have been logged out.")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Change password error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/logout-session", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { session_id } = body;
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      if (!session_id) {
        return c.redirect(`/profile?error=${encodeURIComponent("Session ID is required")}`);
      }
      if (session_id === currentSessionId) {
        return c.redirect(`/profile?error=${encodeURIComponent("Cannot logout current session. Use logout button instead.")}`);
      }
      const [okSession, errSession, session] = await tryFn(
        () => sessionManager.getSession(session_id)
      );
      if (!okSession || !session) {
        return c.redirect(`/profile?error=${encodeURIComponent("Session not found")}`);
      }
      if (session.userId !== (user.userId || user.id)) {
        return c.redirect(`/profile?error=${encodeURIComponent("Access denied")}`);
      }
      await sessionManager.destroySession(session_id);
      return c.redirect(`/profile?success=${encodeURIComponent("Session logged out successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout session error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/logout-all-sessions", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(user.userId || user.id)
      );
      if (!okSessions) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to get sessions:", errSessions);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to logout sessions. Please try again.")}`);
      }
      let loggedOutCount = 0;
      for (const session of allSessions) {
        if (session.id !== currentSessionId) {
          await sessionManager.destroySession(session.id);
          loggedOutCount++;
        }
      }
      return c.redirect(`/profile?success=${encodeURIComponent(`${loggedOutCount} session(s) logged out successfully`)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout all sessions error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/profile/mfa/enroll", sessionAuth(sessionManager, { required: true }), async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    try {
      const user = c.get("user");
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const [okDevices, errDevices, devices] = await tryFn(
        () => plugin.mfaDevicesResource.query({ userId: userData.id, verified: true })
      );
      if (okDevices && devices.length > 0) {
        return c.redirect(`/profile?error=${encodeURIComponent("MFA is already enabled for your account")}`);
      }
      const enrollment = plugin.mfaManager.generateEnrollment(userData.email);
      const qrCodeDataUrl = await plugin.mfaManager.generateQRCodeDataURL(enrollment.qrCodeUrl);
      c.set("mfaEnrollment", enrollment);
      return c.html(MFAEnrollmentPage({
        qrCodeDataUrl,
        secret: enrollment.secret,
        backupCodes: enrollment.backupCodes,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] MFA enrollment page error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/mfa/enroll", sessionAuth(sessionManager, { required: true }), async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    try {
      const user = c.get("user");
      const body = await c.req.parseBody();
      const { token, enrollment_secret, enrollment_backup_codes } = body;
      if (!token || !enrollment_secret || !enrollment_backup_codes) {
        return c.redirect(`/profile/mfa/enroll?error=${encodeURIComponent("Invalid enrollment data")}`);
      }
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const isValid = plugin.mfaManager.verifyTOTP(enrollment_secret, token);
      if (!isValid) {
        return c.redirect(`/profile/mfa/enroll?error=${encodeURIComponent("Invalid verification code. Please try again.")}`);
      }
      const backupCodes = JSON.parse(enrollment_backup_codes);
      const hashedCodes = await plugin.mfaManager.hashBackupCodes(backupCodes);
      const [okDevice, errDevice] = await tryFn(
        () => plugin.mfaDevicesResource.insert({
          userId: userData.id,
          type: "totp",
          secret: enrollment_secret,
          verified: true,
          backupCodes: hashedCodes,
          enrolledAt: (/* @__PURE__ */ new Date()).toISOString(),
          deviceName: "Authenticator App"
        })
      );
      if (!okDevice) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to save MFA device:", errDevice);
        }
        return c.redirect(`/profile/mfa/enroll?error=${encodeURIComponent("Failed to enable MFA. Please try again.")}`);
      }
      await logAudit("mfa_enrolled", { userId: userData.id, type: "totp" });
      return c.redirect(`/profile?success=${encodeURIComponent("Two-factor authentication enabled successfully!")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] MFA enrollment error:", error);
      }
      return c.redirect(`/profile/mfa/enroll?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/mfa/disable", sessionAuth(sessionManager, { required: true }), async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    try {
      const user = c.get("user");
      const body = await c.req.parseBody();
      const { password } = body;
      if (!password) {
        return c.redirect(`/profile?error=${encodeURIComponent("Password is required to disable MFA")}`);
      }
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const isValidPassword = await verifyPassword(password, userData.password);
      if (!isValidPassword) {
        return c.redirect(`/profile?error=${encodeURIComponent("Invalid password")}`);
      }
      const [okDevices, errDevices, devices] = await tryFn(
        () => plugin.mfaDevicesResource.query({ userId: userData.id })
      );
      if (okDevices && devices.length > 0) {
        for (const device of devices) {
          await plugin.mfaDevicesResource.remove(device.id);
        }
        await logAudit("mfa_disabled", { userId: userData.id, by: "user" });
        return c.redirect(`/profile?success=${encodeURIComponent("Two-factor authentication disabled successfully")}`);
      } else {
        return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled for your account")}`);
      }
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] MFA disable error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/profile/mfa/backup-codes", sessionAuth(sessionManager, { required: true }), async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    try {
      const user = c.get("user");
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const [okDevices, errDevices, devices] = await tryFn(
        () => plugin.mfaDevicesResource.query({ userId: userData.id, verified: true })
      );
      if (!okDevices || devices.length === 0) {
        return c.redirect(`/profile?error=${encodeURIComponent("MFA is not enabled for your account")}`);
      }
      const backupCodes = plugin.mfaManager.generateBackupCodes(config.mfa.backupCodesCount);
      const hashedCodes = await plugin.mfaManager.hashBackupCodes(backupCodes);
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.mfaDevicesResource.patch(devices[0].id, {
          backupCodes: hashedCodes
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to regenerate backup codes:", errUpdate);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to regenerate backup codes. Please try again.")}`);
      }
      return c.html(MFABackupCodesPage({
        backupCodes,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] MFA backup codes error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const [okUsers, errUsers, allUsers] = await tryFn(() => usersResource.list({ limit: 1e3 }));
      const [okClients, errClients, allClients] = await tryFn(() => plugin.oauth2ClientsResource.list({ limit: 100 }));
      const [okSessions, errSessions, allSessions] = await tryFn(() => plugin.sessionsResource.list({ limit: 1e3 }));
      const [okCodes, errCodes, allCodes] = await tryFn(() => plugin.oauth2AuthCodesResource.list({ limit: 1e3 }));
      const users = okUsers ? allUsers : [];
      const clients = okClients ? allClients : [];
      const sessions = okSessions ? allSessions : [];
      const codes = okCodes ? allCodes : [];
      const now = /* @__PURE__ */ new Date();
      const stats = {
        totalUsers: users.length,
        activeUsers: users.filter((u) => supportsStatusField ? u.status === "active" : u.active !== false).length,
        pendingUsers: users.filter((u) => supportsStatusField ? u.status === "pending_verification" : u.active === false && !u.emailVerified).length,
        totalClients: clients.length,
        activeClients: clients.filter((c2) => c2.active !== false).length,
        activeSessions: sessions.filter((s) => new Date(s.expiresAt) > now).length,
        uniqueUsers: new Set(sessions.filter((s) => new Date(s.expiresAt) > now).map((s) => s.userId)).size,
        totalAuthCodes: codes.length,
        unusedAuthCodes: codes.filter((c2) => !c2.used).length,
        recentUsers: users.slice(-5).reverse(),
        serverUptime: formatUptime(process.uptime())
      };
      return c.html(AdminDashboardPage({
        stats,
        user,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Admin dashboard error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("Failed to load admin dashboard")}`);
    }
  });
  app.get("/admin/clients", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const error = c.req.query("error");
      const success = c.req.query("success");
      const [okClients, errClients, clients] = await tryFn(
        () => plugin.oauth2ClientsResource.list({ limit: 100 })
      );
      if (!okClients) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to load clients:", errClients);
        }
        return c.redirect(`/admin?error=${encodeURIComponent("Failed to load clients")}`);
      }
      return c.html(AdminClientsPage({
        clients,
        user,
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Admin clients error:", error);
      }
      return c.redirect(`/admin?error=${encodeURIComponent("Failed to load clients")}`);
    }
  });
  app.get("/admin/clients/new", adminOnly(sessionManager), async (c) => {
    const user = c.get("user");
    const error = c.req.query("error");
    return c.html(AdminClientFormPage({
      user,
      error: error ? decodeURIComponent(error) : null,
      availableScopes: config.supportedScopes || ["openid", "profile", "email", "offline_access"],
      availableGrantTypes: config.supportedGrantTypes || ["authorization_code", "refresh_token", "client_credentials"],
      config: uiConfig
    }));
  });
  app.post("/admin/clients/create", adminOnly(sessionManager), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { name, redirectUris, grantTypes, allowedScopes, active } = body;
      if (!name) {
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("Client name is required")}`);
      }
      const redirectUrisArray = Array.isArray(redirectUris) ? redirectUris : [redirectUris];
      const grantTypesArray = Array.isArray(grantTypes) ? grantTypes : grantTypes ? [grantTypes] : [];
      const allowedScopesArray = Array.isArray(allowedScopes) ? allowedScopes : allowedScopes ? [allowedScopes] : [];
      if (redirectUrisArray.length === 0 || redirectUrisArray[0] === "") {
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("At least one redirect URI is required")}`);
      }
      const clientId = idGenerator();
      const clientSecret = idGenerator() + idGenerator();
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.insert({
          clientId,
          clientSecret,
          name: name.trim(),
          redirectUris: redirectUrisArray.filter((uri) => uri && uri.trim() !== ""),
          grantTypes: grantTypesArray,
          allowedScopes: allowedScopesArray,
          active: active === "1"
        })
      );
      if (!okClient) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create client:", errClient);
        }
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("Failed to create client. Please try again.")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client created successfully. Client ID: " + clientId + " | Client Secret: " + clientSecret + " (Save this secret now - it cannot be displayed again!)")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Create client error:", error);
      }
      return c.redirect(`/admin/clients/new?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin/clients/:id/edit", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const clientId = c.req.param("id");
      const error = c.req.query("error");
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.get(clientId)
      );
      if (!okClient) {
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Client not found")}`);
      }
      return c.html(AdminClientFormPage({
        client,
        user,
        error: error ? decodeURIComponent(error) : null,
        availableScopes: config.supportedScopes || ["openid", "profile", "email", "offline_access"],
        availableGrantTypes: config.supportedGrantTypes || ["authorization_code", "refresh_token", "client_credentials"],
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Edit client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to load client")}`);
    }
  });
  app.post("/admin/clients/:id/update", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const body = await c.req.parseBody();
      const { name, redirectUris, grantTypes, allowedScopes, active } = body;
      if (!name) {
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("Client name is required")}`);
      }
      const redirectUrisArray = Array.isArray(redirectUris) ? redirectUris : [redirectUris];
      const grantTypesArray = Array.isArray(grantTypes) ? grantTypes : grantTypes ? [grantTypes] : [];
      const allowedScopesArray = Array.isArray(allowedScopes) ? allowedScopes : allowedScopes ? [allowedScopes] : [];
      if (redirectUrisArray.length === 0 || redirectUrisArray[0] === "") {
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("At least one redirect URI is required")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          name: name.trim(),
          redirectUris: redirectUrisArray.filter((uri) => uri && uri.trim() !== ""),
          grantTypes: grantTypesArray,
          allowedScopes: allowedScopesArray,
          active: active === "1"
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to update client:", errUpdate);
        }
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("Failed to update client. Please try again.")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client updated successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Update client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/delete", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const [okDelete, errDelete] = await tryFn(
        () => plugin.oauth2ClientsResource.delete(clientId)
      );
      if (!okDelete) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to delete client:", errDelete);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to delete client")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client deleted successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Delete client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/rotate-secret", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const newSecret = idGenerator() + idGenerator();
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          clientSecret: newSecret
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to rotate secret:", errUpdate);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to rotate secret")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Secret rotated successfully. New secret: " + newSecret + " (Save this now - it cannot be displayed again!)")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Rotate secret error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/toggle-active", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.get(clientId)
      );
      if (!okClient) {
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Client not found")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          active: !client.active
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to toggle active:", errUpdate);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to update client")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent(`Client ${client.active ? "deactivated" : "activated"} successfully`)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Toggle active error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin/users", adminOnly(sessionManager), async (c) => {
    const error = c.req.query("error");
    const success = c.req.query("success");
    try {
      const [okUsers, errUsers, allUsers] = await tryFn(
        () => usersResource.list({ limit: 1e3 })
      );
      if (!okUsers) {
        console.error("[Identity Plugin] List users error:", errUsers);
        return c.html(AdminUsersPage({
          users: [],
          user: c.get("user"),
          error: "Failed to load users",
          success: success ? decodeURIComponent(success) : null,
          config: uiConfig
        }));
      }
      const users = allUsers || [];
      return c.html(AdminUsersPage({
        users,
        user: c.get("user"),
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        config: uiConfig
      }));
    } catch (error2) {
      console.error("[Identity Plugin] List users error:", error2);
      return c.html(AdminUsersPage({
        users: [],
        user: c.get("user"),
        error: "An error occurred. Please try again.",
        config: uiConfig
      }));
    }
  });
  app.get("/admin/users/:id/edit", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const error = c.req.query("error");
    try {
      const [okUser, errUser, editUser] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !editUser) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      return c.html(AdminUserFormPage({
        editUser,
        user: c.get("user"),
        error: error ? decodeURIComponent(error) : null,
        config: uiConfig
      }));
    } catch (error2) {
      console.error("[Identity Plugin] Get user error:", error2);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/update", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const body = await c.req.parseBody();
    const { name, email, status, role, emailVerified } = body;
    const currentUser = c.get("user");
    try {
      const [okUser, errUser, editUser] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !editUser) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const isSelfEdit = userId === currentUser.id;
      if (email !== editUser.email) {
        const [okExists, errExists, existingUsers] = await tryFn(
          () => usersResource.query({ email: email.toLowerCase().trim() })
        );
        if (okExists && existingUsers && existingUsers.length > 0) {
          return c.html(AdminUserFormPage({
            editUser: { ...editUser, name, email },
            user: currentUser,
            error: "Email already in use",
            config: uiConfig
          }));
        }
      }
      const updates = {
        name: name.trim(),
        email: email.toLowerCase().trim()
      };
      if (!isSelfEdit) {
        if (supportsStatusField && status) {
          updates.status = status;
        }
        if (role) {
          updates.role = role;
        }
      }
      updates.emailVerified = emailVerified === "1";
      if (email !== editUser.email) {
        updates.emailVerified = false;
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(userId, updates)
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Update user error:", errUpdate);
        return c.html(AdminUserFormPage({
          editUser: { ...editUser, ...updates },
          user: currentUser,
          error: "Failed to update user",
          config: uiConfig
        }));
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User ${name} updated successfully`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Update user error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/delete", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot delete your own account")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const userName = user.name;
      const [okDelete, errDelete] = await tryFn(
        () => usersResource.delete(userId)
      );
      if (!okDelete) {
        console.error("[Identity Plugin] Delete user error:", errDelete);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to delete user")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User ${userName} deleted successfully`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Delete user error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/change-status", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const body = await c.req.parseBody();
    const { status } = body;
    const currentUser = c.get("user");
    if (!supportsStatusField) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("Status management is not supported for this deployment")}`);
    }
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot change your own status")}`);
    }
    try {
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { status })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Change status error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to change user status")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User status changed to ${status}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Change status error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/verify-email", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    try {
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { emailVerified: true })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Verify email error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to verify email")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent("Email marked as verified")}`);
    } catch (error) {
      console.error("[Identity Plugin] Verify email error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/reset-password", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("Use the profile page to change your own password")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const resetToken = generatePasswordResetToken();
      const resetExpiry = calculateExpiration(1);
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, {
          passwordResetToken: resetToken,
          passwordResetExpiry: resetExpiry
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Password reset update error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to generate reset token")}`);
      }
      if (plugin.emailService) {
        const resetUrl = `${config.issuer}/reset-password?token=${resetToken}`;
        await plugin.emailService.sendPasswordResetEmail(user.email, {
          name: user.name,
          resetUrl
        });
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`Password reset email sent to ${user.email}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Reset password error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/unlock-account", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    try {
      const [okGet, errGet, user] = await tryFn(() => usersResource.get(userId));
      if (!okGet || !user) {
        console.error("[Identity Plugin] User not found:", userId);
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      if (!user.lockedUntil && !user.failedLoginAttempts) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User account is not locked")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(userId, {
          failedLoginAttempts: 0,
          lockedUntil: null,
          lastFailedLogin: null
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Failed to unlock account:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to unlock account")}`);
      }
      if (config.verbose) {
        console.log(`[Account Lockout] Admin ${currentUser.email} manually unlocked user ${user.email}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`Account unlocked for ${user.email}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Unlock account error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/disable-mfa", adminOnly(sessionManager), async (c) => {
    if (!config.mfa.enabled) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("MFA is not enabled on this server")}`);
    }
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    try {
      const [okGet, errGet, user] = await tryFn(() => usersResource.get(userId));
      if (!okGet || !user) {
        console.error("[Identity Plugin] User not found:", userId);
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const [okDevices, errDevices, devices] = await tryFn(
        () => plugin.mfaDevicesResource.query({ userId: user.id })
      );
      if (!okDevices || devices.length === 0) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("MFA is not enabled for this user")}`);
      }
      for (const device of devices) {
        await plugin.mfaDevicesResource.remove(device.id);
      }
      await logAudit("mfa_disabled", {
        userId: user.id,
        by: "admin",
        adminEmail: currentUser.email
      });
      if (config.verbose) {
        console.log(`[MFA] Admin ${currentUser.email} disabled MFA for user ${user.email}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`MFA disabled for ${user.email}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Admin disable MFA error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/toggle-admin", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot change your own role")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const newRole = user.role === "admin" ? "user" : "admin";
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { role: newRole })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Toggle admin error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to change user role")}`);
      }
      const action = newRole === "admin" ? "granted admin privileges to" : "removed admin privileges from";
      return c.redirect(`/admin/users?success=${encodeURIComponent(`Successfully ${action} ${user.name}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Toggle admin error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/oauth/authorize", sessionAuth(sessionManager, { required: false }), async (c) => {
    const query = c.req.query();
    const {
      response_type,
      client_id,
      redirect_uri,
      scope,
      state,
      code_challenge,
      code_challenge_method = "plain"
    } = query;
    try {
      if (!response_type || !client_id || !redirect_uri) {
        return c.html(OAuthErrorPage({
          error: "invalid_request",
          errorDescription: "Missing required parameters: response_type, client_id, and redirect_uri are required",
          config: uiConfig
        }), 400);
      }
      const user = c.get("user");
      if (!user) {
        const returnUrl = `/oauth/authorize?${new URLSearchParams(query).toString()}`;
        return c.redirect(`/login?returnUrl=${encodeURIComponent(returnUrl)}`);
      }
      const [okClient, errClient, clients] = await tryFn(
        () => plugin.oauth2ClientsResource.query({ clientId: client_id })
      );
      if (!okClient || !clients || clients.length === 0) {
        return c.html(OAuthErrorPage({
          error: "invalid_client",
          errorDescription: "Client not found",
          config: uiConfig
        }), 400);
      }
      const client = clients[0];
      if (client.active === false) {
        return c.html(OAuthErrorPage({
          error: "unauthorized_client",
          errorDescription: "This client is not currently active",
          config: uiConfig
        }), 400);
      }
      if (!client.redirectUris || !client.redirectUris.includes(redirect_uri)) {
        return c.html(OAuthErrorPage({
          error: "invalid_request",
          errorDescription: "The redirect_uri does not match any registered URIs for this client",
          config: uiConfig
        }), 400);
      }
      const requestedScopes = scope ? scope.split(" ") : [];
      if (requestedScopes.length > 0) {
        const invalidScopes = requestedScopes.filter(
          (s) => !client.allowedScopes || !client.allowedScopes.includes(s)
        );
        if (invalidScopes.length > 0) {
          return c.html(OAuthErrorPage({
            error: "invalid_scope",
            errorDescription: `Invalid scopes: ${invalidScopes.join(", ")}`,
            config: uiConfig
          }), 400);
        }
      }
      const PageComponent = getPageComponent(customPages, "consent", ConsentPage);
      return c.html(PageComponent({
        client,
        scopes: requestedScopes,
        user,
        responseType: response_type,
        redirectUri: redirect_uri,
        state,
        codeChallenge: code_challenge,
        codeChallengeMethod: code_challenge_method,
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] OAuth authorize error:", error);
      return c.html(OAuthErrorPage({
        error: "server_error",
        errorDescription: "An error occurred while processing your request",
        config: uiConfig
      }), 500);
    }
  });
  app.post("/oauth/consent", sessionAuth(sessionManager, { required: true }), async (c) => {
    const body = await c.req.parseBody();
    const {
      decision,
      trust_application,
      response_type,
      client_id,
      redirect_uri,
      scope,
      state,
      code_challenge,
      code_challenge_method = "plain"
    } = body;
    const user = c.get("user");
    try {
      if (decision === "deny") {
        const errorParams = new URLSearchParams({
          error: "access_denied",
          error_description: "User denied authorization"
        });
        if (state) {
          errorParams.set("state", state);
        }
        return c.redirect(`${redirect_uri}?${errorParams.toString()}`);
      }
      const authCode = generateAuthCode();
      const requestedScopes = scope ? scope.split(" ") : [];
      const expiresAt = new Date(Date.now() + 10 * 60 * 1e3).toISOString();
      const [okCode, errCode] = await tryFn(
        () => plugin.oauth2AuthCodesResource.insert({
          code: authCode,
          clientId: client_id,
          userId: user.id,
          redirectUri: redirect_uri,
          scope: requestedScopes,
          codeChallenge: code_challenge || null,
          codeChallengeMethod: code_challenge_method || "plain",
          expiresAt,
          used: false,
          trusted: trust_application === "1"
        })
      );
      if (!okCode) {
        console.error("[Identity Plugin] Failed to store auth code:", errCode);
        return c.html(OAuthErrorPage({
          error: "server_error",
          errorDescription: "Failed to generate authorization code",
          config: uiConfig
        }), 500);
      }
      if (trust_application === "1") {
      }
      const successParams = new URLSearchParams({
        code: authCode
      });
      if (state) {
        successParams.set("state", state);
      }
      return c.redirect(`${redirect_uri}?${successParams.toString()}`);
    } catch (error) {
      console.error("[Identity Plugin] OAuth consent error:", error);
      return c.html(`
        <html>
          <body>
            <h1>Server Error</h1>
            <p>An error occurred while processing your consent</p>
          </body>
        </html>
      `, 500);
    }
  });
  app.get("/verify-email", async (c) => {
    const token = c.req.query("token");
    const PageComponent = getPageComponent(customPages, "verifyEmail", VerifyEmailPage);
    if (!token) {
      return c.html(PageComponent({
        status: "pending",
        config: uiConfig
      }));
    }
    try {
      const [okUsers, errUsers, users] = await tryFn(
        () => usersResource.query({ emailVerificationToken: token })
      );
      if (!okUsers || !users || users.length === 0) {
        return c.html(PageComponent({
          status: "error",
          message: "Invalid verification link. It may have already been used or expired.",
          config: uiConfig
        }));
      }
      const user = users[0];
      if (user.emailVerified) {
        return c.html(PageComponent({
          status: "success",
          message: "Your email is already verified! You can sign in now.",
          config: uiConfig
        }));
      }
      if (user.emailVerificationExpiry) {
        if (isExpired(user.emailVerificationExpiry)) {
          return c.html(PageComponent({
            status: "expired",
            email: user.email,
            message: "This verification link has expired. Please request a new one.",
            config: uiConfig
          }));
        }
      }
      const verificationUpdate = {
        emailVerified: true,
        emailVerificationToken: null,
        emailVerificationExpiry: null,
        active: true
      };
      if (supportsStatusField) {
        verificationUpdate.status = "active";
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(user.id, verificationUpdate)
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Email verification update error:", errUpdate);
        return c.html(PageComponent({
          status: "error",
          message: "Failed to verify email. Please try again later.",
          config: uiConfig
        }));
      }
      return c.html(PageComponent({
        status: "success",
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] Email verification error:", error);
      return c.html(PageComponent({
        status: "error",
        message: "An error occurred while verifying your email.",
        config: uiConfig
      }));
    }
  });
  app.post("/verify-email/resend", async (c) => {
    const body = await c.req.parseBody();
    const { email } = body;
    const PageComponent = getPageComponent(customPages, "verifyEmail", VerifyEmailPage);
    if (!email) {
      return c.html(PageComponent({
        status: "error",
        message: "Email address is required.",
        config: uiConfig
      }));
    }
    try {
      const [okUsers, errUsers, users] = await tryFn(
        () => usersResource.query({ email: email.toLowerCase().trim() })
      );
      if (!okUsers || !users || users.length === 0) {
        return c.html(PageComponent({
          status: "pending",
          message: "If an account exists with this email, a verification link has been sent.",
          config: uiConfig
        }));
      }
      const user = users[0];
      if (user.emailVerified) {
        return c.html(PageComponent({
          status: "success",
          message: "Your email is already verified! You can sign in now.",
          config: uiConfig
        }));
      }
      const verificationToken = generatePasswordResetToken();
      const verificationExpiry = calculateExpiration("24h");
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(user.id, {
          emailVerificationToken: verificationToken,
          emailVerificationExpiry: verificationExpiry
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Verification token update error:", errUpdate);
        return c.html(PageComponent({
          status: "error",
          message: "Failed to send verification email. Please try again later.",
          config: uiConfig
        }));
      }
      if (plugin.emailService) {
        await plugin.emailService.sendEmailVerificationEmail({
          to: user.email,
          name: user.name,
          verificationToken
        });
      }
      return c.html(PageComponent({
        status: "pending",
        email: user.email,
        message: "A new verification link has been sent to your email address.",
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] Resend verification error:", error);
      return c.html(PageComponent({
        status: "error",
        message: "An error occurred. Please try again later.",
        config: uiConfig
      }));
    }
  });
}
function formatUptime(seconds) {
  const days = Math.floor(seconds / 86400);
  const hours = Math.floor(seconds % 86400 / 3600);
  const minutes = Math.floor(seconds % 3600 / 60);
  const parts = [];
  if (days > 0) parts.push(`${days}d`);
  if (hours > 0) parts.push(`${hours}h`);
  if (minutes > 0) parts.push(`${minutes}m`);
  return parts.length > 0 ? parts.join(" ") : "< 1m";
}

var routes = /*#__PURE__*/Object.freeze({
  __proto__: null,
  registerUIRoutes: registerUIRoutes
});

export { AVAILABLE_BEHAVIORS, AnalyticsNotEnabledError, ApiPlugin, AuditPlugin, AuthenticationError, AwsInventoryDriver, AwsMockDriver, AzureMockDriver, BACKUP_DRIVERS, BackupPlugin, BaseBackupDriver, BaseCloudDriver, BaseError, BaseReplicator, BehaviorError, BigqueryReplicator, CONSUMER_DRIVERS, Cache, CachePlugin, S3Client as Client, CloudInventoryPlugin, ConnectionString, ConnectionStringError, CookieFarmPlugin, CookieFarmSuitePlugin, CostsPlugin, CryptoError, DEFAULT_BEHAVIOR, Database, DatabaseError, DigitalOceanMockDriver, DynamoDBReplicator, EncryptionError, ErrorMap, EventualConsistencyPlugin, Factory, FilesystemBackupDriver, FilesystemCache, FullTextPlugin, GcpMockDriver, GeoPlugin, IdentityPlugin, ImporterPlugin, InvalidResourceItem, MLPlugin, MemoryCache, MemoryClient, MemoryStorage, MetadataLimitError, MetricsPlugin, MissingMetadata, MongoDBReplicator, MultiBackupDriver, MySQLReplicator, NoSuchBucket, NoSuchKey, NotFound, OracleMockDriver, PartitionAwareFilesystemCache, PartitionDriverError, PartitionError, PermissionError, PlanetScaleReplicator, Plugin, PluginError, PluginObject, PluginStorageError, PostgresReplicator, PuppeteerPlugin, QueueConsumerPlugin, REPLICATOR_DRIVERS, RabbitMqConsumer, RelationPlugin, ReplicatorPlugin, Resource, ResourceError, ResourceIdsPageReader, ResourceIdsReader, ResourceNotFound, ResourceReader, ResourceWriter, S3BackupDriver, S3Cache, S3Client, S3QueuePlugin, Database as S3db, S3dbError, S3dbReplicator, SchedulerPlugin, Schema, SchemaError, Seeder, SpiderSuitePlugin, SqsConsumer, SqsReplicator, StateMachinePlugin, StreamError, TTLPlugin, TfStatePlugin, Transformers, TursoReplicator, UnknownError, ValidationError, Validator, VectorPlugin, VultrMockDriver, WebhookReplicator, behaviors, calculateAttributeNamesSize, calculateAttributeSizes, calculateEffectiveLimit, calculateSystemOverhead, calculateTotalSize, calculateUTF8Bytes, clearUTF8Memory, compactHash, createBackupDriver, createCloudDriver, createConsumer, createCustomGenerator, createReplicator, decode, decodeDecimal, decodeFixedPoint, decodeFixedPointBatch, decrypt, S3db as default, encode, encodeDecimal, encodeFixedPoint, encodeFixedPointBatch, encrypt, expandHash, generateTypes, getBehavior, getNanoidInitializationError, getSizeBreakdown, getUrlAlphabet, hashPassword, hashPasswordSync, idGenerator, initializeNanoid, isBcryptHash, listCloudDrivers, mapAwsError, md5, passwordGenerator, printTypes, registerCloudDriver, sha256, streamToString, transformValue, tryFn, tryFnSync, validateBackupConfig, validateCloudDefinition, validateReplicatorConfig, verifyPassword$1 as verifyPassword };
//# sourceMappingURL=s3db.es.js.map

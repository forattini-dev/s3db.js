import crypto$1, { createHash, createVerify, generateKeyPairSync, createPublicKey, createSign, randomBytes } from 'crypto';
import EventEmitter from 'events';
import { Hono } from 'hono';
import fs, { mkdir, copyFile, unlink, stat, access, readdir, writeFile, readFile as readFile$1, rm, watch } from 'fs/promises';
import path$1, { sep as sep$1, join, dirname } from 'path';
import fs$1, { createReadStream, promises as promises$1, createWriteStream, realpathSync as realpathSync$1, readlinkSync, readdirSync, readdir as readdir$2, lstatSync, existsSync, readFileSync } from 'fs';
import { HeadObjectCommand, GetObjectCommand, S3Client as S3Client$1, PutObjectCommand, CopyObjectCommand, DeleteObjectCommand, DeleteObjectsCommand, ListObjectsV2Command } from '@aws-sdk/client-s3';
import { Buffer as Buffer$1 } from 'buffer';
import os, { homedir } from 'os';
import { pipeline } from 'stream/promises';
import require$$0$2, { Transform, Writable, Readable } from 'stream';
import zlib from 'node:zlib';
import jsonStableStringify from 'json-stable-stringify';
import os$1 from 'node:os';
import { PromisePool } from '@supercharge/promise-pool';
import { customAlphabet, urlAlphabet } from 'nanoid';
import { merge, isString, isEmpty, invert, uniq, cloneDeep, get, set, isObject as isObject$1, chunk, isFunction as isFunction$1 } from 'lodash-es';
import { flatten, unflatten } from 'flat';
import FastestValidator from 'fastest-validator';
import { ReadableStream } from 'node:stream/web';
import require$$0$3, { Agent } from 'http';
import require$$1, { Agent as Agent$1 } from 'https';
import { NodeHttpHandler } from '@smithy/node-http-handler';
import { fileURLToPath } from 'node:url';
import { win32, posix } from 'node:path';
import * as actualFS from 'node:fs';
import { realpath, readlink, readdir as readdir$1, lstat } from 'node:fs/promises';
import { EventEmitter as EventEmitter$1 } from 'node:events';
import Stream from 'node:stream';
import { StringDecoder } from 'node:string_decoder';
import require$$3, { gzip, brotliCompress } from 'zlib';
import require$$1$1, { promisify } from 'util';
import require$$0$1, { fileURLToPath as fileURLToPath$1 } from 'url';
import require$$7 from 'net';
import require$$4 from 'dns';
import require$$1$2 from 'tls';
import require$$0$4 from 'child_process';

function _mergeNamespaces(n, m) {
  m.forEach(function (e) {
    e && typeof e !== 'string' && !Array.isArray(e) && Object.keys(e).forEach(function (k) {
      if (k !== 'default' && !(k in n)) {
        var d = Object.getOwnPropertyDescriptor(e, k);
        Object.defineProperty(n, k, d.get ? d : {
          enumerable: true,
          get: function () { return e[k]; }
        });
      }
    });
  });
  return Object.freeze(n);
}

const alphabet = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
const base = alphabet.length;
const charToValue = Object.fromEntries([...alphabet].map((c, i) => [c, i]));
const encode$1 = (n) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  if (n === 0) return alphabet[0];
  if (n < 0) return "-" + encode$1(-Math.floor(n));
  n = Math.floor(n);
  let s = "";
  while (n) {
    s = alphabet[n % base] + s;
    n = Math.floor(n / base);
  }
  return s;
};
const decode$1 = (s) => {
  if (typeof s !== "string") return NaN;
  if (s === "") return 0;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  let r = 0;
  for (let i = 0; i < s.length; i++) {
    const idx = charToValue[s[i]];
    if (idx === void 0) return NaN;
    r = r * base + idx;
  }
  return negative ? -r : r;
};
const encodeDecimal = (n) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  const negative = n < 0;
  n = Math.abs(n);
  const [intPart, decPart] = n.toString().split(".");
  const encodedInt = encode$1(Number(intPart));
  if (decPart) {
    return (negative ? "-" : "") + encodedInt + "." + decPart;
  }
  return (negative ? "-" : "") + encodedInt;
};
const decodeDecimal = (s) => {
  if (typeof s !== "string") return NaN;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  const [intPart, decPart] = s.split(".");
  const decodedInt = decode$1(intPart);
  if (isNaN(decodedInt)) return NaN;
  const num = decPart ? Number(decodedInt + "." + decPart) : decodedInt;
  return negative ? -num : num;
};
const encodeFixedPoint = (n, precision = 6) => {
  if (typeof n !== "number" || isNaN(n)) return "undefined";
  if (!isFinite(n)) return "undefined";
  const scale = Math.pow(10, precision);
  const scaled = Math.round(n * scale);
  if (scaled === 0) return "^0";
  const negative = scaled < 0;
  let num = Math.abs(scaled);
  let s = "";
  while (num > 0) {
    s = alphabet[num % base] + s;
    num = Math.floor(num / base);
  }
  return "^" + (negative ? "-" : "") + s;
};
const decodeFixedPoint = (s, precision = 6) => {
  if (typeof s !== "string") return NaN;
  if (!s.startsWith("^")) return NaN;
  s = s.slice(1);
  if (s === "0") return 0;
  let negative = false;
  if (s[0] === "-") {
    negative = true;
    s = s.slice(1);
  }
  let r = 0;
  for (let i = 0; i < s.length; i++) {
    const idx = charToValue[s[i]];
    if (idx === void 0) return NaN;
    r = r * base + idx;
  }
  const scale = Math.pow(10, precision);
  const scaled = negative ? -r : r;
  return scaled / scale;
};
const encodeFixedPointBatch = (values, precision = 6) => {
  if (!Array.isArray(values)) return "";
  if (values.length === 0) return "^[]";
  const scale = Math.pow(10, precision);
  const encoded = values.map((n) => {
    if (typeof n !== "number" || isNaN(n) || !isFinite(n)) return "";
    const scaled = Math.round(n * scale);
    if (scaled === 0) return "0";
    const negative = scaled < 0;
    let num = Math.abs(scaled);
    let s = "";
    while (num > 0) {
      s = alphabet[num % base] + s;
      num = Math.floor(num / base);
    }
    return (negative ? "-" : "") + s;
  });
  return "^[" + encoded.join(",") + "]";
};
const decodeFixedPointBatch = (s, precision = 6) => {
  if (typeof s !== "string") return [];
  if (!s.startsWith("^[")) return [];
  s = s.slice(2, -1);
  if (s === "") return [];
  const parts = s.split(",");
  const scale = Math.pow(10, precision);
  return parts.map((part) => {
    if (part === "0") return 0;
    if (part === "") return NaN;
    let negative = false;
    if (part[0] === "-") {
      negative = true;
      part = part.slice(1);
    }
    let r = 0;
    for (let i = 0; i < part.length; i++) {
      const idx = charToValue[part[i]];
      if (idx === void 0) return NaN;
      r = r * base + idx;
    }
    const scaled = negative ? -r : r;
    return scaled / scale;
  });
};

const utf8BytesMemory = /* @__PURE__ */ new Map();
const UTF8_MEMORY_MAX_SIZE = 1e4;
function calculateUTF8Bytes(str) {
  if (typeof str !== "string") {
    str = String(str);
  }
  if (utf8BytesMemory.has(str)) {
    return utf8BytesMemory.get(str);
  }
  let bytes = 0;
  for (let i = 0; i < str.length; i++) {
    const codePoint = str.codePointAt(i);
    if (codePoint <= 127) {
      bytes += 1;
    } else if (codePoint <= 2047) {
      bytes += 2;
    } else if (codePoint <= 65535) {
      bytes += 3;
    } else if (codePoint <= 1114111) {
      bytes += 4;
      if (codePoint > 65535) {
        i++;
      }
    }
  }
  if (utf8BytesMemory.size < UTF8_MEMORY_MAX_SIZE) {
    utf8BytesMemory.set(str, bytes);
  } else if (utf8BytesMemory.size === UTF8_MEMORY_MAX_SIZE) {
    const entriesToDelete = Math.floor(UTF8_MEMORY_MAX_SIZE / 2);
    let deleted = 0;
    for (const key of utf8BytesMemory.keys()) {
      if (deleted >= entriesToDelete) break;
      utf8BytesMemory.delete(key);
      deleted++;
    }
    utf8BytesMemory.set(str, bytes);
  }
  return bytes;
}
function clearUTF8Memory() {
  utf8BytesMemory.clear();
}
function calculateAttributeNamesSize(mappedObject) {
  let totalSize = 0;
  for (const key of Object.keys(mappedObject)) {
    totalSize += calculateUTF8Bytes(key);
  }
  return totalSize;
}
function transformValue(value) {
  if (value === null || value === void 0) {
    return "";
  }
  if (typeof value === "boolean") {
    return value ? "1" : "0";
  }
  if (typeof value === "number") {
    return String(value);
  }
  if (typeof value === "string") {
    return value;
  }
  if (Array.isArray(value)) {
    if (value.length === 0) {
      return "[]";
    }
    return value.map((item) => String(item)).join("|");
  }
  if (typeof value === "object") {
    return JSON.stringify(value);
  }
  return String(value);
}
function calculateAttributeSizes(mappedObject) {
  const sizes = {};
  for (const [key, value] of Object.entries(mappedObject)) {
    const transformedValue = transformValue(value);
    const byteSize = calculateUTF8Bytes(transformedValue);
    sizes[key] = byteSize;
  }
  return sizes;
}
function calculateTotalSize(mappedObject) {
  const valueSizes = calculateAttributeSizes(mappedObject);
  const valueTotal = Object.values(valueSizes).reduce((total, size) => total + size, 0);
  const namesSize = calculateAttributeNamesSize(mappedObject);
  return valueTotal + namesSize;
}
function getSizeBreakdown(mappedObject) {
  const valueSizes = calculateAttributeSizes(mappedObject);
  const namesSize = calculateAttributeNamesSize(mappedObject);
  const valueTotal = Object.values(valueSizes).reduce((sum, size) => sum + size, 0);
  const total = valueTotal + namesSize;
  const sortedAttributes = Object.entries(valueSizes).sort(([, a], [, b]) => b - a).map(([key, size]) => ({
    attribute: key,
    size,
    percentage: (size / total * 100).toFixed(2) + "%"
  }));
  return {
    total,
    valueSizes,
    namesSize,
    valueTotal,
    breakdown: sortedAttributes,
    // Add detailed breakdown including names
    detailedBreakdown: {
      values: valueTotal,
      names: namesSize,
      total
    }
  };
}
function calculateSystemOverhead(config = {}) {
  const { version = "1", timestamps = false, id = "" } = config;
  const systemFields = {
    "_v": String(version)
    // Version field (e.g., "1", "10", "100")
  };
  if (timestamps) {
    systemFields.createdAt = "2024-01-01T00:00:00.000Z";
    systemFields.updatedAt = "2024-01-01T00:00:00.000Z";
  }
  if (id) {
    systemFields.id = id;
  }
  const overheadObject = {};
  for (const [key, value] of Object.entries(systemFields)) {
    overheadObject[key] = value;
  }
  return calculateTotalSize(overheadObject);
}
function calculateEffectiveLimit(config = {}) {
  const { s3Limit = 2048, systemConfig = {} } = config;
  const overhead = calculateSystemOverhead(systemConfig);
  return s3Limit - overhead;
}

class BaseError extends Error {
  constructor({ verbose, bucket, key, message, code, statusCode, requestId, awsMessage, original, commandName, commandInput, metadata, description, ...rest }) {
    if (verbose) message = message + `

Verbose:

${JSON.stringify(rest, null, 2)}`;
    super(message);
    if (typeof Error.captureStackTrace === "function") {
      Error.captureStackTrace(this, this.constructor);
    } else {
      this.stack = new Error(message).stack;
    }
    super.name = this.constructor.name;
    this.name = this.constructor.name;
    this.bucket = bucket;
    this.key = key;
    this.thrownAt = /* @__PURE__ */ new Date();
    this.code = code;
    this.statusCode = statusCode;
    this.requestId = requestId;
    this.awsMessage = awsMessage;
    this.original = original;
    this.commandName = commandName;
    this.commandInput = commandInput;
    this.metadata = metadata;
    this.description = description;
    this.data = { bucket, key, ...rest, verbose, message };
  }
  toJson() {
    return {
      name: this.name,
      message: this.message,
      code: this.code,
      statusCode: this.statusCode,
      requestId: this.requestId,
      awsMessage: this.awsMessage,
      bucket: this.bucket,
      key: this.key,
      thrownAt: this.thrownAt,
      commandName: this.commandName,
      commandInput: this.commandInput,
      metadata: this.metadata,
      description: this.description,
      data: this.data,
      original: this.original,
      stack: this.stack
    };
  }
  toString() {
    return `${this.name} | ${this.message}`;
  }
}
class S3dbError extends BaseError {
  constructor(message, details = {}) {
    let code, statusCode, requestId, awsMessage, original, metadata;
    if (details.original) {
      original = details.original;
      code = original.code || original.Code || original.name;
      statusCode = original.statusCode || original.$metadata && original.$metadata.httpStatusCode;
      requestId = original.requestId || original.$metadata && original.$metadata.requestId;
      awsMessage = original.message;
      metadata = original.$metadata ? { ...original.$metadata } : void 0;
    }
    super({ message, ...details, code, statusCode, requestId, awsMessage, original, metadata });
  }
}
class DatabaseError extends S3dbError {
  constructor(message, details = {}) {
    super(message, details);
    Object.assign(this, details);
  }
}
class ValidationError extends S3dbError {
  constructor(message, details = {}) {
    super(message, details);
    Object.assign(this, details);
  }
}
class AuthenticationError extends S3dbError {
  constructor(message, details = {}) {
    super(message, details);
    Object.assign(this, details);
  }
}
class PermissionError extends S3dbError {
  constructor(message, details = {}) {
    super(message, details);
    Object.assign(this, details);
  }
}
class EncryptionError extends S3dbError {
  constructor(message, details = {}) {
    super(message, details);
    Object.assign(this, details);
  }
}
class ResourceNotFound extends S3dbError {
  constructor({ bucket, resourceName, id, original, ...rest }) {
    if (typeof id !== "string") throw new Error("id must be a string");
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    if (typeof resourceName !== "string") throw new Error("resourceName must be a string");
    super(`Resource not found: ${resourceName}/${id} [bucket:${bucket}]`, {
      bucket,
      resourceName,
      id,
      original,
      ...rest
    });
  }
}
class NoSuchBucket extends S3dbError {
  constructor({ bucket, original, ...rest }) {
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    super(`Bucket does not exists [bucket:${bucket}]`, { bucket, original, ...rest });
  }
}
class NoSuchKey extends S3dbError {
  constructor({ bucket, key, resourceName, id, original, ...rest }) {
    if (typeof key !== "string") throw new Error("key must be a string");
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    if (id !== void 0 && typeof id !== "string") throw new Error("id must be a string");
    super(`No such key: ${key} [bucket:${bucket}]`, { bucket, key, resourceName, id, original, ...rest });
    this.resourceName = resourceName;
    this.id = id;
  }
}
class NotFound extends S3dbError {
  constructor({ bucket, key, resourceName, id, original, ...rest }) {
    if (typeof key !== "string") throw new Error("key must be a string");
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    super(`Not found: ${key} [bucket:${bucket}]`, { bucket, key, resourceName, id, original, ...rest });
    this.resourceName = resourceName;
    this.id = id;
  }
}
class MissingMetadata extends S3dbError {
  constructor({ bucket, original, ...rest }) {
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    super(`Missing metadata for bucket [bucket:${bucket}]`, { bucket, original, ...rest });
  }
}
class InvalidResourceItem extends S3dbError {
  constructor({
    bucket,
    resourceName,
    attributes,
    validation,
    message,
    original,
    ...rest
  }) {
    if (typeof bucket !== "string") throw new Error("bucket must be a string");
    if (typeof resourceName !== "string") throw new Error("resourceName must be a string");
    super(
      message || `Validation error: This item is not valid. Resource=${resourceName} [bucket:${bucket}].
${JSON.stringify(validation, null, 2)}`,
      {
        bucket,
        resourceName,
        attributes,
        validation,
        original,
        ...rest
      }
    );
  }
}
class UnknownError extends S3dbError {
}
const ErrorMap = {
  "NotFound": NotFound,
  "NoSuchKey": NoSuchKey,
  "UnknownError": UnknownError,
  "NoSuchBucket": NoSuchBucket,
  "MissingMetadata": MissingMetadata,
  "InvalidResourceItem": InvalidResourceItem
};
function mapAwsError(err, context = {}) {
  const code = err.code || err.Code || err.name;
  const metadata = err.$metadata ? { ...err.$metadata } : void 0;
  const commandName = context.commandName;
  const commandInput = context.commandInput;
  let description;
  if (code === "NoSuchKey" || code === "NotFound") {
    description = "The specified key does not exist in the bucket. Check if the key exists and if your credentials have permission to access it.";
    return new NoSuchKey({ ...context, original: err, metadata, commandName, commandInput, description });
  }
  if (code === "NoSuchBucket") {
    description = "The specified bucket does not exist. Check if the bucket name is correct and if your credentials have permission to access it.";
    return new NoSuchBucket({ ...context, original: err, metadata, commandName, commandInput, description });
  }
  if (code === "AccessDenied" || err.statusCode === 403 || code === "Forbidden") {
    description = "Access denied. Check your AWS credentials, IAM permissions, and bucket policy.";
    return new PermissionError("Access denied", { ...context, original: err, metadata, commandName, commandInput, description });
  }
  if (code === "ValidationError" || err.statusCode === 400) {
    description = "Validation error. Check the request parameters and payload format.";
    return new ValidationError("Validation error", { ...context, original: err, metadata, commandName, commandInput, description });
  }
  if (code === "MissingMetadata") {
    description = "Object metadata is missing or invalid. Check if the object was uploaded correctly.";
    return new MissingMetadata({ ...context, original: err, metadata, commandName, commandInput, description });
  }
  const errorDetails = [
    `Unknown error: ${err.message || err.toString()}`,
    err.code && `Code: ${err.code}`,
    err.statusCode && `Status: ${err.statusCode}`,
    err.stack && `Stack: ${err.stack.split("\n")[0]}`
  ].filter(Boolean).join(" | ");
  description = `Check the error details and AWS documentation. Original error: ${err.message || err.toString()}`;
  return new UnknownError(errorDetails, { ...context, original: err, metadata, commandName, commandInput, description });
}
class ConnectionStringError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Invalid connection string format. Check the connection string syntax and credentials.";
    super(message, { ...details, description });
  }
}
class CryptoError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Cryptography operation failed. Check if the crypto library is available and input is valid.";
    super(message, { ...details, description });
  }
}
class SchemaError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Schema validation failed. Check schema definition and input data format.";
    super(message, { ...details, description });
  }
}
class ResourceError extends S3dbError {
  constructor(message, details = {}) {
    const description = details.description || "Resource operation failed. Check resource configuration, attributes, and operation context.";
    super(message, { ...details, description });
    Object.assign(this, details);
  }
}
class PartitionError extends S3dbError {
  constructor(message, details = {}) {
    let description = details.description;
    if (!description && details.resourceName && details.partitionName && details.fieldName) {
      const { resourceName, partitionName, fieldName, availableFields = [] } = details;
      description = `
Partition Field Validation Error

Resource: ${resourceName}
Partition: ${partitionName}
Missing Field: ${fieldName}

Available fields in schema:
${availableFields.map((f) => `  \u2022 ${f}`).join("\n") || "  (no fields defined)"}

Possible causes:
1. Field was removed from schema but partition still references it
2. Typo in partition field name
3. Nested field path is incorrect (use dot notation like 'utm.source')

Solution:
${details.strictValidation === false ? "  \u2022 Update partition definition to use existing fields" : `  \u2022 Add missing field to schema, OR
  \u2022 Update partition definition to use existing fields, OR
  \u2022 Use strictValidation: false to skip this check during testing`}

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#partitions
`.trim();
    }
    super(message, {
      ...details,
      description
    });
  }
}
class AnalyticsNotEnabledError extends S3dbError {
  constructor(details = {}) {
    const {
      pluginName = "EventualConsistency",
      resourceName = "unknown",
      field = "unknown",
      configuredResources = [],
      registeredResources = [],
      pluginInitialized = false,
      ...rest
    } = details;
    const message = `Analytics not enabled for ${resourceName}.${field}`;
    const description = `
Analytics Not Enabled

Plugin: ${pluginName}
Resource: ${resourceName}
Field: ${field}

Diagnostics:
  \u2022 Plugin initialized: ${pluginInitialized ? "\u2713 Yes" : "\u2717 No"}
  \u2022 Analytics resources created: ${registeredResources.length}/${configuredResources.length}
${configuredResources.map((r) => {
      const exists = registeredResources.includes(r);
      return `    ${exists ? "\u2713" : "\u2717"} ${r}${!exists ? " (missing)" : ""}`;
    }).join("\n")}

Possible causes:
1. Resource not created yet - Analytics resources are created when db.createResource() is called
2. Resource created before plugin initialization - Plugin must be initialized before resources
3. Field not configured in analytics.resources config

Correct initialization order:
  1. Create database: const db = new Database({ ... })
  2. Install plugins: await db.connect() (triggers plugin.install())
  3. Create resources: await db.createResource({ name: '${resourceName}', ... })
  4. Analytics resources are auto-created by plugin

Example fix:
  const db = new Database({
    bucket: 'my-bucket',
    plugins: [new EventualConsistencyPlugin({
      resources: {
        '${resourceName}': {
          fields: {
            '${field}': { type: 'counter', analytics: true }
          }
        }
      }
    })]
  });

  await db.connect();  // Plugin initialized here
  await db.createResource({ name: '${resourceName}', ... });  // Analytics resource created here

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/eventual-consistency.md
`.trim();
    super(message, {
      ...rest,
      pluginName,
      resourceName,
      field,
      configuredResources,
      registeredResources,
      pluginInitialized,
      description
    });
  }
}
class PluginError extends S3dbError {
  constructor(message, details = {}) {
    const {
      pluginName = "Unknown",
      operation = "unknown",
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Plugin Error

Plugin: ${pluginName}
Operation: ${operation}

Possible causes:
1. Plugin not properly initialized
2. Plugin configuration is invalid
3. Plugin dependencies not met
4. Plugin method called before installation

Solution:
Ensure plugin is added to database and connect() is called before usage.

Example:
  const db = new Database({
    bucket: 'my-bucket',
    plugins: [new ${pluginName}({ /* config */ })]
  });

  await db.connect();  // Plugin installed here
  // Now plugin methods are available

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/README.md
`.trim();
    }
    super(message, {
      ...rest,
      pluginName,
      operation,
      description
    });
  }
}
class PluginStorageError extends S3dbError {
  constructor(message, details = {}) {
    const {
      pluginSlug = "unknown",
      key = "",
      operation = "unknown",
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Plugin Storage Error

Plugin: ${pluginSlug}
Key: ${key}
Operation: ${operation}

Possible causes:
1. Storage not initialized (plugin not installed)
2. Invalid key format
3. S3 operation failed
4. Permissions issue

Solution:
Ensure plugin has access to storage and key is valid.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/README.md#plugin-storage
`.trim();
    }
    super(message, {
      ...rest,
      pluginSlug,
      key,
      operation,
      description
    });
  }
}
class PartitionDriverError extends S3dbError {
  constructor(message, details = {}) {
    const {
      driver = "unknown",
      operation = "unknown",
      queueSize,
      maxQueueSize,
      ...rest
    } = details;
    let description = details.description;
    if (!description && queueSize !== void 0 && maxQueueSize !== void 0) {
      description = `
Partition Driver Error

Driver: ${driver}
Operation: ${operation}
Queue Status: ${queueSize}/${maxQueueSize}

Possible causes:
1. Queue is full (backpressure)
2. Driver not properly configured
3. SQS permissions issue (if using SQS driver)

Solution:
${queueSize >= maxQueueSize ? "Wait for queue to drain or increase maxQueueSize" : "Check driver configuration and permissions"}
`.trim();
    } else if (!description) {
      description = `
Partition Driver Error

Driver: ${driver}
Operation: ${operation}

Check driver configuration and permissions.
`.trim();
    }
    super(message, {
      ...rest,
      driver,
      operation,
      queueSize,
      maxQueueSize,
      description
    });
  }
}
class BehaviorError extends S3dbError {
  constructor(message, details = {}) {
    const {
      behavior = "unknown",
      availableBehaviors = [],
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Behavior Error

Requested: ${behavior}
Available: ${availableBehaviors.join(", ") || "body-overflow, body-only, truncate-data, enforce-limits, user-managed"}

Possible causes:
1. Behavior name misspelled
2. Custom behavior not registered

Solution:
Use one of the available behaviors or register custom behavior.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#behaviors
`.trim();
    }
    super(message, {
      ...rest,
      behavior,
      availableBehaviors,
      description
    });
  }
}
class StreamError extends S3dbError {
  constructor(message, details = {}) {
    const {
      operation = "unknown",
      resource,
      ...rest
    } = details;
    let description = details.description;
    if (!description) {
      description = `
Stream Error

Operation: ${operation}
${resource ? `Resource: ${resource}` : ""}

Possible causes:
1. Stream not properly initialized
2. Resource not available
3. Network error during streaming

Solution:
Check stream configuration and resource availability.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#streaming
`.trim();
    }
    super(message, {
      ...rest,
      operation,
      resource,
      description
    });
  }
}
class MetadataLimitError extends S3dbError {
  constructor(message, details = {}) {
    const {
      totalSize,
      effectiveLimit,
      absoluteLimit = 2047,
      excess,
      resourceName,
      operation,
      ...rest
    } = details;
    let description = details.description;
    if (!description && totalSize && effectiveLimit) {
      description = `
S3 Metadata Size Limit Exceeded

Current Size: ${totalSize} bytes
Effective Limit: ${effectiveLimit} bytes
Absolute Limit: ${absoluteLimit} bytes
${excess ? `Excess: ${excess} bytes` : ""}
${resourceName ? `Resource: ${resourceName}` : ""}
${operation ? `Operation: ${operation}` : ""}

S3 has a hard limit of 2KB (2047 bytes) for object metadata.

Solutions:
1. Use 'body-overflow' behavior to store excess in body
2. Use 'body-only' behavior to store everything in body
3. Reduce number of fields
4. Use shorter field values
5. Enable advanced metadata encoding

Example:
  await db.createResource({
    name: '${resourceName || "myResource"}',
    behavior: 'body-overflow',  // Automatically handles overflow
    attributes: { ... }
  });

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/README.md#metadata-size-limits
`.trim();
    }
    super(message, {
      ...rest,
      totalSize,
      effectiveLimit,
      absoluteLimit,
      excess,
      resourceName,
      operation,
      description
    });
  }
}

function tryFn(fnOrPromise) {
  if (fnOrPromise == null) {
    const err = new Error("fnOrPromise cannot be null or undefined");
    err.stack = new Error().stack;
    return [false, err, void 0];
  }
  if (typeof fnOrPromise === "function") {
    try {
      const result = fnOrPromise();
      if (result == null) {
        return [true, null, result];
      }
      if (typeof result.then === "function") {
        return result.then((data) => [true, null, data]).catch((error) => {
          if (error instanceof Error && Object.isExtensible(error)) {
            const desc = Object.getOwnPropertyDescriptor(error, "stack");
            if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
              try {
                error.stack = new Error().stack;
              } catch (_) {
              }
            }
          }
          return [false, error, void 0];
        });
      }
      return [true, null, result];
    } catch (error) {
      if (error instanceof Error && Object.isExtensible(error)) {
        const desc = Object.getOwnPropertyDescriptor(error, "stack");
        if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
          try {
            error.stack = new Error().stack;
          } catch (_) {
          }
        }
      }
      return [false, error, void 0];
    }
  }
  if (typeof fnOrPromise.then === "function") {
    return Promise.resolve(fnOrPromise).then((data) => [true, null, data]).catch((error) => {
      if (error instanceof Error && Object.isExtensible(error)) {
        const desc = Object.getOwnPropertyDescriptor(error, "stack");
        if (desc && desc.writable && desc.configurable && error.hasOwnProperty("stack")) {
          try {
            error.stack = new Error().stack;
          } catch (_) {
          }
        }
      }
      return [false, error, void 0];
    });
  }
  return [true, null, fnOrPromise];
}
function tryFnSync(fn) {
  try {
    const result = fn();
    return [true, null, result];
  } catch (err) {
    return [false, err, null];
  }
}

async function dynamicCrypto() {
  let lib;
  if (typeof process !== "undefined") {
    lib = crypto$1.webcrypto;
  } else if (typeof window !== "undefined") {
    lib = window.crypto;
  }
  if (!lib) throw new CryptoError("Could not load any crypto library", { context: "dynamicCrypto" });
  return lib;
}
async function sha256(message) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encoder = new TextEncoder();
  const data = encoder.encode(message);
  const [ok, err, hashBuffer] = await tryFn(() => cryptoLib.subtle.digest("SHA-256", data));
  if (!ok) throw new CryptoError("SHA-256 digest failed", { original: err, input: message });
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashHex = hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  return hashHex;
}
async function encrypt(content, passphrase) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const salt = cryptoLib.getRandomValues(new Uint8Array(16));
  const [okKey, errKey, key] = await tryFn(() => getKeyMaterial(passphrase, salt));
  if (!okKey) throw new CryptoError("Key derivation failed", { original: errKey, passphrase, salt });
  const iv = cryptoLib.getRandomValues(new Uint8Array(12));
  const encoder = new TextEncoder();
  const encodedContent = encoder.encode(content);
  const [okEnc, errEnc, encryptedContent] = await tryFn(() => cryptoLib.subtle.encrypt({ name: "AES-GCM", iv }, key, encodedContent));
  if (!okEnc) throw new CryptoError("Encryption failed", { original: errEnc, content });
  const encryptedData = new Uint8Array(salt.length + iv.length + encryptedContent.byteLength);
  encryptedData.set(salt);
  encryptedData.set(iv, salt.length);
  encryptedData.set(new Uint8Array(encryptedContent), salt.length + iv.length);
  return arrayBufferToBase64(encryptedData);
}
async function decrypt(encryptedBase64, passphrase) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encryptedData = base64ToArrayBuffer(encryptedBase64);
  const salt = encryptedData.slice(0, 16);
  const iv = encryptedData.slice(16, 28);
  const encryptedContent = encryptedData.slice(28);
  const [okKey, errKey, key] = await tryFn(() => getKeyMaterial(passphrase, salt));
  if (!okKey) throw new CryptoError("Key derivation failed (decrypt)", { original: errKey, passphrase, salt });
  const [okDec, errDec, decryptedContent] = await tryFn(() => cryptoLib.subtle.decrypt({ name: "AES-GCM", iv }, key, encryptedContent));
  if (!okDec) throw new CryptoError("Decryption failed", { original: errDec, encryptedBase64 });
  const decoder = new TextDecoder();
  return decoder.decode(decryptedContent);
}
async function md5(data) {
  if (typeof process === "undefined") {
    throw new CryptoError("MD5 hashing is only available in Node.js environment", { context: "md5" });
  }
  const [ok, err, result] = await tryFn(async () => {
    return crypto$1.createHash("md5").update(data).digest("base64");
  });
  if (!ok) {
    throw new CryptoError("MD5 hashing failed", { original: err, data });
  }
  return result;
}
async function getKeyMaterial(passphrase, salt) {
  const [okCrypto, errCrypto, cryptoLib] = await tryFn(dynamicCrypto);
  if (!okCrypto) throw new CryptoError("Crypto API not available", { original: errCrypto });
  const encoder = new TextEncoder();
  const keyMaterial = encoder.encode(passphrase);
  const [okImport, errImport, baseKey] = await tryFn(() => cryptoLib.subtle.importKey(
    "raw",
    keyMaterial,
    { name: "PBKDF2" },
    false,
    ["deriveKey"]
  ));
  if (!okImport) throw new CryptoError("importKey failed", { original: errImport, passphrase });
  const [okDerive, errDerive, derivedKey] = await tryFn(() => cryptoLib.subtle.deriveKey(
    {
      name: "PBKDF2",
      salt,
      iterations: 1e5,
      hash: "SHA-256"
    },
    baseKey,
    { name: "AES-GCM", length: 256 },
    true,
    ["encrypt", "decrypt"]
  ));
  if (!okDerive) throw new CryptoError("deriveKey failed", { original: errDerive, passphrase, salt });
  return derivedKey;
}
function arrayBufferToBase64(buffer) {
  if (typeof process !== "undefined") {
    return Buffer.from(buffer).toString("base64");
  } else {
    const [ok, err, binary] = tryFnSync(() => String.fromCharCode.apply(null, new Uint8Array(buffer)));
    if (!ok) throw new CryptoError("Failed to convert ArrayBuffer to base64 (browser)", { original: err });
    return window.btoa(binary);
  }
}
function base64ToArrayBuffer(base64) {
  if (typeof process !== "undefined") {
    return new Uint8Array(Buffer.from(base64, "base64"));
  } else {
    const [ok, err, binaryString] = tryFnSync(() => window.atob(base64));
    if (!ok) throw new CryptoError("Failed to decode base64 (browser)", { original: err });
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes;
  }
}

const idGenerator = customAlphabet(urlAlphabet, 22);
const passwordAlphabet = "ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz23456789";
const passwordGenerator = customAlphabet(passwordAlphabet, 16);

var id = /*#__PURE__*/Object.freeze({
  __proto__: null,
  idGenerator: idGenerator,
  passwordGenerator: passwordGenerator
});

const CONTENT_TYPE_DICT = {
  // JSON/XML (most common, highest savings)
  "application/json": "j",
  // 16B → 1B = -93.75%
  "application/xml": "X",
  // 15B → 1B = -93.3% (changed from 'x' to avoid conflict)
  "application/ld+json": "J",
  // 20B → 1B = -95%
  // Text types
  "text/html": "H",
  // 9B → 1B = -88.9% (changed from 'h' to avoid conflict)
  "text/plain": "T",
  // 10B → 1B = -90% (changed from 'p' to avoid conflict)
  "text/css": "C",
  // 8B → 1B = -87.5% (changed from 'c' to avoid conflict)
  "text/javascript": "V",
  // 15B → 1B = -93.3% (changed from 's' to avoid conflict)
  "text/csv": "v",
  // 8B → 1B = -87.5%
  // Images
  "image/png": "P",
  // 9B → 1B = -88.9%
  "image/jpeg": "I",
  // 10B → 1B = -90%
  "image/gif": "G",
  // 9B → 1B = -88.9%
  "image/svg+xml": "S",
  // 13B → 1B = -92.3%
  "image/webp": "W",
  // 10B → 1B = -90%
  // Application types
  "application/pdf": "Q",
  // 15B → 1B = -93.3% (changed from 'd' to avoid conflict)
  "application/zip": "z",
  // 15B → 1B = -93.3%
  "application/octet-stream": "o",
  // 24B → 1B = -95.8%
  "application/x-www-form-urlencoded": "u",
  // 33B → 1B = -97%
  "multipart/form-data": "F",
  // 19B → 1B = -94.7% (changed from 'f' to avoid conflict)
  // Font types
  "font/woff": "w",
  // 9B → 1B = -88.9%
  "font/woff2": "f"
  // 10B → 1B = -90% (changed from 'F')
};
const URL_PREFIX_DICT = {
  // API endpoints (very common)
  "/api/v1/": "@1",
  // 8B → 2B = -75%
  "/api/v2/": "@2",
  // 8B → 2B = -75%
  "/api/v3/": "@3",
  // 8B → 2B = -75%
  "/api/": "@a",
  // 5B → 2B = -60%
  // HTTPS prefixes
  "https://api.example.com/": "@A",
  // 24B → 2B = -91.7%
  "https://api.": "@H",
  // 11B → 2B = -81.8%
  "https://www.": "@W",
  // 12B → 2B = -83.3%
  "https://": "@h",
  // 8B → 2B = -75%
  "http://": "@t",
  // 7B → 2B = -71.4%
  // AWS/S3 (common in s3db.js context)
  "https://s3.amazonaws.com/": "@s",
  // 26B → 2B = -92.3%
  "https://s3-": "@S",
  // 10B → 2B = -80%
  // Localhost (development)
  "http://localhost:": "@L",
  // 17B → 2B = -88.2%
  "http://localhost": "@l",
  // 16B → 2B = -87.5%
  // Common paths
  "/v1/": "@v",
  // 4B → 2B = -50%
  "/users/": "@u",
  // 7B → 2B = -71.4%
  "/products/": "@p"
  // 10B → 2B = -80%
};
const STATUS_MESSAGE_DICT = {
  // Processing states (very common, good savings)
  "processing": "p",
  // 10B → 1B = -90%
  "completed": "c",
  // 9B → 1B = -88.9%
  "succeeded": "s",
  // 9B → 1B = -88.9%
  "failed": "f",
  // 6B → 1B = -83.3%
  "cancelled": "x",
  // 9B → 1B = -88.9%
  "timeout": "t",
  // 7B → 1B = -85.7%
  "retrying": "r",
  // 8B → 1B = -87.5%
  // Payment states
  "authorized": "a",
  // 10B → 1B = -90%
  "captured": "K",
  // 8B → 1B = -87.5% (changed from C to avoid conflict)
  "refunded": "R",
  // 8B → 1B = -87.5%
  "declined": "d",
  // 8B → 1B = -87.5%
  // Order/delivery states
  "shipped": "h",
  // 7B → 1B = -85.7% (changed from S to avoid conflict)
  "delivered": "D",
  // 9B → 1B = -88.9%
  "returned": "e",
  // 8B → 1B = -87.5% (changed from T to avoid conflict)
  "in_transit": "i",
  // 10B → 1B = -90%
  // Generic states
  "initialized": "n",
  // 11B → 1B = -90.9% (changed from I to avoid conflict)
  "terminated": "m"
  // 10B → 1B = -90% (changed from X to avoid conflict)
};
const CONTENT_TYPE_REVERSE = Object.fromEntries(
  Object.entries(CONTENT_TYPE_DICT).map(([k, v]) => [v, k])
);
const URL_PREFIX_REVERSE = Object.fromEntries(
  Object.entries(URL_PREFIX_DICT).map(([k, v]) => [v, k])
);
const STATUS_MESSAGE_REVERSE = Object.fromEntries(
  Object.entries(STATUS_MESSAGE_DICT).map(([k, v]) => [v, k])
);
const COMBINED_DICT = {
  ...CONTENT_TYPE_DICT,
  ...STATUS_MESSAGE_DICT
  // URL prefixes handled separately (prefix matching)
};
const COMBINED_REVERSE = {
  ...CONTENT_TYPE_REVERSE,
  ...STATUS_MESSAGE_REVERSE
  // URL prefixes handled separately
};
function dictionaryEncode(value) {
  if (typeof value !== "string" || !value) {
    return null;
  }
  if (COMBINED_DICT[value]) {
    return {
      encoded: "d:" + COMBINED_DICT[value],
      encoding: "dictionary",
      originalLength: value.length,
      encodedLength: 2 + COMBINED_DICT[value].length,
      dictionaryType: "exact",
      savings: value.length - (2 + COMBINED_DICT[value].length)
    };
  }
  const sortedPrefixes = Object.entries(URL_PREFIX_DICT).sort(([a], [b]) => b.length - a.length);
  for (const [prefix, code] of sortedPrefixes) {
    if (value.startsWith(prefix)) {
      const remainder = value.substring(prefix.length);
      const encoded = "d:" + code + remainder;
      return {
        encoded,
        encoding: "dictionary",
        originalLength: value.length,
        encodedLength: encoded.length,
        dictionaryType: "prefix",
        prefix,
        remainder,
        savings: value.length - encoded.length
      };
    }
  }
  return null;
}
function dictionaryDecode(encoded) {
  if (typeof encoded !== "string" || !encoded.startsWith("d:")) {
    return null;
  }
  const payload = encoded.substring(2);
  if (payload.length === 0) {
    return null;
  }
  if (payload.length === 1) {
    const decoded = COMBINED_REVERSE[payload];
    if (decoded) {
      return decoded;
    }
  }
  if (payload.startsWith("@")) {
    const prefixCode = payload.substring(0, 2);
    const remainder = payload.substring(2);
    const prefix = URL_PREFIX_REVERSE[prefixCode];
    if (prefix) {
      return prefix + remainder;
    }
  }
  return null;
}

const analysisCache = /* @__PURE__ */ new Map();
const MAX_CACHE_SIZE$1 = 500;
function isAsciiOnly(str) {
  return /^[\x20-\x7E]*$/.test(str);
}
function analyzeString(str) {
  if (!str || typeof str !== "string") {
    return { type: "none", safe: true };
  }
  if (analysisCache.has(str)) {
    return analysisCache.get(str);
  }
  if (isAsciiOnly(str)) {
    const result2 = {
      type: "ascii",
      safe: true,
      stats: { ascii: str.length, latin1: 0, multibyte: 0 }
    };
    cacheAnalysisResult(str, result2);
    return result2;
  }
  let asciiCount = 0;
  let latin1Count = 0;
  let multibyteCount = 0;
  for (let i = 0; i < str.length; i++) {
    const code = str.charCodeAt(i);
    if (code >= 32 && code <= 126) {
      asciiCount++;
    } else if (code < 32 || code === 127) {
      multibyteCount++;
    } else if (code >= 128 && code <= 255) {
      latin1Count++;
    } else {
      multibyteCount++;
    }
  }
  const hasMultibyte = multibyteCount > 0;
  const hasLatin1 = latin1Count > 0;
  let result;
  if (!hasLatin1 && !hasMultibyte) {
    result = {
      type: "ascii",
      safe: true,
      stats: { ascii: asciiCount, latin1: 0, multibyte: 0 }
    };
  } else if (hasMultibyte) {
    const multibyteRatio = multibyteCount / str.length;
    if (multibyteRatio > 0.3) {
      result = {
        type: "base64",
        safe: false,
        reason: "high multibyte content",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: multibyteCount }
      };
    } else {
      result = {
        type: "url",
        safe: false,
        reason: "contains multibyte characters",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: multibyteCount }
      };
    }
  } else {
    const latin1Ratio = latin1Count / str.length;
    if (latin1Ratio > 0.5) {
      result = {
        type: "base64",
        safe: false,
        reason: "high Latin-1 content",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: 0 }
      };
    } else {
      result = {
        type: "url",
        safe: false,
        reason: "contains Latin-1 extended characters",
        stats: { ascii: asciiCount, latin1: latin1Count, multibyte: 0 }
      };
    }
  }
  cacheAnalysisResult(str, result);
  return result;
}
function cacheAnalysisResult(str, result) {
  if (analysisCache.size >= MAX_CACHE_SIZE$1) {
    const firstKey = analysisCache.keys().next().value;
    analysisCache.delete(firstKey);
  }
  analysisCache.set(str, result);
}
const COMMON_VALUES = {
  // Status values (10 entries)
  "active": { encoded: "active", encoding: "none" },
  "inactive": { encoded: "inactive", encoding: "none" },
  "pending": { encoded: "pending", encoding: "none" },
  "completed": { encoded: "completed", encoding: "none" },
  "failed": { encoded: "failed", encoding: "none" },
  "success": { encoded: "success", encoding: "none" },
  "error": { encoded: "error", encoding: "none" },
  "processing": { encoded: "processing", encoding: "none" },
  "queued": { encoded: "queued", encoding: "none" },
  "cancelled": { encoded: "cancelled", encoding: "none" },
  // HTTP methods (7 entries)
  "GET": { encoded: "GET", encoding: "none" },
  "POST": { encoded: "POST", encoding: "none" },
  "PUT": { encoded: "PUT", encoding: "none" },
  "DELETE": { encoded: "DELETE", encoding: "none" },
  "PATCH": { encoded: "PATCH", encoding: "none" },
  "HEAD": { encoded: "HEAD", encoding: "none" },
  "OPTIONS": { encoded: "OPTIONS", encoding: "none" },
  // HTTP status codes (20 entries - most common)
  "200": { encoded: "200", encoding: "none" },
  "201": { encoded: "201", encoding: "none" },
  "204": { encoded: "204", encoding: "none" },
  "301": { encoded: "301", encoding: "none" },
  "302": { encoded: "302", encoding: "none" },
  "304": { encoded: "304", encoding: "none" },
  "400": { encoded: "400", encoding: "none" },
  "401": { encoded: "401", encoding: "none" },
  "403": { encoded: "403", encoding: "none" },
  "404": { encoded: "404", encoding: "none" },
  "405": { encoded: "405", encoding: "none" },
  "409": { encoded: "409", encoding: "none" },
  "422": { encoded: "422", encoding: "none" },
  "429": { encoded: "429", encoding: "none" },
  "500": { encoded: "500", encoding: "none" },
  "502": { encoded: "502", encoding: "none" },
  "503": { encoded: "503", encoding: "none" },
  "504": { encoded: "504", encoding: "none" },
  "OK": { encoded: "OK", encoding: "none" },
  "Created": { encoded: "Created", encoding: "none" },
  // Payment/transaction status (12 entries)
  "paid": { encoded: "paid", encoding: "none" },
  "unpaid": { encoded: "unpaid", encoding: "none" },
  "refunded": { encoded: "refunded", encoding: "none" },
  "pending_payment": { encoded: "pending_payment", encoding: "none" },
  "authorized": { encoded: "authorized", encoding: "none" },
  "captured": { encoded: "captured", encoding: "none" },
  "declined": { encoded: "declined", encoding: "none" },
  "voided": { encoded: "voided", encoding: "none" },
  "chargeback": { encoded: "chargeback", encoding: "none" },
  "disputed": { encoded: "disputed", encoding: "none" },
  "settled": { encoded: "settled", encoding: "none" },
  "reversed": { encoded: "reversed", encoding: "none" },
  // Order/delivery status (10 entries)
  "shipped": { encoded: "shipped", encoding: "none" },
  "delivered": { encoded: "delivered", encoding: "none" },
  "returned": { encoded: "returned", encoding: "none" },
  "in_transit": { encoded: "in_transit", encoding: "none" },
  "out_for_delivery": { encoded: "out_for_delivery", encoding: "none" },
  "ready_to_ship": { encoded: "ready_to_ship", encoding: "none" },
  "backordered": { encoded: "backordered", encoding: "none" },
  "pre_order": { encoded: "pre_order", encoding: "none" },
  "on_hold": { encoded: "on_hold", encoding: "none" },
  "awaiting_pickup": { encoded: "awaiting_pickup", encoding: "none" },
  // User roles (8 entries)
  "admin": { encoded: "admin", encoding: "none" },
  "moderator": { encoded: "moderator", encoding: "none" },
  "owner": { encoded: "owner", encoding: "none" },
  "editor": { encoded: "editor", encoding: "none" },
  "viewer": { encoded: "viewer", encoding: "none" },
  "contributor": { encoded: "contributor", encoding: "none" },
  "guest": { encoded: "guest", encoding: "none" },
  "member": { encoded: "member", encoding: "none" },
  // Log levels (6 entries)
  "trace": { encoded: "trace", encoding: "none" },
  "debug": { encoded: "debug", encoding: "none" },
  "info": { encoded: "info", encoding: "none" },
  "warn": { encoded: "warn", encoding: "none" },
  "fatal": { encoded: "fatal", encoding: "none" },
  "emergency": { encoded: "emergency", encoding: "none" },
  // Environments (7 entries)
  "dev": { encoded: "dev", encoding: "none" },
  "development": { encoded: "development", encoding: "none" },
  "staging": { encoded: "staging", encoding: "none" },
  "production": { encoded: "production", encoding: "none" },
  "test": { encoded: "test", encoding: "none" },
  "qa": { encoded: "qa", encoding: "none" },
  "uat": { encoded: "uat", encoding: "none" },
  // CRUD operations (7 entries)
  "create": { encoded: "create", encoding: "none" },
  "read": { encoded: "read", encoding: "none" },
  "update": { encoded: "update", encoding: "none" },
  "delete": { encoded: "delete", encoding: "none" },
  "list": { encoded: "list", encoding: "none" },
  "search": { encoded: "search", encoding: "none" },
  "count": { encoded: "count", encoding: "none" },
  // States (8 entries)
  "enabled": { encoded: "enabled", encoding: "none" },
  "disabled": { encoded: "disabled", encoding: "none" },
  "archived": { encoded: "archived", encoding: "none" },
  "draft": { encoded: "draft", encoding: "none" },
  "published": { encoded: "published", encoding: "none" },
  "scheduled": { encoded: "scheduled", encoding: "none" },
  "expired": { encoded: "expired", encoding: "none" },
  "locked": { encoded: "locked", encoding: "none" },
  // Priorities (5 entries)
  "low": { encoded: "low", encoding: "none" },
  "medium": { encoded: "medium", encoding: "none" },
  "high": { encoded: "high", encoding: "none" },
  "urgent": { encoded: "urgent", encoding: "none" },
  "critical": { encoded: "critical", encoding: "none" },
  // Boolean variants (8 entries)
  "true": { encoded: "true", encoding: "none" },
  "false": { encoded: "false", encoding: "none" },
  "yes": { encoded: "yes", encoding: "none" },
  "no": { encoded: "no", encoding: "none" },
  "on": { encoded: "on", encoding: "none" },
  "off": { encoded: "off", encoding: "none" },
  "1": { encoded: "1", encoding: "none" },
  "0": { encoded: "0", encoding: "none" },
  // Common null-like values (4 entries)
  "null": { encoded: "null", encoding: "special" },
  "undefined": { encoded: "undefined", encoding: "special" },
  "none": { encoded: "none", encoding: "none" },
  "N/A": { encoded: "N/A", encoding: "none" }
};
function metadataEncode(value) {
  if (value === null) {
    return { encoded: "null", encoding: "special" };
  }
  if (value === void 0) {
    return { encoded: "undefined", encoding: "special" };
  }
  const stringValue = String(value);
  if (stringValue.startsWith("d:") || stringValue.startsWith("u:") || stringValue.startsWith("b:")) {
    return {
      encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
      encoding: "base64",
      reason: "force-encoded to prevent decoding ambiguity"
    };
  }
  const dictResult = dictionaryEncode(stringValue);
  if (dictResult && dictResult.savings > 0) {
    return {
      encoded: dictResult.encoded,
      encoding: "dictionary",
      dictionaryType: dictResult.dictionaryType,
      savings: dictResult.savings,
      compressionRatio: (dictResult.encodedLength / dictResult.originalLength).toFixed(3)
    };
  }
  if (COMMON_VALUES[stringValue]) {
    return COMMON_VALUES[stringValue];
  }
  const analysis = analyzeString(stringValue);
  switch (analysis.type) {
    case "none":
    case "ascii":
      return {
        encoded: stringValue,
        encoding: "none",
        analysis
      };
    case "url":
      return {
        encoded: "u:" + encodeURIComponent(stringValue),
        encoding: "url",
        analysis
      };
    case "base64":
      return {
        encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
        encoding: "base64",
        analysis
      };
    default:
      return {
        encoded: "b:" + Buffer.from(stringValue, "utf8").toString("base64"),
        encoding: "base64",
        analysis
      };
  }
}
function metadataDecode(value) {
  if (value === "null") {
    return null;
  }
  if (value === "undefined") {
    return void 0;
  }
  if (value === null || value === void 0 || typeof value !== "string") {
    return value;
  }
  if (value.startsWith("d:")) {
    const decoded = dictionaryDecode(value);
    if (decoded !== null) {
      return decoded;
    }
  }
  if (value.length >= 2) {
    const firstChar = value.charCodeAt(0);
    const secondChar = value.charCodeAt(1);
    if (secondChar === 58) {
      if (firstChar === 117) {
        if (value.length === 2) return value;
        try {
          return decodeURIComponent(value.substring(2));
        } catch (err) {
          return value;
        }
      }
      if (firstChar === 98) {
        if (value.length === 2) return value;
        try {
          const decoded = Buffer.from(value.substring(2), "base64").toString("utf8");
          return decoded;
        } catch (err) {
          return value;
        }
      }
    }
  }
  return value;
}

const S3_METADATA_LIMIT = 2047;
class PluginStorage {
  /**
   * @param {Object} client - S3db Client instance
   * @param {string} pluginSlug - Plugin identifier (kebab-case)
   */
  constructor(client, pluginSlug) {
    if (!client) {
      throw new PluginStorageError("PluginStorage requires a client instance", {
        operation: "constructor",
        pluginSlug,
        suggestion: "Pass a valid S3db Client instance when creating PluginStorage"
      });
    }
    if (!pluginSlug) {
      throw new PluginStorageError("PluginStorage requires a pluginSlug", {
        operation: "constructor",
        suggestion: 'Provide a plugin slug (e.g., "eventual-consistency", "cache", "audit")'
      });
    }
    this.client = client;
    this.pluginSlug = pluginSlug;
  }
  /**
   * Generate hierarchical plugin-scoped key
   *
   * @param {string} resourceName - Resource name (optional, for resource-scoped data)
   * @param {...string} parts - Additional path parts
   * @returns {string} S3 key
   *
   * @example
   * // Resource-scoped: resource=wallets/plugin=eventual-consistency/balance/transactions/id=txn1
   * getPluginKey('wallets', 'balance', 'transactions', 'id=txn1')
   *
   * // Global plugin data: plugin=eventual-consistency/config
   * getPluginKey(null, 'config')
   */
  getPluginKey(resourceName, ...parts) {
    if (resourceName) {
      return `resource=${resourceName}/plugin=${this.pluginSlug}/${parts.join("/")}`;
    }
    return `plugin=${this.pluginSlug}/${parts.join("/")}`;
  }
  /**
   * Save data with metadata encoding, behavior support, and optional TTL
   *
   * @param {string} key - S3 key
   * @param {Object} data - Data to save
   * @param {Object} options - Options
   * @param {number} options.ttl - Time-to-live in seconds (optional)
   * @param {string} options.behavior - 'body-overflow' | 'body-only' | 'enforce-limits'
   * @param {string} options.contentType - Content type (default: application/json)
   * @returns {Promise<void>}
   */
  async set(key, data, options = {}) {
    const { ttl, behavior = "body-overflow", contentType = "application/json" } = options;
    const dataToSave = { ...data };
    if (ttl && typeof ttl === "number" && ttl > 0) {
      dataToSave._expiresAt = Date.now() + ttl * 1e3;
    }
    const { metadata, body } = this._applyBehavior(dataToSave, behavior);
    const putParams = {
      key,
      metadata,
      contentType
    };
    if (body !== null) {
      putParams.body = JSON.stringify(body);
    }
    const [ok, err] = await tryFn(() => this.client.putObject(putParams));
    if (!ok) {
      throw new PluginStorageError(`Failed to save plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "set",
        behavior,
        ttl,
        original: err,
        suggestion: "Check S3 permissions and key format"
      });
    }
  }
  /**
   * Batch set multiple items
   *
   * @param {Array<{key: string, data: Object, options?: Object}>} items - Items to save
   * @returns {Promise<Array<{ok: boolean, key: string, error?: Error}>>} Results
   */
  async batchSet(items) {
    const results = [];
    for (const item of items) {
      try {
        await this.set(item.key, item.data, item.options || {});
        results.push({ ok: true, key: item.key });
      } catch (error) {
        results.push({ ok: false, key: item.key, error });
      }
    }
    return results;
  }
  /**
   * Get data with automatic metadata decoding and TTL check
   *
   * @param {string} key - S3 key
   * @returns {Promise<Object|null>} Data or null if not found/expired
   */
  async get(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      if (err.name === "NoSuchKey" || err.Code === "NoSuchKey") {
        return null;
      }
      throw new PluginStorageError(`Failed to retrieve plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "get",
        original: err,
        suggestion: "Check if the key exists and S3 permissions are correct"
      });
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, parseErr, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        throw new PluginStorageError(`Failed to parse JSON body`, {
          pluginSlug: this.pluginSlug,
          key,
          operation: "get",
          original: parseErr,
          suggestion: "Body content may be corrupted. Check S3 object integrity"
        });
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (expiresAt) {
      if (Date.now() > expiresAt) {
        await this.delete(key);
        return null;
      }
      delete data._expiresat;
      delete data._expiresAt;
    }
    return data;
  }
  /**
   * Parse metadata values back to their original types
   * @private
   */
  _parseMetadataValues(metadata) {
    const parsed = {};
    for (const [key, value] of Object.entries(metadata)) {
      if (typeof value === "string") {
        if (value.startsWith("{") && value.endsWith("}") || value.startsWith("[") && value.endsWith("]")) {
          const [ok, err, result] = tryFn(() => JSON.parse(value));
          if (ok) {
            parsed[key] = result;
            continue;
          }
        }
        if (!isNaN(value) && value.trim() !== "") {
          parsed[key] = Number(value);
          continue;
        }
        if (value === "true") {
          parsed[key] = true;
          continue;
        }
        if (value === "false") {
          parsed[key] = false;
          continue;
        }
      }
      parsed[key] = value;
    }
    return parsed;
  }
  /**
   * List all keys with plugin prefix
   *
   * @param {string} prefix - Additional prefix (optional)
   * @param {Object} options - List options
   * @param {number} options.limit - Max number of results
   * @returns {Promise<Array<string>>} List of keys
   */
  async list(prefix = "", options = {}) {
    const { limit } = options;
    const fullPrefix = prefix ? `plugin=${this.pluginSlug}/${prefix}` : `plugin=${this.pluginSlug}/`;
    const [ok, err, result] = await tryFn(
      () => this.client.listObjects({ prefix: fullPrefix, maxKeys: limit })
    );
    if (!ok) {
      throw new PluginStorageError(`Failed to list plugin data`, {
        pluginSlug: this.pluginSlug,
        operation: "list",
        prefix,
        fullPrefix,
        limit,
        original: err,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    const keys = result.Contents?.map((item) => item.Key) || [];
    return this._removeKeyPrefix(keys);
  }
  /**
   * List keys for a specific resource
   *
   * @param {string} resourceName - Resource name
   * @param {string} subPrefix - Additional prefix within resource (optional)
   * @param {Object} options - List options
   * @returns {Promise<Array<string>>} List of keys
   */
  async listForResource(resourceName, subPrefix = "", options = {}) {
    const { limit } = options;
    const fullPrefix = subPrefix ? `resource=${resourceName}/plugin=${this.pluginSlug}/${subPrefix}` : `resource=${resourceName}/plugin=${this.pluginSlug}/`;
    const [ok, err, result] = await tryFn(
      () => this.client.listObjects({ prefix: fullPrefix, maxKeys: limit })
    );
    if (!ok) {
      throw new PluginStorageError(`Failed to list resource data`, {
        pluginSlug: this.pluginSlug,
        operation: "listForResource",
        resourceName,
        subPrefix,
        fullPrefix,
        limit,
        original: err,
        suggestion: "Check resource name and S3 permissions"
      });
    }
    const keys = result.Contents?.map((item) => item.Key) || [];
    return this._removeKeyPrefix(keys);
  }
  /**
   * Remove client keyPrefix from keys
   * @private
   */
  _removeKeyPrefix(keys) {
    const keyPrefix = this.client.config.keyPrefix;
    if (!keyPrefix) return keys;
    return keys.map((key) => key.replace(keyPrefix, "")).map((key) => key.startsWith("/") ? key.replace("/", "") : key);
  }
  /**
   * Check if a key exists (not expired)
   *
   * @param {string} key - S3 key
   * @returns {Promise<boolean>} True if exists and not expired
   */
  async has(key) {
    const data = await this.get(key);
    return data !== null;
  }
  /**
   * Check if a key is expired
   *
   * @param {string} key - S3 key
   * @returns {Promise<boolean>} True if expired or not found
   */
  async isExpired(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      return true;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, err2, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        return true;
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (!expiresAt) {
      return false;
    }
    return Date.now() > expiresAt;
  }
  /**
   * Get remaining TTL in seconds
   *
   * @param {string} key - S3 key
   * @returns {Promise<number|null>} Remaining seconds or null if no TTL/not found
   */
  async getTTL(key) {
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      return null;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    let data = parsedMetadata;
    if (response.Body) {
      const [ok2, err2, result] = await tryFn(async () => {
        const bodyContent = await response.Body.transformToString();
        if (bodyContent && bodyContent.trim()) {
          const body = JSON.parse(bodyContent);
          return { ...parsedMetadata, ...body };
        }
        return parsedMetadata;
      });
      if (!ok2) {
        return null;
      }
      data = result;
    }
    const expiresAt = data._expiresat || data._expiresAt;
    if (!expiresAt) {
      return null;
    }
    const remaining = Math.max(0, expiresAt - Date.now());
    return Math.floor(remaining / 1e3);
  }
  /**
   * Extend TTL by adding additional seconds
   *
   * @param {string} key - S3 key
   * @param {number} additionalSeconds - Seconds to add to current TTL
   * @returns {Promise<boolean>} True if extended, false if not found or no TTL
   */
  async touch(key, additionalSeconds) {
    const [ok, err, response] = await tryFn(() => this.client.headObject(key));
    if (!ok) {
      return false;
    }
    const metadata = response.Metadata || {};
    const parsedMetadata = this._parseMetadataValues(metadata);
    const expiresAt = parsedMetadata._expiresat || parsedMetadata._expiresAt;
    if (!expiresAt) {
      return false;
    }
    parsedMetadata._expiresAt = expiresAt + additionalSeconds * 1e3;
    delete parsedMetadata._expiresat;
    const encodedMetadata = {};
    for (const [metaKey, metaValue] of Object.entries(parsedMetadata)) {
      const { encoded } = metadataEncode(metaValue);
      encodedMetadata[metaKey] = encoded;
    }
    const [copyOk] = await tryFn(() => this.client.copyObject({
      from: key,
      to: key,
      metadata: encodedMetadata,
      metadataDirective: "REPLACE",
      contentType: response.ContentType || "application/json"
    }));
    return copyOk;
  }
  /**
   * Delete a single object
   *
   * @param {string} key - S3 key
   * @returns {Promise<void>}
   */
  async delete(key) {
    const [ok, err] = await tryFn(() => this.client.deleteObject(key));
    if (!ok) {
      throw new PluginStorageError(`Failed to delete plugin data`, {
        pluginSlug: this.pluginSlug,
        key,
        operation: "delete",
        original: err,
        suggestion: "Check S3 delete permissions"
      });
    }
  }
  /**
   * Delete all plugin data (for uninstall)
   *
   * @param {string} resourceName - Resource name (optional, if null deletes all plugin data)
   * @returns {Promise<number>} Number of objects deleted
   */
  async deleteAll(resourceName = null) {
    let deleted = 0;
    if (resourceName) {
      const keys = await this.listForResource(resourceName);
      for (const key of keys) {
        await this.delete(key);
        deleted++;
      }
    } else {
      const allKeys = await this.client.getAllKeys({});
      const pluginKeys = allKeys.filter(
        (key) => key.includes(`plugin=${this.pluginSlug}/`)
      );
      for (const key of pluginKeys) {
        await this.delete(key);
        deleted++;
      }
    }
    return deleted;
  }
  /**
   * Batch put operations
   *
   * @param {Array<{key: string, data: Object, options?: Object}>} items - Items to save
   * @returns {Promise<Array<{key: string, ok: boolean, error?: Error}>>} Results
   */
  async batchPut(items) {
    const results = [];
    for (const item of items) {
      const [ok, err] = await tryFn(
        () => this.put(item.key, item.data, item.options)
      );
      results.push({
        key: item.key,
        ok,
        error: err
      });
    }
    return results;
  }
  /**
   * Batch get operations
   *
   * @param {Array<string>} keys - Keys to fetch
   * @returns {Promise<Array<{key: string, ok: boolean, data?: Object, error?: Error}>>} Results
   */
  async batchGet(keys) {
    const results = [];
    for (const key of keys) {
      const [ok, err, data] = await tryFn(() => this.get(key));
      results.push({
        key,
        ok,
        data,
        error: err
      });
    }
    return results;
  }
  /**
   * Acquire a distributed lock with TTL and retry logic
   *
   * @param {string} lockName - Lock identifier
   * @param {Object} options - Lock options
   * @param {number} options.ttl - Lock TTL in seconds (default: 30)
   * @param {number} options.timeout - Max wait time in ms (default: 0, no wait)
   * @param {string} options.workerId - Worker identifier (default: 'unknown')
   * @returns {Promise<Object|null>} Lock object or null if couldn't acquire
   */
  async acquireLock(lockName, options = {}) {
    const { ttl = 30, timeout = 0, workerId = "unknown" } = options;
    const key = this.getPluginKey(null, "locks", lockName);
    const startTime = Date.now();
    while (true) {
      const existing = await this.get(key);
      if (!existing) {
        await this.set(key, { workerId, acquiredAt: Date.now() }, { ttl });
        return { key, workerId };
      }
      if (Date.now() - startTime >= timeout) {
        return null;
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
  }
  /**
   * Release a distributed lock
   *
   * @param {string} lockName - Lock identifier
   * @returns {Promise<void>}
   */
  async releaseLock(lockName) {
    const key = this.getPluginKey(null, "locks", lockName);
    await this.delete(key);
  }
  /**
   * Check if a lock is currently held
   *
   * @param {string} lockName - Lock identifier
   * @returns {Promise<boolean>} True if locked
   */
  async isLocked(lockName) {
    const key = this.getPluginKey(null, "locks", lockName);
    const lock = await this.get(key);
    return lock !== null;
  }
  /**
   * Increment a counter value
   *
   * Optimization: Uses HEAD + COPY for existing counters to avoid body transfer.
   * Falls back to GET + PUT for non-existent counters or those with additional data.
   *
   * @param {string} key - S3 key
   * @param {number} amount - Amount to increment (default: 1)
   * @param {Object} options - Options (e.g., ttl)
   * @returns {Promise<number>} New value
   */
  async increment(key, amount = 1, options = {}) {
    const [headOk, headErr, headResponse] = await tryFn(() => this.client.headObject(key));
    if (headOk && headResponse.Metadata) {
      const metadata = headResponse.Metadata || {};
      const parsedMetadata = this._parseMetadataValues(metadata);
      const currentValue = parsedMetadata.value || 0;
      const newValue = currentValue + amount;
      parsedMetadata.value = newValue;
      if (options.ttl) {
        parsedMetadata._expiresAt = Date.now() + options.ttl * 1e3;
      }
      const encodedMetadata = {};
      for (const [metaKey, metaValue] of Object.entries(parsedMetadata)) {
        const { encoded } = metadataEncode(metaValue);
        encodedMetadata[metaKey] = encoded;
      }
      const [copyOk] = await tryFn(() => this.client.copyObject({
        from: key,
        to: key,
        metadata: encodedMetadata,
        metadataDirective: "REPLACE",
        contentType: headResponse.ContentType || "application/json"
      }));
      if (copyOk) {
        return newValue;
      }
    }
    const data = await this.get(key);
    const value = (data?.value || 0) + amount;
    await this.set(key, { value }, options);
    return value;
  }
  /**
   * Decrement a counter value
   *
   * @param {string} key - S3 key
   * @param {number} amount - Amount to decrement (default: 1)
   * @param {Object} options - Options (e.g., ttl)
   * @returns {Promise<number>} New value
   */
  async decrement(key, amount = 1, options = {}) {
    return this.increment(key, -amount, options);
  }
  /**
   * Apply behavior to split data between metadata and body
   *
   * @private
   * @param {Object} data - Data to split
   * @param {string} behavior - Behavior strategy
   * @returns {{metadata: Object, body: Object|null}}
   */
  _applyBehavior(data, behavior) {
    const effectiveLimit = calculateEffectiveLimit({ s3Limit: S3_METADATA_LIMIT });
    let metadata = {};
    let body = null;
    switch (behavior) {
      case "body-overflow": {
        const entries = Object.entries(data);
        const sorted = entries.map(([key, value]) => {
          const jsonValue = typeof value === "object" ? JSON.stringify(value) : value;
          const { encoded } = metadataEncode(jsonValue);
          const keySize = calculateUTF8Bytes(key);
          const valueSize = calculateUTF8Bytes(encoded);
          return { key, value, jsonValue, encoded, size: keySize + valueSize };
        }).sort((a, b) => a.size - b.size);
        let currentSize = 0;
        for (const item of sorted) {
          if (currentSize + item.size <= effectiveLimit) {
            metadata[item.key] = item.jsonValue;
            currentSize += item.size;
          } else {
            if (body === null) body = {};
            body[item.key] = item.value;
          }
        }
        break;
      }
      case "body-only": {
        body = data;
        break;
      }
      case "enforce-limits": {
        let currentSize = 0;
        for (const [key, value] of Object.entries(data)) {
          const jsonValue = typeof value === "object" ? JSON.stringify(value) : value;
          const { encoded } = metadataEncode(jsonValue);
          const keySize = calculateUTF8Bytes(key);
          const valueSize = calculateUTF8Bytes(encoded);
          currentSize += keySize + valueSize;
          if (currentSize > effectiveLimit) {
            throw new MetadataLimitError(`Data exceeds metadata limit with enforce-limits behavior`, {
              totalSize: currentSize,
              effectiveLimit,
              absoluteLimit: S3_METADATA_LIMIT,
              excess: currentSize - effectiveLimit,
              operation: "PluginStorage.set",
              pluginSlug: this.pluginSlug,
              suggestion: "Use 'body-overflow' or 'body-only' behavior to handle large data"
            });
          }
          metadata[key] = jsonValue;
        }
        break;
      }
      default:
        throw new BehaviorError(`Unknown behavior: ${behavior}`, {
          behavior,
          availableBehaviors: ["body-overflow", "body-only", "enforce-limits"],
          operation: "PluginStorage._applyBehavior",
          pluginSlug: this.pluginSlug,
          suggestion: "Use 'body-overflow', 'body-only', or 'enforce-limits'"
        });
    }
    return { metadata, body };
  }
}

class Plugin extends EventEmitter {
  constructor(options = {}) {
    super();
    this.name = this.constructor.name;
    this.options = options;
    this.hooks = /* @__PURE__ */ new Map();
    this.slug = options.slug || this._generateSlug();
    this._storage = null;
  }
  /**
   * Generate kebab-case slug from class name
   * @private
   * @returns {string}
   */
  _generateSlug() {
    return this.name.replace(/Plugin$/, "").replace(/([a-z])([A-Z])/g, "$1-$2").toLowerCase();
  }
  /**
   * Get PluginStorage instance (lazy-loaded)
   * @returns {PluginStorage}
   */
  getStorage() {
    if (!this._storage) {
      if (!this.database || !this.database.client) {
        throw new Error("Plugin must be installed before accessing storage");
      }
      this._storage = new PluginStorage(this.database.client, this.slug);
    }
    return this._storage;
  }
  /**
   * Install plugin
   * @param {Database} database - Database instance
   */
  async install(database) {
    this.database = database;
    this.beforeInstall();
    await this.onInstall();
    this.afterInstall();
  }
  async start() {
    this.beforeStart();
    await this.onStart();
    this.afterStart();
  }
  async stop() {
    this.beforeStop();
    await this.onStop();
    this.afterStop();
  }
  /**
   * Uninstall plugin and cleanup all data
   * @param {Object} options - Uninstall options
   * @param {boolean} options.purgeData - Delete all plugin data from S3 (default: false)
   */
  async uninstall(options = {}) {
    const { purgeData = false } = options;
    this.beforeUninstall();
    await this.onUninstall(options);
    if (purgeData && this._storage) {
      const deleted = await this._storage.deleteAll();
      this.emit("plugin.dataPurged", { deleted });
    }
    this.afterUninstall();
  }
  // Override these methods in subclasses
  async onInstall() {
  }
  async onStart() {
  }
  async onStop() {
  }
  async onUninstall(options) {
  }
  // Hook management methods
  addHook(resource, event, handler) {
    if (!this.hooks.has(resource)) {
      this.hooks.set(resource, /* @__PURE__ */ new Map());
    }
    const resourceHooks = this.hooks.get(resource);
    if (!resourceHooks.has(event)) {
      resourceHooks.set(event, []);
    }
    resourceHooks.get(event).push(handler);
  }
  removeHook(resource, event, handler) {
    const resourceHooks = this.hooks.get(resource);
    if (resourceHooks && resourceHooks.has(event)) {
      const handlers = resourceHooks.get(event);
      const index = handlers.indexOf(handler);
      if (index > -1) {
        handlers.splice(index, 1);
      }
    }
  }
  // Enhanced resource method wrapping that supports multiple plugins
  wrapResourceMethod(resource, methodName, wrapper) {
    const originalMethod = resource[methodName];
    if (!resource._pluginWrappers) {
      resource._pluginWrappers = /* @__PURE__ */ new Map();
    }
    if (!resource._pluginWrappers.has(methodName)) {
      resource._pluginWrappers.set(methodName, []);
    }
    resource._pluginWrappers.get(methodName).push(wrapper);
    if (!resource[`_wrapped_${methodName}`]) {
      resource[`_wrapped_${methodName}`] = originalMethod;
      const isJestMock = originalMethod && originalMethod._isMockFunction;
      resource[methodName] = async function(...args) {
        let result = await resource[`_wrapped_${methodName}`](...args);
        for (const wrapper2 of resource._pluginWrappers.get(methodName)) {
          result = await wrapper2.call(this, result, args, methodName);
        }
        return result;
      };
      if (isJestMock) {
        Object.setPrototypeOf(resource[methodName], Object.getPrototypeOf(originalMethod));
        Object.assign(resource[methodName], originalMethod);
      }
    }
  }
  /**
   * Add a middleware to intercept a resource method (Koa/Express style).
   * Middleware signature: async (next, ...args) => { ... }
   * - Chame next(...args) para continuar a cadeia.
   * - Retorne sem chamar next para interromper.
   * - Pode modificar argumentos/resultados.
   */
  addMiddleware(resource, methodName, middleware) {
    if (typeof resource[methodName] !== "function") {
      throw new Error(`Cannot add middleware to "${methodName}": method does not exist on resource "${resource.name || "unknown"}"`);
    }
    if (!resource._pluginMiddlewares) {
      resource._pluginMiddlewares = {};
    }
    if (!resource._pluginMiddlewares[methodName]) {
      resource._pluginMiddlewares[methodName] = [];
      const originalMethod = resource[methodName].bind(resource);
      resource[methodName] = async function(...args) {
        let idx = -1;
        const next = async (...nextArgs) => {
          idx++;
          if (idx < resource._pluginMiddlewares[methodName].length) {
            return await resource._pluginMiddlewares[methodName][idx].call(this, next, ...nextArgs);
          } else {
            return await originalMethod(...nextArgs);
          }
        };
        return await next(...args);
      };
    }
    resource._pluginMiddlewares[methodName].push(middleware);
  }
  // Partition-aware helper methods
  getPartitionValues(data, resource) {
    if (!resource.config?.partitions) return {};
    const partitionValues = {};
    for (const [partitionName, partitionDef] of Object.entries(resource.config.partitions)) {
      if (partitionDef.fields) {
        partitionValues[partitionName] = {};
        for (const [fieldName, rule] of Object.entries(partitionDef.fields)) {
          const value = this.getNestedFieldValue(data, fieldName);
          if (value !== null && value !== void 0) {
            partitionValues[partitionName][fieldName] = resource.applyPartitionRule(value, rule);
          }
        }
      } else {
        partitionValues[partitionName] = {};
      }
    }
    return partitionValues;
  }
  getNestedFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data[fieldPath] ?? null;
    }
    const keys = fieldPath.split(".");
    let value = data;
    for (const key of keys) {
      if (value && typeof value === "object" && key in value) {
        value = value[key];
      } else {
        return null;
      }
    }
    return value ?? null;
  }
  // Event emission methods
  beforeInstall() {
    this.emit("plugin.beforeInstall", /* @__PURE__ */ new Date());
  }
  afterInstall() {
    this.emit("plugin.afterInstall", /* @__PURE__ */ new Date());
  }
  beforeStart() {
    this.emit("plugin.beforeStart", /* @__PURE__ */ new Date());
  }
  afterStart() {
    this.emit("plugin.afterStart", /* @__PURE__ */ new Date());
  }
  beforeStop() {
    this.emit("plugin.beforeStop", /* @__PURE__ */ new Date());
  }
  afterStop() {
    this.emit("plugin.afterStop", /* @__PURE__ */ new Date());
  }
  beforeUninstall() {
    this.emit("plugin.beforeUninstall", /* @__PURE__ */ new Date());
  }
  afterUninstall() {
    this.emit("plugin.afterUninstall", /* @__PURE__ */ new Date());
  }
}

const PluginObject = {
  setup(database) {
  },
  start() {
  },
  stop() {
  }
};

const PLUGIN_DEPENDENCIES = {
  "postgresql-replicator": {
    name: "PostgreSQL Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "pg": {
        version: "^8.0.0",
        description: "PostgreSQL client for Node.js",
        installCommand: "pnpm add pg",
        npmUrl: "https://www.npmjs.com/package/pg"
      }
    }
  },
  "bigquery-replicator": {
    name: "BigQuery Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "@google-cloud/bigquery": {
        version: "^7.0.0",
        description: "Google Cloud BigQuery SDK",
        installCommand: "pnpm add @google-cloud/bigquery",
        npmUrl: "https://www.npmjs.com/package/@google-cloud/bigquery"
      }
    }
  },
  "sqs-replicator": {
    name: "SQS Replicator",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md",
    dependencies: {
      "@aws-sdk/client-sqs": {
        version: "^3.0.0",
        description: "AWS SDK for SQS",
        installCommand: "pnpm add @aws-sdk/client-sqs",
        npmUrl: "https://www.npmjs.com/package/@aws-sdk/client-sqs"
      }
    }
  },
  "sqs-consumer": {
    name: "SQS Queue Consumer",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue-consumer.md",
    dependencies: {
      "@aws-sdk/client-sqs": {
        version: "^3.0.0",
        description: "AWS SDK for SQS",
        installCommand: "pnpm add @aws-sdk/client-sqs",
        npmUrl: "https://www.npmjs.com/package/@aws-sdk/client-sqs"
      }
    }
  },
  "rabbitmq-consumer": {
    name: "RabbitMQ Queue Consumer",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue-consumer.md",
    dependencies: {
      "amqplib": {
        version: "^0.10.0",
        description: "AMQP 0-9-1 library for RabbitMQ",
        installCommand: "pnpm add amqplib",
        npmUrl: "https://www.npmjs.com/package/amqplib"
      }
    }
  },
  "tfstate-plugin": {
    name: "Tfstate Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/tfstate.md",
    dependencies: {
      "node-cron": {
        version: "^4.0.0",
        description: "Cron job scheduler for auto-sync functionality",
        installCommand: "pnpm add node-cron",
        npmUrl: "https://www.npmjs.com/package/node-cron"
      }
    }
  },
  "api-plugin": {
    name: "API Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/api.md",
    dependencies: {
      "hono": {
        version: "^4.0.0",
        description: "Ultra-light HTTP server framework",
        installCommand: "pnpm add hono",
        npmUrl: "https://www.npmjs.com/package/hono"
      },
      "@hono/node-server": {
        version: "^1.0.0",
        description: "Node.js adapter for Hono",
        installCommand: "pnpm add @hono/node-server",
        npmUrl: "https://www.npmjs.com/package/@hono/node-server"
      },
      "@hono/swagger-ui": {
        version: "^0.4.0",
        description: "Swagger UI integration for Hono",
        installCommand: "pnpm add @hono/swagger-ui",
        npmUrl: "https://www.npmjs.com/package/@hono/swagger-ui"
      },
      "jose": {
        version: "^5.0.0 || ^6.0.0",
        description: "Universal JOSE and JWE implementation (for OAuth2 token validation)",
        installCommand: "pnpm add jose",
        npmUrl: "https://www.npmjs.com/package/jose"
      }
    }
  },
  "identity-plugin": {
    name: "Identity Provider Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/identity.md",
    dependencies: {
      "hono": {
        version: "^4.0.0",
        description: "Ultra-light HTTP server framework",
        installCommand: "pnpm add hono",
        npmUrl: "https://www.npmjs.com/package/hono"
      },
      "@hono/node-server": {
        version: "^1.0.0",
        description: "Node.js adapter for Hono",
        installCommand: "pnpm add @hono/node-server",
        npmUrl: "https://www.npmjs.com/package/@hono/node-server"
      },
      "jose": {
        version: "^5.0.0 || ^6.0.0",
        description: "Universal JOSE and JWE implementation (for RSA key generation and JWT signing)",
        installCommand: "pnpm add jose",
        npmUrl: "https://www.npmjs.com/package/jose"
      },
      "bcrypt": {
        version: "^5.1.0",
        description: "Secure password hashing library",
        installCommand: "pnpm add bcrypt",
        npmUrl: "https://www.npmjs.com/package/bcrypt"
      },
      "nodemailer": {
        version: "^6.9.0",
        description: "Email sending library for password reset and verification",
        installCommand: "pnpm add nodemailer",
        npmUrl: "https://www.npmjs.com/package/nodemailer"
      }
    }
  },
  "ml-plugin": {
    name: "ML Plugin",
    docsUrl: "https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/ml-plugin.md",
    dependencies: {
      "@tensorflow/tfjs-node": {
        version: "^4.0.0",
        description: "TensorFlow.js for Node.js with native bindings",
        installCommand: "pnpm add @tensorflow/tfjs-node",
        npmUrl: "https://www.npmjs.com/package/@tensorflow/tfjs-node"
      }
    }
  }
};
function isVersionCompatible(actual, required) {
  if (!actual || !required) return false;
  if (required.includes("||")) {
    const ranges = required.split("||").map((r) => r.trim());
    return ranges.some((range) => isVersionCompatible(actual, range));
  }
  const cleanRequired = required.replace(/^[\^~]/, "");
  const actualMajor = parseInt(actual.split(".")[0], 10);
  const requiredMajor = parseInt(cleanRequired.split(".")[0], 10);
  if (required.startsWith("^")) {
    return actualMajor === requiredMajor;
  }
  if (required.startsWith("~")) {
    const actualMinor = parseInt(actual.split(".")[1] || "0", 10);
    const requiredMinor = parseInt(cleanRequired.split(".")[1] || "0", 10);
    return actualMajor === requiredMajor && actualMinor >= requiredMinor;
  }
  return actualMajor >= requiredMajor;
}
async function tryLoadPackage(packageName) {
  try {
    const pkg = await import(packageName);
    let version = null;
    try {
      const pkgJson = await import(`${packageName}/package.json`, { assert: { type: 'json' } });
      version = pkgJson.default?.version || pkgJson.version || null;
    } catch (e) {
      version = "unknown";
    }
    return { installed: true, version, error: null };
  } catch (error) {
    return { installed: false, version: null, error };
  }
}
async function requirePluginDependency(pluginId, options = {}) {
  const {
    throwOnError = true,
    checkVersions = true
  } = options;
  const pluginDef = PLUGIN_DEPENDENCIES[pluginId];
  if (!pluginDef) {
    const error = new Error(
      `Unknown plugin identifier: ${pluginId}. Available plugins: ${Object.keys(PLUGIN_DEPENDENCIES).join(", ")}`
    );
    if (throwOnError) throw error;
    return { valid: false, missing: [], incompatible: [], messages: [error.message] };
  }
  const missing = [];
  const incompatible = [];
  const messages = [];
  for (const [pkgName, pkgInfo] of Object.entries(pluginDef.dependencies)) {
    const { installed, version, error } = await tryLoadPackage(pkgName);
    if (!installed) {
      missing.push(pkgName);
      messages.push(
        `\u274C Missing dependency: ${pkgName}
   Description: ${pkgInfo.description}
   Required: ${pkgInfo.version}
   Install: ${pkgInfo.installCommand}`
      );
      continue;
    }
    if (checkVersions && version && version !== "unknown") {
      const compatible = isVersionCompatible(version, pkgInfo.version);
      if (!compatible) {
        incompatible.push(pkgName);
        messages.push(
          `\u26A0\uFE0F  Incompatible version: ${pkgName}
   Installed: ${version}
   Required: ${pkgInfo.version}
   Update: ${pkgInfo.installCommand}`
        );
      } else {
        messages.push(
          `\u2705 ${pkgName}@${version} (compatible with ${pkgInfo.version})`
        );
      }
    } else {
      messages.push(
        `\u2705 ${pkgName}@${version || "unknown"} (installed)`
      );
    }
  }
  const valid = missing.length === 0 && incompatible.length === 0;
  if (!valid && throwOnError) {
    const depCount = Object.keys(pluginDef.dependencies).length;
    const missingCount = missing.length;
    const incompatCount = incompatible.length;
    const errorMsg = [
      "",
      "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557",
      `\u2551  \u274C ${pluginDef.name} - Missing Dependencies  \u2551`,
      "\u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D",
      "",
      `\u{1F4E6} Plugin: ${pluginId}`,
      `\u{1F4CA} Status: ${depCount - missingCount - incompatCount}/${depCount} dependencies satisfied`,
      "",
      "\u{1F50D} Dependency Status:",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
      ...messages,
      "",
      "\u{1F680} Quick Fix - Install Missing Dependencies:",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
      "",
      "  Option 1: Install individually",
      ...Object.entries(pluginDef.dependencies).filter(([pkg]) => missing.includes(pkg) || incompatible.includes(pkg)).map(([pkg, info]) => `    ${info.installCommand}`),
      "",
      "  Option 2: Install all at once",
      `    pnpm add ${Object.keys(pluginDef.dependencies).join(" ")}`,
      "",
      "\u{1F4DA} Documentation:",
      `    ${pluginDef.docsUrl}`,
      "",
      "\u{1F4A1} Troubleshooting:",
      "  \u2022 If packages are installed but not detected, try:",
      "    1. Delete node_modules and reinstall: rm -rf node_modules && pnpm install",
      "    2. Check Node.js version: node --version (requires Node 18+)",
      "    3. Verify pnpm version: pnpm --version (requires pnpm 8+)",
      "",
      "  \u2022 Still having issues? Check:",
      "    - Package.json has correct dependencies listed",
      "    - No conflicting versions in pnpm-lock.yaml",
      "    - File permissions (especially in node_modules/)",
      "",
      "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
      ""
    ].join("\n");
    const error = new Error(errorMsg);
    error.pluginId = pluginId;
    error.pluginName = pluginDef.name;
    error.missing = missing;
    error.incompatible = incompatible;
    error.docsUrl = pluginDef.docsUrl;
    throw error;
  }
  return { valid, missing, incompatible, messages };
}

function success$1(data, options = {}) {
  const { status = 200, meta = {} } = options;
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      ...meta
    },
    _status: status
  };
}
function error$1(error2, options = {}) {
  const { status = 500, code = "INTERNAL_ERROR", details = {} } = options;
  const errorMessage = error2 instanceof Error ? error2.message : error2;
  const errorStack = error2 instanceof Error && process.env.NODE_ENV !== "production" ? error2.stack : void 0;
  return {
    success: false,
    error: {
      message: errorMessage,
      code,
      details,
      stack: errorStack
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: status
  };
}
function list(items, pagination = {}) {
  const { total, page, pageSize, pageCount } = pagination;
  return {
    success: true,
    data: items,
    pagination: {
      total: total || items.length,
      page: page || 1,
      pageSize: pageSize || items.length,
      pageCount: pageCount || 1
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: 200
  };
}
function created(data, location) {
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      location
    },
    _status: 201
  };
}
function noContent() {
  return {
    success: true,
    data: null,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: 204
  };
}
function validationError(errors) {
  return error$1("Validation failed", {
    status: 400,
    code: "VALIDATION_ERROR",
    details: { errors }
  });
}
function notFound(resource, id) {
  return error$1(`${resource} with id '${id}' not found`, {
    status: 404,
    code: "NOT_FOUND",
    details: { resource, id }
  });
}
function unauthorized(message = "Unauthorized") {
  return error$1(message, {
    status: 401,
    code: "UNAUTHORIZED"
  });
}

const errorStatusMap$1 = {
  "ValidationError": 400,
  "InvalidResourceItem": 400,
  "ResourceNotFound": 404,
  "NoSuchKey": 404,
  "NoSuchBucket": 404,
  "PartitionError": 400,
  "CryptoError": 500,
  "SchemaError": 400,
  "QueueError": 500,
  "ResourceError": 500
};
function getStatusFromError$1(err) {
  if (err.name && errorStatusMap$1[err.name]) {
    return errorStatusMap$1[err.name];
  }
  if (err.constructor && err.constructor.name && errorStatusMap$1[err.constructor.name]) {
    return errorStatusMap$1[err.constructor.name];
  }
  if (err.message) {
    if (err.message.includes("not found") || err.message.includes("does not exist")) {
      return 404;
    }
    if (err.message.includes("validation") || err.message.includes("invalid")) {
      return 400;
    }
    if (err.message.includes("unauthorized") || err.message.includes("authentication")) {
      return 401;
    }
    if (err.message.includes("forbidden") || err.message.includes("permission")) {
      return 403;
    }
  }
  return 500;
}
function errorHandler$1(err, c) {
  const status = getStatusFromError$1(err);
  const code = err.name || "INTERNAL_ERROR";
  const details = {};
  if (err.resource) details.resource = err.resource;
  if (err.bucket) details.bucket = err.bucket;
  if (err.key) details.key = err.key;
  if (err.operation) details.operation = err.operation;
  if (err.suggestion) details.suggestion = err.suggestion;
  if (err.availableResources) details.availableResources = err.availableResources;
  const response = error$1(err, {
    status,
    code,
    details
  });
  if (status >= 500) {
    console.error("[API Plugin] Error:", {
      message: err.message,
      code,
      status,
      stack: err.stack,
      details
    });
  } else if (status >= 400 && status < 500 && c.get("verbose")) {
    console.warn("[API Plugin] Client error:", {
      message: err.message,
      code,
      status,
      details
    });
  }
  return c.json(response, response._status);
}
function asyncHandler(fn) {
  return async (c) => {
    try {
      return await fn(c);
    } catch (err) {
      return errorHandler$1(err, c);
    }
  };
}

function checkGuard(user, guard, context = {}) {
  if (!guard) {
    return true;
  }
  if (!user && guard !== true) {
    return false;
  }
  if (typeof guard === "boolean") {
    return guard;
  }
  if (typeof guard === "function") {
    try {
      return guard(user, context);
    } catch (err) {
      console.error("[Guards] Error executing guard function:", err);
      return false;
    }
  }
  if (typeof guard === "string") {
    return hasScope(user, guard);
  }
  if (Array.isArray(guard)) {
    return guard.some((scope) => hasScope(user, scope));
  }
  if (typeof guard === "object") {
    if (guard.role) {
      if (Array.isArray(guard.role)) {
        if (!guard.role.includes(user.role)) {
          return false;
        }
      } else if (user.role !== guard.role) {
        return false;
      }
    }
    if (guard.scopes) {
      const requiredScopes = Array.isArray(guard.scopes) ? guard.scopes : [guard.scopes];
      if (!requiredScopes.every((scope) => hasScope(user, scope))) {
        return false;
      }
    }
    if (guard.check && typeof guard.check === "function") {
      try {
        return guard.check(user, context);
      } catch (err) {
        console.error("[Guards] Error executing guard.check function:", err);
        return false;
      }
    }
    return true;
  }
  return false;
}
function hasScope(user, scope) {
  if (!user || !user.scopes) {
    return false;
  }
  if (!Array.isArray(user.scopes)) {
    return false;
  }
  if (user.scopes.includes(scope)) {
    return true;
  }
  const wildcards = user.scopes.filter((s) => s.endsWith(":*"));
  for (const wildcard of wildcards) {
    const prefix = wildcard.slice(0, -2);
    if (scope.startsWith(prefix + ":")) {
      return true;
    }
  }
  if (user.scopes.includes("*")) {
    return true;
  }
  return false;
}
function getOperationGuard(guards, operation) {
  if (!guards) {
    return null;
  }
  if (typeof guards === "function" || typeof guards === "string" || Array.isArray(guards)) {
    return guards;
  }
  if (typeof guards === "object") {
    if (guards[operation] !== void 0) {
      return guards[operation];
    }
    if (guards.all !== void 0) {
      return guards.all;
    }
    const aliases = {
      list: "read",
      get: "read",
      create: "write",
      update: "write",
      delete: "write"
    };
    if (aliases[operation] && guards[aliases[operation]] !== void 0) {
      return guards[aliases[operation]];
    }
  }
  return null;
}
function guardMiddleware(guards, operation) {
  return async (c, next) => {
    const user = c.get("user");
    const guard = getOperationGuard(guards, operation);
    const authorized = checkGuard(user, guard, {
      operation,
      resourceName: c.req.param("resource"),
      data: c.req.method !== "GET" ? await c.req.json().catch(() => ({})) : {}
    });
    if (!authorized) {
      return c.json({
        success: false,
        error: {
          message: "Forbidden: Insufficient permissions",
          code: "FORBIDDEN",
          details: {
            operation,
            user: user ? { id: user.id, role: user.role } : null
          }
        },
        _status: 403
      }, 403);
    }
    await next();
  };
}

function parseCustomRoute(routeDef) {
  let def = routeDef.trim();
  const isAsync = def.startsWith("async ");
  if (isAsync) {
    def = def.substring(6).trim();
  }
  const parts = def.split(/\s+/);
  if (parts.length < 2) {
    throw new Error(`Invalid route definition: "${routeDef}". Expected format: "METHOD /path" or "async METHOD /path"`);
  }
  const method = parts[0].toUpperCase();
  const path = parts.slice(1).join(" ").trim();
  const validMethods = ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"];
  if (!validMethods.includes(method)) {
    throw new Error(`Invalid HTTP method: "${method}". Must be one of: ${validMethods.join(", ")}`);
  }
  if (!path.startsWith("/")) {
    throw new Error(`Invalid route path: "${path}". Path must start with "/"`);
  }
  return { method, path, isAsync };
}
function createResourceRoutes(resource, version, config = {}, Hono) {
  const app = new Hono();
  const {
    methods = ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"],
    customMiddleware = [],
    enableValidation = true,
    versionPrefix = ""
    // Empty string by default (calculated in server.js)
  } = config;
  const resourceName = resource.name;
  const basePath = versionPrefix ? `/${versionPrefix}/${resourceName}` : `/${resourceName}`;
  const guards = resource.config?.guards || null;
  customMiddleware.forEach((middleware) => {
    app.use("*", middleware);
  });
  if (resource.config?.api && typeof resource.config.api === "object") {
    for (const [routeDef, handler] of Object.entries(resource.config.api)) {
      try {
        const { method, path } = parseCustomRoute(routeDef);
        if (typeof handler !== "function") {
          throw new Error(`Handler for route "${routeDef}" must be a function`);
        }
        app.on(method, path, asyncHandler(async (c) => {
          const result = await handler(c, { resource, database: resource.database });
          if (result && result.constructor && result.constructor.name === "Response") {
            return result;
          }
          if (result !== void 0 && result !== null) {
            return c.json(success$1(result));
          }
          return c.json(noContent(), 204);
        }));
        if (config.verbose || resource.database?.verbose) {
          console.log(`[API Plugin] Registered custom route for ${resourceName}: ${method} ${path}`);
        }
      } catch (error) {
        console.error(`[API Plugin] Error registering custom route "${routeDef}" for ${resourceName}:`, error.message);
        throw error;
      }
    }
  }
  if (methods.includes("GET")) {
    app.get("/", guardMiddleware(guards, "list"), asyncHandler(async (c) => {
      const query = c.req.query();
      const limit = parseInt(query.limit) || 100;
      const offset = parseInt(query.offset) || 0;
      const partition = query.partition;
      const partitionValues = query.partitionValues ? JSON.parse(query.partitionValues) : void 0;
      const reservedKeys = ["limit", "offset", "partition", "partitionValues", "sort"];
      const filters = {};
      for (const [key, value] of Object.entries(query)) {
        if (!reservedKeys.includes(key)) {
          try {
            filters[key] = JSON.parse(value);
          } catch {
            filters[key] = value;
          }
        }
      }
      let items;
      let total;
      if (Object.keys(filters).length > 0) {
        items = await resource.query(filters, { limit, offset });
        total = items.length;
      } else if (partition && partitionValues) {
        items = await resource.listPartition({
          partition,
          partitionValues,
          limit,
          offset
        });
        total = items.length;
      } else {
        items = await resource.list({ limit, offset });
        total = items.length;
      }
      const response = list(items, {
        total,
        page: Math.floor(offset / limit) + 1,
        pageSize: limit,
        pageCount: Math.ceil(total / limit)
      });
      c.header("X-Total-Count", total.toString());
      c.header("X-Page-Count", Math.ceil(total / limit).toString());
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("GET")) {
    app.get("/:id", guardMiddleware(guards, "get"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const query = c.req.query();
      const partition = query.partition;
      const partitionValues = query.partitionValues ? JSON.parse(query.partitionValues) : void 0;
      let item;
      if (partition && partitionValues) {
        item = await resource.getFromPartition({
          id,
          partitionName: partition,
          partitionValues
        });
      } else {
        item = await resource.get(id);
      }
      if (!item) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const response = success$1(item);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("POST")) {
    app.post("/", guardMiddleware(guards, "create"), asyncHandler(async (c) => {
      const data = await c.req.json();
      const item = await resource.insert(data);
      const location = `${basePath}/${item.id}`;
      const response = created(item, location);
      c.header("Location", location);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("PUT")) {
    app.put("/:id", guardMiddleware(guards, "update"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const data = await c.req.json();
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const updated = await resource.update(id, data);
      const response = success$1(updated);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("PATCH")) {
    app.patch("/:id", guardMiddleware(guards, "update"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const data = await c.req.json();
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      const merged = { ...existing, ...data, id };
      const updated = await resource.update(id, merged);
      const response = success$1(updated);
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("DELETE")) {
    app.delete("/:id", guardMiddleware(guards, "delete"), asyncHandler(async (c) => {
      const id = c.req.param("id");
      const existing = await resource.get(id);
      if (!existing) {
        const response2 = notFound(resourceName, id);
        return c.json(response2, response2._status);
      }
      await resource.delete(id);
      const response = noContent();
      return c.json(response, response._status);
    }));
  }
  if (methods.includes("HEAD")) {
    app.on("HEAD", "/", asyncHandler(async (c) => {
      const total = await resource.count();
      const version2 = resource.config?.currentVersion || resource.version || "v1";
      c.header("X-Total-Count", total.toString());
      c.header("X-Resource-Version", version2);
      c.header("X-Schema-Fields", Object.keys(resource.config?.attributes || {}).length.toString());
      return c.body(null, 200);
    }));
    app.on("HEAD", "/:id", asyncHandler(async (c) => {
      const id = c.req.param("id");
      const item = await resource.get(id);
      if (!item) {
        return c.body(null, 404);
      }
      if (item.updatedAt) {
        c.header("Last-Modified", new Date(item.updatedAt).toUTCString());
      }
      return c.body(null, 200);
    }));
  }
  if (methods.includes("OPTIONS")) {
    app.options("/", asyncHandler(async (c) => {
      c.header("Allow", methods.join(", "));
      const total = await resource.count();
      const schema = resource.config?.attributes || {};
      const version2 = resource.config?.currentVersion || resource.version || "v1";
      const metadata = {
        resource: resourceName,
        version: version2,
        totalRecords: total,
        allowedMethods: methods,
        schema: Object.entries(schema).map(([name, def]) => ({
          name,
          type: typeof def === "string" ? def.split("|")[0] : def.type,
          rules: typeof def === "string" ? def.split("|").slice(1) : []
        })),
        endpoints: {
          list: `/${version2}/${resourceName}`,
          get: `/${version2}/${resourceName}/:id`,
          create: `/${version2}/${resourceName}`,
          update: `/${version2}/${resourceName}/:id`,
          delete: `/${version2}/${resourceName}/:id`
        },
        queryParameters: {
          limit: "number (1-1000, default: 100)",
          offset: "number (min: 0, default: 0)",
          partition: "string (partition name)",
          partitionValues: "JSON string",
          "[any field]": "any (filter by field value)"
        }
      };
      return c.json(metadata);
    }));
    app.options("/:id", (c) => {
      c.header("Allow", methods.filter((m) => m !== "POST").join(", "));
      return c.body(null, 204);
    });
  }
  return app;
}
function createRelationalRoutes(sourceResource, relationName, relationConfig, version, Hono) {
  const app = new Hono();
  const resourceName = sourceResource.name;
  const relatedResourceName = relationConfig.resource;
  app.get("/", asyncHandler(async (c) => {
    const pathParts = c.req.path.split("/");
    const relationNameIndex = pathParts.lastIndexOf(relationName);
    const id = pathParts[relationNameIndex - 1];
    const query = c.req.query();
    const source = await sourceResource.get(id);
    if (!source) {
      const response = notFound(resourceName, id);
      return c.json(response, response._status);
    }
    const result = await sourceResource.get(id, {
      include: [relationName]
    });
    const relatedData = result[relationName];
    if (!relatedData) {
      if (relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany") {
        const response = list([], {
          total: 0,
          page: 1,
          pageSize: 100,
          pageCount: 0
        });
        return c.json(response, response._status);
      } else {
        const response = notFound(relatedResourceName, "related resource");
        return c.json(response, response._status);
      }
    }
    if (relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany") {
      const items = Array.isArray(relatedData) ? relatedData : [relatedData];
      const limit = parseInt(query.limit) || 100;
      const offset = parseInt(query.offset) || 0;
      const paginatedItems = items.slice(offset, offset + limit);
      const response = list(paginatedItems, {
        total: items.length,
        page: Math.floor(offset / limit) + 1,
        pageSize: limit,
        pageCount: Math.ceil(items.length / limit)
      });
      c.header("X-Total-Count", items.length.toString());
      c.header("X-Page-Count", Math.ceil(items.length / limit).toString());
      return c.json(response, response._status);
    } else {
      const response = success$1(relatedData);
      return c.json(response, response._status);
    }
  }));
  return app;
}

function createToken(payload, secret, expiresIn = "7d") {
  const match = expiresIn.match(/^(\d+)([smhd])$/);
  if (!match) {
    throw new Error("Invalid expiresIn format. Use: 60s, 30m, 24h, 7d");
  }
  const [, value, unit] = match;
  const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
  const expiresInSeconds = parseInt(value) * multipliers[unit];
  const header = { alg: "HS256", typ: "JWT" };
  const now = Math.floor(Date.now() / 1e3);
  const data = {
    ...payload,
    iat: now,
    exp: now + expiresInSeconds
  };
  const encodedHeader = Buffer.from(JSON.stringify(header)).toString("base64url");
  const encodedPayload = Buffer.from(JSON.stringify(data)).toString("base64url");
  const signature = createHash("sha256").update(`${encodedHeader}.${encodedPayload}.${secret}`).digest("base64url");
  return `${encodedHeader}.${encodedPayload}.${signature}`;
}
function verifyToken(token, secret) {
  try {
    const [encodedHeader, encodedPayload, signature] = token.split(".");
    if (!encodedHeader || !encodedPayload || !signature) {
      return null;
    }
    const expectedSignature = createHash("sha256").update(`${encodedHeader}.${encodedPayload}.${secret}`).digest("base64url");
    if (signature !== expectedSignature) {
      return null;
    }
    const payload = JSON.parse(Buffer.from(encodedPayload, "base64url").toString());
    const now = Math.floor(Date.now() / 1e3);
    if (payload.exp && payload.exp < now) {
      return null;
    }
    return payload;
  } catch (err) {
    return null;
  }
}
function jwtAuth(options = {}) {
  const { secret, usersResource, optional = false } = options;
  if (!secret) {
    throw new Error("JWT secret is required");
  }
  return async (c, next) => {
    const authHeader = c.req.header("authorization");
    if (!authHeader) {
      if (optional) {
        return await next();
      }
      const response = unauthorized("No authorization header provided");
      return c.json(response, response._status);
    }
    const match = authHeader.match(/^Bearer\s+(.+)$/i);
    if (!match) {
      const response = unauthorized("Invalid authorization header format. Use: Bearer <token>");
      return c.json(response, response._status);
    }
    const token = match[1];
    const payload = verifyToken(token, secret);
    if (!payload) {
      const response = unauthorized("Invalid or expired token");
      return c.json(response, response._status);
    }
    if (usersResource && payload.userId) {
      try {
        const user = await usersResource.get(payload.userId);
        if (!user) {
          const response = unauthorized("User not found");
          return c.json(response, response._status);
        }
        if (!user.active) {
          const response = unauthorized("User account is inactive");
          return c.json(response, response._status);
        }
        c.set("user", user);
        c.set("authMethod", "jwt");
      } catch (err) {
        console.error("[JWT Auth] Error loading user:", err);
        const response = unauthorized("Authentication error");
        return c.json(response, response._status);
      }
    } else {
      c.set("user", payload);
      c.set("authMethod", "jwt");
    }
    await next();
  };
}

function generateApiKey(length = 32) {
  const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
  let apiKey = "";
  for (let i = 0; i < length; i++) {
    apiKey += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return apiKey;
}
function apiKeyAuth(options = {}) {
  const {
    headerName = "X-API-Key",
    usersResource,
    optional = false
  } = options;
  if (!usersResource) {
    throw new Error("usersResource is required for API key authentication");
  }
  return async (c, next) => {
    const apiKey = c.req.header(headerName);
    if (!apiKey) {
      if (optional) {
        return await next();
      }
      const response = unauthorized(`Missing ${headerName} header`);
      return c.json(response, response._status);
    }
    try {
      const users = await usersResource.query({ apiKey });
      if (!users || users.length === 0) {
        const response = unauthorized("Invalid API key");
        return c.json(response, response._status);
      }
      const user = users[0];
      if (!user.active) {
        const response = unauthorized("User account is inactive");
        return c.json(response, response._status);
      }
      c.set("user", user);
      c.set("authMethod", "apiKey");
      await next();
    } catch (err) {
      console.error("[API Key Auth] Error validating key:", err);
      const response = unauthorized("Authentication error");
      return c.json(response, response._status);
    }
  };
}

function createAuthRoutes(authResource, config = {}) {
  const app = new Hono();
  const {
    driver,
    // 'jwt' or 'basic'
    usernameField = "email",
    // Field name for username (default: 'email')
    passwordField = "password",
    // Field name for password (default: 'password')
    jwtSecret,
    jwtExpiresIn = "7d",
    passphrase = "secret",
    allowRegistration = true
  } = config;
  if (allowRegistration) {
    app.post("/register", asyncHandler(async (c) => {
      const data = await c.req.json();
      const username = data[usernameField];
      const password = data[passwordField];
      const role = data.role || "user";
      if (!username || !password) {
        const response2 = validationError([
          { field: usernameField, message: `${usernameField} is required` },
          { field: passwordField, message: `${passwordField} is required` }
        ]);
        return c.json(response2, response2._status);
      }
      if (password.length < 8) {
        const response2 = validationError([
          { field: passwordField, message: "Password must be at least 8 characters" }
        ]);
        return c.json(response2, response2._status);
      }
      const queryFilter = { [usernameField]: username };
      const existing = await authResource.query(queryFilter);
      if (existing && existing.length > 0) {
        const response2 = error$1(`${usernameField} already exists`, {
          status: 409,
          code: "CONFLICT"
        });
        return c.json(response2, response2._status);
      }
      const userData = {
        ...data,
        // Include all fields from request first
        [usernameField]: username,
        // Override to ensure correct value
        [passwordField]: password
        // Will be auto-encrypted by schema (secret field)
      };
      if (!userData.role) {
        userData.role = role;
      }
      if (userData.active === void 0) {
        userData.active = true;
      }
      const user = await authResource.insert(userData);
      let token = null;
      if (driver === "jwt" && jwtSecret) {
        token = createToken(
          {
            userId: user.id,
            [usernameField]: user[usernameField],
            role: user.role
          },
          jwtSecret,
          jwtExpiresIn
        );
      }
      const { [passwordField]: _, ...userWithoutPassword } = user;
      const response = created({
        user: userWithoutPassword,
        ...token && { token }
        // Only include token if JWT driver
      }, `/auth/users/${user.id}`);
      return c.json(response, response._status);
    }));
  }
  if (driver === "jwt") {
    app.post("/login", asyncHandler(async (c) => {
      const data = await c.req.json();
      const username = data[usernameField];
      const password = data[passwordField];
      if (!username || !password) {
        const response2 = unauthorized(`${usernameField} and ${passwordField} are required`);
        return c.json(response2, response2._status);
      }
      const queryFilter = { [usernameField]: username };
      const users = await authResource.query(queryFilter);
      if (!users || users.length === 0) {
        const response2 = unauthorized("Invalid credentials");
        return c.json(response2, response2._status);
      }
      const user = users[0];
      if (user.active !== void 0 && !user.active) {
        const response2 = unauthorized("User account is inactive");
        return c.json(response2, response2._status);
      }
      const isValid = user[passwordField] === password;
      if (!isValid) {
        const response2 = unauthorized("Invalid credentials");
        return c.json(response2, response2._status);
      }
      if (user.lastLoginAt !== void 0) {
        await authResource.update(user.id, {
          lastLoginAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
      let token = null;
      if (jwtSecret) {
        token = createToken(
          {
            userId: user.id,
            [usernameField]: user[usernameField],
            role: user.role
          },
          jwtSecret,
          jwtExpiresIn
        );
      }
      const { [passwordField]: _, ...userWithoutPassword } = user;
      const response = success$1({
        user: userWithoutPassword,
        token,
        expiresIn: jwtExpiresIn
      });
      return c.json(response, response._status);
    }));
  }
  if (jwtSecret) {
    app.post("/token/refresh", asyncHandler(async (c) => {
      const user = c.get("user");
      if (!user) {
        const response2 = unauthorized("Authentication required");
        return c.json(response2, response2._status);
      }
      const token = createToken(
        { userId: user.id, username: user.username, role: user.role },
        jwtSecret,
        jwtExpiresIn
      );
      const response = success$1({
        token,
        expiresIn: jwtExpiresIn
      });
      return c.json(response, response._status);
    }));
  }
  app.get("/me", asyncHandler(async (c) => {
    const user = c.get("user");
    if (!user) {
      const response2 = unauthorized("Authentication required");
      return c.json(response2, response2._status);
    }
    if (!user.password) {
      const response2 = success$1(user);
      return c.json(response2, response2._status);
    }
    const { password: _, ...userWithoutPassword } = user;
    const response = success$1(userWithoutPassword);
    return c.json(response, response._status);
  }));
  app.post("/api-key/regenerate", asyncHandler(async (c) => {
    const user = c.get("user");
    if (!user) {
      const response2 = unauthorized("Authentication required");
      return c.json(response2, response2._status);
    }
    const newApiKey = generateApiKey();
    await usersResource.update(user.id, {
      apiKey: newApiKey
    });
    const response = success$1({
      apiKey: newApiKey,
      message: "API key regenerated successfully"
    });
    return c.json(response, response._status);
  }));
  return app;
}

function parseRouteKey(key) {
  const match = key.match(/^(GET|POST|PUT|PATCH|DELETE|HEAD|OPTIONS)\s+(.+)$/i);
  if (!match) {
    throw new Error(`Invalid route key format: "${key}". Expected format: "METHOD /path"`);
  }
  return {
    method: match[1].toUpperCase(),
    path: match[2]
  };
}
function mountCustomRoutes(app, routes, context = {}, verbose = false) {
  if (!routes || typeof routes !== "object") {
    return;
  }
  for (const [key, handler] of Object.entries(routes)) {
    try {
      const { method, path } = parseRouteKey(key);
      const wrappedHandler = asyncHandler(async (c) => {
        c.set("customRouteContext", context);
        return await handler(c);
      });
      app.on(method, path, wrappedHandler);
      if (verbose) {
        console.log(`[Custom Routes] Mounted ${method} ${path}`);
      }
    } catch (err) {
      console.error(`[Custom Routes] Error mounting route "${key}":`, err.message);
    }
  }
}

function success(data, options = {}) {
  const { status = 200, meta = {} } = options;
  return {
    success: true,
    data,
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      ...meta
    },
    _status: status
  };
}
function error(error2, options = {}) {
  const { status = 500, code = "INTERNAL_ERROR", details = {} } = options;
  const errorMessage = error2 instanceof Error ? error2.message : error2;
  const errorStack = error2 instanceof Error && process.env.NODE_ENV !== "production" ? error2.stack : void 0;
  return {
    success: false,
    error: {
      message: errorMessage,
      code,
      details,
      stack: errorStack
    },
    meta: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    },
    _status: status
  };
}
function payloadTooLarge(size, limit) {
  return error("Request payload too large", {
    status: 413,
    code: "PAYLOAD_TOO_LARGE",
    details: {
      receivedSize: size,
      maxSize: limit,
      receivedMB: (size / 1024 / 1024).toFixed(2),
      maxMB: (limit / 1024 / 1024).toFixed(2)
    }
  });
}

const errorStatusMap = {
  "ValidationError": 400,
  "InvalidResourceItem": 400,
  "ResourceNotFound": 404,
  "NoSuchKey": 404,
  "NoSuchBucket": 404,
  "PartitionError": 400,
  "CryptoError": 500,
  "SchemaError": 400,
  "QueueError": 500,
  "ResourceError": 500
};
function getStatusFromError(err) {
  if (err.name && errorStatusMap[err.name]) {
    return errorStatusMap[err.name];
  }
  if (err.constructor && err.constructor.name && errorStatusMap[err.constructor.name]) {
    return errorStatusMap[err.constructor.name];
  }
  if (err.message) {
    if (err.message.includes("not found") || err.message.includes("does not exist")) {
      return 404;
    }
    if (err.message.includes("validation") || err.message.includes("invalid")) {
      return 400;
    }
    if (err.message.includes("unauthorized") || err.message.includes("authentication")) {
      return 401;
    }
    if (err.message.includes("forbidden") || err.message.includes("permission")) {
      return 403;
    }
  }
  return 500;
}
function errorHandler(err, c) {
  const status = getStatusFromError(err);
  const code = err.name || "INTERNAL_ERROR";
  const details = {};
  if (err.resource) details.resource = err.resource;
  if (err.bucket) details.bucket = err.bucket;
  if (err.key) details.key = err.key;
  if (err.operation) details.operation = err.operation;
  if (err.suggestion) details.suggestion = err.suggestion;
  if (err.availableResources) details.availableResources = err.availableResources;
  const response = error(err, {
    status,
    code,
    details
  });
  if (status >= 500) {
    console.error("[API Plugin] Error:", {
      message: err.message,
      code,
      status,
      stack: err.stack,
      details
    });
  } else if (status >= 400 && status < 500 && c.get("verbose")) {
    console.warn("[API Plugin] Client error:", {
      message: err.message,
      code,
      status,
      details
    });
  }
  return c.json(response, response._status);
}

function mapFieldTypeToOpenAPI(fieldType) {
  const type = fieldType.split("|")[0].trim();
  const typeMap = {
    "string": { type: "string" },
    "number": { type: "number" },
    "integer": { type: "integer" },
    "boolean": { type: "boolean" },
    "array": { type: "array", items: { type: "string" } },
    "object": { type: "object" },
    "json": { type: "object" },
    "secret": { type: "string", format: "password" },
    "email": { type: "string", format: "email" },
    "url": { type: "string", format: "uri" },
    "date": { type: "string", format: "date" },
    "datetime": { type: "string", format: "date-time" },
    "ip4": { type: "string", format: "ipv4", description: "IPv4 address" },
    "ip6": { type: "string", format: "ipv6", description: "IPv6 address" },
    "embedding": { type: "array", items: { type: "number" }, description: "Vector embedding" }
  };
  if (type.startsWith("embedding:")) {
    const length = parseInt(type.split(":")[1]);
    return {
      type: "array",
      items: { type: "number" },
      minItems: length,
      maxItems: length,
      description: `Vector embedding (${length} dimensions)`
    };
  }
  return typeMap[type] || { type: "string" };
}
function extractValidationRules(fieldDef) {
  const rules = {};
  const parts = fieldDef.split("|");
  for (const part of parts) {
    const [rule, value] = part.split(":").map((s) => s.trim());
    switch (rule) {
      case "required":
        rules.required = true;
        break;
      case "min":
        rules.minimum = parseFloat(value);
        break;
      case "max":
        rules.maximum = parseFloat(value);
        break;
      case "minlength":
        rules.minLength = parseInt(value);
        break;
      case "maxlength":
        rules.maxLength = parseInt(value);
        break;
      case "pattern":
        rules.pattern = value;
        break;
      case "enum":
        rules.enum = value.split(",").map((v) => v.trim());
        break;
      case "default":
        rules.default = value;
        break;
    }
  }
  return rules;
}
function generateResourceSchema(resource) {
  const properties = {};
  const required = [];
  const allAttributes = resource.config?.attributes || resource.attributes || {};
  const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
  const attributes = Object.fromEntries(
    Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
  );
  const resourceDescription = resource.config?.description;
  const attributeDescriptions = typeof resourceDescription === "object" ? resourceDescription.attributes || {} : {};
  properties.id = {
    type: "string",
    description: "Unique identifier for the resource",
    example: "2_gDTpeU6EI0e8B92n_R3Y",
    readOnly: true
  };
  for (const [fieldName, fieldDef] of Object.entries(attributes)) {
    if (typeof fieldDef === "object" && fieldDef.type) {
      const baseType = mapFieldTypeToOpenAPI(fieldDef.type);
      properties[fieldName] = {
        ...baseType,
        description: fieldDef.description || attributeDescriptions[fieldName] || void 0
      };
      if (fieldDef.required) {
        required.push(fieldName);
      }
      if (fieldDef.type === "object" && fieldDef.props) {
        properties[fieldName].properties = {};
        for (const [propName, propDef] of Object.entries(fieldDef.props)) {
          const propType = typeof propDef === "string" ? propDef : propDef.type;
          properties[fieldName].properties[propName] = mapFieldTypeToOpenAPI(propType);
        }
      }
      if (fieldDef.type === "array" && fieldDef.items) {
        properties[fieldName].items = mapFieldTypeToOpenAPI(fieldDef.items);
      }
    } else if (typeof fieldDef === "string") {
      const baseType = mapFieldTypeToOpenAPI(fieldDef);
      const rules = extractValidationRules(fieldDef);
      properties[fieldName] = {
        ...baseType,
        ...rules,
        description: attributeDescriptions[fieldName] || void 0
      };
      if (rules.required) {
        required.push(fieldName);
        delete properties[fieldName].required;
      }
    }
  }
  return {
    type: "object",
    properties,
    required: required.length > 0 ? required : void 0
  };
}
function generateResourcePaths(resource, version, config = {}) {
  const resourceName = resource.name;
  let versionPrefixConfig = config.versionPrefix !== void 0 ? config.versionPrefix : false;
  let prefix = "";
  if (versionPrefixConfig === true) {
    prefix = version;
  } else if (versionPrefixConfig === false) {
    prefix = "";
  } else if (typeof versionPrefixConfig === "string") {
    prefix = versionPrefixConfig;
  }
  const basePath = prefix ? `/${prefix}/${resourceName}` : `/${resourceName}`;
  const schema = generateResourceSchema(resource);
  const methods = config.methods || ["GET", "POST", "PUT", "PATCH", "DELETE"];
  const authMethods = config.auth || [];
  const requiresAuth = authMethods && authMethods.length > 0;
  const paths = {};
  const security = [];
  if (requiresAuth) {
    if (authMethods.includes("jwt")) security.push({ bearerAuth: [] });
    if (authMethods.includes("apiKey")) security.push({ apiKeyAuth: [] });
    if (authMethods.includes("basic")) security.push({ basicAuth: [] });
  }
  const partitions = resource.config?.options?.partitions || resource.config?.partitions || resource.partitions || {};
  const partitionNames = Object.keys(partitions);
  const hasPartitions = partitionNames.length > 0;
  let partitionDescription = "Partition name for filtering";
  let partitionValuesDescription = "Partition values as JSON string";
  let partitionExample = void 0;
  let partitionValuesExample = void 0;
  if (hasPartitions) {
    const partitionDocs = partitionNames.map((name) => {
      const partition = partitions[name];
      const fields = Object.keys(partition.fields || {});
      const fieldTypes = Object.entries(partition.fields || {}).map(([field, type]) => `${field}: ${type}`).join(", ");
      return `- **${name}**: Filters by ${fields.join(", ")} (${fieldTypes})`;
    }).join("\n");
    partitionDescription = `Available partitions:
${partitionDocs}`;
    const examplePartition = partitionNames[0];
    const exampleFields = partitions[examplePartition]?.fields || {};
    Object.entries(exampleFields).map(([field, type]) => `"${field}": <${type} value>`).join(", ");
    partitionValuesDescription = `Partition field values as JSON string. Must match the structure of the selected partition.

Example for "${examplePartition}" partition: \`{"${Object.keys(exampleFields)[0]}": "value"}\``;
    partitionExample = examplePartition;
    const firstField = Object.keys(exampleFields)[0];
    const firstFieldType = exampleFields[firstField];
    let exampleValue = "example";
    if (firstFieldType === "number" || firstFieldType === "integer") {
      exampleValue = 123;
    } else if (firstFieldType === "boolean") {
      exampleValue = true;
    }
    partitionValuesExample = JSON.stringify({ [firstField]: exampleValue });
  }
  const attributeQueryParams = [];
  if (hasPartitions) {
    const partitionFieldsSet = /* @__PURE__ */ new Set();
    for (const [partitionName, partition] of Object.entries(partitions)) {
      const fields = partition.fields || {};
      for (const fieldName of Object.keys(fields)) {
        partitionFieldsSet.add(fieldName);
      }
    }
    const allAttributes = resource.config?.attributes || resource.attributes || {};
    const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
    const attributes = Object.fromEntries(
      Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
    );
    for (const fieldName of partitionFieldsSet) {
      const fieldDef = attributes[fieldName];
      if (!fieldDef) continue;
      let fieldType;
      if (typeof fieldDef === "object" && fieldDef.type) {
        fieldType = fieldDef.type;
      } else if (typeof fieldDef === "string") {
        fieldType = fieldDef.split("|")[0].trim();
      } else {
        fieldType = "string";
      }
      const openAPIType = mapFieldTypeToOpenAPI(fieldType);
      attributeQueryParams.push({
        name: fieldName,
        in: "query",
        description: `Filter by ${fieldName} field (indexed via partitions for efficient querying). Value will be parsed as JSON if possible, otherwise treated as string.`,
        required: false,
        schema: openAPIType
      });
    }
  }
  if (methods.includes("GET")) {
    paths[basePath] = {
      get: {
        tags: [resourceName],
        summary: `List ${resourceName}`,
        description: `Retrieve a paginated list of ${resourceName}. Supports filtering by passing any resource field as a query parameter (e.g., ?status=active&year=2024). Values are parsed as JSON if possible, otherwise treated as strings.

**Pagination**: Use \`limit\` and \`offset\` to paginate results. For example:
- First page (10 items): \`?limit=10&offset=0\`
- Second page: \`?limit=10&offset=10\`
- Third page: \`?limit=10&offset=20\`

The response includes pagination metadata in the \`pagination\` object with total count and page information.${hasPartitions ? "\n\n**Partitioning**: This resource supports partitioned queries for optimized filtering. Use the `partition` and `partitionValues` parameters together." : ""}`,
        parameters: [
          {
            name: "limit",
            in: "query",
            description: "Maximum number of items to return per page (page size)",
            schema: { type: "integer", default: 100, minimum: 1, maximum: 1e3 },
            example: 10
          },
          {
            name: "offset",
            in: "query",
            description: "Number of items to skip before starting to return results. Use for pagination: offset = (page - 1) * limit",
            schema: { type: "integer", default: 0, minimum: 0 },
            example: 0
          },
          ...hasPartitions ? [
            {
              name: "partition",
              in: "query",
              description: partitionDescription,
              schema: {
                type: "string",
                enum: partitionNames
              },
              example: partitionExample
            },
            {
              name: "partitionValues",
              in: "query",
              description: partitionValuesDescription,
              schema: { type: "string" },
              example: partitionValuesExample
            }
          ] : [],
          ...attributeQueryParams
        ],
        responses: {
          200: {
            description: "Successful response",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "array",
                      items: schema
                    },
                    pagination: {
                      type: "object",
                      description: "Pagination metadata for the current request",
                      properties: {
                        total: {
                          type: "integer",
                          description: "Total number of items available",
                          example: 150
                        },
                        page: {
                          type: "integer",
                          description: "Current page number (1-indexed)",
                          example: 1
                        },
                        pageSize: {
                          type: "integer",
                          description: "Number of items per page (same as limit parameter)",
                          example: 10
                        },
                        pageCount: {
                          type: "integer",
                          description: "Total number of pages available",
                          example: 15
                        }
                      }
                    }
                  }
                }
              }
            },
            headers: {
              "X-Total-Count": {
                description: "Total number of records",
                schema: { type: "integer" }
              },
              "X-Page-Count": {
                description: "Total number of pages",
                schema: { type: "integer" }
              }
            }
          }
        },
        security: security.length > 0 ? security : void 0
      }
    };
  }
  if (methods.includes("GET")) {
    paths[`${basePath}/{id}`] = {
      get: {
        tags: [resourceName],
        summary: `Get ${resourceName} by ID`,
        description: `Retrieve a single ${resourceName} by its ID${hasPartitions ? ". Optionally specify a partition for more efficient retrieval." : ""}`,
        parameters: [
          {
            name: "id",
            in: "path",
            required: true,
            description: `${resourceName} ID`,
            schema: { type: "string" }
          },
          ...hasPartitions ? [
            {
              name: "partition",
              in: "query",
              description: partitionDescription,
              schema: {
                type: "string",
                enum: partitionNames
              },
              example: partitionExample
            },
            {
              name: "partitionValues",
              in: "query",
              description: partitionValuesDescription,
              schema: { type: "string" },
              example: partitionValuesExample
            }
          ] : []
        ],
        responses: {
          200: {
            description: "Successful response",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: schema
                  }
                }
              }
            }
          },
          404: {
            description: "Resource not found",
            content: {
              "application/json": {
                schema: { $ref: "#/components/schemas/Error" }
              }
            }
          }
        },
        security: security.length > 0 ? security : void 0
      }
    };
  }
  if (methods.includes("POST")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].post = {
      tags: [resourceName],
      summary: `Create ${resourceName}`,
      description: `Create a new ${resourceName}`,
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema
          }
        }
      },
      responses: {
        201: {
          description: "Resource created successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          },
          headers: {
            Location: {
              description: "URL of the created resource",
              schema: { type: "string" }
            }
          }
        },
        400: {
          description: "Validation error",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/ValidationError" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("PUT")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].put = {
      tags: [resourceName],
      summary: `Update ${resourceName} (full)`,
      description: `Fully update a ${resourceName}`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema
          }
        }
      },
      responses: {
        200: {
          description: "Resource updated successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          }
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("PATCH")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].patch = {
      tags: [resourceName],
      summary: `Update ${resourceName} (partial)`,
      description: `Partially update a ${resourceName}`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      requestBody: {
        required: true,
        content: {
          "application/json": {
            schema: {
              ...schema,
              required: void 0
              // Partial updates don't require all fields
            }
          }
        }
      },
      responses: {
        200: {
          description: "Resource updated successfully",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: schema
                }
              }
            }
          }
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("DELETE")) {
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].delete = {
      tags: [resourceName],
      summary: `Delete ${resourceName}`,
      description: `Delete a ${resourceName} by ID`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        204: {
          description: "Resource deleted successfully"
        },
        404: {
          description: "Resource not found",
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("HEAD")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].head = {
      tags: [resourceName],
      summary: `Get ${resourceName} statistics`,
      description: `Get statistics about ${resourceName} collection without retrieving data. Returns statistics in response headers.`,
      responses: {
        200: {
          description: "Statistics retrieved successfully",
          headers: {
            "X-Total-Count": {
              description: "Total number of records",
              schema: { type: "integer" }
            },
            "X-Resource-Version": {
              description: "Current resource version",
              schema: { type: "string" }
            },
            "X-Schema-Fields": {
              description: "Number of schema fields",
              schema: { type: "integer" }
            }
          }
        }
      },
      security: security.length > 0 ? security : void 0
    };
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].head = {
      tags: [resourceName],
      summary: `Check if ${resourceName} exists`,
      description: `Check if a ${resourceName} exists without retrieving its data`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        200: {
          description: "Resource exists",
          headers: {
            "Last-Modified": {
              description: "Last modification date",
              schema: { type: "string", format: "date-time" }
            }
          }
        },
        404: {
          description: "Resource not found"
        }
      },
      security: security.length > 0 ? security : void 0
    };
  }
  if (methods.includes("OPTIONS")) {
    if (!paths[basePath]) paths[basePath] = {};
    paths[basePath].options = {
      tags: [resourceName],
      summary: `Get ${resourceName} metadata`,
      description: `Get complete metadata about ${resourceName} resource including schema, allowed methods, endpoints, and query parameters`,
      responses: {
        200: {
          description: "Metadata retrieved successfully",
          headers: {
            "Allow": {
              description: "Allowed HTTP methods",
              schema: { type: "string", example: "GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS" }
            }
          },
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  resource: { type: "string" },
                  version: { type: "string" },
                  totalRecords: { type: "integer" },
                  allowedMethods: {
                    type: "array",
                    items: { type: "string" }
                  },
                  schema: {
                    type: "array",
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string" },
                        type: { type: "string" },
                        rules: { type: "array", items: { type: "string" } }
                      }
                    }
                  },
                  endpoints: {
                    type: "object",
                    properties: {
                      list: { type: "string" },
                      get: { type: "string" },
                      create: { type: "string" },
                      update: { type: "string" },
                      delete: { type: "string" }
                    }
                  },
                  queryParameters: { type: "object" }
                }
              }
            }
          }
        }
      }
    };
    if (!paths[`${basePath}/{id}`]) paths[`${basePath}/{id}`] = {};
    paths[`${basePath}/{id}`].options = {
      tags: [resourceName],
      summary: `Get allowed methods for ${resourceName} item`,
      description: `Get allowed HTTP methods for individual ${resourceName} operations`,
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          schema: { type: "string" }
        }
      ],
      responses: {
        204: {
          description: "Methods retrieved successfully",
          headers: {
            "Allow": {
              description: "Allowed HTTP methods",
              schema: { type: "string", example: "GET, PUT, PATCH, DELETE, HEAD, OPTIONS" }
            }
          }
        }
      }
    };
  }
  return paths;
}
function generateRelationalPaths(resource, relationName, relationConfig, version, relatedSchema, versionPrefix = "") {
  const resourceName = resource.name;
  const basePath = versionPrefix ? `/${versionPrefix}/${resourceName}/{id}/${relationName}` : `/${resourceName}/{id}/${relationName}`;
  relationConfig.resource;
  const isToMany = relationConfig.type === "hasMany" || relationConfig.type === "belongsToMany";
  const paths = {};
  paths[basePath] = {
    get: {
      tags: [resourceName],
      summary: `Get ${relationName} of ${resourceName}`,
      description: `Retrieve ${relationName} (${relationConfig.type}) associated with this ${resourceName}. This endpoint uses the RelationPlugin to efficiently load related data` + (relationConfig.partitionHint ? ` via the '${relationConfig.partitionHint}' partition.` : "."),
      parameters: [
        {
          name: "id",
          in: "path",
          required: true,
          description: `${resourceName} ID`,
          schema: { type: "string" }
        },
        ...isToMany ? [
          {
            name: "limit",
            in: "query",
            description: "Maximum number of items to return",
            schema: { type: "integer", default: 100, minimum: 1, maximum: 1e3 }
          },
          {
            name: "offset",
            in: "query",
            description: "Number of items to skip",
            schema: { type: "integer", default: 0, minimum: 0 }
          }
        ] : []
      ],
      responses: {
        200: {
          description: "Successful response",
          content: {
            "application/json": {
              schema: isToMany ? {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "array",
                    items: relatedSchema
                  },
                  pagination: {
                    type: "object",
                    properties: {
                      total: { type: "integer" },
                      page: { type: "integer" },
                      pageSize: { type: "integer" },
                      pageCount: { type: "integer" }
                    }
                  }
                }
              } : {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: relatedSchema
                }
              }
            }
          },
          ...isToMany ? {
            headers: {
              "X-Total-Count": {
                description: "Total number of related records",
                schema: { type: "integer" }
              },
              "X-Page-Count": {
                description: "Total number of pages",
                schema: { type: "integer" }
              }
            }
          } : {}
        },
        404: {
          description: `${resourceName} not found` + (isToMany ? "" : " or no related resource exists"),
          content: {
            "application/json": {
              schema: { $ref: "#/components/schemas/Error" }
            }
          }
        }
      }
    }
  };
  return paths;
}
function generateOpenAPISpec(database, config = {}) {
  const {
    title = "s3db.js API",
    version = "1.0.0",
    description = "Auto-generated REST API documentation for s3db.js resources",
    serverUrl = "http://localhost:3000",
    auth = {},
    resources: resourceConfigs = {}
  } = config;
  const resourcesTableRows = [];
  for (const [name, resource] of Object.entries(database.resources)) {
    if (name.startsWith("plg_") && !resourceConfigs[name]) {
      continue;
    }
    const version2 = resource.config?.currentVersion || resource.version || "v1";
    const resourceDescription = resource.config?.description;
    const descText = typeof resourceDescription === "object" ? resourceDescription.resource : resourceDescription || "No description";
    const config2 = resourceConfigs[name] || {};
    let versionPrefixConfig = config2.versionPrefix !== void 0 ? config2.versionPrefix : false;
    let prefix = "";
    if (versionPrefixConfig === true) {
      prefix = version2;
    } else if (versionPrefixConfig === false) {
      prefix = "";
    } else if (typeof versionPrefixConfig === "string") {
      prefix = versionPrefixConfig;
    }
    const basePath = prefix ? `/${prefix}/${name}` : `/${name}`;
    resourcesTableRows.push(`| ${name} | ${descText} | \`${basePath}\` |`);
  }
  const enhancedDescription = `${description}

## Available Resources

| Resource | Description | Base Path |
|----------|-------------|-----------|
${resourcesTableRows.join("\n")}

---

For detailed information about each endpoint, see the sections below.`;
  const spec = {
    openapi: "3.1.0",
    info: {
      title,
      version,
      description: enhancedDescription,
      contact: {
        name: "s3db.js",
        url: "https://github.com/forattini-dev/s3db.js"
      }
    },
    servers: [
      {
        url: serverUrl,
        description: "API Server"
      }
    ],
    paths: {},
    components: {
      schemas: {
        Error: {
          type: "object",
          properties: {
            success: { type: "boolean", example: false },
            error: {
              type: "object",
              properties: {
                message: { type: "string" },
                code: { type: "string" },
                details: { type: "object" }
              }
            }
          }
        },
        ValidationError: {
          type: "object",
          properties: {
            success: { type: "boolean", example: false },
            error: {
              type: "object",
              properties: {
                message: { type: "string", example: "Validation failed" },
                code: { type: "string", example: "VALIDATION_ERROR" },
                details: {
                  type: "object",
                  properties: {
                    errors: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          field: { type: "string" },
                          message: { type: "string" },
                          expected: { type: "string" },
                          actual: {}
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      },
      securitySchemes: {}
    },
    tags: []
  };
  if (auth.jwt?.enabled) {
    spec.components.securitySchemes.bearerAuth = {
      type: "http",
      scheme: "bearer",
      bearerFormat: "JWT",
      description: "JWT authentication"
    };
  }
  if (auth.apiKey?.enabled) {
    spec.components.securitySchemes.apiKeyAuth = {
      type: "apiKey",
      in: "header",
      name: auth.apiKey.headerName || "X-API-Key",
      description: "API Key authentication"
    };
  }
  if (auth.basic?.enabled) {
    spec.components.securitySchemes.basicAuth = {
      type: "http",
      scheme: "basic",
      description: "HTTP Basic authentication"
    };
  }
  const resources = database.resources;
  const relationsPlugin = database.plugins?.relation || database.plugins?.RelationPlugin || null;
  for (const [name, resource] of Object.entries(resources)) {
    if (name.startsWith("plg_") && !resourceConfigs[name]) {
      continue;
    }
    const config2 = resourceConfigs[name] || {
      methods: ["GET", "POST", "PUT", "PATCH", "DELETE"],
      auth: false
    };
    const version2 = resource.config?.currentVersion || resource.version || "v1";
    let versionPrefixConfig = config2.versionPrefix !== void 0 ? config2.versionPrefix : false;
    let prefix = "";
    if (versionPrefixConfig === true) {
      prefix = version2;
    } else if (versionPrefixConfig === false) {
      prefix = "";
    } else if (typeof versionPrefixConfig === "string") {
      prefix = versionPrefixConfig;
    }
    const paths = generateResourcePaths(resource, version2, config2);
    Object.assign(spec.paths, paths);
    const resourceDescription = resource.config?.description;
    const tagDescription = typeof resourceDescription === "object" ? resourceDescription.resource : resourceDescription || `Operations for ${name} resource`;
    spec.tags.push({
      name,
      description: tagDescription
    });
    spec.components.schemas[name] = generateResourceSchema(resource);
    if (relationsPlugin && relationsPlugin.relations && relationsPlugin.relations[name]) {
      const relationsDef = relationsPlugin.relations[name];
      for (const [relationName, relationConfig] of Object.entries(relationsDef)) {
        if (relationConfig.type === "belongsTo") {
          continue;
        }
        const exposeRelation = config2?.relations?.[relationName]?.expose !== false;
        if (!exposeRelation) {
          continue;
        }
        const relatedResource = database.resources[relationConfig.resource];
        if (!relatedResource) {
          continue;
        }
        const relatedSchema = generateResourceSchema(relatedResource);
        const relationalPaths = generateRelationalPaths(
          resource,
          relationName,
          relationConfig,
          version2,
          relatedSchema,
          prefix
        );
        Object.assign(spec.paths, relationalPaths);
      }
    }
  }
  if (auth.jwt?.enabled || auth.apiKey?.enabled || auth.basic?.enabled) {
    spec.paths["/auth/login"] = {
      post: {
        tags: ["Authentication"],
        summary: "Login",
        description: "Authenticate with username and password",
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  username: { type: "string" },
                  password: { type: "string", format: "password" }
                },
                required: ["username", "password"]
              }
            }
          }
        },
        responses: {
          200: {
            description: "Login successful",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "object",
                      properties: {
                        token: { type: "string" },
                        user: { type: "object" }
                      }
                    }
                  }
                }
              }
            }
          },
          401: {
            description: "Invalid credentials",
            content: {
              "application/json": {
                schema: { $ref: "#/components/schemas/Error" }
              }
            }
          }
        }
      }
    };
    spec.paths["/auth/register"] = {
      post: {
        tags: ["Authentication"],
        summary: "Register",
        description: "Register a new user",
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  username: { type: "string", minLength: 3 },
                  password: { type: "string", format: "password", minLength: 8 },
                  email: { type: "string", format: "email" }
                },
                required: ["username", "password"]
              }
            }
          }
        },
        responses: {
          201: {
            description: "User registered successfully",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    success: { type: "boolean", example: true },
                    data: {
                      type: "object",
                      properties: {
                        token: { type: "string" },
                        user: { type: "object" }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    };
    spec.tags.push({
      name: "Authentication",
      description: "Authentication endpoints"
    });
  }
  spec.paths["/health"] = {
    get: {
      tags: ["Health"],
      summary: "Generic Health Check",
      description: "Generic health check endpoint that includes references to liveness and readiness probes",
      responses: {
        200: {
          description: "API is healthy",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "ok" },
                      uptime: { type: "number", description: "Process uptime in seconds" },
                      timestamp: { type: "string", format: "date-time" },
                      checks: {
                        type: "object",
                        properties: {
                          liveness: { type: "string", example: "/health/live" },
                          readiness: { type: "string", example: "/health/ready" }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.paths["/health/live"] = {
    get: {
      tags: ["Health"],
      summary: "Liveness Probe",
      description: "Kubernetes liveness probe - checks if the application is alive. If this fails, Kubernetes will restart the pod.",
      responses: {
        200: {
          description: "Application is alive",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "alive" },
                      timestamp: { type: "string", format: "date-time" }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.paths["/health/ready"] = {
    get: {
      tags: ["Health"],
      summary: "Readiness Probe",
      description: "Kubernetes readiness probe - checks if the application is ready to receive traffic. If this fails, Kubernetes will remove the pod from service endpoints.",
      responses: {
        200: {
          description: "Application is ready to receive traffic",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: true },
                  data: {
                    type: "object",
                    properties: {
                      status: { type: "string", example: "ready" },
                      database: {
                        type: "object",
                        properties: {
                          connected: { type: "boolean", example: true },
                          resources: { type: "integer", example: 5 }
                        }
                      },
                      timestamp: { type: "string", format: "date-time" }
                    }
                  }
                }
              }
            }
          }
        },
        503: {
          description: "Application is not ready",
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  success: { type: "boolean", example: false },
                  error: {
                    type: "object",
                    properties: {
                      message: { type: "string", example: "Service not ready" },
                      code: { type: "string", example: "NOT_READY" },
                      details: {
                        type: "object",
                        properties: {
                          database: {
                            type: "object",
                            properties: {
                              connected: { type: "boolean", example: false },
                              resources: { type: "integer", example: 0 }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  };
  spec.tags.push({
    name: "Health",
    description: "Health check endpoints for monitoring and Kubernetes probes"
  });
  const metricsPlugin = database.plugins?.metrics || database.plugins?.MetricsPlugin;
  if (metricsPlugin && metricsPlugin.config?.prometheus?.enabled) {
    const metricsPath = metricsPlugin.config.prometheus.path || "/metrics";
    const isIntegrated = metricsPlugin.config.prometheus.mode !== "standalone";
    if (isIntegrated) {
      spec.paths[metricsPath] = {
        get: {
          tags: ["Monitoring"],
          summary: "Prometheus Metrics",
          description: "Exposes application metrics in Prometheus text-based exposition format for monitoring and observability. Metrics include operation counts, durations, errors, uptime, and resource statistics.",
          responses: {
            200: {
              description: "Metrics in Prometheus format",
              content: {
                "text/plain": {
                  schema: {
                    type: "string",
                    example: '# HELP s3db_operations_total Total number of operations by type and resource\n# TYPE s3db_operations_total counter\ns3db_operations_total{operation="insert",resource="cars"} 1523\ns3db_operations_total{operation="update",resource="cars"} 342\n\n# HELP s3db_operation_duration_seconds Average operation duration in seconds\n# TYPE s3db_operation_duration_seconds gauge\ns3db_operation_duration_seconds{operation="insert",resource="cars"} 0.045\n\n# HELP s3db_operation_errors_total Total number of operation errors\n# TYPE s3db_operation_errors_total counter\ns3db_operation_errors_total{operation="insert",resource="cars"} 12\n'
                  }
                }
              }
            }
          }
        }
      };
      spec.tags.push({
        name: "Monitoring",
        description: "Monitoring and observability endpoints (Prometheus)"
      });
    }
  }
  return spec;
}

function parseBasicAuth(authHeader) {
  if (!authHeader) {
    return null;
  }
  const match = authHeader.match(/^Basic\s+(.+)$/i);
  if (!match) {
    return null;
  }
  try {
    const decoded = Buffer.from(match[1], "base64").toString("utf-8");
    const [username, ...passwordParts] = decoded.split(":");
    const password = passwordParts.join(":");
    if (!username || !password) {
      return null;
    }
    return { username, password };
  } catch (err) {
    return null;
  }
}
function basicAuth(options = {}) {
  const {
    realm = "API Access",
    authResource,
    usernameField = "email",
    passwordField = "password",
    passphrase = "secret",
    optional = false
  } = options;
  if (!authResource) {
    throw new Error("authResource is required for Basic authentication");
  }
  return async (c, next) => {
    const authHeader = c.req.header("authorization");
    if (!authHeader) {
      if (optional) {
        return await next();
      }
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Basic authentication required");
      return c.json(response, response._status);
    }
    const credentials = parseBasicAuth(authHeader);
    if (!credentials) {
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Invalid Basic authentication format");
      return c.json(response, response._status);
    }
    const { username, password } = credentials;
    try {
      const queryFilter = { [usernameField]: username };
      const users = await authResource.query(queryFilter);
      if (!users || users.length === 0) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("Invalid credentials");
        return c.json(response, response._status);
      }
      const user = users[0];
      if (user.active !== void 0 && !user.active) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("User account is inactive");
        return c.json(response, response._status);
      }
      const storedPassword = user[passwordField];
      const isValid = storedPassword === password;
      if (!isValid) {
        c.header("WWW-Authenticate", `Basic realm="${realm}"`);
        const response = unauthorized("Invalid credentials");
        return c.json(response, response._status);
      }
      c.set("user", user);
      c.set("authMethod", "basic");
      await next();
    } catch (err) {
      console.error("[Basic Auth] Error validating credentials:", err);
      c.header("WWW-Authenticate", `Basic realm="${realm}"`);
      const response = unauthorized("Authentication error");
      return c.json(response, response._status);
    }
  };
}

const encoder = new TextEncoder();
const decoder = new TextDecoder();
function concat(...buffers) {
    const size = buffers.reduce((acc, { length }) => acc + length, 0);
    const buf = new Uint8Array(size);
    let i = 0;
    for (const buffer of buffers) {
        buf.set(buffer, i);
        i += buffer.length;
    }
    return buf;
}

function encodeBase64(input) {
    if (Uint8Array.prototype.toBase64) {
        return input.toBase64();
    }
    const CHUNK_SIZE = 0x8000;
    const arr = [];
    for (let i = 0; i < input.length; i += CHUNK_SIZE) {
        arr.push(String.fromCharCode.apply(null, input.subarray(i, i + CHUNK_SIZE)));
    }
    return btoa(arr.join(''));
}
function decodeBase64(encoded) {
    if (Uint8Array.fromBase64) {
        return Uint8Array.fromBase64(encoded);
    }
    const binary = atob(encoded);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) {
        bytes[i] = binary.charCodeAt(i);
    }
    return bytes;
}

function decode(input) {
    if (Uint8Array.fromBase64) {
        return Uint8Array.fromBase64(typeof input === 'string' ? input : decoder.decode(input), {
            alphabet: 'base64url',
        });
    }
    let encoded = input;
    if (encoded instanceof Uint8Array) {
        encoded = decoder.decode(encoded);
    }
    encoded = encoded.replace(/-/g, '+').replace(/_/g, '/').replace(/\s/g, '');
    try {
        return decodeBase64(encoded);
    }
    catch {
        throw new TypeError('The input to be decoded is not correctly encoded.');
    }
}
function encode(input) {
    let unencoded = input;
    if (typeof unencoded === 'string') {
        unencoded = encoder.encode(unencoded);
    }
    if (Uint8Array.prototype.toBase64) {
        return unencoded.toBase64({ alphabet: 'base64url', omitPadding: true });
    }
    return encodeBase64(unencoded).replace(/=/g, '').replace(/\+/g, '-').replace(/\//g, '_');
}

class JOSEError extends Error {
    static code = 'ERR_JOSE_GENERIC';
    code = 'ERR_JOSE_GENERIC';
    constructor(message, options) {
        super(message, options);
        this.name = this.constructor.name;
        Error.captureStackTrace?.(this, this.constructor);
    }
}
class JWTClaimValidationFailed extends JOSEError {
    static code = 'ERR_JWT_CLAIM_VALIDATION_FAILED';
    code = 'ERR_JWT_CLAIM_VALIDATION_FAILED';
    claim;
    reason;
    payload;
    constructor(message, payload, claim = 'unspecified', reason = 'unspecified') {
        super(message, { cause: { claim, reason, payload } });
        this.claim = claim;
        this.reason = reason;
        this.payload = payload;
    }
}
class JWTExpired extends JOSEError {
    static code = 'ERR_JWT_EXPIRED';
    code = 'ERR_JWT_EXPIRED';
    claim;
    reason;
    payload;
    constructor(message, payload, claim = 'unspecified', reason = 'unspecified') {
        super(message, { cause: { claim, reason, payload } });
        this.claim = claim;
        this.reason = reason;
        this.payload = payload;
    }
}
class JOSEAlgNotAllowed extends JOSEError {
    static code = 'ERR_JOSE_ALG_NOT_ALLOWED';
    code = 'ERR_JOSE_ALG_NOT_ALLOWED';
}
class JOSENotSupported extends JOSEError {
    static code = 'ERR_JOSE_NOT_SUPPORTED';
    code = 'ERR_JOSE_NOT_SUPPORTED';
}
class JWSInvalid extends JOSEError {
    static code = 'ERR_JWS_INVALID';
    code = 'ERR_JWS_INVALID';
}
class JWTInvalid extends JOSEError {
    static code = 'ERR_JWT_INVALID';
    code = 'ERR_JWT_INVALID';
}
class JWKSInvalid extends JOSEError {
    static code = 'ERR_JWKS_INVALID';
    code = 'ERR_JWKS_INVALID';
}
class JWKSNoMatchingKey extends JOSEError {
    static code = 'ERR_JWKS_NO_MATCHING_KEY';
    code = 'ERR_JWKS_NO_MATCHING_KEY';
    constructor(message = 'no applicable key found in the JSON Web Key Set', options) {
        super(message, options);
    }
}
class JWKSMultipleMatchingKeys extends JOSEError {
    [Symbol.asyncIterator];
    static code = 'ERR_JWKS_MULTIPLE_MATCHING_KEYS';
    code = 'ERR_JWKS_MULTIPLE_MATCHING_KEYS';
    constructor(message = 'multiple matching keys found in the JSON Web Key Set', options) {
        super(message, options);
    }
}
class JWKSTimeout extends JOSEError {
    static code = 'ERR_JWKS_TIMEOUT';
    code = 'ERR_JWKS_TIMEOUT';
    constructor(message = 'request timed out', options) {
        super(message, options);
    }
}
class JWSSignatureVerificationFailed extends JOSEError {
    static code = 'ERR_JWS_SIGNATURE_VERIFICATION_FAILED';
    code = 'ERR_JWS_SIGNATURE_VERIFICATION_FAILED';
    constructor(message = 'signature verification failed', options) {
        super(message, options);
    }
}

function unusable(name, prop = 'algorithm.name') {
    return new TypeError(`CryptoKey does not support this operation, its ${prop} must be ${name}`);
}
function isAlgorithm(algorithm, name) {
    return algorithm.name === name;
}
function getHashLength(hash) {
    return parseInt(hash.name.slice(4), 10);
}
function getNamedCurve(alg) {
    switch (alg) {
        case 'ES256':
            return 'P-256';
        case 'ES384':
            return 'P-384';
        case 'ES512':
            return 'P-521';
        default:
            throw new Error('unreachable');
    }
}
function checkUsage(key, usage) {
    if (usage && !key.usages.includes(usage)) {
        throw new TypeError(`CryptoKey does not support this operation, its usages must include ${usage}.`);
    }
}
function checkSigCryptoKey(key, alg, usage) {
    switch (alg) {
        case 'HS256':
        case 'HS384':
        case 'HS512': {
            if (!isAlgorithm(key.algorithm, 'HMAC'))
                throw unusable('HMAC');
            const expected = parseInt(alg.slice(2), 10);
            const actual = getHashLength(key.algorithm.hash);
            if (actual !== expected)
                throw unusable(`SHA-${expected}`, 'algorithm.hash');
            break;
        }
        case 'RS256':
        case 'RS384':
        case 'RS512': {
            if (!isAlgorithm(key.algorithm, 'RSASSA-PKCS1-v1_5'))
                throw unusable('RSASSA-PKCS1-v1_5');
            const expected = parseInt(alg.slice(2), 10);
            const actual = getHashLength(key.algorithm.hash);
            if (actual !== expected)
                throw unusable(`SHA-${expected}`, 'algorithm.hash');
            break;
        }
        case 'PS256':
        case 'PS384':
        case 'PS512': {
            if (!isAlgorithm(key.algorithm, 'RSA-PSS'))
                throw unusable('RSA-PSS');
            const expected = parseInt(alg.slice(2), 10);
            const actual = getHashLength(key.algorithm.hash);
            if (actual !== expected)
                throw unusable(`SHA-${expected}`, 'algorithm.hash');
            break;
        }
        case 'Ed25519':
        case 'EdDSA': {
            if (!isAlgorithm(key.algorithm, 'Ed25519'))
                throw unusable('Ed25519');
            break;
        }
        case 'ML-DSA-44':
        case 'ML-DSA-65':
        case 'ML-DSA-87': {
            if (!isAlgorithm(key.algorithm, alg))
                throw unusable(alg);
            break;
        }
        case 'ES256':
        case 'ES384':
        case 'ES512': {
            if (!isAlgorithm(key.algorithm, 'ECDSA'))
                throw unusable('ECDSA');
            const expected = getNamedCurve(alg);
            const actual = key.algorithm.namedCurve;
            if (actual !== expected)
                throw unusable(expected, 'algorithm.namedCurve');
            break;
        }
        default:
            throw new TypeError('CryptoKey does not support this operation');
    }
    checkUsage(key, usage);
}

function message(msg, actual, ...types) {
    types = types.filter(Boolean);
    if (types.length > 2) {
        const last = types.pop();
        msg += `one of type ${types.join(', ')}, or ${last}.`;
    }
    else if (types.length === 2) {
        msg += `one of type ${types[0]} or ${types[1]}.`;
    }
    else {
        msg += `of type ${types[0]}.`;
    }
    if (actual == null) {
        msg += ` Received ${actual}`;
    }
    else if (typeof actual === 'function' && actual.name) {
        msg += ` Received function ${actual.name}`;
    }
    else if (typeof actual === 'object' && actual != null) {
        if (actual.constructor?.name) {
            msg += ` Received an instance of ${actual.constructor.name}`;
        }
    }
    return msg;
}
var invalidKeyInput = (actual, ...types) => {
    return message('Key must be ', actual, ...types);
};
function withAlg(alg, actual, ...types) {
    return message(`Key for the ${alg} algorithm must be `, actual, ...types);
}

function isCryptoKey(key) {
    return key?.[Symbol.toStringTag] === 'CryptoKey';
}
function isKeyObject(key) {
    return key?.[Symbol.toStringTag] === 'KeyObject';
}
var isKeyLike = (key) => {
    return isCryptoKey(key) || isKeyObject(key);
};

var isDisjoint = (...headers) => {
    const sources = headers.filter(Boolean);
    if (sources.length === 0 || sources.length === 1) {
        return true;
    }
    let acc;
    for (const header of sources) {
        const parameters = Object.keys(header);
        if (!acc || acc.size === 0) {
            acc = new Set(parameters);
            continue;
        }
        for (const parameter of parameters) {
            if (acc.has(parameter)) {
                return false;
            }
            acc.add(parameter);
        }
    }
    return true;
};

function isObjectLike(value) {
    return typeof value === 'object' && value !== null;
}
var isObject = (input) => {
    if (!isObjectLike(input) || Object.prototype.toString.call(input) !== '[object Object]') {
        return false;
    }
    if (Object.getPrototypeOf(input) === null) {
        return true;
    }
    let proto = input;
    while (Object.getPrototypeOf(proto) !== null) {
        proto = Object.getPrototypeOf(proto);
    }
    return Object.getPrototypeOf(input) === proto;
};

var checkKeyLength = (alg, key) => {
    if (alg.startsWith('RS') || alg.startsWith('PS')) {
        const { modulusLength } = key.algorithm;
        if (typeof modulusLength !== 'number' || modulusLength < 2048) {
            throw new TypeError(`${alg} requires key modulusLength to be 2048 bits or larger`);
        }
    }
};

function subtleMapping(jwk) {
    let algorithm;
    let keyUsages;
    switch (jwk.kty) {
        case 'AKP': {
            switch (jwk.alg) {
                case 'ML-DSA-44':
                case 'ML-DSA-65':
                case 'ML-DSA-87':
                    algorithm = { name: jwk.alg };
                    keyUsages = jwk.priv ? ['sign'] : ['verify'];
                    break;
                default:
                    throw new JOSENotSupported('Invalid or unsupported JWK "alg" (Algorithm) Parameter value');
            }
            break;
        }
        case 'RSA': {
            switch (jwk.alg) {
                case 'PS256':
                case 'PS384':
                case 'PS512':
                    algorithm = { name: 'RSA-PSS', hash: `SHA-${jwk.alg.slice(-3)}` };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'RS256':
                case 'RS384':
                case 'RS512':
                    algorithm = { name: 'RSASSA-PKCS1-v1_5', hash: `SHA-${jwk.alg.slice(-3)}` };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'RSA-OAEP':
                case 'RSA-OAEP-256':
                case 'RSA-OAEP-384':
                case 'RSA-OAEP-512':
                    algorithm = {
                        name: 'RSA-OAEP',
                        hash: `SHA-${parseInt(jwk.alg.slice(-3), 10) || 1}`,
                    };
                    keyUsages = jwk.d ? ['decrypt', 'unwrapKey'] : ['encrypt', 'wrapKey'];
                    break;
                default:
                    throw new JOSENotSupported('Invalid or unsupported JWK "alg" (Algorithm) Parameter value');
            }
            break;
        }
        case 'EC': {
            switch (jwk.alg) {
                case 'ES256':
                    algorithm = { name: 'ECDSA', namedCurve: 'P-256' };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'ES384':
                    algorithm = { name: 'ECDSA', namedCurve: 'P-384' };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'ES512':
                    algorithm = { name: 'ECDSA', namedCurve: 'P-521' };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'ECDH-ES':
                case 'ECDH-ES+A128KW':
                case 'ECDH-ES+A192KW':
                case 'ECDH-ES+A256KW':
                    algorithm = { name: 'ECDH', namedCurve: jwk.crv };
                    keyUsages = jwk.d ? ['deriveBits'] : [];
                    break;
                default:
                    throw new JOSENotSupported('Invalid or unsupported JWK "alg" (Algorithm) Parameter value');
            }
            break;
        }
        case 'OKP': {
            switch (jwk.alg) {
                case 'Ed25519':
                case 'EdDSA':
                    algorithm = { name: 'Ed25519' };
                    keyUsages = jwk.d ? ['sign'] : ['verify'];
                    break;
                case 'ECDH-ES':
                case 'ECDH-ES+A128KW':
                case 'ECDH-ES+A192KW':
                case 'ECDH-ES+A256KW':
                    algorithm = { name: jwk.crv };
                    keyUsages = jwk.d ? ['deriveBits'] : [];
                    break;
                default:
                    throw new JOSENotSupported('Invalid or unsupported JWK "alg" (Algorithm) Parameter value');
            }
            break;
        }
        default:
            throw new JOSENotSupported('Invalid or unsupported JWK "kty" (Key Type) Parameter value');
    }
    return { algorithm, keyUsages };
}
var importJWK$1 = async (jwk) => {
    if (!jwk.alg) {
        throw new TypeError('"alg" argument is required when "jwk.alg" is not present');
    }
    const { algorithm, keyUsages } = subtleMapping(jwk);
    const keyData = { ...jwk };
    if (keyData.kty !== 'AKP') {
        delete keyData.alg;
    }
    delete keyData.use;
    return crypto.subtle.importKey('jwk', keyData, algorithm, jwk.ext ?? (jwk.d || jwk.priv ? false : true), jwk.key_ops ?? keyUsages);
};

async function importJWK(jwk, alg, options) {
    if (!isObject(jwk)) {
        throw new TypeError('JWK must be an object');
    }
    let ext;
    alg ??= jwk.alg;
    ext ??= jwk.ext;
    switch (jwk.kty) {
        case 'oct':
            if (typeof jwk.k !== 'string' || !jwk.k) {
                throw new TypeError('missing "k" (Key Value) Parameter value');
            }
            return decode(jwk.k);
        case 'RSA':
            if ('oth' in jwk && jwk.oth !== undefined) {
                throw new JOSENotSupported('RSA JWK "oth" (Other Primes Info) Parameter value is not supported');
            }
            return importJWK$1({ ...jwk, alg, ext });
        case 'AKP': {
            if (typeof jwk.alg !== 'string' || !jwk.alg) {
                throw new TypeError('missing "alg" (Algorithm) Parameter value');
            }
            if (alg !== undefined && alg !== jwk.alg) {
                throw new TypeError('JWK alg and alg option value mismatch');
            }
            return importJWK$1({ ...jwk, ext });
        }
        case 'EC':
        case 'OKP':
            return importJWK$1({ ...jwk, alg, ext });
        default:
            throw new JOSENotSupported('Unsupported "kty" (Key Type) Parameter value');
    }
}

var validateCrit = (Err, recognizedDefault, recognizedOption, protectedHeader, joseHeader) => {
    if (joseHeader.crit !== undefined && protectedHeader?.crit === undefined) {
        throw new Err('"crit" (Critical) Header Parameter MUST be integrity protected');
    }
    if (!protectedHeader || protectedHeader.crit === undefined) {
        return new Set();
    }
    if (!Array.isArray(protectedHeader.crit) ||
        protectedHeader.crit.length === 0 ||
        protectedHeader.crit.some((input) => typeof input !== 'string' || input.length === 0)) {
        throw new Err('"crit" (Critical) Header Parameter MUST be an array of non-empty strings when present');
    }
    let recognized;
    if (recognizedOption !== undefined) {
        recognized = new Map([...Object.entries(recognizedOption), ...recognizedDefault.entries()]);
    }
    else {
        recognized = recognizedDefault;
    }
    for (const parameter of protectedHeader.crit) {
        if (!recognized.has(parameter)) {
            throw new JOSENotSupported(`Extension Header Parameter "${parameter}" is not recognized`);
        }
        if (joseHeader[parameter] === undefined) {
            throw new Err(`Extension Header Parameter "${parameter}" is missing`);
        }
        if (recognized.get(parameter) && protectedHeader[parameter] === undefined) {
            throw new Err(`Extension Header Parameter "${parameter}" MUST be integrity protected`);
        }
    }
    return new Set(protectedHeader.crit);
};

var validateAlgorithms = (option, algorithms) => {
    if (algorithms !== undefined &&
        (!Array.isArray(algorithms) || algorithms.some((s) => typeof s !== 'string'))) {
        throw new TypeError(`"${option}" option must be an array of strings`);
    }
    if (!algorithms) {
        return undefined;
    }
    return new Set(algorithms);
};

function isJWK(key) {
    return isObject(key) && typeof key.kty === 'string';
}
function isPrivateJWK(key) {
    return (key.kty !== 'oct' &&
        ((key.kty === 'AKP' && typeof key.priv === 'string') || typeof key.d === 'string'));
}
function isPublicJWK(key) {
    return key.kty !== 'oct' && typeof key.d === 'undefined' && typeof key.priv === 'undefined';
}
function isSecretJWK(key) {
    return key.kty === 'oct' && typeof key.k === 'string';
}

let cache;
const handleJWK = async (key, jwk, alg, freeze = false) => {
    cache ||= new WeakMap();
    let cached = cache.get(key);
    if (cached?.[alg]) {
        return cached[alg];
    }
    const cryptoKey = await importJWK$1({ ...jwk, alg });
    if (freeze)
        Object.freeze(key);
    if (!cached) {
        cache.set(key, { [alg]: cryptoKey });
    }
    else {
        cached[alg] = cryptoKey;
    }
    return cryptoKey;
};
const handleKeyObject = (keyObject, alg) => {
    cache ||= new WeakMap();
    let cached = cache.get(keyObject);
    if (cached?.[alg]) {
        return cached[alg];
    }
    const isPublic = keyObject.type === 'public';
    const extractable = isPublic ? true : false;
    let cryptoKey;
    if (keyObject.asymmetricKeyType === 'x25519') {
        switch (alg) {
            case 'ECDH-ES':
            case 'ECDH-ES+A128KW':
            case 'ECDH-ES+A192KW':
            case 'ECDH-ES+A256KW':
                break;
            default:
                throw new TypeError('given KeyObject instance cannot be used for this algorithm');
        }
        cryptoKey = keyObject.toCryptoKey(keyObject.asymmetricKeyType, extractable, isPublic ? [] : ['deriveBits']);
    }
    if (keyObject.asymmetricKeyType === 'ed25519') {
        if (alg !== 'EdDSA' && alg !== 'Ed25519') {
            throw new TypeError('given KeyObject instance cannot be used for this algorithm');
        }
        cryptoKey = keyObject.toCryptoKey(keyObject.asymmetricKeyType, extractable, [
            isPublic ? 'verify' : 'sign',
        ]);
    }
    switch (keyObject.asymmetricKeyType) {
        case 'ml-dsa-44':
        case 'ml-dsa-65':
        case 'ml-dsa-87': {
            if (alg !== keyObject.asymmetricKeyType.toUpperCase()) {
                throw new TypeError('given KeyObject instance cannot be used for this algorithm');
            }
            cryptoKey = keyObject.toCryptoKey(keyObject.asymmetricKeyType, extractable, [
                isPublic ? 'verify' : 'sign',
            ]);
        }
    }
    if (keyObject.asymmetricKeyType === 'rsa') {
        let hash;
        switch (alg) {
            case 'RSA-OAEP':
                hash = 'SHA-1';
                break;
            case 'RS256':
            case 'PS256':
            case 'RSA-OAEP-256':
                hash = 'SHA-256';
                break;
            case 'RS384':
            case 'PS384':
            case 'RSA-OAEP-384':
                hash = 'SHA-384';
                break;
            case 'RS512':
            case 'PS512':
            case 'RSA-OAEP-512':
                hash = 'SHA-512';
                break;
            default:
                throw new TypeError('given KeyObject instance cannot be used for this algorithm');
        }
        if (alg.startsWith('RSA-OAEP')) {
            return keyObject.toCryptoKey({
                name: 'RSA-OAEP',
                hash,
            }, extractable, isPublic ? ['encrypt'] : ['decrypt']);
        }
        cryptoKey = keyObject.toCryptoKey({
            name: alg.startsWith('PS') ? 'RSA-PSS' : 'RSASSA-PKCS1-v1_5',
            hash,
        }, extractable, [isPublic ? 'verify' : 'sign']);
    }
    if (keyObject.asymmetricKeyType === 'ec') {
        const nist = new Map([
            ['prime256v1', 'P-256'],
            ['secp384r1', 'P-384'],
            ['secp521r1', 'P-521'],
        ]);
        const namedCurve = nist.get(keyObject.asymmetricKeyDetails?.namedCurve);
        if (!namedCurve) {
            throw new TypeError('given KeyObject instance cannot be used for this algorithm');
        }
        if (alg === 'ES256' && namedCurve === 'P-256') {
            cryptoKey = keyObject.toCryptoKey({
                name: 'ECDSA',
                namedCurve,
            }, extractable, [isPublic ? 'verify' : 'sign']);
        }
        if (alg === 'ES384' && namedCurve === 'P-384') {
            cryptoKey = keyObject.toCryptoKey({
                name: 'ECDSA',
                namedCurve,
            }, extractable, [isPublic ? 'verify' : 'sign']);
        }
        if (alg === 'ES512' && namedCurve === 'P-521') {
            cryptoKey = keyObject.toCryptoKey({
                name: 'ECDSA',
                namedCurve,
            }, extractable, [isPublic ? 'verify' : 'sign']);
        }
        if (alg.startsWith('ECDH-ES')) {
            cryptoKey = keyObject.toCryptoKey({
                name: 'ECDH',
                namedCurve,
            }, extractable, isPublic ? [] : ['deriveBits']);
        }
    }
    if (!cryptoKey) {
        throw new TypeError('given KeyObject instance cannot be used for this algorithm');
    }
    if (!cached) {
        cache.set(keyObject, { [alg]: cryptoKey });
    }
    else {
        cached[alg] = cryptoKey;
    }
    return cryptoKey;
};
var normalizeKey = async (key, alg) => {
    if (key instanceof Uint8Array) {
        return key;
    }
    if (isCryptoKey(key)) {
        return key;
    }
    if (isKeyObject(key)) {
        if (key.type === 'secret') {
            return key.export();
        }
        if ('toCryptoKey' in key && typeof key.toCryptoKey === 'function') {
            try {
                return handleKeyObject(key, alg);
            }
            catch (err) {
                if (err instanceof TypeError) {
                    throw err;
                }
            }
        }
        let jwk = key.export({ format: 'jwk' });
        return handleJWK(key, jwk, alg);
    }
    if (isJWK(key)) {
        if (key.k) {
            return decode(key.k);
        }
        return handleJWK(key, key, alg, true);
    }
    throw new Error('unreachable');
};

const tag = (key) => key?.[Symbol.toStringTag];
const jwkMatchesOp = (alg, key, usage) => {
    if (key.use !== undefined) {
        let expected;
        switch (usage) {
            case 'sign':
            case 'verify':
                expected = 'sig';
                break;
            case 'encrypt':
            case 'decrypt':
                expected = 'enc';
                break;
        }
        if (key.use !== expected) {
            throw new TypeError(`Invalid key for this operation, its "use" must be "${expected}" when present`);
        }
    }
    if (key.alg !== undefined && key.alg !== alg) {
        throw new TypeError(`Invalid key for this operation, its "alg" must be "${alg}" when present`);
    }
    if (Array.isArray(key.key_ops)) {
        let expectedKeyOp;
        switch (true) {
            case usage === 'sign' || usage === 'verify':
            case alg === 'dir':
            case alg.includes('CBC-HS'):
                expectedKeyOp = usage;
                break;
            case alg.startsWith('PBES2'):
                expectedKeyOp = 'deriveBits';
                break;
            case /^A\d{3}(?:GCM)?(?:KW)?$/.test(alg):
                if (!alg.includes('GCM') && alg.endsWith('KW')) {
                    expectedKeyOp = usage === 'encrypt' ? 'wrapKey' : 'unwrapKey';
                }
                else {
                    expectedKeyOp = usage;
                }
                break;
            case usage === 'encrypt' && alg.startsWith('RSA'):
                expectedKeyOp = 'wrapKey';
                break;
            case usage === 'decrypt':
                expectedKeyOp = alg.startsWith('RSA') ? 'unwrapKey' : 'deriveBits';
                break;
        }
        if (expectedKeyOp && key.key_ops?.includes?.(expectedKeyOp) === false) {
            throw new TypeError(`Invalid key for this operation, its "key_ops" must include "${expectedKeyOp}" when present`);
        }
    }
    return true;
};
const symmetricTypeCheck = (alg, key, usage) => {
    if (key instanceof Uint8Array)
        return;
    if (isJWK(key)) {
        if (isSecretJWK(key) && jwkMatchesOp(alg, key, usage))
            return;
        throw new TypeError(`JSON Web Key for symmetric algorithms must have JWK "kty" (Key Type) equal to "oct" and the JWK "k" (Key Value) present`);
    }
    if (!isKeyLike(key)) {
        throw new TypeError(withAlg(alg, key, 'CryptoKey', 'KeyObject', 'JSON Web Key', 'Uint8Array'));
    }
    if (key.type !== 'secret') {
        throw new TypeError(`${tag(key)} instances for symmetric algorithms must be of type "secret"`);
    }
};
const asymmetricTypeCheck = (alg, key, usage) => {
    if (isJWK(key)) {
        switch (usage) {
            case 'decrypt':
            case 'sign':
                if (isPrivateJWK(key) && jwkMatchesOp(alg, key, usage))
                    return;
                throw new TypeError(`JSON Web Key for this operation be a private JWK`);
            case 'encrypt':
            case 'verify':
                if (isPublicJWK(key) && jwkMatchesOp(alg, key, usage))
                    return;
                throw new TypeError(`JSON Web Key for this operation be a public JWK`);
        }
    }
    if (!isKeyLike(key)) {
        throw new TypeError(withAlg(alg, key, 'CryptoKey', 'KeyObject', 'JSON Web Key'));
    }
    if (key.type === 'secret') {
        throw new TypeError(`${tag(key)} instances for asymmetric algorithms must not be of type "secret"`);
    }
    if (key.type === 'public') {
        switch (usage) {
            case 'sign':
                throw new TypeError(`${tag(key)} instances for asymmetric algorithm signing must be of type "private"`);
            case 'decrypt':
                throw new TypeError(`${tag(key)} instances for asymmetric algorithm decryption must be of type "private"`);
        }
    }
    if (key.type === 'private') {
        switch (usage) {
            case 'verify':
                throw new TypeError(`${tag(key)} instances for asymmetric algorithm verifying must be of type "public"`);
            case 'encrypt':
                throw new TypeError(`${tag(key)} instances for asymmetric algorithm encryption must be of type "public"`);
        }
    }
};
var checkKeyType = (alg, key, usage) => {
    const symmetric = alg.startsWith('HS') ||
        alg === 'dir' ||
        alg.startsWith('PBES2') ||
        /^A(?:128|192|256)(?:GCM)?(?:KW)?$/.test(alg) ||
        /^A(?:128|192|256)CBC-HS(?:256|384|512)$/.test(alg);
    if (symmetric) {
        symmetricTypeCheck(alg, key, usage);
    }
    else {
        asymmetricTypeCheck(alg, key, usage);
    }
};

var subtleAlgorithm = (alg, algorithm) => {
    const hash = `SHA-${alg.slice(-3)}`;
    switch (alg) {
        case 'HS256':
        case 'HS384':
        case 'HS512':
            return { hash, name: 'HMAC' };
        case 'PS256':
        case 'PS384':
        case 'PS512':
            return { hash, name: 'RSA-PSS', saltLength: parseInt(alg.slice(-3), 10) >> 3 };
        case 'RS256':
        case 'RS384':
        case 'RS512':
            return { hash, name: 'RSASSA-PKCS1-v1_5' };
        case 'ES256':
        case 'ES384':
        case 'ES512':
            return { hash, name: 'ECDSA', namedCurve: algorithm.namedCurve };
        case 'Ed25519':
        case 'EdDSA':
            return { name: 'Ed25519' };
        case 'ML-DSA-44':
        case 'ML-DSA-65':
        case 'ML-DSA-87':
            return { name: alg };
        default:
            throw new JOSENotSupported(`alg ${alg} is not supported either by JOSE or your javascript runtime`);
    }
};

var getSignKey = async (alg, key, usage) => {
    if (key instanceof Uint8Array) {
        if (!alg.startsWith('HS')) {
            throw new TypeError(invalidKeyInput(key, 'CryptoKey', 'KeyObject', 'JSON Web Key'));
        }
        return crypto.subtle.importKey('raw', key, { hash: `SHA-${alg.slice(-3)}`, name: 'HMAC' }, false, [usage]);
    }
    checkSigCryptoKey(key, alg, usage);
    return key;
};

var verify = async (alg, key, signature, data) => {
    const cryptoKey = await getSignKey(alg, key, 'verify');
    checkKeyLength(alg, cryptoKey);
    const algorithm = subtleAlgorithm(alg, cryptoKey.algorithm);
    try {
        return await crypto.subtle.verify(algorithm, cryptoKey, signature, data);
    }
    catch {
        return false;
    }
};

async function flattenedVerify(jws, key, options) {
    if (!isObject(jws)) {
        throw new JWSInvalid('Flattened JWS must be an object');
    }
    if (jws.protected === undefined && jws.header === undefined) {
        throw new JWSInvalid('Flattened JWS must have either of the "protected" or "header" members');
    }
    if (jws.protected !== undefined && typeof jws.protected !== 'string') {
        throw new JWSInvalid('JWS Protected Header incorrect type');
    }
    if (jws.payload === undefined) {
        throw new JWSInvalid('JWS Payload missing');
    }
    if (typeof jws.signature !== 'string') {
        throw new JWSInvalid('JWS Signature missing or incorrect type');
    }
    if (jws.header !== undefined && !isObject(jws.header)) {
        throw new JWSInvalid('JWS Unprotected Header incorrect type');
    }
    let parsedProt = {};
    if (jws.protected) {
        try {
            const protectedHeader = decode(jws.protected);
            parsedProt = JSON.parse(decoder.decode(protectedHeader));
        }
        catch {
            throw new JWSInvalid('JWS Protected Header is invalid');
        }
    }
    if (!isDisjoint(parsedProt, jws.header)) {
        throw new JWSInvalid('JWS Protected and JWS Unprotected Header Parameter names must be disjoint');
    }
    const joseHeader = {
        ...parsedProt,
        ...jws.header,
    };
    const extensions = validateCrit(JWSInvalid, new Map([['b64', true]]), options?.crit, parsedProt, joseHeader);
    let b64 = true;
    if (extensions.has('b64')) {
        b64 = parsedProt.b64;
        if (typeof b64 !== 'boolean') {
            throw new JWSInvalid('The "b64" (base64url-encode payload) Header Parameter must be a boolean');
        }
    }
    const { alg } = joseHeader;
    if (typeof alg !== 'string' || !alg) {
        throw new JWSInvalid('JWS "alg" (Algorithm) Header Parameter missing or invalid');
    }
    const algorithms = options && validateAlgorithms('algorithms', options.algorithms);
    if (algorithms && !algorithms.has(alg)) {
        throw new JOSEAlgNotAllowed('"alg" (Algorithm) Header Parameter value not allowed');
    }
    if (b64) {
        if (typeof jws.payload !== 'string') {
            throw new JWSInvalid('JWS Payload must be a string');
        }
    }
    else if (typeof jws.payload !== 'string' && !(jws.payload instanceof Uint8Array)) {
        throw new JWSInvalid('JWS Payload must be a string or an Uint8Array instance');
    }
    let resolvedKey = false;
    if (typeof key === 'function') {
        key = await key(parsedProt, jws);
        resolvedKey = true;
    }
    checkKeyType(alg, key, 'verify');
    const data = concat(encoder.encode(jws.protected ?? ''), encoder.encode('.'), typeof jws.payload === 'string' ? encoder.encode(jws.payload) : jws.payload);
    let signature;
    try {
        signature = decode(jws.signature);
    }
    catch {
        throw new JWSInvalid('Failed to base64url decode the signature');
    }
    const k = await normalizeKey(key, alg);
    const verified = await verify(alg, k, signature, data);
    if (!verified) {
        throw new JWSSignatureVerificationFailed();
    }
    let payload;
    if (b64) {
        try {
            payload = decode(jws.payload);
        }
        catch {
            throw new JWSInvalid('Failed to base64url decode the payload');
        }
    }
    else if (typeof jws.payload === 'string') {
        payload = encoder.encode(jws.payload);
    }
    else {
        payload = jws.payload;
    }
    const result = { payload };
    if (jws.protected !== undefined) {
        result.protectedHeader = parsedProt;
    }
    if (jws.header !== undefined) {
        result.unprotectedHeader = jws.header;
    }
    if (resolvedKey) {
        return { ...result, key: k };
    }
    return result;
}

async function compactVerify(jws, key, options) {
    if (jws instanceof Uint8Array) {
        jws = decoder.decode(jws);
    }
    if (typeof jws !== 'string') {
        throw new JWSInvalid('Compact JWS must be a string or Uint8Array');
    }
    const { 0: protectedHeader, 1: payload, 2: signature, length } = jws.split('.');
    if (length !== 3) {
        throw new JWSInvalid('Invalid Compact JWS');
    }
    const verified = await flattenedVerify({ payload, protected: protectedHeader, signature }, key, options);
    const result = { payload: verified.payload, protectedHeader: verified.protectedHeader };
    if (typeof key === 'function') {
        return { ...result, key: verified.key };
    }
    return result;
}

var epoch = (date) => Math.floor(date.getTime() / 1000);

const minute = 60;
const hour = minute * 60;
const day = hour * 24;
const week = day * 7;
const year = day * 365.25;
const REGEX = /^(\+|\-)? ?(\d+|\d+\.\d+) ?(seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)(?: (ago|from now))?$/i;
var secs = (str) => {
    const matched = REGEX.exec(str);
    if (!matched || (matched[4] && matched[1])) {
        throw new TypeError('Invalid time period format');
    }
    const value = parseFloat(matched[2]);
    const unit = matched[3].toLowerCase();
    let numericDate;
    switch (unit) {
        case 'sec':
        case 'secs':
        case 'second':
        case 'seconds':
        case 's':
            numericDate = Math.round(value);
            break;
        case 'minute':
        case 'minutes':
        case 'min':
        case 'mins':
        case 'm':
            numericDate = Math.round(value * minute);
            break;
        case 'hour':
        case 'hours':
        case 'hr':
        case 'hrs':
        case 'h':
            numericDate = Math.round(value * hour);
            break;
        case 'day':
        case 'days':
        case 'd':
            numericDate = Math.round(value * day);
            break;
        case 'week':
        case 'weeks':
        case 'w':
            numericDate = Math.round(value * week);
            break;
        default:
            numericDate = Math.round(value * year);
            break;
    }
    if (matched[1] === '-' || matched[4] === 'ago') {
        return -numericDate;
    }
    return numericDate;
};

function validateInput(label, input) {
    if (!Number.isFinite(input)) {
        throw new TypeError(`Invalid ${label} input`);
    }
    return input;
}
const normalizeTyp = (value) => {
    if (value.includes('/')) {
        return value.toLowerCase();
    }
    return `application/${value.toLowerCase()}`;
};
const checkAudiencePresence = (audPayload, audOption) => {
    if (typeof audPayload === 'string') {
        return audOption.includes(audPayload);
    }
    if (Array.isArray(audPayload)) {
        return audOption.some(Set.prototype.has.bind(new Set(audPayload)));
    }
    return false;
};
function validateClaimsSet(protectedHeader, encodedPayload, options = {}) {
    let payload;
    try {
        payload = JSON.parse(decoder.decode(encodedPayload));
    }
    catch {
    }
    if (!isObject(payload)) {
        throw new JWTInvalid('JWT Claims Set must be a top-level JSON object');
    }
    const { typ } = options;
    if (typ &&
        (typeof protectedHeader.typ !== 'string' ||
            normalizeTyp(protectedHeader.typ) !== normalizeTyp(typ))) {
        throw new JWTClaimValidationFailed('unexpected "typ" JWT header value', payload, 'typ', 'check_failed');
    }
    const { requiredClaims = [], issuer, subject, audience, maxTokenAge } = options;
    const presenceCheck = [...requiredClaims];
    if (maxTokenAge !== undefined)
        presenceCheck.push('iat');
    if (audience !== undefined)
        presenceCheck.push('aud');
    if (subject !== undefined)
        presenceCheck.push('sub');
    if (issuer !== undefined)
        presenceCheck.push('iss');
    for (const claim of new Set(presenceCheck.reverse())) {
        if (!(claim in payload)) {
            throw new JWTClaimValidationFailed(`missing required "${claim}" claim`, payload, claim, 'missing');
        }
    }
    if (issuer &&
        !(Array.isArray(issuer) ? issuer : [issuer]).includes(payload.iss)) {
        throw new JWTClaimValidationFailed('unexpected "iss" claim value', payload, 'iss', 'check_failed');
    }
    if (subject && payload.sub !== subject) {
        throw new JWTClaimValidationFailed('unexpected "sub" claim value', payload, 'sub', 'check_failed');
    }
    if (audience &&
        !checkAudiencePresence(payload.aud, typeof audience === 'string' ? [audience] : audience)) {
        throw new JWTClaimValidationFailed('unexpected "aud" claim value', payload, 'aud', 'check_failed');
    }
    let tolerance;
    switch (typeof options.clockTolerance) {
        case 'string':
            tolerance = secs(options.clockTolerance);
            break;
        case 'number':
            tolerance = options.clockTolerance;
            break;
        case 'undefined':
            tolerance = 0;
            break;
        default:
            throw new TypeError('Invalid clockTolerance option type');
    }
    const { currentDate } = options;
    const now = epoch(currentDate || new Date());
    if ((payload.iat !== undefined || maxTokenAge) && typeof payload.iat !== 'number') {
        throw new JWTClaimValidationFailed('"iat" claim must be a number', payload, 'iat', 'invalid');
    }
    if (payload.nbf !== undefined) {
        if (typeof payload.nbf !== 'number') {
            throw new JWTClaimValidationFailed('"nbf" claim must be a number', payload, 'nbf', 'invalid');
        }
        if (payload.nbf > now + tolerance) {
            throw new JWTClaimValidationFailed('"nbf" claim timestamp check failed', payload, 'nbf', 'check_failed');
        }
    }
    if (payload.exp !== undefined) {
        if (typeof payload.exp !== 'number') {
            throw new JWTClaimValidationFailed('"exp" claim must be a number', payload, 'exp', 'invalid');
        }
        if (payload.exp <= now - tolerance) {
            throw new JWTExpired('"exp" claim timestamp check failed', payload, 'exp', 'check_failed');
        }
    }
    if (maxTokenAge) {
        const age = now - payload.iat;
        const max = typeof maxTokenAge === 'number' ? maxTokenAge : secs(maxTokenAge);
        if (age - tolerance > max) {
            throw new JWTExpired('"iat" claim timestamp check failed (too far in the past)', payload, 'iat', 'check_failed');
        }
        if (age < 0 - tolerance) {
            throw new JWTClaimValidationFailed('"iat" claim timestamp check failed (it should be in the past)', payload, 'iat', 'check_failed');
        }
    }
    return payload;
}
class JWTClaimsBuilder {
    #payload;
    constructor(payload) {
        if (!isObject(payload)) {
            throw new TypeError('JWT Claims Set MUST be an object');
        }
        this.#payload = structuredClone(payload);
    }
    data() {
        return encoder.encode(JSON.stringify(this.#payload));
    }
    get iss() {
        return this.#payload.iss;
    }
    set iss(value) {
        this.#payload.iss = value;
    }
    get sub() {
        return this.#payload.sub;
    }
    set sub(value) {
        this.#payload.sub = value;
    }
    get aud() {
        return this.#payload.aud;
    }
    set aud(value) {
        this.#payload.aud = value;
    }
    set jti(value) {
        this.#payload.jti = value;
    }
    set nbf(value) {
        if (typeof value === 'number') {
            this.#payload.nbf = validateInput('setNotBefore', value);
        }
        else if (value instanceof Date) {
            this.#payload.nbf = validateInput('setNotBefore', epoch(value));
        }
        else {
            this.#payload.nbf = epoch(new Date()) + secs(value);
        }
    }
    set exp(value) {
        if (typeof value === 'number') {
            this.#payload.exp = validateInput('setExpirationTime', value);
        }
        else if (value instanceof Date) {
            this.#payload.exp = validateInput('setExpirationTime', epoch(value));
        }
        else {
            this.#payload.exp = epoch(new Date()) + secs(value);
        }
    }
    set iat(value) {
        if (typeof value === 'undefined') {
            this.#payload.iat = epoch(new Date());
        }
        else if (value instanceof Date) {
            this.#payload.iat = validateInput('setIssuedAt', epoch(value));
        }
        else if (typeof value === 'string') {
            this.#payload.iat = validateInput('setIssuedAt', epoch(new Date()) + secs(value));
        }
        else {
            this.#payload.iat = validateInput('setIssuedAt', value);
        }
    }
}

async function jwtVerify(jwt, key, options) {
    const verified = await compactVerify(jwt, key, options);
    if (verified.protectedHeader.crit?.includes('b64') && verified.protectedHeader.b64 === false) {
        throw new JWTInvalid('JWTs MUST NOT use unencoded payload');
    }
    const payload = validateClaimsSet(verified.protectedHeader, verified.payload, options);
    const result = { payload, protectedHeader: verified.protectedHeader };
    if (typeof key === 'function') {
        return { ...result, key: verified.key };
    }
    return result;
}

var sign$1 = async (alg, key, data) => {
    const cryptoKey = await getSignKey(alg, key, 'sign');
    checkKeyLength(alg, cryptoKey);
    const signature = await crypto.subtle.sign(subtleAlgorithm(alg, cryptoKey.algorithm), cryptoKey, data);
    return new Uint8Array(signature);
};

class FlattenedSign {
    #payload;
    #protectedHeader;
    #unprotectedHeader;
    constructor(payload) {
        if (!(payload instanceof Uint8Array)) {
            throw new TypeError('payload must be an instance of Uint8Array');
        }
        this.#payload = payload;
    }
    setProtectedHeader(protectedHeader) {
        if (this.#protectedHeader) {
            throw new TypeError('setProtectedHeader can only be called once');
        }
        this.#protectedHeader = protectedHeader;
        return this;
    }
    setUnprotectedHeader(unprotectedHeader) {
        if (this.#unprotectedHeader) {
            throw new TypeError('setUnprotectedHeader can only be called once');
        }
        this.#unprotectedHeader = unprotectedHeader;
        return this;
    }
    async sign(key, options) {
        if (!this.#protectedHeader && !this.#unprotectedHeader) {
            throw new JWSInvalid('either setProtectedHeader or setUnprotectedHeader must be called before #sign()');
        }
        if (!isDisjoint(this.#protectedHeader, this.#unprotectedHeader)) {
            throw new JWSInvalid('JWS Protected and JWS Unprotected Header Parameter names must be disjoint');
        }
        const joseHeader = {
            ...this.#protectedHeader,
            ...this.#unprotectedHeader,
        };
        const extensions = validateCrit(JWSInvalid, new Map([['b64', true]]), options?.crit, this.#protectedHeader, joseHeader);
        let b64 = true;
        if (extensions.has('b64')) {
            b64 = this.#protectedHeader.b64;
            if (typeof b64 !== 'boolean') {
                throw new JWSInvalid('The "b64" (base64url-encode payload) Header Parameter must be a boolean');
            }
        }
        const { alg } = joseHeader;
        if (typeof alg !== 'string' || !alg) {
            throw new JWSInvalid('JWS "alg" (Algorithm) Header Parameter missing or invalid');
        }
        checkKeyType(alg, key, 'sign');
        let payload = this.#payload;
        if (b64) {
            payload = encoder.encode(encode(payload));
        }
        let protectedHeader;
        if (this.#protectedHeader) {
            protectedHeader = encoder.encode(encode(JSON.stringify(this.#protectedHeader)));
        }
        else {
            protectedHeader = encoder.encode('');
        }
        const data = concat(protectedHeader, encoder.encode('.'), payload);
        const k = await normalizeKey(key, alg);
        const signature = await sign$1(alg, k, data);
        const jws = {
            signature: encode(signature),
            payload: '',
        };
        if (b64) {
            jws.payload = decoder.decode(payload);
        }
        if (this.#unprotectedHeader) {
            jws.header = this.#unprotectedHeader;
        }
        if (this.#protectedHeader) {
            jws.protected = decoder.decode(protectedHeader);
        }
        return jws;
    }
}

class CompactSign {
    #flattened;
    constructor(payload) {
        this.#flattened = new FlattenedSign(payload);
    }
    setProtectedHeader(protectedHeader) {
        this.#flattened.setProtectedHeader(protectedHeader);
        return this;
    }
    async sign(key, options) {
        const jws = await this.#flattened.sign(key, options);
        if (jws.payload === undefined) {
            throw new TypeError('use the flattened module for creating JWS with b64: false');
        }
        return `${jws.protected}.${jws.payload}.${jws.signature}`;
    }
}

class SignJWT {
    #protectedHeader;
    #jwt;
    constructor(payload = {}) {
        this.#jwt = new JWTClaimsBuilder(payload);
    }
    setIssuer(issuer) {
        this.#jwt.iss = issuer;
        return this;
    }
    setSubject(subject) {
        this.#jwt.sub = subject;
        return this;
    }
    setAudience(audience) {
        this.#jwt.aud = audience;
        return this;
    }
    setJti(jwtId) {
        this.#jwt.jti = jwtId;
        return this;
    }
    setNotBefore(input) {
        this.#jwt.nbf = input;
        return this;
    }
    setExpirationTime(input) {
        this.#jwt.exp = input;
        return this;
    }
    setIssuedAt(input) {
        this.#jwt.iat = input;
        return this;
    }
    setProtectedHeader(protectedHeader) {
        this.#protectedHeader = protectedHeader;
        return this;
    }
    async sign(key, options) {
        const sig = new CompactSign(this.#jwt.data());
        sig.setProtectedHeader(this.#protectedHeader);
        if (Array.isArray(this.#protectedHeader?.crit) &&
            this.#protectedHeader.crit.includes('b64') &&
            this.#protectedHeader.b64 === false) {
            throw new JWTInvalid('JWTs MUST NOT use unencoded payload');
        }
        return sig.sign(key, options);
    }
}

function getKtyFromAlg(alg) {
    switch (typeof alg === 'string' && alg.slice(0, 2)) {
        case 'RS':
        case 'PS':
            return 'RSA';
        case 'ES':
            return 'EC';
        case 'Ed':
            return 'OKP';
        case 'ML':
            return 'AKP';
        default:
            throw new JOSENotSupported('Unsupported "alg" value for a JSON Web Key Set');
    }
}
function isJWKSLike(jwks) {
    return (jwks &&
        typeof jwks === 'object' &&
        Array.isArray(jwks.keys) &&
        jwks.keys.every(isJWKLike));
}
function isJWKLike(key) {
    return isObject(key);
}
class LocalJWKSet {
    #jwks;
    #cached = new WeakMap();
    constructor(jwks) {
        if (!isJWKSLike(jwks)) {
            throw new JWKSInvalid('JSON Web Key Set malformed');
        }
        this.#jwks = structuredClone(jwks);
    }
    jwks() {
        return this.#jwks;
    }
    async getKey(protectedHeader, token) {
        const { alg, kid } = { ...protectedHeader, ...token?.header };
        const kty = getKtyFromAlg(alg);
        const candidates = this.#jwks.keys.filter((jwk) => {
            let candidate = kty === jwk.kty;
            if (candidate && typeof kid === 'string') {
                candidate = kid === jwk.kid;
            }
            if (candidate && (typeof jwk.alg === 'string' || kty === 'AKP')) {
                candidate = alg === jwk.alg;
            }
            if (candidate && typeof jwk.use === 'string') {
                candidate = jwk.use === 'sig';
            }
            if (candidate && Array.isArray(jwk.key_ops)) {
                candidate = jwk.key_ops.includes('verify');
            }
            if (candidate) {
                switch (alg) {
                    case 'ES256':
                        candidate = jwk.crv === 'P-256';
                        break;
                    case 'ES384':
                        candidate = jwk.crv === 'P-384';
                        break;
                    case 'ES512':
                        candidate = jwk.crv === 'P-521';
                        break;
                    case 'Ed25519':
                    case 'EdDSA':
                        candidate = jwk.crv === 'Ed25519';
                        break;
                }
            }
            return candidate;
        });
        const { 0: jwk, length } = candidates;
        if (length === 0) {
            throw new JWKSNoMatchingKey();
        }
        if (length !== 1) {
            const error = new JWKSMultipleMatchingKeys();
            const _cached = this.#cached;
            error[Symbol.asyncIterator] = async function* () {
                for (const jwk of candidates) {
                    try {
                        yield await importWithAlgCache(_cached, jwk, alg);
                    }
                    catch { }
                }
            };
            throw error;
        }
        return importWithAlgCache(this.#cached, jwk, alg);
    }
}
async function importWithAlgCache(cache, jwk, alg) {
    const cached = cache.get(jwk) || cache.set(jwk, {}).get(jwk);
    if (cached[alg] === undefined) {
        const key = await importJWK({ ...jwk, ext: true }, alg);
        if (key instanceof Uint8Array || key.type !== 'public') {
            throw new JWKSInvalid('JSON Web Key Set members must be public keys');
        }
        cached[alg] = key;
    }
    return cached[alg];
}
function createLocalJWKSet(jwks) {
    const set = new LocalJWKSet(jwks);
    const localJWKSet = async (protectedHeader, token) => set.getKey(protectedHeader, token);
    Object.defineProperties(localJWKSet, {
        jwks: {
            value: () => structuredClone(set.jwks()),
            enumerable: false,
            configurable: false,
            writable: false,
        },
    });
    return localJWKSet;
}

function isCloudflareWorkers() {
    return (typeof WebSocketPair !== 'undefined' ||
        (typeof navigator !== 'undefined' && navigator.userAgent === 'Cloudflare-Workers') ||
        (typeof EdgeRuntime !== 'undefined' && EdgeRuntime === 'vercel'));
}
let USER_AGENT;
if (typeof navigator === 'undefined' || !navigator.userAgent?.startsWith?.('Mozilla/5.0 ')) {
    const NAME = 'jose';
    const VERSION = 'v6.1.0';
    USER_AGENT = `${NAME}/${VERSION}`;
}
const customFetch = Symbol();
async function fetchJwks(url, headers, signal, fetchImpl = fetch) {
    const response = await fetchImpl(url, {
        method: 'GET',
        signal,
        redirect: 'manual',
        headers,
    }).catch((err) => {
        if (err.name === 'TimeoutError') {
            throw new JWKSTimeout();
        }
        throw err;
    });
    if (response.status !== 200) {
        throw new JOSEError('Expected 200 OK from the JSON Web Key Set HTTP response');
    }
    try {
        return await response.json();
    }
    catch {
        throw new JOSEError('Failed to parse the JSON Web Key Set HTTP response as JSON');
    }
}
const jwksCache$1 = Symbol();
function isFreshJwksCache(input, cacheMaxAge) {
    if (typeof input !== 'object' || input === null) {
        return false;
    }
    if (!('uat' in input) || typeof input.uat !== 'number' || Date.now() - input.uat >= cacheMaxAge) {
        return false;
    }
    if (!('jwks' in input) ||
        !isObject(input.jwks) ||
        !Array.isArray(input.jwks.keys) ||
        !Array.prototype.every.call(input.jwks.keys, isObject)) {
        return false;
    }
    return true;
}
class RemoteJWKSet {
    #url;
    #timeoutDuration;
    #cooldownDuration;
    #cacheMaxAge;
    #jwksTimestamp;
    #pendingFetch;
    #headers;
    #customFetch;
    #local;
    #cache;
    constructor(url, options) {
        if (!(url instanceof URL)) {
            throw new TypeError('url must be an instance of URL');
        }
        this.#url = new URL(url.href);
        this.#timeoutDuration =
            typeof options?.timeoutDuration === 'number' ? options?.timeoutDuration : 5000;
        this.#cooldownDuration =
            typeof options?.cooldownDuration === 'number' ? options?.cooldownDuration : 30000;
        this.#cacheMaxAge = typeof options?.cacheMaxAge === 'number' ? options?.cacheMaxAge : 600000;
        this.#headers = new Headers(options?.headers);
        if (USER_AGENT && !this.#headers.has('User-Agent')) {
            this.#headers.set('User-Agent', USER_AGENT);
        }
        if (!this.#headers.has('accept')) {
            this.#headers.set('accept', 'application/json');
            this.#headers.append('accept', 'application/jwk-set+json');
        }
        this.#customFetch = options?.[customFetch];
        if (options?.[jwksCache$1] !== undefined) {
            this.#cache = options?.[jwksCache$1];
            if (isFreshJwksCache(options?.[jwksCache$1], this.#cacheMaxAge)) {
                this.#jwksTimestamp = this.#cache.uat;
                this.#local = createLocalJWKSet(this.#cache.jwks);
            }
        }
    }
    pendingFetch() {
        return !!this.#pendingFetch;
    }
    coolingDown() {
        return typeof this.#jwksTimestamp === 'number'
            ? Date.now() < this.#jwksTimestamp + this.#cooldownDuration
            : false;
    }
    fresh() {
        return typeof this.#jwksTimestamp === 'number'
            ? Date.now() < this.#jwksTimestamp + this.#cacheMaxAge
            : false;
    }
    jwks() {
        return this.#local?.jwks();
    }
    async getKey(protectedHeader, token) {
        if (!this.#local || !this.fresh()) {
            await this.reload();
        }
        try {
            return await this.#local(protectedHeader, token);
        }
        catch (err) {
            if (err instanceof JWKSNoMatchingKey) {
                if (this.coolingDown() === false) {
                    await this.reload();
                    return this.#local(protectedHeader, token);
                }
            }
            throw err;
        }
    }
    async reload() {
        if (this.#pendingFetch && isCloudflareWorkers()) {
            this.#pendingFetch = undefined;
        }
        this.#pendingFetch ||= fetchJwks(this.#url.href, this.#headers, AbortSignal.timeout(this.#timeoutDuration), this.#customFetch)
            .then((json) => {
            this.#local = createLocalJWKSet(json);
            if (this.#cache) {
                this.#cache.uat = Date.now();
                this.#cache.jwks = json;
            }
            this.#jwksTimestamp = Date.now();
            this.#pendingFetch = undefined;
        })
            .catch((err) => {
            this.#pendingFetch = undefined;
            throw err;
        });
        await this.#pendingFetch;
    }
}
function createRemoteJWKSet(url, options) {
    const set = new RemoteJWKSet(url, options);
    const remoteJWKSet = async (protectedHeader, token) => set.getKey(protectedHeader, token);
    Object.defineProperties(remoteJWKSet, {
        coolingDown: {
            get: () => set.coolingDown(),
            enumerable: true,
            configurable: false,
        },
        fresh: {
            get: () => set.fresh(),
            enumerable: true,
            configurable: false,
        },
        reload: {
            value: () => set.reload(),
            enumerable: true,
            configurable: false,
            writable: false,
        },
        reloading: {
            get: () => set.pendingFetch(),
            enumerable: true,
            configurable: false,
        },
        jwks: {
            value: () => set.jwks(),
            enumerable: true,
            configurable: false,
            writable: false,
        },
    });
    return remoteJWKSet;
}

const jwksCache = /* @__PURE__ */ new Map();
function createOAuth2Handler(config, usersResource) {
  const {
    issuer,
    jwksUri,
    audience = null,
    algorithms = ["RS256", "ES256"],
    cacheTTL = 36e5,
    // 1 hour
    clockTolerance = 60,
    // 60 seconds tolerance for exp/nbf
    validateScopes = true,
    fetchUserInfo = true
  } = config;
  if (!issuer) {
    throw new Error("[OAuth2 Auth] Missing required config: issuer");
  }
  const finalJwksUri = jwksUri || `${issuer}/.well-known/jwks.json`;
  const getJWKS = () => {
    const cacheKey = finalJwksUri;
    if (jwksCache.has(cacheKey)) {
      const cached = jwksCache.get(cacheKey);
      if (Date.now() - cached.timestamp < cacheTTL) {
        return cached.jwks;
      }
    }
    const jwks = createRemoteJWKSet(new URL(finalJwksUri), {
      cooldownDuration: 3e4,
      // 30 seconds cooldown between fetches
      cacheMaxAge: cacheTTL
    });
    jwksCache.set(cacheKey, {
      jwks,
      timestamp: Date.now()
    });
    return jwks;
  };
  return async (c) => {
    const authHeader = c.req.header("authorization") || c.req.header("Authorization");
    if (!authHeader || !authHeader.startsWith("Bearer ")) {
      return null;
    }
    const token = authHeader.substring(7);
    try {
      const jwks = getJWKS();
      const verifyOptions = {
        issuer,
        algorithms,
        clockTolerance
      };
      if (audience) {
        verifyOptions.audience = audience;
      }
      const { payload } = await jwtVerify(token, jwks, verifyOptions);
      const userId = payload.sub;
      const email = payload.email || null;
      const username = payload.preferred_username || payload.username || email;
      const scopes = payload.scope ? payload.scope.split(" ") : payload.scopes || [];
      const role = payload.role || "user";
      let user = null;
      if (fetchUserInfo && userId && usersResource) {
        try {
          user = await usersResource.get(userId).catch(() => null);
          if (!user && email) {
            const users = await usersResource.query({ email }, { limit: 1 });
            user = users[0] || null;
          }
        } catch (err) {
        }
      }
      if (user) {
        return {
          ...user,
          scopes: user.scopes || scopes,
          // Prefer database scopes
          role: user.role || role,
          tokenClaims: payload
          // Include full token claims
        };
      }
      return {
        id: userId,
        username: username || userId,
        email,
        role,
        scopes,
        active: true,
        tokenClaims: payload,
        isVirtual: true
        // Flag to indicate user is not in local database
      };
    } catch (err) {
      if (config.verbose) {
        console.error("[OAuth2 Auth] Token verification failed:", err.message);
      }
      return null;
    }
  };
}

function createAuthMiddleware(options = {}) {
  const {
    methods = [],
    jwt: jwtConfig = {},
    apiKey: apiKeyConfig = {},
    basic: basicConfig = {},
    oauth2: oauth2Config = {},
    oidc: oidcMiddleware = null,
    usersResource,
    optional = false
  } = options;
  if (methods.length === 0) {
    return async (c, next) => await next();
  }
  const middlewares = [];
  if (methods.includes("jwt") && jwtConfig.secret) {
    middlewares.push({
      name: "jwt",
      middleware: jwtAuth({
        secret: jwtConfig.secret,
        usersResource,
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("apiKey") && usersResource) {
    middlewares.push({
      name: "apiKey",
      middleware: apiKeyAuth({
        headerName: apiKeyConfig.headerName || "X-API-Key",
        usersResource,
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("basic") && usersResource) {
    middlewares.push({
      name: "basic",
      middleware: basicAuth({
        realm: basicConfig.realm || "API Access",
        passphrase: basicConfig.passphrase || "secret",
        optional: true
        // Check all methods before rejecting
      })
    });
  }
  if (methods.includes("oauth2") && oauth2Config.issuer) {
    const oauth2Handler = createOAuth2Handler(oauth2Config, usersResource);
    middlewares.push({
      name: "oauth2",
      middleware: async (c, next) => {
        const user = await oauth2Handler(c);
        if (user) {
          c.set("user", user);
          return await next();
        }
      }
    });
  }
  if (oidcMiddleware) {
    middlewares.push({
      name: "oidc",
      middleware: oidcMiddleware
    });
  }
  return async (c, next) => {
    for (const { name, middleware } of middlewares) {
      let authSuccess = false;
      const tempNext = async () => {
        authSuccess = true;
      };
      await middleware(c, tempNext);
      if (authSuccess && c.get("user")) {
        return await next();
      }
    }
    if (optional) {
      return await next();
    }
    const response = unauthorized(
      `Authentication required. Supported methods: ${methods.join(", ")}`
    );
    return c.json(response, response._status);
  };
}

async function getOrCreateUser(usersResource, claims, config) {
  const userId = claims.email || claims.preferred_username || claims.sub;
  if (!userId) {
    throw new Error("Cannot extract user ID from OIDC claims (no email/preferred_username/sub)");
  }
  let user = null;
  let userExists = false;
  try {
    user = await usersResource.get(userId);
    userExists = true;
  } catch (err) {
  }
  const now = (/* @__PURE__ */ new Date()).toISOString();
  if (user) {
    const updates = {
      lastLoginAt: now,
      metadata: {
        ...user.metadata,
        oidc: {
          sub: claims.sub,
          provider: config.issuer,
          lastSync: now,
          claims: {
            name: claims.name,
            email: claims.email,
            picture: claims.picture
          }
        }
      }
    };
    if (claims.name && claims.name !== user.name) {
      updates.name = claims.name;
    }
    user = await usersResource.update(userId, updates);
    return { user, created: false };
  }
  const newUser = {
    id: userId,
    email: claims.email || userId,
    username: claims.preferred_username || claims.email || userId,
    name: claims.name || claims.email || userId,
    picture: claims.picture || null,
    role: config.defaultRole || "user",
    scopes: config.defaultScopes || ["openid", "profile", "email"],
    active: true,
    apiKey: null,
    // Will be generated on first API usage if needed
    lastLoginAt: now,
    metadata: {
      oidc: {
        sub: claims.sub,
        provider: config.issuer,
        createdAt: now,
        claims: {
          name: claims.name,
          email: claims.email,
          picture: claims.picture
        }
      },
      costCenterId: config.defaultCostCenter || null,
      teamId: config.defaultTeam || null
    }
  };
  user = await usersResource.insert(newUser);
  return { user, created: true };
}
async function refreshAccessToken(tokenEndpoint, refreshToken, clientId, clientSecret) {
  const response = await fetch(tokenEndpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/x-www-form-urlencoded",
      "Authorization": `Basic ${Buffer.from(`${clientId}:${clientSecret}`).toString("base64")}`
    },
    body: new URLSearchParams({
      grant_type: "refresh_token",
      refresh_token: refreshToken
    })
  });
  if (!response.ok) {
    throw new Error(`Token refresh failed: ${response.status}`);
  }
  return await response.json();
}
function createOIDCHandler(config, app, usersResource) {
  const finalConfig = {
    scopes: ["openid", "profile", "email", "offline_access"],
    cookieName: "oidc_session",
    cookieMaxAge: 6048e5,
    // 7 days (same as absolute duration)
    rollingDuration: 864e5,
    // 24 hours
    absoluteDuration: 6048e5,
    // 7 days
    loginPath: "/auth/login",
    callbackPath: "/auth/callback",
    logoutPath: "/auth/logout",
    postLoginRedirect: "/",
    postLogoutRedirect: "/",
    idpLogout: true,
    autoCreateUser: true,
    autoRefreshTokens: true,
    refreshThreshold: 3e5,
    // 5 minutes before expiry
    cookieSecure: process.env.NODE_ENV === "production",
    cookieSameSite: "Lax",
    defaultRole: "user",
    defaultScopes: ["openid", "profile", "email"],
    ...config
  };
  const {
    issuer,
    clientId,
    clientSecret,
    redirectUri,
    scopes,
    cookieSecret,
    cookieName,
    cookieMaxAge,
    rollingDuration,
    absoluteDuration,
    loginPath,
    callbackPath,
    logoutPath,
    postLoginRedirect,
    postLogoutRedirect,
    idpLogout,
    autoCreateUser,
    autoRefreshTokens,
    refreshThreshold,
    cookieSecure,
    cookieSameSite
  } = finalConfig;
  const authorizationEndpoint = `${issuer}/oauth/authorize`;
  const tokenEndpoint = `${issuer}/oauth/token`;
  const logoutEndpoint = `${issuer}/oauth2/v2.0/logout`;
  async function encodeSession(data) {
    const secret = new TextEncoder().encode(cookieSecret);
    const jwt = await new SignJWT(data).setProtectedHeader({ alg: "HS256" }).setIssuedAt().setExpirationTime(`${Math.floor(cookieMaxAge / 1e3)}s`).sign(secret);
    return jwt;
  }
  async function decodeSession(jwt) {
    try {
      const secret = new TextEncoder().encode(cookieSecret);
      const { payload } = await jwtVerify(jwt, secret);
      return payload;
    } catch (err) {
      return null;
    }
  }
  function validateSessionDuration(session) {
    const now = Date.now();
    if (session.issued_at + absoluteDuration < now) {
      return { valid: false, reason: "absolute_expired" };
    }
    if (session.last_activity + rollingDuration < now) {
      return { valid: false, reason: "rolling_expired" };
    }
    return { valid: true };
  }
  function generateState() {
    return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
  }
  function decodeIdToken(idToken) {
    try {
      const parts = idToken.split(".");
      if (parts.length !== 3) return null;
      const payload = Buffer.from(parts[1], "base64").toString("utf-8");
      return JSON.parse(payload);
    } catch (err) {
      return null;
    }
  }
  app.get(loginPath, async (c) => {
    const state = generateState();
    const stateJWT = await encodeSession({ state, type: "csrf", expires: Date.now() + 6e5 });
    c.header("Set-Cookie", `${cookieName}_state=${stateJWT}; Path=/; HttpOnly; Max-Age=600; SameSite=Lax`);
    const params = new URLSearchParams({
      response_type: "code",
      client_id: clientId,
      redirect_uri: redirectUri,
      scope: scopes.join(" "),
      state
    });
    return c.redirect(`${authorizationEndpoint}?${params.toString()}`, 302);
  });
  app.get(callbackPath, async (c) => {
    const code = c.req.query("code");
    const state = c.req.query("state");
    const stateCookie = c.req.cookie(`${cookieName}_state`);
    if (!stateCookie) {
      return c.json({ error: "Missing state cookie (CSRF protection)" }, 400);
    }
    const stateData = await decodeSession(stateCookie);
    if (!stateData || stateData.state !== state) {
      return c.json({ error: "Invalid state (CSRF protection)" }, 400);
    }
    c.header("Set-Cookie", `${cookieName}_state=; Path=/; HttpOnly; Max-Age=0`);
    if (!code) {
      return c.json({ error: "Missing authorization code" }, 400);
    }
    try {
      const tokenResponse = await fetch(tokenEndpoint, {
        method: "POST",
        headers: {
          "Content-Type": "application/x-www-form-urlencoded",
          "Authorization": `Basic ${Buffer.from(`${clientId}:${clientSecret}`).toString("base64")}`
        },
        body: new URLSearchParams({
          grant_type: "authorization_code",
          code,
          redirect_uri: redirectUri
        })
      });
      if (!tokenResponse.ok) {
        const error = await tokenResponse.text();
        console.error("[OIDC] Token exchange failed:", error);
        return c.json({ error: "Failed to exchange code for tokens" }, 500);
      }
      const tokens = await tokenResponse.json();
      const idTokenClaims = decodeIdToken(tokens.id_token);
      if (!idTokenClaims) {
        return c.json({ error: "Failed to decode id_token" }, 500);
      }
      let user = null;
      let userCreated = false;
      if (autoCreateUser && usersResource) {
        try {
          const result = await getOrCreateUser(usersResource, idTokenClaims, finalConfig);
          user = result.user;
          userCreated = result.created;
          if (finalConfig.onUserAuthenticated && typeof finalConfig.onUserAuthenticated === "function") {
            try {
              await finalConfig.onUserAuthenticated({
                user,
                created: userCreated,
                claims: idTokenClaims,
                tokens: {
                  access_token: tokens.access_token,
                  id_token: tokens.id_token,
                  refresh_token: tokens.refresh_token
                },
                context: c
                // 🔥 Pass Hono context for cookie/header manipulation
              });
            } catch (hookErr) {
              console.error("[OIDC] onUserAuthenticated hook failed:", hookErr);
            }
          }
        } catch (err) {
          console.error("[OIDC] Failed to create/update user:", err);
        }
      }
      const now = Date.now();
      const sessionData = {
        access_token: tokens.access_token,
        id_token: tokens.id_token,
        refresh_token: tokens.refresh_token,
        expires_at: now + tokens.expires_in * 1e3,
        issued_at: now,
        last_activity: now,
        // User data (avoid DB lookup on every request)
        user: user ? {
          id: user.id,
          email: user.email,
          username: user.username,
          name: user.name,
          picture: user.picture,
          role: user.role,
          scopes: user.scopes,
          active: user.active,
          metadata: {
            costCenterId: user.metadata?.costCenterId,
            teamId: user.metadata?.teamId
          }
        } : {
          id: idTokenClaims.sub,
          email: idTokenClaims.email,
          username: idTokenClaims.preferred_username || idTokenClaims.email,
          name: idTokenClaims.name,
          picture: idTokenClaims.picture,
          role: "user",
          scopes,
          active: true,
          isVirtual: true
        }
      };
      const sessionJWT = await encodeSession(sessionData);
      const cookieOptions = [
        `${cookieName}=${sessionJWT}`,
        "Path=/",
        "HttpOnly",
        `Max-Age=${Math.floor(cookieMaxAge / 1e3)}`,
        `SameSite=${cookieSameSite}`
      ];
      if (cookieSecure) {
        cookieOptions.push("Secure");
      }
      c.header("Set-Cookie", cookieOptions.join("; "));
      return c.redirect(postLoginRedirect, 302);
    } catch (err) {
      console.error("[OIDC] Error during token exchange:", err);
      return c.json({ error: "Authentication failed" }, 500);
    }
  });
  app.get(logoutPath, async (c) => {
    const sessionCookie = c.req.cookie(cookieName);
    let idToken = null;
    if (sessionCookie) {
      const session = await decodeSession(sessionCookie);
      idToken = session?.id_token;
    }
    c.header("Set-Cookie", `${cookieName}=; Path=/; HttpOnly; Max-Age=0`);
    if (idpLogout && idToken) {
      const params = new URLSearchParams({
        id_token_hint: idToken,
        post_logout_redirect_uri: `${postLogoutRedirect}`
      });
      return c.redirect(`${logoutEndpoint}?${params.toString()}`, 302);
    }
    return c.redirect(postLogoutRedirect, 302);
  });
  const middleware = async (c, next) => {
    const sessionCookie = c.req.cookie(cookieName);
    if (!sessionCookie) {
      return await next();
    }
    const session = await decodeSession(sessionCookie);
    if (!session || !session.access_token) {
      return await next();
    }
    const validation = validateSessionDuration(session);
    if (!validation.valid) {
      c.header("Set-Cookie", `${cookieName}=; Path=/; HttpOnly; Max-Age=0`);
      return await next();
    }
    if (autoRefreshTokens && session.refresh_token && session.expires_at) {
      const timeUntilExpiry = session.expires_at - Date.now();
      if (timeUntilExpiry < refreshThreshold) {
        try {
          const newTokens = await refreshAccessToken(
            tokenEndpoint,
            session.refresh_token,
            clientId,
            clientSecret
          );
          session.access_token = newTokens.access_token;
          session.expires_at = Date.now() + newTokens.expires_in * 1e3;
          if (newTokens.refresh_token) {
            session.refresh_token = newTokens.refresh_token;
          }
        } catch (err) {
          console.error("[OIDC] Token refresh failed:", err);
        }
      }
    }
    session.last_activity = Date.now();
    c.set("user", {
      ...session.user,
      authMethod: "oidc",
      session: {
        access_token: session.access_token,
        refresh_token: session.refresh_token,
        expires_at: session.expires_at
      }
    });
    const newSessionJWT = await encodeSession(session);
    const cookieOptions = [
      `${cookieName}=${newSessionJWT}`,
      "Path=/",
      "HttpOnly",
      `Max-Age=${Math.floor(cookieMaxAge / 1e3)}`,
      `SameSite=${cookieSameSite}`
    ];
    if (cookieSecure) {
      cookieOptions.push("Secure");
    }
    c.header("Set-Cookie", cookieOptions.join("; "));
    return await next();
  };
  return {
    middleware,
    routes: {
      [loginPath]: "Login (redirect to SSO)",
      [callbackPath]: "OAuth2 callback",
      [logoutPath]: "Logout (local + IdP)"
    },
    config: finalConfig
  };
}

function patternToRegex(pattern) {
  let escaped = pattern.replace(/[.+?^${}()|[\]\\]/g, "\\$&");
  escaped = escaped.replace(/\*\*/g, "__DOUBLE_STAR__");
  escaped = escaped.replace(/\*/g, "([^/]+)");
  escaped = escaped.replace(/__DOUBLE_STAR__/g, "(.*)");
  return new RegExp(`^${escaped}$`);
}
function matchPath(pattern, path) {
  const regex = patternToRegex(pattern);
  return regex.test(path);
}
function calculateSpecificity(pattern) {
  const segments = pattern.split("/").filter((s) => s !== "");
  let score = 0;
  for (const segment of segments) {
    if (segment === "**") {
      score += 10;
    } else if (segment === "*") {
      score += 100;
    } else {
      score += 1e3;
    }
  }
  return score;
}
function findBestMatch(rules, path) {
  if (!rules || rules.length === 0) {
    return null;
  }
  const matches = rules.map((rule) => ({
    rule,
    specificity: calculateSpecificity(rule.pattern)
  })).filter(({ rule }) => matchPath(rule.pattern, path)).sort((a, b) => b.specificity - a.specificity);
  return matches.length > 0 ? matches[0].rule : null;
}
function validatePathAuth(pathAuth) {
  if (!Array.isArray(pathAuth)) {
    throw new Error("pathAuth must be an array of rules");
  }
  for (const [index, rule] of pathAuth.entries()) {
    if (!rule.pattern || typeof rule.pattern !== "string") {
      throw new Error(`pathAuth[${index}]: pattern is required and must be a string`);
    }
    if (!rule.pattern.startsWith("/")) {
      throw new Error(`pathAuth[${index}]: pattern must start with / (got: ${rule.pattern})`);
    }
    if (rule.drivers !== void 0 && !Array.isArray(rule.drivers)) {
      throw new Error(`pathAuth[${index}]: drivers must be an array (got: ${typeof rule.drivers})`);
    }
    if (rule.required !== void 0 && typeof rule.required !== "boolean") {
      throw new Error(`pathAuth[${index}]: required must be a boolean (got: ${typeof rule.required})`);
    }
    const validDrivers = ["jwt", "apiKey", "basic", "oauth2", "oidc"];
    if (rule.drivers) {
      for (const driver of rule.drivers) {
        if (!validDrivers.includes(driver)) {
          throw new Error(
            `pathAuth[${index}]: invalid driver '${driver}'. Valid drivers: ${validDrivers.join(", ")}`
          );
        }
      }
    }
  }
}

const MIME_TYPES = {
  // Text
  "txt": "text/plain",
  "html": "text/html",
  "htm": "text/html",
  "css": "text/css",
  "js": "text/javascript",
  "mjs": "text/javascript",
  "json": "application/json",
  "xml": "application/xml",
  "csv": "text/csv",
  "md": "text/markdown",
  // Images
  "jpg": "image/jpeg",
  "jpeg": "image/jpeg",
  "png": "image/png",
  "gif": "image/gif",
  "webp": "image/webp",
  "svg": "image/svg+xml",
  "ico": "image/x-icon",
  "bmp": "image/bmp",
  "tiff": "image/tiff",
  "tif": "image/tiff",
  // Audio
  "mp3": "audio/mpeg",
  "wav": "audio/wav",
  "ogg": "audio/ogg",
  "flac": "audio/flac",
  "m4a": "audio/mp4",
  // Video
  "mp4": "video/mp4",
  "webm": "video/webm",
  "ogv": "video/ogg",
  "avi": "video/x-msvideo",
  "mov": "video/quicktime",
  "mkv": "video/x-matroska",
  // Documents
  "pdf": "application/pdf",
  "doc": "application/msword",
  "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
  "xls": "application/vnd.ms-excel",
  "xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
  "ppt": "application/vnd.ms-powerpoint",
  "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
  // Archives
  "zip": "application/zip",
  "tar": "application/x-tar",
  "gz": "application/gzip",
  "bz2": "application/x-bzip2",
  "7z": "application/x-7z-compressed",
  "rar": "application/vnd.rar",
  // Fonts
  "ttf": "font/ttf",
  "otf": "font/otf",
  "woff": "font/woff",
  "woff2": "font/woff2",
  "eot": "application/vnd.ms-fontobject",
  // Application
  "wasm": "application/wasm",
  "bin": "application/octet-stream"
};
function getMimeType(filename) {
  if (!filename || typeof filename !== "string") {
    return "application/octet-stream";
  }
  const ext = filename.split(".").pop().toLowerCase();
  return MIME_TYPES[ext] || "application/octet-stream";
}
function getCharset(mimeType) {
  if (!mimeType) return null;
  if (mimeType.startsWith("text/")) return "utf-8";
  if (mimeType.includes("javascript")) return "utf-8";
  if (mimeType.includes("json")) return "utf-8";
  if (mimeType.includes("xml")) return "utf-8";
  return null;
}
function getContentType(filename) {
  const mimeType = getMimeType(filename);
  const charset = getCharset(mimeType);
  return charset ? `${mimeType}; charset=${charset}` : mimeType;
}

function createFilesystemHandler(config = {}) {
  const {
    root,
    index = ["index.html"],
    fallback = false,
    maxAge = 0,
    dotfiles = "ignore",
    etag = true,
    cors = false
  } = config;
  if (!root) {
    throw new Error('Filesystem static handler requires "root" directory');
  }
  const absoluteRoot = path$1.resolve(root);
  let fallbackFile = null;
  if (fallback === true) {
    fallbackFile = index[0];
  } else if (typeof fallback === "string") {
    fallbackFile = fallback;
  }
  return async (c) => {
    try {
      let requestPath = c.req.path.replace(/^\//, "");
      const safePath = path$1.normalize(requestPath).replace(/^(\.\.(\/|\\|$))+/, "");
      const fullPath = path$1.join(absoluteRoot, safePath);
      if (!fullPath.startsWith(absoluteRoot)) {
        return c.json({ success: false, error: { message: "Forbidden" } }, 403);
      }
      let stats;
      let useFallback = false;
      try {
        stats = await fs.stat(fullPath);
      } catch (err) {
        if (err.code === "ENOENT" && fallbackFile) {
          useFallback = true;
        } else if (err.code === "ENOENT") {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        } else {
          throw err;
        }
      }
      let filePath = fullPath;
      if (useFallback) {
        filePath = path$1.join(absoluteRoot, fallbackFile);
        try {
          stats = await fs.stat(filePath);
        } catch (err) {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
      }
      if (!useFallback && stats.isDirectory()) {
        let indexFound = false;
        for (const indexFile of index) {
          const indexPath = path$1.join(fullPath, indexFile);
          try {
            const indexStats = await fs.stat(indexPath);
            if (indexStats.isFile()) {
              filePath = indexPath;
              stats = indexStats;
              indexFound = true;
              break;
            }
          } catch (err) {
          }
        }
        if (!indexFound) {
          if (fallbackFile) {
            filePath = path$1.join(absoluteRoot, fallbackFile);
            try {
              stats = await fs.stat(filePath);
            } catch (err) {
              return c.json({ success: false, error: { message: "Forbidden" } }, 403);
            }
          } else {
            return c.json({ success: false, error: { message: "Forbidden" } }, 403);
          }
        }
      }
      const filename = path$1.basename(filePath);
      if (filename.startsWith(".")) {
        if (dotfiles === "deny") {
          return c.json({ success: false, error: { message: "Forbidden" } }, 403);
        } else if (dotfiles === "ignore") {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
      }
      const etagValue = etag ? `"${crypto$1.createHash("md5").update(`${stats.mtime.getTime()}-${stats.size}`).digest("hex")}"` : null;
      if (etagValue) {
        const ifNoneMatch = c.req.header("If-None-Match");
        if (ifNoneMatch === etagValue) {
          return c.body(null, 304, {
            "ETag": etagValue,
            "Cache-Control": maxAge > 0 ? `public, max-age=${Math.floor(maxAge / 1e3)}` : "no-cache"
          });
        }
      }
      const contentType = getContentType(filename);
      const headers = {
        "Content-Type": contentType,
        "Content-Length": stats.size.toString(),
        "Last-Modified": stats.mtime.toUTCString()
      };
      if (etagValue) {
        headers["ETag"] = etagValue;
      }
      if (maxAge > 0) {
        headers["Cache-Control"] = `public, max-age=${Math.floor(maxAge / 1e3)}`;
      } else {
        headers["Cache-Control"] = "no-cache";
      }
      if (cors) {
        headers["Access-Control-Allow-Origin"] = "*";
        headers["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
      }
      const rangeHeader = c.req.header("Range");
      if (rangeHeader) {
        const parts = rangeHeader.replace(/bytes=/, "").split("-");
        const start = parseInt(parts[0], 10);
        const end = parts[1] ? parseInt(parts[1], 10) : stats.size - 1;
        if (start >= stats.size || end >= stats.size) {
          return c.body(null, 416, {
            "Content-Range": `bytes */${stats.size}`
          });
        }
        const chunkSize = end - start + 1;
        const stream2 = createReadStream(filePath, { start, end });
        headers["Content-Range"] = `bytes ${start}-${end}/${stats.size}`;
        headers["Content-Length"] = chunkSize.toString();
        headers["Accept-Ranges"] = "bytes";
        return c.body(stream2, 206, headers);
      }
      if (c.req.method === "HEAD") {
        return c.body(null, 200, headers);
      }
      const stream = createReadStream(filePath);
      return c.body(stream, 200, headers);
    } catch (err) {
      console.error("[Static Filesystem] Error:", err);
      return c.json({ success: false, error: { message: "Internal Server Error" } }, 500);
    }
  };
}
function validateFilesystemConfig(config) {
  if (!config.root || typeof config.root !== "string") {
    throw new Error('Filesystem static config requires "root" directory (string)');
  }
  if (config.index !== void 0 && !Array.isArray(config.index)) {
    throw new Error('Filesystem static "index" must be an array');
  }
  if (config.fallback !== void 0 && typeof config.fallback !== "string" && typeof config.fallback !== "boolean") {
    throw new Error('Filesystem static "fallback" must be a string (filename) or boolean');
  }
  if (config.maxAge !== void 0 && typeof config.maxAge !== "number") {
    throw new Error('Filesystem static "maxAge" must be a number');
  }
  if (config.dotfiles !== void 0 && !["ignore", "allow", "deny"].includes(config.dotfiles)) {
    throw new Error('Filesystem static "dotfiles" must be "ignore", "allow", or "deny"');
  }
  if (config.etag !== void 0 && typeof config.etag !== "boolean") {
    throw new Error('Filesystem static "etag" must be a boolean');
  }
  if (config.cors !== void 0 && typeof config.cors !== "boolean") {
    throw new Error('Filesystem static "cors" must be a boolean');
  }
}

const escapeUri = (uri) => encodeURIComponent(uri).replace(/[!'()*]/g, hexEncode);
const hexEncode = (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`;

function buildQueryString(query) {
    const parts = [];
    for (let key of Object.keys(query).sort()) {
        const value = query[key];
        key = escapeUri(key);
        if (Array.isArray(value)) {
            for (let i = 0, iLen = value.length; i < iLen; i++) {
                parts.push(`${key}=${escapeUri(value[i])}`);
            }
        }
        else {
            let qsEntry = key;
            if (value || typeof value === "string") {
                qsEntry += `=${escapeUri(value)}`;
            }
            parts.push(qsEntry);
        }
    }
    return parts.join("&");
}

function formatUrl(request) {
    const { port, query } = request;
    let { protocol, path, hostname } = request;
    if (protocol && protocol.slice(-1) !== ":") {
        protocol += ":";
    }
    if (port) {
        hostname += `:${port}`;
    }
    if (path && path.charAt(0) !== "/") {
        path = `/${path}`;
    }
    let queryString = query ? buildQueryString(query) : "";
    if (queryString && queryString[0] !== "?") {
        queryString = `?${queryString}`;
    }
    let auth = "";
    if (request.username != null || request.password != null) {
        const username = request.username ?? "";
        const password = request.password ?? "";
        auth = `${username}:${password}@`;
    }
    let fragment = "";
    if (request.fragment) {
        fragment = `#${request.fragment}`;
    }
    return `${protocol}//${auth}${hostname}${path}${queryString}${fragment}`;
}

const resolveParamsForS3 = async (endpointParams) => {
    const bucket = endpointParams?.Bucket || "";
    if (typeof endpointParams.Bucket === "string") {
        endpointParams.Bucket = bucket.replace(/#/g, encodeURIComponent("#")).replace(/\?/g, encodeURIComponent("?"));
    }
    if (isArnBucketName(bucket)) {
        if (endpointParams.ForcePathStyle === true) {
            throw new Error("Path-style addressing cannot be used with ARN buckets");
        }
    }
    else if (!isDnsCompatibleBucketName(bucket) ||
        (bucket.indexOf(".") !== -1 && !String(endpointParams.Endpoint).startsWith("http:")) ||
        bucket.toLowerCase() !== bucket ||
        bucket.length < 3) {
        endpointParams.ForcePathStyle = true;
    }
    if (endpointParams.DisableMultiRegionAccessPoints) {
        endpointParams.disableMultiRegionAccessPoints = true;
        endpointParams.DisableMRAP = true;
    }
    return endpointParams;
};
const DOMAIN_PATTERN = /^[a-z0-9][a-z0-9\.\-]{1,61}[a-z0-9]$/;
const IP_ADDRESS_PATTERN = /(\d+\.){3}\d+/;
const DOTS_PATTERN = /\.\./;
const isDnsCompatibleBucketName = (bucketName) => DOMAIN_PATTERN.test(bucketName) && !IP_ADDRESS_PATTERN.test(bucketName) && !DOTS_PATTERN.test(bucketName);
const isArnBucketName = (bucketName) => {
    const [arn, partition, service, , , bucket] = bucketName.split(":");
    const isArn = arn === "arn" && bucketName.split(":").length >= 6;
    const isValidArn = Boolean(isArn && partition && service && bucket);
    if (isArn && !isValidArn) {
        throw new Error(`Invalid ARN: ${bucketName} was an invalid ARN.`);
    }
    return isValidArn;
};

const createConfigValueProvider = (configKey, canonicalEndpointParamKey, config) => {
    const configProvider = async () => {
        const configValue = config[configKey] ?? config[canonicalEndpointParamKey];
        if (typeof configValue === "function") {
            return configValue();
        }
        return configValue;
    };
    if (configKey === "credentialScope" || canonicalEndpointParamKey === "CredentialScope") {
        return async () => {
            const credentials = typeof config.credentials === "function" ? await config.credentials() : config.credentials;
            const configValue = credentials?.credentialScope ?? credentials?.CredentialScope;
            return configValue;
        };
    }
    if (configKey === "accountId" || canonicalEndpointParamKey === "AccountId") {
        return async () => {
            const credentials = typeof config.credentials === "function" ? await config.credentials() : config.credentials;
            const configValue = credentials?.accountId ?? credentials?.AccountId;
            return configValue;
        };
    }
    if (configKey === "endpoint" || canonicalEndpointParamKey === "endpoint") {
        return async () => {
            if (config.isCustomEndpoint === false) {
                return undefined;
            }
            const endpoint = await configProvider();
            if (endpoint && typeof endpoint === "object") {
                if ("url" in endpoint) {
                    return endpoint.url.href;
                }
                if ("hostname" in endpoint) {
                    const { protocol, hostname, port, path } = endpoint;
                    return `${protocol}//${hostname}${port ? ":" + port : ""}${path}`;
                }
            }
            return endpoint;
        };
    }
    return configProvider;
};

class ProviderError extends Error {
    name = "ProviderError";
    tryNextLink;
    constructor(message, options = true) {
        let logger;
        let tryNextLink = true;
        if (typeof options === "boolean") {
            logger = undefined;
            tryNextLink = options;
        }
        else if (options != null && typeof options === "object") {
            logger = options.logger;
            tryNextLink = options.tryNextLink ?? true;
        }
        super(message);
        this.tryNextLink = tryNextLink;
        Object.setPrototypeOf(this, ProviderError.prototype);
        logger?.debug?.(`@smithy/property-provider ${tryNextLink ? "->" : "(!)"} ${message}`);
    }
    static from(error, options = true) {
        return Object.assign(new this(error.message, options), error);
    }
}

class CredentialsProviderError extends ProviderError {
    name = "CredentialsProviderError";
    constructor(message, options = true) {
        super(message, options);
        Object.setPrototypeOf(this, CredentialsProviderError.prototype);
    }
}

const chain = (...providers) => async () => {
    if (providers.length === 0) {
        throw new ProviderError("No providers in chain");
    }
    let lastProviderError;
    for (const provider of providers) {
        try {
            const credentials = await provider();
            return credentials;
        }
        catch (err) {
            lastProviderError = err;
            if (err?.tryNextLink) {
                continue;
            }
            throw err;
        }
    }
    throw lastProviderError;
};

const fromStatic$1 = (staticValue) => () => Promise.resolve(staticValue);

const memoize = (provider, isExpired, requiresRefresh) => {
    let resolved;
    let pending;
    let hasResult;
    let isConstant = false;
    const coalesceProvider = async () => {
        if (!pending) {
            pending = provider();
        }
        try {
            resolved = await pending;
            hasResult = true;
            isConstant = false;
        }
        finally {
            pending = undefined;
        }
        return resolved;
    };
    {
        return async (options) => {
            if (!hasResult || options?.forceRefresh) {
                resolved = await coalesceProvider();
            }
            return resolved;
        };
    }
};

function getSelectorName(functionString) {
    try {
        const constants = new Set(Array.from(functionString.match(/([A-Z_]){3,}/g) ?? []));
        constants.delete("CONFIG");
        constants.delete("CONFIG_PREFIX_SEPARATOR");
        constants.delete("ENV");
        return [...constants].join(", ");
    }
    catch (e) {
        return functionString;
    }
}

const fromEnv = (envVarSelector, options) => async () => {
    try {
        const config = envVarSelector(process.env, options);
        if (config === undefined) {
            throw new Error();
        }
        return config;
    }
    catch (e) {
        throw new CredentialsProviderError(e.message || `Not found in ENV: ${getSelectorName(envVarSelector.toString())}`, { logger: options?.logger });
    }
};

const homeDirCache = {};
const getHomeDirCacheKey = () => {
    if (process && process.geteuid) {
        return `${process.geteuid()}`;
    }
    return "DEFAULT";
};
const getHomeDir = () => {
    const { HOME, USERPROFILE, HOMEPATH, HOMEDRIVE = `C:${sep$1}` } = process.env;
    if (HOME)
        return HOME;
    if (USERPROFILE)
        return USERPROFILE;
    if (HOMEPATH)
        return `${HOMEDRIVE}${HOMEPATH}`;
    const homeDirCacheKey = getHomeDirCacheKey();
    if (!homeDirCache[homeDirCacheKey])
        homeDirCache[homeDirCacheKey] = homedir();
    return homeDirCache[homeDirCacheKey];
};

const ENV_PROFILE = "AWS_PROFILE";
const DEFAULT_PROFILE = "default";
const getProfileName = (init) => init.profile || process.env[ENV_PROFILE] || DEFAULT_PROFILE;

var IniSectionType;
(function (IniSectionType) {
    IniSectionType["PROFILE"] = "profile";
    IniSectionType["SSO_SESSION"] = "sso-session";
    IniSectionType["SERVICES"] = "services";
})(IniSectionType || (IniSectionType = {}));

const CONFIG_PREFIX_SEPARATOR = ".";

const getConfigData = (data) => Object.entries(data)
    .filter(([key]) => {
    const indexOfSeparator = key.indexOf(CONFIG_PREFIX_SEPARATOR);
    if (indexOfSeparator === -1) {
        return false;
    }
    return Object.values(IniSectionType).includes(key.substring(0, indexOfSeparator));
})
    .reduce((acc, [key, value]) => {
    const indexOfSeparator = key.indexOf(CONFIG_PREFIX_SEPARATOR);
    const updatedKey = key.substring(0, indexOfSeparator) === IniSectionType.PROFILE ? key.substring(indexOfSeparator + 1) : key;
    acc[updatedKey] = value;
    return acc;
}, {
    ...(data.default && { default: data.default }),
});

const ENV_CONFIG_PATH = "AWS_CONFIG_FILE";
const getConfigFilepath = () => process.env[ENV_CONFIG_PATH] || join(getHomeDir(), ".aws", "config");

const ENV_CREDENTIALS_PATH = "AWS_SHARED_CREDENTIALS_FILE";
const getCredentialsFilepath = () => process.env[ENV_CREDENTIALS_PATH] || join(getHomeDir(), ".aws", "credentials");

const prefixKeyRegex = /^([\w-]+)\s(["'])?([\w-@\+\.%:/]+)\2$/;
const profileNameBlockList = ["__proto__", "profile __proto__"];
const parseIni = (iniData) => {
    const map = {};
    let currentSection;
    let currentSubSection;
    for (const iniLine of iniData.split(/\r?\n/)) {
        const trimmedLine = iniLine.split(/(^|\s)[;#]/)[0].trim();
        const isSection = trimmedLine[0] === "[" && trimmedLine[trimmedLine.length - 1] === "]";
        if (isSection) {
            currentSection = undefined;
            currentSubSection = undefined;
            const sectionName = trimmedLine.substring(1, trimmedLine.length - 1);
            const matches = prefixKeyRegex.exec(sectionName);
            if (matches) {
                const [, prefix, , name] = matches;
                if (Object.values(IniSectionType).includes(prefix)) {
                    currentSection = [prefix, name].join(CONFIG_PREFIX_SEPARATOR);
                }
            }
            else {
                currentSection = sectionName;
            }
            if (profileNameBlockList.includes(sectionName)) {
                throw new Error(`Found invalid profile name "${sectionName}"`);
            }
        }
        else if (currentSection) {
            const indexOfEqualsSign = trimmedLine.indexOf("=");
            if (![0, -1].includes(indexOfEqualsSign)) {
                const [name, value] = [
                    trimmedLine.substring(0, indexOfEqualsSign).trim(),
                    trimmedLine.substring(indexOfEqualsSign + 1).trim(),
                ];
                if (value === "") {
                    currentSubSection = name;
                }
                else {
                    if (currentSubSection && iniLine.trimStart() === iniLine) {
                        currentSubSection = undefined;
                    }
                    map[currentSection] = map[currentSection] || {};
                    const key = currentSubSection ? [currentSubSection, name].join(CONFIG_PREFIX_SEPARATOR) : name;
                    map[currentSection][key] = value;
                }
            }
        }
    }
    return map;
};

const { readFile } = promises$1;
const filePromisesHash = {};
const fileIntercept = {};
const slurpFile = (path, options) => {
    if (fileIntercept[path] !== undefined) {
        return fileIntercept[path];
    }
    if (!filePromisesHash[path] || options?.ignoreCache) {
        filePromisesHash[path] = readFile(path, "utf8");
    }
    return filePromisesHash[path];
};

const swallowError = () => ({});
const loadSharedConfigFiles = async (init = {}) => {
    const { filepath = getCredentialsFilepath(), configFilepath = getConfigFilepath() } = init;
    const homeDir = getHomeDir();
    const relativeHomeDirPrefix = "~/";
    let resolvedFilepath = filepath;
    if (filepath.startsWith(relativeHomeDirPrefix)) {
        resolvedFilepath = join(homeDir, filepath.slice(2));
    }
    let resolvedConfigFilepath = configFilepath;
    if (configFilepath.startsWith(relativeHomeDirPrefix)) {
        resolvedConfigFilepath = join(homeDir, configFilepath.slice(2));
    }
    const parsedFiles = await Promise.all([
        slurpFile(resolvedConfigFilepath, {
            ignoreCache: init.ignoreCache,
        })
            .then(parseIni)
            .then(getConfigData)
            .catch(swallowError),
        slurpFile(resolvedFilepath, {
            ignoreCache: init.ignoreCache,
        })
            .then(parseIni)
            .catch(swallowError),
    ]);
    return {
        configFile: parsedFiles[0],
        credentialsFile: parsedFiles[1],
    };
};

const fromSharedConfigFiles = (configSelector, { preferredFile = "config", ...init } = {}) => async () => {
    const profile = getProfileName(init);
    const { configFile, credentialsFile } = await loadSharedConfigFiles(init);
    const profileFromCredentials = credentialsFile[profile] || {};
    const profileFromConfig = configFile[profile] || {};
    const mergedProfile = preferredFile === "config"
        ? { ...profileFromCredentials, ...profileFromConfig }
        : { ...profileFromConfig, ...profileFromCredentials };
    try {
        const cfgFile = preferredFile === "config" ? configFile : credentialsFile;
        const configValue = configSelector(mergedProfile, cfgFile);
        if (configValue === undefined) {
            throw new Error();
        }
        return configValue;
    }
    catch (e) {
        throw new CredentialsProviderError(e.message || `Not found in config files w/ profile [${profile}]: ${getSelectorName(configSelector.toString())}`, { logger: init.logger });
    }
};

const isFunction = (func) => "undefined" === "function";
const fromStatic = (defaultValue) => isFunction() ? async () => await defaultValue() : fromStatic$1(defaultValue);

const loadConfig = ({ environmentVariableSelector, configFileSelector, default: defaultValue }, configuration = {}) => {
    const { signingName, logger } = configuration;
    const envOptions = { signingName, logger };
    return memoize(chain(fromEnv(environmentVariableSelector, envOptions), fromSharedConfigFiles(configFileSelector, configuration), fromStatic(defaultValue)));
};

const ENV_ENDPOINT_URL = "AWS_ENDPOINT_URL";
const CONFIG_ENDPOINT_URL = "endpoint_url";
const getEndpointUrlConfig = (serviceId) => ({
    environmentVariableSelector: (env) => {
        const serviceSuffixParts = serviceId.split(" ").map((w) => w.toUpperCase());
        const serviceEndpointUrl = env[[ENV_ENDPOINT_URL, ...serviceSuffixParts].join("_")];
        if (serviceEndpointUrl)
            return serviceEndpointUrl;
        const endpointUrl = env[ENV_ENDPOINT_URL];
        if (endpointUrl)
            return endpointUrl;
        return undefined;
    },
    configFileSelector: (profile, config) => {
        if (config && profile.services) {
            const servicesSection = config[["services", profile.services].join(CONFIG_PREFIX_SEPARATOR)];
            if (servicesSection) {
                const servicePrefixParts = serviceId.split(" ").map((w) => w.toLowerCase());
                const endpointUrl = servicesSection[[servicePrefixParts.join("_"), CONFIG_ENDPOINT_URL].join(CONFIG_PREFIX_SEPARATOR)];
                if (endpointUrl)
                    return endpointUrl;
            }
        }
        const endpointUrl = profile[CONFIG_ENDPOINT_URL];
        if (endpointUrl)
            return endpointUrl;
        return undefined;
    },
    default: undefined,
});

const getEndpointFromConfig = async (serviceId) => loadConfig(getEndpointUrlConfig(serviceId ?? ""))();

function parseQueryString(querystring) {
    const query = {};
    querystring = querystring.replace(/^\?/, "");
    if (querystring) {
        for (const pair of querystring.split("&")) {
            let [key, value = null] = pair.split("=");
            key = decodeURIComponent(key);
            if (value) {
                value = decodeURIComponent(value);
            }
            if (!(key in query)) {
                query[key] = value;
            }
            else if (Array.isArray(query[key])) {
                query[key].push(value);
            }
            else {
                query[key] = [query[key], value];
            }
        }
    }
    return query;
}

const parseUrl = (url) => {
    if (typeof url === "string") {
        return parseUrl(new URL(url));
    }
    const { hostname, pathname, port, protocol, search } = url;
    let query;
    if (search) {
        query = parseQueryString(search);
    }
    return {
        hostname,
        port: port ? parseInt(port) : undefined,
        protocol,
        path: pathname,
        query,
    };
};

const toEndpointV1 = (endpoint) => {
    if (typeof endpoint === "object") {
        if ("url" in endpoint) {
            return parseUrl(endpoint.url);
        }
        return endpoint;
    }
    return parseUrl(endpoint);
};

const getEndpointFromInstructions = async (commandInput, instructionsSupplier, clientConfig, context) => {
    if (!clientConfig.isCustomEndpoint) {
        let endpointFromConfig;
        if (clientConfig.serviceConfiguredEndpoint) {
            endpointFromConfig = await clientConfig.serviceConfiguredEndpoint();
        }
        else {
            endpointFromConfig = await getEndpointFromConfig(clientConfig.serviceId);
        }
        if (endpointFromConfig) {
            clientConfig.endpoint = () => Promise.resolve(toEndpointV1(endpointFromConfig));
            clientConfig.isCustomEndpoint = true;
        }
    }
    const endpointParams = await resolveParams(commandInput, instructionsSupplier, clientConfig);
    if (typeof clientConfig.endpointProvider !== "function") {
        throw new Error("config.endpointProvider is not set.");
    }
    const endpoint = clientConfig.endpointProvider(endpointParams, context);
    return endpoint;
};
const resolveParams = async (commandInput, instructionsSupplier, clientConfig) => {
    const endpointParams = {};
    const instructions = instructionsSupplier?.getEndpointParameterInstructions?.() || {};
    for (const [name, instruction] of Object.entries(instructions)) {
        switch (instruction.type) {
            case "staticContextParams":
                endpointParams[name] = instruction.value;
                break;
            case "contextParams":
                endpointParams[name] = commandInput[instruction.name];
                break;
            case "clientContextParams":
            case "builtInParams":
                endpointParams[name] = await createConfigValueProvider(instruction.name, name, clientConfig)();
                break;
            case "operationContextParams":
                endpointParams[name] = instruction.get(commandInput);
                break;
            default:
                throw new Error("Unrecognized endpoint parameter instruction: " + JSON.stringify(instruction));
        }
    }
    if (Object.keys(instructions).length === 0) {
        Object.assign(endpointParams, clientConfig);
    }
    if (String(clientConfig.serviceId).toLowerCase() === "s3") {
        await resolveParamsForS3(endpointParams);
    }
    return endpointParams;
};

const normalizeProvider = (input) => {
    if (typeof input === "function")
        return input;
    const promisified = Promise.resolve(input);
    return () => promisified;
};

class HttpRequest {
    method;
    protocol;
    hostname;
    port;
    path;
    query;
    headers;
    username;
    password;
    fragment;
    body;
    constructor(options) {
        this.method = options.method || "GET";
        this.hostname = options.hostname || "localhost";
        this.port = options.port;
        this.query = options.query || {};
        this.headers = options.headers || {};
        this.body = options.body;
        this.protocol = options.protocol
            ? options.protocol.slice(-1) !== ":"
                ? `${options.protocol}:`
                : options.protocol
            : "https:";
        this.path = options.path ? (options.path.charAt(0) !== "/" ? `/${options.path}` : options.path) : "/";
        this.username = options.username;
        this.password = options.password;
        this.fragment = options.fragment;
    }
    static clone(request) {
        const cloned = new HttpRequest({
            ...request,
            headers: { ...request.headers },
        });
        if (cloned.query) {
            cloned.query = cloneQuery(cloned.query);
        }
        return cloned;
    }
    static isInstance(request) {
        if (!request) {
            return false;
        }
        const req = request;
        return ("method" in req &&
            "protocol" in req &&
            "hostname" in req &&
            "path" in req &&
            typeof req["query"] === "object" &&
            typeof req["headers"] === "object");
    }
    clone() {
        return HttpRequest.clone(this);
    }
}
function cloneQuery(query) {
    return Object.keys(query).reduce((carry, paramName) => {
        const param = query[paramName];
        return {
            ...carry,
            [paramName]: Array.isArray(param) ? [...param] : param,
        };
    }, {});
}

const isArrayBuffer = (arg) => (typeof ArrayBuffer === "function" && arg instanceof ArrayBuffer) ||
    Object.prototype.toString.call(arg) === "[object ArrayBuffer]";

const fromString = (input, encoding) => {
    if (typeof input !== "string") {
        throw new TypeError(`The "input" argument must be of type string. Received type ${typeof input} (${input})`);
    }
    return Buffer$1.from(input, encoding) ;
};

const fromUtf8 = (input) => {
    const buf = fromString(input, "utf8");
    return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength / Uint8Array.BYTES_PER_ELEMENT);
};

const toUint8Array = (data) => {
    if (typeof data === "string") {
        return fromUtf8(data);
    }
    if (ArrayBuffer.isView(data)) {
        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);
    }
    return new Uint8Array(data);
};

const SHORT_TO_HEX = {};
const HEX_TO_SHORT = {};
for (let i = 0; i < 256; i++) {
    let encodedByte = i.toString(16).toLowerCase();
    if (encodedByte.length === 1) {
        encodedByte = `0${encodedByte}`;
    }
    SHORT_TO_HEX[i] = encodedByte;
    HEX_TO_SHORT[encodedByte] = i;
}
function fromHex(encoded) {
    if (encoded.length % 2 !== 0) {
        throw new Error("Hex encoded strings must have an even number length");
    }
    const out = new Uint8Array(encoded.length / 2);
    for (let i = 0; i < encoded.length; i += 2) {
        const encodedByte = encoded.slice(i, i + 2).toLowerCase();
        if (encodedByte in HEX_TO_SHORT) {
            out[i / 2] = HEX_TO_SHORT[encodedByte];
        }
        else {
            throw new Error(`Cannot decode unrecognized sequence ${encodedByte} as hexadecimal`);
        }
    }
    return out;
}
function toHex(bytes) {
    let out = "";
    for (let i = 0; i < bytes.byteLength; i++) {
        out += SHORT_TO_HEX[bytes[i]];
    }
    return out;
}

const ALGORITHM_QUERY_PARAM = "X-Amz-Algorithm";
const CREDENTIAL_QUERY_PARAM = "X-Amz-Credential";
const AMZ_DATE_QUERY_PARAM = "X-Amz-Date";
const SIGNED_HEADERS_QUERY_PARAM = "X-Amz-SignedHeaders";
const EXPIRES_QUERY_PARAM = "X-Amz-Expires";
const SIGNATURE_QUERY_PARAM = "X-Amz-Signature";
const TOKEN_QUERY_PARAM = "X-Amz-Security-Token";
const AUTH_HEADER = "authorization";
const AMZ_DATE_HEADER = AMZ_DATE_QUERY_PARAM.toLowerCase();
const DATE_HEADER = "date";
const GENERATED_HEADERS = [AUTH_HEADER, AMZ_DATE_HEADER, DATE_HEADER];
const SIGNATURE_HEADER = SIGNATURE_QUERY_PARAM.toLowerCase();
const SHA256_HEADER$1 = "x-amz-content-sha256";
const TOKEN_HEADER = TOKEN_QUERY_PARAM.toLowerCase();
const ALWAYS_UNSIGNABLE_HEADERS = {
    authorization: true,
    "cache-control": true,
    connection: true,
    expect: true,
    from: true,
    "keep-alive": true,
    "max-forwards": true,
    pragma: true,
    referer: true,
    te: true,
    trailer: true,
    "transfer-encoding": true,
    upgrade: true,
    "user-agent": true,
    "x-amzn-trace-id": true,
};
const PROXY_HEADER_PATTERN = /^proxy-/;
const SEC_HEADER_PATTERN = /^sec-/;
const ALGORITHM_IDENTIFIER = "AWS4-HMAC-SHA256";
const EVENT_ALGORITHM_IDENTIFIER = "AWS4-HMAC-SHA256-PAYLOAD";
const UNSIGNED_PAYLOAD$1 = "UNSIGNED-PAYLOAD";
const MAX_CACHE_SIZE = 50;
const KEY_TYPE_IDENTIFIER = "aws4_request";
const MAX_PRESIGNED_TTL = 60 * 60 * 24 * 7;

const signingKeyCache = {};
const cacheQueue = [];
const createScope = (shortDate, region, service) => `${shortDate}/${region}/${service}/${KEY_TYPE_IDENTIFIER}`;
const getSigningKey = async (sha256Constructor, credentials, shortDate, region, service) => {
    const credsHash = await hmac(sha256Constructor, credentials.secretAccessKey, credentials.accessKeyId);
    const cacheKey = `${shortDate}:${region}:${service}:${toHex(credsHash)}:${credentials.sessionToken}`;
    if (cacheKey in signingKeyCache) {
        return signingKeyCache[cacheKey];
    }
    cacheQueue.push(cacheKey);
    while (cacheQueue.length > MAX_CACHE_SIZE) {
        delete signingKeyCache[cacheQueue.shift()];
    }
    let key = `AWS4${credentials.secretAccessKey}`;
    for (const signable of [shortDate, region, service, KEY_TYPE_IDENTIFIER]) {
        key = await hmac(sha256Constructor, key, signable);
    }
    return (signingKeyCache[cacheKey] = key);
};
const hmac = (ctor, secret, data) => {
    const hash = new ctor(secret);
    hash.update(toUint8Array(data));
    return hash.digest();
};

const getCanonicalHeaders = ({ headers }, unsignableHeaders, signableHeaders) => {
    const canonical = {};
    for (const headerName of Object.keys(headers).sort()) {
        if (headers[headerName] == undefined) {
            continue;
        }
        const canonicalHeaderName = headerName.toLowerCase();
        if (canonicalHeaderName in ALWAYS_UNSIGNABLE_HEADERS ||
            unsignableHeaders?.has(canonicalHeaderName) ||
            PROXY_HEADER_PATTERN.test(canonicalHeaderName) ||
            SEC_HEADER_PATTERN.test(canonicalHeaderName)) {
            if (!signableHeaders || (signableHeaders && !signableHeaders.has(canonicalHeaderName))) {
                continue;
            }
        }
        canonical[canonicalHeaderName] = headers[headerName].trim().replace(/\s+/g, " ");
    }
    return canonical;
};

const getPayloadHash = async ({ headers, body }, hashConstructor) => {
    for (const headerName of Object.keys(headers)) {
        if (headerName.toLowerCase() === SHA256_HEADER$1) {
            return headers[headerName];
        }
    }
    if (body == undefined) {
        return "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855";
    }
    else if (typeof body === "string" || ArrayBuffer.isView(body) || isArrayBuffer(body)) {
        const hashCtor = new hashConstructor();
        hashCtor.update(toUint8Array(body));
        return toHex(await hashCtor.digest());
    }
    return UNSIGNED_PAYLOAD$1;
};

class HeaderFormatter {
    format(headers) {
        const chunks = [];
        for (const headerName of Object.keys(headers)) {
            const bytes = fromUtf8(headerName);
            chunks.push(Uint8Array.from([bytes.byteLength]), bytes, this.formatHeaderValue(headers[headerName]));
        }
        const out = new Uint8Array(chunks.reduce((carry, bytes) => carry + bytes.byteLength, 0));
        let position = 0;
        for (const chunk of chunks) {
            out.set(chunk, position);
            position += chunk.byteLength;
        }
        return out;
    }
    formatHeaderValue(header) {
        switch (header.type) {
            case "boolean":
                return Uint8Array.from([header.value ? 0 : 1]);
            case "byte":
                return Uint8Array.from([2, header.value]);
            case "short":
                const shortView = new DataView(new ArrayBuffer(3));
                shortView.setUint8(0, 3);
                shortView.setInt16(1, header.value, false);
                return new Uint8Array(shortView.buffer);
            case "integer":
                const intView = new DataView(new ArrayBuffer(5));
                intView.setUint8(0, 4);
                intView.setInt32(1, header.value, false);
                return new Uint8Array(intView.buffer);
            case "long":
                const longBytes = new Uint8Array(9);
                longBytes[0] = 5;
                longBytes.set(header.value.bytes, 1);
                return longBytes;
            case "binary":
                const binView = new DataView(new ArrayBuffer(3 + header.value.byteLength));
                binView.setUint8(0, 6);
                binView.setUint16(1, header.value.byteLength, false);
                const binBytes = new Uint8Array(binView.buffer);
                binBytes.set(header.value, 3);
                return binBytes;
            case "string":
                const utf8Bytes = fromUtf8(header.value);
                const strView = new DataView(new ArrayBuffer(3 + utf8Bytes.byteLength));
                strView.setUint8(0, 7);
                strView.setUint16(1, utf8Bytes.byteLength, false);
                const strBytes = new Uint8Array(strView.buffer);
                strBytes.set(utf8Bytes, 3);
                return strBytes;
            case "timestamp":
                const tsBytes = new Uint8Array(9);
                tsBytes[0] = 8;
                tsBytes.set(Int64.fromNumber(header.value.valueOf()).bytes, 1);
                return tsBytes;
            case "uuid":
                if (!UUID_PATTERN.test(header.value)) {
                    throw new Error(`Invalid UUID received: ${header.value}`);
                }
                const uuidBytes = new Uint8Array(17);
                uuidBytes[0] = 9;
                uuidBytes.set(fromHex(header.value.replace(/\-/g, "")), 1);
                return uuidBytes;
        }
    }
}
var HEADER_VALUE_TYPE;
(function (HEADER_VALUE_TYPE) {
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["boolTrue"] = 0] = "boolTrue";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["boolFalse"] = 1] = "boolFalse";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["byte"] = 2] = "byte";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["short"] = 3] = "short";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["integer"] = 4] = "integer";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["long"] = 5] = "long";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["byteArray"] = 6] = "byteArray";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["string"] = 7] = "string";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["timestamp"] = 8] = "timestamp";
    HEADER_VALUE_TYPE[HEADER_VALUE_TYPE["uuid"] = 9] = "uuid";
})(HEADER_VALUE_TYPE || (HEADER_VALUE_TYPE = {}));
const UUID_PATTERN = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;
class Int64 {
    bytes;
    constructor(bytes) {
        this.bytes = bytes;
        if (bytes.byteLength !== 8) {
            throw new Error("Int64 buffers must be exactly 8 bytes");
        }
    }
    static fromNumber(number) {
        if (number > 9_223_372_036_854_775_807 || number < -9223372036854776e3) {
            throw new Error(`${number} is too large (or, if negative, too small) to represent as an Int64`);
        }
        const bytes = new Uint8Array(8);
        for (let i = 7, remaining = Math.abs(Math.round(number)); i > -1 && remaining > 0; i--, remaining /= 256) {
            bytes[i] = remaining;
        }
        if (number < 0) {
            negate(bytes);
        }
        return new Int64(bytes);
    }
    valueOf() {
        const bytes = this.bytes.slice(0);
        const negative = bytes[0] & 0b10000000;
        if (negative) {
            negate(bytes);
        }
        return parseInt(toHex(bytes), 16) * (negative ? -1 : 1);
    }
    toString() {
        return String(this.valueOf());
    }
}
function negate(bytes) {
    for (let i = 0; i < 8; i++) {
        bytes[i] ^= 0xff;
    }
    for (let i = 7; i > -1; i--) {
        bytes[i]++;
        if (bytes[i] !== 0)
            break;
    }
}

const hasHeader = (soughtHeader, headers) => {
    soughtHeader = soughtHeader.toLowerCase();
    for (const headerName of Object.keys(headers)) {
        if (soughtHeader === headerName.toLowerCase()) {
            return true;
        }
    }
    return false;
};

const moveHeadersToQuery = (request, options = {}) => {
    const { headers, query = {} } = HttpRequest.clone(request);
    for (const name of Object.keys(headers)) {
        const lname = name.toLowerCase();
        if ((lname.slice(0, 6) === "x-amz-" && !options.unhoistableHeaders?.has(lname)) ||
            options.hoistableHeaders?.has(lname)) {
            query[name] = headers[name];
            delete headers[name];
        }
    }
    return {
        ...request,
        headers,
        query,
    };
};

const prepareRequest = (request) => {
    request = HttpRequest.clone(request);
    for (const headerName of Object.keys(request.headers)) {
        if (GENERATED_HEADERS.indexOf(headerName.toLowerCase()) > -1) {
            delete request.headers[headerName];
        }
    }
    return request;
};

const getCanonicalQuery = ({ query = {} }) => {
    const keys = [];
    const serialized = {};
    for (const key of Object.keys(query)) {
        if (key.toLowerCase() === SIGNATURE_HEADER) {
            continue;
        }
        const encodedKey = escapeUri(key);
        keys.push(encodedKey);
        const value = query[key];
        if (typeof value === "string") {
            serialized[encodedKey] = `${encodedKey}=${escapeUri(value)}`;
        }
        else if (Array.isArray(value)) {
            serialized[encodedKey] = value
                .slice(0)
                .reduce((encoded, value) => encoded.concat([`${encodedKey}=${escapeUri(value)}`]), [])
                .sort()
                .join("&");
        }
    }
    return keys
        .sort()
        .map((key) => serialized[key])
        .filter((serialized) => serialized)
        .join("&");
};

const iso8601 = (time) => toDate(time)
    .toISOString()
    .replace(/\.\d{3}Z$/, "Z");
const toDate = (time) => {
    if (typeof time === "number") {
        return new Date(time * 1000);
    }
    if (typeof time === "string") {
        if (Number(time)) {
            return new Date(Number(time) * 1000);
        }
        return new Date(time);
    }
    return time;
};

class SignatureV4Base {
    service;
    regionProvider;
    credentialProvider;
    sha256;
    uriEscapePath;
    applyChecksum;
    constructor({ applyChecksum, credentials, region, service, sha256, uriEscapePath = true, }) {
        this.service = service;
        this.sha256 = sha256;
        this.uriEscapePath = uriEscapePath;
        this.applyChecksum = typeof applyChecksum === "boolean" ? applyChecksum : true;
        this.regionProvider = normalizeProvider(region);
        this.credentialProvider = normalizeProvider(credentials);
    }
    createCanonicalRequest(request, canonicalHeaders, payloadHash) {
        const sortedHeaders = Object.keys(canonicalHeaders).sort();
        return `${request.method}
${this.getCanonicalPath(request)}
${getCanonicalQuery(request)}
${sortedHeaders.map((name) => `${name}:${canonicalHeaders[name]}`).join("\n")}

${sortedHeaders.join(";")}
${payloadHash}`;
    }
    async createStringToSign(longDate, credentialScope, canonicalRequest, algorithmIdentifier) {
        const hash = new this.sha256();
        hash.update(toUint8Array(canonicalRequest));
        const hashedRequest = await hash.digest();
        return `${algorithmIdentifier}
${longDate}
${credentialScope}
${toHex(hashedRequest)}`;
    }
    getCanonicalPath({ path }) {
        if (this.uriEscapePath) {
            const normalizedPathSegments = [];
            for (const pathSegment of path.split("/")) {
                if (pathSegment?.length === 0)
                    continue;
                if (pathSegment === ".")
                    continue;
                if (pathSegment === "..") {
                    normalizedPathSegments.pop();
                }
                else {
                    normalizedPathSegments.push(pathSegment);
                }
            }
            const normalizedPath = `${path?.startsWith("/") ? "/" : ""}${normalizedPathSegments.join("/")}${normalizedPathSegments.length > 0 && path?.endsWith("/") ? "/" : ""}`;
            const doubleEncoded = escapeUri(normalizedPath);
            return doubleEncoded.replace(/%2F/g, "/");
        }
        return path;
    }
    validateResolvedCredentials(credentials) {
        if (typeof credentials !== "object" ||
            typeof credentials.accessKeyId !== "string" ||
            typeof credentials.secretAccessKey !== "string") {
            throw new Error("Resolved credential object is not valid");
        }
    }
    formatDate(now) {
        const longDate = iso8601(now).replace(/[\-:]/g, "");
        return {
            longDate,
            shortDate: longDate.slice(0, 8),
        };
    }
    getCanonicalHeaderList(headers) {
        return Object.keys(headers).sort().join(";");
    }
}

class SignatureV4 extends SignatureV4Base {
    headerFormatter = new HeaderFormatter();
    constructor({ applyChecksum, credentials, region, service, sha256, uriEscapePath = true, }) {
        super({
            applyChecksum,
            credentials,
            region,
            service,
            sha256,
            uriEscapePath,
        });
    }
    async presign(originalRequest, options = {}) {
        const { signingDate = new Date(), expiresIn = 3600, unsignableHeaders, unhoistableHeaders, signableHeaders, hoistableHeaders, signingRegion, signingService, } = options;
        const credentials = await this.credentialProvider();
        this.validateResolvedCredentials(credentials);
        const region = signingRegion ?? (await this.regionProvider());
        const { longDate, shortDate } = this.formatDate(signingDate);
        if (expiresIn > MAX_PRESIGNED_TTL) {
            return Promise.reject("Signature version 4 presigned URLs" + " must have an expiration date less than one week in" + " the future");
        }
        const scope = createScope(shortDate, region, signingService ?? this.service);
        const request = moveHeadersToQuery(prepareRequest(originalRequest), { unhoistableHeaders, hoistableHeaders });
        if (credentials.sessionToken) {
            request.query[TOKEN_QUERY_PARAM] = credentials.sessionToken;
        }
        request.query[ALGORITHM_QUERY_PARAM] = ALGORITHM_IDENTIFIER;
        request.query[CREDENTIAL_QUERY_PARAM] = `${credentials.accessKeyId}/${scope}`;
        request.query[AMZ_DATE_QUERY_PARAM] = longDate;
        request.query[EXPIRES_QUERY_PARAM] = expiresIn.toString(10);
        const canonicalHeaders = getCanonicalHeaders(request, unsignableHeaders, signableHeaders);
        request.query[SIGNED_HEADERS_QUERY_PARAM] = this.getCanonicalHeaderList(canonicalHeaders);
        request.query[SIGNATURE_QUERY_PARAM] = await this.getSignature(longDate, scope, this.getSigningKey(credentials, region, shortDate, signingService), this.createCanonicalRequest(request, canonicalHeaders, await getPayloadHash(originalRequest, this.sha256)));
        return request;
    }
    async sign(toSign, options) {
        if (typeof toSign === "string") {
            return this.signString(toSign, options);
        }
        else if (toSign.headers && toSign.payload) {
            return this.signEvent(toSign, options);
        }
        else if (toSign.message) {
            return this.signMessage(toSign, options);
        }
        else {
            return this.signRequest(toSign, options);
        }
    }
    async signEvent({ headers, payload }, { signingDate = new Date(), priorSignature, signingRegion, signingService }) {
        const region = signingRegion ?? (await this.regionProvider());
        const { shortDate, longDate } = this.formatDate(signingDate);
        const scope = createScope(shortDate, region, signingService ?? this.service);
        const hashedPayload = await getPayloadHash({ headers: {}, body: payload }, this.sha256);
        const hash = new this.sha256();
        hash.update(headers);
        const hashedHeaders = toHex(await hash.digest());
        const stringToSign = [
            EVENT_ALGORITHM_IDENTIFIER,
            longDate,
            scope,
            priorSignature,
            hashedHeaders,
            hashedPayload,
        ].join("\n");
        return this.signString(stringToSign, { signingDate, signingRegion: region, signingService });
    }
    async signMessage(signableMessage, { signingDate = new Date(), signingRegion, signingService }) {
        const promise = this.signEvent({
            headers: this.headerFormatter.format(signableMessage.message.headers),
            payload: signableMessage.message.body,
        }, {
            signingDate,
            signingRegion,
            signingService,
            priorSignature: signableMessage.priorSignature,
        });
        return promise.then((signature) => {
            return { message: signableMessage.message, signature };
        });
    }
    async signString(stringToSign, { signingDate = new Date(), signingRegion, signingService } = {}) {
        const credentials = await this.credentialProvider();
        this.validateResolvedCredentials(credentials);
        const region = signingRegion ?? (await this.regionProvider());
        const { shortDate } = this.formatDate(signingDate);
        const hash = new this.sha256(await this.getSigningKey(credentials, region, shortDate, signingService));
        hash.update(toUint8Array(stringToSign));
        return toHex(await hash.digest());
    }
    async signRequest(requestToSign, { signingDate = new Date(), signableHeaders, unsignableHeaders, signingRegion, signingService, } = {}) {
        const credentials = await this.credentialProvider();
        this.validateResolvedCredentials(credentials);
        const region = signingRegion ?? (await this.regionProvider());
        const request = prepareRequest(requestToSign);
        const { longDate, shortDate } = this.formatDate(signingDate);
        const scope = createScope(shortDate, region, signingService ?? this.service);
        request.headers[AMZ_DATE_HEADER] = longDate;
        if (credentials.sessionToken) {
            request.headers[TOKEN_HEADER] = credentials.sessionToken;
        }
        const payloadHash = await getPayloadHash(request, this.sha256);
        if (!hasHeader(SHA256_HEADER$1, request.headers) && this.applyChecksum) {
            request.headers[SHA256_HEADER$1] = payloadHash;
        }
        const canonicalHeaders = getCanonicalHeaders(request, unsignableHeaders, signableHeaders);
        const signature = await this.getSignature(longDate, scope, this.getSigningKey(credentials, region, shortDate, signingService), this.createCanonicalRequest(request, canonicalHeaders, payloadHash));
        request.headers[AUTH_HEADER] =
            `${ALGORITHM_IDENTIFIER} ` +
                `Credential=${credentials.accessKeyId}/${scope}, ` +
                `SignedHeaders=${this.getCanonicalHeaderList(canonicalHeaders)}, ` +
                `Signature=${signature}`;
        return request;
    }
    async getSignature(longDate, credentialScope, keyPromise, canonicalRequest) {
        const stringToSign = await this.createStringToSign(longDate, credentialScope, canonicalRequest, ALGORITHM_IDENTIFIER);
        const hash = new this.sha256(await keyPromise);
        hash.update(toUint8Array(stringToSign));
        return toHex(await hash.digest());
    }
    getSigningKey(credentials, region, shortDate, service) {
        return getSigningKey(this.sha256, credentials, shortDate, region, service || this.service);
    }
}

const SESSION_TOKEN_QUERY_PARAM = "X-Amz-S3session-Token";
const SESSION_TOKEN_HEADER = SESSION_TOKEN_QUERY_PARAM.toLowerCase();

class SignatureV4S3Express extends SignatureV4 {
    async signWithCredentials(requestToSign, credentials, options) {
        const credentialsWithoutSessionToken = getCredentialsWithoutSessionToken(credentials);
        requestToSign.headers[SESSION_TOKEN_HEADER] = credentials.sessionToken;
        const privateAccess = this;
        setSingleOverride(privateAccess, credentialsWithoutSessionToken);
        return privateAccess.signRequest(requestToSign, options ?? {});
    }
    async presignWithCredentials(requestToSign, credentials, options) {
        const credentialsWithoutSessionToken = getCredentialsWithoutSessionToken(credentials);
        delete requestToSign.headers[SESSION_TOKEN_HEADER];
        requestToSign.headers[SESSION_TOKEN_QUERY_PARAM] = credentials.sessionToken;
        requestToSign.query = requestToSign.query ?? {};
        requestToSign.query[SESSION_TOKEN_QUERY_PARAM] = credentials.sessionToken;
        const privateAccess = this;
        setSingleOverride(privateAccess, credentialsWithoutSessionToken);
        return this.presign(requestToSign, options);
    }
}
function getCredentialsWithoutSessionToken(credentials) {
    const credentialsWithoutSessionToken = {
        accessKeyId: credentials.accessKeyId,
        secretAccessKey: credentials.secretAccessKey,
        expiration: credentials.expiration,
    };
    return credentialsWithoutSessionToken;
}
function setSingleOverride(privateAccess, credentialsWithoutSessionToken) {
    const id = setTimeout(() => {
        throw new Error("SignatureV4S3Express credential override was created but not called.");
    }, 10);
    const currentCredentialProvider = privateAccess.credentialProvider;
    const overrideCredentialsProviderOnce = () => {
        clearTimeout(id);
        privateAccess.credentialProvider = currentCredentialProvider;
        return Promise.resolve(credentialsWithoutSessionToken);
    };
    privateAccess.credentialProvider = overrideCredentialsProviderOnce;
}

class SignatureV4MultiRegion {
    sigv4aSigner;
    sigv4Signer;
    signerOptions;
    static sigv4aDependency() {
        return "none";
    }
    constructor(options) {
        this.sigv4Signer = new SignatureV4S3Express(options);
        this.signerOptions = options;
    }
    async sign(requestToSign, options = {}) {
        if (options.signingRegion === "*") {
            return this.getSigv4aSigner().sign(requestToSign, options);
        }
        return this.sigv4Signer.sign(requestToSign, options);
    }
    async signWithCredentials(requestToSign, credentials, options = {}) {
        if (options.signingRegion === "*") {
            this.getSigv4aSigner();
            {
                throw new Error(`signWithCredentials with signingRegion '*' is only supported when using the CRT dependency @aws-sdk/signature-v4-crt. ` +
                    `Please check whether you have installed the "@aws-sdk/signature-v4-crt" package explicitly. ` +
                    `You must also register the package by calling [require("@aws-sdk/signature-v4-crt");] ` +
                    `or an ESM equivalent such as [import "@aws-sdk/signature-v4-crt";]. ` +
                    `For more information please go to https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt`);
            }
        }
        return this.sigv4Signer.signWithCredentials(requestToSign, credentials, options);
    }
    async presign(originalRequest, options = {}) {
        if (options.signingRegion === "*") {
            this.getSigv4aSigner();
            {
                throw new Error(`presign with signingRegion '*' is only supported when using the CRT dependency @aws-sdk/signature-v4-crt. ` +
                    `Please check whether you have installed the "@aws-sdk/signature-v4-crt" package explicitly. ` +
                    `You must also register the package by calling [require("@aws-sdk/signature-v4-crt");] ` +
                    `or an ESM equivalent such as [import "@aws-sdk/signature-v4-crt";]. ` +
                    `For more information please go to https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt`);
            }
        }
        return this.sigv4Signer.presign(originalRequest, options);
    }
    async presignWithCredentials(originalRequest, credentials, options = {}) {
        if (options.signingRegion === "*") {
            throw new Error("Method presignWithCredentials is not supported for [signingRegion=*].");
        }
        return this.sigv4Signer.presignWithCredentials(originalRequest, credentials, options);
    }
    getSigv4aSigner() {
        if (!this.sigv4aSigner) {
            if (this.signerOptions.runtime === "node") {
                {
                    throw new Error("Neither CRT nor JS SigV4a implementation is available. " +
                        "Please load either @aws-sdk/signature-v4-crt or @aws-sdk/signature-v4a. " +
                        "For more information please go to " +
                        "https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt");
                }
            }
            else {
                {
                    throw new Error("JS SigV4a implementation is not available or not a valid constructor. " +
                        "Please check whether you have installed the @aws-sdk/signature-v4a package explicitly. The CRT implementation is not available for browsers. " +
                        "You must also register the package by calling [require('@aws-sdk/signature-v4a');] " +
                        "or an ESM equivalent such as [import '@aws-sdk/signature-v4a';]. " +
                        "For more information please go to " +
                        "https://github.com/aws/aws-sdk-js-v3#using-javascript-non-crt-implementation-of-sigv4a");
                }
            }
        }
        return this.sigv4aSigner;
    }
}

const UNSIGNED_PAYLOAD = "UNSIGNED-PAYLOAD";
const SHA256_HEADER = "X-Amz-Content-Sha256";

class S3RequestPresigner {
    signer;
    constructor(options) {
        const resolvedOptions = {
            service: options.signingName || options.service || "s3",
            uriEscapePath: options.uriEscapePath || false,
            applyChecksum: options.applyChecksum || false,
            ...options,
        };
        this.signer = new SignatureV4MultiRegion(resolvedOptions);
    }
    presign(requestToSign, { unsignableHeaders = new Set(), hoistableHeaders = new Set(), unhoistableHeaders = new Set(), ...options } = {}) {
        this.prepareRequest(requestToSign, {
            unsignableHeaders,
            unhoistableHeaders,
            hoistableHeaders,
        });
        return this.signer.presign(requestToSign, {
            expiresIn: 900,
            unsignableHeaders,
            unhoistableHeaders,
            ...options,
        });
    }
    presignWithCredentials(requestToSign, credentials, { unsignableHeaders = new Set(), hoistableHeaders = new Set(), unhoistableHeaders = new Set(), ...options } = {}) {
        this.prepareRequest(requestToSign, {
            unsignableHeaders,
            unhoistableHeaders,
            hoistableHeaders,
        });
        return this.signer.presignWithCredentials(requestToSign, credentials, {
            expiresIn: 900,
            unsignableHeaders,
            unhoistableHeaders,
            ...options,
        });
    }
    prepareRequest(requestToSign, { unsignableHeaders = new Set(), unhoistableHeaders = new Set(), hoistableHeaders = new Set(), } = {}) {
        unsignableHeaders.add("content-type");
        Object.keys(requestToSign.headers)
            .map((header) => header.toLowerCase())
            .filter((header) => header.startsWith("x-amz-server-side-encryption"))
            .forEach((header) => {
            if (!hoistableHeaders.has(header)) {
                unhoistableHeaders.add(header);
            }
        });
        requestToSign.headers[SHA256_HEADER] = UNSIGNED_PAYLOAD;
        const currentHostHeader = requestToSign.headers.host;
        const port = requestToSign.port;
        const expectedHostHeader = `${requestToSign.hostname}${requestToSign.port != null ? ":" + port : ""}`;
        if (!currentHostHeader || (currentHostHeader === requestToSign.hostname && requestToSign.port != null)) {
            requestToSign.headers.host = expectedHostHeader;
        }
    }
}

const getSignedUrl = async (client, command, options = {}) => {
    let s3Presigner;
    let region;
    if (typeof client.config.endpointProvider === "function") {
        const endpointV2 = await getEndpointFromInstructions(command.input, command.constructor, client.config);
        const authScheme = endpointV2.properties?.authSchemes?.[0];
        if (authScheme?.name === "sigv4a") {
            region = authScheme?.signingRegionSet?.join(",");
        }
        else {
            region = authScheme?.signingRegion;
        }
        s3Presigner = new S3RequestPresigner({
            ...client.config,
            signingName: authScheme?.signingName,
            region: async () => region,
        });
    }
    else {
        s3Presigner = new S3RequestPresigner(client.config);
    }
    const presignInterceptMiddleware = (next, context) => async (args) => {
        const { request } = args;
        if (!HttpRequest.isInstance(request)) {
            throw new Error("Request to be presigned is not an valid HTTP request.");
        }
        delete request.headers["amz-sdk-invocation-id"];
        delete request.headers["amz-sdk-request"];
        delete request.headers["x-amz-user-agent"];
        let presigned;
        const presignerOptions = {
            ...options,
            signingRegion: options.signingRegion ?? context["signing_region"] ?? region,
            signingService: options.signingService ?? context["signing_service"],
        };
        if (context.s3ExpressIdentity) {
            presigned = await s3Presigner.presignWithCredentials(request, context.s3ExpressIdentity, presignerOptions);
        }
        else {
            presigned = await s3Presigner.presign(request, presignerOptions);
        }
        return {
            response: {},
            output: {
                $metadata: { httpStatusCode: 200 },
                presigned,
            },
        };
    };
    const middlewareName = "presignInterceptMiddleware";
    const clientStack = client.middlewareStack.clone();
    clientStack.addRelativeTo(presignInterceptMiddleware, {
        name: middlewareName,
        relation: "before",
        toMiddleware: "awsAuthMiddleware",
        override: true,
    });
    const handler = command.resolveMiddleware(clientStack, client.config, {});
    const { output } = await handler({ input: command.input });
    const { presigned } = output;
    return formatUrl(presigned);
};

function createS3Handler(config = {}) {
  const {
    s3Client,
    bucket,
    prefix = "",
    streaming = true,
    signedUrlExpiry = 300,
    maxAge = 0,
    cacheControl,
    contentDisposition = "inline",
    etag = true,
    cors = false
  } = config;
  if (!s3Client) {
    throw new Error('S3 static handler requires "s3Client"');
  }
  if (!bucket) {
    throw new Error('S3 static handler requires "bucket" name');
  }
  return async (c) => {
    try {
      let requestPath = c.req.path.replace(/^\//, "");
      const key = prefix ? `${prefix}${requestPath}` : requestPath;
      if (key.includes("..") || key.includes("//")) {
        return c.json({ success: false, error: { message: "Forbidden" } }, 403);
      }
      let metadata;
      try {
        const headCommand = new HeadObjectCommand({ Bucket: bucket, Key: key });
        metadata = await s3Client.send(headCommand);
      } catch (err) {
        if (err.name === "NotFound" || err.$metadata?.httpStatusCode === 404) {
          return c.json({ success: false, error: { message: "Not Found" } }, 404);
        }
        throw err;
      }
      if (etag && metadata.ETag) {
        const ifNoneMatch = c.req.header("If-None-Match");
        if (ifNoneMatch === metadata.ETag) {
          const headers2 = {
            "ETag": metadata.ETag,
            "Cache-Control": cacheControl || (maxAge > 0 ? `public, max-age=${Math.floor(maxAge / 1e3)}` : "no-cache")
          };
          if (cors) {
            headers2["Access-Control-Allow-Origin"] = "*";
            headers2["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
          }
          return c.body(null, 304, headers2);
        }
      }
      if (!streaming) {
        const getCommand2 = new GetObjectCommand({ Bucket: bucket, Key: key });
        const signedUrl = await getSignedUrl(s3Client, getCommand2, { expiresIn: signedUrlExpiry });
        return c.redirect(signedUrl, 302);
      }
      const contentType = metadata.ContentType || getContentType(key);
      const headers = {
        "Content-Type": contentType,
        "Content-Length": metadata.ContentLength?.toString() || "0",
        "Last-Modified": metadata.LastModified?.toUTCString() || (/* @__PURE__ */ new Date()).toUTCString()
      };
      if (metadata.ETag && etag) {
        headers["ETag"] = metadata.ETag;
      }
      if (cacheControl) {
        headers["Cache-Control"] = cacheControl;
      } else if (maxAge > 0) {
        headers["Cache-Control"] = `public, max-age=${Math.floor(maxAge / 1e3)}`;
      } else {
        headers["Cache-Control"] = "no-cache";
      }
      if (contentDisposition) {
        const filename = key.split("/").pop();
        headers["Content-Disposition"] = `${contentDisposition}; filename="${filename}"`;
      }
      if (cors) {
        headers["Access-Control-Allow-Origin"] = "*";
        headers["Access-Control-Allow-Methods"] = "GET, HEAD, OPTIONS";
      }
      const rangeHeader = c.req.header("Range");
      let getCommand;
      if (rangeHeader) {
        const parts = rangeHeader.replace(/bytes=/, "").split("-");
        const start = parseInt(parts[0], 10);
        const end = parts[1] ? parseInt(parts[1], 10) : metadata.ContentLength - 1;
        if (start >= metadata.ContentLength || end >= metadata.ContentLength) {
          return c.body(null, 416, {
            "Content-Range": `bytes */${metadata.ContentLength}`
          });
        }
        const range = `bytes=${start}-${end}`;
        getCommand = new GetObjectCommand({ Bucket: bucket, Key: key, Range: range });
        const chunkSize = end - start + 1;
        headers["Content-Range"] = `bytes ${start}-${end}/${metadata.ContentLength}`;
        headers["Content-Length"] = chunkSize.toString();
        headers["Accept-Ranges"] = "bytes";
        const response2 = await s3Client.send(getCommand);
        return c.body(response2.Body, 206, headers);
      }
      if (c.req.method === "HEAD") {
        return c.body(null, 200, headers);
      }
      getCommand = new GetObjectCommand({ Bucket: bucket, Key: key });
      const response = await s3Client.send(getCommand);
      return c.body(response.Body, 200, headers);
    } catch (err) {
      console.error("[Static S3] Error:", err);
      return c.json({ success: false, error: { message: "Internal Server Error" } }, 500);
    }
  };
}
function validateS3Config(config) {
  if (!config.bucket || typeof config.bucket !== "string") {
    throw new Error('S3 static config requires "bucket" name (string)');
  }
  if (config.prefix !== void 0 && typeof config.prefix !== "string") {
    throw new Error('S3 static "prefix" must be a string');
  }
  if (config.streaming !== void 0 && typeof config.streaming !== "boolean") {
    throw new Error('S3 static "streaming" must be a boolean');
  }
  if (config.signedUrlExpiry !== void 0 && typeof config.signedUrlExpiry !== "number") {
    throw new Error('S3 static "signedUrlExpiry" must be a number');
  }
  if (config.maxAge !== void 0 && typeof config.maxAge !== "number") {
    throw new Error('S3 static "maxAge" must be a number');
  }
  if (config.cacheControl !== void 0 && typeof config.cacheControl !== "string") {
    throw new Error('S3 static "cacheControl" must be a string');
  }
  if (config.contentDisposition !== void 0 && typeof config.contentDisposition !== "string") {
    throw new Error('S3 static "contentDisposition" must be a string');
  }
  if (config.etag !== void 0 && typeof config.etag !== "boolean") {
    throw new Error('S3 static "etag" must be a boolean');
  }
  if (config.cors !== void 0 && typeof config.cors !== "boolean") {
    throw new Error('S3 static "cors" must be a boolean');
  }
}

class ApiServer {
  /**
   * Create API server
   * @param {Object} options - Server options
   * @param {number} options.port - Server port
   * @param {string} options.host - Server host
   * @param {Object} options.database - s3db.js database instance
   * @param {Object} options.resources - Resource configuration
   * @param {Array} options.middlewares - Global middlewares
   */
  constructor(options = {}) {
    this.options = {
      port: options.port || 3e3,
      host: options.host || "0.0.0.0",
      database: options.database,
      resources: options.resources || {},
      routes: options.routes || {},
      // Plugin-level custom routes
      middlewares: options.middlewares || [],
      verbose: options.verbose || false,
      auth: options.auth || {},
      static: options.static || [],
      // Static file serving config
      docsEnabled: options.docsEnabled !== false,
      // Enable /docs by default
      docsUI: options.docsUI || "redoc",
      // 'swagger' or 'redoc'
      maxBodySize: options.maxBodySize || 10 * 1024 * 1024,
      // 10MB default
      rootHandler: options.rootHandler,
      // Custom handler for root path, if not provided redirects to /docs
      versionPrefix: options.versionPrefix,
      // Global version prefix config
      apiInfo: {
        title: options.apiTitle || "s3db.js API",
        version: options.apiVersion || "1.0.0",
        description: options.apiDescription || "Auto-generated REST API for s3db.js resources"
      }
    };
    this.app = null;
    this.server = null;
    this.isRunning = false;
    this.openAPISpec = null;
    this.initialized = false;
    this.relationsPlugin = this.options.database?.plugins?.relation || this.options.database?.plugins?.RelationPlugin || null;
  }
  /**
   * Setup all routes
   * @private
   */
  _setupRoutes() {
    this.options.middlewares.forEach((middleware) => {
      this.app.use("*", middleware);
    });
    this.app.use("*", async (c, next) => {
      const method = c.req.method;
      if (["POST", "PUT", "PATCH"].includes(method)) {
        const contentLength = c.req.header("content-length");
        if (contentLength) {
          const size = parseInt(contentLength);
          if (size > this.options.maxBodySize) {
            const response = payloadTooLarge(size, this.options.maxBodySize);
            c.header("Connection", "close");
            return c.json(response, response._status);
          }
        }
      }
      await next();
    });
    this.app.get("/health/live", (c) => {
      const response = success({
        status: "alive",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/ready", (c) => {
      const isReady = this.options.database && this.options.database.connected && Object.keys(this.options.database.resources).length > 0;
      if (!isReady) {
        const response2 = error("Service not ready", {
          status: 503,
          code: "NOT_READY",
          details: {
            database: {
              connected: this.options.database?.connected || false,
              resources: Object.keys(this.options.database?.resources || {}).length
            }
          }
        });
        return c.json(response2, 503);
      }
      const response = success({
        status: "ready",
        database: {
          connected: true,
          resources: Object.keys(this.options.database.resources).length
        },
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health", (c) => {
      const response = success({
        status: "ok",
        uptime: process.uptime(),
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        checks: {
          liveness: "/health/live",
          readiness: "/health/ready"
        }
      });
      return c.json(response);
    });
    this.app.get("/", (c) => {
      if (this.options.rootHandler) {
        return this.options.rootHandler(c);
      }
      return c.redirect("/docs", 302);
    });
    this._setupStaticRoutes();
    if (this.options.docsEnabled) {
      this.app.get("/openapi.json", (c) => {
        if (!this.openAPISpec) {
          this.openAPISpec = this._generateOpenAPISpec();
        }
        return c.json(this.openAPISpec);
      });
      if (this.options.docsUI === "swagger") {
        this.app.get("/docs", this.swaggerUI({
          url: "/openapi.json"
        }));
      } else {
        this.app.get("/docs", (c) => {
          return c.html(`<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${this.options.apiInfo.title} - API Documentation</title>
  <style>
    body {
      margin: 0;
      padding: 0;
    }
  </style>
</head>
<body>
  <redoc spec-url="/openapi.json"></redoc>
  <script src="https://cdn.redoc.ly/redoc/v2.5.1/bundles/redoc.standalone.js"><\/script>
</body>
</html>`);
        });
      }
    }
    this._setupResourceRoutes();
    if (this.options.auth.driver) {
      this._setupAuthRoutes();
    }
    const oidcDriver = this.options.auth?.drivers?.find((d) => d.driver === "oidc");
    if (oidcDriver) {
      this._setupOIDCRoutes(oidcDriver.config);
    }
    if (this.relationsPlugin) {
      this._setupRelationalRoutes();
    }
    this._setupPluginRoutes();
    this.app.onError((err, c) => {
      return errorHandler(err, c);
    });
    this.app.notFound((c) => {
      const response = error("Route not found", {
        status: 404,
        code: "NOT_FOUND",
        details: {
          path: c.req.path,
          method: c.req.method
        }
      });
      return c.json(response, 404);
    });
  }
  /**
   * Setup routes for all resources
   * @private
   */
  _setupResourceRoutes() {
    const { database } = this.options;
    const resources = database.resources;
    const authMiddleware = this._createAuthMiddleware();
    for (const [name, resource] of Object.entries(resources)) {
      if (name.startsWith("plg_")) {
        continue;
      }
      const version = resource.config?.currentVersion || resource.version || "v1";
      let versionPrefixConfig = resource.config?.versionPrefix !== void 0 ? resource.config?.versionPrefix : this.options.versionPrefix !== void 0 ? this.options.versionPrefix : false;
      let prefix = "";
      if (versionPrefixConfig === true) {
        prefix = version;
      } else if (versionPrefixConfig === false) {
        prefix = "";
      } else if (typeof versionPrefixConfig === "string") {
        prefix = versionPrefixConfig;
      }
      const middlewares = [];
      if (authMiddleware) {
        middlewares.push(authMiddleware);
      }
      const resourceApp = createResourceRoutes(resource, version, {
        methods: resource.config?.methods || ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"],
        customMiddleware: middlewares,
        enableValidation: resource.config?.validation !== false,
        versionPrefix: prefix
      }, this.Hono);
      const mountPath = prefix ? `/${prefix}/${name}` : `/${name}`;
      this.app.route(mountPath, resourceApp);
      if (this.options.verbose) {
        console.log(`[API Plugin] Mounted routes for resource '${name}' at ${mountPath}`);
      }
      if (resource.config?.routes) {
        const routeContext = {
          resource,
          database,
          resourceName: name,
          version
        };
        mountCustomRoutes(resourceApp, resource.config.routes, routeContext, this.options.verbose);
      }
    }
  }
  /**
   * Setup authentication routes (when auth drivers are configured)
   * @private
   */
  _setupAuthRoutes() {
    const { database, auth } = this.options;
    const { drivers, resource: resourceName, usernameField, passwordField } = auth;
    const jwtDriver = drivers.find((d) => d.driver === "jwt");
    if (!jwtDriver) {
      return;
    }
    const authResource = database.resources[resourceName];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${resourceName}' not found. Skipping auth routes.`);
      return;
    }
    const driverConfig = jwtDriver.config || {};
    const authConfig = {
      driver: "jwt",
      usernameField,
      passwordField,
      jwtSecret: driverConfig.jwtSecret || driverConfig.secret,
      jwtExpiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d",
      passphrase: driverConfig.passphrase || "secret",
      allowRegistration: driverConfig.allowRegistration !== false
    };
    const authApp = createAuthRoutes(authResource, authConfig);
    this.app.route("/auth", authApp);
    if (this.options.verbose) {
      console.log("[API Plugin] Mounted auth routes (driver: jwt) at /auth");
    }
  }
  /**
   * Setup OIDC routes (when oidc driver is configured)
   * @private
   * @param {Object} config - OIDC driver configuration
   */
  _setupOIDCRoutes(config) {
    const { database, auth } = this.options;
    const authResource = database.resources[auth.resource];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${auth.resource}' not found for OIDC`);
      return;
    }
    const oidcHandler = createOIDCHandler(config, this.app, authResource);
    this.oidcMiddleware = oidcHandler.middleware;
    if (this.options.verbose) {
      console.log("[API Plugin] Mounted OIDC routes:");
      for (const [path, description] of Object.entries(oidcHandler.routes)) {
        console.log(`[API Plugin]   ${path} - ${description}`);
      }
    }
  }
  /**
   * Create authentication middleware based on configured drivers
   * @private
   * @returns {Function|null} Hono middleware or null
   */
  _createAuthMiddleware() {
    const { database, auth } = this.options;
    const { drivers, resource: defaultResourceName, pathAuth } = auth;
    if (!drivers || drivers.length === 0) {
      return null;
    }
    const authResource = database.resources[defaultResourceName];
    if (!authResource) {
      console.error(`[API Plugin] Auth resource '${defaultResourceName}' not found for middleware`);
      return null;
    }
    if (pathAuth) {
      try {
        validatePathAuth(pathAuth);
      } catch (err) {
        console.error(`[API Plugin] Invalid pathAuth configuration: ${err.message}`);
        throw err;
      }
    }
    const extractDriverConfigs = (driverNames) => {
      const configs = {
        jwt: {},
        apiKey: {},
        basic: {},
        oauth2: {}
      };
      for (const driverDef of drivers) {
        const driverName = driverDef.driver;
        const driverConfig = driverDef.config || {};
        if (driverNames && !driverNames.includes(driverName)) {
          continue;
        }
        if (driverName === "oauth2-server" || driverName === "oidc") {
          continue;
        }
        if (driverName === "jwt") {
          configs.jwt = {
            secret: driverConfig.jwtSecret || driverConfig.secret,
            expiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d"
          };
        } else if (driverName === "apiKey") {
          configs.apiKey = {
            headerName: driverConfig.headerName || "X-API-Key"
          };
        } else if (driverName === "basic") {
          configs.basic = {
            realm: driverConfig.realm || "API Access",
            passphrase: driverConfig.passphrase || "secret"
          };
        } else if (driverName === "oauth2") {
          configs.oauth2 = driverConfig;
        }
      }
      return configs;
    };
    if (pathAuth) {
      return async (c, next) => {
        const requestPath = c.req.path;
        const matchedRule = findBestMatch(pathAuth, requestPath);
        if (this.options.verbose) {
          if (matchedRule) {
            console.log(`[API Plugin] Path ${requestPath} matched rule: ${matchedRule.pattern}`);
          } else {
            console.log(`[API Plugin] Path ${requestPath} no pathAuth rule matched (using global auth)`);
          }
        }
        if (!matchedRule) {
          const methods2 = drivers.map((d) => d.driver).filter((d) => d !== "oauth2-server" && d !== "oidc");
          const driverConfigs3 = extractDriverConfigs(null);
          const globalAuth = createAuthMiddleware({
            methods: methods2,
            jwt: driverConfigs3.jwt,
            apiKey: driverConfigs3.apiKey,
            basic: driverConfigs3.basic,
            oauth2: driverConfigs3.oauth2,
            oidc: this.oidcMiddleware || null,
            usersResource: authResource,
            optional: true
          });
          return await globalAuth(c, next);
        }
        if (!matchedRule.required) {
          return await next();
        }
        const ruleMethods = matchedRule.drivers || [];
        const driverConfigs2 = extractDriverConfigs(ruleMethods);
        const ruleAuth = createAuthMiddleware({
          methods: ruleMethods,
          jwt: driverConfigs2.jwt,
          apiKey: driverConfigs2.apiKey,
          basic: driverConfigs2.basic,
          oauth2: driverConfigs2.oauth2,
          oidc: this.oidcMiddleware || null,
          usersResource: authResource,
          optional: false
          // Auth is required for this path
        });
        return await ruleAuth(c, next);
      };
    }
    const methods = [];
    const driverConfigs = {
      jwt: {},
      apiKey: {},
      basic: {},
      oauth2: {}
    };
    for (const driverDef of drivers) {
      const driverName = driverDef.driver;
      const driverConfig = driverDef.config || {};
      if (driverName === "oauth2-server" || driverName === "oidc") {
        continue;
      }
      if (!methods.includes(driverName)) {
        methods.push(driverName);
      }
      if (driverName === "jwt") {
        driverConfigs.jwt = {
          secret: driverConfig.jwtSecret || driverConfig.secret,
          expiresIn: driverConfig.jwtExpiresIn || driverConfig.expiresIn || "7d"
        };
      } else if (driverName === "apiKey") {
        driverConfigs.apiKey = {
          headerName: driverConfig.headerName || "X-API-Key"
        };
      } else if (driverName === "basic") {
        driverConfigs.basic = {
          realm: driverConfig.realm || "API Access",
          passphrase: driverConfig.passphrase || "secret"
        };
      } else if (driverName === "oauth2") {
        driverConfigs.oauth2 = driverConfig;
      }
    }
    return createAuthMiddleware({
      methods,
      jwt: driverConfigs.jwt,
      apiKey: driverConfigs.apiKey,
      basic: driverConfigs.basic,
      oauth2: driverConfigs.oauth2,
      oidc: this.oidcMiddleware || null,
      // OIDC middleware (if configured)
      usersResource: authResource,
      optional: true
      // Let guards handle authorization
    });
  }
  /**
   * Setup relational routes (when RelationPlugin is active)
   * @private
   */
  _setupRelationalRoutes() {
    if (!this.relationsPlugin || !this.relationsPlugin.relations) {
      return;
    }
    const { database } = this.options;
    const relations = this.relationsPlugin.relations;
    if (this.options.verbose) {
      console.log("[API Plugin] Setting up relational routes...");
    }
    for (const [resourceName, relationsDef] of Object.entries(relations)) {
      const resource = database.resources[resourceName];
      if (!resource) {
        if (this.options.verbose) {
          console.warn(`[API Plugin] Resource '${resourceName}' not found for relational routes`);
        }
        continue;
      }
      if (resourceName.startsWith("plg_") && !this.options.resources[resourceName]) {
        continue;
      }
      const version = resource.config?.currentVersion || resource.version || "v1";
      for (const [relationName, relationConfig] of Object.entries(relationsDef)) {
        if (relationConfig.type === "belongsTo") {
          continue;
        }
        const resourceConfig = this.options.resources[resourceName];
        const exposeRelation = resourceConfig?.relations?.[relationName]?.expose !== false;
        if (!exposeRelation) {
          continue;
        }
        const relationalApp = createRelationalRoutes(
          resource,
          relationName,
          relationConfig,
          version,
          this.Hono
        );
        this.app.route(`/${version}/${resourceName}/:id/${relationName}`, relationalApp);
        if (this.options.verbose) {
          console.log(
            `[API Plugin] Mounted relational route: /${version}/${resourceName}/:id/${relationName} (${relationConfig.type} -> ${relationConfig.resource})`
          );
        }
      }
    }
  }
  /**
   * Setup plugin-level custom routes
   * @private
   */
  _setupPluginRoutes() {
    const { routes, database } = this.options;
    if (!routes || Object.keys(routes).length === 0) {
      return;
    }
    const context = {
      database,
      plugins: database?.plugins || {}
    };
    mountCustomRoutes(this.app, routes, context, this.options.verbose);
    if (this.options.verbose) {
      console.log(`[API Plugin] Mounted ${Object.keys(routes).length} plugin-level custom routes`);
    }
  }
  /**
   * Setup static file serving routes
   * @private
   */
  _setupStaticRoutes() {
    const { static: staticConfigs, database } = this.options;
    if (!staticConfigs || staticConfigs.length === 0) {
      return;
    }
    if (!Array.isArray(staticConfigs)) {
      throw new Error("Static config must be an array of mount points");
    }
    for (const [index, config] of staticConfigs.entries()) {
      try {
        if (!config.driver) {
          throw new Error(`static[${index}]: "driver" is required (filesystem or s3)`);
        }
        if (!config.path) {
          throw new Error(`static[${index}]: "path" is required (mount path)`);
        }
        if (!config.path.startsWith("/")) {
          throw new Error(`static[${index}]: "path" must start with / (got: ${config.path})`);
        }
        const driverConfig = config.config || {};
        let handler;
        if (config.driver === "filesystem") {
          validateFilesystemConfig({ ...config, ...driverConfig });
          handler = createFilesystemHandler({
            root: config.root,
            index: driverConfig.index,
            fallback: driverConfig.fallback,
            maxAge: driverConfig.maxAge,
            dotfiles: driverConfig.dotfiles,
            etag: driverConfig.etag,
            cors: driverConfig.cors
          });
        } else if (config.driver === "s3") {
          validateS3Config({ ...config, ...driverConfig });
          const s3Client = database?.client?.client;
          if (!s3Client) {
            throw new Error(`static[${index}]: S3 driver requires database with S3 client`);
          }
          handler = createS3Handler({
            s3Client,
            bucket: config.bucket,
            prefix: config.prefix,
            streaming: driverConfig.streaming,
            signedUrlExpiry: driverConfig.signedUrlExpiry,
            maxAge: driverConfig.maxAge,
            cacheControl: driverConfig.cacheControl,
            contentDisposition: driverConfig.contentDisposition,
            etag: driverConfig.etag,
            cors: driverConfig.cors
          });
        } else {
          throw new Error(
            `static[${index}]: invalid driver "${config.driver}". Valid drivers: filesystem, s3`
          );
        }
        const mountPath = config.path === "/" ? "/*" : `${config.path}/*`;
        this.app.get(mountPath, handler);
        this.app.head(mountPath, handler);
        if (this.options.verbose) {
          console.log(
            `[API Plugin] Mounted static files (${config.driver}) at ${config.path}` + (config.driver === "filesystem" ? ` -> ${config.root}` : ` -> s3://${config.bucket}/${config.prefix || ""}`)
          );
        }
      } catch (err) {
        console.error(`[API Plugin] Failed to setup static files for index ${index}:`, err.message);
        throw err;
      }
    }
  }
  /**
   * Start the server
   * @returns {Promise<void>}
   */
  async start() {
    if (this.isRunning) {
      console.warn("[API Plugin] Server is already running");
      return;
    }
    if (!this.initialized) {
      const { Hono } = await import('hono');
      const { serve } = await import('@hono/node-server');
      const { swaggerUI } = await import('@hono/swagger-ui');
      this.Hono = Hono;
      this.serve = serve;
      this.swaggerUI = swaggerUI;
      this.app = new Hono();
      this._setupRoutes();
      this.initialized = true;
    }
    const { port, host } = this.options;
    return new Promise((resolve, reject) => {
      try {
        this.server = this.serve({
          fetch: this.app.fetch,
          port,
          hostname: host
        }, (info) => {
          this.isRunning = true;
          console.log(`[API Plugin] Server listening on http://${info.address}:${info.port}`);
          resolve();
        });
      } catch (err) {
        reject(err);
      }
    });
  }
  /**
   * Stop the server
   * @returns {Promise<void>}
   */
  async stop() {
    if (!this.isRunning) {
      console.warn("[API Plugin] Server is not running");
      return;
    }
    if (this.server && typeof this.server.close === "function") {
      await new Promise((resolve) => {
        this.server.close(() => {
          this.isRunning = false;
          console.log("[API Plugin] Server stopped");
          resolve();
        });
      });
    } else {
      this.isRunning = false;
      console.log("[API Plugin] Server stopped");
    }
  }
  /**
   * Get server info
   * @returns {Object} Server information
   */
  getInfo() {
    return {
      isRunning: this.isRunning,
      port: this.options.port,
      host: this.options.host,
      resources: Object.keys(this.options.database.resources).length
    };
  }
  /**
   * Get Hono app instance
   * @returns {Hono} Hono app
   */
  getApp() {
    return this.app;
  }
  /**
   * Generate OpenAPI specification
   * @private
   * @returns {Object} OpenAPI spec
   */
  _generateOpenAPISpec() {
    const { port, host, database, resources, auth, apiInfo } = this.options;
    return generateOpenAPISpec(database, {
      title: apiInfo.title,
      version: apiInfo.version,
      description: apiInfo.description,
      serverUrl: `http://${host === "0.0.0.0" ? "localhost" : host}:${port}`,
      auth,
      resources
    });
  }
}

class ApiPlugin extends Plugin {
  /**
   * Create API Plugin instance
   * @param {Object} options - Plugin configuration
   */
  constructor(options = {}) {
    super(options);
    this.config = {
      // Server configuration
      port: options.port || 3e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      // Version prefix configuration (global default)
      // Can be: true (use resource version), false (no prefix - DEFAULT), or string (custom prefix like 'api/v1')
      versionPrefix: options.versionPrefix !== void 0 ? options.versionPrefix : false,
      docs: {
        enabled: options.docs?.enabled !== false && options.docsEnabled !== false,
        // Enable by default
        ui: options.docs?.ui || "redoc",
        // 'swagger' or 'redoc' (redoc is prettier!)
        title: options.docs?.title || options.apiTitle || "s3db.js API",
        version: options.docs?.version || options.apiVersion || "1.0.0",
        description: options.docs?.description || options.apiDescription || "Auto-generated REST API for s3db.js resources"
      },
      // Authentication configuration (multiple drivers)
      auth: options.auth ? {
        // Array of authentication drivers (OR logic - any driver can authenticate)
        drivers: options.auth.drivers || [],
        // Global settings
        resource: options.auth.resource || "users",
        usernameField: options.auth.usernameField || "email",
        passwordField: options.auth.passwordField || "password"
      } : {
        drivers: [],
        resource: "users",
        usernameField: "email",
        passwordField: "password"
      },
      // Custom routes (plugin-level)
      routes: options.routes || {},
      // CORS configuration
      cors: {
        enabled: options.cors?.enabled || false,
        origin: options.cors?.origin || "*",
        methods: options.cors?.methods || ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
        allowedHeaders: options.cors?.allowedHeaders || ["Content-Type", "Authorization", "X-API-Key"],
        exposedHeaders: options.cors?.exposedHeaders || ["X-Total-Count", "X-Page-Count"],
        credentials: options.cors?.credentials !== false,
        maxAge: options.cors?.maxAge || 86400
      },
      // Rate limiting configuration
      rateLimit: {
        enabled: options.rateLimit?.enabled || false,
        windowMs: options.rateLimit?.windowMs || 6e4,
        // 1 minute
        maxRequests: options.rateLimit?.maxRequests || 100,
        keyGenerator: options.rateLimit?.keyGenerator || null
      },
      // Logging configuration
      logging: {
        enabled: options.logging?.enabled || false,
        format: options.logging?.format || ":method :path :status :response-time ms",
        verbose: options.logging?.verbose || false
      },
      // Compression configuration
      compression: {
        enabled: options.compression?.enabled || false,
        threshold: options.compression?.threshold || 1024,
        // 1KB
        level: options.compression?.level || 6
      },
      // Validation configuration
      validation: {
        enabled: options.validation?.enabled !== false,
        validateOnInsert: options.validation?.validateOnInsert !== false,
        validateOnUpdate: options.validation?.validateOnUpdate !== false,
        returnValidationErrors: options.validation?.returnValidationErrors !== false
      },
      // Security Headers (Helmet-like configuration)
      security: {
        enabled: options.security?.enabled !== false,
        // Enabled by default
        // Content Security Policy (CSP)
        contentSecurityPolicy: options.security?.contentSecurityPolicy !== false ? {
          enabled: options.security?.contentSecurityPolicy?.enabled !== false,
          directives: options.security?.contentSecurityPolicy?.directives || options.csp?.directives || {
            "default-src": ["'self'"],
            "script-src": ["'self'", "'unsafe-inline'", "https://cdn.redoc.ly/redoc/v2.5.1/"],
            "style-src": ["'self'", "'unsafe-inline'", "https://cdn.redoc.ly/redoc/v2.5.1/", "https://fonts.googleapis.com"],
            "font-src": ["'self'", "https://fonts.gstatic.com"],
            "img-src": ["'self'", "data:", "https:"],
            "connect-src": ["'self'"]
          },
          reportOnly: options.security?.contentSecurityPolicy?.reportOnly || options.csp?.reportOnly || false,
          reportUri: options.security?.contentSecurityPolicy?.reportUri || options.csp?.reportUri || null
        } : false,
        // X-Frame-Options (clickjacking protection)
        frameguard: options.security?.frameguard !== false ? {
          action: options.security?.frameguard?.action || "deny"
          // 'deny' or 'sameorigin'
        } : false,
        // X-Content-Type-Options (MIME sniffing protection)
        noSniff: options.security?.noSniff !== false,
        // Enabled by default
        // Strict-Transport-Security (HSTS - force HTTPS)
        hsts: options.security?.hsts !== false ? {
          maxAge: options.security?.hsts?.maxAge || 15552e3,
          // 180 days (Helmet default)
          includeSubDomains: options.security?.hsts?.includeSubDomains !== false,
          preload: options.security?.hsts?.preload || false
        } : false,
        // Referrer-Policy (privacy)
        referrerPolicy: options.security?.referrerPolicy !== false ? {
          policy: options.security?.referrerPolicy?.policy || "no-referrer"
        } : false,
        // X-DNS-Prefetch-Control (DNS leak protection)
        dnsPrefetchControl: options.security?.dnsPrefetchControl !== false ? {
          allow: options.security?.dnsPrefetchControl?.allow || false
        } : false,
        // X-Download-Options (IE8+ download security)
        ieNoOpen: options.security?.ieNoOpen !== false,
        // Enabled by default
        // X-Permitted-Cross-Domain-Policies (Flash/PDF security)
        permittedCrossDomainPolicies: options.security?.permittedCrossDomainPolicies !== false ? {
          policy: options.security?.permittedCrossDomainPolicies?.policy || "none"
        } : false,
        // X-XSS-Protection (legacy XSS filter)
        xssFilter: options.security?.xssFilter !== false ? {
          mode: options.security?.xssFilter?.mode || "block"
        } : false,
        // Permissions-Policy (modern feature policy)
        permissionsPolicy: options.security?.permissionsPolicy !== false ? {
          features: options.security?.permissionsPolicy?.features || {
            geolocation: [],
            microphone: [],
            camera: [],
            payment: [],
            usb: [],
            magnetometer: [],
            gyroscope: [],
            accelerometer: []
          }
        } : false
      },
      // Legacy CSP config (backward compatibility)
      csp: {
        enabled: options.csp?.enabled || false,
        directives: options.csp?.directives || {},
        reportOnly: options.csp?.reportOnly || false,
        reportUri: options.csp?.reportUri || null
      },
      // Custom global middlewares
      middlewares: options.middlewares || []
    };
    this.server = null;
    this.usersResource = null;
  }
  /**
   * Validate plugin dependencies
   * @private
   */
  async _validateDependencies() {
    await requirePluginDependency("api-plugin", {
      throwOnError: true,
      checkVersions: true
    });
  }
  /**
   * Install plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[API Plugin] Installing...");
    }
    try {
      await this._validateDependencies();
    } catch (err) {
      console.error("[API Plugin] Dependency validation failed:", err.message);
      throw err;
    }
    const authEnabled = this.config.auth.drivers.length > 0;
    if (authEnabled) {
      await this._createUsersResource();
    }
    await this._setupMiddlewares();
    if (this.config.verbose) {
      console.log("[API Plugin] Installed successfully");
    }
  }
  /**
   * Create users resource for authentication
   * @private
   */
  async _createUsersResource() {
    const [ok, err, resource] = await tryFn(
      () => this.database.createResource({
        name: "plg_users",
        attributes: {
          id: "string|required",
          username: "string|required|minlength:3",
          email: "string|required|email",
          // Required to support email-based auth
          password: "secret|required|minlength:8",
          apiKey: "string|optional",
          jwtSecret: "string|optional",
          role: "string|default:user",
          scopes: "array|items:string|optional",
          // Authorization scopes (e.g., ['read:users', 'write:cars'])
          active: "boolean|default:true",
          createdAt: "string|optional",
          lastLoginAt: "string|optional",
          metadata: "json|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "ApiPlugin"
      })
    );
    if (ok) {
      this.usersResource = resource;
      if (this.config.verbose) {
        console.log("[API Plugin] Created plg_users resource for authentication");
      }
    } else if (this.database.resources.plg_users) {
      this.usersResource = this.database.resources.plg_users;
      if (this.config.verbose) {
        console.log("[API Plugin] Using existing plg_users resource");
      }
    } else {
      throw err;
    }
  }
  /**
   * Setup middlewares
   * @private
   */
  async _setupMiddlewares() {
    const middlewares = [];
    middlewares.push(async (c, next) => {
      c.set("requestId", idGenerator());
      c.set("verbose", this.config.verbose);
      await next();
    });
    if (this.config.security.enabled) {
      const securityMiddleware = await this._createSecurityMiddleware();
      middlewares.push(securityMiddleware);
    }
    if (this.config.cors.enabled) {
      const corsMiddleware = await this._createCorsMiddleware();
      middlewares.push(corsMiddleware);
    }
    if (this.config.csp.enabled && !this.config.security.contentSecurityPolicy) {
      const cspMiddleware = await this._createCSPMiddleware();
      middlewares.push(cspMiddleware);
    }
    if (this.config.rateLimit.enabled) {
      const rateLimitMiddleware = await this._createRateLimitMiddleware();
      middlewares.push(rateLimitMiddleware);
    }
    if (this.config.logging.enabled) {
      const loggingMiddleware = await this._createLoggingMiddleware();
      middlewares.push(loggingMiddleware);
    }
    if (this.config.compression.enabled) {
      const compressionMiddleware = await this._createCompressionMiddleware();
      middlewares.push(compressionMiddleware);
    }
    middlewares.push(...this.config.middlewares);
    this.compiledMiddlewares = middlewares;
  }
  /**
   * Create CORS middleware
   * @private
   *
   * Handles Cross-Origin Resource Sharing (CORS) headers and preflight requests.
   * Supports wildcard origins, credential-based requests, and OPTIONS preflight.
   */
  async _createCorsMiddleware() {
    return async (c, next) => {
      const { origin, methods, allowedHeaders, exposedHeaders, credentials, maxAge } = this.config.cors;
      c.header("Access-Control-Allow-Origin", origin);
      c.header("Access-Control-Allow-Methods", methods.join(", "));
      c.header("Access-Control-Allow-Headers", allowedHeaders.join(", "));
      c.header("Access-Control-Expose-Headers", exposedHeaders.join(", "));
      if (credentials) {
        c.header("Access-Control-Allow-Credentials", "true");
      }
      c.header("Access-Control-Max-Age", maxAge.toString());
      if (c.req.method === "OPTIONS") {
        return c.body(null, 204);
      }
      await next();
    };
  }
  /**
   * Create CSP middleware
   * @private
   */
  async _createCSPMiddleware() {
    return async (c, next) => {
      const { directives, reportOnly, reportUri } = this.config.csp;
      const cspParts = [];
      for (const [directive, values] of Object.entries(directives)) {
        if (Array.isArray(values) && values.length > 0) {
          cspParts.push(`${directive} ${values.join(" ")}`);
        } else if (typeof values === "string") {
          cspParts.push(`${directive} ${values}`);
        }
      }
      if (reportUri) {
        cspParts.push(`report-uri ${reportUri}`);
      }
      const cspValue = cspParts.join("; ");
      const headerName = reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
      c.header(headerName, cspValue);
      await next();
    };
  }
  /**
   * Create rate limiting middleware
   * @private
   *
   * Implements sliding window rate limiting with configurable window size and max requests.
   * Returns 429 status code with Retry-After header when limit is exceeded.
   * Uses IP address or custom key generator to track request counts.
   */
  async _createRateLimitMiddleware() {
    const requests = /* @__PURE__ */ new Map();
    const { windowMs, maxRequests, keyGenerator } = this.config.rateLimit;
    return async (c, next) => {
      const key = keyGenerator ? keyGenerator(c) : c.req.header("x-forwarded-for") || c.req.header("cf-connecting-ip") || "unknown";
      if (!requests.has(key)) {
        requests.set(key, { count: 0, resetAt: Date.now() + windowMs });
      }
      const record = requests.get(key);
      if (Date.now() > record.resetAt) {
        record.count = 0;
        record.resetAt = Date.now() + windowMs;
      }
      if (record.count >= maxRequests) {
        const retryAfter = Math.ceil((record.resetAt - Date.now()) / 1e3);
        c.header("Retry-After", retryAfter.toString());
        c.header("X-RateLimit-Limit", maxRequests.toString());
        c.header("X-RateLimit-Remaining", "0");
        c.header("X-RateLimit-Reset", record.resetAt.toString());
        return c.json({
          success: false,
          error: {
            message: "Rate limit exceeded",
            code: "RATE_LIMIT_EXCEEDED",
            details: { retryAfter }
          }
        }, 429);
      }
      record.count++;
      c.header("X-RateLimit-Limit", maxRequests.toString());
      c.header("X-RateLimit-Remaining", (maxRequests - record.count).toString());
      c.header("X-RateLimit-Reset", record.resetAt.toString());
      await next();
    };
  }
  /**
   * Create logging middleware with customizable format
   * @private
   *
   * Supported tokens:
   * - :method - HTTP method (GET, POST, etc)
   * - :path - Request path
   * - :status - HTTP status code
   * - :response-time - Response time in milliseconds
   * - :user - Username or 'anonymous'
   * - :requestId - Request ID (UUID)
   *
   * Example format: ':method :path :status :response-time ms - :user'
   * Output: 'GET /api/v1/cars 200 45ms - john'
   */
  async _createLoggingMiddleware() {
    const { format } = this.config.logging;
    return async (c, next) => {
      const start = Date.now();
      const method = c.req.method;
      const path = c.req.path;
      const requestId = c.get("requestId");
      await next();
      const duration = Date.now() - start;
      const status = c.res.status;
      const user = c.get("user")?.username || c.get("user")?.email || "anonymous";
      let logMessage = format.replace(":method", method).replace(":path", path).replace(":status", status).replace(":response-time", duration).replace(":user", user).replace(":requestId", requestId);
      console.log(`[API Plugin] ${logMessage}`);
    };
  }
  /**
   * Create compression middleware (using Node.js zlib)
   * @private
   */
  async _createCompressionMiddleware() {
    const { gzip, brotliCompress } = await import('zlib');
    const { promisify } = await import('util');
    const gzipAsync = promisify(gzip);
    const brotliAsync = promisify(brotliCompress);
    const { threshold, level } = this.config.compression;
    const skipContentTypes = [
      "image/",
      "video/",
      "audio/",
      "application/zip",
      "application/gzip",
      "application/x-gzip",
      "application/x-bzip2"
    ];
    return async (c, next) => {
      await next();
      if (!c.res || !c.res.body) {
        return;
      }
      if (c.res.headers.has("content-encoding")) {
        return;
      }
      const contentType = c.res.headers.get("content-type") || "";
      if (skipContentTypes.some((type) => contentType.startsWith(type))) {
        return;
      }
      const acceptEncoding = c.req.header("accept-encoding") || "";
      const supportsBrotli = acceptEncoding.includes("br");
      const supportsGzip = acceptEncoding.includes("gzip");
      if (!supportsBrotli && !supportsGzip) {
        return;
      }
      let body;
      try {
        const text = await c.res.text();
        body = Buffer.from(text, "utf-8");
      } catch (err) {
        return;
      }
      if (body.length < threshold) {
        return;
      }
      let compressed;
      let encoding;
      try {
        if (supportsBrotli) {
          compressed = await brotliAsync(body);
          encoding = "br";
        } else {
          compressed = await gzipAsync(body, { level });
          encoding = "gzip";
        }
        if (compressed.length >= body.length) {
          return;
        }
        const headers = new Headers(c.res.headers);
        headers.set("Content-Encoding", encoding);
        headers.set("Content-Length", compressed.length.toString());
        headers.set("Vary", "Accept-Encoding");
        c.res = new Response(compressed, {
          status: c.res.status,
          statusText: c.res.statusText,
          headers
        });
      } catch (err) {
        if (this.config.verbose) {
          console.error("[API Plugin] Compression error:", err.message);
        }
      }
    };
  }
  /**
   * Create security headers middleware (Helmet-like)
   * @private
   */
  async _createSecurityMiddleware() {
    const { security } = this.config;
    return async (c, next) => {
      if (security.noSniff) {
        c.header("X-Content-Type-Options", "nosniff");
      }
      if (security.frameguard) {
        const action = security.frameguard.action.toUpperCase();
        if (action === "DENY") {
          c.header("X-Frame-Options", "DENY");
        } else if (action === "SAMEORIGIN") {
          c.header("X-Frame-Options", "SAMEORIGIN");
        }
      }
      if (security.hsts) {
        const parts = [`max-age=${security.hsts.maxAge}`];
        if (security.hsts.includeSubDomains) {
          parts.push("includeSubDomains");
        }
        if (security.hsts.preload) {
          parts.push("preload");
        }
        c.header("Strict-Transport-Security", parts.join("; "));
      }
      if (security.referrerPolicy) {
        c.header("Referrer-Policy", security.referrerPolicy.policy);
      }
      if (security.dnsPrefetchControl) {
        const value = security.dnsPrefetchControl.allow ? "on" : "off";
        c.header("X-DNS-Prefetch-Control", value);
      }
      if (security.ieNoOpen) {
        c.header("X-Download-Options", "noopen");
      }
      if (security.permittedCrossDomainPolicies) {
        c.header("X-Permitted-Cross-Domain-Policies", security.permittedCrossDomainPolicies.policy);
      }
      if (security.xssFilter) {
        const mode = security.xssFilter.mode;
        c.header("X-XSS-Protection", mode === "block" ? "1; mode=block" : "0");
      }
      if (security.permissionsPolicy && security.permissionsPolicy.features) {
        const features = security.permissionsPolicy.features;
        const policies = [];
        for (const [feature, allowList] of Object.entries(features)) {
          if (Array.isArray(allowList)) {
            const value = allowList.length === 0 ? `${feature}=()` : `${feature}=(${allowList.join(" ")})`;
            policies.push(value);
          }
        }
        if (policies.length > 0) {
          c.header("Permissions-Policy", policies.join(", "));
        }
      }
      const cspConfig = this.config.csp.enabled ? this.config.csp : security.contentSecurityPolicy;
      if (cspConfig && cspConfig.enabled !== false && cspConfig.directives) {
        const cspParts = [];
        for (const [directive, values] of Object.entries(cspConfig.directives)) {
          if (Array.isArray(values) && values.length > 0) {
            cspParts.push(`${directive} ${values.join(" ")}`);
          } else if (typeof values === "string") {
            cspParts.push(`${directive} ${values}`);
          }
        }
        if (cspConfig.reportUri) {
          cspParts.push(`report-uri ${cspConfig.reportUri}`);
        }
        if (cspParts.length > 0) {
          const cspValue = cspParts.join("; ");
          const headerName = cspConfig.reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
          c.header(headerName, cspValue);
        }
      }
      await next();
    };
  }
  /**
   * Start plugin
   */
  async onStart() {
    if (this.config.verbose) {
      console.log("[API Plugin] Starting server...");
    }
    this.server = new ApiServer({
      port: this.config.port,
      host: this.config.host,
      database: this.database,
      resources: this.config.resources,
      routes: this.config.routes,
      middlewares: this.compiledMiddlewares,
      verbose: this.config.verbose,
      auth: this.config.auth,
      docsEnabled: this.config.docs.enabled,
      docsUI: this.config.docs.ui,
      apiTitle: this.config.docs.title,
      apiVersion: this.config.docs.version,
      apiDescription: this.config.docs.description
    });
    await this.server.start();
    this.emit("plugin.started", {
      port: this.config.port,
      host: this.config.host
    });
  }
  /**
   * Stop plugin
   */
  async onStop() {
    if (this.config.verbose) {
      console.log("[API Plugin] Stopping server...");
    }
    if (this.server) {
      await this.server.stop();
      this.server = null;
    }
    this.emit("plugin.stopped");
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    const { purgeData = false } = options;
    await this.onStop();
    if (purgeData && this.usersResource) {
      const [ok] = await tryFn(() => this.database.deleteResource("plg_users"));
      if (ok && this.config.verbose) {
        console.log("[API Plugin] Deleted plg_users resource");
      }
    }
    if (this.config.verbose) {
      console.log("[API Plugin] Uninstalled successfully");
    }
  }
  /**
   * Get server information
   * @returns {Object} Server info
   */
  getServerInfo() {
    return this.server ? this.server.getInfo() : { isRunning: false };
  }
  /**
   * Get Hono app instance (for advanced usage)
   * @returns {Hono|null} Hono app
   */
  getApp() {
    return this.server ? this.server.getApp() : null;
  }
}

function generateKeyPair(modulusLength = 2048) {
  const { publicKey, privateKey } = generateKeyPairSync("rsa", {
    modulusLength,
    publicKeyEncoding: {
      type: "spki",
      format: "pem"
    },
    privateKeyEncoding: {
      type: "pkcs8",
      format: "pem"
    }
  });
  const kid = createHash("sha256").update(publicKey).digest("hex").substring(0, 16);
  return {
    publicKey,
    privateKey,
    kid,
    algorithm: "RS256",
    use: "sig",
    createdAt: (/* @__PURE__ */ new Date()).toISOString()
  };
}
function pemToJwk(publicKeyPem, kid) {
  const keyObject = createPublicKey(publicKeyPem);
  const exported = keyObject.export({ format: "jwk" });
  return {
    kty: "RSA",
    use: "sig",
    alg: "RS256",
    kid,
    n: exported.n,
    // modulus
    e: exported.e
    // exponent
  };
}
function createRS256Token(payload, privateKey, kid, expiresIn = "15m") {
  const match = expiresIn.match(/^(\d+)([smhd])$/);
  if (!match) {
    throw new Error("Invalid expiresIn format. Use: 60s, 30m, 24h, 7d");
  }
  const [, value, unit] = match;
  const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
  const expiresInSeconds = parseInt(value) * multipliers[unit];
  const header = {
    alg: "RS256",
    typ: "JWT",
    kid
  };
  const now = Math.floor(Date.now() / 1e3);
  const data = {
    ...payload,
    iat: now,
    exp: now + expiresInSeconds
  };
  const encodedHeader = Buffer.from(JSON.stringify(header)).toString("base64url");
  const encodedPayload = Buffer.from(JSON.stringify(data)).toString("base64url");
  const sign = createSign("RSA-SHA256");
  sign.update(`${encodedHeader}.${encodedPayload}`);
  sign.end();
  const signature = sign.sign(privateKey, "base64url");
  return `${encodedHeader}.${encodedPayload}.${signature}`;
}
function verifyRS256Token(token, publicKey) {
  try {
    const parts = token.split(".");
    if (parts.length !== 3) {
      return null;
    }
    const [encodedHeader, encodedPayload, signature] = parts;
    const verify = createVerify("RSA-SHA256");
    verify.update(`${encodedHeader}.${encodedPayload}`);
    verify.end();
    const isValid = verify.verify(publicKey, signature, "base64url");
    if (!isValid) {
      return null;
    }
    const header = JSON.parse(Buffer.from(encodedHeader, "base64url").toString());
    const payload = JSON.parse(Buffer.from(encodedPayload, "base64url").toString());
    if (header.alg !== "RS256") {
      return null;
    }
    const now = Math.floor(Date.now() / 1e3);
    if (payload.exp && payload.exp < now) {
      return null;
    }
    return {
      header,
      payload
    };
  } catch (err) {
    return null;
  }
}
function getKidFromToken(token) {
  try {
    const [encodedHeader] = token.split(".");
    const header = JSON.parse(Buffer.from(encodedHeader, "base64url").toString());
    return header.kid || null;
  } catch (err) {
    return null;
  }
}
class KeyManager {
  constructor(keyResource) {
    this.keyResource = keyResource;
    this.currentKey = null;
    this.keys = /* @__PURE__ */ new Map();
  }
  /**
   * Initialize key manager - load or generate keys
   */
  async initialize() {
    const existingKeys = await this.keyResource.list();
    if (existingKeys.length > 0) {
      for (const keyRecord of existingKeys) {
        this.keys.set(keyRecord.kid, {
          publicKey: keyRecord.publicKey,
          privateKey: keyRecord.privateKey,
          kid: keyRecord.kid,
          createdAt: keyRecord.createdAt,
          active: keyRecord.active
        });
        if (keyRecord.active) {
          this.currentKey = keyRecord;
        }
      }
    }
    if (!this.currentKey) {
      await this.rotateKey();
    }
  }
  /**
   * Rotate keys - generate new key pair
   */
  async rotateKey() {
    const keyPair = generateKeyPair();
    const oldKeys = await this.keyResource.query({ active: true });
    for (const oldKey of oldKeys) {
      await this.keyResource.update(oldKey.id, { active: false });
    }
    const keyRecord = await this.keyResource.insert({
      kid: keyPair.kid,
      publicKey: keyPair.publicKey,
      privateKey: keyPair.privateKey,
      algorithm: keyPair.algorithm,
      use: keyPair.use,
      active: true,
      createdAt: keyPair.createdAt
    });
    this.currentKey = keyRecord;
    this.keys.set(keyRecord.kid, keyRecord);
    return keyRecord;
  }
  /**
   * Get current active key
   */
  getCurrentKey() {
    return this.currentKey;
  }
  /**
   * Get key by kid
   */
  getKey(kid) {
    return this.keys.get(kid);
  }
  /**
   * Get all public keys in JWKS format
   */
  async getJWKS() {
    const keys = Array.from(this.keys.values()).map((key) => ({
      kty: "RSA",
      use: "sig",
      alg: "RS256",
      kid: key.kid,
      ...pemToJwk(key.publicKey, key.kid)
    }));
    return { keys };
  }
  /**
   * Create JWT with current active key
   */
  createToken(payload, expiresIn = "15m") {
    if (!this.currentKey) {
      throw new Error("No active key available");
    }
    return createRS256Token(
      payload,
      this.currentKey.privateKey,
      this.currentKey.kid,
      expiresIn
    );
  }
  /**
   * Verify JWT token
   */
  async verifyToken(token) {
    const kid = getKidFromToken(token);
    if (!kid) {
      return null;
    }
    const key = this.getKey(kid);
    if (!key) {
      return null;
    }
    return verifyRS256Token(token, key.publicKey);
  }
}

var rsaKeys = /*#__PURE__*/Object.freeze({
  __proto__: null,
  KeyManager: KeyManager,
  createRS256Token: createRS256Token,
  generateKeyPair: generateKeyPair,
  getKidFromToken: getKidFromToken,
  pemToJwk: pemToJwk,
  verifyRS256Token: verifyRS256Token
});

function generateDiscoveryDocument(options = {}) {
  const {
    issuer,
    grantTypes = ["authorization_code", "client_credentials", "refresh_token"],
    responseTypes = ["code", "token", "id_token", "code id_token", "code token", "id_token token", "code id_token token"],
    scopes = ["openid", "profile", "email", "offline_access"]
  } = options;
  if (!issuer) {
    throw new Error("Issuer URL is required for OIDC discovery");
  }
  const baseUrl = issuer.replace(/\/$/, "");
  return {
    issuer: baseUrl,
    authorization_endpoint: `${baseUrl}/auth/authorize`,
    token_endpoint: `${baseUrl}/auth/token`,
    userinfo_endpoint: `${baseUrl}/auth/userinfo`,
    jwks_uri: `${baseUrl}/.well-known/jwks.json`,
    registration_endpoint: `${baseUrl}/auth/register`,
    introspection_endpoint: `${baseUrl}/auth/introspect`,
    revocation_endpoint: `${baseUrl}/auth/revoke`,
    end_session_endpoint: `${baseUrl}/auth/logout`,
    // Supported features
    scopes_supported: scopes,
    response_types_supported: responseTypes,
    response_modes_supported: ["query", "fragment", "form_post"],
    grant_types_supported: grantTypes,
    subject_types_supported: ["public"],
    id_token_signing_alg_values_supported: ["RS256"],
    token_endpoint_auth_methods_supported: [
      "client_secret_basic",
      "client_secret_post",
      "none"
    ],
    // Claims
    claims_supported: [
      "sub",
      "iss",
      "aud",
      "exp",
      "iat",
      "auth_time",
      "nonce",
      "email",
      "email_verified",
      "name",
      "given_name",
      "family_name",
      "picture",
      "locale"
    ],
    // Code challenge methods (PKCE)
    code_challenge_methods_supported: ["plain", "S256"],
    // UI locales
    ui_locales_supported: ["en", "pt-BR"],
    // Service documentation
    service_documentation: `${baseUrl}/docs`,
    // Additional metadata
    claim_types_supported: ["normal"],
    claims_parameter_supported: false,
    request_parameter_supported: false,
    request_uri_parameter_supported: false,
    require_request_uri_registration: false,
    // Discovery document version
    version: "1.0"
  };
}
function validateClaims(payload, options = {}) {
  const {
    issuer,
    audience,
    clockTolerance = 60
  } = options;
  const now = Math.floor(Date.now() / 1e3);
  if (!payload.sub) {
    return { valid: false, error: "Missing required claim: sub" };
  }
  if (!payload.iat) {
    return { valid: false, error: "Missing required claim: iat" };
  }
  if (!payload.exp) {
    return { valid: false, error: "Missing required claim: exp" };
  }
  if (issuer && payload.iss !== issuer) {
    return {
      valid: false,
      error: `Invalid issuer. Expected: ${issuer}, Got: ${payload.iss}`
    };
  }
  if (audience) {
    const audiences = Array.isArray(payload.aud) ? payload.aud : [payload.aud];
    if (!audiences.includes(audience)) {
      return {
        valid: false,
        error: `Invalid audience. Expected: ${audience}, Got: ${audiences.join(", ")}`
      };
    }
  }
  if (payload.exp < now - clockTolerance) {
    return { valid: false, error: "Token has expired" };
  }
  if (payload.nbf && payload.nbf > now + clockTolerance) {
    return { valid: false, error: "Token not yet valid (nbf)" };
  }
  if (payload.iat > now + clockTolerance) {
    return { valid: false, error: "Token issued in the future" };
  }
  return { valid: true, error: null };
}
function extractUserClaims(user, scopes = []) {
  const claims = {
    sub: user.id
    // Subject - user ID
  };
  if (scopes.includes("email") && user.email) {
    claims.email = user.email;
    claims.email_verified = user.emailVerified || false;
  }
  if (scopes.includes("profile")) {
    if (user.name) claims.name = user.name;
    if (user.givenName) claims.given_name = user.givenName;
    if (user.familyName) claims.family_name = user.familyName;
    if (user.picture) claims.picture = user.picture;
    if (user.locale) claims.locale = user.locale;
    if (user.zoneinfo) claims.zoneinfo = user.zoneinfo;
    if (user.birthdate) claims.birthdate = user.birthdate;
    if (user.gender) claims.gender = user.gender;
  }
  return claims;
}
function parseScopes(scopeString) {
  if (!scopeString || typeof scopeString !== "string") {
    return [];
  }
  return scopeString.trim().split(/\s+/).filter((s) => s.length > 0);
}
function validateScopes(requestedScopes, supportedScopes) {
  if (!Array.isArray(requestedScopes)) {
    requestedScopes = parseScopes(requestedScopes);
  }
  const invalidScopes = requestedScopes.filter((scope) => !supportedScopes.includes(scope));
  if (invalidScopes.length > 0) {
    return {
      valid: false,
      error: `Unsupported scopes: ${invalidScopes.join(", ")}`,
      scopes: []
    };
  }
  return {
    valid: true,
    error: null,
    scopes: requestedScopes
  };
}
function generateAuthCode(length = 32) {
  const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~";
  let code = "";
  for (let i = 0; i < length; i++) {
    code += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return code;
}
function generateClientId() {
  return crypto$1.randomUUID();
}
function generateClientSecret(length = 64) {
  return crypto$1.randomBytes(length / 2).toString("hex");
}

class OAuth2Server {
  constructor(options = {}) {
    const {
      issuer,
      keyResource,
      userResource,
      clientResource,
      authCodeResource,
      supportedScopes = ["openid", "profile", "email", "offline_access"],
      supportedGrantTypes = ["authorization_code", "client_credentials", "refresh_token"],
      supportedResponseTypes = ["code", "token", "id_token"],
      accessTokenExpiry = "15m",
      idTokenExpiry = "15m",
      refreshTokenExpiry = "7d",
      authCodeExpiry = "10m"
    } = options;
    if (!issuer) {
      throw new Error("Issuer URL is required for OAuth2Server");
    }
    if (!keyResource) {
      throw new Error("keyResource is required for OAuth2Server");
    }
    if (!userResource) {
      throw new Error("userResource is required for OAuth2Server");
    }
    this.issuer = issuer.replace(/\/$/, "");
    this.keyResource = keyResource;
    this.userResource = userResource;
    this.clientResource = clientResource;
    this.authCodeResource = authCodeResource;
    this.supportedScopes = supportedScopes;
    this.supportedGrantTypes = supportedGrantTypes;
    this.supportedResponseTypes = supportedResponseTypes;
    this.accessTokenExpiry = accessTokenExpiry;
    this.idTokenExpiry = idTokenExpiry;
    this.refreshTokenExpiry = refreshTokenExpiry;
    this.authCodeExpiry = authCodeExpiry;
    this.keyManager = new KeyManager(keyResource);
  }
  /**
   * Initialize OAuth2 server - load keys
   */
  async initialize() {
    await this.keyManager.initialize();
  }
  /**
   * OIDC Discovery endpoint handler
   * GET /.well-known/openid-configuration
   */
  async discoveryHandler(req, res) {
    try {
      const document = generateDiscoveryDocument({
        issuer: this.issuer,
        grantTypes: this.supportedGrantTypes,
        responseTypes: this.supportedResponseTypes,
        scopes: this.supportedScopes
      });
      res.status(200).json(document);
    } catch (error) {
      res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * JWKS endpoint handler
   * GET /.well-known/jwks.json
   */
  async jwksHandler(req, res) {
    try {
      const jwks = await this.keyManager.getJWKS();
      res.status(200).json(jwks);
    } catch (error) {
      res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token endpoint handler
   * POST /auth/token
   *
   * Supports:
   * - client_credentials grant
   * - authorization_code grant (if authCodeResource provided)
   * - refresh_token grant (if authCodeResource provided)
   */
  async tokenHandler(req, res) {
    try {
      const { grant_type, scope, client_id, client_secret } = req.body;
      if (!grant_type) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "grant_type is required"
        });
      }
      if (!this.supportedGrantTypes.includes(grant_type)) {
        return res.status(400).json({
          error: "unsupported_grant_type",
          error_description: `Grant type ${grant_type} is not supported`
        });
      }
      if (!client_id) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "client_id is required"
        });
      }
      if (this.clientResource) {
        const client = await this.authenticateClient(client_id, client_secret);
        if (!client) {
          return res.status(401).json({
            error: "invalid_client",
            error_description: "Client authentication failed"
          });
        }
      }
      switch (grant_type) {
        case "client_credentials":
          return await this.handleClientCredentials(req, res, { client_id, scope });
        case "authorization_code":
          return await this.handleAuthorizationCode(req, res);
        case "refresh_token":
          return await this.handleRefreshToken(req, res);
        default:
          return res.status(400).json({
            error: "unsupported_grant_type",
            error_description: `Grant type ${grant_type} is not supported`
          });
      }
    } catch (error) {
      res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Client Credentials flow handler
   */
  async handleClientCredentials(req, res, { client_id, scope }) {
    const scopes = parseScopes(scope);
    const scopeValidation = validateScopes(scopes, this.supportedScopes);
    if (!scopeValidation.valid) {
      return res.status(400).json({
        error: "invalid_scope",
        error_description: scopeValidation.error
      });
    }
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: client_id,
      aud: this.issuer,
      scope: scopeValidation.scopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    return res.status(200).json({
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry),
      scope: scopeValidation.scopes.join(" ")
    });
  }
  /**
   * Authorization Code flow handler
   */
  async handleAuthorizationCode(req, res) {
    if (!this.authCodeResource) {
      return res.status(400).json({
        error: "unsupported_grant_type",
        error_description: "Authorization code flow requires authCodeResource"
      });
    }
    const { code, redirect_uri, code_verifier } = req.body;
    if (!code) {
      return res.status(400).json({
        error: "invalid_request",
        error_description: "code is required"
      });
    }
    const authCodes = await this.authCodeResource.query({ code });
    if (authCodes.length === 0) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Invalid authorization code"
      });
    }
    const authCode = authCodes[0];
    const now = Math.floor(Date.now() / 1e3);
    if (authCode.expiresAt < now) {
      await this.authCodeResource.remove(authCode.id);
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Authorization code has expired"
      });
    }
    if (authCode.redirectUri !== redirect_uri) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "redirect_uri mismatch"
      });
    }
    if (authCode.codeChallenge) {
      if (!code_verifier) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "code_verifier is required"
        });
      }
      const isValid = await this.validatePKCE(
        code_verifier,
        authCode.codeChallenge,
        authCode.codeChallengeMethod
      );
      if (!isValid) {
        return res.status(400).json({
          error: "invalid_grant",
          error_description: "Invalid code_verifier"
        });
      }
    }
    const user = await this.userResource.get(authCode.userId);
    if (!user) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "User not found"
      });
    }
    const scopes = parseScopes(authCode.scope);
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: user.id,
      aud: authCode.audience || this.issuer,
      scope: scopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    const response = {
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry)
    };
    if (scopes.includes("openid")) {
      const userClaims = extractUserClaims(user, scopes);
      const idToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: authCode.clientId,
        nonce: authCode.nonce,
        ...userClaims
      }, this.idTokenExpiry);
      response.id_token = idToken;
    }
    if (scopes.includes("offline_access")) {
      const refreshToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: this.issuer,
        scope: scopes.join(" "),
        token_type: "refresh_token"
      }, this.refreshTokenExpiry);
      response.refresh_token = refreshToken;
    }
    await this.authCodeResource.remove(authCode.id);
    return res.status(200).json(response);
  }
  /**
   * Refresh Token flow handler
   */
  async handleRefreshToken(req, res) {
    const { refresh_token, scope } = req.body;
    if (!refresh_token) {
      return res.status(400).json({
        error: "invalid_request",
        error_description: "refresh_token is required"
      });
    }
    const verified = await this.keyManager.verifyToken(refresh_token);
    if (!verified) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Invalid refresh token"
      });
    }
    const { payload } = verified;
    if (payload.token_type !== "refresh_token") {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "Token is not a refresh token"
      });
    }
    const claimValidation = validateClaims(payload, {
      issuer: this.issuer,
      clockTolerance: 60
    });
    if (!claimValidation.valid) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: claimValidation.error
      });
    }
    const requestedScopes = scope ? parseScopes(scope) : parseScopes(payload.scope);
    const originalScopes = parseScopes(payload.scope);
    const invalidScopes = requestedScopes.filter((s) => !originalScopes.includes(s));
    if (invalidScopes.length > 0) {
      return res.status(400).json({
        error: "invalid_scope",
        error_description: `Cannot request scopes not in original grant: ${invalidScopes.join(", ")}`
      });
    }
    const user = await this.userResource.get(payload.sub);
    if (!user) {
      return res.status(400).json({
        error: "invalid_grant",
        error_description: "User not found"
      });
    }
    const accessToken = this.keyManager.createToken({
      iss: this.issuer,
      sub: user.id,
      aud: payload.aud,
      scope: requestedScopes.join(" "),
      token_type: "access_token"
    }, this.accessTokenExpiry);
    const response = {
      access_token: accessToken,
      token_type: "Bearer",
      expires_in: this.parseExpiryToSeconds(this.accessTokenExpiry)
    };
    if (requestedScopes.includes("openid")) {
      const userClaims = extractUserClaims(user, requestedScopes);
      const idToken = this.keyManager.createToken({
        iss: this.issuer,
        sub: user.id,
        aud: payload.aud,
        ...userClaims
      }, this.idTokenExpiry);
      response.id_token = idToken;
    }
    return res.status(200).json(response);
  }
  /**
   * UserInfo endpoint handler
   * GET /auth/userinfo
   */
  async userinfoHandler(req, res) {
    try {
      const authHeader = req.headers.authorization;
      if (!authHeader || !authHeader.startsWith("Bearer ")) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: "Missing or invalid Authorization header"
        });
      }
      const token = authHeader.substring(7);
      const verified = await this.keyManager.verifyToken(token);
      if (!verified) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: "Invalid access token"
        });
      }
      const { payload } = verified;
      const claimValidation = validateClaims(payload, {
        issuer: this.issuer,
        clockTolerance: 60
      });
      if (!claimValidation.valid) {
        return res.status(401).json({
          error: "invalid_token",
          error_description: claimValidation.error
        });
      }
      const user = await this.userResource.get(payload.sub);
      if (!user) {
        return res.status(404).json({
          error: "not_found",
          error_description: "User not found"
        });
      }
      const scopes = parseScopes(payload.scope);
      const userClaims = extractUserClaims(user, scopes);
      return res.status(200).json({
        sub: user.id,
        ...userClaims
      });
    } catch (error) {
      res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token Introspection endpoint handler (RFC 7662)
   * POST /auth/introspect
   */
  async introspectHandler(req, res) {
    try {
      const { token, token_type_hint } = req.body;
      if (!token) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "token is required"
        });
      }
      const verified = await this.keyManager.verifyToken(token);
      if (!verified) {
        return res.status(200).json({ active: false });
      }
      const { payload } = verified;
      const claimValidation = validateClaims(payload, {
        issuer: this.issuer,
        clockTolerance: 60
      });
      if (!claimValidation.valid) {
        return res.status(200).json({ active: false });
      }
      return res.status(200).json({
        active: true,
        scope: payload.scope,
        client_id: payload.aud,
        username: payload.sub,
        token_type: payload.token_type || "access_token",
        exp: payload.exp,
        iat: payload.iat,
        sub: payload.sub,
        iss: payload.iss,
        aud: payload.aud
      });
    } catch (error) {
      res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Authenticate client with credentials
   */
  async authenticateClient(clientId, clientSecret) {
    if (!this.clientResource) {
      return null;
    }
    try {
      const clients = await this.clientResource.query({ clientId });
      if (clients.length === 0) {
        return null;
      }
      const client = clients[0];
      if (client.clientSecret !== clientSecret) {
        return null;
      }
      return client;
    } catch (error) {
      return null;
    }
  }
  /**
   * Validate PKCE code verifier
   */
  async validatePKCE(codeVerifier, codeChallenge, codeChallengeMethod = "plain") {
    if (codeChallengeMethod === "plain") {
      return codeVerifier === codeChallenge;
    }
    if (codeChallengeMethod === "S256") {
      const crypto = await import('crypto');
      const hash = crypto.createHash("sha256").update(codeVerifier).digest("base64url");
      return hash === codeChallenge;
    }
    return false;
  }
  /**
   * Parse expiry string to seconds
   */
  parseExpiryToSeconds(expiresIn) {
    const match = expiresIn.match(/^(\d+)([smhd])$/);
    if (!match) {
      throw new Error("Invalid expiresIn format");
    }
    const [, value, unit] = match;
    const multipliers = { s: 1, m: 60, h: 3600, d: 86400 };
    return parseInt(value) * multipliers[unit];
  }
  /**
   * Authorization endpoint handler (GET /oauth/authorize)
   * Implements OAuth2 authorization code flow
   *
   * Query params:
   * - response_type: 'code' (required)
   * - client_id: Client identifier (required)
   * - redirect_uri: Callback URL (required)
   * - scope: Requested scopes (optional)
   * - state: CSRF protection (recommended)
   * - code_challenge: PKCE challenge (optional)
   * - code_challenge_method: PKCE method (optional, default: plain)
   */
  async authorizeHandler(req, res) {
    try {
      const {
        response_type,
        client_id,
        redirect_uri,
        scope,
        state,
        code_challenge,
        code_challenge_method = "plain"
      } = req.query || {};
      if (!response_type || !client_id || !redirect_uri) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "response_type, client_id, and redirect_uri are required"
        });
      }
      if (!this.supportedResponseTypes.includes(response_type)) {
        return res.status(400).json({
          error: "unsupported_response_type",
          error_description: `Response type ${response_type} is not supported`
        });
      }
      if (this.clientResource) {
        const clients = await this.clientResource.query({ clientId: client_id });
        if (clients.length === 0) {
          return res.status(400).json({
            error: "invalid_client",
            error_description: "Client not found"
          });
        }
        const client = clients[0];
        if (!client.redirectUris.includes(redirect_uri)) {
          return res.status(400).json({
            error: "invalid_request",
            error_description: "Invalid redirect_uri"
          });
        }
        if (scope) {
          const requestedScopes = scope.split(" ");
          const invalidScopes = requestedScopes.filter(
            (s) => !client.allowedScopes.includes(s)
          );
          if (invalidScopes.length > 0) {
            return res.status(400).json({
              error: "invalid_scope",
              error_description: `Invalid scopes: ${invalidScopes.join(", ")}`
            });
          }
        }
      }
      const html = `
<!DOCTYPE html>
<html>
<head>
  <title>Authorization - ${this.issuer}</title>
  <style>
    body { font-family: system-ui; max-width: 400px; margin: 100px auto; padding: 20px; }
    form { background: #f5f5f5; padding: 20px; border-radius: 8px; }
    input { width: 100%; padding: 10px; margin: 10px 0; box-sizing: border-box; }
    button { width: 100%; padding: 12px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
    button:hover { background: #0056b3; }
    .info { background: #e7f3ff; padding: 10px; border-radius: 4px; margin-bottom: 20px; }
  </style>
</head>
<body>
  <div class="info">
    <strong>Application requesting access:</strong><br>
    Client ID: ${client_id}<br>
    Scopes: ${scope || "none"}<br>
    Redirect: ${redirect_uri}
  </div>
  <form method="POST" action="/oauth/authorize">
    <input type="hidden" name="response_type" value="${response_type}">
    <input type="hidden" name="client_id" value="${client_id}">
    <input type="hidden" name="redirect_uri" value="${redirect_uri}">
    <input type="hidden" name="scope" value="${scope || ""}">
    <input type="hidden" name="state" value="${state || ""}">
    <input type="hidden" name="code_challenge" value="${code_challenge || ""}">
    <input type="hidden" name="code_challenge_method" value="${code_challenge_method}">

    <input type="email" name="username" placeholder="Email" required>
    <input type="password" name="password" placeholder="Password" required>
    <button type="submit">Authorize</button>
  </form>
</body>
</html>`;
      return res.status(200).header("Content-Type", "text/html").send(html);
    } catch (error) {
      console.error("[OAuth2Server] Authorization error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Authorization endpoint handler (POST /oauth/authorize)
   * Processes user authentication and generates authorization code
   */
  async authorizePostHandler(req, res) {
    try {
      const {
        response_type,
        client_id,
        redirect_uri,
        scope,
        state,
        code_challenge,
        code_challenge_method = "plain",
        username,
        password
      } = req.body || {};
      const users = await this.userResource.query({ email: username });
      if (users.length === 0) {
        return res.status(401).json({
          error: "access_denied",
          error_description: "Invalid credentials"
        });
      }
      const user = users[0];
      if (user.password !== password) {
        return res.status(401).json({
          error: "access_denied",
          error_description: "Invalid credentials"
        });
      }
      const code = generateAuthCode();
      const expiresAt = new Date(Date.now() + this.parseExpiryToSeconds(this.authCodeExpiry) * 1e3).toISOString();
      if (this.authCodeResource) {
        await this.authCodeResource.insert({
          code,
          clientId: client_id,
          userId: user.id,
          redirectUri: redirect_uri,
          scope: scope || "",
          expiresAt,
          used: false,
          codeChallenge: code_challenge || null,
          codeChallengeMethod: code_challenge_method
        });
      }
      const url = new URL(redirect_uri);
      url.searchParams.set("code", code);
      if (state) {
        url.searchParams.set("state", state);
      }
      return res.redirect(url.toString());
    } catch (error) {
      console.error("[OAuth2Server] Authorization POST error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Client Registration endpoint handler (POST /oauth/register)
   * Implements RFC 7591 - OAuth 2.0 Dynamic Client Registration
   *
   * Request body:
   * - redirect_uris: Array of redirect URIs (required)
   * - token_endpoint_auth_method: 'client_secret_basic' | 'client_secret_post'
   * - grant_types: Array of grant types (optional)
   * - response_types: Array of response types (optional)
   * - client_name: Human-readable name (optional)
   * - client_uri: URL of client homepage (optional)
   * - logo_uri: URL of client logo (optional)
   * - scope: Space-separated scopes (optional)
   * - contacts: Array of contact emails (optional)
   * - tos_uri: Terms of service URL (optional)
   * - policy_uri: Privacy policy URL (optional)
   */
  async registerClientHandler(req, res) {
    try {
      const {
        redirect_uris,
        token_endpoint_auth_method = "client_secret_basic",
        grant_types,
        response_types,
        client_name,
        client_uri,
        logo_uri,
        scope,
        contacts,
        tos_uri,
        policy_uri
      } = req.body || {};
      if (!redirect_uris || !Array.isArray(redirect_uris) || redirect_uris.length === 0) {
        return res.status(400).json({
          error: "invalid_redirect_uri",
          error_description: "redirect_uris is required and must be a non-empty array"
        });
      }
      for (const uri of redirect_uris) {
        try {
          new URL(uri);
        } catch {
          return res.status(400).json({
            error: "invalid_redirect_uri",
            error_description: `Invalid redirect URI: ${uri}`
          });
        }
      }
      const clientId = generateClientId();
      const clientSecret = generateClientSecret();
      const clientData = {
        clientId,
        clientSecret,
        name: client_name || `Client ${clientId}`,
        redirectUris: redirect_uris,
        allowedScopes: scope ? scope.split(" ") : this.supportedScopes,
        grantTypes: grant_types || ["authorization_code", "refresh_token"],
        responseTypes: response_types || ["code"],
        tokenEndpointAuthMethod: token_endpoint_auth_method,
        active: true
      };
      if (client_uri) clientData.clientUri = client_uri;
      if (logo_uri) clientData.logoUri = logo_uri;
      if (contacts) clientData.contacts = contacts;
      if (tos_uri) clientData.tosUri = tos_uri;
      if (policy_uri) clientData.policyUri = policy_uri;
      if (!this.clientResource) {
        return res.status(500).json({
          error: "server_error",
          error_description: "Client registration not available"
        });
      }
      const client = await this.clientResource.insert(clientData);
      return res.status(201).json({
        client_id: clientId,
        client_secret: clientSecret,
        client_id_issued_at: Math.floor(Date.now() / 1e3),
        client_secret_expires_at: 0,
        // 0 = never expires
        redirect_uris,
        token_endpoint_auth_method,
        grant_types: clientData.grantTypes,
        response_types: clientData.responseTypes,
        client_name: clientData.name,
        client_uri,
        logo_uri,
        scope: clientData.allowedScopes.join(" "),
        contacts,
        tos_uri,
        policy_uri
      });
    } catch (error) {
      console.error("[OAuth2Server] Client registration error:", error);
      return res.status(500).json({
        error: "server_error",
        error_description: error.message
      });
    }
  }
  /**
   * Token Revocation endpoint handler (POST /oauth/revoke)
   * Implements RFC 7009 - OAuth 2.0 Token Revocation
   *
   * Request body:
   * - token: Token to revoke (required)
   * - token_type_hint: 'access_token' | 'refresh_token' (optional)
   */
  async revokeHandler(req, res) {
    try {
      const { token, token_type_hint } = req.body || {};
      if (!token) {
        return res.status(400).json({
          error: "invalid_request",
          error_description: "token is required"
        });
      }
      const { publicKey, privateKey, kid } = await this.keyManager.getCurrentKey();
      const { verifyRS256Token } = await Promise.resolve().then(function () { return rsaKeys; });
      const [valid, payload] = verifyRS256Token(token, publicKey);
      if (!valid) {
        return res.status(200).send();
      }
      return res.status(200).send();
    } catch (error) {
      console.error("[OAuth2Server] Token revocation error:", error);
      return res.status(200).send();
    }
  }
  /**
   * Rotate signing keys
   */
  async rotateKeys() {
    return await this.keyManager.rotateKey();
  }
}

class IdentityPlugin extends Plugin {
  /**
   * Create Identity Provider Plugin instance
   * @param {Object} options - Plugin configuration
   */
  constructor(options = {}) {
    super(options);
    this.config = {
      // Server configuration
      port: options.port || 4e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      // OAuth2/OIDC configuration
      issuer: options.issuer || `http://localhost:${options.port || 4e3}`,
      supportedScopes: options.supportedScopes || ["openid", "profile", "email", "offline_access"],
      supportedGrantTypes: options.supportedGrantTypes || ["authorization_code", "client_credentials", "refresh_token"],
      supportedResponseTypes: options.supportedResponseTypes || ["code", "token", "id_token"],
      // Token expiration
      accessTokenExpiry: options.accessTokenExpiry || "15m",
      idTokenExpiry: options.idTokenExpiry || "15m",
      refreshTokenExpiry: options.refreshTokenExpiry || "7d",
      authCodeExpiry: options.authCodeExpiry || "10m",
      // User resource (for authentication)
      userResource: options.userResource || "users",
      // CORS configuration
      cors: {
        enabled: options.cors?.enabled !== false,
        // Enabled by default for identity servers
        origin: options.cors?.origin || "*",
        methods: options.cors?.methods || ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
        allowedHeaders: options.cors?.allowedHeaders || ["Content-Type", "Authorization", "X-API-Key"],
        credentials: options.cors?.credentials !== false,
        maxAge: options.cors?.maxAge || 86400
      },
      // Security headers
      security: {
        enabled: options.security?.enabled !== false
      },
      // Logging
      logging: {
        enabled: options.logging?.enabled || false,
        format: options.logging?.format || ":method :path :status :response-time ms"
      },
      // Session Management
      session: {
        sessionExpiry: options.session?.sessionExpiry || "24h",
        cookieName: options.session?.cookieName || "s3db_session",
        cookiePath: options.session?.cookiePath || "/",
        cookieHttpOnly: options.session?.cookieHttpOnly !== false,
        cookieSecure: options.session?.cookieSecure || false,
        // Set true in production with HTTPS
        cookieSameSite: options.session?.cookieSameSite || "Lax",
        cleanupInterval: options.session?.cleanupInterval || 36e5,
        // 1 hour
        enableCleanup: options.session?.enableCleanup !== false
      },
      // Password Policy
      passwordPolicy: {
        minLength: options.passwordPolicy?.minLength || 8,
        maxLength: options.passwordPolicy?.maxLength || 128,
        requireUppercase: options.passwordPolicy?.requireUppercase !== false,
        requireLowercase: options.passwordPolicy?.requireLowercase !== false,
        requireNumbers: options.passwordPolicy?.requireNumbers !== false,
        requireSymbols: options.passwordPolicy?.requireSymbols || false,
        bcryptRounds: options.passwordPolicy?.bcryptRounds || 10
      },
      // Registration Configuration
      registration: {
        enabled: options.registration?.enabled !== false,
        // Enabled by default
        requireEmailVerification: options.registration?.requireEmailVerification !== false,
        // Required by default
        allowedDomains: options.registration?.allowedDomains || null,
        // null = allow all domains
        blockedDomains: options.registration?.blockedDomains || [],
        // Block specific domains
        customMessage: options.registration?.customMessage || null
        // Custom message when disabled
      },
      // UI Configuration (white-label customization)
      ui: {
        // Branding
        title: options.ui?.title || "S3DB Identity",
        companyName: options.ui?.companyName || "S3DB",
        tagline: options.ui?.tagline || "Secure Identity & Access Management",
        logoUrl: options.ui?.logoUrl || null,
        logo: options.ui?.logo || null,
        // Deprecated, use logoUrl
        favicon: options.ui?.favicon || null,
        // Colors (11 options)
        primaryColor: options.ui?.primaryColor || "#007bff",
        secondaryColor: options.ui?.secondaryColor || "#6c757d",
        successColor: options.ui?.successColor || "#28a745",
        dangerColor: options.ui?.dangerColor || "#dc3545",
        warningColor: options.ui?.warningColor || "#ffc107",
        infoColor: options.ui?.infoColor || "#17a2b8",
        textColor: options.ui?.textColor || "#212529",
        textMuted: options.ui?.textMuted || "#6c757d",
        backgroundColor: options.ui?.backgroundColor || "#ffffff",
        backgroundLight: options.ui?.backgroundLight || "#f8f9fa",
        borderColor: options.ui?.borderColor || "#dee2e6",
        // Typography
        fontFamily: options.ui?.fontFamily || '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif',
        fontSize: options.ui?.fontSize || "16px",
        // Layout
        borderRadius: options.ui?.borderRadius || "0.375rem",
        boxShadow: options.ui?.boxShadow || "0 0.125rem 0.25rem rgba(0, 0, 0, 0.075)",
        // Company Info
        footerText: options.ui?.footerText || null,
        supportEmail: options.ui?.supportEmail || null,
        privacyUrl: options.ui?.privacyUrl || "/privacy",
        termsUrl: options.ui?.termsUrl || "/terms",
        // Social Links
        socialLinks: options.ui?.socialLinks || null,
        // Custom CSS
        customCSS: options.ui?.customCSS || null,
        // Custom Pages (override default pages)
        customPages: options.ui?.customPages || {},
        // Base URL
        baseUrl: options.ui?.baseUrl || `http://localhost:${options.port || 4e3}`
      },
      // Email Configuration (SMTP)
      email: {
        enabled: options.email?.enabled !== false,
        from: options.email?.from || "noreply@s3db.identity",
        replyTo: options.email?.replyTo || null,
        smtp: {
          host: options.email?.smtp?.host || "localhost",
          port: options.email?.smtp?.port || 587,
          secure: options.email?.smtp?.secure || false,
          auth: {
            user: options.email?.smtp?.auth?.user || "",
            pass: options.email?.smtp?.auth?.pass || ""
          },
          tls: {
            rejectUnauthorized: options.email?.smtp?.tls?.rejectUnauthorized !== false
          }
        },
        templates: {
          baseUrl: options.email?.templates?.baseUrl || options.ui?.baseUrl || `http://localhost:${options.port || 4e3}`,
          brandName: options.email?.templates?.brandName || options.ui?.title || "S3DB Identity",
          brandLogo: options.email?.templates?.brandLogo || options.ui?.logo || null,
          brandColor: options.email?.templates?.brandColor || options.ui?.primaryColor || "#007bff",
          supportEmail: options.email?.templates?.supportEmail || options.email?.replyTo || null,
          customFooter: options.email?.templates?.customFooter || null
        }
      },
      // Features (MVP - Phase 1)
      features: {
        // Endpoints (can be disabled individually)
        discovery: options.features?.discovery !== false,
        // GET /.well-known/openid-configuration
        jwks: options.features?.jwks !== false,
        // GET /.well-known/jwks.json
        token: options.features?.token !== false,
        // POST /oauth/token
        authorize: options.features?.authorize !== false,
        // GET/POST /oauth/authorize
        userinfo: options.features?.userinfo !== false,
        // GET /oauth/userinfo
        introspection: options.features?.introspection !== false,
        // POST /oauth/introspect
        revocation: options.features?.revocation !== false,
        // POST /oauth/revoke
        registration: options.features?.registration !== false,
        // POST /oauth/register (RFC 7591)
        // Authorization Code Flow UI
        builtInLoginUI: options.features?.builtInLoginUI !== false,
        // HTML login form
        customLoginHandler: options.features?.customLoginHandler || null,
        // Custom UI handler
        // PKCE (Proof Key for Code Exchange - RFC 7636)
        pkce: {
          enabled: options.features?.pkce?.enabled !== false,
          // PKCE support
          required: options.features?.pkce?.required || false,
          // Force PKCE for public clients
          methods: options.features?.pkce?.methods || ["S256", "plain"]
          // Supported methods
        },
        // Refresh tokens
        refreshTokens: options.features?.refreshTokens !== false,
        // Enable refresh tokens
        refreshTokenRotation: options.features?.refreshTokenRotation || false,
        // Rotate on each use
        revokeOldRefreshTokens: options.features?.revokeOldRefreshTokens !== false
        // Revoke old tokens after rotation
        // Future features (Phase 2 - commented for reference)
        // admin: { enabled: false, apiKey: null, endpoints: {...} },
        // consent: { enabled: false, skipForTrustedClients: true },
        // mfa: { enabled: false, methods: ['totp', 'sms', 'email'] },
        // emailVerification: { enabled: false, required: false },
        // passwordPolicy: { enabled: false, minLength: 8, ... },
        // webhooks: { enabled: false, endpoints: [], events: [] }
      }
    };
    this.server = null;
    this.oauth2Server = null;
    this.sessionManager = null;
    this.emailService = null;
    this.oauth2KeysResource = null;
    this.oauth2ClientsResource = null;
    this.oauth2AuthCodesResource = null;
    this.sessionsResource = null;
    this.passwordResetTokensResource = null;
    this.usersResource = null;
  }
  /**
   * Validate plugin dependencies
   * @private
   */
  async _validateDependencies() {
    await requirePluginDependency("identity-plugin", {
      throwOnError: true,
      checkVersions: true
    });
  }
  /**
   * Install plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Installing...");
    }
    try {
      await this._validateDependencies();
    } catch (err) {
      console.error("[Identity Plugin] Dependency validation failed:", err.message);
      throw err;
    }
    await this._createOAuth2Resources();
    await this._ensureUsersResource();
    await this._initializeOAuth2Server();
    await this._initializeSessionManager();
    await this._initializeEmailService();
    if (this.config.verbose) {
      console.log("[Identity Plugin] Installed successfully");
    }
  }
  /**
   * Create OAuth2 resources for authorization server
   * @private
   */
  async _createOAuth2Resources() {
    const [okKeys, errKeys, keysResource] = await tryFn(
      () => this.database.createResource({
        name: "plg_oauth_keys",
        attributes: {
          kid: "string|required",
          publicKey: "string|required",
          privateKey: "secret|required",
          algorithm: "string|default:RS256",
          use: "string|default:sig",
          active: "boolean|default:true",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okKeys) {
      this.oauth2KeysResource = keysResource;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Created plg_oauth_keys resource");
      }
    } else if (this.database.resources.plg_oauth_keys) {
      this.oauth2KeysResource = this.database.resources.plg_oauth_keys;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Using existing plg_oauth_keys resource");
      }
    } else {
      throw errKeys;
    }
    const [okClients, errClients, clientsResource] = await tryFn(
      () => this.database.createResource({
        name: "plg_oauth_clients",
        attributes: {
          clientId: "string|required",
          clientSecret: "secret|required",
          name: "string|required",
          redirectUris: "array|items:string|required",
          allowedScopes: "array|items:string|optional",
          grantTypes: 'array|items:string|default:["authorization_code","refresh_token"]',
          active: "boolean|default:true",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okClients) {
      this.oauth2ClientsResource = clientsResource;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Created plg_oauth_clients resource");
      }
    } else if (this.database.resources.plg_oauth_clients) {
      this.oauth2ClientsResource = this.database.resources.plg_oauth_clients;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Using existing plg_oauth_clients resource");
      }
    } else {
      throw errClients;
    }
    const [okCodes, errCodes, codesResource] = await tryFn(
      () => this.database.createResource({
        name: "plg_auth_codes",
        attributes: {
          code: "string|required",
          clientId: "string|required",
          userId: "string|required",
          redirectUri: "string|required",
          scope: "string|optional",
          expiresAt: "string|required",
          used: "boolean|default:false",
          codeChallenge: "string|optional",
          // PKCE support
          codeChallengeMethod: "string|optional",
          // PKCE support
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okCodes) {
      this.oauth2AuthCodesResource = codesResource;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Created plg_auth_codes resource");
      }
    } else if (this.database.resources.plg_auth_codes) {
      this.oauth2AuthCodesResource = this.database.resources.plg_auth_codes;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Using existing plg_auth_codes resource");
      }
    } else {
      throw errCodes;
    }
    const [okSessions, errSessions, sessionsResource] = await tryFn(
      () => this.database.createResource({
        name: "plg_sessions",
        attributes: {
          userId: "string|required",
          expiresAt: "string|required",
          ipAddress: "ip4|optional",
          userAgent: "string|optional",
          metadata: "object|optional",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okSessions) {
      this.sessionsResource = sessionsResource;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Created plg_sessions resource");
      }
    } else if (this.database.resources.plg_sessions) {
      this.sessionsResource = this.database.resources.plg_sessions;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Using existing plg_sessions resource");
      }
    } else {
      throw errSessions;
    }
    const [okResetTokens, errResetTokens, resetTokensResource] = await tryFn(
      () => this.database.createResource({
        name: "plg_password_reset_tokens",
        attributes: {
          userId: "string|required",
          token: "string|required",
          expiresAt: "string|required",
          used: "boolean|default:false",
          createdAt: "string|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (okResetTokens) {
      this.passwordResetTokensResource = resetTokensResource;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Created plg_password_reset_tokens resource");
      }
    } else if (this.database.resources.plg_password_reset_tokens) {
      this.passwordResetTokensResource = this.database.resources.plg_password_reset_tokens;
      if (this.config.verbose) {
        console.log("[Identity Plugin] Using existing plg_password_reset_tokens resource");
      }
    } else {
      throw errResetTokens;
    }
  }
  /**
   * Ensure users resource exists (for authentication)
   * @private
   */
  async _ensureUsersResource() {
    const resourceName = this.config.userResource;
    if (this.database.resources[resourceName]) {
      this.usersResource = this.database.resources[resourceName];
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Using existing ${resourceName} resource`);
      }
      return;
    }
    const [ok, err, resource] = await tryFn(
      () => this.database.createResource({
        name: resourceName,
        attributes: {
          email: "string|required|email",
          password: "secret|required",
          name: "string|optional",
          scopes: "array|items:string|optional",
          active: "boolean|default:true"
        },
        behavior: "body-overflow",
        timestamps: true,
        createdBy: "IdentityPlugin"
      })
    );
    if (ok) {
      this.usersResource = resource;
      if (this.config.verbose) {
        console.log(`[Identity Plugin] Created ${resourceName} resource`);
      }
    } else {
      throw err;
    }
  }
  /**
   * Initialize OAuth2 Server instance
   * @private
   */
  async _initializeOAuth2Server() {
    this.oauth2Server = new OAuth2Server({
      issuer: this.config.issuer,
      keyResource: this.oauth2KeysResource,
      userResource: this.usersResource,
      clientResource: this.oauth2ClientsResource,
      authCodeResource: this.oauth2AuthCodesResource,
      supportedScopes: this.config.supportedScopes,
      supportedGrantTypes: this.config.supportedGrantTypes,
      supportedResponseTypes: this.config.supportedResponseTypes,
      accessTokenExpiry: this.config.accessTokenExpiry,
      idTokenExpiry: this.config.idTokenExpiry,
      refreshTokenExpiry: this.config.refreshTokenExpiry,
      authCodeExpiry: this.config.authCodeExpiry
    });
    await this.oauth2Server.initialize();
    if (this.config.verbose) {
      console.log("[Identity Plugin] OAuth2 Server initialized");
      console.log(`[Identity Plugin] Issuer: ${this.config.issuer}`);
      console.log(`[Identity Plugin] Supported scopes: ${this.config.supportedScopes.join(", ")}`);
      console.log(`[Identity Plugin] Supported grant types: ${this.config.supportedGrantTypes.join(", ")}`);
    }
  }
  /**
   * Initialize Session Manager
   * @private
   */
  async _initializeSessionManager() {
    const { SessionManager } = await Promise.resolve().then(function () { return sessionManager; });
    this.sessionManager = new SessionManager({
      sessionResource: this.sessionsResource,
      config: this.config.session
    });
    if (this.config.verbose) {
      console.log("[Identity Plugin] Session Manager initialized");
      console.log(`[Identity Plugin] Session expiry: ${this.config.session.sessionExpiry}`);
      console.log(`[Identity Plugin] Cookie name: ${this.config.session.cookieName}`);
    }
  }
  /**
   * Initialize email service
   * @private
   */
  async _initializeEmailService() {
    const { EmailService } = await Promise.resolve().then(function () { return emailService; });
    this.emailService = new EmailService({
      enabled: this.config.email.enabled,
      from: this.config.email.from,
      replyTo: this.config.email.replyTo,
      smtp: this.config.email.smtp,
      templates: this.config.email.templates,
      verbose: this.config.verbose
    });
    if (this.config.verbose) {
      console.log("[Identity Plugin] Email Service initialized");
      console.log(`[Identity Plugin] Email enabled: ${this.config.email.enabled}`);
      if (this.config.email.enabled) {
        console.log(`[Identity Plugin] SMTP host: ${this.config.email.smtp.host}:${this.config.email.smtp.port}`);
        console.log(`[Identity Plugin] From address: ${this.config.email.from}`);
      }
    }
  }
  /**
   * Start plugin
   */
  async onStart() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Starting server...");
    }
    const { IdentityServer } = await Promise.resolve().then(function () { return server; });
    this.server = new IdentityServer({
      port: this.config.port,
      host: this.config.host,
      verbose: this.config.verbose,
      issuer: this.config.issuer,
      oauth2Server: this.oauth2Server,
      sessionManager: this.sessionManager,
      usersResource: this.usersResource,
      identityPlugin: this,
      cors: this.config.cors,
      security: this.config.security,
      logging: this.config.logging
    });
    await this.server.start();
    this.emit("plugin.started", {
      port: this.config.port,
      host: this.config.host,
      issuer: this.config.issuer
    });
  }
  /**
   * Stop plugin
   */
  async onStop() {
    if (this.config.verbose) {
      console.log("[Identity Plugin] Stopping server...");
    }
    if (this.server) {
      await this.server.stop();
      this.server = null;
    }
    if (this.sessionManager) {
      this.sessionManager.stopCleanup();
    }
    if (this.emailService) {
      await this.emailService.close();
    }
    this.emit("plugin.stopped");
  }
  /**
   * Uninstall plugin
   */
  async onUninstall(options = {}) {
    const { purgeData = false } = options;
    await this.onStop();
    if (purgeData) {
      const resourcesToDelete = ["plg_oauth_keys", "plg_oauth_clients", "plg_auth_codes"];
      for (const resourceName of resourcesToDelete) {
        const [ok] = await tryFn(() => this.database.deleteResource(resourceName));
        if (ok && this.config.verbose) {
          console.log(`[Identity Plugin] Deleted ${resourceName} resource`);
        }
      }
    }
    if (this.config.verbose) {
      console.log("[Identity Plugin] Uninstalled successfully");
    }
  }
  /**
   * Get server information
   * @returns {Object} Server info
   */
  getServerInfo() {
    return this.server ? this.server.getInfo() : { isRunning: false };
  }
  /**
   * Get OAuth2 Server instance (for advanced usage)
   * @returns {OAuth2Server|null}
   */
  getOAuth2Server() {
    return this.oauth2Server;
  }
}

class AuditPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.auditResource = null;
    this.config = {
      includeData: options.includeData !== false,
      includePartitions: options.includePartitions !== false,
      maxDataSize: options.maxDataSize || 1e4,
      ...options
    };
  }
  async onInstall() {
    const [ok, err, auditResource] = await tryFn(() => this.database.createResource({
      name: "plg_audits",
      attributes: {
        id: "string|required",
        resourceName: "string|required",
        operation: "string|required",
        recordId: "string|required",
        userId: "string|optional",
        timestamp: "string|required",
        createdAt: "string|required",
        // YYYY-MM-DD for partitioning
        oldData: "string|optional",
        newData: "string|optional",
        partition: "string|optional",
        partitionValues: "string|optional",
        metadata: "string|optional"
      },
      partitions: {
        byDate: { fields: { createdAt: "string|maxlength:10" } },
        byResource: { fields: { resourceName: "string" } }
      },
      behavior: "body-overflow"
    }));
    this.auditResource = ok ? auditResource : this.database.resources.plg_audits || null;
    if (!ok && !this.auditResource) return;
    this.database.addHook("afterCreateResource", (context) => {
      if (context.resource.name !== "plg_audits") {
        this.setupResourceAuditing(context.resource);
      }
    });
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name !== "plg_audits") {
        this.setupResourceAuditing(resource);
      }
    }
  }
  async onStart() {
  }
  async onStop() {
  }
  setupResourceAuditing(resource) {
    resource.on("inserted", async (data) => {
      const partitionValues = this.config.includePartitions ? this.getPartitionValues(data, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "insert",
        recordId: data.id || "auto-generated",
        oldData: null,
        newData: this.config.includeData ? JSON.stringify(this.truncateData(data)) : null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    resource.on("updated", async (data) => {
      let oldData = data.$before;
      if (this.config.includeData && !oldData) {
        const [ok, err, fetched] = await tryFn(() => resource.get(data.id));
        if (ok) oldData = fetched;
      }
      const partitionValues = this.config.includePartitions ? this.getPartitionValues(data, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "update",
        recordId: data.id,
        oldData: oldData && this.config.includeData ? JSON.stringify(this.truncateData(oldData)) : null,
        newData: this.config.includeData ? JSON.stringify(this.truncateData(data)) : null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    resource.on("deleted", async (data) => {
      let oldData = data;
      if (this.config.includeData && !oldData) {
        const [ok, err, fetched] = await tryFn(() => resource.get(data.id));
        if (ok) oldData = fetched;
      }
      const partitionValues = oldData && this.config.includePartitions ? this.getPartitionValues(oldData, resource) : null;
      await this.logAudit({
        resourceName: resource.name,
        operation: "delete",
        recordId: data.id,
        oldData: oldData && this.config.includeData ? JSON.stringify(this.truncateData(oldData)) : null,
        newData: null,
        partition: partitionValues ? this.getPrimaryPartition(partitionValues) : null,
        partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
      });
    });
    const originalDeleteMany = resource.deleteMany.bind(resource);
    const plugin = this;
    resource.deleteMany = async function(ids) {
      const objectsToDelete = [];
      for (const id of ids) {
        const [ok, err, fetched] = await tryFn(() => resource.get(id));
        if (ok) {
          objectsToDelete.push(fetched);
        } else {
          objectsToDelete.push({ id });
        }
      }
      const result = await originalDeleteMany(ids);
      for (const oldData of objectsToDelete) {
        const partitionValues = oldData && plugin.config.includePartitions ? plugin.getPartitionValues(oldData, resource) : null;
        await plugin.logAudit({
          resourceName: resource.name,
          operation: "deleteMany",
          recordId: oldData.id,
          oldData: oldData && plugin.config.includeData ? JSON.stringify(plugin.truncateData(oldData)) : null,
          newData: null,
          partition: partitionValues ? plugin.getPrimaryPartition(partitionValues) : null,
          partitionValues: partitionValues ? JSON.stringify(partitionValues) : null
        });
      }
      return result;
    };
    resource._originalDeleteMany = originalDeleteMany;
  }
  // Backward compatibility for tests
  installEventListenersForResource(resource) {
    return this.setupResourceAuditing(resource);
  }
  async logAudit(auditData) {
    if (!this.auditResource) {
      return;
    }
    const now = /* @__PURE__ */ new Date();
    const auditRecord = {
      id: `audit-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`,
      userId: this.getCurrentUserId?.() || "system",
      timestamp: now.toISOString(),
      createdAt: now.toISOString().slice(0, 10),
      // YYYY-MM-DD for partitioning
      metadata: JSON.stringify({ source: "audit-plugin", version: "2.0" }),
      resourceName: auditData.resourceName,
      operation: auditData.operation,
      recordId: auditData.recordId
    };
    if (auditData.oldData !== null) {
      auditRecord.oldData = auditData.oldData;
    }
    if (auditData.newData !== null) {
      auditRecord.newData = auditData.newData;
    }
    if (auditData.partition !== null) {
      auditRecord.partition = auditData.partition;
    }
    if (auditData.partitionValues !== null) {
      auditRecord.partitionValues = auditData.partitionValues;
    }
    try {
      await this.auditResource.insert(auditRecord);
    } catch (error) {
      console.warn("Audit logging failed:", error.message);
    }
  }
  getPartitionValues(data, resource) {
    if (!this.config.includePartitions) return null;
    const partitions = resource.config?.partitions || resource.partitions;
    if (!partitions) {
      return null;
    }
    const partitionValues = {};
    for (const [partitionName, partitionConfig] of Object.entries(partitions)) {
      const values = {};
      for (const field of Object.keys(partitionConfig.fields)) {
        values[field] = this.getNestedFieldValue(data, field);
      }
      if (Object.values(values).some((v) => v !== void 0 && v !== null)) {
        partitionValues[partitionName] = values;
      }
    }
    return Object.keys(partitionValues).length > 0 ? partitionValues : null;
  }
  getNestedFieldValue(data, fieldPath) {
    const parts = fieldPath.split(".");
    let value = data;
    for (const part of parts) {
      if (value && typeof value === "object" && part in value) {
        value = value[part];
      } else {
        return void 0;
      }
    }
    return value;
  }
  getPrimaryPartition(partitionValues) {
    if (!partitionValues) return null;
    const partitionNames = Object.keys(partitionValues);
    return partitionNames.length > 0 ? partitionNames[0] : null;
  }
  truncateData(data) {
    if (!this.config.includeData) return null;
    const dataStr = JSON.stringify(data);
    if (dataStr.length <= this.config.maxDataSize) {
      return data;
    }
    return {
      ...data,
      _truncated: true,
      _originalSize: dataStr.length,
      _truncatedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
  }
  async getAuditLogs(options = {}) {
    if (!this.auditResource) return [];
    const { resourceName, operation, recordId, partition, startDate, endDate, limit = 100, offset = 0 } = options;
    let items = [];
    if (resourceName && !operation && !recordId && !partition && !startDate && !endDate) {
      const [ok, err, result] = await tryFn(
        () => this.auditResource.query({ resourceName }, { limit: limit + offset })
      );
      items = ok && result ? result : [];
      return items.slice(offset, offset + limit);
    } else if (startDate && !resourceName && !operation && !recordId && !partition) {
      const dates = this._generateDateRange(startDate, endDate);
      for (const date of dates) {
        const [ok, err, result] = await tryFn(
          () => this.auditResource.query({ createdAt: date })
        );
        if (ok && result) {
          items.push(...result);
        }
      }
      return items.slice(offset, offset + limit);
    } else if (resourceName || operation || recordId || partition || startDate || endDate) {
      const fetchSize = Math.min(1e4, Math.max(1e3, (limit + offset) * 20));
      const result = await this.auditResource.list({ limit: fetchSize });
      items = result || [];
      if (resourceName) {
        items = items.filter((log) => log.resourceName === resourceName);
      }
      if (operation) {
        items = items.filter((log) => log.operation === operation);
      }
      if (recordId) {
        items = items.filter((log) => log.recordId === recordId);
      }
      if (partition) {
        items = items.filter((log) => log.partition === partition);
      }
      if (startDate || endDate) {
        items = items.filter((log) => {
          const timestamp = new Date(log.timestamp);
          if (startDate && timestamp < new Date(startDate)) return false;
          if (endDate && timestamp > new Date(endDate)) return false;
          return true;
        });
      }
      return items.slice(offset, offset + limit);
    } else {
      const result = await this.auditResource.page({ size: limit, offset });
      return result.items || [];
    }
  }
  _generateDateRange(startDate, endDate) {
    const dates = [];
    const start = new Date(startDate);
    const end = endDate ? new Date(endDate) : /* @__PURE__ */ new Date();
    for (let d = new Date(start); d <= end; d.setDate(d.getDate() + 1)) {
      dates.push(d.toISOString().slice(0, 10));
    }
    return dates;
  }
  async getRecordHistory(resourceName, recordId) {
    return await this.getAuditLogs({ resourceName, recordId });
  }
  async getPartitionHistory(resourceName, partitionName, partitionValues) {
    return await this.getAuditLogs({
      resourceName,
      partition: partitionName,
      partitionValues: JSON.stringify(partitionValues)
    });
  }
  async getAuditStats(options = {}) {
    const logs = await this.getAuditLogs(options);
    const stats = {
      total: logs.length,
      byOperation: {},
      byResource: {},
      byPartition: {},
      byUser: {},
      timeline: {}
    };
    for (const log of logs) {
      stats.byOperation[log.operation] = (stats.byOperation[log.operation] || 0) + 1;
      stats.byResource[log.resourceName] = (stats.byResource[log.resourceName] || 0) + 1;
      if (log.partition) {
        stats.byPartition[log.partition] = (stats.byPartition[log.partition] || 0) + 1;
      }
      stats.byUser[log.userId] = (stats.byUser[log.userId] || 0) + 1;
      const date = log.timestamp.split("T")[0];
      stats.timeline[date] = (stats.timeline[date] || 0) + 1;
    }
    return stats;
  }
  /**
   * Clean up audit logs older than retention period
   * @param {number} retentionDays - Number of days to retain (default: 90)
   * @returns {Promise<number>} Number of records deleted
   */
  async cleanupOldAudits(retentionDays = 90) {
    if (!this.auditResource) return 0;
    const cutoffDate = /* @__PURE__ */ new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    const datesToDelete = [];
    const startDate = new Date(cutoffDate);
    startDate.setDate(startDate.getDate() - 365);
    for (let d = new Date(startDate); d < cutoffDate; d.setDate(d.getDate() + 1)) {
      datesToDelete.push(d.toISOString().slice(0, 10));
    }
    let deletedCount = 0;
    for (const dateStr of datesToDelete) {
      const [ok, err, oldAudits] = await tryFn(
        () => this.auditResource.query({ createdAt: dateStr })
      );
      if (ok && oldAudits) {
        for (const audit of oldAudits) {
          const [delOk] = await tryFn(() => this.auditResource.delete(audit.id));
          if (delOk) {
            deletedCount++;
          }
        }
      }
    }
    return deletedCount;
  }
}

class BackupError extends S3dbError {
  constructor(message, details = {}) {
    const { driver = "unknown", operation = "unknown", backupId, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Backup Operation Error

Driver: ${driver}
Operation: ${operation}
${backupId ? `Backup ID: ${backupId}` : ""}

Common causes:
1. Invalid backup driver configuration
2. Destination storage not accessible
3. Insufficient permissions
4. Network connectivity issues
5. Invalid backup file format

Solution:
Check driver configuration and ensure destination storage is accessible.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/backup.md
`.trim();
    }
    super(message, { ...rest, driver, operation, backupId, description });
  }
}

class BaseBackupDriver {
  constructor(config = {}) {
    this.config = {
      compression: "gzip",
      encryption: null,
      verbose: false,
      ...config
    };
  }
  /**
   * Initialize the driver
   * @param {Database} database - S3DB database instance
   */
  async setup(database) {
    this.database = database;
    await this.onSetup();
  }
  /**
   * Override this method to perform driver-specific setup
   */
  async onSetup() {
  }
  /**
   * Upload a backup file to the destination
   * @param {string} filePath - Path to the backup file
   * @param {string} backupId - Unique backup identifier
   * @param {Object} manifest - Backup manifest with metadata
   * @returns {Object} Upload result with destination info
   */
  async upload(filePath, backupId, manifest) {
    throw new BackupError("upload() method must be implemented by subclass", {
      operation: "upload",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the upload() method"
    });
  }
  /**
   * Download a backup file from the destination
   * @param {string} backupId - Unique backup identifier
   * @param {string} targetPath - Local path to save the backup
   * @param {Object} metadata - Backup metadata
   * @returns {string} Path to downloaded file
   */
  async download(backupId, targetPath, metadata) {
    throw new BackupError("download() method must be implemented by subclass", {
      operation: "download",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the download() method"
    });
  }
  /**
   * Delete a backup from the destination
   * @param {string} backupId - Unique backup identifier
   * @param {Object} metadata - Backup metadata
   */
  async delete(backupId, metadata) {
    throw new BackupError("delete() method must be implemented by subclass", {
      operation: "delete",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the delete() method"
    });
  }
  /**
   * List backups available in the destination
   * @param {Object} options - List options (limit, prefix, etc.)
   * @returns {Array} List of backup metadata
   */
  async list(options = {}) {
    throw new BackupError("list() method must be implemented by subclass", {
      operation: "list",
      driver: this.constructor.name,
      suggestion: "Extend BaseBackupDriver and implement the list() method"
    });
  }
  /**
   * Verify backup integrity
   * @param {string} backupId - Unique backup identifier
   * @param {string} expectedChecksum - Expected file checksum
   * @param {Object} metadata - Backup metadata
   * @returns {boolean} True if backup is valid
   */
  async verify(backupId, expectedChecksum, metadata) {
    throw new BackupError("verify() method must be implemented by subclass", {
      operation: "verify",
      driver: this.constructor.name,
      backupId,
      suggestion: "Extend BaseBackupDriver and implement the verify() method"
    });
  }
  /**
   * Get driver type identifier
   * @returns {string} Driver type
   */
  getType() {
    throw new BackupError("getType() method must be implemented by subclass", {
      operation: "getType",
      driver: this.constructor.name,
      suggestion: "Extend BaseBackupDriver and implement the getType() method"
    });
  }
  /**
   * Get driver-specific storage info
   * @returns {Object} Storage information
   */
  getStorageInfo() {
    return {
      type: this.getType(),
      config: this.config
    };
  }
  /**
   * Clean up resources
   */
  async cleanup() {
  }
  /**
   * Log message if verbose mode is enabled
   * @param {string} message - Message to log
   */
  log(message) {
    if (this.config.verbose) {
      console.log(`[${this.getType()}BackupDriver] ${message}`);
    }
  }
}

class FilesystemBackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      path: "./backups/{date}/",
      permissions: 420,
      directoryPermissions: 493,
      ...config
    });
  }
  getType() {
    return "filesystem";
  }
  async onSetup() {
    if (!this.config.path) {
      throw new BackupError("FilesystemBackupDriver: path configuration is required", {
        operation: "onSetup",
        driver: "filesystem",
        suggestion: 'Provide a path in config: new FilesystemBackupDriver({ path: "/path/to/backups" })'
      });
    }
    this.log(`Initialized with path: ${this.config.path}`);
  }
  /**
   * Resolve path template variables
   * @param {string} backupId - Backup identifier
   * @param {Object} manifest - Backup manifest
   * @returns {string} Resolved path
   */
  resolvePath(backupId, manifest = {}) {
    const now = /* @__PURE__ */ new Date();
    const dateStr = now.toISOString().slice(0, 10);
    const timeStr = now.toISOString().slice(11, 19).replace(/:/g, "-");
    return this.config.path.replace("{date}", dateStr).replace("{time}", timeStr).replace("{year}", now.getFullYear().toString()).replace("{month}", (now.getMonth() + 1).toString().padStart(2, "0")).replace("{day}", now.getDate().toString().padStart(2, "0")).replace("{backupId}", backupId).replace("{type}", manifest.type || "backup");
  }
  async upload(filePath, backupId, manifest) {
    const targetDir = this.resolvePath(backupId, manifest);
    const targetPath = path$1.join(targetDir, `${backupId}.backup`);
    const manifestPath = path$1.join(targetDir, `${backupId}.manifest.json`);
    const [createDirOk, createDirErr] = await tryFn(
      () => mkdir(targetDir, { recursive: true, mode: this.config.directoryPermissions })
    );
    if (!createDirOk) {
      throw new BackupError("Failed to create backup directory", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        targetDir,
        original: createDirErr,
        suggestion: "Check directory permissions and disk space"
      });
    }
    const [copyOk, copyErr] = await tryFn(() => copyFile(filePath, targetPath));
    if (!copyOk) {
      throw new BackupError("Failed to copy backup file", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        filePath,
        targetPath,
        original: copyErr,
        suggestion: "Check file permissions and disk space"
      });
    }
    const [manifestOk, manifestErr] = await tryFn(
      () => import('fs/promises').then((fs) => fs.writeFile(
        manifestPath,
        JSON.stringify(manifest, null, 2),
        { mode: this.config.permissions }
      ))
    );
    if (!manifestOk) {
      await tryFn(() => unlink(targetPath));
      throw new BackupError("Failed to write manifest file", {
        operation: "upload",
        driver: "filesystem",
        backupId,
        manifestPath,
        original: manifestErr,
        suggestion: "Check directory permissions and disk space"
      });
    }
    const [statOk, , stats] = await tryFn(() => stat(targetPath));
    const size = statOk ? stats.size : 0;
    this.log(`Uploaded backup ${backupId} to ${targetPath} (${size} bytes)`);
    return {
      path: targetPath,
      manifestPath,
      size,
      uploadedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
  }
  async download(backupId, targetPath, metadata) {
    const sourcePath = metadata.path || path$1.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const [existsOk] = await tryFn(() => access(sourcePath));
    if (!existsOk) {
      throw new BackupError("Backup file not found", {
        operation: "download",
        driver: "filesystem",
        backupId,
        sourcePath,
        suggestion: "Check if backup exists using list() method"
      });
    }
    const targetDir = path$1.dirname(targetPath);
    await tryFn(() => mkdir(targetDir, { recursive: true }));
    const [copyOk, copyErr] = await tryFn(() => copyFile(sourcePath, targetPath));
    if (!copyOk) {
      throw new BackupError("Failed to download backup", {
        operation: "download",
        driver: "filesystem",
        backupId,
        sourcePath,
        targetPath,
        original: copyErr,
        suggestion: "Check file permissions and disk space"
      });
    }
    this.log(`Downloaded backup ${backupId} from ${sourcePath} to ${targetPath}`);
    return targetPath;
  }
  async delete(backupId, metadata) {
    const backupPath = metadata.path || path$1.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const manifestPath = metadata.manifestPath || path$1.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.manifest.json`
    );
    const [deleteBackupOk] = await tryFn(() => unlink(backupPath));
    const [deleteManifestOk] = await tryFn(() => unlink(manifestPath));
    if (!deleteBackupOk && !deleteManifestOk) {
      throw new BackupError("Failed to delete backup files", {
        operation: "delete",
        driver: "filesystem",
        backupId,
        backupPath,
        manifestPath,
        suggestion: "Check file permissions"
      });
    }
    this.log(`Deleted backup ${backupId}`);
  }
  async list(options = {}) {
    const { limit = 50, prefix = "" } = options;
    const basePath = this.resolvePath("*").replace("*", "");
    try {
      const results = [];
      await this._scanDirectory(path$1.dirname(basePath), prefix, results, limit);
      results.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
      return results.slice(0, limit);
    } catch (error) {
      this.log(`Error listing backups: ${error.message}`);
      return [];
    }
  }
  async _scanDirectory(dirPath, prefix, results, limit) {
    if (results.length >= limit) return;
    const [readDirOk, , files] = await tryFn(() => readdir(dirPath));
    if (!readDirOk) return;
    for (const file of files) {
      if (results.length >= limit) break;
      const fullPath = path$1.join(dirPath, file);
      const [statOk, , stats] = await tryFn(() => stat(fullPath));
      if (!statOk) continue;
      if (stats.isDirectory()) {
        await this._scanDirectory(fullPath, prefix, results, limit);
      } else if (file.endsWith(".manifest.json")) {
        const [readOk, , content] = await tryFn(
          () => import('fs/promises').then((fs) => fs.readFile(fullPath, "utf8"))
        );
        if (readOk) {
          try {
            const manifest = JSON.parse(content);
            const backupId = file.replace(".manifest.json", "");
            if (!prefix || backupId.includes(prefix)) {
              results.push({
                id: backupId,
                path: fullPath.replace(".manifest.json", ".backup"),
                manifestPath: fullPath,
                size: stats.size,
                createdAt: manifest.createdAt || stats.birthtime.toISOString(),
                ...manifest
              });
            }
          } catch (parseErr) {
            this.log(`Failed to parse manifest ${fullPath}: ${parseErr.message}`);
          }
        }
      }
    }
  }
  async verify(backupId, expectedChecksum, metadata) {
    const backupPath = metadata.path || path$1.join(
      this.resolvePath(backupId, metadata),
      `${backupId}.backup`
    );
    const [readOk, readErr] = await tryFn(async () => {
      const hash = crypto$1.createHash("sha256");
      const stream = createReadStream(backupPath);
      await pipeline(stream, hash);
      const actualChecksum = hash.digest("hex");
      return actualChecksum === expectedChecksum;
    });
    if (!readOk) {
      this.log(`Verification failed for ${backupId}: ${readErr.message}`);
      return false;
    }
    return readOk;
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      path: this.config.path,
      permissions: this.config.permissions,
      directoryPermissions: this.config.directoryPermissions
    };
  }
}

class S3BackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      bucket: null,
      // Will use database bucket if not specified
      path: "backups/{date}/",
      storageClass: "STANDARD_IA",
      serverSideEncryption: "AES256",
      client: null,
      // Will use database client if not specified
      ...config
    });
  }
  getType() {
    return "s3";
  }
  async onSetup() {
    if (!this.config.client) {
      this.config.client = this.database.client;
    }
    if (!this.config.bucket) {
      this.config.bucket = this.database.bucket;
    }
    if (!this.config.client) {
      throw new BackupError("S3BackupDriver: client is required", {
        operation: "onSetup",
        driver: "s3",
        suggestion: "Provide a client in config or ensure database has a client configured"
      });
    }
    if (!this.config.bucket) {
      throw new BackupError("S3BackupDriver: bucket is required", {
        operation: "onSetup",
        driver: "s3",
        suggestion: "Provide a bucket in config or ensure database has a bucket configured"
      });
    }
    this.log(`Initialized with bucket: ${this.config.bucket}, path: ${this.config.path}`);
  }
  /**
   * Resolve S3 key template variables
   * @param {string} backupId - Backup identifier
   * @param {Object} manifest - Backup manifest
   * @returns {string} Resolved S3 key
   */
  resolveKey(backupId, manifest = {}) {
    const now = /* @__PURE__ */ new Date();
    const dateStr = now.toISOString().slice(0, 10);
    const timeStr = now.toISOString().slice(11, 19).replace(/:/g, "-");
    const basePath = this.config.path.replace("{date}", dateStr).replace("{time}", timeStr).replace("{year}", now.getFullYear().toString()).replace("{month}", (now.getMonth() + 1).toString().padStart(2, "0")).replace("{day}", now.getDate().toString().padStart(2, "0")).replace("{backupId}", backupId).replace("{type}", manifest.type || "backup");
    return path$1.posix.join(basePath, `${backupId}.backup`);
  }
  resolveManifestKey(backupId, manifest = {}) {
    return this.resolveKey(backupId, manifest).replace(".backup", ".manifest.json");
  }
  async upload(filePath, backupId, manifest) {
    const backupKey = this.resolveKey(backupId, manifest);
    const manifestKey = this.resolveManifestKey(backupId, manifest);
    const [statOk, , stats] = await tryFn(() => stat(filePath));
    const fileSize = statOk ? stats.size : 0;
    const [uploadOk, uploadErr] = await tryFn(async () => {
      const fileStream = createReadStream(filePath);
      return await this.config.client.uploadObject({
        bucket: this.config.bucket,
        key: backupKey,
        body: fileStream,
        contentLength: fileSize,
        metadata: {
          "backup-id": backupId,
          "backup-type": manifest.type || "backup",
          "created-at": (/* @__PURE__ */ new Date()).toISOString()
        },
        storageClass: this.config.storageClass,
        serverSideEncryption: this.config.serverSideEncryption
      });
    });
    if (!uploadOk) {
      throw new BackupError("Failed to upload backup file to S3", {
        operation: "upload",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        key: backupKey,
        original: uploadErr,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    const [manifestOk, manifestErr] = await tryFn(
      () => this.config.client.uploadObject({
        bucket: this.config.bucket,
        key: manifestKey,
        body: JSON.stringify(manifest, null, 2),
        contentType: "application/json",
        metadata: {
          "backup-id": backupId,
          "manifest-for": backupKey
        },
        storageClass: this.config.storageClass,
        serverSideEncryption: this.config.serverSideEncryption
      })
    );
    if (!manifestOk) {
      await tryFn(() => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: backupKey
      }));
      throw new BackupError("Failed to upload manifest to S3", {
        operation: "upload",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        manifestKey,
        original: manifestErr,
        suggestion: "Check S3 permissions and bucket configuration"
      });
    }
    this.log(`Uploaded backup ${backupId} to s3://${this.config.bucket}/${backupKey} (${fileSize} bytes)`);
    return {
      bucket: this.config.bucket,
      key: backupKey,
      manifestKey,
      size: fileSize,
      storageClass: this.config.storageClass,
      uploadedAt: (/* @__PURE__ */ new Date()).toISOString(),
      etag: uploadOk?.ETag
    };
  }
  async download(backupId, targetPath, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const [downloadOk, downloadErr] = await tryFn(
      () => this.config.client.downloadObject({
        bucket: this.config.bucket,
        key: backupKey,
        filePath: targetPath
      })
    );
    if (!downloadOk) {
      throw new BackupError("Failed to download backup from S3", {
        operation: "download",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        key: backupKey,
        targetPath,
        original: downloadErr,
        suggestion: "Check if backup exists and S3 permissions are correct"
      });
    }
    this.log(`Downloaded backup ${backupId} from s3://${this.config.bucket}/${backupKey} to ${targetPath}`);
    return targetPath;
  }
  async delete(backupId, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const manifestKey = metadata.manifestKey || this.resolveManifestKey(backupId, metadata);
    const [deleteBackupOk] = await tryFn(
      () => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: backupKey
      })
    );
    const [deleteManifestOk] = await tryFn(
      () => this.config.client.deleteObject({
        bucket: this.config.bucket,
        key: manifestKey
      })
    );
    if (!deleteBackupOk && !deleteManifestOk) {
      throw new BackupError("Failed to delete backup from S3", {
        operation: "delete",
        driver: "s3",
        backupId,
        bucket: this.config.bucket,
        backupKey,
        manifestKey,
        suggestion: "Check S3 delete permissions"
      });
    }
    this.log(`Deleted backup ${backupId} from S3`);
  }
  async list(options = {}) {
    const { limit = 50, prefix = "" } = options;
    const searchPrefix = this.config.path.replace(/\{[^}]+\}/g, "");
    const [listOk, listErr, response] = await tryFn(
      () => this.config.client.listObjects({
        bucket: this.config.bucket,
        prefix: searchPrefix,
        maxKeys: limit * 2
        // Get more to account for manifest files
      })
    );
    if (!listOk) {
      this.log(`Error listing S3 objects: ${listErr.message}`);
      return [];
    }
    const manifestObjects = (response.Contents || []).filter((obj) => obj.Key.endsWith(".manifest.json")).filter((obj) => !prefix || obj.Key.includes(prefix));
    const results = [];
    for (const obj of manifestObjects.slice(0, limit)) {
      const [manifestOk, , manifestContent] = await tryFn(
        () => this.config.client.getObject({
          bucket: this.config.bucket,
          key: obj.Key
        })
      );
      if (manifestOk) {
        try {
          const manifest = JSON.parse(manifestContent);
          const backupId = path$1.basename(obj.Key, ".manifest.json");
          results.push({
            id: backupId,
            bucket: this.config.bucket,
            key: obj.Key.replace(".manifest.json", ".backup"),
            manifestKey: obj.Key,
            size: obj.Size,
            lastModified: obj.LastModified,
            storageClass: obj.StorageClass,
            createdAt: manifest.createdAt || obj.LastModified,
            ...manifest
          });
        } catch (parseErr) {
          this.log(`Failed to parse manifest ${obj.Key}: ${parseErr.message}`);
        }
      }
    }
    results.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
    return results;
  }
  async verify(backupId, expectedChecksum, metadata) {
    const backupKey = metadata.key || this.resolveKey(backupId, metadata);
    const [verifyOk, verifyErr] = await tryFn(async () => {
      const headResponse = await this.config.client.headObject({
        bucket: this.config.bucket,
        key: backupKey
      });
      const etag = headResponse.ETag?.replace(/"/g, "");
      if (etag && !etag.includes("-")) {
        const expectedMd5 = crypto$1.createHash("md5").update(expectedChecksum).digest("hex");
        return etag === expectedMd5;
      } else {
        const [streamOk, , stream] = await tryFn(
          () => this.config.client.getObjectStream({
            bucket: this.config.bucket,
            key: backupKey
          })
        );
        if (!streamOk) return false;
        const hash = crypto$1.createHash("sha256");
        for await (const chunk of stream) {
          hash.update(chunk);
        }
        const actualChecksum = hash.digest("hex");
        return actualChecksum === expectedChecksum;
      }
    });
    if (!verifyOk) {
      this.log(`Verification failed for ${backupId}: ${verifyErr?.message || "checksum mismatch"}`);
      return false;
    }
    return true;
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      bucket: this.config.bucket,
      path: this.config.path,
      storageClass: this.config.storageClass,
      serverSideEncryption: this.config.serverSideEncryption
    };
  }
}

class MultiBackupDriver extends BaseBackupDriver {
  constructor(config = {}) {
    super({
      destinations: [],
      strategy: "all",
      // 'all', 'any', 'priority'
      concurrency: 3,
      ...config
    });
    this.drivers = [];
  }
  getType() {
    return "multi";
  }
  async onSetup() {
    if (!Array.isArray(this.config.destinations) || this.config.destinations.length === 0) {
      throw new BackupError("MultiBackupDriver requires non-empty destinations array", {
        operation: "onSetup",
        driver: "multi",
        destinationsProvided: this.config.destinations,
        suggestion: 'Provide destinations array: { destinations: [{ driver: "s3", config: {...} }, { driver: "filesystem", config: {...} }] }'
      });
    }
    for (const [index, destConfig] of this.config.destinations.entries()) {
      if (!destConfig.driver) {
        throw new BackupError(`Destination ${index} missing driver type`, {
          operation: "onSetup",
          driver: "multi",
          destinationIndex: index,
          destination: destConfig,
          suggestion: 'Each destination must have a driver property: { driver: "s3", config: {...} } or { driver: "filesystem", config: {...} }'
        });
      }
      try {
        const driver = createBackupDriver(destConfig.driver, destConfig.config || {});
        await driver.setup(this.database);
        this.drivers.push({
          driver,
          config: destConfig,
          index
        });
        this.log(`Setup destination ${index}: ${destConfig.driver}`);
      } catch (error) {
        throw new BackupError(`Failed to setup destination ${index}`, {
          operation: "onSetup",
          driver: "multi",
          destinationIndex: index,
          destinationDriver: destConfig.driver,
          destinationConfig: destConfig.config,
          original: error,
          suggestion: "Check destination driver configuration and ensure dependencies are available"
        });
      }
    }
    if (this.config.requireAll === false) {
      this.config.strategy = "any";
    }
    this.log(`Initialized with ${this.drivers.length} destinations, strategy: ${this.config.strategy}`);
  }
  async upload(filePath, backupId, manifest) {
    const strategy = this.config.strategy;
    const errors = [];
    if (strategy === "priority") {
      for (const { driver, config, index } of this.drivers) {
        const [ok, err, result] = await tryFn(
          () => driver.upload(filePath, backupId, manifest)
        );
        if (ok) {
          this.log(`Priority upload successful to destination ${index}`);
          return [{
            ...result,
            driver: config.driver,
            destination: index,
            status: "success"
          }];
        } else {
          errors.push({ destination: index, error: err.message });
          this.log(`Priority upload failed to destination ${index}: ${err.message}`);
        }
      }
      throw new BackupError("All priority destinations failed", {
        operation: "upload",
        driver: "multi",
        strategy: "priority",
        backupId,
        totalDestinations: this.drivers.length,
        failures: errors,
        suggestion: "Check destination configurations and ensure at least one destination is accessible"
      });
    }
    const uploadPromises = this.drivers.map(async ({ driver, config, index }) => {
      const [ok, err, result] = await tryFn(
        () => driver.upload(filePath, backupId, manifest)
      );
      if (ok) {
        this.log(`Upload successful to destination ${index}`);
        return {
          ...result,
          driver: config.driver,
          destination: index,
          status: "success"
        };
      } else {
        this.log(`Upload failed to destination ${index}: ${err.message}`);
        const errorResult = {
          driver: config.driver,
          destination: index,
          status: "failed",
          error: err.message
        };
        errors.push(errorResult);
        return errorResult;
      }
    });
    const allResults = await this._executeConcurrent(uploadPromises, this.config.concurrency);
    const successResults = allResults.filter((r) => r.status === "success");
    const failedResults = allResults.filter((r) => r.status === "failed");
    if (strategy === "all" && failedResults.length > 0) {
      throw new BackupError('Some destinations failed with strategy "all"', {
        operation: "upload",
        driver: "multi",
        strategy: "all",
        backupId,
        totalDestinations: this.drivers.length,
        successCount: successResults.length,
        failedCount: failedResults.length,
        failures: failedResults,
        suggestion: 'All destinations must succeed with "all" strategy. Use "any" strategy to tolerate failures, or fix failing destinations.'
      });
    }
    if (strategy === "any" && successResults.length === 0) {
      throw new BackupError('All destinations failed with strategy "any"', {
        operation: "upload",
        driver: "multi",
        strategy: "any",
        backupId,
        totalDestinations: this.drivers.length,
        failures: failedResults,
        suggestion: 'At least one destination must succeed with "any" strategy. Check all destination configurations.'
      });
    }
    return allResults;
  }
  async download(backupId, targetPath, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, err, result] = await tryFn(
        () => driverInstance.driver.download(backupId, targetPath, destMetadata)
      );
      if (ok) {
        this.log(`Downloaded from destination ${destMetadata.destination}`);
        return result;
      } else {
        this.log(`Download failed from destination ${destMetadata.destination}: ${err.message}`);
      }
    }
    throw new BackupError("Failed to download backup from any destination", {
      operation: "download",
      driver: "multi",
      backupId,
      targetPath,
      attemptedDestinations: destinations.length,
      suggestion: "Check if backup exists in at least one destination and destinations are accessible"
    });
  }
  async delete(backupId, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    const errors = [];
    let successCount = 0;
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, err] = await tryFn(
        () => driverInstance.driver.delete(backupId, destMetadata)
      );
      if (ok) {
        successCount++;
        this.log(`Deleted from destination ${destMetadata.destination}`);
      } else {
        errors.push(`${destMetadata.destination}: ${err.message}`);
        this.log(`Delete failed from destination ${destMetadata.destination}: ${err.message}`);
      }
    }
    if (successCount === 0 && errors.length > 0) {
      throw new BackupError("Failed to delete from any destination", {
        operation: "delete",
        driver: "multi",
        backupId,
        attemptedDestinations: destinations.length,
        failures: errors,
        suggestion: "Check if backup exists in destinations and destinations are accessible with delete permissions"
      });
    }
    if (errors.length > 0) {
      this.log(`Partial delete success, some errors: ${errors.join("; ")}`);
    }
  }
  async list(options = {}) {
    const allLists = await Promise.allSettled(
      this.drivers.map(
        ({ driver, index }) => driver.list(options).catch((err) => {
          this.log(`List failed for destination ${index}: ${err.message}`);
          return [];
        })
      )
    );
    const backupMap = /* @__PURE__ */ new Map();
    allLists.forEach((result, index) => {
      if (result.status === "fulfilled") {
        result.value.forEach((backup) => {
          const existing = backupMap.get(backup.id);
          if (!existing || new Date(backup.createdAt) > new Date(existing.createdAt)) {
            backupMap.set(backup.id, {
              ...backup,
              destinations: existing ? [...existing.destinations || [], { destination: index, ...backup }] : [{ destination: index, ...backup }]
            });
          }
        });
      }
    });
    const results = Array.from(backupMap.values()).sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt)).slice(0, options.limit || 50);
    return results;
  }
  async verify(backupId, expectedChecksum, metadata) {
    const destinations = Array.isArray(metadata.destinations) ? metadata.destinations : [metadata];
    for (const destMetadata of destinations) {
      if (destMetadata.status !== "success") continue;
      const driverInstance = this.drivers.find((d) => d.index === destMetadata.destination);
      if (!driverInstance) continue;
      const [ok, , isValid] = await tryFn(
        () => driverInstance.driver.verify(backupId, expectedChecksum, destMetadata)
      );
      if (ok && isValid) {
        this.log(`Verification successful from destination ${destMetadata.destination}`);
        return true;
      }
    }
    return false;
  }
  async cleanup() {
    await Promise.all(
      this.drivers.map(
        ({ driver }) => tryFn(() => driver.cleanup()).catch(() => {
        })
      )
    );
  }
  getStorageInfo() {
    return {
      ...super.getStorageInfo(),
      strategy: this.config.strategy,
      destinations: this.drivers.map(({ driver, config, index }) => ({
        index,
        driver: config.driver,
        info: driver.getStorageInfo()
      }))
    };
  }
  /**
   * Execute promises with concurrency limit
   * @param {Array} promises - Array of promise functions
   * @param {number} concurrency - Max concurrent executions
   * @returns {Array} Results in original order
   */
  async _executeConcurrent(promises, concurrency) {
    const results = new Array(promises.length);
    const executing = [];
    for (let i = 0; i < promises.length; i++) {
      const promise = Promise.resolve(promises[i]).then((result) => {
        results[i] = result;
        return result;
      });
      executing.push(promise);
      if (executing.length >= concurrency) {
        await Promise.race(executing);
        executing.splice(executing.findIndex((p) => p === promise), 1);
      }
    }
    await Promise.all(executing);
    return results;
  }
}

const BACKUP_DRIVERS = {
  filesystem: FilesystemBackupDriver,
  s3: S3BackupDriver,
  multi: MultiBackupDriver
};
function createBackupDriver(driver, config = {}) {
  const DriverClass = BACKUP_DRIVERS[driver];
  if (!DriverClass) {
    throw new BackupError(`Unknown backup driver: ${driver}`, {
      operation: "createBackupDriver",
      driver,
      availableDrivers: Object.keys(BACKUP_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(BACKUP_DRIVERS).join(", ")}`
    });
  }
  return new DriverClass(config);
}
function validateBackupConfig(driver, config = {}) {
  if (!driver || typeof driver !== "string") {
    throw new BackupError("Driver type must be a non-empty string", {
      operation: "validateBackupConfig",
      driver,
      suggestion: "Provide a valid driver type string (filesystem, s3, or multi)"
    });
  }
  if (!BACKUP_DRIVERS[driver]) {
    throw new BackupError(`Unknown backup driver: ${driver}`, {
      operation: "validateBackupConfig",
      driver,
      availableDrivers: Object.keys(BACKUP_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(BACKUP_DRIVERS).join(", ")}`
    });
  }
  switch (driver) {
    case "filesystem":
      if (!config.path) {
        throw new BackupError('FilesystemBackupDriver requires "path" configuration', {
          operation: "validateBackupConfig",
          driver: "filesystem",
          config,
          suggestion: 'Provide a "path" property in config: { path: "/path/to/backups" }'
        });
      }
      break;
    case "s3":
      break;
    case "multi":
      if (!Array.isArray(config.destinations) || config.destinations.length === 0) {
        throw new BackupError('MultiBackupDriver requires non-empty "destinations" array', {
          operation: "validateBackupConfig",
          driver: "multi",
          config,
          suggestion: 'Provide destinations array: { destinations: [{ driver: "s3", config: {...} }] }'
        });
      }
      config.destinations.forEach((dest, index) => {
        if (!dest.driver) {
          throw new BackupError(`Destination ${index} must have a "driver" property`, {
            operation: "validateBackupConfig",
            driver: "multi",
            destinationIndex: index,
            destination: dest,
            suggestion: 'Each destination must have a driver property: { driver: "s3", config: {...} }'
          });
        }
        if (dest.driver !== "multi") {
          validateBackupConfig(dest.driver, dest.config || {});
        }
      });
      break;
  }
  return true;
}

class StreamingExporter {
  constructor(options = {}) {
    this.encoding = options.encoding || "utf8";
    this.compress = options.compress !== false;
    this.batchSize = options.batchSize || 100;
    this.onProgress = options.onProgress || null;
  }
  /**
   * Export single resource to JSONL file
   *
   * @param {Resource} resource - S3DB resource
   * @param {string} outputPath - Output file path
   * @param {string} type - Export type ('full' or 'incremental')
   * @param {Date} sinceTimestamp - For incremental backups
   * @returns {Promise<{recordCount: number, bytesWritten: number}>}
   */
  async exportResource(resource, outputPath, type = "full", sinceTimestamp = null) {
    let recordCount = 0;
    let bytesWritten = 0;
    const writeStream = createWriteStream(outputPath);
    let outputStream = writeStream;
    if (this.compress) {
      const gzipStream = zlib.createGzip();
      gzipStream.pipe(writeStream);
      outputStream = gzipStream;
    }
    try {
      let records;
      if (type === "incremental" && sinceTimestamp) {
        records = await resource.list({
          filter: { updatedAt: { ">": sinceTimestamp.toISOString() } }
        });
      } else {
        records = await resource.list();
      }
      for (const record of records) {
        const line = JSON.stringify(record) + "\n";
        const canWrite = outputStream.write(line, this.encoding);
        recordCount++;
        bytesWritten += Buffer.byteLength(line, this.encoding);
        if (this.onProgress && recordCount % 1e3 === 0) {
          this.onProgress({
            resourceName: resource.name,
            recordCount,
            bytesWritten
          });
        }
        if (!canWrite) {
          await new Promise((resolve) => outputStream.once("drain", resolve));
        }
      }
      outputStream.end();
      await new Promise((resolve, reject) => {
        writeStream.on("finish", resolve);
        writeStream.on("error", reject);
      });
      return { recordCount, bytesWritten };
    } catch (error) {
      outputStream.destroy();
      throw error;
    }
  }
  /**
   * Export multiple resources
   *
   * @param {Object} resources - Map of resource name -> resource
   * @param {string} outputDir - Output directory
   * @param {string} type - Export type
   * @param {Date} sinceTimestamp - For incremental
   * @returns {Promise<Map<string, {recordCount, bytesWritten}>>}
   */
  async exportResources(resources, outputDir, type = "full", sinceTimestamp = null) {
    const results = /* @__PURE__ */ new Map();
    for (const [resourceName, resource] of Object.entries(resources)) {
      const ext = this.compress ? ".jsonl.gz" : ".jsonl";
      const outputPath = `${outputDir}/${resourceName}${ext}`;
      const stats = await this.exportResource(resource, outputPath, type, sinceTimestamp);
      results.set(resourceName, {
        ...stats,
        filePath: outputPath,
        compressed: this.compress
      });
    }
    return results;
  }
}

class BackupPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      // Driver configuration
      driver: options.driver || "filesystem",
      driverConfig: options.config || {},
      // Scheduling configuration
      schedule: options.schedule || {},
      // Retention policy (Grandfather-Father-Son)
      retention: {
        daily: 7,
        weekly: 4,
        monthly: 12,
        yearly: 3,
        ...options.retention
      },
      // Backup options
      compression: options.compression || "gzip",
      encryption: options.encryption || null,
      verification: options.verification !== false,
      parallelism: options.parallelism || 4,
      include: options.include || null,
      exclude: options.exclude || [],
      backupMetadataResource: options.backupMetadataResource || "plg_backup_metadata",
      tempDir: options.tempDir || path$1.join(os.tmpdir(), "s3db", "backups"),
      verbose: options.verbose || false,
      // Hooks
      onBackupStart: options.onBackupStart || null,
      onBackupComplete: options.onBackupComplete || null,
      onBackupError: options.onBackupError || null,
      onRestoreStart: options.onRestoreStart || null,
      onRestoreComplete: options.onRestoreComplete || null,
      onRestoreError: options.onRestoreError || null
    };
    this.driver = null;
    this.activeBackups = /* @__PURE__ */ new Set();
    validateBackupConfig(this.config.driver, this.config.driverConfig);
    this._validateConfiguration();
  }
  _validateConfiguration() {
    if (this.config.encryption && (!this.config.encryption.key || !this.config.encryption.algorithm)) {
      throw new Error("BackupPlugin: Encryption requires both key and algorithm");
    }
    if (this.config.compression && !["none", "gzip", "brotli", "deflate"].includes(this.config.compression)) {
      throw new Error("BackupPlugin: Invalid compression type. Use: none, gzip, brotli, deflate");
    }
  }
  async onInstall() {
    this.driver = createBackupDriver(this.config.driver, this.config.driverConfig);
    await this.driver.setup(this.database);
    await mkdir(this.config.tempDir, { recursive: true });
    await this._createBackupMetadataResource();
    if (this.config.verbose) {
      const storageInfo = this.driver.getStorageInfo();
      console.log(`[BackupPlugin] Initialized with driver: ${storageInfo.type}`);
    }
    this.emit("db:plugin:initialized", {
      driver: this.driver.getType(),
      config: this.driver.getStorageInfo()
    });
  }
  async _createBackupMetadataResource() {
    const [ok] = await tryFn(() => this.database.createResource({
      name: this.config.backupMetadataResource,
      attributes: {
        id: "string|required",
        type: "string|required",
        timestamp: "number|required",
        resources: "json|required",
        driverInfo: "json|required",
        // Store driver info instead of destinations
        size: "number|default:0",
        compressed: "boolean|default:false",
        encrypted: "boolean|default:false",
        checksum: "string|default:null",
        status: "string|required",
        error: "string|default:null",
        duration: "number|default:0",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: true
    }));
    if (!ok && this.config.verbose) {
      console.log(`[BackupPlugin] Backup metadata resource '${this.config.backupMetadataResource}' already exists`);
    }
  }
  /**
   * Create a backup
   * @param {string} type - Backup type ('full' or 'incremental')
   * @param {Object} options - Backup options
   * @returns {Object} Backup result
   */
  async backup(type = "full", options = {}) {
    const backupId = this._generateBackupId(type);
    const startTime = Date.now();
    if (this.activeBackups.has(backupId)) {
      throw new Error(`Backup '${backupId}' is already in progress`);
    }
    try {
      this.activeBackups.add(backupId);
      if (this.config.onBackupStart) {
        await this._executeHook(this.config.onBackupStart, type, { backupId });
      }
      this.emit("plg:backup:start", { id: backupId, type });
      const metadata = await this._createBackupMetadata(backupId, type);
      const tempBackupDir = path$1.join(this.config.tempDir, backupId);
      await mkdir(tempBackupDir, { recursive: true });
      try {
        const manifest = await this._createBackupManifest(type, options);
        const exportedFiles = await this._exportResources(manifest.resources, tempBackupDir, type);
        if (exportedFiles.length === 0) {
          throw new Error("No resources were exported for backup");
        }
        const archiveExtension = this.config.compression !== "none" ? ".tar.gz" : ".json";
        const finalPath = path$1.join(tempBackupDir, `${backupId}${archiveExtension}`);
        const totalSize = await this._createArchive(exportedFiles, finalPath, this.config.compression);
        const checksum = await this._generateChecksum(finalPath);
        const uploadResult = await this.driver.upload(finalPath, backupId, manifest);
        if (this.config.verification) {
          const isValid = await this.driver.verify(backupId, checksum, uploadResult);
          if (!isValid) {
            throw new Error("Backup verification failed");
          }
        }
        const duration = Date.now() - startTime;
        await this._updateBackupMetadata(backupId, {
          status: "completed",
          size: totalSize,
          checksum,
          driverInfo: uploadResult,
          duration
        });
        if (this.config.onBackupComplete) {
          const stats = { backupId, type, size: totalSize, duration, driverInfo: uploadResult };
          await this._executeHook(this.config.onBackupComplete, type, stats);
        }
        this.emit("plg:backup:complete", {
          id: backupId,
          type,
          size: totalSize,
          duration,
          driverInfo: uploadResult
        });
        await this._cleanupOldBackups();
        return {
          id: backupId,
          type,
          size: totalSize,
          duration,
          checksum,
          driverInfo: uploadResult
        };
      } finally {
        await this._cleanupTempFiles(tempBackupDir);
      }
    } catch (error) {
      if (this.config.onBackupError) {
        await this._executeHook(this.config.onBackupError, type, { backupId, error });
      }
      await this._updateBackupMetadata(backupId, {
        status: "failed",
        error: error.message,
        duration: Date.now() - startTime
      });
      this.emit("plg:backup:error", { id: backupId, type, error: error.message });
      throw error;
    } finally {
      this.activeBackups.delete(backupId);
    }
  }
  _generateBackupId(type) {
    const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
    const random = Math.random().toString(36).substring(2, 8);
    return `${type}-${timestamp}-${random}`;
  }
  async _createBackupMetadata(backupId, type) {
    const now = /* @__PURE__ */ new Date();
    const metadata = {
      id: backupId,
      type,
      timestamp: Date.now(),
      resources: [],
      driverInfo: {},
      size: 0,
      status: "in_progress",
      compressed: this.config.compression !== "none",
      encrypted: !!this.config.encryption,
      checksum: null,
      error: null,
      duration: 0,
      createdAt: now.toISOString().slice(0, 10)
    };
    const [ok] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].insert(metadata)
    );
    return metadata;
  }
  async _updateBackupMetadata(backupId, updates) {
    const [ok] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].update(backupId, updates)
    );
  }
  async _createBackupManifest(type, options) {
    let resourcesToBackup = options.resources || (this.config.include ? this.config.include : await this.database.listResources());
    if (Array.isArray(resourcesToBackup) && resourcesToBackup.length > 0 && typeof resourcesToBackup[0] === "object") {
      resourcesToBackup = resourcesToBackup.map((resource) => resource.name || resource);
    }
    const filteredResources = resourcesToBackup.filter(
      (name) => !this.config.exclude.includes(name)
    );
    return {
      type,
      timestamp: Date.now(),
      resources: filteredResources,
      compression: this.config.compression,
      encrypted: !!this.config.encryption,
      s3db_version: this.database.constructor.version || "unknown"
    };
  }
  async _exportResources(resourceNames, tempDir, type) {
    const exportedFiles = [];
    const resourceStats = /* @__PURE__ */ new Map();
    const exporter = new StreamingExporter({
      compress: true,
      // Always use gzip for backups
      onProgress: this.config.verbose ? (stats) => {
        if (stats.recordCount % 1e4 === 0) {
          console.log(`[BackupPlugin] Exported ${stats.recordCount} records from '${stats.resourceName}'`);
        }
      } : null
    });
    let sinceTimestamp = null;
    if (type === "incremental") {
      const [lastBackupOk, , lastBackups] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          filter: {
            status: "completed",
            type: { $in: ["full", "incremental"] }
          },
          sort: { timestamp: -1 },
          limit: 1
        })
      );
      if (lastBackupOk && lastBackups && lastBackups.length > 0) {
        sinceTimestamp = new Date(lastBackups[0].timestamp);
      } else {
        sinceTimestamp = new Date(Date.now() - 24 * 60 * 60 * 1e3);
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Incremental backup since ${sinceTimestamp.toISOString()}`);
      }
    }
    for (const resourceName of resourceNames) {
      const resource = this.database.resources[resourceName];
      if (!resource) {
        if (this.config.verbose) {
          console.warn(`[BackupPlugin] Resource '${resourceName}' not found, skipping`);
        }
        continue;
      }
      const exportPath = path$1.join(tempDir, `${resourceName}.jsonl.gz`);
      try {
        const stats = await exporter.exportResource(resource, exportPath, type, sinceTimestamp);
        exportedFiles.push(exportPath);
        resourceStats.set(resourceName, {
          ...stats,
          definition: resource.config
        });
        if (this.config.verbose) {
          console.log(
            `[BackupPlugin] Exported ${stats.recordCount} records from '${resourceName}' (${(stats.bytesWritten / 1024 / 1024).toFixed(2)} MB compressed)`
          );
        }
      } catch (error) {
        if (this.config.verbose) {
          console.error(`[BackupPlugin] Error exporting '${resourceName}': ${error.message}`);
        }
        throw error;
      }
    }
    await this._generateMetadataFile(tempDir, resourceStats, type);
    exportedFiles.push(path$1.join(tempDir, "s3db.json"));
    return exportedFiles;
  }
  /**
   * Generate s3db.json metadata file
   */
  async _generateMetadataFile(tempDir, resourceStats, type) {
    const metadata = {
      version: "1.0",
      backupType: type,
      exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
      database: {
        bucket: this.database.bucket,
        region: this.database.region
      },
      resources: {}
    };
    for (const [resourceName, stats] of resourceStats.entries()) {
      metadata.resources[resourceName] = {
        name: resourceName,
        attributes: stats.definition.attributes || {},
        partitions: stats.definition.partitions || {},
        timestamps: stats.definition.timestamps || false,
        recordCount: stats.recordCount,
        exportFile: `${resourceName}.jsonl.gz`,
        compression: "gzip",
        format: "jsonl",
        bytesWritten: stats.bytesWritten
      };
    }
    const metadataPath = path$1.join(tempDir, "s3db.json");
    await writeFile(metadataPath, JSON.stringify(metadata, null, 2));
    if (this.config.verbose) {
      console.log(`[BackupPlugin] Generated s3db.json metadata`);
    }
  }
  async _createArchive(files, targetPath, compressionType) {
    const archive = {
      version: "1.0",
      created: (/* @__PURE__ */ new Date()).toISOString(),
      files: []
    };
    let totalSize = 0;
    for (const filePath of files) {
      const [readOk, readErr, content] = await tryFn(() => readFile$1(filePath, "utf8"));
      if (!readOk) {
        if (this.config.verbose) {
          console.warn(`[BackupPlugin] Failed to read ${filePath}: ${readErr?.message}`);
        }
        continue;
      }
      const fileName = path$1.basename(filePath);
      totalSize += content.length;
      archive.files.push({
        name: fileName,
        size: content.length,
        content
      });
    }
    const archiveJson = JSON.stringify(archive);
    if (compressionType === "none") {
      await writeFile(targetPath, archiveJson, "utf8");
    } else {
      const output = createWriteStream(targetPath);
      const gzip = zlib.createGzip({ level: 6 });
      await pipeline(
        async function* () {
          yield Buffer.from(archiveJson, "utf8");
        },
        gzip,
        output
      );
    }
    const [statOk, , stats] = await tryFn(() => stat(targetPath));
    return statOk ? stats.size : totalSize;
  }
  async _generateChecksum(filePath) {
    const [ok, err, result] = await tryFn(async () => {
      const hash = crypto$1.createHash("sha256");
      const stream = createReadStream(filePath);
      await pipeline(stream, hash);
      return hash.digest("hex");
    });
    if (!ok) {
      throw new Error(`Failed to generate checksum for ${filePath}: ${err?.message}`);
    }
    return result;
  }
  async _cleanupTempFiles(tempDir) {
    const [ok] = await tryFn(
      () => import('fs/promises').then((fs) => fs.rm(tempDir, { recursive: true, force: true }))
    );
  }
  /**
   * Restore from backup
   * @param {string} backupId - Backup identifier
   * @param {Object} options - Restore options
   * @returns {Object} Restore result
   */
  async restore(backupId, options = {}) {
    try {
      if (this.config.onRestoreStart) {
        await this._executeHook(this.config.onRestoreStart, backupId, options);
      }
      this.emit("plg:backup:restore-start", { id: backupId, options });
      const backup = await this.getBackupStatus(backupId);
      if (!backup) {
        throw new Error(`Backup '${backupId}' not found`);
      }
      if (backup.status !== "completed") {
        throw new Error(`Backup '${backupId}' is not in completed status`);
      }
      const tempRestoreDir = path$1.join(this.config.tempDir, `restore-${backupId}`);
      await mkdir(tempRestoreDir, { recursive: true });
      try {
        const downloadPath = path$1.join(tempRestoreDir, `${backupId}.backup`);
        await this.driver.download(backupId, downloadPath, backup.driverInfo);
        if (this.config.verification && backup.checksum) {
          const actualChecksum = await this._generateChecksum(downloadPath);
          if (actualChecksum !== backup.checksum) {
            throw new Error("Backup verification failed during restore");
          }
        }
        const restoredResources = await this._restoreFromBackup(downloadPath, options);
        if (this.config.onRestoreComplete) {
          await this._executeHook(this.config.onRestoreComplete, backupId, { restored: restoredResources });
        }
        this.emit("plg:backup:restore-complete", {
          id: backupId,
          restored: restoredResources
        });
        return {
          backupId,
          restored: restoredResources
        };
      } finally {
        await this._cleanupTempFiles(tempRestoreDir);
      }
    } catch (error) {
      if (this.config.onRestoreError) {
        await this._executeHook(this.config.onRestoreError, backupId, { error });
      }
      this.emit("plg:backup:restore-error", { id: backupId, error: error.message });
      throw error;
    }
  }
  async _restoreFromBackup(backupPath, options) {
    const restoredResources = [];
    try {
      let archiveData = "";
      if (this.config.compression !== "none") {
        const input = createReadStream(backupPath);
        const gunzip = zlib.createGunzip();
        const chunks = [];
        await new Promise((resolve, reject) => {
          input.pipe(gunzip).on("data", (chunk) => chunks.push(chunk)).on("end", resolve).on("error", reject);
        });
        archiveData = Buffer.concat(chunks).toString("utf8");
      } else {
        archiveData = await readFile$1(backupPath, "utf8");
      }
      let archive;
      try {
        archive = JSON.parse(archiveData);
      } catch (parseError) {
        throw new Error(`Failed to parse backup archive: ${parseError.message}`);
      }
      if (!archive || typeof archive !== "object") {
        throw new Error("Invalid backup archive: not a valid JSON object");
      }
      if (!archive.version || !archive.files) {
        throw new Error("Invalid backup archive format: missing version or files array");
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Restoring ${archive.files.length} files from backup`);
      }
      for (const file of archive.files) {
        try {
          const resourceData = JSON.parse(file.content);
          if (!resourceData.resourceName || !resourceData.definition) {
            if (this.config.verbose) {
              console.warn(`[BackupPlugin] Skipping invalid file: ${file.name}`);
            }
            continue;
          }
          const resourceName = resourceData.resourceName;
          if (options.resources && !options.resources.includes(resourceName)) {
            continue;
          }
          let resource = this.database.resources[resourceName];
          if (!resource) {
            if (this.config.verbose) {
              console.log(`[BackupPlugin] Creating resource '${resourceName}'`);
            }
            const [createOk, createErr] = await tryFn(
              () => this.database.createResource(resourceData.definition)
            );
            if (!createOk) {
              if (this.config.verbose) {
                console.warn(`[BackupPlugin] Failed to create resource '${resourceName}': ${createErr?.message}`);
              }
              continue;
            }
            resource = this.database.resources[resourceName];
          }
          if (resourceData.records && Array.isArray(resourceData.records)) {
            const mode = options.mode || "merge";
            if (mode === "replace") {
              const ids = await resource.listIds();
              for (const id of ids) {
                await resource.delete(id);
              }
            }
            let insertedCount = 0;
            for (const record of resourceData.records) {
              const [insertOk] = await tryFn(async () => {
                if (mode === "skip") {
                  const existing = await resource.get(record.id);
                  if (existing) {
                    return false;
                  }
                }
                await resource.insert(record);
                return true;
              });
              if (insertOk) {
                insertedCount++;
              }
            }
            restoredResources.push({
              name: resourceName,
              recordsRestored: insertedCount,
              totalRecords: resourceData.records.length
            });
            if (this.config.verbose) {
              console.log(`[BackupPlugin] Restored ${insertedCount}/${resourceData.records.length} records to '${resourceName}'`);
            }
          }
        } catch (fileError) {
          if (this.config.verbose) {
            console.warn(`[BackupPlugin] Error processing file ${file.name}: ${fileError.message}`);
          }
        }
      }
      return restoredResources;
    } catch (error) {
      if (this.config.verbose) {
        console.error(`[BackupPlugin] Error restoring backup: ${error.message}`);
      }
      throw new Error(`Failed to restore backup: ${error.message}`);
    }
  }
  /**
   * List available backups
   * @param {Object} options - List options
   * @returns {Array} List of backups
   */
  async listBackups(options = {}) {
    try {
      const driverBackups = await this.driver.list(options);
      const [metaOk, , metadataRecords] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          limit: options.limit || 50,
          sort: { timestamp: -1 }
        })
      );
      const metadataMap = /* @__PURE__ */ new Map();
      if (metaOk) {
        metadataRecords.forEach((record) => metadataMap.set(record.id, record));
      }
      const combinedBackups = driverBackups.map((backup) => ({
        ...backup,
        ...metadataMap.get(backup.id) || {}
      }));
      return combinedBackups;
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Error listing backups: ${error.message}`);
      }
      return [];
    }
  }
  /**
   * Get backup status
   * @param {string} backupId - Backup identifier
   * @returns {Object|null} Backup status
   */
  async getBackupStatus(backupId) {
    const [ok, , backup] = await tryFn(
      () => this.database.resources[this.config.backupMetadataResource].get(backupId)
    );
    return ok ? backup : null;
  }
  async _cleanupOldBackups() {
    try {
      const [listOk, , allBackups] = await tryFn(
        () => this.database.resources[this.config.backupMetadataResource].list({
          filter: { status: "completed" },
          sort: { timestamp: -1 }
        })
      );
      if (!listOk || !allBackups || allBackups.length === 0) {
        return;
      }
      const now = Date.now();
      const msPerDay = 24 * 60 * 60 * 1e3;
      const msPerWeek = 7 * msPerDay;
      const msPerMonth = 30 * msPerDay;
      const msPerYear = 365 * msPerDay;
      const categorized = {
        daily: [],
        weekly: [],
        monthly: [],
        yearly: []
      };
      for (const backup of allBackups) {
        const age = now - backup.timestamp;
        if (age <= msPerDay * this.config.retention.daily) {
          categorized.daily.push(backup);
        } else if (age <= msPerWeek * this.config.retention.weekly) {
          categorized.weekly.push(backup);
        } else if (age <= msPerMonth * this.config.retention.monthly) {
          categorized.monthly.push(backup);
        } else if (age <= msPerYear * this.config.retention.yearly) {
          categorized.yearly.push(backup);
        }
      }
      const toKeep = /* @__PURE__ */ new Set();
      categorized.daily.forEach((b) => toKeep.add(b.id));
      const weeklyByWeek = /* @__PURE__ */ new Map();
      for (const backup of categorized.weekly) {
        const weekNum = Math.floor((now - backup.timestamp) / msPerWeek);
        if (!weeklyByWeek.has(weekNum)) {
          weeklyByWeek.set(weekNum, backup);
          toKeep.add(backup.id);
        }
      }
      const monthlyByMonth = /* @__PURE__ */ new Map();
      for (const backup of categorized.monthly) {
        const monthNum = Math.floor((now - backup.timestamp) / msPerMonth);
        if (!monthlyByMonth.has(monthNum)) {
          monthlyByMonth.set(monthNum, backup);
          toKeep.add(backup.id);
        }
      }
      const yearlyByYear = /* @__PURE__ */ new Map();
      for (const backup of categorized.yearly) {
        const yearNum = Math.floor((now - backup.timestamp) / msPerYear);
        if (!yearlyByYear.has(yearNum)) {
          yearlyByYear.set(yearNum, backup);
          toKeep.add(backup.id);
        }
      }
      const backupsToDelete = allBackups.filter((b) => !toKeep.has(b.id));
      if (backupsToDelete.length === 0) {
        return;
      }
      if (this.config.verbose) {
        console.log(`[BackupPlugin] Cleaning up ${backupsToDelete.length} old backups (keeping ${toKeep.size})`);
      }
      for (const backup of backupsToDelete) {
        try {
          await this.driver.delete(backup.id, backup.driverInfo);
          await this.database.resources[this.config.backupMetadataResource].delete(backup.id);
          if (this.config.verbose) {
            console.log(`[BackupPlugin] Deleted old backup: ${backup.id}`);
          }
        } catch (deleteError) {
          if (this.config.verbose) {
            console.warn(`[BackupPlugin] Failed to delete backup ${backup.id}: ${deleteError.message}`);
          }
        }
      }
    } catch (error) {
      if (this.config.verbose) {
        console.warn(`[BackupPlugin] Error during cleanup: ${error.message}`);
      }
    }
  }
  async _executeHook(hook, ...args) {
    if (typeof hook === "function") {
      return await hook(...args);
    }
  }
  async start() {
    if (this.config.verbose) {
      const storageInfo = this.driver.getStorageInfo();
      console.log(`[BackupPlugin] Started with driver: ${storageInfo.type}`);
    }
  }
  async stop() {
    for (const backupId of this.activeBackups) {
      this.emit("plg:backup:cancelled", { id: backupId });
    }
    this.activeBackups.clear();
    if (this.driver) {
      await this.driver.cleanup();
    }
  }
}

class CacheError extends S3dbError {
  constructor(message, details = {}) {
    const { driver = "unknown", operation = "unknown", resourceName, key, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Cache Operation Error

Driver: ${driver}
Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}
${key ? `Key: ${key}` : ""}

Common causes:
1. Invalid cache key format
2. Cache driver not properly initialized
3. Resource not found or not cached
4. Memory limits exceeded
5. Filesystem permissions issues

Solution:
Check cache configuration and ensure the cache driver is properly initialized.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/cache.md
`.trim();
    }
    super(message, { ...rest, driver, operation, resourceName, key, description });
  }
}

class Cache extends EventEmitter {
  constructor(config = {}) {
    super();
    this.config = config;
  }
  // to implement:
  async _set(key, data) {
  }
  async _get(key) {
  }
  async _del(key) {
  }
  async _clear(key) {
  }
  validateKey(key) {
    if (key === null || key === void 0 || typeof key !== "string" || !key) {
      throw new CacheError("Invalid cache key", {
        operation: "validateKey",
        driver: this.constructor.name,
        key,
        keyType: typeof key,
        suggestion: "Cache key must be a non-empty string"
      });
    }
  }
  // generic class methods
  async set(key, data) {
    this.validateKey(key);
    await this._set(key, data);
    this.emit("set", data);
    return data;
  }
  async get(key) {
    this.validateKey(key);
    const data = await this._get(key);
    this.emit("fetched", data);
    return data;
  }
  async del(key) {
    this.validateKey(key);
    const data = await this._del(key);
    this.emit("deleted", data);
    return data;
  }
  async delete(key) {
    return this.del(key);
  }
  async clear(prefix) {
    const data = await this._clear(prefix);
    this.emit("clear", data);
    return data;
  }
}

class S3Cache extends Cache {
  constructor({
    client,
    keyPrefix = "cache",
    ttl = 0,
    prefix = void 0,
    enableCompression = true,
    compressionThreshold = 1024
  }) {
    super();
    this.client = client;
    this.keyPrefix = keyPrefix;
    this.config.ttl = ttl;
    this.config.client = client;
    this.config.prefix = prefix !== void 0 ? prefix : keyPrefix + (keyPrefix.endsWith("/") ? "" : "/");
    this.config.enableCompression = enableCompression;
    this.config.compressionThreshold = compressionThreshold;
    this.storage = new PluginStorage(client, "cache");
  }
  /**
   * Compress data if enabled and above threshold
   * @private
   */
  _compressData(data) {
    const jsonString = JSON.stringify(data);
    if (!this.config.enableCompression || jsonString.length < this.config.compressionThreshold) {
      return {
        data: jsonString,
        compressed: false,
        originalSize: jsonString.length
      };
    }
    const compressed = zlib.gzipSync(jsonString).toString("base64");
    return {
      data: compressed,
      compressed: true,
      originalSize: jsonString.length,
      compressedSize: compressed.length,
      compressionRatio: (compressed.length / jsonString.length).toFixed(2)
    };
  }
  /**
   * Decompress data if needed
   * @private
   */
  _decompressData(storedData) {
    if (!storedData || !storedData.compressed) {
      return storedData && storedData.data ? JSON.parse(storedData.data) : null;
    }
    const buffer = Buffer.from(storedData.data, "base64");
    const decompressed = zlib.unzipSync(buffer).toString();
    return JSON.parse(decompressed);
  }
  async _set(key, data) {
    const compressed = this._compressData(data);
    return this.storage.set(
      this.storage.getPluginKey(null, this.keyPrefix, key),
      compressed,
      {
        ttl: this.config.ttl,
        behavior: "body-only",
        // Compressed data is already optimized, skip metadata encoding
        contentType: compressed.compressed ? "application/gzip" : "application/json"
      }
    );
  }
  async _get(key) {
    const storedData = await this.storage.get(
      this.storage.getPluginKey(null, this.keyPrefix, key)
    );
    if (!storedData) return null;
    return this._decompressData(storedData);
  }
  async _del(key) {
    await this.storage.delete(
      this.storage.getPluginKey(null, this.keyPrefix, key)
    );
    return true;
  }
  async _clear() {
    const pluginPrefix = `plugin=cache/${this.keyPrefix}`;
    const allKeys = await this.client.getAllKeys({ prefix: pluginPrefix });
    for (const key of allKeys) {
      await this.storage.delete(key);
    }
  }
  async size() {
    const keys = await this.keys();
    return keys.length;
  }
  async keys() {
    const pluginPrefix = `plugin=cache/${this.keyPrefix}`;
    const allKeys = await this.client.getAllKeys({ prefix: pluginPrefix });
    const prefixToRemove = `plugin=cache/${this.keyPrefix}/`;
    return allKeys.map((k) => k.startsWith(prefixToRemove) ? k.slice(prefixToRemove.length) : k);
  }
}

class MemoryCache extends Cache {
  constructor(config = {}) {
    super(config);
    this.cache = {};
    this.meta = {};
    this.maxSize = config.maxSize !== void 0 ? config.maxSize : 1e3;
    if (config.maxMemoryBytes && config.maxMemoryBytes > 0 && config.maxMemoryPercent && config.maxMemoryPercent > 0) {
      throw new Error(
        "[MemoryCache] Cannot use both maxMemoryBytes and maxMemoryPercent. Choose one: maxMemoryBytes (absolute) or maxMemoryPercent (0...1 fraction)."
      );
    }
    if (config.maxMemoryPercent && config.maxMemoryPercent > 0) {
      if (config.maxMemoryPercent > 1) {
        throw new Error(
          `[MemoryCache] maxMemoryPercent must be between 0 and 1 (e.g., 0.1 for 10%). Received: ${config.maxMemoryPercent}`
        );
      }
      const totalMemory = os$1.totalmem();
      this.maxMemoryBytes = Math.floor(totalMemory * config.maxMemoryPercent);
      this.maxMemoryPercent = config.maxMemoryPercent;
    } else {
      this.maxMemoryBytes = config.maxMemoryBytes !== void 0 ? config.maxMemoryBytes : 0;
      this.maxMemoryPercent = 0;
    }
    this.ttl = config.ttl !== void 0 ? config.ttl : 3e5;
    this.enableCompression = config.enableCompression !== void 0 ? config.enableCompression : false;
    this.compressionThreshold = config.compressionThreshold !== void 0 ? config.compressionThreshold : 1024;
    this.compressionStats = {
      totalCompressed: 0,
      totalOriginalSize: 0,
      totalCompressedSize: 0,
      compressionRatio: 0
    };
    this.currentMemoryBytes = 0;
    this.evictedDueToMemory = 0;
  }
  async _set(key, data) {
    let finalData = data;
    let compressed = false;
    let originalSize = 0;
    let compressedSize = 0;
    const serialized = JSON.stringify(data);
    originalSize = Buffer.byteLength(serialized, "utf8");
    if (this.enableCompression) {
      try {
        if (originalSize >= this.compressionThreshold) {
          const compressedBuffer = zlib.gzipSync(Buffer.from(serialized, "utf8"));
          finalData = {
            __compressed: true,
            __data: compressedBuffer.toString("base64"),
            __originalSize: originalSize
          };
          compressedSize = Buffer.byteLength(finalData.__data, "utf8");
          compressed = true;
          this.compressionStats.totalCompressed++;
          this.compressionStats.totalOriginalSize += originalSize;
          this.compressionStats.totalCompressedSize += compressedSize;
          this.compressionStats.compressionRatio = (this.compressionStats.totalCompressedSize / this.compressionStats.totalOriginalSize).toFixed(2);
        }
      } catch (error) {
        console.warn(`[MemoryCache] Compression failed for key '${key}':`, error.message);
      }
    }
    const itemSize = compressed ? compressedSize : originalSize;
    if (Object.prototype.hasOwnProperty.call(this.cache, key)) {
      const oldSize = this.meta[key]?.compressedSize || 0;
      this.currentMemoryBytes -= oldSize;
    }
    if (this.maxMemoryBytes > 0) {
      while (this.currentMemoryBytes + itemSize > this.maxMemoryBytes && Object.keys(this.cache).length > 0) {
        const oldestKey = Object.entries(this.meta).sort((a, b) => a[1].ts - b[1].ts)[0]?.[0];
        if (oldestKey) {
          const evictedSize = this.meta[oldestKey]?.compressedSize || 0;
          delete this.cache[oldestKey];
          delete this.meta[oldestKey];
          this.currentMemoryBytes -= evictedSize;
          this.evictedDueToMemory++;
        } else {
          break;
        }
      }
    }
    if (this.maxSize > 0 && Object.keys(this.cache).length >= this.maxSize) {
      const oldestKey = Object.entries(this.meta).sort((a, b) => a[1].ts - b[1].ts)[0]?.[0];
      if (oldestKey) {
        const evictedSize = this.meta[oldestKey]?.compressedSize || 0;
        delete this.cache[oldestKey];
        delete this.meta[oldestKey];
        this.currentMemoryBytes -= evictedSize;
      }
    }
    this.cache[key] = finalData;
    this.meta[key] = {
      ts: Date.now(),
      compressed,
      originalSize,
      compressedSize: itemSize
    };
    this.currentMemoryBytes += itemSize;
    return data;
  }
  async _get(key) {
    if (!Object.prototype.hasOwnProperty.call(this.cache, key)) return null;
    if (this.ttl > 0) {
      const now = Date.now();
      const meta = this.meta[key];
      if (meta && now - meta.ts > this.ttl) {
        const itemSize = meta.compressedSize || 0;
        this.currentMemoryBytes -= itemSize;
        delete this.cache[key];
        delete this.meta[key];
        return null;
      }
    }
    const rawData = this.cache[key];
    if (rawData && typeof rawData === "object" && rawData.__compressed) {
      try {
        const compressedBuffer = Buffer.from(rawData.__data, "base64");
        const decompressed = zlib.gunzipSync(compressedBuffer).toString("utf8");
        return JSON.parse(decompressed);
      } catch (error) {
        console.warn(`[MemoryCache] Decompression failed for key '${key}':`, error.message);
        delete this.cache[key];
        delete this.meta[key];
        return null;
      }
    }
    return rawData;
  }
  async _del(key) {
    if (Object.prototype.hasOwnProperty.call(this.cache, key)) {
      const itemSize = this.meta[key]?.compressedSize || 0;
      this.currentMemoryBytes -= itemSize;
    }
    delete this.cache[key];
    delete this.meta[key];
    return true;
  }
  async _clear(prefix) {
    if (!prefix) {
      this.cache = {};
      this.meta = {};
      this.currentMemoryBytes = 0;
      return true;
    }
    for (const key of Object.keys(this.cache)) {
      if (key.startsWith(prefix)) {
        const itemSize = this.meta[key]?.compressedSize || 0;
        this.currentMemoryBytes -= itemSize;
        delete this.cache[key];
        delete this.meta[key];
      }
    }
    return true;
  }
  async size() {
    return Object.keys(this.cache).length;
  }
  async keys() {
    return Object.keys(this.cache);
  }
  /**
   * Get compression statistics
   * @returns {Object} Compression stats including total compressed items, ratios, and space savings
   */
  getCompressionStats() {
    if (!this.enableCompression) {
      return { enabled: false, message: "Compression is disabled" };
    }
    const spaceSavings = this.compressionStats.totalOriginalSize > 0 ? ((this.compressionStats.totalOriginalSize - this.compressionStats.totalCompressedSize) / this.compressionStats.totalOriginalSize * 100).toFixed(2) : 0;
    return {
      enabled: true,
      totalItems: Object.keys(this.cache).length,
      compressedItems: this.compressionStats.totalCompressed,
      compressionThreshold: this.compressionThreshold,
      totalOriginalSize: this.compressionStats.totalOriginalSize,
      totalCompressedSize: this.compressionStats.totalCompressedSize,
      averageCompressionRatio: this.compressionStats.compressionRatio,
      spaceSavingsPercent: spaceSavings,
      memoryUsage: {
        uncompressed: `${(this.compressionStats.totalOriginalSize / 1024).toFixed(2)} KB`,
        compressed: `${(this.compressionStats.totalCompressedSize / 1024).toFixed(2)} KB`,
        saved: `${((this.compressionStats.totalOriginalSize - this.compressionStats.totalCompressedSize) / 1024).toFixed(2)} KB`
      }
    };
  }
  /**
   * Get memory usage statistics
   * @returns {Object} Memory stats including current usage, limits, and eviction counts
   */
  getMemoryStats() {
    const totalItems = Object.keys(this.cache).length;
    const memoryUsagePercent = this.maxMemoryBytes > 0 ? (this.currentMemoryBytes / this.maxMemoryBytes * 100).toFixed(2) : 0;
    const systemMemory = {
      total: os$1.totalmem(),
      free: os$1.freemem(),
      used: os$1.totalmem() - os$1.freemem()
    };
    const cachePercentOfTotal = systemMemory.total > 0 ? (this.currentMemoryBytes / systemMemory.total * 100).toFixed(2) : 0;
    return {
      currentMemoryBytes: this.currentMemoryBytes,
      maxMemoryBytes: this.maxMemoryBytes,
      maxMemoryPercent: this.maxMemoryPercent,
      memoryUsagePercent: parseFloat(memoryUsagePercent),
      cachePercentOfSystemMemory: parseFloat(cachePercentOfTotal),
      totalItems,
      maxSize: this.maxSize,
      evictedDueToMemory: this.evictedDueToMemory,
      averageItemSize: totalItems > 0 ? Math.round(this.currentMemoryBytes / totalItems) : 0,
      memoryUsage: {
        current: this._formatBytes(this.currentMemoryBytes),
        max: this.maxMemoryBytes > 0 ? this._formatBytes(this.maxMemoryBytes) : "unlimited",
        available: this.maxMemoryBytes > 0 ? this._formatBytes(this.maxMemoryBytes - this.currentMemoryBytes) : "unlimited"
      },
      systemMemory: {
        total: this._formatBytes(systemMemory.total),
        free: this._formatBytes(systemMemory.free),
        used: this._formatBytes(systemMemory.used),
        cachePercent: `${cachePercentOfTotal}%`
      }
    };
  }
  /**
   * Format bytes to human-readable format
   * @private
   */
  _formatBytes(bytes) {
    if (bytes === 0) return "0 B";
    const k = 1024;
    const sizes = ["B", "KB", "MB", "GB"];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return `${(bytes / Math.pow(k, i)).toFixed(2)} ${sizes[i]}`;
  }
}

class FilesystemCache extends Cache {
  constructor({
    directory,
    prefix = "cache",
    ttl = 36e5,
    enableCompression = true,
    compressionThreshold = 1024,
    createDirectory = true,
    fileExtension = ".cache",
    enableMetadata = true,
    maxFileSize = 10485760,
    // 10MB
    enableStats = false,
    enableCleanup = true,
    cleanupInterval = 3e5,
    // 5 minutes
    encoding = "utf8",
    fileMode = 420,
    enableBackup = false,
    backupSuffix = ".bak",
    enableLocking = false,
    lockTimeout = 5e3,
    enableJournal = false,
    journalFile = "cache.journal",
    ...config
  }) {
    super(config);
    if (!directory) {
      throw new Error("FilesystemCache: directory parameter is required");
    }
    this.directory = path$1.resolve(directory);
    this.prefix = prefix;
    this.ttl = ttl;
    this.enableCompression = enableCompression;
    this.compressionThreshold = compressionThreshold;
    this.createDirectory = createDirectory;
    this.fileExtension = fileExtension;
    this.enableMetadata = enableMetadata;
    this.maxFileSize = maxFileSize;
    this.enableStats = enableStats;
    this.enableCleanup = enableCleanup;
    this.cleanupInterval = cleanupInterval;
    this.encoding = encoding;
    this.fileMode = fileMode;
    this.enableBackup = enableBackup;
    this.backupSuffix = backupSuffix;
    this.enableLocking = enableLocking;
    this.lockTimeout = lockTimeout;
    this.enableJournal = enableJournal;
    this.journalFile = path$1.join(this.directory, journalFile);
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      clears: 0,
      errors: 0
    };
    this.locks = /* @__PURE__ */ new Map();
    this.cleanupTimer = null;
    this._init();
  }
  async _init() {
    if (this.createDirectory) {
      await this._ensureDirectory(this.directory);
    }
    if (this.enableCleanup && this.cleanupInterval > 0) {
      this.cleanupTimer = setInterval(() => {
        this._cleanup().catch((err) => {
          console.warn("FilesystemCache cleanup error:", err.message);
        });
      }, this.cleanupInterval);
    }
  }
  async _ensureDirectory(dir) {
    const [ok, err] = await tryFn(async () => {
      await mkdir(dir, { recursive: true });
    });
    if (!ok && err.code !== "EEXIST") {
      throw new Error(`Failed to create cache directory: ${err.message}`);
    }
  }
  _getFilePath(key) {
    const sanitizedKey = key.replace(/[<>:"/\\|?*]/g, "_");
    const filename = `${this.prefix}_${sanitizedKey}${this.fileExtension}`;
    return path$1.join(this.directory, filename);
  }
  _getMetadataPath(filePath) {
    return filePath + ".meta";
  }
  async _set(key, data) {
    const filePath = this._getFilePath(key);
    try {
      let serialized = JSON.stringify(data);
      const originalSize = Buffer.byteLength(serialized, this.encoding);
      if (originalSize > this.maxFileSize) {
        throw new Error(`Cache data exceeds maximum file size: ${originalSize} > ${this.maxFileSize}`);
      }
      let compressed = false;
      let finalData = serialized;
      if (this.enableCompression && originalSize >= this.compressionThreshold) {
        const compressedBuffer = zlib.gzipSync(Buffer.from(serialized, this.encoding));
        finalData = compressedBuffer.toString("base64");
        compressed = true;
      }
      if (this.enableBackup && await this._fileExists(filePath)) {
        const backupPath = filePath + this.backupSuffix;
        await this._copyFile(filePath, backupPath);
      }
      if (this.enableLocking) {
        await this._acquireLock(filePath);
      }
      try {
        await writeFile(filePath, finalData, {
          encoding: compressed ? "utf8" : this.encoding,
          mode: this.fileMode
        });
        if (this.enableMetadata) {
          const metadata = {
            key,
            timestamp: Date.now(),
            ttl: this.ttl,
            compressed,
            originalSize,
            compressedSize: compressed ? Buffer.byteLength(finalData, "utf8") : originalSize,
            compressionRatio: compressed ? (Buffer.byteLength(finalData, "utf8") / originalSize).toFixed(2) : 1
          };
          await writeFile(this._getMetadataPath(filePath), JSON.stringify(metadata), {
            encoding: this.encoding,
            mode: this.fileMode
          });
        }
        if (this.enableStats) {
          this.stats.sets++;
        }
        if (this.enableJournal) {
          await this._journalOperation("set", key, { size: originalSize, compressed });
        }
      } finally {
        if (this.enableLocking) {
          this._releaseLock(filePath);
        }
      }
      return data;
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new Error(`Failed to set cache key '${key}': ${error.message}`);
    }
  }
  async _get(key) {
    const filePath = this._getFilePath(key);
    try {
      if (!await this._fileExists(filePath)) {
        if (this.enableStats) {
          this.stats.misses++;
        }
        return null;
      }
      let isExpired = false;
      if (this.enableMetadata) {
        const metadataPath = this._getMetadataPath(filePath);
        if (await this._fileExists(metadataPath)) {
          const [ok, err, metadata] = await tryFn(async () => {
            const metaContent = await readFile$1(metadataPath, this.encoding);
            return JSON.parse(metaContent);
          });
          if (ok && metadata.ttl > 0) {
            const age = Date.now() - metadata.timestamp;
            isExpired = age > metadata.ttl;
          }
        }
      } else if (this.ttl > 0) {
        const stats = await stat(filePath);
        const age = Date.now() - stats.mtime.getTime();
        isExpired = age > this.ttl;
      }
      if (isExpired) {
        await this._del(key);
        if (this.enableStats) {
          this.stats.misses++;
        }
        return null;
      }
      if (this.enableLocking) {
        await this._acquireLock(filePath);
      }
      try {
        const content = await readFile$1(filePath, this.encoding);
        let isCompressed = false;
        if (this.enableMetadata) {
          const metadataPath = this._getMetadataPath(filePath);
          if (await this._fileExists(metadataPath)) {
            const [ok, err, metadata] = await tryFn(async () => {
              const metaContent = await readFile$1(metadataPath, this.encoding);
              return JSON.parse(metaContent);
            });
            if (ok) {
              isCompressed = metadata.compressed;
            }
          }
        }
        let finalContent = content;
        if (isCompressed || this.enableCompression && content.match(/^[A-Za-z0-9+/=]+$/)) {
          try {
            const compressedBuffer = Buffer.from(content, "base64");
            finalContent = zlib.gunzipSync(compressedBuffer).toString(this.encoding);
          } catch (decompressError) {
            finalContent = content;
          }
        }
        const data = JSON.parse(finalContent);
        if (this.enableStats) {
          this.stats.hits++;
        }
        return data;
      } finally {
        if (this.enableLocking) {
          this._releaseLock(filePath);
        }
      }
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      await this._del(key);
      return null;
    }
  }
  async _del(key) {
    const filePath = this._getFilePath(key);
    try {
      if (await this._fileExists(filePath)) {
        await unlink(filePath);
      }
      if (this.enableMetadata) {
        const metadataPath = this._getMetadataPath(filePath);
        if (await this._fileExists(metadataPath)) {
          await unlink(metadataPath);
        }
      }
      if (this.enableBackup) {
        const backupPath = filePath + this.backupSuffix;
        if (await this._fileExists(backupPath)) {
          await unlink(backupPath);
        }
      }
      if (this.enableStats) {
        this.stats.deletes++;
      }
      if (this.enableJournal) {
        await this._journalOperation("delete", key);
      }
      return true;
    } catch (error) {
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new Error(`Failed to delete cache key '${key}': ${error.message}`);
    }
  }
  async _clear(prefix) {
    try {
      if (!await this._fileExists(this.directory)) {
        if (this.enableStats) {
          this.stats.clears++;
        }
        return true;
      }
      const files = await readdir(this.directory);
      const cacheFiles = files.filter((file) => {
        if (!file.startsWith(this.prefix)) return false;
        if (!file.endsWith(this.fileExtension)) return false;
        if (prefix) {
          const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
          return keyPart.startsWith(prefix);
        }
        return true;
      });
      for (const file of cacheFiles) {
        const filePath = path$1.join(this.directory, file);
        try {
          if (await this._fileExists(filePath)) {
            await unlink(filePath);
          }
        } catch (error) {
          if (error.code !== "ENOENT") {
            throw error;
          }
        }
        if (this.enableMetadata) {
          try {
            const metadataPath = this._getMetadataPath(filePath);
            if (await this._fileExists(metadataPath)) {
              await unlink(metadataPath);
            }
          } catch (error) {
            if (error.code !== "ENOENT") {
              throw error;
            }
          }
        }
        if (this.enableBackup) {
          try {
            const backupPath = filePath + this.backupSuffix;
            if (await this._fileExists(backupPath)) {
              await unlink(backupPath);
            }
          } catch (error) {
            if (error.code !== "ENOENT") {
              throw error;
            }
          }
        }
      }
      if (this.enableStats) {
        this.stats.clears++;
      }
      if (this.enableJournal) {
        await this._journalOperation("clear", prefix || "all", { count: cacheFiles.length });
      }
      return true;
    } catch (error) {
      if (error.code === "ENOENT") {
        if (this.enableStats) {
          this.stats.clears++;
        }
        return true;
      }
      if (this.enableStats) {
        this.stats.errors++;
      }
      throw new Error(`Failed to clear cache: ${error.message}`);
    }
  }
  async size() {
    const keys = await this.keys();
    return keys.length;
  }
  async keys() {
    try {
      const files = await readdir(this.directory);
      const cacheFiles = files.filter(
        (file) => file.startsWith(this.prefix) && file.endsWith(this.fileExtension)
      );
      const keys = cacheFiles.map((file) => {
        const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
        return keyPart;
      });
      return keys;
    } catch (error) {
      console.warn("FilesystemCache: Failed to list keys:", error.message);
      return [];
    }
  }
  // Helper methods
  async _fileExists(filePath) {
    const [ok] = await tryFn(async () => {
      await stat(filePath);
    });
    return ok;
  }
  async _copyFile(src, dest) {
    const [ok, err] = await tryFn(async () => {
      const content = await readFile$1(src);
      await writeFile(dest, content);
    });
    if (!ok) {
      console.warn("FilesystemCache: Failed to create backup:", err.message);
    }
  }
  async _cleanup() {
    if (!this.ttl || this.ttl <= 0) return;
    try {
      const files = await readdir(this.directory);
      const now = Date.now();
      for (const file of files) {
        if (!file.startsWith(this.prefix) || !file.endsWith(this.fileExtension)) {
          continue;
        }
        const filePath = path$1.join(this.directory, file);
        let shouldDelete = false;
        if (this.enableMetadata) {
          const metadataPath = this._getMetadataPath(filePath);
          if (await this._fileExists(metadataPath)) {
            const [ok, err, metadata] = await tryFn(async () => {
              const metaContent = await readFile$1(metadataPath, this.encoding);
              return JSON.parse(metaContent);
            });
            if (ok && metadata.ttl > 0) {
              const age = now - metadata.timestamp;
              shouldDelete = age > metadata.ttl;
            }
          }
        } else {
          const [ok, err, stats] = await tryFn(async () => {
            return await stat(filePath);
          });
          if (ok) {
            const age = now - stats.mtime.getTime();
            shouldDelete = age > this.ttl;
          }
        }
        if (shouldDelete) {
          const keyPart = file.slice(this.prefix.length + 1, -this.fileExtension.length);
          await this._del(keyPart);
        }
      }
    } catch (error) {
      console.warn("FilesystemCache cleanup error:", error.message);
    }
  }
  async _acquireLock(filePath) {
    if (!this.enableLocking) return;
    const lockKey = filePath;
    const startTime = Date.now();
    while (this.locks.has(lockKey)) {
      if (Date.now() - startTime > this.lockTimeout) {
        throw new Error(`Lock timeout for file: ${filePath}`);
      }
      await new Promise((resolve) => setTimeout(resolve, 10));
    }
    this.locks.set(lockKey, Date.now());
  }
  _releaseLock(filePath) {
    if (!this.enableLocking) return;
    this.locks.delete(filePath);
  }
  async _journalOperation(operation, key, metadata = {}) {
    if (!this.enableJournal) return;
    const entry = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      operation,
      key,
      metadata
    };
    const [ok, err] = await tryFn(async () => {
      const line = JSON.stringify(entry) + "\n";
      await fs$1.promises.appendFile(this.journalFile, line, this.encoding);
    });
    if (!ok) {
      console.warn("FilesystemCache journal error:", err.message);
    }
  }
  // Cleanup on process exit
  destroy() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
  }
  // Get cache statistics
  getStats() {
    return {
      ...this.stats,
      directory: this.directory,
      ttl: this.ttl,
      compression: this.enableCompression,
      metadata: this.enableMetadata,
      cleanup: this.enableCleanup,
      locking: this.enableLocking,
      journal: this.enableJournal
    };
  }
}

class PartitionAwareFilesystemCache extends FilesystemCache {
  constructor({
    partitionStrategy = "hierarchical",
    // 'hierarchical', 'flat', 'temporal'
    trackUsage = true,
    preloadRelated = false,
    preloadThreshold = 10,
    maxCacheSize = null,
    usageStatsFile = "partition-usage.json",
    ...config
  }) {
    super(config);
    this.partitionStrategy = partitionStrategy;
    this.trackUsage = trackUsage;
    this.preloadRelated = preloadRelated;
    this.preloadThreshold = preloadThreshold;
    this.maxCacheSize = maxCacheSize;
    this.usageStatsFile = path$1.join(this.directory, usageStatsFile);
    this.partitionUsage = /* @__PURE__ */ new Map();
    this.loadUsageStats();
  }
  /**
   * Generate partition-aware cache key
   */
  _getPartitionCacheKey(resource, action, partition, partitionValues = {}, params = {}) {
    const keyParts = [`resource=${resource}`, `action=${action}`];
    if (partition && Object.keys(partitionValues).length > 0) {
      keyParts.push(`partition=${partition}`);
      const sortedFields = Object.entries(partitionValues).sort(([a], [b]) => a.localeCompare(b));
      for (const [field, value] of sortedFields) {
        if (value !== null && value !== void 0) {
          keyParts.push(`${field}=${value}`);
        }
      }
    }
    if (Object.keys(params).length > 0) {
      const paramsStr = Object.entries(params).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}=${v}`).join("|");
      keyParts.push(`params=${Buffer.from(paramsStr).toString("base64")}`);
    }
    return keyParts.join("/") + this.fileExtension;
  }
  /**
   * Get directory path for partition cache
   */
  _getPartitionDirectory(resource, partition, partitionValues = {}) {
    const basePath = path$1.join(this.directory, `resource=${resource}`);
    if (!partition) {
      return basePath;
    }
    if (this.partitionStrategy === "flat") {
      return path$1.join(basePath, "partitions");
    }
    if (this.partitionStrategy === "temporal" && this._isTemporalPartition(partition, partitionValues)) {
      return this._getTemporalDirectory(basePath, partition, partitionValues);
    }
    const pathParts = [basePath, `partition=${partition}`];
    const sortedFields = Object.entries(partitionValues).sort(([a], [b]) => a.localeCompare(b));
    for (const [field, value] of sortedFields) {
      if (value !== null && value !== void 0) {
        pathParts.push(`${field}=${this._sanitizePathValue(value)}`);
      }
    }
    return path$1.join(...pathParts);
  }
  /**
   * Enhanced set method with partition awareness
   */
  async _set(key, data, options = {}) {
    const { resource, action, partition, partitionValues, params } = options;
    if (resource && partition) {
      const partitionKey = this._getPartitionCacheKey(resource, action, partition, partitionValues, params);
      const partitionDir = this._getPartitionDirectory(resource, partition, partitionValues);
      await this._ensureDirectory(partitionDir);
      const filePath = path$1.join(partitionDir, this._sanitizeFileName(partitionKey));
      if (this.trackUsage) {
        await this._trackPartitionUsage(resource, partition, partitionValues);
      }
      const partitionData = {
        data,
        metadata: {
          resource,
          partition,
          partitionValues,
          timestamp: Date.now(),
          ttl: this.ttl
        }
      };
      return this._writeFileWithMetadata(filePath, partitionData);
    }
    return super._set(key, data);
  }
  /**
   * Public set method with partition support
   */
  async set(resource, action, data, options = {}) {
    if (typeof resource === "string" && typeof action === "string" && options.partition) {
      const key = this._getPartitionCacheKey(resource, action, options.partition, options.partitionValues, options.params);
      return this._set(key, data, { resource, action, ...options });
    }
    return super.set(resource, action);
  }
  /**
   * Public get method with partition support
   */
  async get(resource, action, options = {}) {
    if (typeof resource === "string" && typeof action === "string" && options.partition) {
      const key = this._getPartitionCacheKey(resource, action, options.partition, options.partitionValues, options.params);
      return this._get(key, { resource, action, ...options });
    }
    return super.get(resource);
  }
  /**
   * Enhanced get method with partition awareness
   */
  async _get(key, options = {}) {
    const { resource, action, partition, partitionValues, params } = options;
    if (resource && partition) {
      const partitionKey = this._getPartitionCacheKey(resource, action, partition, partitionValues, params);
      const partitionDir = this._getPartitionDirectory(resource, partition, partitionValues);
      const filePath = path$1.join(partitionDir, this._sanitizeFileName(partitionKey));
      if (!await this._fileExists(filePath)) {
        if (this.preloadRelated) {
          await this._preloadRelatedPartitions(resource, partition, partitionValues);
        }
        return null;
      }
      const result = await this._readFileWithMetadata(filePath);
      if (result && this.trackUsage) {
        await this._trackPartitionUsage(resource, partition, partitionValues);
      }
      return result?.data || null;
    }
    return super._get(key);
  }
  /**
   * Clear cache for specific partition
   */
  async clearPartition(resource, partition, partitionValues = {}) {
    const partitionDir = this._getPartitionDirectory(resource, partition, partitionValues);
    const [ok, err] = await tryFn(async () => {
      if (await this._fileExists(partitionDir)) {
        await rm(partitionDir, { recursive: true });
      }
    });
    if (!ok) {
      console.warn(`Failed to clear partition cache: ${err.message}`);
    }
    const usageKey = this._getUsageKey(resource, partition, partitionValues);
    this.partitionUsage.delete(usageKey);
    await this._saveUsageStats();
    return ok;
  }
  /**
   * Clear all partitions for a resource
   */
  async clearResourcePartitions(resource) {
    const resourceDir = path$1.join(this.directory, `resource=${resource}`);
    const [ok, err] = await tryFn(async () => {
      if (await this._fileExists(resourceDir)) {
        await rm(resourceDir, { recursive: true });
      }
    });
    for (const [key] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        this.partitionUsage.delete(key);
      }
    }
    await this._saveUsageStats();
    return ok;
  }
  /**
   * Get partition cache statistics
   */
  async getPartitionStats(resource, partition = null) {
    const stats = {
      totalFiles: 0,
      totalSize: 0,
      partitions: {},
      usage: {}
    };
    const resourceDir = path$1.join(this.directory, `resource=${resource}`);
    if (!await this._fileExists(resourceDir)) {
      return stats;
    }
    await this._calculateDirectoryStats(resourceDir, stats);
    for (const [key, usage] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        const partitionName = key.split("/")[1];
        if (!partition || partitionName === partition) {
          stats.usage[partitionName] = usage;
        }
      }
    }
    return stats;
  }
  /**
   * Get cache recommendations based on usage patterns
   */
  async getCacheRecommendations(resource) {
    const recommendations = [];
    const now = Date.now();
    const dayMs = 24 * 60 * 60 * 1e3;
    for (const [key, usage] of this.partitionUsage.entries()) {
      if (key.startsWith(`${resource}/`)) {
        const [, partition] = key.split("/");
        const daysSinceLastAccess = (now - usage.lastAccess) / dayMs;
        const accessesPerDay = usage.count / Math.max(1, daysSinceLastAccess);
        let recommendation = "keep";
        let priority = usage.count;
        if (daysSinceLastAccess > 30) {
          recommendation = "archive";
          priority = 0;
        } else if (accessesPerDay < 0.1) {
          recommendation = "reduce_ttl";
          priority = 1;
        } else if (accessesPerDay > 10) {
          recommendation = "preload";
          priority = 100;
        }
        recommendations.push({
          partition,
          recommendation,
          priority,
          usage: accessesPerDay,
          lastAccess: new Date(usage.lastAccess).toISOString()
        });
      }
    }
    return recommendations.sort((a, b) => b.priority - a.priority);
  }
  /**
   * Preload frequently accessed partitions
   */
  async warmPartitionCache(resource, options = {}) {
    const { partitions = [], maxFiles = 1e3 } = options;
    let warmedCount = 0;
    for (const partition of partitions) {
      const usageKey = `${resource}/${partition}`;
      const usage = this.partitionUsage.get(usageKey);
      if (usage && usage.count >= this.preloadThreshold) {
        console.log(`\u{1F525} Warming cache for ${resource}/${partition} (${usage.count} accesses)`);
        warmedCount++;
      }
      if (warmedCount >= maxFiles) break;
    }
    return warmedCount;
  }
  // Private helper methods
  async _trackPartitionUsage(resource, partition, partitionValues) {
    const usageKey = this._getUsageKey(resource, partition, partitionValues);
    const current = this.partitionUsage.get(usageKey) || {
      count: 0,
      firstAccess: Date.now(),
      lastAccess: Date.now()
    };
    current.count++;
    current.lastAccess = Date.now();
    this.partitionUsage.set(usageKey, current);
    if (current.count % 10 === 0) {
      await this._saveUsageStats();
    }
  }
  _getUsageKey(resource, partition, partitionValues) {
    const valuePart = Object.entries(partitionValues).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}=${v}`).join("|");
    return `${resource}/${partition}/${valuePart}`;
  }
  async _preloadRelatedPartitions(resource, partition, partitionValues) {
    console.log(`\u{1F3AF} Preloading related partitions for ${resource}/${partition}`);
    if (partitionValues.timestamp || partitionValues.date) ;
  }
  _isTemporalPartition(partition, partitionValues) {
    const temporalFields = ["date", "timestamp", "createdAt", "updatedAt"];
    return Object.keys(partitionValues).some(
      (field) => temporalFields.some((tf) => field.toLowerCase().includes(tf))
    );
  }
  _getTemporalDirectory(basePath, partition, partitionValues) {
    const dateValue = Object.values(partitionValues)[0];
    if (typeof dateValue === "string" && dateValue.match(/^\d{4}-\d{2}-\d{2}/)) {
      const [year, month, day] = dateValue.split("-");
      return path$1.join(basePath, "temporal", year, month, day);
    }
    return path$1.join(basePath, `partition=${partition}`);
  }
  _sanitizePathValue(value) {
    return String(value).replace(/[<>:"/\\|?*]/g, "_");
  }
  _sanitizeFileName(filename) {
    return filename.replace(/[<>:"/\\|?*]/g, "_");
  }
  async _calculateDirectoryStats(dir, stats) {
    const [ok, err, files] = await tryFn(() => readdir(dir));
    if (!ok) return;
    for (const file of files) {
      const filePath = path$1.join(dir, file);
      const [statOk, statErr, fileStat] = await tryFn(() => stat(filePath));
      if (statOk) {
        if (fileStat.isDirectory()) {
          await this._calculateDirectoryStats(filePath, stats);
        } else {
          stats.totalFiles++;
          stats.totalSize += fileStat.size;
        }
      }
    }
  }
  async loadUsageStats() {
    const [ok, err, content] = await tryFn(async () => {
      const data = await readFile$1(this.usageStatsFile, "utf8");
      return JSON.parse(data);
    });
    if (ok && content) {
      this.partitionUsage = new Map(Object.entries(content));
    }
  }
  async _saveUsageStats() {
    const statsObject = Object.fromEntries(this.partitionUsage);
    await tryFn(async () => {
      await writeFile(
        this.usageStatsFile,
        JSON.stringify(statsObject, null, 2),
        "utf8"
      );
    });
  }
  async _writeFileWithMetadata(filePath, data) {
    const content = JSON.stringify(data);
    const [ok, err] = await tryFn(async () => {
      await writeFile(filePath, content, {
        encoding: this.encoding,
        mode: this.fileMode
      });
    });
    if (!ok) {
      throw new Error(`Failed to write cache file: ${err.message}`);
    }
    return true;
  }
  async _readFileWithMetadata(filePath) {
    const [ok, err, content] = await tryFn(async () => {
      return await readFile$1(filePath, this.encoding);
    });
    if (!ok || !content) return null;
    try {
      return JSON.parse(content);
    } catch (error) {
      return { data: content };
    }
  }
}

class CachePlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      // Driver configuration
      driver: options.driver || "s3",
      config: {
        ttl: options.ttl,
        maxSize: options.maxSize,
        maxMemoryBytes: options.maxMemoryBytes,
        maxMemoryPercent: options.maxMemoryPercent,
        ...options.config
        // Driver-specific config (can override ttl/maxSize/maxMemoryBytes/maxMemoryPercent)
      },
      // Resource filtering
      include: options.include || null,
      // Array of resource names to cache (null = all)
      exclude: options.exclude || [],
      // Array of resource names to exclude
      // Partition settings
      includePartitions: options.includePartitions !== false,
      partitionStrategy: options.partitionStrategy || "hierarchical",
      partitionAware: options.partitionAware !== false,
      trackUsage: options.trackUsage !== false,
      preloadRelated: options.preloadRelated !== false,
      // Retry configuration
      retryAttempts: options.retryAttempts || 3,
      retryDelay: options.retryDelay || 100,
      // ms
      // Logging
      verbose: options.verbose || false
    };
    this.stats = {
      hits: 0,
      misses: 0,
      writes: 0,
      deletes: 0,
      errors: 0,
      startTime: Date.now()
    };
  }
  async onInstall() {
    if (this.config.driver && typeof this.config.driver === "object") {
      this.driver = this.config.driver;
    } else if (this.config.driver === "memory") {
      this.driver = new MemoryCache(this.config.config);
    } else if (this.config.driver === "filesystem") {
      if (this.config.partitionAware) {
        this.driver = new PartitionAwareFilesystemCache({
          partitionStrategy: this.config.partitionStrategy,
          trackUsage: this.config.trackUsage,
          preloadRelated: this.config.preloadRelated,
          ...this.config.config
        });
      } else {
        this.driver = new FilesystemCache(this.config.config);
      }
    } else {
      this.driver = new S3Cache({
        client: this.database.client,
        ...this.config.config
      });
    }
    this.installDatabaseHooks();
    this.installResourceHooks();
  }
  /**
   * Install database hooks to handle resource creation/updates
   */
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", async ({ resource }) => {
      if (this.shouldCacheResource(resource.name)) {
        this.installResourceHooksForResource(resource);
      }
    });
  }
  async onStart() {
  }
  async onStop() {
  }
  // Remove the old installDatabaseProxy method
  installResourceHooks() {
    for (const resource of Object.values(this.database.resources)) {
      if (!this.shouldCacheResource(resource.name)) {
        continue;
      }
      this.installResourceHooksForResource(resource);
    }
  }
  shouldCacheResource(resourceName) {
    const resourceMetadata = this.database.savedMetadata?.resources?.[resourceName];
    if (resourceMetadata?.createdBy && resourceMetadata.createdBy !== "user" && !this.config.include) {
      return false;
    }
    if (resourceName.startsWith("plg_") && !this.config.include) {
      return false;
    }
    if (this.config.exclude.includes(resourceName)) {
      return false;
    }
    if (this.config.include && !this.config.include.includes(resourceName)) {
      return false;
    }
    return true;
  }
  installResourceHooksForResource(resource) {
    if (!this.driver) return;
    Object.defineProperty(resource, "cache", {
      value: this.driver,
      writable: true,
      configurable: true,
      enumerable: false
    });
    resource.cacheKeyFor = async (options = {}) => {
      const { action, params = {}, partition, partitionValues } = options;
      return this.generateCacheKey(resource, action, params, partition, partitionValues);
    };
    if (this.driver instanceof PartitionAwareFilesystemCache) {
      resource.clearPartitionCache = async (partition, partitionValues = {}) => {
        return await this.driver.clearPartition(resource.name, partition, partitionValues);
      };
      resource.getPartitionCacheStats = async (partition = null) => {
        return await this.driver.getPartitionStats(resource.name, partition);
      };
      resource.getCacheRecommendations = async () => {
        return await this.driver.getCacheRecommendations(resource.name);
      };
      resource.warmPartitionCache = async (partitions = [], options = {}) => {
        return await this.driver.warmPartitionCache(resource.name, { partitions, ...options });
      };
    }
    const cacheMethods = [
      "count",
      "listIds",
      "getMany",
      "getAll",
      "page",
      "list",
      "get",
      "exists",
      "content",
      "hasContent",
      "query",
      "getFromPartition"
    ];
    for (const method of cacheMethods) {
      resource.useMiddleware(method, async (ctx, next) => {
        let skipCache = false;
        const lastArg = ctx.args[ctx.args.length - 1];
        if (lastArg && typeof lastArg === "object" && lastArg.skipCache === true) {
          skipCache = true;
        }
        if (skipCache) {
          return await next();
        }
        let key;
        if (method === "getMany") {
          key = await resource.cacheKeyFor({ action: method, params: { ids: ctx.args[0] } });
        } else if (method === "page") {
          const { offset, size, partition, partitionValues } = ctx.args[0] || {};
          key = await resource.cacheKeyFor({ action: method, params: { offset, size }, partition, partitionValues });
        } else if (method === "list" || method === "listIds" || method === "count") {
          const { partition, partitionValues } = ctx.args[0] || {};
          key = await resource.cacheKeyFor({ action: method, partition, partitionValues });
        } else if (method === "query") {
          const filter = ctx.args[0] || {};
          const options = ctx.args[1] || {};
          key = await resource.cacheKeyFor({
            action: method,
            params: { filter, options: { limit: options.limit, offset: options.offset } },
            partition: options.partition,
            partitionValues: options.partitionValues
          });
        } else if (method === "getFromPartition") {
          const { id, partitionName, partitionValues } = ctx.args[0] || {};
          key = await resource.cacheKeyFor({
            action: method,
            params: { id, partitionName },
            partition: partitionName,
            partitionValues
          });
        } else if (method === "getAll") {
          key = await resource.cacheKeyFor({ action: method });
        } else if (["get", "exists", "content", "hasContent"].includes(method)) {
          key = await resource.cacheKeyFor({ action: method, params: { id: ctx.args[0] } });
        }
        if (this.driver instanceof PartitionAwareFilesystemCache) {
          let partition, partitionValues;
          if (method === "list" || method === "listIds" || method === "count" || method === "page") {
            const args = ctx.args[0] || {};
            partition = args.partition;
            partitionValues = args.partitionValues;
          } else if (method === "query") {
            const options = ctx.args[1] || {};
            partition = options.partition;
            partitionValues = options.partitionValues;
          } else if (method === "getFromPartition") {
            const { partitionName, partitionValues: pValues } = ctx.args[0] || {};
            partition = partitionName;
            partitionValues = pValues;
          }
          const [ok, err, result] = await tryFn(() => resource.cache._get(key, {
            resource: resource.name,
            action: method,
            partition,
            partitionValues
          }));
          if (ok && result !== null && result !== void 0) {
            this.stats.hits++;
            return result;
          }
          if (!ok && err.name !== "NoSuchKey") {
            this.stats.errors++;
            throw err;
          }
          this.stats.misses++;
          const freshResult = await next();
          this.stats.writes++;
          await resource.cache._set(key, freshResult, {
            resource: resource.name,
            action: method,
            partition,
            partitionValues
          });
          return freshResult;
        } else {
          const [ok, err, result] = await tryFn(() => resource.cache.get(key));
          if (ok && result !== null && result !== void 0) {
            this.stats.hits++;
            return result;
          }
          if (!ok && err.name !== "NoSuchKey") {
            this.stats.errors++;
            throw err;
          }
          this.stats.misses++;
          const freshResult = await next();
          this.stats.writes++;
          await resource.cache.set(key, freshResult);
          return freshResult;
        }
      });
    }
    const writeMethods = ["insert", "update", "delete", "deleteMany", "setContent", "deleteContent", "replace"];
    for (const method of writeMethods) {
      resource.useMiddleware(method, async (ctx, next) => {
        const result = await next();
        if (method === "insert") {
          await this.clearCacheForResource(resource, ctx.args[0]);
        } else if (method === "update") {
          await this.clearCacheForResource(resource, { id: ctx.args[0], ...ctx.args[1] });
        } else if (method === "delete") {
          let data = { id: ctx.args[0] };
          if (typeof resource.get === "function") {
            const [ok, err, full] = await tryFn(() => resource.get(ctx.args[0]));
            if (ok && full) data = full;
          }
          await this.clearCacheForResource(resource, data);
        } else if (method === "setContent" || method === "deleteContent") {
          const id = ctx.args[0]?.id || ctx.args[0];
          await this.clearCacheForResource(resource, { id });
        } else if (method === "replace") {
          const id = ctx.args[0];
          await this.clearCacheForResource(resource, { id, ...ctx.args[1] });
        } else if (method === "deleteMany") {
          await this.clearCacheForResource(resource);
        }
        return result;
      });
    }
  }
  async clearCacheForResource(resource, data) {
    if (!resource.cache) return;
    const keyPrefix = `resource=${resource.name}`;
    if (data && data.id) {
      const itemSpecificMethods = ["get", "exists", "content", "hasContent"];
      for (const method of itemSpecificMethods) {
        const specificKey = await this.generateCacheKey(resource, method, { id: data.id });
        const [ok2, err2] = await this.clearCacheWithRetry(resource.cache, specificKey);
        if (!ok2) {
          this.emit("plg:cache:clear-error", {
            resource: resource.name,
            method,
            id: data.id,
            error: err2.message
          });
          if (this.config.verbose) {
            console.warn(`[CachePlugin] Failed to clear ${method} cache for ${resource.name}:${data.id}:`, err2.message);
          }
        }
      }
      if (this.config.includePartitions === true && resource.config?.partitions && Object.keys(resource.config.partitions).length > 0) {
        const partitionValues = this.getPartitionValues(data, resource);
        for (const [partitionName, values] of Object.entries(partitionValues)) {
          if (values && Object.keys(values).length > 0 && Object.values(values).some((v) => v !== null && v !== void 0)) {
            const partitionKeyPrefix = join(keyPrefix, `partition=${partitionName}`);
            const [ok2, err2] = await this.clearCacheWithRetry(resource.cache, partitionKeyPrefix);
            if (!ok2) {
              this.emit("plg:cache:clear-error", {
                resource: resource.name,
                partition: partitionName,
                error: err2.message
              });
              if (this.config.verbose) {
                console.warn(`[CachePlugin] Failed to clear partition cache for ${resource.name}/${partitionName}:`, err2.message);
              }
            }
          }
        }
      }
    }
    const [ok, err] = await this.clearCacheWithRetry(resource.cache, keyPrefix);
    if (!ok) {
      this.emit("plg:cache:clear-error", {
        resource: resource.name,
        type: "broad",
        error: err.message
      });
      if (this.config.verbose) {
        console.warn(`[CachePlugin] Failed to clear broad cache for ${resource.name}, trying specific methods:`, err.message);
      }
      const aggregateMethods = ["count", "list", "listIds", "getAll", "page", "query"];
      for (const method of aggregateMethods) {
        await this.clearCacheWithRetry(resource.cache, `${keyPrefix}/action=${method}`);
        await this.clearCacheWithRetry(resource.cache, `resource=${resource.name}/action=${method}`);
      }
    }
  }
  async clearCacheWithRetry(cache, key) {
    let lastError;
    for (let attempt = 0; attempt < this.config.retryAttempts; attempt++) {
      const [ok, err] = await tryFn(() => cache.clear(key));
      if (ok) {
        this.stats.deletes++;
        return [true, null];
      }
      lastError = err;
      if (err.name === "NoSuchKey" || err.code === "NoSuchKey") {
        return [true, null];
      }
      if (attempt < this.config.retryAttempts - 1) {
        const delay = this.config.retryDelay * Math.pow(2, attempt);
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
    return [false, lastError];
  }
  async generateCacheKey(resource, action, params = {}, partition = null, partitionValues = null) {
    const keyParts = [
      `resource=${resource.name}`,
      `action=${action}`
    ];
    if (partition && partitionValues && Object.keys(partitionValues).length > 0) {
      keyParts.push(`partition:${partition}`);
      for (const [field, value] of Object.entries(partitionValues)) {
        if (value !== null && value !== void 0) {
          keyParts.push(`${field}:${value}`);
        }
      }
    }
    if (Object.keys(params).length > 0) {
      const paramsHash = this.hashParams(params);
      keyParts.push(paramsHash);
    }
    return join(...keyParts) + ".json.gz";
  }
  hashParams(params) {
    const serialized = jsonStableStringify(params) || "empty";
    return crypto$1.createHash("md5").update(serialized).digest("hex").substring(0, 16);
  }
  // Utility methods
  async getCacheStats() {
    if (!this.driver) return null;
    return {
      size: await this.driver.size(),
      keys: await this.driver.keys(),
      driver: this.driver.constructor.name
    };
  }
  async clearAllCache() {
    if (!this.driver) return;
    for (const resource of Object.values(this.database.resources)) {
      if (resource.cache) {
        const keyPrefix = `resource=${resource.name}`;
        await resource.cache.clear(keyPrefix);
      }
    }
  }
  async warmCache(resourceName, options = {}) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new CacheError("Resource not found for cache warming", {
        operation: "warmCache",
        driver: this.driver?.constructor.name,
        resourceName,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name spelling or ensure resource has been created"
      });
    }
    const { includePartitions = true, sampleSize = 100 } = options;
    if (this.driver instanceof PartitionAwareFilesystemCache && resource.warmPartitionCache) {
      const partitionNames = resource.config.partitions ? Object.keys(resource.config.partitions) : [];
      return await resource.warmPartitionCache(partitionNames, options);
    }
    let offset = 0;
    const pageSize = 100;
    const sampledRecords = [];
    while (sampledRecords.length < sampleSize) {
      const [ok, err, pageResult] = await tryFn(() => resource.page({ offset, size: pageSize }));
      if (!ok || !pageResult) {
        break;
      }
      const pageItems = Array.isArray(pageResult) ? pageResult : pageResult.items || [];
      if (pageItems.length === 0) {
        break;
      }
      sampledRecords.push(...pageItems);
      offset += pageSize;
    }
    if (includePartitions && resource.config.partitions && sampledRecords.length > 0) {
      for (const [partitionName, partitionDef] of Object.entries(resource.config.partitions)) {
        if (partitionDef.fields) {
          const partitionValuesSet = /* @__PURE__ */ new Set();
          for (const record of sampledRecords) {
            const values = this.getPartitionValues(record, resource);
            if (values[partitionName]) {
              partitionValuesSet.add(JSON.stringify(values[partitionName]));
            }
          }
          for (const partitionValueStr of partitionValuesSet) {
            const partitionValues = JSON.parse(partitionValueStr);
            await tryFn(() => resource.list({ partition: partitionName, partitionValues }));
          }
        }
      }
    }
    return {
      resourceName,
      recordsSampled: sampledRecords.length,
      partitionsWarmed: includePartitions && resource.config.partitions ? Object.keys(resource.config.partitions).length : 0
    };
  }
  async analyzeCacheUsage() {
    if (!(this.driver instanceof PartitionAwareFilesystemCache)) {
      return { message: "Cache usage analysis is only available with PartitionAwareFilesystemCache" };
    }
    const analysis = {
      totalResources: Object.keys(this.database.resources).length,
      resourceStats: {},
      recommendations: {},
      summary: {
        mostUsedPartitions: [],
        leastUsedPartitions: [],
        suggestedOptimizations: []
      }
    };
    for (const [resourceName, resource] of Object.entries(this.database.resources)) {
      if (!this.shouldCacheResource(resourceName)) {
        continue;
      }
      try {
        analysis.resourceStats[resourceName] = await this.driver.getPartitionStats(resourceName);
        analysis.recommendations[resourceName] = await this.driver.getCacheRecommendations(resourceName);
      } catch (error) {
        analysis.resourceStats[resourceName] = { error: error.message };
      }
    }
    const allRecommendations = Object.values(analysis.recommendations).flat();
    analysis.summary.mostUsedPartitions = allRecommendations.filter((r) => r.recommendation === "preload").sort((a, b) => b.priority - a.priority).slice(0, 5);
    analysis.summary.leastUsedPartitions = allRecommendations.filter((r) => r.recommendation === "archive").slice(0, 5);
    analysis.summary.suggestedOptimizations = [
      `Consider preloading ${analysis.summary.mostUsedPartitions.length} high-usage partitions`,
      `Archive ${analysis.summary.leastUsedPartitions.length} unused partitions`,
      `Monitor cache hit rates for partition efficiency`
    ];
    return analysis;
  }
  /**
   * Get cache statistics including hit/miss rates
   * @returns {Object} Stats object with hits, misses, writes, deletes, errors, and calculated metrics
   */
  getStats() {
    const total = this.stats.hits + this.stats.misses;
    const hitRate = total > 0 ? this.stats.hits / total * 100 : 0;
    const missRate = total > 0 ? this.stats.misses / total * 100 : 0;
    const uptime = Date.now() - this.stats.startTime;
    const uptimeSeconds = Math.floor(uptime / 1e3);
    return {
      // Raw counters
      hits: this.stats.hits,
      misses: this.stats.misses,
      writes: this.stats.writes,
      deletes: this.stats.deletes,
      errors: this.stats.errors,
      // Calculated metrics
      total,
      hitRate: hitRate.toFixed(2) + "%",
      missRate: missRate.toFixed(2) + "%",
      hitRateDecimal: hitRate / 100,
      missRateDecimal: missRate / 100,
      // Uptime
      uptime: uptimeSeconds,
      uptimeFormatted: this._formatUptime(uptimeSeconds),
      startTime: new Date(this.stats.startTime).toISOString(),
      // Rates per second
      hitsPerSecond: uptimeSeconds > 0 ? (this.stats.hits / uptimeSeconds).toFixed(2) : 0,
      missesPerSecond: uptimeSeconds > 0 ? (this.stats.misses / uptimeSeconds).toFixed(2) : 0,
      writesPerSecond: uptimeSeconds > 0 ? (this.stats.writes / uptimeSeconds).toFixed(2) : 0
    };
  }
  /**
   * Reset cache statistics
   */
  resetStats() {
    this.stats = {
      hits: 0,
      misses: 0,
      writes: 0,
      deletes: 0,
      errors: 0,
      startTime: Date.now()
    };
  }
  /**
   * Format uptime in human-readable format
   * @private
   */
  _formatUptime(seconds) {
    const days = Math.floor(seconds / 86400);
    const hours = Math.floor(seconds % 86400 / 3600);
    const minutes = Math.floor(seconds % 3600 / 60);
    const secs = seconds % 60;
    const parts = [];
    if (days > 0) parts.push(`${days}d`);
    if (hours > 0) parts.push(`${hours}h`);
    if (minutes > 0) parts.push(`${minutes}m`);
    if (secs > 0 || parts.length === 0) parts.push(`${secs}s`);
    return parts.join(" ");
  }
}

class CostsPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.config = {
      considerFreeTier: config.considerFreeTier !== void 0 ? config.considerFreeTier : false,
      region: config.region || "us-east-1",
      ...config
    };
    this.map = {
      PutObjectCommand: "put",
      GetObjectCommand: "get",
      CopyObjectCommand: "copy",
      HeadObjectCommand: "head",
      DeleteObjectCommand: "delete",
      DeleteObjectsCommand: "delete",
      ListObjectsV2Command: "list"
    };
    this.costs = {
      total: 0,
      // === REQUESTS PRICING ===
      requests: {
        prices: {
          put: 5e-3 / 1e3,
          copy: 5e-3 / 1e3,
          list: 5e-3 / 1e3,
          post: 5e-3 / 1e3,
          get: 4e-4 / 1e3,
          select: 4e-4 / 1e3,
          delete: 4e-4 / 1e3,
          head: 4e-4 / 1e3
        },
        total: 0,
        counts: {
          put: 0,
          post: 0,
          copy: 0,
          list: 0,
          get: 0,
          select: 0,
          delete: 0,
          head: 0
        },
        totalEvents: 0,
        events: {
          PutObjectCommand: 0,
          GetObjectCommand: 0,
          CopyObjectCommand: 0,
          HeadObjectCommand: 0,
          DeleteObjectCommand: 0,
          DeleteObjectsCommand: 0,
          ListObjectsV2Command: 0
        },
        subtotal: 0
      },
      // === STORAGE PRICING ===
      storage: {
        totalBytes: 0,
        totalGB: 0,
        // Tiered pricing (S3 Standard - us-east-1)
        tiers: [
          { limit: 50 * 1024, pricePerGB: 0.023 },
          // First 50 TB
          { limit: 500 * 1024, pricePerGB: 0.022 },
          // Next 450 TB
          { limit: 999999999, pricePerGB: 0.021 }
          // Over 500 TB (effectively unlimited)
        ],
        currentTier: 0,
        subtotal: 0
        // Monthly storage cost estimate
      },
      // === DATA TRANSFER PRICING ===
      dataTransfer: {
        // Upload (always free)
        inBytes: 0,
        inGB: 0,
        inCost: 0,
        // Always $0
        // Download (charged with tiers)
        outBytes: 0,
        outGB: 0,
        // Tiered pricing (out to internet)
        tiers: [
          { limit: 10 * 1024, pricePerGB: 0.09 },
          // First 10 TB
          { limit: 50 * 1024, pricePerGB: 0.085 },
          // Next 40 TB
          { limit: 150 * 1024, pricePerGB: 0.07 },
          // Next 100 TB
          { limit: 999999999, pricePerGB: 0.05 }
          // Over 150 TB (effectively unlimited)
        ],
        // Free tier (100GB/month aggregated across AWS)
        freeTierGB: 100,
        freeTierUsed: 0,
        currentTier: 0,
        subtotal: 0
        // Data transfer out cost
      }
    };
  }
  async onInstall() {
    if (!this.database || !this.database.client) {
      return;
    }
    this.client = this.database.client;
    this.client.costs = JSON.parse(JSON.stringify(this.costs));
  }
  async onStart() {
    if (this.client) {
      this.client.on("cl:response", (name, response, input) => this.addRequest(name, this.map[name], response, input));
    }
  }
  addRequest(name, method, response = {}, input = {}) {
    if (!method) return;
    this.costs.requests.totalEvents++;
    this.costs.requests.total++;
    this.costs.requests.events[name]++;
    this.costs.requests.counts[method]++;
    const requestCost = this.costs.requests.prices[method];
    this.costs.requests.subtotal += requestCost;
    let contentLength = 0;
    if (["put", "post", "copy"].includes(method)) {
      const body = input.Body || input.body;
      if (body) {
        if (typeof body === "string") {
          contentLength = Buffer.byteLength(body, "utf8");
        } else if (Buffer.isBuffer(body)) {
          contentLength = body.length;
        } else if (body.length !== void 0) {
          contentLength = body.length;
        }
      }
      if (contentLength > 0) {
        this.trackStorage(contentLength);
        this.trackDataTransferIn(contentLength);
      }
    }
    if (method === "get") {
      contentLength = response?.httpResponse?.headers?.["content-length"] || response?.ContentLength || 0;
      if (contentLength > 0) {
        this.trackDataTransferOut(contentLength);
      }
    }
    if (this.client && this.client.costs) {
      this.client.costs.requests.totalEvents++;
      this.client.costs.requests.total++;
      this.client.costs.requests.events[name]++;
      this.client.costs.requests.counts[method]++;
      this.client.costs.requests.subtotal += requestCost;
    }
    this.updateTotal();
  }
  trackStorage(bytes) {
    this.costs.storage.totalBytes += bytes;
    this.costs.storage.totalGB = this.costs.storage.totalBytes / (1024 * 1024 * 1024);
    this.costs.storage.subtotal = this.calculateStorageCost(this.costs.storage);
    if (this.client && this.client.costs) {
      this.client.costs.storage.totalBytes += bytes;
      this.client.costs.storage.totalGB = this.client.costs.storage.totalBytes / (1024 * 1024 * 1024);
      this.client.costs.storage.subtotal = this.calculateStorageCost(this.client.costs.storage);
    }
    this.updateTotal();
  }
  trackDataTransferIn(bytes) {
    this.costs.dataTransfer.inBytes += bytes;
    this.costs.dataTransfer.inGB = this.costs.dataTransfer.inBytes / (1024 * 1024 * 1024);
    if (this.client && this.client.costs) {
      this.client.costs.dataTransfer.inBytes += bytes;
      this.client.costs.dataTransfer.inGB = this.client.costs.dataTransfer.inBytes / (1024 * 1024 * 1024);
    }
    this.updateTotal();
  }
  trackDataTransferOut(bytes) {
    this.costs.dataTransfer.outBytes += bytes;
    this.costs.dataTransfer.outGB = this.costs.dataTransfer.outBytes / (1024 * 1024 * 1024);
    this.costs.dataTransfer.subtotal = this.calculateDataTransferCost(this.costs.dataTransfer);
    if (this.client && this.client.costs) {
      this.client.costs.dataTransfer.outBytes += bytes;
      this.client.costs.dataTransfer.outGB = this.client.costs.dataTransfer.outBytes / (1024 * 1024 * 1024);
      this.client.costs.dataTransfer.subtotal = this.calculateDataTransferCost(this.client.costs.dataTransfer);
    }
    this.updateTotal();
  }
  calculateStorageCost(storage) {
    const totalGB = storage.totalGB;
    let cost = 0;
    let remaining = totalGB;
    for (let i = 0; i < storage.tiers.length; i++) {
      const tier = storage.tiers[i];
      const prevLimit = i > 0 ? storage.tiers[i - 1].limit : 0;
      const tierCapacity = tier.limit - prevLimit;
      if (remaining <= 0) break;
      const gbInTier = Math.min(remaining, tierCapacity);
      cost += gbInTier * tier.pricePerGB;
      remaining -= gbInTier;
      if (remaining <= 0) {
        storage.currentTier = i;
        break;
      }
    }
    return cost;
  }
  calculateDataTransferCost(dataTransfer) {
    let totalGB = dataTransfer.outGB;
    let cost = 0;
    if (this.config && this.config.considerFreeTier) {
      const freeTierRemaining = dataTransfer.freeTierGB - dataTransfer.freeTierUsed;
      if (freeTierRemaining > 0 && totalGB > 0) {
        const gbToDeduct = Math.min(totalGB, freeTierRemaining);
        totalGB -= gbToDeduct;
        dataTransfer.freeTierUsed += gbToDeduct;
      }
    }
    let remaining = totalGB;
    for (let i = 0; i < dataTransfer.tiers.length; i++) {
      const tier = dataTransfer.tiers[i];
      const prevLimit = i > 0 ? dataTransfer.tiers[i - 1].limit : 0;
      const tierCapacity = tier.limit - prevLimit;
      if (remaining <= 0) break;
      const gbInTier = Math.min(remaining, tierCapacity);
      cost += gbInTier * tier.pricePerGB;
      remaining -= gbInTier;
      if (remaining <= 0) {
        dataTransfer.currentTier = i;
        break;
      }
    }
    return cost;
  }
  updateTotal() {
    this.costs.total = this.costs.requests.subtotal + this.costs.storage.subtotal + this.costs.dataTransfer.subtotal;
    if (this.client && this.client.costs) {
      this.client.costs.total = this.client.costs.requests.subtotal + this.client.costs.storage.subtotal + this.client.costs.dataTransfer.subtotal;
    }
  }
}

function createConfig(options, detectedTimezone) {
  const consolidation = options.consolidation || {};
  const locks = options.locks || {};
  const gc = options.garbageCollection || {};
  const analytics = options.analytics || {};
  const batch = options.batch || {};
  const lateArrivals = options.lateArrivals || {};
  const checkpoints = options.checkpoints || {};
  return {
    // Cohort (timezone)
    cohort: {
      timezone: options.cohort?.timezone || detectedTimezone
    },
    // Reducer function
    reducer: options.reducer || ((transactions) => {
      let baseValue = 0;
      for (const t of transactions) {
        if (t.operation === "set") {
          baseValue = t.value;
        } else if (t.operation === "add") {
          baseValue += t.value;
        } else if (t.operation === "sub") {
          baseValue -= t.value;
        }
      }
      return baseValue;
    }),
    // Consolidation settings
    consolidationInterval: consolidation.interval ?? 300,
    consolidationConcurrency: consolidation.concurrency ?? 5,
    consolidationWindow: consolidation.window ?? 24,
    autoConsolidate: consolidation.auto !== false,
    mode: consolidation.mode || "async",
    // ✅ Performance tuning - Mark applied concurrency (default 50, up from 10)
    markAppliedConcurrency: consolidation.markAppliedConcurrency ?? 50,
    // ✅ Performance tuning - Recalculate concurrency (default 50, up from 10)
    recalculateConcurrency: consolidation.recalculateConcurrency ?? 50,
    // Late arrivals
    lateArrivalStrategy: lateArrivals.strategy || "warn",
    // Batch transactions
    batchTransactions: batch.enabled || false,
    batchSize: batch.size || 100,
    // Locks
    lockTimeout: locks.timeout || 300,
    // Garbage collection
    transactionRetention: gc.retention ?? 30,
    gcInterval: gc.interval ?? 86400,
    // Analytics
    enableAnalytics: analytics.enabled || false,
    analyticsConfig: {
      periods: analytics.periods || ["hour", "day", "month"],
      metrics: analytics.metrics || ["count", "sum", "avg", "min", "max"],
      rollupStrategy: analytics.rollupStrategy || "incremental",
      retentionDays: analytics.retentionDays ?? 365
    },
    // Checkpoints
    enableCheckpoints: checkpoints.enabled !== false,
    checkpointStrategy: checkpoints.strategy || "hourly",
    checkpointRetention: checkpoints.retention ?? 90,
    checkpointThreshold: checkpoints.threshold ?? 1e3,
    deleteConsolidatedTransactions: checkpoints.deleteConsolidated !== false,
    autoCheckpoint: checkpoints.auto !== false,
    // Debug
    verbose: options.verbose || false
  };
}
function validateResourcesConfig(resources) {
  if (!resources || typeof resources !== "object") {
    throw new Error(
      "EventualConsistencyPlugin requires 'resources' option.\nExample: { resources: { urls: ['clicks', 'views'], posts: ['likes'] } }"
    );
  }
  for (const [resourceName, fields] of Object.entries(resources)) {
    if (!Array.isArray(fields)) {
      throw new Error(
        `EventualConsistencyPlugin resources.${resourceName} must be an array of field names`
      );
    }
  }
}
function logConfigWarnings(config) {
  if (config.batchTransactions && !config.verbose) {
    console.warn(
      `[EventualConsistency] WARNING: batch.enabled is true. This stores transactions in memory and will lose data if container crashes. Not recommended for distributed/production environments.`
    );
  }
  if (!config.enableCheckpoints && !config.verbose) {
    console.warn(
      `[EventualConsistency] INFO: checkpoints.enabled is false. Checkpoints improve performance in high-volume scenarios by creating snapshots. Consider enabling for production use.`
    );
  }
}
function logInitialization(config, fieldHandlers, timezoneAutoDetected) {
  if (!config.verbose) return;
  const totalFields = Array.from(fieldHandlers.values()).reduce((sum, handlers) => sum + handlers.size, 0);
  console.log(
    `[EventualConsistency] Initialized with ${fieldHandlers.size} resource(s), ${totalFields} field(s) total`
  );
  if (timezoneAutoDetected) {
    console.log(
      `[EventualConsistency] Using timezone: ${config.cohort.timezone} (${process.env.TZ ? "from TZ env var" : "default UTC"})`
    );
  }
}

function detectTimezone() {
  if (process.env.TZ) {
    return process.env.TZ;
  }
  return "UTC";
}
function getTimezoneOffset(timezone, verbose = false) {
  try {
    const now = /* @__PURE__ */ new Date();
    const utcDate = new Date(now.toLocaleString("en-US", { timeZone: "UTC" }));
    const tzDate = new Date(now.toLocaleString("en-US", { timeZone: timezone }));
    return tzDate.getTime() - utcDate.getTime();
  } catch (err) {
    const offsets = {
      "UTC": 0,
      "America/New_York": -5 * 36e5,
      "America/Chicago": -6 * 36e5,
      "America/Denver": -7 * 36e5,
      "America/Los_Angeles": -8 * 36e5,
      "America/Sao_Paulo": -3 * 36e5,
      "Europe/London": 0,
      "Europe/Paris": 1 * 36e5,
      "Europe/Berlin": 1 * 36e5,
      "Asia/Tokyo": 9 * 36e5,
      "Asia/Shanghai": 8 * 36e5,
      "Australia/Sydney": 10 * 36e5
    };
    if (verbose && !offsets[timezone]) {
      console.warn(
        `[EventualConsistency] Unknown timezone '${timezone}', using UTC. Consider using a valid IANA timezone (e.g., 'America/New_York')`
      );
    }
    return offsets[timezone] || 0;
  }
}
function getISOWeek(date) {
  const target = new Date(date.valueOf());
  const dayNr = (date.getUTCDay() + 6) % 7;
  target.setUTCDate(target.getUTCDate() - dayNr + 3);
  const yearStart = new Date(Date.UTC(target.getUTCFullYear(), 0, 1));
  const firstThursday = new Date(yearStart.valueOf());
  if (yearStart.getUTCDay() !== 4) {
    firstThursday.setUTCDate(yearStart.getUTCDate() + (4 - yearStart.getUTCDay() + 7) % 7);
  }
  const weekNumber = 1 + Math.round((target - firstThursday) / 6048e5);
  return {
    year: target.getUTCFullYear(),
    week: weekNumber
  };
}
function getCohortInfo(date, timezone, verbose = false) {
  const offset = getTimezoneOffset(timezone, verbose);
  const localDate = new Date(date.getTime() + offset);
  const year = localDate.getFullYear();
  const month = String(localDate.getMonth() + 1).padStart(2, "0");
  const day = String(localDate.getDate()).padStart(2, "0");
  const hour = String(localDate.getHours()).padStart(2, "0");
  const { year: weekYear, week: weekNumber } = getISOWeek(localDate);
  const week = `${weekYear}-W${String(weekNumber).padStart(2, "0")}`;
  return {
    date: `${year}-${month}-${day}`,
    hour: `${year}-${month}-${day}T${hour}`,
    // ISO-like format for hour partition
    week,
    // ISO 8601 week format (e.g., '2025-W42')
    month: `${year}-${month}`
  };
}
function createSyntheticSetTransaction(currentValue) {
  return {
    id: "__synthetic__",
    operation: "set",
    value: currentValue,
    timestamp: (/* @__PURE__ */ new Date(0)).toISOString(),
    synthetic: true
  };
}
function createFieldHandler(resourceName, fieldName) {
  return {
    resource: resourceName,
    field: fieldName,
    transactionResource: null,
    targetResource: null,
    analyticsResource: null,
    lockResource: null,
    checkpointResource: null,
    consolidationTimer: null,
    gcTimer: null,
    pendingTransactions: /* @__PURE__ */ new Map(),
    deferredSetup: false
  };
}
function validateNestedPath(resource, fieldPath) {
  const parts = fieldPath.split(".");
  const rootField = parts[0];
  if (!resource.attributes || !resource.attributes[rootField]) {
    return {
      valid: false,
      rootField,
      fullPath: fieldPath,
      error: `Root field "${rootField}" not found in resource attributes`
    };
  }
  if (parts.length === 1) {
    return { valid: true, rootField, fullPath: fieldPath };
  }
  let current = resource.attributes[rootField];
  let foundJson = false;
  let levelsAfterJson = 0;
  for (let i = 1; i < parts.length; i++) {
    const part = parts[i];
    if (foundJson) {
      levelsAfterJson++;
      if (levelsAfterJson > 1) {
        return {
          valid: false,
          rootField,
          fullPath: fieldPath,
          error: `Path "${fieldPath}" exceeds 1 level after 'json' field. Maximum nesting after 'json' is 1 level.`
        };
      }
      continue;
    }
    if (typeof current === "string") {
      if (current === "json" || current.startsWith("json|")) {
        foundJson = true;
        levelsAfterJson++;
        if (levelsAfterJson > 1) {
          return {
            valid: false,
            rootField,
            fullPath: fieldPath,
            error: `Path "${fieldPath}" exceeds 1 level after 'json' field`
          };
        }
        continue;
      }
      return {
        valid: false,
        rootField,
        fullPath: fieldPath,
        error: `Field "${parts.slice(0, i).join(".")}" is type "${current}" and cannot be nested`
      };
    }
    if (typeof current === "object") {
      if (current.$$type) {
        const type = current.$$type;
        if (type === "json" || type.includes("json")) {
          foundJson = true;
          levelsAfterJson++;
          continue;
        }
        if (type !== "object" && !type.includes("object")) {
          return {
            valid: false,
            rootField,
            fullPath: fieldPath,
            error: `Field "${parts.slice(0, i).join(".")}" is type "${type}" and cannot be nested`
          };
        }
      }
      if (!current[part]) {
        return {
          valid: false,
          rootField,
          fullPath: fieldPath,
          error: `Field "${part}" not found in "${parts.slice(0, i).join(".")}"`
        };
      }
      current = current[part];
    } else {
      return {
        valid: false,
        rootField,
        fullPath: fieldPath,
        error: `Invalid structure at "${parts.slice(0, i).join(".")}"`
      };
    }
  }
  return { valid: true, rootField, fullPath: fieldPath };
}
function resolveFieldAndPlugin(resource, field, value) {
  if (!resource._eventualConsistencyPlugins) {
    throw new Error(`No eventual consistency plugins configured for this resource`);
  }
  if (field.includes(".")) {
    const validation = validateNestedPath(resource, field);
    if (!validation.valid) {
      throw new Error(validation.error);
    }
    const rootField = validation.rootField;
    const fieldPlugin2 = resource._eventualConsistencyPlugins[rootField];
    if (!fieldPlugin2) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new Error(
        `No eventual consistency plugin found for root field "${rootField}". Available fields: ${availableFields}`
      );
    }
    return {
      field: rootField,
      // Root field for plugin lookup
      fieldPath: field,
      // Full path for nested access
      value,
      plugin: fieldPlugin2
    };
  }
  const fieldPlugin = resource._eventualConsistencyPlugins[field];
  if (!fieldPlugin) {
    const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
    throw new Error(
      `No eventual consistency plugin found for field "${field}". Available fields: ${availableFields}`
    );
  }
  return { field, fieldPath: field, value, plugin: fieldPlugin };
}
function groupByCohort(transactions, cohortField) {
  const groups = {};
  for (const txn of transactions) {
    const cohort = txn[cohortField];
    if (!cohort) continue;
    if (!groups[cohort]) {
      groups[cohort] = [];
    }
    groups[cohort].push(txn);
  }
  return groups;
}
function ensureCohortHour(transaction, timezone = "UTC", verbose = false) {
  if (transaction.cohortHour) {
    return transaction;
  }
  if (transaction.timestamp) {
    const date = new Date(transaction.timestamp);
    const cohortInfo = getCohortInfo(date, timezone, verbose);
    if (verbose) {
      console.log(
        `[EventualConsistency] Transaction ${transaction.id} missing cohortHour, calculated from timestamp: ${cohortInfo.hour}`
      );
    }
    transaction.cohortHour = cohortInfo.hour;
    if (!transaction.cohortWeek) {
      transaction.cohortWeek = cohortInfo.week;
    }
    if (!transaction.cohortMonth) {
      transaction.cohortMonth = cohortInfo.month;
    }
  } else if (verbose) {
    console.warn(
      `[EventualConsistency] Transaction ${transaction.id} missing both cohortHour and timestamp, cannot calculate cohort`
    );
  }
  return transaction;
}
function ensureCohortHours(transactions, timezone = "UTC", verbose = false) {
  if (!transactions || !Array.isArray(transactions)) {
    return transactions;
  }
  return transactions.map((txn) => ensureCohortHour(txn, timezone, verbose));
}

function createPartitionConfig() {
  const partitions = {
    // Composite partition by originalId + applied status
    // This is THE MOST CRITICAL optimization for consolidation!
    // Why: Consolidation always queries { originalId, applied: false }
    // Without this: Reads ALL transactions (applied + pending) and filters manually
    // With this: Reads ONLY pending transactions - can be 1000x faster!
    byOriginalIdAndApplied: {
      fields: {
        originalId: "string",
        applied: "boolean"
      }
    },
    // Partition by time cohorts for batch consolidation across many records
    byHour: {
      fields: {
        cohortHour: "string"
      }
    },
    byDay: {
      fields: {
        cohortDate: "string"
      }
    },
    byWeek: {
      fields: {
        cohortWeek: "string"
      }
    },
    byMonth: {
      fields: {
        cohortMonth: "string"
      }
    }
  };
  return partitions;
}

async function createTransaction(handler, data, config) {
  const now = /* @__PURE__ */ new Date();
  const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
  const watermarkMs = config.consolidationWindow * 60 * 60 * 1e3;
  const watermarkTime = now.getTime() - watermarkMs;
  const cohortHourDate = /* @__PURE__ */ new Date(cohortInfo.hour + ":00:00Z");
  if (cohortHourDate.getTime() < watermarkTime) {
    const hoursLate = Math.floor((now.getTime() - cohortHourDate.getTime()) / (60 * 60 * 1e3));
    if (config.lateArrivalStrategy === "ignore") {
      if (config.verbose) {
        console.warn(
          `[EventualConsistency] Late arrival ignored: transaction for ${cohortInfo.hour} is ${hoursLate}h late (watermark: ${config.consolidationWindow}h)`
        );
      }
      return null;
    } else if (config.lateArrivalStrategy === "warn") {
      console.warn(
        `[EventualConsistency] Late arrival detected: transaction for ${cohortInfo.hour} is ${hoursLate}h late (watermark: ${config.consolidationWindow}h). Processing anyway, but consolidation may not pick it up.`
      );
    }
  }
  const transaction = {
    id: idGenerator(),
    originalId: data.originalId,
    field: handler.field,
    value: data.value || 0,
    operation: data.operation || "set",
    timestamp: now.toISOString(),
    cohortDate: cohortInfo.date,
    cohortHour: cohortInfo.hour,
    cohortWeek: cohortInfo.week,
    cohortMonth: cohortInfo.month,
    source: data.source || "unknown",
    applied: false
  };
  if (config.batchTransactions) {
    handler.pendingTransactions.set(transaction.id, transaction);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${handler.resource}.${handler.field} - Transaction batched: ${data.operation} ${data.value} for ${data.originalId} (batch: ${handler.pendingTransactions.size}/${config.batchSize})`
      );
    }
    if (handler.pendingTransactions.size >= config.batchSize) {
      await flushPendingTransactions(handler);
    }
  } else {
    await handler.transactionResource.insert(transaction);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${handler.resource}.${handler.field} - Transaction created: ${data.operation} ${data.value} for ${data.originalId} (cohort: ${cohortInfo.hour}, applied: false)`
      );
    }
  }
  return transaction;
}
async function flushPendingTransactions(handler) {
  if (handler.pendingTransactions.size === 0) return;
  const transactions = Array.from(handler.pendingTransactions.values());
  try {
    await Promise.all(
      transactions.map(
        (transaction) => handler.transactionResource.insert(transaction)
      )
    );
    handler.pendingTransactions.clear();
  } catch (error) {
    console.error("Failed to flush pending transactions:", error);
    throw error;
  }
}

function startConsolidationTimer(handler, resourceName, fieldName, runConsolidationCallback, config) {
  const intervalMs = config.consolidationInterval * 1e3;
  if (config.verbose) {
    const nextRun = new Date(Date.now() + intervalMs);
    console.log(
      `[EventualConsistency] ${resourceName}.${fieldName} - Consolidation timer started. Next run at ${nextRun.toISOString()} (every ${config.consolidationInterval}s)`
    );
  }
  handler.consolidationTimer = setInterval(async () => {
    await runConsolidationCallback(handler, resourceName, fieldName);
  }, intervalMs);
  return handler.consolidationTimer;
}
async function runConsolidation(transactionResource, consolidateRecordFn, emitFn, config) {
  const startTime = Date.now();
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${config.resource}.${config.field} - Starting consolidation run at ${(/* @__PURE__ */ new Date()).toISOString()}`
    );
  }
  try {
    const now = /* @__PURE__ */ new Date();
    const hoursToCheck = config.consolidationWindow || 24;
    const cohortHours = [];
    for (let i = 0; i < hoursToCheck; i++) {
      const date = new Date(now.getTime() - i * 60 * 60 * 1e3);
      const cohortInfo = getCohortInfo(date, config.cohort.timezone, config.verbose);
      cohortHours.push(cohortInfo.hour);
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Querying ${hoursToCheck} hour partitions for pending transactions...`
      );
    }
    const transactionsByHour = await Promise.all(
      cohortHours.map(async (cohortHour) => {
        const [ok, err, txns] = await tryFn(
          () => transactionResource.query({
            cohortHour,
            applied: false
          })
        );
        return ok ? txns : [];
      })
    );
    const transactions = transactionsByHour.flat();
    if (transactions.length === 0) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No pending transactions found. Next run in ${config.consolidationInterval}s`
        );
      }
      return;
    }
    const uniqueIds = [...new Set(transactions.map((t) => t.originalId))];
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Found ${transactions.length} pending transactions for ${uniqueIds.length} records. Consolidating with concurrency=${config.consolidationConcurrency}...`
      );
    }
    const { results, errors } = await PromisePool.for(uniqueIds).withConcurrency(config.consolidationConcurrency).process(async (id) => {
      return await consolidateRecordFn(id);
    });
    const duration = Date.now() - startTime;
    if (errors && errors.length > 0) {
      console.error(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidation completed with ${errors.length} errors in ${duration}ms:`,
        errors
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidation complete: ${results.length} records consolidated in ${duration}ms (${errors.length} errors). Next run in ${config.consolidationInterval}s`
      );
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:consolidated", {
        resource: config.resource,
        field: config.field,
        recordCount: uniqueIds.length,
        successCount: results.length,
        errorCount: errors.length,
        duration
      });
    }
  } catch (error) {
    const duration = Date.now() - startTime;
    console.error(
      `[EventualConsistency] ${config.resource}.${config.field} - Consolidation error after ${duration}ms:`,
      error
    );
    if (emitFn) {
      emitFn("plg:eventual-consistency:consolidation-error", error);
    }
  }
}
async function consolidateRecord(originalId, transactionResource, targetResource, storage, analyticsResource, updateAnalyticsFn, config) {
  const lockKey = `consolidation-${config.resource}-${config.field}-${originalId}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: config.lockTimeout || 30,
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] Lock for ${originalId} already held, skipping`);
    }
    const [recordOk, recordErr, record] = await tryFn(
      () => targetResource.get(originalId)
    );
    return recordOk && record ? record[config.field] || 0 : 0;
  }
  try {
    const [ok, err, transactions] = await tryFn(
      () => transactionResource.query({
        originalId,
        applied: false
      })
    );
    if (!ok || !transactions || transactions.length === 0) {
      const [recordOk2, recordErr2, record2] = await tryFn(
        () => targetResource.get(originalId)
      );
      const currentValue2 = recordOk2 && record2 ? record2[config.field] || 0 : 0;
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No pending transactions for ${originalId}, skipping`
        );
      }
      return currentValue2;
    }
    const [appliedOk, appliedErr, appliedTransactions] = await tryFn(
      () => transactionResource.query({
        originalId,
        applied: true
      })
    );
    let currentValue = 0;
    if (appliedOk && appliedTransactions && appliedTransactions.length > 0) {
      const [recordExistsOk, recordExistsErr, recordExists] = await tryFn(
        () => targetResource.get(originalId)
      );
      if (!recordExistsOk || !recordExists) {
        if (config.verbose) {
          console.log(
            `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist, deleting ${appliedTransactions.length} old applied transactions`
          );
        }
        const { results, errors } = await PromisePool.for(appliedTransactions).withConcurrency(10).process(async (txn) => {
          const [deleted] = await tryFn(() => transactionResource.delete(txn.id));
          return deleted;
        });
        if (config.verbose && errors && errors.length > 0) {
          console.warn(
            `[EventualConsistency] ${config.resource}.${config.field} - Failed to delete ${errors.length} old applied transactions`
          );
        }
        currentValue = 0;
        appliedTransactions.length = 0;
      } else {
        appliedTransactions.sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        const hasSetInApplied = appliedTransactions.some((t) => t.operation === "set");
        if (!hasSetInApplied) {
          const recordValue = recordExists[config.field] || 0;
          if (typeof recordValue === "number") {
            let appliedDelta = 0;
            for (const t of appliedTransactions) {
              if (t.operation === "add") appliedDelta += t.value;
              else if (t.operation === "sub") appliedDelta -= t.value;
            }
            const baseValue = recordValue - appliedDelta;
            const hasExistingAnchor = appliedTransactions.some((t) => t.source === "anchor");
            if (baseValue !== 0 && typeof baseValue === "number" && !hasExistingAnchor) {
              const firstTransactionDate = new Date(appliedTransactions[0].timestamp);
              const cohortInfo = getCohortInfo(firstTransactionDate, config.cohort.timezone, config.verbose);
              const anchorTransaction = {
                id: idGenerator(),
                originalId,
                field: config.field,
                fieldPath: config.field,
                // Add fieldPath for consistency
                value: baseValue,
                operation: "set",
                timestamp: new Date(firstTransactionDate.getTime() - 1).toISOString(),
                // 1ms before first txn to ensure it's first
                cohortDate: cohortInfo.date,
                cohortHour: cohortInfo.hour,
                cohortMonth: cohortInfo.month,
                source: "anchor",
                applied: true
              };
              await transactionResource.insert(anchorTransaction);
              appliedTransactions.unshift(anchorTransaction);
            }
          }
        }
        currentValue = config.reducer(appliedTransactions);
      }
    } else {
      const [recordOk2, recordErr2, record2] = await tryFn(
        () => targetResource.get(originalId)
      );
      currentValue = recordOk2 && record2 ? record2[config.field] || 0 : 0;
      if (currentValue !== 0 && typeof currentValue === "number") {
        let anchorTimestamp;
        if (transactions && transactions.length > 0) {
          const firstPendingDate = new Date(transactions[0].timestamp);
          anchorTimestamp = new Date(firstPendingDate.getTime() - 1).toISOString();
        } else {
          anchorTimestamp = (/* @__PURE__ */ new Date()).toISOString();
        }
        const cohortInfo = getCohortInfo(new Date(anchorTimestamp), config.cohort.timezone, config.verbose);
        const anchorTransaction = {
          id: idGenerator(),
          originalId,
          field: config.field,
          fieldPath: config.field,
          // Add fieldPath for consistency
          value: currentValue,
          operation: "set",
          timestamp: anchorTimestamp,
          cohortDate: cohortInfo.date,
          cohortHour: cohortInfo.hour,
          cohortMonth: cohortInfo.month,
          source: "anchor",
          applied: true
        };
        await transactionResource.insert(anchorTransaction);
        if (config.verbose) {
          console.log(
            `[EventualConsistency] ${config.resource}.${config.field} - Created anchor transaction for ${originalId} with base value ${currentValue}`
          );
        }
      }
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Consolidating ${originalId}: ${transactions.length} pending transactions (current: ${currentValue} from ${appliedOk && appliedTransactions?.length > 0 ? "applied transactions" : "record"})`
      );
    }
    transactions.sort(
      (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
    );
    const transactionsByPath = {};
    for (const txn of transactions) {
      const path = txn.fieldPath || txn.field || config.field;
      if (!transactionsByPath[path]) {
        transactionsByPath[path] = [];
      }
      transactionsByPath[path].push(txn);
    }
    const appliedByPath = {};
    if (appliedOk && appliedTransactions && appliedTransactions.length > 0) {
      for (const txn of appliedTransactions) {
        const path = txn.fieldPath || txn.field || config.field;
        if (!appliedByPath[path]) {
          appliedByPath[path] = [];
        }
        appliedByPath[path].push(txn);
      }
    }
    const consolidatedValues = {};
    const lodash = await import('lodash-es');
    const [currentRecordOk, currentRecordErr, currentRecord] = await tryFn(
      () => targetResource.get(originalId)
    );
    for (const [fieldPath, pathTransactions] of Object.entries(transactionsByPath)) {
      let pathCurrentValue = 0;
      if (appliedByPath[fieldPath] && appliedByPath[fieldPath].length > 0) {
        appliedByPath[fieldPath].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        pathCurrentValue = config.reducer(appliedByPath[fieldPath]);
      } else {
        if (currentRecordOk && currentRecord) {
          const recordValue = lodash.get(currentRecord, fieldPath, 0);
          if (typeof recordValue === "number") {
            pathCurrentValue = recordValue;
          }
        }
      }
      if (pathCurrentValue !== 0) {
        pathTransactions.unshift(createSyntheticSetTransaction(pathCurrentValue));
      }
      const pathConsolidatedValue = config.reducer(pathTransactions);
      consolidatedValues[fieldPath] = pathConsolidatedValue;
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${fieldPath} - ${originalId}: ${pathCurrentValue} \u2192 ${pathConsolidatedValue} (${pathTransactions.length - (pathCurrentValue !== 0 ? 1 : 0)} pending txns)`
        );
      }
    }
    if (config.verbose) {
      console.log(
        `\u{1F525} [DEBUG] BEFORE targetResource.update() {
  originalId: '${originalId}',
  consolidatedValues: ${JSON.stringify(consolidatedValues, null, 2)}
}`
      );
    }
    const [recordOk, recordErr, record] = await tryFn(
      () => targetResource.get(originalId)
    );
    let updateOk, updateErr, updateResult;
    if (!recordOk || !record) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist yet. Will attempt update anyway (expected to fail).`
        );
      }
      const minimalRecord = { id: originalId };
      for (const [fieldPath, value] of Object.entries(consolidatedValues)) {
        lodash.set(minimalRecord, fieldPath, value);
      }
      const result = await tryFn(
        () => targetResource.update(originalId, minimalRecord)
      );
      updateOk = result[0];
      updateErr = result[1];
      updateResult = result[2];
    } else {
      for (const [fieldPath, value] of Object.entries(consolidatedValues)) {
        lodash.set(record, fieldPath, value);
      }
      const result = await tryFn(
        () => targetResource.update(originalId, record)
      );
      updateOk = result[0];
      updateErr = result[1];
      updateResult = result[2];
    }
    const consolidatedValue = consolidatedValues[config.field] || (record ? lodash.get(record, config.field, 0) : 0);
    if (config.verbose) {
      console.log(
        `\u{1F525} [DEBUG] AFTER targetResource.update() {
  updateOk: ${updateOk},
  updateErr: ${updateErr?.message || "undefined"},
  consolidatedValue (main field): ${consolidatedValue}
}`
      );
    }
    if (updateOk && config.verbose) {
      const [verifyOk, verifyErr, verifiedRecord] = await tryFn(
        () => targetResource.get(originalId, { skipCache: true })
      );
      for (const [fieldPath, expectedValue] of Object.entries(consolidatedValues)) {
        const actualValue = lodash.get(verifiedRecord, fieldPath);
        const match = actualValue === expectedValue;
        console.log(
          `\u{1F525} [DEBUG] VERIFICATION ${fieldPath} {
  expectedValue: ${expectedValue},
  actualValue: ${actualValue},
  ${match ? "\u2705 MATCH" : "\u274C MISMATCH"}
}`
        );
        if (!match) {
          console.error(
            `\u274C [CRITICAL BUG] Update reported success but value not persisted!
  Resource: ${config.resource}
  FieldPath: ${fieldPath}
  Record ID: ${originalId}
  Expected: ${expectedValue}
  Actually got: ${actualValue}
  This indicates a bug in s3db.js resource.update()`
          );
        }
      }
    }
    if (!updateOk) {
      if (updateErr?.message?.includes("does not exist")) {
        if (config.verbose) {
          console.warn(
            `[EventualConsistency] ${config.resource}.${config.field} - Record ${originalId} doesn't exist. Skipping consolidation. ${transactions.length} transactions will remain pending until record is created.`
          );
        }
        return consolidatedValue;
      }
      console.error(
        `[EventualConsistency] ${config.resource}.${config.field} - FAILED to update ${originalId}: ${updateErr?.message || updateErr}`,
        { error: updateErr, consolidatedValue, currentValue }
      );
      throw updateErr;
    }
    if (updateOk) {
      const transactionsToUpdate = transactions.filter((txn) => txn.id !== "__synthetic__");
      const markAppliedConcurrency = config.markAppliedConcurrency || 50;
      const { results, errors } = await PromisePool.for(transactionsToUpdate).withConcurrency(markAppliedConcurrency).process(async (txn) => {
        const txnWithCohorts = ensureCohortHour(txn, config.cohort.timezone, false);
        const updateData = { applied: true };
        if (txnWithCohorts.cohortHour && !txn.cohortHour) {
          updateData.cohortHour = txnWithCohorts.cohortHour;
        }
        if (txnWithCohorts.cohortDate && !txn.cohortDate) {
          updateData.cohortDate = txnWithCohorts.cohortDate;
        }
        if (txnWithCohorts.cohortWeek && !txn.cohortWeek) {
          updateData.cohortWeek = txnWithCohorts.cohortWeek;
        }
        if (txnWithCohorts.cohortMonth && !txn.cohortMonth) {
          updateData.cohortMonth = txnWithCohorts.cohortMonth;
        }
        const [ok2, err2] = await tryFn(
          () => transactionResource.update(txn.id, updateData)
        );
        if (!ok2 && config.verbose) {
          console.warn(
            `[EventualConsistency] Failed to mark transaction ${txn.id} as applied:`,
            err2?.message,
            "Update data:",
            updateData
          );
        }
        return ok2;
      });
      if (errors && errors.length > 0 && config.verbose) {
        console.warn(`[EventualConsistency] ${errors.length} transactions failed to mark as applied`);
      }
      if (config.enableAnalytics && transactionsToUpdate.length > 0 && updateAnalyticsFn) {
        const [analyticsOk, analyticsErr] = await tryFn(
          () => updateAnalyticsFn(transactionsToUpdate)
        );
        if (!analyticsOk) {
          console.error(
            `[EventualConsistency] ${config.resource}.${config.field} - CRITICAL: Analytics update failed for ${originalId}, but consolidation succeeded:`,
            {
              error: analyticsErr?.message || analyticsErr,
              stack: analyticsErr?.stack,
              originalId,
              transactionCount: transactionsToUpdate.length
            }
          );
        }
      }
      if (targetResource && targetResource.cache && typeof targetResource.cache.delete === "function") {
        try {
          const cacheKey = await targetResource.cacheKeyFor({ id: originalId });
          await targetResource.cache.delete(cacheKey);
          if (config.verbose) {
            console.log(
              `[EventualConsistency] ${config.resource}.${config.field} - Cache invalidated for ${originalId}`
            );
          }
        } catch (cacheErr) {
          if (config.verbose) {
            console.warn(
              `[EventualConsistency] ${config.resource}.${config.field} - Failed to invalidate cache for ${originalId}: ${cacheErr?.message}`
            );
          }
        }
      }
    }
    return consolidatedValue;
  } finally {
    const [lockReleased, lockReleaseErr] = await tryFn(
      () => storage.releaseLock(lockKey)
    );
    if (!lockReleased && config.verbose) {
      console.warn(`[EventualConsistency] Failed to release lock ${lockKey}:`, lockReleaseErr?.message);
    }
  }
}
async function getConsolidatedValue(originalId, options, transactionResource, targetResource, config) {
  const includeApplied = options.includeApplied || false;
  const startDate = options.startDate;
  const endDate = options.endDate;
  const query = { originalId };
  if (!includeApplied) {
    query.applied = false;
  }
  const [ok, err, transactions] = await tryFn(
    () => transactionResource.query(query)
  );
  if (!ok || !transactions || transactions.length === 0) {
    const [recordOk2, recordErr2, record2] = await tryFn(
      () => targetResource.get(originalId)
    );
    if (recordOk2 && record2) {
      return record2[config.field] || 0;
    }
    return 0;
  }
  let filtered = transactions;
  if (startDate || endDate) {
    filtered = transactions.filter((t) => {
      const timestamp = new Date(t.timestamp);
      if (startDate && timestamp < new Date(startDate)) return false;
      if (endDate && timestamp > new Date(endDate)) return false;
      return true;
    });
  }
  const [recordOk, recordErr, record] = await tryFn(
    () => targetResource.get(originalId)
  );
  const currentValue = recordOk && record ? record[config.field] || 0 : 0;
  const hasSetOperation = filtered.some((t) => t.operation === "set");
  if (currentValue !== 0 && !hasSetOperation) {
    filtered.unshift(createSyntheticSetTransaction(currentValue));
  }
  filtered.sort(
    (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
  );
  return config.reducer(filtered);
}
async function getCohortStats(cohortDate, transactionResource) {
  const [ok, err, transactions] = await tryFn(
    () => transactionResource.query({
      cohortDate
    })
  );
  if (!ok) return null;
  const stats = {
    date: cohortDate,
    transactionCount: transactions.length,
    totalValue: 0,
    byOperation: { set: 0, add: 0, sub: 0 },
    byOriginalId: {}
  };
  for (const txn of transactions) {
    stats.totalValue += txn.value || 0;
    stats.byOperation[txn.operation] = (stats.byOperation[txn.operation] || 0) + 1;
    if (!stats.byOriginalId[txn.originalId]) {
      stats.byOriginalId[txn.originalId] = {
        count: 0,
        value: 0
      };
    }
    stats.byOriginalId[txn.originalId].count++;
    stats.byOriginalId[txn.originalId].value += txn.value || 0;
  }
  return stats;
}
async function recalculateRecord(originalId, transactionResource, targetResource, storage, consolidateRecordFn, config) {
  const lockKey = `recalculate-${config.resource}-${config.field}-${originalId}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: config.lockTimeout || 30,
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] Recalculate lock for ${originalId} already held, skipping`);
    }
    throw new Error(`Cannot recalculate ${originalId}: lock already held by another worker`);
  }
  try {
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Starting recalculation for ${originalId} (resetting all transactions to pending)`
      );
    }
    const [allOk, allErr, allTransactions] = await tryFn(
      () => transactionResource.query({
        originalId
      })
    );
    if (!allOk || !allTransactions || allTransactions.length === 0) {
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - No transactions found for ${originalId}, nothing to recalculate`
        );
      }
      return 0;
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Found ${allTransactions.length} total transactions for ${originalId}, marking all as pending...`
      );
    }
    const hasAnchor = allTransactions.some((txn) => txn.source === "anchor");
    if (!hasAnchor) {
      const now = /* @__PURE__ */ new Date();
      const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
      const oldestTransaction = allTransactions.sort(
        (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
      )[0];
      const anchorTimestamp = oldestTransaction ? new Date(new Date(oldestTransaction.timestamp).getTime() - 1).toISOString() : now.toISOString();
      const anchorCohortInfo = getCohortInfo(new Date(anchorTimestamp), config.cohort.timezone, config.verbose);
      const anchorTransaction = {
        id: idGenerator(),
        originalId,
        field: config.field,
        fieldPath: config.field,
        value: 0,
        // Always 0 for recalculate - we start from scratch
        operation: "set",
        timestamp: anchorTimestamp,
        cohortDate: anchorCohortInfo.date,
        cohortHour: anchorCohortInfo.hour,
        cohortMonth: anchorCohortInfo.month,
        source: "anchor",
        applied: true
        // Anchor is always applied
      };
      await transactionResource.insert(anchorTransaction);
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Created anchor transaction for ${originalId} with value 0`
        );
      }
    }
    const transactionsToReset = allTransactions.filter((txn) => txn.source !== "anchor");
    const recalculateConcurrency = config.recalculateConcurrency || 50;
    const { results, errors } = await PromisePool.for(transactionsToReset).withConcurrency(recalculateConcurrency).process(async (txn) => {
      const [ok, err] = await tryFn(
        () => transactionResource.update(txn.id, { applied: false })
      );
      if (!ok && config.verbose) {
        console.warn(`[EventualConsistency] Failed to reset transaction ${txn.id}:`, err?.message);
      }
      return ok;
    });
    if (errors && errors.length > 0) {
      console.warn(
        `[EventualConsistency] ${config.resource}.${config.field} - Failed to reset ${errors.length} transactions during recalculation`
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Reset ${results.length} transactions to pending, now resetting record value and running consolidation...`
      );
    }
    const [resetOk, resetErr] = await tryFn(
      () => targetResource.update(originalId, {
        [config.field]: 0
      })
    );
    if (!resetOk && config.verbose) {
      console.warn(
        `[EventualConsistency] ${config.resource}.${config.field} - Failed to reset record value for ${originalId}: ${resetErr?.message}`
      );
    }
    const consolidatedValue = await consolidateRecordFn(originalId);
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Recalculation complete for ${originalId}: final value = ${consolidatedValue}`
      );
    }
    return consolidatedValue;
  } finally {
    const [lockReleased, lockReleaseErr] = await tryFn(
      () => storage.releaseLock(lockKey)
    );
    if (!lockReleased && config.verbose) {
      console.warn(`[EventualConsistency] Failed to release recalculate lock ${lockKey}:`, lockReleaseErr?.message);
    }
  }
}

function startGarbageCollectionTimer(handler, resourceName, fieldName, runGCCallback, config) {
  const gcIntervalMs = config.gcInterval * 1e3;
  handler.gcTimer = setInterval(async () => {
    await runGCCallback(handler, resourceName, fieldName);
  }, gcIntervalMs);
  return handler.gcTimer;
}
async function runGarbageCollection(transactionResource, storage, config, emitFn) {
  const lockKey = `gc-${config.resource}-${config.field}`;
  const lock = await storage.acquireLock(lockKey, {
    ttl: 300,
    // 5 minutes for GC
    timeout: 0,
    // Don't wait if locked
    workerId: process.pid ? String(process.pid) : "unknown"
  });
  if (!lock) {
    if (config.verbose) {
      console.log(`[EventualConsistency] GC already running in another container`);
    }
    return;
  }
  try {
    const now = Date.now();
    const retentionMs = config.transactionRetention * 24 * 60 * 60 * 1e3;
    const cutoffDate = new Date(now - retentionMs);
    const cutoffIso = cutoffDate.toISOString();
    if (config.verbose) {
      console.log(`[EventualConsistency] Running GC for transactions older than ${cutoffIso} (${config.transactionRetention} days)`);
    }
    const [ok, err, oldTransactions] = await tryFn(
      () => transactionResource.query({
        applied: true,
        timestamp: { "<": cutoffIso }
      })
    );
    if (!ok) {
      if (config.verbose) {
        console.warn(`[EventualConsistency] GC failed to query transactions:`, err?.message);
      }
      return;
    }
    if (!oldTransactions || oldTransactions.length === 0) {
      if (config.verbose) {
        console.log(`[EventualConsistency] No old transactions to clean up`);
      }
      return;
    }
    if (config.verbose) {
      console.log(`[EventualConsistency] Deleting ${oldTransactions.length} old transactions`);
    }
    const { results, errors } = await PromisePool.for(oldTransactions).withConcurrency(10).process(async (txn) => {
      const [deleted] = await tryFn(() => transactionResource.delete(txn.id));
      return deleted;
    });
    if (config.verbose) {
      console.log(`[EventualConsistency] GC completed: ${results.length} deleted, ${errors.length} errors`);
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:gc-completed", {
        resource: config.resource,
        field: config.field,
        deletedCount: results.length,
        errorCount: errors.length
      });
    }
  } catch (error) {
    if (config.verbose) {
      console.warn(`[EventualConsistency] GC error:`, error.message);
    }
    if (emitFn) {
      emitFn("plg:eventual-consistency:gc-error", error);
    }
  } finally {
    await tryFn(() => storage.releaseLock(lockKey));
  }
}

async function updateAnalytics(transactions, analyticsResource, config) {
  if (!analyticsResource || transactions.length === 0) return;
  if (!config.field) {
    throw new Error(
      `[EventualConsistency] CRITICAL BUG: config.field is undefined in updateAnalytics()!
This indicates a race condition in the plugin where multiple handlers are sharing the same config object.
Config: ${JSON.stringify({ resource: config.resource, field: config.field })}
Transactions count: ${transactions.length}
AnalyticsResource: ${analyticsResource?.name || "unknown"}`
    );
  }
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${config.resource}.${config.field} - Updating analytics for ${transactions.length} transactions...`
    );
  }
  try {
    const byHour = groupByCohort(transactions, "cohortHour");
    const cohortCount = Object.keys(byHour).length;
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Updating ${cohortCount} hourly analytics cohorts IN PARALLEL...`
      );
    }
    await Promise.all(
      Object.entries(byHour).map(
        ([cohort, txns]) => upsertAnalytics("hour", cohort, txns, analyticsResource, config)
      )
    );
    if (config.analyticsConfig.rollupStrategy === "incremental") {
      const uniqueHours = Object.keys(byHour);
      if (config.verbose) {
        console.log(
          `[EventualConsistency] ${config.resource}.${config.field} - Rolling up ${uniqueHours.length} hours to daily/weekly/monthly analytics IN PARALLEL...`
        );
      }
      await Promise.all(
        uniqueHours.map(
          (cohortHour) => rollupAnalytics(cohortHour, analyticsResource, config)
        )
      );
    }
    if (config.verbose) {
      console.log(
        `[EventualConsistency] ${config.resource}.${config.field} - Analytics update complete for ${cohortCount} cohorts`
      );
    }
  } catch (error) {
    console.error(
      `[EventualConsistency] CRITICAL: ${config.resource}.${config.field} - Analytics update failed:`,
      {
        error: error.message,
        stack: error.stack,
        field: config.field,
        resource: config.resource,
        transactionCount: transactions.length
      }
    );
    throw new Error(
      `Analytics update failed for ${config.resource}.${config.field}: ${error.message}`
    );
  }
}
async function upsertAnalytics(period, cohort, transactions, analyticsResource, config) {
  const id = `${period}-${cohort}`;
  const transactionCount = transactions.length;
  const signedValues = transactions.map((t) => {
    if (t.operation === "sub") return -t.value;
    return t.value;
  });
  const totalValue = signedValues.reduce((sum, v) => sum + v, 0);
  const avgValue = totalValue / transactionCount;
  const minValue = Math.min(...signedValues);
  const maxValue = Math.max(...signedValues);
  const operations = calculateOperationBreakdown(transactions);
  const recordCount = new Set(transactions.map((t) => t.originalId)).size;
  const now = (/* @__PURE__ */ new Date()).toISOString();
  const [existingOk, existingErr, existing] = await tryFn(
    () => analyticsResource.get(id)
  );
  if (existingOk && existing) {
    const newTransactionCount = existing.transactionCount + transactionCount;
    const newTotalValue = existing.totalValue + totalValue;
    const newAvgValue = newTotalValue / newTransactionCount;
    const newMinValue = Math.min(existing.minValue, minValue);
    const newMaxValue = Math.max(existing.maxValue, maxValue);
    const newOperations = { ...existing.operations };
    for (const [op, stats] of Object.entries(operations)) {
      if (!newOperations[op]) {
        newOperations[op] = { count: 0, sum: 0 };
      }
      newOperations[op].count += stats.count;
      newOperations[op].sum += stats.sum;
    }
    const newRecordCount = Math.max(existing.recordCount, recordCount);
    await tryFn(
      () => analyticsResource.update(id, {
        transactionCount: newTransactionCount,
        totalValue: newTotalValue,
        avgValue: newAvgValue,
        minValue: newMinValue,
        maxValue: newMaxValue,
        operations: newOperations,
        recordCount: newRecordCount,
        updatedAt: now
      })
    );
  } else {
    await tryFn(
      () => analyticsResource.insert({
        id,
        field: config.field,
        period,
        cohort,
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        consolidatedAt: now,
        updatedAt: now
      })
    );
  }
}
function calculateOperationBreakdown(transactions) {
  const breakdown = {};
  for (const txn of transactions) {
    const op = txn.operation;
    if (!breakdown[op]) {
      breakdown[op] = { count: 0, sum: 0 };
    }
    breakdown[op].count++;
    const signedValue = op === "sub" ? -txn.value : txn.value;
    breakdown[op].sum += signedValue;
  }
  return breakdown;
}
async function rollupAnalytics(cohortHour, analyticsResource, config) {
  const cohortDate = cohortHour.substring(0, 10);
  const cohortMonth = cohortHour.substring(0, 7);
  const date = new Date(cohortDate);
  const cohortWeek = getCohortWeekFromDate(date);
  await rollupPeriod("day", cohortDate, cohortDate, analyticsResource, config);
  await rollupPeriod("week", cohortWeek, cohortWeek, analyticsResource, config);
  await rollupPeriod("month", cohortMonth, cohortMonth, analyticsResource, config);
}
function getCohortWeekFromDate(date) {
  const target = new Date(date.valueOf());
  const dayNr = (date.getUTCDay() + 6) % 7;
  target.setUTCDate(target.getUTCDate() - dayNr + 3);
  const yearStart = new Date(Date.UTC(target.getUTCFullYear(), 0, 1));
  const firstThursday = new Date(yearStart.valueOf());
  if (yearStart.getUTCDay() !== 4) {
    firstThursday.setUTCDate(yearStart.getUTCDate() + (4 - yearStart.getUTCDay() + 7) % 7);
  }
  const weekNumber = 1 + Math.round((target - firstThursday) / 6048e5);
  const weekYear = target.getUTCFullYear();
  return `${weekYear}-W${String(weekNumber).padStart(2, "0")}`;
}
async function rollupPeriod(period, cohort, sourcePrefix, analyticsResource, config) {
  let sourcePeriod;
  if (period === "day") {
    sourcePeriod = "hour";
  } else if (period === "week") {
    sourcePeriod = "day";
  } else if (period === "month") {
    sourcePeriod = "day";
  } else {
    sourcePeriod = "day";
  }
  const [ok, err, allAnalytics] = await tryFn(
    () => analyticsResource.list()
  );
  if (!ok || !allAnalytics) return;
  let sourceAnalytics;
  if (period === "week") {
    sourceAnalytics = allAnalytics.filter((a) => {
      if (a.period !== sourcePeriod) return false;
      const dayDate = new Date(a.cohort);
      const dayWeek = getCohortWeekFromDate(dayDate);
      return dayWeek === cohort;
    });
  } else {
    sourceAnalytics = allAnalytics.filter(
      (a) => a.period === sourcePeriod && a.cohort.startsWith(sourcePrefix)
    );
  }
  if (sourceAnalytics.length === 0) return;
  const transactionCount = sourceAnalytics.reduce((sum, a) => sum + a.transactionCount, 0);
  const totalValue = sourceAnalytics.reduce((sum, a) => sum + a.totalValue, 0);
  const avgValue = totalValue / transactionCount;
  const minValue = Math.min(...sourceAnalytics.map((a) => a.minValue));
  const maxValue = Math.max(...sourceAnalytics.map((a) => a.maxValue));
  const operations = {};
  for (const analytics of sourceAnalytics) {
    for (const [op, stats] of Object.entries(analytics.operations || {})) {
      if (!operations[op]) {
        operations[op] = { count: 0, sum: 0 };
      }
      operations[op].count += stats.count;
      operations[op].sum += stats.sum;
    }
  }
  const recordCount = Math.max(...sourceAnalytics.map((a) => a.recordCount));
  const id = `${period}-${cohort}`;
  const now = (/* @__PURE__ */ new Date()).toISOString();
  const [existingOk, existingErr, existing] = await tryFn(
    () => analyticsResource.get(id)
  );
  if (existingOk && existing) {
    await tryFn(
      () => analyticsResource.update(id, {
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        updatedAt: now
      })
    );
  } else {
    await tryFn(
      () => analyticsResource.insert({
        id,
        field: config.field,
        period,
        cohort,
        transactionCount,
        totalValue,
        avgValue,
        minValue,
        maxValue,
        operations,
        recordCount,
        consolidatedAt: now,
        updatedAt: now
      })
    );
  }
}
function fillGaps(data, period, startDate, endDate) {
  if (!data || data.length === 0) {
    data = [];
  }
  const dataMap = /* @__PURE__ */ new Map();
  data.forEach((item) => {
    dataMap.set(item.cohort, item);
  });
  const result = [];
  const emptyRecord = {
    count: 0,
    sum: 0,
    avg: 0,
    min: 0,
    max: 0,
    recordCount: 0
  };
  if (period === "hour") {
    const start = /* @__PURE__ */ new Date(startDate + "T00:00:00Z");
    const end = /* @__PURE__ */ new Date(endDate + "T23:59:59Z");
    for (let dt = new Date(start); dt <= end; dt.setHours(dt.getHours() + 1)) {
      const cohort = dt.toISOString().substring(0, 13);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
    }
  } else if (period === "day") {
    const start = new Date(startDate);
    const end = new Date(endDate);
    for (let dt = new Date(start); dt <= end; dt.setDate(dt.getDate() + 1)) {
      const cohort = dt.toISOString().substring(0, 10);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
    }
  } else if (period === "month") {
    const startYear = parseInt(startDate.substring(0, 4));
    const startMonth = parseInt(startDate.substring(5, 7));
    const endYear = parseInt(endDate.substring(0, 4));
    const endMonth = parseInt(endDate.substring(5, 7));
    for (let year = startYear; year <= endYear; year++) {
      const firstMonth = year === startYear ? startMonth : 1;
      const lastMonth = year === endYear ? endMonth : 12;
      for (let month = firstMonth; month <= lastMonth; month++) {
        const cohort = `${year}-${month.toString().padStart(2, "0")}`;
        result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      }
    }
  }
  return result;
}
async function getAnalytics(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new Error(`No eventual consistency configured for resource: ${resourceName}`);
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new Error(`No eventual consistency configured for field: ${resourceName}.${field}`);
  }
  if (!handler.analyticsResource) {
    throw new Error("Analytics not enabled for this plugin");
  }
  const { period = "day", date, startDate, endDate, month, year, breakdown = false, recordId } = options;
  if (recordId) {
    return await getAnalyticsForRecord(resourceName, field, recordId, options, handler);
  }
  const [ok, err, allAnalytics] = await tryFn(
    () => handler.analyticsResource.list()
  );
  if (!ok || !allAnalytics) {
    return [];
  }
  let filtered = allAnalytics.filter((a) => a.period === period);
  if (date) {
    if (period === "hour") {
      filtered = filtered.filter((a) => a.cohort.startsWith(date));
    } else {
      filtered = filtered.filter((a) => a.cohort === date);
    }
  } else if (startDate && endDate) {
    filtered = filtered.filter((a) => a.cohort >= startDate && a.cohort <= endDate);
  } else if (month) {
    filtered = filtered.filter((a) => a.cohort.startsWith(month));
  } else if (year) {
    filtered = filtered.filter((a) => a.cohort.startsWith(String(year)));
  }
  filtered.sort((a, b) => a.cohort.localeCompare(b.cohort));
  if (breakdown === "operations") {
    return filtered.map((a) => ({
      cohort: a.cohort,
      ...a.operations
    }));
  }
  return filtered.map((a) => ({
    cohort: a.cohort,
    count: a.transactionCount,
    sum: a.totalValue,
    avg: a.avgValue,
    min: a.minValue,
    max: a.maxValue,
    operations: a.operations,
    recordCount: a.recordCount
  }));
}
async function getAnalyticsForRecord(resourceName, field, recordId, options, handler) {
  const { period = "day", date, startDate, endDate, month, year } = options;
  const [okTrue, errTrue, appliedTransactions] = await tryFn(
    () => handler.transactionResource.query({
      originalId: recordId,
      applied: true
    })
  );
  const [okFalse, errFalse, pendingTransactions] = await tryFn(
    () => handler.transactionResource.query({
      originalId: recordId,
      applied: false
    })
  );
  let allTransactions = [
    ...okTrue && appliedTransactions ? appliedTransactions : [],
    ...okFalse && pendingTransactions ? pendingTransactions : []
  ];
  if (allTransactions.length === 0) {
    return [];
  }
  allTransactions = ensureCohortHours(allTransactions, handler.config?.cohort?.timezone || "UTC", false);
  let filtered = allTransactions;
  if (date) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(date));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate === date);
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(date));
    }
  } else if (startDate && endDate) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour >= startDate && t.cohortHour <= endDate);
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate >= startDate && t.cohortDate <= endDate);
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth >= startDate && t.cohortMonth <= endDate);
    }
  } else if (month) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(month));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate.startsWith(month));
    }
  } else if (year) {
    if (period === "hour") {
      filtered = filtered.filter((t) => t.cohortHour && t.cohortHour.startsWith(String(year)));
    } else if (period === "day") {
      filtered = filtered.filter((t) => t.cohortDate && t.cohortDate.startsWith(String(year)));
    } else if (period === "month") {
      filtered = filtered.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(String(year)));
    }
  }
  const cohortField = period === "hour" ? "cohortHour" : period === "day" ? "cohortDate" : "cohortMonth";
  const aggregated = aggregateTransactionsByCohort(filtered, cohortField);
  return aggregated;
}
function aggregateTransactionsByCohort(transactions, cohortField) {
  const groups = {};
  for (const txn of transactions) {
    const cohort = txn[cohortField];
    if (!cohort) continue;
    if (!groups[cohort]) {
      groups[cohort] = {
        cohort,
        count: 0,
        sum: 0,
        min: Infinity,
        max: -Infinity,
        recordCount: /* @__PURE__ */ new Set(),
        operations: {}
      };
    }
    const group = groups[cohort];
    const signedValue = txn.operation === "sub" ? -txn.value : txn.value;
    group.count++;
    group.sum += signedValue;
    group.min = Math.min(group.min, signedValue);
    group.max = Math.max(group.max, signedValue);
    group.recordCount.add(txn.originalId);
    const op = txn.operation;
    if (!group.operations[op]) {
      group.operations[op] = { count: 0, sum: 0 };
    }
    group.operations[op].count++;
    group.operations[op].sum += signedValue;
  }
  return Object.values(groups).map((g) => ({
    cohort: g.cohort,
    count: g.count,
    sum: g.sum,
    avg: g.sum / g.count,
    min: g.min === Infinity ? 0 : g.min,
    max: g.max === -Infinity ? 0 : g.max,
    recordCount: g.recordCount.size,
    operations: g.operations
  })).sort((a, b) => a.cohort.localeCompare(b.cohort));
}
async function getMonthByDay(resourceName, field, month, options, fieldHandlers) {
  const year = parseInt(month.substring(0, 4));
  const monthNum = parseInt(month.substring(5, 7));
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const startDate = firstDay.toISOString().substring(0, 10);
  const endDate = lastDay.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getDayByHour(resourceName, field, date, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    date
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", date, date);
  }
  return data;
}
async function getLastNDays(resourceName, field, days, options, fieldHandlers) {
  const dates = Array.from({ length: days }, (_, i) => {
    const date = /* @__PURE__ */ new Date();
    date.setDate(date.getDate() - i);
    return date.toISOString().substring(0, 10);
  }).reverse();
  const data = await getAnalytics(resourceName, field, {
    ...options,
    // ✅ Include all options (recordId, etc.)
    period: "day",
    startDate: dates[0],
    endDate: dates[dates.length - 1]
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", dates[0], dates[dates.length - 1]);
  }
  return data;
}
async function getYearByMonth(resourceName, field, year, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "month",
    year
  }, fieldHandlers);
  if (options.fillGaps) {
    const startDate = `${year}-01`;
    const endDate = `${year}-12`;
    return fillGaps(data, "month", startDate, endDate);
  }
  return data;
}
async function getYearByWeek(resourceName, field, year, options, fieldHandlers) {
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    year
  }, fieldHandlers);
  if (options.fillGaps) {
    const startWeek = `${year}-W01`;
    const endWeek = `${year}-W53`;
    return fillGaps(data, "week", startWeek, endWeek);
  }
  return data;
}
async function getMonthByWeek(resourceName, field, month, options, fieldHandlers) {
  const year = parseInt(month.substring(0, 4));
  const monthNum = parseInt(month.substring(5, 7));
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const firstWeek = getCohortWeekFromDate(firstDay);
  const lastWeek = getCohortWeekFromDate(lastDay);
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    startDate: firstWeek,
    endDate: lastWeek
  }, fieldHandlers);
  return data;
}
async function getMonthByHour(resourceName, field, month, options, fieldHandlers) {
  let year, monthNum;
  if (month === "last") {
    const now = /* @__PURE__ */ new Date();
    now.setMonth(now.getMonth() - 1);
    year = now.getFullYear();
    monthNum = now.getMonth() + 1;
  } else {
    year = parseInt(month.substring(0, 4));
    monthNum = parseInt(month.substring(5, 7));
  }
  const firstDay = new Date(year, monthNum - 1, 1);
  const lastDay = new Date(year, monthNum, 0);
  const startDate = firstDay.toISOString().substring(0, 10);
  const endDate = lastDay.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", startDate, endDate);
  }
  return data;
}
async function getTopRecords(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new Error(`No eventual consistency configured for resource: ${resourceName}`);
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new Error(`No eventual consistency configured for field: ${resourceName}.${field}`);
  }
  if (!handler.transactionResource) {
    throw new Error("Transaction resource not initialized");
  }
  const { period = "day", date, metric = "transactionCount", limit = 10 } = options;
  const [ok, err, transactions] = await tryFn(
    () => handler.transactionResource.list()
  );
  if (!ok || !transactions) {
    return [];
  }
  let filtered = transactions;
  if (date) {
    if (period === "hour") {
      filtered = transactions.filter((t) => t.cohortHour && t.cohortHour.startsWith(date));
    } else if (period === "day") {
      filtered = transactions.filter((t) => t.cohortDate === date);
    } else if (period === "month") {
      filtered = transactions.filter((t) => t.cohortMonth && t.cohortMonth.startsWith(date));
    }
  }
  const byRecord = {};
  for (const txn of filtered) {
    const recordId = txn.originalId;
    if (!byRecord[recordId]) {
      byRecord[recordId] = { count: 0, sum: 0 };
    }
    byRecord[recordId].count++;
    byRecord[recordId].sum += txn.value;
  }
  const records = Object.entries(byRecord).map(([recordId, stats]) => ({
    recordId,
    count: stats.count,
    sum: stats.sum
  }));
  records.sort((a, b) => {
    if (metric === "transactionCount") {
      return b.count - a.count;
    } else if (metric === "totalValue") {
      return b.sum - a.sum;
    }
    return 0;
  });
  return records.slice(0, limit);
}
async function getYearByDay(resourceName, field, year, options, fieldHandlers) {
  const startDate = `${year}-01-01`;
  const endDate = `${year}-12-31`;
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getWeekByDay(resourceName, field, week, options, fieldHandlers) {
  const year = parseInt(week.substring(0, 4));
  const weekNum = parseInt(week.substring(6, 8));
  const jan4 = new Date(Date.UTC(year, 0, 4));
  const jan4Day = jan4.getUTCDay() || 7;
  const firstMonday = new Date(Date.UTC(year, 0, 4 - jan4Day + 1));
  const weekStart = new Date(firstMonday);
  weekStart.setUTCDate(weekStart.getUTCDate() + (weekNum - 1) * 7);
  const days = [];
  for (let i = 0; i < 7; i++) {
    const day = new Date(weekStart);
    day.setUTCDate(weekStart.getUTCDate() + i);
    days.push(day.toISOString().substring(0, 10));
  }
  const startDate = days[0];
  const endDate = days[6];
  const data = await getAnalytics(resourceName, field, {
    period: "day",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "day", startDate, endDate);
  }
  return data;
}
async function getWeekByHour(resourceName, field, week, options, fieldHandlers) {
  const year = parseInt(week.substring(0, 4));
  const weekNum = parseInt(week.substring(6, 8));
  const jan4 = new Date(Date.UTC(year, 0, 4));
  const jan4Day = jan4.getUTCDay() || 7;
  const firstMonday = new Date(Date.UTC(year, 0, 4 - jan4Day + 1));
  const weekStart = new Date(firstMonday);
  weekStart.setUTCDate(weekStart.getUTCDate() + (weekNum - 1) * 7);
  const weekEnd = new Date(weekStart);
  weekEnd.setUTCDate(weekEnd.getUTCDate() + 6);
  const startDate = weekStart.toISOString().substring(0, 10);
  const endDate = weekEnd.toISOString().substring(0, 10);
  const data = await getAnalytics(resourceName, field, {
    period: "hour",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    return fillGaps(data, "hour", startDate, endDate);
  }
  return data;
}
async function getLastNHours(resourceName, field, hours = 24, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const hoursAgo = new Date(now);
  hoursAgo.setHours(hoursAgo.getHours() - hours + 1);
  const startHour = hoursAgo.toISOString().substring(0, 13);
  const endHour = now.toISOString().substring(0, 13);
  const data = await getAnalytics(resourceName, field, {
    ...options,
    // ✅ Include all options (recordId, etc.)
    period: "hour",
    startDate: startHour,
    endDate: endHour
  }, fieldHandlers);
  if (options.fillGaps) {
    const result = [];
    const emptyRecord = { count: 0, sum: 0, avg: 0, min: 0, max: 0, recordCount: 0 };
    const dataMap = new Map(data.map((d) => [d.cohort, d]));
    const current = new Date(hoursAgo);
    for (let i = 0; i < hours; i++) {
      const cohort = current.toISOString().substring(0, 13);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      current.setHours(current.getHours() + 1);
    }
    return result;
  }
  return data;
}
async function getLastNWeeks(resourceName, field, weeks = 4, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const weeksAgo = new Date(now);
  weeksAgo.setDate(weeksAgo.getDate() - weeks * 7);
  const weekCohorts = [];
  const currentDate = new Date(weeksAgo);
  while (currentDate <= now) {
    const weekCohort = getCohortWeekFromDate(currentDate);
    if (!weekCohorts.includes(weekCohort)) {
      weekCohorts.push(weekCohort);
    }
    currentDate.setDate(currentDate.getDate() + 7);
  }
  const startWeek = weekCohorts[0];
  const endWeek = weekCohorts[weekCohorts.length - 1];
  const data = await getAnalytics(resourceName, field, {
    period: "week",
    startDate: startWeek,
    endDate: endWeek
  }, fieldHandlers);
  return data;
}
async function getLastNMonths(resourceName, field, months = 12, options, fieldHandlers) {
  const now = /* @__PURE__ */ new Date();
  const monthsAgo = new Date(now);
  monthsAgo.setMonth(monthsAgo.getMonth() - months + 1);
  const startDate = monthsAgo.toISOString().substring(0, 7);
  const endDate = now.toISOString().substring(0, 7);
  const data = await getAnalytics(resourceName, field, {
    ...options,
    // ✅ Include all options (recordId, etc.)
    period: "month",
    startDate,
    endDate
  }, fieldHandlers);
  if (options.fillGaps) {
    const result = [];
    const emptyRecord = { count: 0, sum: 0, avg: 0, min: 0, max: 0, recordCount: 0 };
    const dataMap = new Map(data.map((d) => [d.cohort, d]));
    const current = new Date(monthsAgo);
    for (let i = 0; i < months; i++) {
      const cohort = current.toISOString().substring(0, 7);
      result.push(dataMap.get(cohort) || { cohort, ...emptyRecord });
      current.setMonth(current.getMonth() + 1);
    }
    return result;
  }
  return data;
}
async function getRawEvents(resourceName, field, options, fieldHandlers) {
  const resourceHandlers = fieldHandlers.get(resourceName);
  if (!resourceHandlers) {
    throw new Error(`No eventual consistency configured for resource: ${resourceName}`);
  }
  const handler = resourceHandlers.get(field);
  if (!handler) {
    throw new Error(`No eventual consistency configured for field: ${resourceName}.${field}`);
  }
  if (!handler.transactionResource) {
    throw new Error("Transaction resource not initialized");
  }
  const {
    recordId,
    startDate,
    endDate,
    cohortDate,
    cohortHour,
    cohortMonth,
    applied,
    operation,
    limit
  } = options;
  const query = {};
  if (recordId !== void 0) {
    query.originalId = recordId;
  }
  if (applied !== void 0) {
    query.applied = applied;
  }
  const [ok, err, allTransactions] = await tryFn(
    () => handler.transactionResource.query(query)
  );
  if (!ok || !allTransactions) {
    return [];
  }
  let filtered = allTransactions;
  if (operation !== void 0) {
    filtered = filtered.filter((t) => t.operation === operation);
  }
  if (cohortDate) {
    filtered = filtered.filter((t) => t.cohortDate === cohortDate);
  }
  if (cohortHour) {
    filtered = filtered.filter((t) => t.cohortHour === cohortHour);
  }
  if (cohortMonth) {
    filtered = filtered.filter((t) => t.cohortMonth === cohortMonth);
  }
  if (startDate && endDate) {
    const isHourly = startDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter(
      (t) => t[cohortField] && t[cohortField] >= startDate && t[cohortField] <= endDate
    );
  } else if (startDate) {
    const isHourly = startDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter((t) => t[cohortField] && t[cohortField] >= startDate);
  } else if (endDate) {
    const isHourly = endDate.length > 10;
    const cohortField = isHourly ? "cohortHour" : "cohortDate";
    filtered = filtered.filter((t) => t[cohortField] && t[cohortField] <= endDate);
  }
  filtered.sort((a, b) => {
    const aTime = new Date(a.timestamp || a.createdAt).getTime();
    const bTime = new Date(b.timestamp || b.createdAt).getTime();
    return bTime - aTime;
  });
  if (limit && limit > 0) {
    filtered = filtered.slice(0, limit);
  }
  return filtered;
}

function addHelperMethods(resource, plugin, config) {
  resource.set = async (id, field, value) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, value);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value,
      operation: "set",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "set",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    return value;
  };
  resource.add = async (id, field, amount) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, amount);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value: amount,
      operation: "add",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "add",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    const [ok, err, record] = await tryFn(() => handler.targetResource.get(id));
    if (!ok || !record) return amount;
    const lodash = await import('lodash-es');
    const currentValue = lodash.get(record, fieldPath, 0);
    return currentValue + amount;
  };
  resource.sub = async (id, field, amount) => {
    const { field: rootField, fieldPath, plugin: handler } = resolveFieldAndPlugin(resource, field, amount);
    const now = /* @__PURE__ */ new Date();
    const cohortInfo = getCohortInfo(now, config.cohort.timezone, config.verbose);
    const transaction = {
      id: idGenerator(),
      originalId: id,
      field: handler.field,
      fieldPath,
      // Store full path for nested access
      value: amount,
      operation: "sub",
      timestamp: now.toISOString(),
      cohortDate: cohortInfo.date,
      cohortHour: cohortInfo.hour,
      cohortMonth: cohortInfo.month,
      source: "sub",
      applied: false
    };
    await handler.transactionResource.insert(transaction);
    if (config.mode === "sync") {
      return await plugin._syncModeConsolidate(handler, id, fieldPath);
    }
    const [ok, err, record] = await tryFn(() => handler.targetResource.get(id));
    if (!ok || !record) return -amount;
    const lodash = await import('lodash-es');
    const currentValue = lodash.get(record, fieldPath, 0);
    return currentValue - amount;
  };
  resource.increment = async (id, field) => {
    return await resource.add(id, field, 1);
  };
  resource.decrement = async (id, field) => {
    return await resource.sub(id, field, 1);
  };
  resource.consolidate = async (id, field) => {
    if (!field) {
      throw new Error(`Field parameter is required: consolidate(id, field)`);
    }
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new Error(
        `No eventual consistency plugin found for field "${field}". Available fields: ${availableFields}`
      );
    }
    return await plugin._consolidateWithHandler(handler, id);
  };
  resource.getConsolidatedValue = async (id, field, options = {}) => {
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new Error(
        `No eventual consistency plugin found for field "${field}". Available fields: ${availableFields}`
      );
    }
    return await plugin._getConsolidatedValueWithHandler(handler, id, options);
  };
  resource.recalculate = async (id, field) => {
    if (!field) {
      throw new Error(`Field parameter is required: recalculate(id, field)`);
    }
    const handler = resource._eventualConsistencyPlugins[field];
    if (!handler) {
      const availableFields = Object.keys(resource._eventualConsistencyPlugins).join(", ");
      throw new Error(
        `No eventual consistency plugin found for field "${field}". Available fields: ${availableFields}`
      );
    }
    return await plugin._recalculateWithHandler(handler, id);
  };
}

async function onInstall(database, fieldHandlers, completeFieldSetupFn, watchForResourceFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    const targetResource = database.resources[resourceName];
    if (!targetResource) {
      for (const handler of resourceHandlers.values()) {
        handler.deferredSetup = true;
      }
      watchForResourceFn(resourceName);
      continue;
    }
    for (const [fieldName, handler] of resourceHandlers) {
      handler.targetResource = targetResource;
      await completeFieldSetupFn(handler);
    }
  }
}
function watchForResource(resourceName, database, fieldHandlers, completeFieldSetupFn) {
  const hookCallback = async ({ resource, config }) => {
    if (config.name === resourceName) {
      const resourceHandlers = fieldHandlers.get(resourceName);
      if (!resourceHandlers) return;
      for (const [fieldName, handler] of resourceHandlers) {
        if (handler.deferredSetup) {
          handler.targetResource = resource;
          handler.deferredSetup = false;
          await completeFieldSetupFn(handler);
        }
      }
    }
  };
  database.addHook("afterCreateResource", hookCallback);
}
async function completeFieldSetup(handler, database, config, plugin) {
  if (!handler.targetResource) return;
  const resourceName = handler.resource;
  const fieldName = handler.field;
  const transactionResourceName = `plg_${resourceName}_tx_${fieldName}`;
  const partitionConfig = createPartitionConfig();
  const [ok, err, transactionResource] = await tryFn(
    () => database.createResource({
      name: transactionResourceName,
      attributes: {
        id: "string|required",
        originalId: "string|required",
        field: "string|required",
        fieldPath: "string|optional",
        // Support for nested field paths (e.g., 'utmResults.medium')
        value: "number|required",
        operation: "string|required",
        timestamp: "string|required",
        cohortDate: "string|required",
        cohortHour: "string|required",
        cohortWeek: "string|optional",
        cohortMonth: "string|optional",
        source: "string|optional",
        applied: "boolean|optional"
      },
      behavior: "body-overflow",
      timestamps: true,
      partitions: partitionConfig,
      asyncPartitions: true,
      createdBy: "EventualConsistencyPlugin"
    })
  );
  if (!ok && !database.resources[transactionResourceName]) {
    throw new Error(`Failed to create transaction resource for ${resourceName}.${fieldName}: ${err?.message}`);
  }
  handler.transactionResource = ok ? transactionResource : database.resources[transactionResourceName];
  if (config.enableAnalytics) {
    await createAnalyticsResource(handler, database, resourceName, fieldName);
  }
  addHelperMethodsForHandler(handler, plugin, config);
  if (config.verbose) {
    console.log(
      `[EventualConsistency] ${resourceName}.${fieldName} - Setup complete. Resources: ${transactionResourceName}${config.enableAnalytics ? `, plg_${resourceName}_an_${fieldName}` : ""} (locks via PluginStorage TTL)`
    );
  }
}
async function createAnalyticsResource(handler, database, resourceName, fieldName) {
  const analyticsResourceName = `plg_${resourceName}_an_${fieldName}`;
  const [ok, err, analyticsResource] = await tryFn(
    () => database.createResource({
      name: analyticsResourceName,
      attributes: {
        id: "string|required",
        field: "string|required",
        period: "string|required",
        cohort: "string|required",
        transactionCount: "number|required",
        totalValue: "number|required",
        avgValue: "number|required",
        minValue: "number|required",
        maxValue: "number|required",
        operations: "object|optional",
        recordCount: "number|required",
        consolidatedAt: "string|required",
        updatedAt: "string|required"
      },
      behavior: "body-overflow",
      timestamps: false,
      asyncPartitions: true,
      // ✅ Multi-attribute partitions for optimal analytics query performance
      partitions: {
        // Query by period (hour/day/week/month)
        byPeriod: {
          fields: { period: "string" }
        },
        // Query by period + cohort (e.g., all hour records for specific hours)
        byPeriodCohort: {
          fields: {
            period: "string",
            cohort: "string"
          }
        },
        // Query by field + period (e.g., all daily analytics for clicks field)
        byFieldPeriod: {
          fields: {
            field: "string",
            period: "string"
          }
        }
      },
      createdBy: "EventualConsistencyPlugin"
    })
  );
  if (!ok && !database.resources[analyticsResourceName]) {
    throw new Error(`Failed to create analytics resource for ${resourceName}.${fieldName}: ${err?.message}`);
  }
  handler.analyticsResource = ok ? analyticsResource : database.resources[analyticsResourceName];
}
function addHelperMethodsForHandler(handler, plugin, config) {
  const resource = handler.targetResource;
  const fieldName = handler.field;
  if (!resource._eventualConsistencyPlugins) {
    resource._eventualConsistencyPlugins = {};
  }
  resource._eventualConsistencyPlugins[fieldName] = handler;
  if (!resource.add) {
    addHelperMethods(resource, plugin, config);
  }
}
async function onStart(fieldHandlers, config, runConsolidationFn, runGCFn, emitFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    for (const [fieldName, handler] of resourceHandlers) {
      if (!handler.deferredSetup) {
        if (config.autoConsolidate && config.mode === "async") {
          startConsolidationTimer(handler, resourceName, fieldName, runConsolidationFn, config);
        }
        if (config.transactionRetention && config.transactionRetention > 0) {
          startGarbageCollectionTimer(handler, resourceName, fieldName, runGCFn, config);
        }
        if (emitFn) {
          emitFn("plg:eventual-consistency:started", {
            resource: resourceName,
            field: fieldName,
            cohort: config.cohort
          });
        }
      }
    }
  }
}
async function onStop(fieldHandlers, emitFn) {
  for (const [resourceName, resourceHandlers] of fieldHandlers) {
    for (const [fieldName, handler] of resourceHandlers) {
      if (handler.consolidationTimer) {
        clearInterval(handler.consolidationTimer);
        handler.consolidationTimer = null;
      }
      if (handler.gcTimer) {
        clearInterval(handler.gcTimer);
        handler.gcTimer = null;
      }
      if (handler.pendingTransactions && handler.pendingTransactions.size > 0) {
        await flushPendingTransactions(handler);
      }
      if (emitFn) {
        emitFn("plg:eventual-consistency:stopped", {
          resource: resourceName,
          field: fieldName
        });
      }
    }
  }
}

class EventualConsistencyPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    validateResourcesConfig(options.resources);
    const detectedTimezone = detectTimezone();
    const timezoneAutoDetected = !options.cohort?.timezone;
    this.config = createConfig(options, detectedTimezone);
    this.fieldHandlers = /* @__PURE__ */ new Map();
    for (const [resourceName, fields] of Object.entries(options.resources)) {
      const resourceHandlers = /* @__PURE__ */ new Map();
      for (const fieldName of fields) {
        resourceHandlers.set(fieldName, createFieldHandler(resourceName, fieldName));
      }
      this.fieldHandlers.set(resourceName, resourceHandlers);
    }
    logConfigWarnings(this.config);
    logInitialization(this.config, this.fieldHandlers, timezoneAutoDetected);
  }
  /**
   * Install hook - create resources and register helpers
   */
  async onInstall() {
    await onInstall(
      this.database,
      this.fieldHandlers,
      (handler) => completeFieldSetup(handler, this.database, this.config, this),
      (resourceName) => watchForResource(
        resourceName,
        this.database,
        this.fieldHandlers,
        (handler) => completeFieldSetup(handler, this.database, this.config, this)
      )
    );
  }
  /**
   * Start hook - begin timers and emit events
   */
  async onStart() {
    await onStart(
      this.fieldHandlers,
      this.config,
      (handler, resourceName, fieldName) => this._runConsolidationForHandler(handler, resourceName, fieldName),
      (handler, resourceName, fieldName) => this._runGarbageCollectionForHandler(handler, resourceName, fieldName),
      (event, data) => this.emit(event, data)
    );
  }
  /**
   * Stop hook - stop timers and flush pending
   */
  async onStop() {
    await onStop(
      this.fieldHandlers,
      (event, data) => this.emit(event, data)
    );
  }
  /**
   * Create partition configuration
   * @returns {Object} Partition configuration
   */
  createPartitionConfig() {
    return createPartitionConfig();
  }
  /**
   * Get cohort information for a date
   * @param {Date} date - Date to get cohort info for
   * @returns {Object} Cohort information
   */
  getCohortInfo(date) {
    return getCohortInfo(date, this.config.cohort.timezone, this.config.verbose);
  }
  /**
   * Create a transaction for a field handler
   * @param {Object} handler - Field handler
   * @param {Object} data - Transaction data
   * @returns {Promise<Object|null>} Created transaction
   */
  async createTransaction(handler, data) {
    return await createTransaction(handler, data, this.config);
  }
  /**
   * Consolidate a single record (internal method)
   * This is used internally by consolidation timers and helper methods
   * @private
   */
  async consolidateRecord(originalId) {
    return await consolidateRecord(
      originalId,
      this.transactionResource,
      this.targetResource,
      this.getStorage(),
      this.analyticsResource,
      (transactions) => this.updateAnalytics(transactions),
      this.config
    );
  }
  /**
   * Get consolidated value without applying (internal method)
   * @private
   */
  async getConsolidatedValue(originalId, options = {}) {
    return await getConsolidatedValue(
      originalId,
      options,
      this.transactionResource,
      this.targetResource,
      this.config
    );
  }
  /**
   * Get cohort statistics
   * @param {string} cohortDate - Cohort date
   * @returns {Promise<Object|null>} Cohort statistics
   */
  async getCohortStats(cohortDate) {
    return await getCohortStats(cohortDate, this.transactionResource);
  }
  /**
   * Recalculate from scratch (internal method)
   * @private
   */
  async recalculateRecord(originalId) {
    return await recalculateRecord(
      originalId,
      this.transactionResource,
      this.targetResource,
      this.getStorage(),
      (id) => this.consolidateRecord(id),
      this.config
    );
  }
  /**
   * Update analytics
   * @private
   */
  async updateAnalytics(transactions) {
    return await updateAnalytics(transactions, this.analyticsResource, this.config);
  }
  /**
   * Helper method for sync mode consolidation
   * @private
   */
  async _syncModeConsolidate(handler, id, field) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.consolidateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Helper method for consolidate with handler
   * @private
   */
  async _consolidateWithHandler(handler, id) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.consolidateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Helper method for getConsolidatedValue with handler
   * @private
   */
  async _getConsolidatedValueWithHandler(handler, id, options) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    const result = await this.getConsolidatedValue(id, options);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    return result;
  }
  /**
   * Helper method for recalculate with handler
   * @private
   */
  async _recalculateWithHandler(handler, id) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = handler.resource;
    this.config.field = handler.field;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    const result = await this.recalculateRecord(id);
    this.config.resource = oldResource;
    this.config.field = oldField;
    this.transactionResource = oldTransactionResource;
    this.targetResource = oldTargetResource;
    this.analyticsResource = oldAnalyticsResource;
    return result;
  }
  /**
   * Run consolidation for a handler
   * @private
   */
  async _runConsolidationForHandler(handler, resourceName, fieldName) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    const oldAnalyticsResource = this.analyticsResource;
    this.config.resource = resourceName;
    this.config.field = fieldName;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    this.analyticsResource = handler.analyticsResource;
    try {
      await runConsolidation(
        this.transactionResource,
        (id) => this.consolidateRecord(id),
        (event, data) => this.emit(event, data),
        this.config
      );
    } finally {
      this.config.resource = oldResource;
      this.config.field = oldField;
      this.transactionResource = oldTransactionResource;
      this.targetResource = oldTargetResource;
      this.analyticsResource = oldAnalyticsResource;
    }
  }
  /**
   * Run garbage collection for a handler
   * @private
   */
  async _runGarbageCollectionForHandler(handler, resourceName, fieldName) {
    const oldResource = this.config.resource;
    const oldField = this.config.field;
    const oldTransactionResource = this.transactionResource;
    const oldTargetResource = this.targetResource;
    this.config.resource = resourceName;
    this.config.field = fieldName;
    this.transactionResource = handler.transactionResource;
    this.targetResource = handler.targetResource;
    try {
      await runGarbageCollection(
        this.transactionResource,
        this.getStorage(),
        this.config,
        (event, data) => this.emit(event, data)
      );
    } finally {
      this.config.resource = oldResource;
      this.config.field = oldField;
      this.transactionResource = oldTransactionResource;
      this.targetResource = oldTargetResource;
    }
  }
  // Public Analytics API
  /**
   * Get analytics for a specific period
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @returns {Promise<Array>} Analytics data
   */
  async getAnalytics(resourceName, field, options = {}) {
    return await getAnalytics(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the month
   */
  async getMonthByDay(resourceName, field, month, options = {}) {
    return await getMonthByDay(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire day, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} date - Date in YYYY-MM-DD format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the day
   */
  async getDayByHour(resourceName, field, date, options = {}) {
    return await getDayByHour(resourceName, field, date, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N days, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} days - Number of days to look back (default: 7)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics
   */
  async getLastNDays(resourceName, field, days = 7, options = {}) {
    return await getLastNDays(resourceName, field, days, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by months
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Monthly analytics for the year
   */
  async getYearByMonth(resourceName, field, year, options = {}) {
    return await getYearByMonth(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format (or 'last' for previous month)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the month
   */
  async getMonthByHour(resourceName, field, month, options = {}) {
    return await getMonthByHour(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics for the year (up to 53 weeks)
   */
  async getYearByWeek(resourceName, field, year, options = {}) {
    return await getYearByWeek(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire month, broken down by weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} month - Month in YYYY-MM format
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics for the month
   */
  async getMonthByWeek(resourceName, field, month, options = {}) {
    return await getMonthByWeek(resourceName, field, month, options, this.fieldHandlers);
  }
  /**
   * Get top records by volume
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @returns {Promise<Array>} Top records
   */
  async getTopRecords(resourceName, field, options = {}) {
    return await getTopRecords(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire year, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} year - Year (e.g., 2025)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the year (up to 365/366 records)
   */
  async getYearByDay(resourceName, field, year, options = {}) {
    return await getYearByDay(resourceName, field, year, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire week, broken down by days
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} week - Week in YYYY-Www format (e.g., '2025-W42')
   * @param {Object} options - Options
   * @returns {Promise<Array>} Daily analytics for the week (7 records)
   */
  async getWeekByDay(resourceName, field, week, options = {}) {
    return await getWeekByDay(resourceName, field, week, options, this.fieldHandlers);
  }
  /**
   * Get analytics for entire week, broken down by hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {string} week - Week in YYYY-Www format (e.g., '2025-W42')
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics for the week (168 records)
   */
  async getWeekByHour(resourceName, field, week, options = {}) {
    return await getWeekByHour(resourceName, field, week, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N hours
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} hours - Number of hours to look back (default: 24)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Hourly analytics
   */
  async getLastNHours(resourceName, field, hours = 24, options = {}) {
    return await getLastNHours(resourceName, field, hours, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N weeks
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} weeks - Number of weeks to look back (default: 4)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Weekly analytics
   */
  async getLastNWeeks(resourceName, field, weeks = 4, options = {}) {
    return await getLastNWeeks(resourceName, field, weeks, options, this.fieldHandlers);
  }
  /**
   * Get analytics for last N months
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {number} months - Number of months to look back (default: 12)
   * @param {Object} options - Options
   * @returns {Promise<Array>} Monthly analytics
   */
  async getLastNMonths(resourceName, field, months = 12, options = {}) {
    return await getLastNMonths(resourceName, field, months, options, this.fieldHandlers);
  }
  /**
   * Get raw transaction events for custom aggregation
   *
   * This method provides direct access to the underlying transaction events,
   * allowing developers to perform custom aggregations beyond the pre-built analytics.
   * Useful for complex queries, custom metrics, or when you need the raw event data.
   *
   * @param {string} resourceName - Resource name
   * @param {string} field - Field name
   * @param {Object} options - Query options
   * @param {string} options.recordId - Filter by specific record ID
   * @param {string} options.startDate - Start date filter (YYYY-MM-DD or YYYY-MM-DDTHH)
   * @param {string} options.endDate - End date filter (YYYY-MM-DD or YYYY-MM-DDTHH)
   * @param {string} options.cohortDate - Filter by cohort date (YYYY-MM-DD)
   * @param {string} options.cohortHour - Filter by cohort hour (YYYY-MM-DDTHH)
   * @param {string} options.cohortMonth - Filter by cohort month (YYYY-MM)
   * @param {boolean} options.applied - Filter by applied status (true/false/undefined for both)
   * @param {string} options.operation - Filter by operation type ('add', 'sub', 'set')
   * @param {number} options.limit - Maximum number of events to return
   * @returns {Promise<Array>} Raw transaction events
   *
   * @example
   * // Get all events for a specific record
   * const events = await plugin.getRawEvents('wallets', 'balance', {
   *   recordId: 'wallet1'
   * });
   *
   * @example
   * // Get events for a specific time range
   * const events = await plugin.getRawEvents('wallets', 'balance', {
   *   startDate: '2025-10-01',
   *   endDate: '2025-10-31'
   * });
   *
   * @example
   * // Get only pending (unapplied) transactions
   * const pending = await plugin.getRawEvents('wallets', 'balance', {
   *   applied: false
   * });
   */
  async getRawEvents(resourceName, field, options = {}) {
    return await getRawEvents(resourceName, field, options, this.fieldHandlers);
  }
  /**
   * Get diagnostics information about the plugin state
   *
   * This method provides comprehensive diagnostic information about the EventualConsistencyPlugin,
   * including configured resources, field handlers, timers, and overall health status.
   * Useful for debugging initialization issues, configuration problems, or runtime errors.
   *
   * @param {Object} options - Diagnostic options
   * @param {string} options.resourceName - Optional: limit diagnostics to specific resource
   * @param {string} options.field - Optional: limit diagnostics to specific field
   * @param {boolean} options.includeStats - Include transaction statistics (default: false)
   * @returns {Promise<Object>} Diagnostic information
   *
   * @example
   * // Get overall plugin diagnostics
   * const diagnostics = await plugin.getDiagnostics();
   * console.log(diagnostics);
   *
   * @example
   * // Get diagnostics for specific resource/field with stats
   * const diagnostics = await plugin.getDiagnostics({
   *   resourceName: 'wallets',
   *   field: 'balance',
   *   includeStats: true
   * });
   */
  async getDiagnostics(options = {}) {
    const { resourceName, field, includeStats = false } = options;
    const diagnostics = {
      plugin: {
        name: "EventualConsistencyPlugin",
        initialized: this.database !== null && this.database !== void 0,
        verbose: this.config.verbose || false,
        timezone: this.config.cohort?.timezone || "UTC",
        consolidation: {
          mode: this.config.consolidation?.mode || "timer",
          interval: this.config.consolidation?.interval || 6e4,
          batchSize: this.config.consolidation?.batchSize || 100
        },
        garbageCollection: {
          enabled: this.config.garbageCollection?.enabled !== false,
          retentionDays: this.config.garbageCollection?.retentionDays || 30,
          interval: this.config.garbageCollection?.interval || 36e5
        }
      },
      resources: [],
      errors: [],
      warnings: []
    };
    for (const [resName, resourceHandlers] of this.fieldHandlers.entries()) {
      if (resourceName && resName !== resourceName) {
        continue;
      }
      const resourceDiag = {
        name: resName,
        fields: []
      };
      for (const [fieldName, handler] of resourceHandlers.entries()) {
        if (field && fieldName !== field) {
          continue;
        }
        const fieldDiag = {
          name: fieldName,
          type: handler.type || "counter",
          analyticsEnabled: handler.analyticsResource !== null && handler.analyticsResource !== void 0,
          resources: {
            transaction: handler.transactionResource?.name || null,
            target: handler.targetResource?.name || null,
            analytics: handler.analyticsResource?.name || null
          },
          timers: {
            consolidation: handler.consolidationTimer !== null && handler.consolidationTimer !== void 0,
            garbageCollection: handler.garbageCollectionTimer !== null && handler.garbageCollectionTimer !== void 0
          }
        };
        if (!handler.transactionResource) {
          diagnostics.errors.push({
            resource: resName,
            field: fieldName,
            issue: "Missing transaction resource",
            suggestion: "Ensure plugin is installed and resources are created after plugin installation"
          });
        }
        if (!handler.targetResource) {
          diagnostics.warnings.push({
            resource: resName,
            field: fieldName,
            issue: "Missing target resource",
            suggestion: "Target resource may not have been created yet"
          });
        }
        if (handler.analyticsResource && !handler.analyticsResource.name) {
          diagnostics.errors.push({
            resource: resName,
            field: fieldName,
            issue: "Invalid analytics resource",
            suggestion: "Analytics resource exists but has no name - possible initialization failure"
          });
        }
        if (includeStats && handler.transactionResource) {
          try {
            const [okPending, errPending, pendingTxns] = await handler.transactionResource.query({ applied: false }).catch(() => [false, null, []]);
            const [okApplied, errApplied, appliedTxns] = await handler.transactionResource.query({ applied: true }).catch(() => [false, null, []]);
            fieldDiag.stats = {
              pendingTransactions: okPending ? pendingTxns?.length || 0 : "error",
              appliedTransactions: okApplied ? appliedTxns?.length || 0 : "error",
              totalTransactions: okPending && okApplied ? (pendingTxns?.length || 0) + (appliedTxns?.length || 0) : "error"
            };
            if (handler.analyticsResource) {
              const [okAnalytics, errAnalytics, analyticsRecords] = await handler.analyticsResource.list().catch(() => [false, null, []]);
              fieldDiag.stats.analyticsRecords = okAnalytics ? analyticsRecords?.length || 0 : "error";
            }
          } catch (error) {
            diagnostics.warnings.push({
              resource: resName,
              field: fieldName,
              issue: "Failed to fetch statistics",
              error: error.message
            });
          }
        }
        resourceDiag.fields.push(fieldDiag);
      }
      if (resourceDiag.fields.length > 0) {
        diagnostics.resources.push(resourceDiag);
      }
    }
    diagnostics.health = {
      status: diagnostics.errors.length === 0 ? diagnostics.warnings.length === 0 ? "healthy" : "warning" : "error",
      totalResources: diagnostics.resources.length,
      totalFields: diagnostics.resources.reduce((sum, r) => sum + r.fields.length, 0),
      errorCount: diagnostics.errors.length,
      warningCount: diagnostics.warnings.length
    };
    return diagnostics;
  }
}

class FulltextError extends S3dbError {
  constructor(message, details = {}) {
    const { resourceName, query, operation = "unknown", ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Fulltext Search Operation Error

Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}
${query ? `Query: ${query}` : ""}

Common causes:
1. Resource not indexed for fulltext search
2. Invalid query syntax
3. Index not built yet
4. Search configuration missing
5. Field not indexed

Solution:
Ensure resource is configured for fulltext search and index is built.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/fulltext.md
`.trim();
    }
    super(message, { ...rest, resourceName, query, operation, description });
  }
}

class FullTextPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.indexResource = null;
    this.config = {
      minWordLength: options.minWordLength || 3,
      maxResults: options.maxResults || 100,
      ...options
    };
    this.indexes = /* @__PURE__ */ new Map();
    this.dirtyIndexes = /* @__PURE__ */ new Set();
    this.deletedIndexes = /* @__PURE__ */ new Set();
  }
  async onInstall() {
    const [ok, err, indexResource] = await tryFn(() => this.database.createResource({
      name: "plg_fulltext_indexes",
      attributes: {
        id: "string|required",
        resourceName: "string|required",
        fieldName: "string|required",
        word: "string|required",
        recordIds: "json|required",
        // Array of record IDs containing this word
        count: "number|required",
        lastUpdated: "string|required"
      },
      partitions: {
        byResource: { fields: { resourceName: "string" } }
      },
      behavior: "body-overflow"
    }));
    this.indexResource = ok ? indexResource : this.database.resources.fulltext_indexes;
    await this.loadIndexes();
    this.installDatabaseHooks();
    this.installIndexingHooks();
  }
  async start() {
  }
  async stop() {
    await this.saveIndexes();
    this.removeDatabaseHooks();
  }
  async loadIndexes() {
    if (!this.indexResource) return;
    const [ok, err, allIndexes] = await tryFn(() => this.indexResource.getAll());
    if (ok) {
      for (const indexRecord of allIndexes) {
        const key = `${indexRecord.resourceName}:${indexRecord.fieldName}:${indexRecord.word}`;
        this.indexes.set(key, {
          recordIds: indexRecord.recordIds || [],
          count: indexRecord.count || 0
        });
      }
    }
  }
  async saveIndexes() {
    if (!this.indexResource) return;
    const [ok, err] = await tryFn(async () => {
      for (const key of this.deletedIndexes) {
        const [resourceName] = key.split(":");
        const [queryOk, queryErr, results] = await tryFn(
          () => this.indexResource.query({ resourceName })
        );
        if (queryOk && results) {
          for (const index of results) {
            const indexKey = `${index.resourceName}:${index.fieldName}:${index.word}`;
            if (indexKey === key) {
              await this.indexResource.delete(index.id);
            }
          }
        }
      }
      for (const key of this.dirtyIndexes) {
        const [resourceName, fieldName, word] = key.split(":");
        const data = this.indexes.get(key);
        if (!data) continue;
        const [queryOk, queryErr, results] = await tryFn(
          () => this.indexResource.query({ resourceName })
        );
        let existingRecord = null;
        if (queryOk && results) {
          existingRecord = results.find(
            (index) => index.resourceName === resourceName && index.fieldName === fieldName && index.word === word
          );
        }
        if (existingRecord) {
          await this.indexResource.update(existingRecord.id, {
            recordIds: data.recordIds,
            count: data.count,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } else {
          await this.indexResource.insert({
            id: `index-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName,
            fieldName,
            word,
            recordIds: data.recordIds,
            count: data.count,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
      }
      this.dirtyIndexes.clear();
      this.deletedIndexes.clear();
    });
  }
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", (resource) => {
      if (resource.name !== "plg_fulltext_indexes") {
        this.installResourceHooks(resource);
      }
    });
  }
  removeDatabaseHooks() {
    this.database.removeHook("afterCreateResource", this.installResourceHooks.bind(this));
  }
  installIndexingHooks() {
    if (!this.database.plugins) {
      this.database.plugins = {};
    }
    this.database.plugins.fulltext = this;
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name === "plg_fulltext_indexes") continue;
      this.installResourceHooks(resource);
    }
    if (!this.database._fulltextProxyInstalled) {
      this.database._previousCreateResourceForFullText = this.database.createResource;
      this.database.createResource = async function(...args) {
        const resource = await this._previousCreateResourceForFullText(...args);
        if (this.plugins?.fulltext && resource.name !== "plg_fulltext_indexes") {
          this.plugins.fulltext.installResourceHooks(resource);
        }
        return resource;
      };
      this.database._fulltextProxyInstalled = true;
    }
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name !== "plg_fulltext_indexes") {
        this.installResourceHooks(resource);
      }
    }
  }
  installResourceHooks(resource) {
    resource._insert = resource.insert;
    resource._update = resource.update;
    resource._delete = resource.delete;
    resource._deleteMany = resource.deleteMany;
    this.wrapResourceMethod(resource, "insert", async (result, args, methodName) => {
      const [data] = args;
      this.indexRecord(resource.name, result.id, data).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "update", async (result, args, methodName) => {
      const [id, data] = args;
      this.removeRecordFromIndex(resource.name, id).catch(() => {
      });
      this.indexRecord(resource.name, id, result).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "delete", async (result, args, methodName) => {
      const [id] = args;
      this.removeRecordFromIndex(resource.name, id).catch(() => {
      });
      return result;
    });
    this.wrapResourceMethod(resource, "deleteMany", async (result, args, methodName) => {
      const [ids] = args;
      for (const id of ids) {
        this.removeRecordFromIndex(resource.name, id).catch(() => {
        });
      }
      return result;
    });
  }
  async indexRecord(resourceName, recordId, data) {
    const indexedFields = this.getIndexedFields(resourceName);
    if (!indexedFields || indexedFields.length === 0) {
      return;
    }
    for (const fieldName of indexedFields) {
      const fieldValue = this.getFieldValue(data, fieldName);
      if (!fieldValue) {
        continue;
      }
      const words = this.tokenize(fieldValue);
      for (const word of words) {
        if (word.length < this.config.minWordLength) {
          continue;
        }
        const key = `${resourceName}:${fieldName}:${word.toLowerCase()}`;
        const existing = this.indexes.get(key) || { recordIds: [], count: 0 };
        if (!existing.recordIds.includes(recordId)) {
          existing.recordIds.push(recordId);
          existing.count = existing.recordIds.length;
        }
        this.indexes.set(key, existing);
        this.dirtyIndexes.add(key);
      }
    }
  }
  async removeRecordFromIndex(resourceName, recordId) {
    for (const [key, data] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        const index = data.recordIds.indexOf(recordId);
        if (index > -1) {
          data.recordIds.splice(index, 1);
          data.count = data.recordIds.length;
          if (data.recordIds.length === 0) {
            this.indexes.delete(key);
            this.deletedIndexes.add(key);
          } else {
            this.indexes.set(key, data);
            this.dirtyIndexes.add(key);
          }
        }
      }
    }
  }
  getFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data && data[fieldPath] !== void 0 ? data[fieldPath] : null;
    }
    const keys = fieldPath.split(".");
    let value = data;
    for (const key of keys) {
      if (value && typeof value === "object" && key in value) {
        value = value[key];
      } else {
        return null;
      }
    }
    return value;
  }
  tokenize(text) {
    if (!text) return [];
    const str = String(text).toLowerCase();
    return str.replace(/[^\w\s\u00C0-\u017F]/g, " ").split(/\s+/).filter((word) => word.length > 0);
  }
  getIndexedFields(resourceName) {
    if (this.config.fields) {
      return this.config.fields;
    }
    const fieldMappings = {
      users: ["name", "email"],
      products: ["name", "description"],
      articles: ["title", "content"]
      // Add more mappings as needed
    };
    return fieldMappings[resourceName] || [];
  }
  // Main search method
  async search(resourceName, query, options = {}) {
    const {
      fields = null,
      // Specific fields to search in
      limit = this.config.maxResults,
      offset = 0,
      exactMatch = false
    } = options;
    if (!query || query.trim().length === 0) {
      return [];
    }
    const searchWords = this.tokenize(query);
    const results = /* @__PURE__ */ new Map();
    const searchFields = fields || this.getIndexedFields(resourceName);
    if (searchFields.length === 0) {
      return [];
    }
    for (const word of searchWords) {
      if (word.length < this.config.minWordLength) continue;
      for (const fieldName of searchFields) {
        if (exactMatch) {
          const key = `${resourceName}:${fieldName}:${word.toLowerCase()}`;
          const indexData = this.indexes.get(key);
          if (indexData) {
            for (const recordId of indexData.recordIds) {
              const currentScore = results.get(recordId) || 0;
              results.set(recordId, currentScore + 1);
            }
          }
        } else {
          for (const [key, indexData] of this.indexes.entries()) {
            if (key.startsWith(`${resourceName}:${fieldName}:${word.toLowerCase()}`)) {
              for (const recordId of indexData.recordIds) {
                const currentScore = results.get(recordId) || 0;
                results.set(recordId, currentScore + 1);
              }
            }
          }
        }
      }
    }
    const sortedResults = Array.from(results.entries()).map(([recordId, score]) => ({ recordId, score })).sort((a, b) => b.score - a.score).slice(offset, offset + limit);
    return sortedResults;
  }
  // Search and return full records
  async searchRecords(resourceName, query, options = {}) {
    const searchResults = await this.search(resourceName, query, options);
    if (searchResults.length === 0) {
      return [];
    }
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new FulltextError(`Resource '${resourceName}' not found`, {
        operation: "searchRecords",
        resourceName,
        query,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before searching"
      });
    }
    const recordIds = searchResults.map((result2) => result2.recordId);
    const records = await resource.getMany(recordIds);
    const result = records.filter((record) => record && typeof record === "object").map((record) => {
      const searchResult = searchResults.find((sr) => sr.recordId === record.id);
      return {
        ...record,
        _searchScore: searchResult ? searchResult.score : 0
      };
    }).sort((a, b) => b._searchScore - a._searchScore);
    return result;
  }
  // Utility methods
  async rebuildIndex(resourceName) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new FulltextError(`Resource '${resourceName}' not found`, {
        operation: "rebuildIndex",
        resourceName,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before rebuilding index"
      });
    }
    for (const [key] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        this.indexes.delete(key);
      }
    }
    const allRecords = await resource.getAll();
    const batchSize = 100;
    for (let i = 0; i < allRecords.length; i += batchSize) {
      const batch = allRecords.slice(i, i + batchSize);
      for (const record of batch) {
        const [ok, err] = await tryFn(() => this.indexRecord(resourceName, record.id, record));
      }
    }
    await this.saveIndexes();
  }
  async getIndexStats() {
    const stats = {
      totalIndexes: this.indexes.size,
      resources: {},
      totalWords: 0
    };
    for (const [key, data] of this.indexes.entries()) {
      const [resourceName, fieldName] = key.split(":");
      if (!stats.resources[resourceName]) {
        stats.resources[resourceName] = {
          fields: {},
          totalRecords: /* @__PURE__ */ new Set(),
          totalWords: 0
        };
      }
      if (!stats.resources[resourceName].fields[fieldName]) {
        stats.resources[resourceName].fields[fieldName] = {
          words: 0,
          totalOccurrences: 0
        };
      }
      stats.resources[resourceName].fields[fieldName].words++;
      stats.resources[resourceName].fields[fieldName].totalOccurrences += data.count;
      stats.resources[resourceName].totalWords++;
      for (const recordId of data.recordIds) {
        stats.resources[resourceName].totalRecords.add(recordId);
      }
      stats.totalWords++;
    }
    for (const resourceName in stats.resources) {
      stats.resources[resourceName].totalRecords = stats.resources[resourceName].totalRecords.size;
    }
    return stats;
  }
  async rebuildAllIndexes({ timeout } = {}) {
    if (timeout) {
      return Promise.race([
        this._rebuildAllIndexesInternal(),
        new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout")), timeout))
      ]);
    }
    return this._rebuildAllIndexesInternal();
  }
  async _rebuildAllIndexesInternal() {
    const resourceNames = Object.keys(this.database.resources).filter((name) => name !== "plg_fulltext_indexes");
    for (const resourceName of resourceNames) {
      const [ok, err] = await tryFn(() => this.rebuildIndex(resourceName));
    }
  }
  async clearIndex(resourceName) {
    for (const [key] of this.indexes.entries()) {
      if (key.startsWith(`${resourceName}:`)) {
        this.indexes.delete(key);
      }
    }
    await this.saveIndexes();
  }
  async clearAllIndexes() {
    this.indexes.clear();
    await this.saveIndexes();
  }
}

class GeoPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.resources = config.resources || {};
    this.verbose = config.verbose !== void 0 ? config.verbose : false;
    this.base32 = "0123456789bcdefghjkmnpqrstuvwxyz";
  }
  /**
   * Install the plugin
   */
  async install(database) {
    await super.install(database);
    for (const [resourceName, config] of Object.entries(this.resources)) {
      await this._setupResource(resourceName, config);
    }
    this.database.addHook("afterCreateResource", async (context) => {
      const { resource, config: resourceConfig } = context;
      const geoConfig = this.resources[resource.name];
      if (geoConfig) {
        await this._setupResource(resource.name, geoConfig);
      }
    });
    if (this.verbose) {
      console.log(`[GeoPlugin] Installed with ${Object.keys(this.resources).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "GeoPlugin",
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Setup a resource with geo capabilities
   */
  async _setupResource(resourceName, config) {
    if (!this.database.resources[resourceName]) {
      if (this.verbose) {
        console.warn(`[GeoPlugin] Resource "${resourceName}" not found, will setup when created`);
      }
      return;
    }
    const resource = this.database.resources[resourceName];
    if (!resource || typeof resource.addHook !== "function") {
      if (this.verbose) {
        console.warn(`[GeoPlugin] Resource "${resourceName}" not found or invalid`);
      }
      return;
    }
    if (!config.latField || !config.lonField) {
      throw new Error(
        `[GeoPlugin] Resource "${resourceName}" must have "latField" and "lonField" configured`
      );
    }
    if (!config.precision || config.precision < 1 || config.precision > 12) {
      config.precision = 5;
    }
    resource._geoConfig = config;
    const latField = resource.attributes[config.latField];
    const lonField = resource.attributes[config.lonField];
    const isLatOptional = typeof latField === "object" && latField.optional === true;
    const isLonOptional = typeof lonField === "object" && lonField.optional === true;
    const areCoordinatesOptional = isLatOptional || isLonOptional;
    const geohashType = areCoordinatesOptional ? "string|optional" : "string";
    let needsUpdate = false;
    const newAttributes = { ...resource.attributes };
    if (config.addGeohash && !newAttributes.geohash) {
      newAttributes.geohash = geohashType;
      needsUpdate = true;
    }
    if (!newAttributes._geohash) {
      newAttributes._geohash = geohashType;
      needsUpdate = true;
    }
    if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
      for (const zoom of config.zoomLevels) {
        const fieldName = `_geohash_zoom${zoom}`;
        if (!newAttributes[fieldName]) {
          newAttributes[fieldName] = geohashType;
          needsUpdate = true;
        }
      }
    }
    if (needsUpdate) {
      resource.updateAttributes(newAttributes);
      if (this.database.uploadMetadataFile) {
        await this.database.uploadMetadataFile();
      }
    }
    if (config.usePartitions) {
      await this._setupPartitions(resource, config);
    }
    this._addHooks(resource, config);
    this._addHelperMethods(resource, config);
    if (this.verbose) {
      console.log(
        `[GeoPlugin] Setup resource "${resourceName}" with precision ${config.precision} (~${this._getPrecisionDistance(config.precision)}km cells)` + (config.usePartitions ? " [Partitions enabled]" : "")
      );
    }
  }
  /**
   * Setup geohash partitions for efficient spatial queries
   * Creates multiple zoom-level partitions if zoomLevels configured
   */
  async _setupPartitions(resource, config) {
    const updatedConfig = { ...resource.config };
    updatedConfig.partitions = updatedConfig.partitions || {};
    let partitionsCreated = 0;
    if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
      for (const zoom of config.zoomLevels) {
        const partitionName = `byGeohashZoom${zoom}`;
        const fieldName = `_geohash_zoom${zoom}`;
        if (!updatedConfig.partitions[partitionName]) {
          updatedConfig.partitions[partitionName] = {
            fields: {
              [fieldName]: "string"
            }
          };
          partitionsCreated++;
          if (this.verbose) {
            console.log(
              `[GeoPlugin] Created ${partitionName} partition for "${resource.name}" (precision ${zoom}, ~${this._getPrecisionDistance(zoom)}km cells)`
            );
          }
        }
      }
    } else {
      const hasGeohashPartition = resource.config.partitions && resource.config.partitions.byGeohash;
      if (!hasGeohashPartition) {
        updatedConfig.partitions.byGeohash = {
          fields: {
            _geohash: "string"
          }
        };
        partitionsCreated++;
        if (this.verbose) {
          console.log(`[GeoPlugin] Created byGeohash partition for "${resource.name}"`);
        }
      }
    }
    if (partitionsCreated > 0) {
      resource.config = updatedConfig;
      resource.setupPartitionHooks();
      if (this.database.uploadMetadataFile) {
        await this.database.uploadMetadataFile();
      }
    }
  }
  /**
   * Add hooks to automatically calculate geohash at all zoom levels
   */
  _addHooks(resource, config) {
    const calculateGeohash = async (data) => {
      const lat = data[config.latField];
      const lon = data[config.lonField];
      if (lat !== void 0 && lon !== void 0) {
        const geohash = this.encodeGeohash(lat, lon, config.precision);
        if (config.addGeohash) {
          data.geohash = geohash;
        }
        data._geohash = geohash;
        if (config.zoomLevels && Array.isArray(config.zoomLevels)) {
          for (const zoom of config.zoomLevels) {
            const zoomGeohash = this.encodeGeohash(lat, lon, zoom);
            data[`_geohash_zoom${zoom}`] = zoomGeohash;
          }
        }
      }
      return data;
    };
    resource.addHook("beforeInsert", calculateGeohash);
    resource.addHook("beforeUpdate", calculateGeohash);
  }
  /**
   * Add helper methods to resource
   */
  _addHelperMethods(resource, config) {
    const plugin = this;
    resource.findNearby = async function({ lat, lon, radius = 10, limit = 100 }) {
      if (lat === void 0 || lon === void 0) {
        throw new Error("lat and lon are required for findNearby");
      }
      const longitude = lon;
      let allRecords = [];
      if (config.usePartitions) {
        let partitionName, fieldName, precision;
        if (config.zoomLevels && config.zoomLevels.length > 0) {
          const optimalZoom = plugin._selectOptimalZoom(config.zoomLevels, radius);
          partitionName = `byGeohashZoom${optimalZoom}`;
          fieldName = `_geohash_zoom${optimalZoom}`;
          precision = optimalZoom;
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] Auto-selected zoom${optimalZoom} (${plugin._getPrecisionDistance(optimalZoom)}km cells) for ${radius}km radius query`
            );
          }
        } else {
          partitionName = "byGeohash";
          fieldName = "_geohash";
          precision = config.precision;
        }
        if (this.config.partitions?.[partitionName]) {
          const centerGeohash = plugin.encodeGeohash(lat, longitude, precision);
          const neighbors = plugin.getNeighbors(centerGeohash);
          const geohashesToSearch = [centerGeohash, ...neighbors];
          const partitionResults = await Promise.all(
            geohashesToSearch.map(async (geohash) => {
              const [ok, err, records] = await tryFn(async () => {
                return await this.listPartition({
                  partition: partitionName,
                  partitionValues: { [fieldName]: geohash },
                  limit: limit * 2
                });
              });
              return ok ? records : [];
            })
          );
          allRecords = partitionResults.flat();
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] findNearby searched ${geohashesToSearch.length} ${partitionName} partitions, found ${allRecords.length} candidates`
            );
          }
        } else {
          allRecords = await this.list({ limit: limit * 10 });
        }
      } else {
        allRecords = await this.list({ limit: limit * 10 });
      }
      const withDistances = allRecords.map((record) => {
        const recordLat = record[config.latField];
        const recordLon = record[config.lonField];
        if (recordLat === void 0 || recordLon === void 0) {
          return null;
        }
        const distance = plugin.calculateDistance(lat, longitude, recordLat, recordLon);
        return {
          ...record,
          _distance: distance
        };
      }).filter((record) => record !== null && record._distance <= radius).sort((a, b) => a._distance - b._distance).slice(0, limit);
      return withDistances;
    };
    resource.findInBounds = async function({ north, south, east, west, limit = 100 }) {
      if (north === void 0 || south === void 0 || east === void 0 || west === void 0) {
        throw new Error("north, south, east, west are required for findInBounds");
      }
      let allRecords = [];
      if (config.usePartitions) {
        let partitionName, precision;
        if (config.zoomLevels && config.zoomLevels.length > 0) {
          const centerLat = (north + south) / 2;
          const centerLon = (east + west) / 2;
          const latRadius = plugin.calculateDistance(centerLat, centerLon, north, centerLon);
          const lonRadius = plugin.calculateDistance(centerLat, centerLon, centerLat, east);
          const approximateRadius = Math.max(latRadius, lonRadius);
          const optimalZoom = plugin._selectOptimalZoom(config.zoomLevels, approximateRadius);
          partitionName = `byGeohashZoom${optimalZoom}`;
          precision = optimalZoom;
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] Auto-selected zoom${optimalZoom} (${plugin._getPrecisionDistance(optimalZoom)}km cells) for ${approximateRadius.toFixed(1)}km bounding box`
            );
          }
        } else {
          partitionName = "byGeohash";
          precision = config.precision;
        }
        if (this.config.partitions?.[partitionName]) {
          const geohashesToSearch = plugin._getGeohashesInBounds({
            north,
            south,
            east,
            west,
            precision
          });
          const partitionResults = await Promise.all(
            geohashesToSearch.map(async (geohash) => {
              const [ok, err, records] = await tryFn(async () => {
                const fieldName = config.zoomLevels ? `_geohash_zoom${precision}` : "_geohash";
                return await this.listPartition({
                  partition: partitionName,
                  partitionValues: { [fieldName]: geohash },
                  limit: limit * 2
                });
              });
              return ok ? records : [];
            })
          );
          allRecords = partitionResults.flat();
          if (plugin.verbose) {
            console.log(
              `[GeoPlugin] findInBounds searched ${geohashesToSearch.length} ${partitionName} partitions, found ${allRecords.length} candidates`
            );
          }
        } else {
          allRecords = await this.list({ limit: limit * 10 });
        }
      } else {
        allRecords = await this.list({ limit: limit * 10 });
      }
      const inBounds = allRecords.filter((record) => {
        const lat = record[config.latField];
        const lon = record[config.lonField];
        if (lat === void 0 || lon === void 0) {
          return false;
        }
        return lat <= north && lat >= south && lon <= east && lon >= west;
      }).slice(0, limit);
      return inBounds;
    };
    resource.getDistance = async function(id1, id2) {
      let record1, record2;
      try {
        [record1, record2] = await Promise.all([
          this.get(id1),
          this.get(id2)
        ]);
      } catch (err) {
        if (err.name === "NoSuchKey" || err.message?.includes("No such key")) {
          throw new Error("One or both records not found");
        }
        throw err;
      }
      if (!record1 || !record2) {
        throw new Error("One or both records not found");
      }
      const lat1 = record1[config.latField];
      const lon1 = record1[config.lonField];
      const lat2 = record2[config.latField];
      const lon2 = record2[config.lonField];
      if (lat1 === void 0 || lon1 === void 0 || lat2 === void 0 || lon2 === void 0) {
        throw new Error("One or both records missing coordinates");
      }
      const distance = plugin.calculateDistance(lat1, lon1, lat2, lon2);
      return {
        distance,
        unit: "km",
        from: id1,
        to: id2
      };
    };
  }
  /**
   * Encode coordinates to geohash
   * @param {number} latitude - Latitude (-90 to 90)
   * @param {number} longitude - Longitude (-180 to 180)
   * @param {number} precision - Number of characters in geohash
   * @returns {string} Geohash string
   */
  encodeGeohash(latitude, longitude, precision = 5) {
    let idx = 0;
    let bit = 0;
    let evenBit = true;
    let geohash = "";
    let latMin = -90;
    let latMax = 90;
    let lonMin = -180;
    let lonMax = 180;
    while (geohash.length < precision) {
      if (evenBit) {
        const lonMid = (lonMin + lonMax) / 2;
        if (longitude > lonMid) {
          idx |= 1 << 4 - bit;
          lonMin = lonMid;
        } else {
          lonMax = lonMid;
        }
      } else {
        const latMid = (latMin + latMax) / 2;
        if (latitude > latMid) {
          idx |= 1 << 4 - bit;
          latMin = latMid;
        } else {
          latMax = latMid;
        }
      }
      evenBit = !evenBit;
      if (bit < 4) {
        bit++;
      } else {
        geohash += this.base32[idx];
        bit = 0;
        idx = 0;
      }
    }
    return geohash;
  }
  /**
   * Decode geohash to coordinates
   * @param {string} geohash - Geohash string
   * @returns {Object} { latitude, longitude, error }
   */
  decodeGeohash(geohash) {
    let evenBit = true;
    let latMin = -90;
    let latMax = 90;
    let lonMin = -180;
    let lonMax = 180;
    for (let i = 0; i < geohash.length; i++) {
      const chr = geohash[i];
      const idx = this.base32.indexOf(chr);
      if (idx === -1) {
        throw new Error(`Invalid geohash character: ${chr}`);
      }
      for (let n = 4; n >= 0; n--) {
        const bitN = idx >> n & 1;
        if (evenBit) {
          const lonMid = (lonMin + lonMax) / 2;
          if (bitN === 1) {
            lonMin = lonMid;
          } else {
            lonMax = lonMid;
          }
        } else {
          const latMid = (latMin + latMax) / 2;
          if (bitN === 1) {
            latMin = latMid;
          } else {
            latMax = latMid;
          }
        }
        evenBit = !evenBit;
      }
    }
    const latitude = (latMin + latMax) / 2;
    const longitude = (lonMin + lonMax) / 2;
    return {
      latitude,
      longitude,
      error: {
        latitude: latMax - latMin,
        longitude: lonMax - lonMin
      }
    };
  }
  /**
   * Calculate distance between two coordinates using Haversine formula
   * @param {number} lat1 - Latitude of point 1
   * @param {number} lon1 - Longitude of point 1
   * @param {number} lat2 - Latitude of point 2
   * @param {number} lon2 - Longitude of point 2
   * @returns {number} Distance in kilometers
   */
  calculateDistance(lat1, lon1, lat2, lon2) {
    const R = 6371;
    const dLat = this._toRadians(lat2 - lat1);
    const dLon = this._toRadians(lon2 - lon1);
    const a = Math.sin(dLat / 2) * Math.sin(dLat / 2) + Math.cos(this._toRadians(lat1)) * Math.cos(this._toRadians(lat2)) * Math.sin(dLon / 2) * Math.sin(dLon / 2);
    const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
    return R * c;
  }
  /**
   * Get geohash neighbors (8 surrounding cells)
   * @param {string} geohash - Center geohash
   * @returns {Array<string>} Array of 8 neighboring geohashes
   */
  getNeighbors(geohash) {
    const decoded = this.decodeGeohash(geohash);
    const { latitude, longitude, error } = decoded;
    const latStep = error.latitude;
    const lonStep = error.longitude;
    const neighbors = [];
    const directions = [
      [-latStep, -lonStep],
      // SW
      [-latStep, 0],
      // S
      [-latStep, lonStep],
      // SE
      [0, -lonStep],
      // W
      [0, lonStep],
      // E
      [latStep, -lonStep],
      // NW
      [latStep, 0],
      // N
      [latStep, lonStep]
      // NE
    ];
    for (const [latDelta, lonDelta] of directions) {
      const neighborHash = this.encodeGeohash(
        latitude + latDelta,
        longitude + lonDelta,
        geohash.length
      );
      neighbors.push(neighborHash);
    }
    return neighbors;
  }
  /**
   * Get all geohashes that cover a bounding box
   * @param {Object} bounds - Bounding box { north, south, east, west, precision }
   * @returns {Array<string>} Array of unique geohashes covering the area
   */
  _getGeohashesInBounds({ north, south, east, west, precision }) {
    const geohashes = /* @__PURE__ */ new Set();
    const cellSize = this._getPrecisionDistance(precision);
    const latStep = cellSize / 111;
    const lonStep = cellSize / (111 * Math.cos(this._toRadians((north + south) / 2)));
    for (let lat = south; lat <= north; lat += latStep) {
      for (let lon = west; lon <= east; lon += lonStep) {
        const geohash = this.encodeGeohash(lat, lon, precision);
        geohashes.add(geohash);
      }
    }
    const corners = [
      [north, west],
      [north, east],
      [south, west],
      [south, east],
      [(north + south) / 2, west],
      [(north + south) / 2, east],
      [north, (east + west) / 2],
      [south, (east + west) / 2]
    ];
    for (const [lat, lon] of corners) {
      const geohash = this.encodeGeohash(lat, lon, precision);
      geohashes.add(geohash);
    }
    return Array.from(geohashes);
  }
  /**
   * Convert degrees to radians
   */
  _toRadians(degrees) {
    return degrees * (Math.PI / 180);
  }
  /**
   * Get approximate cell size for precision level
   */
  _getPrecisionDistance(precision) {
    const distances = {
      1: 5e3,
      2: 1250,
      3: 156,
      4: 39,
      5: 4.9,
      6: 1.2,
      7: 0.15,
      8: 0.038,
      9: 47e-4,
      10: 12e-4,
      11: 15e-5,
      12: 37e-6
    };
    return distances[precision] || 5;
  }
  /**
   * Select optimal zoom level based on search radius
   * @param {Array<number>} zoomLevels - Available zoom levels
   * @param {number} radiusKm - Search radius in kilometers
   * @returns {number} Optimal zoom precision
   */
  _selectOptimalZoom(zoomLevels, radiusKm) {
    if (!zoomLevels || zoomLevels.length === 0) {
      return null;
    }
    const targetCellSize = radiusKm / 2.5;
    let bestZoom = zoomLevels[0];
    let bestDiff = Math.abs(this._getPrecisionDistance(bestZoom) - targetCellSize);
    for (const zoom of zoomLevels) {
      const cellSize = this._getPrecisionDistance(zoom);
      const diff = Math.abs(cellSize - targetCellSize);
      if (diff < bestDiff) {
        bestDiff = diff;
        bestZoom = zoom;
      }
    }
    return bestZoom;
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      resources: Object.keys(this.resources).length,
      configurations: Object.entries(this.resources).map(([name, config]) => ({
        resource: name,
        latField: config.latField,
        lonField: config.lonField,
        precision: config.precision,
        cellSize: `~${this._getPrecisionDistance(config.precision)}km`
      }))
    };
  }
  /**
   * Uninstall the plugin
   */
  async uninstall() {
    if (this.verbose) {
      console.log("[GeoPlugin] Uninstalled");
    }
    this.emit("db:plugin:uninstalled", {
      plugin: "GeoPlugin"
    });
    await super.uninstall();
  }
}

class MetricsPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      collectPerformance: options.collectPerformance !== false,
      collectErrors: options.collectErrors !== false,
      collectUsage: options.collectUsage !== false,
      retentionDays: options.retentionDays || 30,
      flushInterval: options.flushInterval || 6e4,
      // 1 minute
      // Prometheus configuration
      prometheus: {
        enabled: options.prometheus?.enabled !== false,
        // Enabled by default
        mode: options.prometheus?.mode || "auto",
        // 'auto' | 'integrated' | 'standalone'
        port: options.prometheus?.port || 9090,
        // Standalone server port
        path: options.prometheus?.path || "/metrics",
        // Metrics endpoint path
        includeResourceLabels: options.prometheus?.includeResourceLabels !== false
      },
      ...options
    };
    this.metrics = {
      operations: {
        insert: { count: 0, totalTime: 0, errors: 0 },
        update: { count: 0, totalTime: 0, errors: 0 },
        delete: { count: 0, totalTime: 0, errors: 0 },
        get: { count: 0, totalTime: 0, errors: 0 },
        list: { count: 0, totalTime: 0, errors: 0 },
        count: { count: 0, totalTime: 0, errors: 0 }
      },
      resources: {},
      errors: [],
      performance: [],
      startTime: (/* @__PURE__ */ new Date()).toISOString()
    };
    this.flushTimer = null;
    this.metricsServer = null;
  }
  async onInstall() {
    if (typeof process !== "undefined" && process.env.NODE_ENV === "test") return;
    const [ok, err] = await tryFn(async () => {
      const [ok1, err1, metricsResource] = await tryFn(() => this.database.createResource({
        name: "plg_metrics",
        attributes: {
          id: "string|required",
          type: "string|required",
          // 'operation', 'error', 'performance'
          resourceName: "string",
          operation: "string",
          count: "number|required",
          totalTime: "number|required",
          errors: "number|required",
          avgTime: "number|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.metricsResource = ok1 ? metricsResource : this.database.resources.plg_metrics;
      const [ok2, err2, errorsResource] = await tryFn(() => this.database.createResource({
        name: "plg_error_logs",
        attributes: {
          id: "string|required",
          resourceName: "string|required",
          operation: "string|required",
          error: "string|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.errorsResource = ok2 ? errorsResource : this.database.resources.plg_error_logs;
      const [ok3, err3, performanceResource] = await tryFn(() => this.database.createResource({
        name: "plg_performance_logs",
        attributes: {
          id: "string|required",
          resourceName: "string|required",
          operation: "string|required",
          duration: "number|required",
          timestamp: "string|required",
          metadata: "json",
          createdAt: "string|required"
          // YYYY-MM-DD for partitioning
        },
        partitions: {
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        },
        behavior: "body-overflow"
      }));
      this.performanceResource = ok3 ? performanceResource : this.database.resources.plg_performance_logs;
    });
    if (!ok) {
      this.metricsResource = this.database.resources.plg_metrics;
      this.errorsResource = this.database.resources.plg_error_logs;
      this.performanceResource = this.database.resources.plg_performance_logs;
    }
    this.installDatabaseHooks();
    this.installMetricsHooks();
    if (typeof process !== "undefined" && process.env.NODE_ENV !== "test") {
      this.startFlushTimer();
    }
  }
  async start() {
    await this._setupPrometheusExporter();
  }
  async stop() {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
      this.flushTimer = null;
    }
    if (this.metricsServer) {
      await new Promise((resolve) => {
        this.metricsServer.close(() => {
          console.log("[Metrics Plugin] Standalone metrics server stopped");
          this.metricsServer = null;
          resolve();
        });
      });
    }
    this.removeDatabaseHooks();
  }
  installDatabaseHooks() {
    this.database.addHook("afterCreateResource", (resource) => {
      if (resource.name !== "plg_metrics" && resource.name !== "plg_error_logs" && resource.name !== "plg_performance_logs") {
        this.installResourceHooks(resource);
      }
    });
  }
  removeDatabaseHooks() {
    this.database.removeHook("afterCreateResource", this.installResourceHooks.bind(this));
  }
  installMetricsHooks() {
    for (const resource of Object.values(this.database.resources)) {
      if (["plg_metrics", "plg_error_logs", "plg_performance_logs"].includes(resource.name)) {
        continue;
      }
      this.installResourceHooks(resource);
    }
    this.database._createResource = this.database.createResource;
    this.database.createResource = async function(...args) {
      const resource = await this._createResource(...args);
      if (this.plugins?.metrics && !["plg_metrics", "plg_error_logs", "plg_performance_logs"].includes(resource.name)) {
        this.plugins.metrics.installResourceHooks(resource);
      }
      return resource;
    };
  }
  installResourceHooks(resource) {
    resource._insert = resource.insert;
    resource._update = resource.update;
    resource._delete = resource.delete;
    resource._deleteMany = resource.deleteMany;
    resource._get = resource.get;
    resource._getMany = resource.getMany;
    resource._getAll = resource.getAll;
    resource._list = resource.list;
    resource._listIds = resource.listIds;
    resource._count = resource.count;
    resource._page = resource.page;
    resource.insert = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._insert(...args));
      this.recordOperation(resource.name, "insert", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "insert", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.update = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._update(...args));
      this.recordOperation(resource.name, "update", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "update", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.delete = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._delete(...args));
      this.recordOperation(resource.name, "delete", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "delete", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.deleteMany = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._deleteMany(...args));
      this.recordOperation(resource.name, "delete", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "delete", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.get = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._get(...args));
      this.recordOperation(resource.name, "get", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "get", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.getMany = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._getMany(...args));
      this.recordOperation(resource.name, "get", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "get", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.getAll = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._getAll(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.list = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._list(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.listIds = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._listIds(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.count = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._count(...args));
      this.recordOperation(resource.name, "count", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "count", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
    resource.page = async function(...args) {
      const startTime = Date.now();
      const [ok, err, result] = await tryFn(() => resource._page(...args));
      this.recordOperation(resource.name, "list", Date.now() - startTime, !ok);
      if (!ok) this.recordError(resource.name, "list", err);
      if (!ok) throw err;
      return result;
    }.bind(this);
  }
  recordOperation(resourceName, operation, duration, isError) {
    if (this.metrics.operations[operation]) {
      this.metrics.operations[operation].count++;
      this.metrics.operations[operation].totalTime += duration;
      if (isError) {
        this.metrics.operations[operation].errors++;
      }
    }
    if (!this.metrics.resources[resourceName]) {
      this.metrics.resources[resourceName] = {
        insert: { count: 0, totalTime: 0, errors: 0 },
        update: { count: 0, totalTime: 0, errors: 0 },
        delete: { count: 0, totalTime: 0, errors: 0 },
        get: { count: 0, totalTime: 0, errors: 0 },
        list: { count: 0, totalTime: 0, errors: 0 },
        count: { count: 0, totalTime: 0, errors: 0 }
      };
    }
    if (this.metrics.resources[resourceName][operation]) {
      this.metrics.resources[resourceName][operation].count++;
      this.metrics.resources[resourceName][operation].totalTime += duration;
      if (isError) {
        this.metrics.resources[resourceName][operation].errors++;
      }
    }
    if (this.config.collectPerformance) {
      this.metrics.performance.push({
        resourceName,
        operation,
        duration,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
  }
  recordError(resourceName, operation, error) {
    if (!this.config.collectErrors) return;
    this.metrics.errors.push({
      resourceName,
      operation,
      error: error.message,
      stack: error.stack,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  }
  startFlushTimer() {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
    }
    if (this.config.flushInterval > 0) {
      this.flushTimer = setInterval(() => {
        this.flushMetrics().catch(() => {
        });
      }, this.config.flushInterval);
    }
  }
  async flushMetrics() {
    if (!this.metricsResource) return;
    const [ok, err] = await tryFn(async () => {
      let metadata, perfMetadata, errorMetadata, resourceMetadata;
      if (typeof process !== "undefined" && process.env.NODE_ENV === "test") {
        metadata = {};
        perfMetadata = {};
        errorMetadata = {};
        resourceMetadata = {};
      } else {
        metadata = { global: "true" };
        perfMetadata = { perf: "true" };
        errorMetadata = { error: "true" };
        resourceMetadata = { resource: "true" };
      }
      const now = /* @__PURE__ */ new Date();
      const createdAt = now.toISOString().slice(0, 10);
      for (const [operation, data] of Object.entries(this.metrics.operations)) {
        if (data.count > 0) {
          await this.metricsResource.insert({
            id: `metrics-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            type: "operation",
            resourceName: "global",
            operation,
            count: data.count,
            totalTime: data.totalTime,
            errors: data.errors,
            avgTime: data.count > 0 ? data.totalTime / data.count : 0,
            timestamp: now.toISOString(),
            createdAt,
            metadata
          });
        }
      }
      for (const [resourceName, operations] of Object.entries(this.metrics.resources)) {
        for (const [operation, data] of Object.entries(operations)) {
          if (data.count > 0) {
            await this.metricsResource.insert({
              id: `metrics-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
              type: "operation",
              resourceName,
              operation,
              count: data.count,
              totalTime: data.totalTime,
              errors: data.errors,
              avgTime: data.count > 0 ? data.totalTime / data.count : 0,
              timestamp: now.toISOString(),
              createdAt,
              metadata: resourceMetadata
            });
          }
        }
      }
      if (this.config.collectPerformance && this.metrics.performance.length > 0) {
        for (const perf of this.metrics.performance) {
          await this.performanceResource.insert({
            id: `perf-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName: perf.resourceName,
            operation: perf.operation,
            duration: perf.duration,
            timestamp: perf.timestamp,
            createdAt: perf.timestamp.slice(0, 10),
            // YYYY-MM-DD from timestamp
            metadata: perfMetadata
          });
        }
      }
      if (this.config.collectErrors && this.metrics.errors.length > 0) {
        for (const error of this.metrics.errors) {
          await this.errorsResource.insert({
            id: `error-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
            resourceName: error.resourceName,
            operation: error.operation,
            error: error.error,
            stack: error.stack,
            timestamp: error.timestamp,
            createdAt: error.timestamp.slice(0, 10),
            // YYYY-MM-DD from timestamp
            metadata: errorMetadata
          });
        }
      }
      this.resetMetrics();
    });
  }
  resetMetrics() {
    for (const operation of Object.keys(this.metrics.operations)) {
      this.metrics.operations[operation] = { count: 0, totalTime: 0, errors: 0 };
    }
    for (const resourceName of Object.keys(this.metrics.resources)) {
      for (const operation of Object.keys(this.metrics.resources[resourceName])) {
        this.metrics.resources[resourceName][operation] = { count: 0, totalTime: 0, errors: 0 };
      }
    }
    this.metrics.performance = [];
    this.metrics.errors = [];
  }
  // Utility methods
  async getMetrics(options = {}) {
    const {
      type = "operation",
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    if (!this.metricsResource) return [];
    const allMetrics = await this.metricsResource.getAll();
    let filtered = allMetrics.filter((metric) => {
      if (type && metric.type !== type) return false;
      if (resourceName && metric.resourceName !== resourceName) return false;
      if (operation && metric.operation !== operation) return false;
      if (startDate && new Date(metric.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(metric.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getErrorLogs(options = {}) {
    if (!this.errorsResource) return [];
    const {
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    const allErrors = await this.errorsResource.getAll();
    let filtered = allErrors.filter((error) => {
      if (resourceName && error.resourceName !== resourceName) return false;
      if (operation && error.operation !== operation) return false;
      if (startDate && new Date(error.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(error.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getPerformanceLogs(options = {}) {
    if (!this.performanceResource) return [];
    const {
      resourceName,
      operation,
      startDate,
      endDate,
      limit = 100,
      offset = 0
    } = options;
    const allPerformance = await this.performanceResource.getAll();
    let filtered = allPerformance.filter((perf) => {
      if (resourceName && perf.resourceName !== resourceName) return false;
      if (operation && perf.operation !== operation) return false;
      if (startDate && new Date(perf.timestamp) < new Date(startDate)) return false;
      if (endDate && new Date(perf.timestamp) > new Date(endDate)) return false;
      return true;
    });
    filtered.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
    return filtered.slice(offset, offset + limit);
  }
  async getStats() {
    const now = /* @__PURE__ */ new Date();
    const startDate = new Date(now.getTime() - 24 * 60 * 60 * 1e3);
    const [metrics, errors, performance] = await Promise.all([
      this.getMetrics({ startDate: startDate.toISOString() }),
      this.getErrorLogs({ startDate: startDate.toISOString() }),
      this.getPerformanceLogs({ startDate: startDate.toISOString() })
    ]);
    const stats = {
      period: "24h",
      totalOperations: 0,
      totalErrors: errors.length,
      avgResponseTime: 0,
      operationsByType: {},
      resources: {},
      uptime: {
        startTime: this.metrics.startTime,
        duration: now.getTime() - new Date(this.metrics.startTime).getTime()
      }
    };
    for (const metric of metrics) {
      if (metric.type === "operation") {
        stats.totalOperations += metric.count;
        if (!stats.operationsByType[metric.operation]) {
          stats.operationsByType[metric.operation] = {
            count: 0,
            errors: 0,
            avgTime: 0
          };
        }
        stats.operationsByType[metric.operation].count += metric.count;
        stats.operationsByType[metric.operation].errors += metric.errors;
        const current = stats.operationsByType[metric.operation];
        const totalCount2 = current.count;
        const newAvg = (current.avgTime * (totalCount2 - metric.count) + metric.totalTime) / totalCount2;
        current.avgTime = newAvg;
      }
    }
    const totalTime = metrics.reduce((sum, m) => sum + m.totalTime, 0);
    const totalCount = metrics.reduce((sum, m) => sum + m.count, 0);
    stats.avgResponseTime = totalCount > 0 ? totalTime / totalCount : 0;
    return stats;
  }
  async cleanupOldData() {
    const cutoffDate = /* @__PURE__ */ new Date();
    cutoffDate.setDate(cutoffDate.getDate() - this.config.retentionDays);
    cutoffDate.toISOString().slice(0, 10);
    const datesToDelete = [];
    const startDate = new Date(cutoffDate);
    startDate.setDate(startDate.getDate() - 365);
    for (let d = new Date(startDate); d < cutoffDate; d.setDate(d.getDate() + 1)) {
      datesToDelete.push(d.toISOString().slice(0, 10));
    }
    if (this.metricsResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldMetrics] = await tryFn(
          () => this.metricsResource.query({ createdAt: dateStr })
        );
        if (ok && oldMetrics) {
          for (const metric of oldMetrics) {
            await tryFn(() => this.metricsResource.delete(metric.id));
          }
        }
      }
    }
    if (this.errorsResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldErrors] = await tryFn(
          () => this.errorsResource.query({ createdAt: dateStr })
        );
        if (ok && oldErrors) {
          for (const error of oldErrors) {
            await tryFn(() => this.errorsResource.delete(error.id));
          }
        }
      }
    }
    if (this.performanceResource) {
      for (const dateStr of datesToDelete) {
        const [ok, err, oldPerformance] = await tryFn(
          () => this.performanceResource.query({ createdAt: dateStr })
        );
        if (ok && oldPerformance) {
          for (const perf of oldPerformance) {
            await tryFn(() => this.performanceResource.delete(perf.id));
          }
        }
      }
    }
  }
  /**
   * Get metrics in Prometheus format
   * @returns {Promise<string>} Prometheus metrics text
   */
  async getPrometheusMetrics() {
    const { formatPrometheusMetrics } = await Promise.resolve().then(function () { return prometheusFormatter; });
    return formatPrometheusMetrics(this);
  }
  /**
   * Setup Prometheus metrics exporter
   * Chooses mode based on configuration and API Plugin availability
   * @private
   */
  async _setupPrometheusExporter() {
    if (!this.config.prometheus.enabled) {
      return;
    }
    const mode = this.config.prometheus.mode;
    const apiPlugin = this.database.plugins?.api || this.database.plugins?.ApiPlugin;
    if (mode === "auto") {
      if (apiPlugin && apiPlugin.server) {
        await this._setupIntegratedMetrics(apiPlugin);
      } else {
        await this._setupStandaloneMetrics();
      }
    } else if (mode === "integrated") {
      if (!apiPlugin || !apiPlugin.server) {
        throw new Error(
          "[Metrics Plugin] prometheus.mode=integrated requires API Plugin to be active"
        );
      }
      await this._setupIntegratedMetrics(apiPlugin);
    } else if (mode === "standalone") {
      await this._setupStandaloneMetrics();
    } else {
      console.warn(
        `[Metrics Plugin] Unknown prometheus.mode="${mode}". Valid modes: auto, integrated, standalone`
      );
    }
  }
  /**
   * Setup integrated metrics (uses API Plugin's server)
   * @param {ApiPlugin} apiPlugin - API Plugin instance
   * @private
   */
  async _setupIntegratedMetrics(apiPlugin) {
    const app = apiPlugin.getApp();
    const path = this.config.prometheus.path;
    if (!app) {
      console.error("[Metrics Plugin] Failed to get Hono app from API Plugin");
      return;
    }
    app.get(path, async (c) => {
      try {
        const metrics = await this.getPrometheusMetrics();
        return c.text(metrics, 200, {
          "Content-Type": "text/plain; version=0.0.4; charset=utf-8"
        });
      } catch (err) {
        console.error("[Metrics Plugin] Error generating Prometheus metrics:", err);
        return c.text("Internal Server Error", 500);
      }
    });
    const port = apiPlugin.config?.port || 3e3;
    console.log(
      `[Metrics Plugin] Prometheus metrics available at http://localhost:${port}${path} (integrated mode)`
    );
  }
  /**
   * Setup standalone metrics server (separate HTTP server)
   * @private
   */
  async _setupStandaloneMetrics() {
    const { createServer } = await import('http');
    const port = this.config.prometheus.port;
    const path = this.config.prometheus.path;
    this.metricsServer = createServer(async (req, res) => {
      res.setHeader("Access-Control-Allow-Origin", "*");
      res.setHeader("Access-Control-Allow-Methods", "GET");
      res.setHeader("Access-Control-Allow-Headers", "Content-Type");
      if (req.url === path && req.method === "GET") {
        try {
          const metrics = await this.getPrometheusMetrics();
          res.writeHead(200, {
            "Content-Type": "text/plain; version=0.0.4; charset=utf-8",
            "Content-Length": Buffer.byteLength(metrics, "utf8")
          });
          res.end(metrics);
        } catch (err) {
          console.error("[Metrics Plugin] Error generating Prometheus metrics:", err);
          res.writeHead(500, { "Content-Type": "text/plain" });
          res.end("Internal Server Error");
        }
      } else if (req.method === "OPTIONS") {
        res.writeHead(204);
        res.end();
      } else {
        res.writeHead(404, { "Content-Type": "text/plain" });
        res.end("Not Found");
      }
    });
    this.metricsServer.listen(port, "0.0.0.0", () => {
      console.log(
        `[Metrics Plugin] Prometheus metrics available at http://0.0.0.0:${port}${path} (standalone mode)`
      );
    });
    this.metricsServer.on("error", (err) => {
      console.error("[Metrics Plugin] Standalone metrics server error:", err);
    });
  }
}

class AsyncEventEmitter extends EventEmitter {
  constructor() {
    super();
    this._asyncMode = true;
  }
  emit(event, ...args) {
    if (!this._asyncMode) {
      return super.emit(event, ...args);
    }
    const listeners = this.listeners(event);
    if (listeners.length === 0) {
      return false;
    }
    setImmediate(async () => {
      for (const listener of listeners) {
        try {
          await listener(...args);
        } catch (error) {
          if (event !== "error") {
            this.emit("error", error);
          } else {
            console.error("Error in error handler:", error);
          }
        }
      }
    });
    return true;
  }
  emitSync(event, ...args) {
    return super.emit(event, ...args);
  }
  setAsyncMode(enabled) {
    this._asyncMode = enabled;
  }
}

async function secretHandler(actual, errors, schema) {
  if (!this.passphrase) {
    errors.push(new ValidationError("Missing configuration for secrets encryption.", {
      actual,
      type: "encryptionKeyMissing",
      suggestion: "Provide a passphrase for secret encryption."
    }));
    return actual;
  }
  const [ok, err, res] = await tryFn(() => encrypt(String(actual), this.passphrase));
  if (ok) return res;
  errors.push(new ValidationError("Problem encrypting secret.", {
    actual,
    type: "encryptionProblem",
    error: err,
    suggestion: "Check the passphrase and input value."
  }));
  return actual;
}
async function jsonHandler(actual, errors, schema) {
  if (isString(actual)) return actual;
  const [ok, err, json] = tryFnSync(() => JSON.stringify(actual));
  if (!ok) throw new ValidationError("Failed to stringify JSON", { original: err, input: actual });
  return json;
}
class Validator extends FastestValidator {
  constructor({ options, passphrase, autoEncrypt = true } = {}) {
    super(merge({}, {
      useNewCustomCheckerFunction: true,
      messages: {
        encryptionKeyMissing: "Missing configuration for secrets encryption.",
        encryptionProblem: "Problem encrypting secret. Actual: {actual}. Error: {error}"
      },
      defaults: {
        string: {
          trim: true
        },
        object: {
          strict: "remove"
        },
        number: {
          convert: true
        }
      }
    }, options));
    this.passphrase = passphrase;
    this.autoEncrypt = autoEncrypt;
    this.alias("secret", {
      type: "string",
      custom: this.autoEncrypt ? secretHandler : void 0,
      messages: {
        string: "The '{field}' field must be a string.",
        stringMin: "This secret '{field}' field length must be at least {expected} long."
      }
    });
    this.alias("secretAny", {
      type: "any",
      custom: this.autoEncrypt ? secretHandler : void 0
    });
    this.alias("secretNumber", {
      type: "number",
      custom: this.autoEncrypt ? secretHandler : void 0
    });
    this.alias("json", {
      type: "any",
      custom: this.autoEncrypt ? jsonHandler : void 0
    });
    this.alias("embedding", {
      type: "array",
      items: "number",
      empty: false
    });
  }
}
const ValidatorManager = new Proxy(Validator, {
  instance: null,
  construct(target, args) {
    if (!this.instance) this.instance = new target(...args);
    return this.instance;
  }
});

function isValidIPv4(ip) {
  if (typeof ip !== "string") return false;
  const ipv4Regex = /^(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})$/;
  const match = ip.match(ipv4Regex);
  if (!match) return false;
  for (let i = 1; i <= 4; i++) {
    const octet = parseInt(match[i], 10);
    if (octet < 0 || octet > 255) return false;
  }
  return true;
}
function isValidIPv6(ip) {
  if (typeof ip !== "string") return false;
  const ipv6Regex = /^(([0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]+|::(ffff(:0{1,4})?:)?((25[0-5]|(2[0-4]|1?[0-9])?[0-9])\.){3}(25[0-5]|(2[0-4]|1?[0-9])?[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1?[0-9])?[0-9])\.){3}(25[0-5]|(2[0-4]|1?[0-9])?[0-9]))$/;
  return ipv6Regex.test(ip);
}
function encodeIPv4(ip) {
  if (!isValidIPv4(ip)) {
    throw new Error(`Invalid IPv4 address: ${ip}`);
  }
  const octets = ip.split(".").map((octet) => parseInt(octet, 10));
  const buffer = Buffer.from(octets);
  return buffer.toString("base64");
}
function decodeIPv4(encoded) {
  if (typeof encoded !== "string") {
    throw new Error("Encoded IPv4 must be a string");
  }
  const [ok, err, result] = tryFn(() => {
    const buffer = Buffer.from(encoded, "base64");
    if (buffer.length !== 4) {
      throw new Error(`Invalid encoded IPv4 length: ${buffer.length} (expected 4)`);
    }
    return Array.from(buffer).join(".");
  });
  if (!ok) {
    throw new Error(`Failed to decode IPv4: ${err.message}`);
  }
  return result;
}
function expandIPv6(ip) {
  if (!isValidIPv6(ip)) {
    throw new Error(`Invalid IPv6 address: ${ip}`);
  }
  let expanded = ip;
  if (expanded === "::") {
    return "0000:0000:0000:0000:0000:0000:0000:0000";
  }
  if (expanded.includes("::")) {
    const parts = expanded.split("::");
    const leftParts = parts[0] ? parts[0].split(":") : [];
    const rightParts = parts[1] ? parts[1].split(":") : [];
    const missingGroups = 8 - leftParts.length - rightParts.length;
    const middleParts = Array(missingGroups).fill("0");
    expanded = [...leftParts, ...middleParts, ...rightParts].join(":");
  }
  const groups = expanded.split(":");
  const paddedGroups = groups.map((group) => group.padStart(4, "0"));
  return paddedGroups.join(":");
}
function compressIPv6(ip) {
  let compressed = ip.split(":").map((group) => {
    return parseInt(group, 16).toString(16);
  }).join(":");
  const zeroSequences = [];
  let currentSequence = { start: -1, length: 0 };
  compressed.split(":").forEach((group, index) => {
    if (group === "0") {
      if (currentSequence.start === -1) {
        currentSequence.start = index;
        currentSequence.length = 1;
      } else {
        currentSequence.length++;
      }
    } else {
      if (currentSequence.length > 0) {
        zeroSequences.push({ ...currentSequence });
        currentSequence = { start: -1, length: 0 };
      }
    }
  });
  if (currentSequence.length > 0) {
    zeroSequences.push(currentSequence);
  }
  const longestSequence = zeroSequences.filter((seq) => seq.length >= 2).sort((a, b) => b.length - a.length)[0];
  if (longestSequence) {
    const parts = compressed.split(":");
    const before = parts.slice(0, longestSequence.start).join(":");
    const after = parts.slice(longestSequence.start + longestSequence.length).join(":");
    if (before && after) {
      compressed = `${before}::${after}`;
    } else if (before) {
      compressed = `${before}::`;
    } else if (after) {
      compressed = `::${after}`;
    } else {
      compressed = "::";
    }
  }
  return compressed;
}
function encodeIPv6(ip) {
  if (!isValidIPv6(ip)) {
    throw new Error(`Invalid IPv6 address: ${ip}`);
  }
  const expanded = expandIPv6(ip);
  const groups = expanded.split(":");
  const bytes = [];
  for (const group of groups) {
    const value = parseInt(group, 16);
    bytes.push(value >> 8 & 255);
    bytes.push(value & 255);
  }
  const buffer = Buffer.from(bytes);
  return buffer.toString("base64");
}
function decodeIPv6(encoded, compress = true) {
  if (typeof encoded !== "string") {
    throw new Error("Encoded IPv6 must be a string");
  }
  if (encoded.length !== 24 && isValidIPv6(encoded)) {
    return compress ? encoded : expandIPv6(encoded);
  }
  const [ok, err, result] = tryFn(() => {
    const buffer = Buffer.from(encoded, "base64");
    if (buffer.length !== 16) {
      throw new Error(`Invalid encoded IPv6 length: ${buffer.length} (expected 16)`);
    }
    const groups = [];
    for (let i = 0; i < 16; i += 2) {
      const value = buffer[i] << 8 | buffer[i + 1];
      groups.push(value.toString(16).padStart(4, "0"));
    }
    const fullAddress = groups.join(":");
    return compress ? compressIPv6(fullAddress) : fullAddress;
  });
  if (!ok) {
    throw new Error(`Failed to decode IPv6: ${err.message}`);
  }
  return result;
}

function encodeGeoLat(lat, precision = 6) {
  if (lat === null || lat === void 0) return lat;
  if (typeof lat !== "number" || isNaN(lat)) return lat;
  if (!isFinite(lat)) return lat;
  if (lat < -90 || lat > 90) {
    throw new Error(`Latitude out of range [-90, 90]: ${lat}`);
  }
  const normalized = lat + 90;
  const scale = Math.pow(10, precision);
  const scaled = Math.round(normalized * scale);
  return "~" + encode$1(scaled);
}
function decodeGeoLat(encoded, precision = 6) {
  if (typeof encoded !== "string") return encoded;
  if (!encoded.startsWith("~")) return encoded;
  const scaled = decode$1(encoded.slice(1));
  if (isNaN(scaled)) return NaN;
  const scale = Math.pow(10, precision);
  const normalized = scaled / scale;
  return normalized - 90;
}
function encodeGeoLon(lon, precision = 6) {
  if (lon === null || lon === void 0) return lon;
  if (typeof lon !== "number" || isNaN(lon)) return lon;
  if (!isFinite(lon)) return lon;
  if (lon < -180 || lon > 180) {
    throw new Error(`Longitude out of range [-180, 180]: ${lon}`);
  }
  const normalized = lon + 180;
  const scale = Math.pow(10, precision);
  const scaled = Math.round(normalized * scale);
  return "~" + encode$1(scaled);
}
function decodeGeoLon(encoded, precision = 6) {
  if (typeof encoded !== "string") return encoded;
  if (!encoded.startsWith("~")) return encoded;
  const scaled = decode$1(encoded.slice(1));
  if (isNaN(scaled)) return NaN;
  const scale = Math.pow(10, precision);
  const normalized = scaled / scale;
  return normalized - 180;
}
function encodeGeoPoint(lat, lon, precision = 6) {
  const latEncoded = encodeGeoLat(lat, precision);
  const lonEncoded = encodeGeoLon(lon, precision);
  return latEncoded + lonEncoded;
}
function decodeGeoPoint(encoded, precision = 6) {
  if (typeof encoded !== "string") return { latitude: NaN, longitude: NaN };
  const parts = encoded.split("~").filter((p) => p.length > 0);
  if (parts.length !== 2) {
    return { latitude: NaN, longitude: NaN };
  }
  const latitude = decodeGeoLat("~" + parts[0], precision);
  const longitude = decodeGeoLon("~" + parts[1], precision);
  return { latitude, longitude };
}

function generateBase62Mapping(keys) {
  const mapping = {};
  const reversedMapping = {};
  keys.forEach((key, index) => {
    const base62Key = encode$1(index);
    mapping[key] = base62Key;
    reversedMapping[base62Key] = key;
  });
  return { mapping, reversedMapping };
}
function generatePluginAttributeHash(pluginName, attributeName) {
  const input = `${pluginName}:${attributeName}`;
  const hash = createHash("sha256").update(input).digest();
  const num = hash.readUInt32BE(0);
  const base62Hash = encode$1(num);
  const paddedHash = base62Hash.padStart(3, "0").substring(0, 3);
  return "p" + paddedHash.toLowerCase();
}
function generatePluginMapping(attributes) {
  const mapping = {};
  const reversedMapping = {};
  const usedHashes = /* @__PURE__ */ new Set();
  for (const { key, pluginName } of attributes) {
    let hash = generatePluginAttributeHash(pluginName, key);
    let counter = 1;
    let finalHash = hash;
    while (usedHashes.has(finalHash)) {
      finalHash = `${hash}${counter}`;
      counter++;
    }
    usedHashes.add(finalHash);
    mapping[key] = finalHash;
    reversedMapping[finalHash] = key;
  }
  return { mapping, reversedMapping };
}
const SchemaActions = {
  trim: (value) => value == null ? value : value.trim(),
  encrypt: async (value, { passphrase }) => {
    if (value === null || value === void 0) return value;
    const [ok, err, res] = await tryFn(() => encrypt(value, passphrase));
    return ok ? res : value;
  },
  decrypt: async (value, { passphrase }) => {
    if (value === null || value === void 0) return value;
    const [ok, err, raw] = await tryFn(() => decrypt(value, passphrase));
    if (!ok) return value;
    if (raw === "null") return null;
    if (raw === "undefined") return void 0;
    return raw;
  },
  toString: (value) => value == null ? value : String(value),
  fromArray: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const escapedItems = value.map((item) => {
      if (typeof item === "string") {
        return item.replace(/\\/g, "\\\\").replace(new RegExp(`\\${separator}`, "g"), `\\${separator}`);
      }
      return String(item);
    });
    return escapedItems.join(separator);
  },
  toArray: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value;
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const items = [];
    let current = "";
    let i = 0;
    const str = String(value);
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items;
  },
  toJSON: (value) => {
    if (value === null) return null;
    if (value === void 0) return void 0;
    if (typeof value === "string") {
      const [ok2, err2, parsed] = tryFnSync(() => JSON.parse(value));
      if (ok2 && typeof parsed === "object") return value;
      return value;
    }
    const [ok, err, json] = tryFnSync(() => JSON.stringify(value));
    return ok ? json : value;
  },
  fromJSON: (value) => {
    if (value === null) return null;
    if (value === void 0) return void 0;
    if (typeof value !== "string") return value;
    if (value === "") return "";
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(value));
    return ok ? parsed : value;
  },
  toNumber: (value) => isString(value) ? value.includes(".") ? parseFloat(value) : parseInt(value) : value,
  toBool: (value) => [true, 1, "true", "1", "yes", "y"].includes(value),
  fromBool: (value) => [true, 1, "true", "1", "yes", "y"].includes(value) ? "1" : "0",
  fromBase62: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") return value;
    if (typeof value === "string") {
      const n = decode$1(value);
      return isNaN(n) ? void 0 : n;
    }
    return void 0;
  },
  toBase62: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") {
      return encode$1(value);
    }
    if (typeof value === "string") {
      const n = Number(value);
      return isNaN(n) ? value : encode$1(n);
    }
    return value;
  },
  fromBase62Decimal: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") return value;
    if (typeof value === "string") {
      const n = decodeDecimal(value);
      return isNaN(n) ? void 0 : n;
    }
    return void 0;
  },
  toBase62Decimal: (value) => {
    if (value === null || value === void 0 || value === "") return value;
    if (typeof value === "number") {
      return encodeDecimal(value);
    }
    if (typeof value === "string") {
      const n = Number(value);
      return isNaN(n) ? value : encodeDecimal(n);
    }
    return value;
  },
  fromArrayOfNumbers: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const base62Items = value.map((item) => {
      if (typeof item === "number" && !isNaN(item)) {
        return encode$1(item);
      }
      const n = Number(item);
      return isNaN(n) ? "" : encode$1(n);
    });
    return base62Items.join(separator);
  },
  toArrayOfNumbers: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value.map((v) => typeof v === "number" ? v : decode$1(v));
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const str = String(value);
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decode$1(v);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  fromArrayOfDecimals: (value, { separator }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "";
    }
    const base62Items = value.map((item) => {
      if (typeof item === "number" && !isNaN(item)) {
        return encodeDecimal(item);
      }
      const n = Number(item);
      return isNaN(n) ? "" : encodeDecimal(n);
    });
    return base62Items.join(separator);
  },
  toArrayOfDecimals: (value, { separator }) => {
    if (Array.isArray(value)) {
      return value.map((v) => typeof v === "number" ? v : decodeDecimal(v));
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "") {
      return [];
    }
    const str = String(value);
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decodeDecimal(v);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  fromArrayOfEmbeddings: (value, { separator, precision = 6 }) => {
    if (value === null || value === void 0 || !Array.isArray(value)) {
      return value;
    }
    if (value.length === 0) {
      return "^[]";
    }
    return encodeFixedPointBatch(value, precision);
  },
  toArrayOfEmbeddings: (value, { separator, precision = 6 }) => {
    if (Array.isArray(value)) {
      return value;
    }
    if (value === null || value === void 0) {
      return value;
    }
    if (value === "" || value === "^[]") {
      return [];
    }
    const str = String(value);
    if (str.startsWith("^[")) {
      return decodeFixedPointBatch(str, precision);
    }
    const items = [];
    let current = "";
    let i = 0;
    while (i < str.length) {
      if (str[i] === "\\" && i + 1 < str.length) {
        current += str[i + 1];
        i += 2;
      } else if (str[i] === separator) {
        items.push(current);
        current = "";
        i++;
      } else {
        current += str[i];
        i++;
      }
    }
    items.push(current);
    return items.map((v) => {
      if (typeof v === "number") return v;
      if (typeof v === "string" && v !== "") {
        const n = decodeFixedPoint(v, precision);
        return isNaN(n) ? NaN : n;
      }
      return NaN;
    });
  },
  encodeIPv4: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!isValidIPv4(value)) return value;
    const [ok, err, encoded] = tryFnSync(() => encodeIPv4(value));
    return ok ? encoded : value;
  },
  decodeIPv4: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeIPv4(value));
    return ok ? decoded : value;
  },
  encodeIPv6: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!isValidIPv6(value)) return value;
    const [ok, err, encoded] = tryFnSync(() => encodeIPv6(value));
    return ok ? encoded : value;
  },
  decodeIPv6: (value) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeIPv6(value));
    return ok ? decoded : value;
  },
  // Money type - Integer-based (banking standard)
  // Simplified approach: decimals instead of currency
  encodeMoney: (value, { decimals = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const multiplier = Math.pow(10, decimals);
    const integerValue = Math.round(value * multiplier);
    const [ok, err, encoded] = tryFnSync(() => "$" + encode$1(integerValue));
    return ok ? encoded : value;
  },
  decodeMoney: (value, { decimals = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    if (!value.startsWith("$")) return value;
    const [ok, err, integerValue] = tryFnSync(() => decode$1(value.slice(1)));
    if (!ok || isNaN(integerValue)) return value;
    const divisor = Math.pow(10, decimals);
    return integerValue / divisor;
  },
  // Decimal type - Fixed-point for non-monetary decimals
  encodeDecimalFixed: (value, { precision = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeFixedPoint(value, precision));
    return ok ? encoded : value;
  },
  decodeDecimalFixed: (value, { precision = 2 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeFixedPoint(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Latitude
  encodeGeoLatitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeGeoLat(value, precision));
    return ok ? encoded : value;
  },
  decodeGeoLatitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoLat(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Longitude
  encodeGeoLongitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "number") return value;
    const [ok, err, encoded] = tryFnSync(() => encodeGeoLon(value, precision));
    return ok ? encoded : value;
  },
  decodeGeoLongitude: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoLon(value, precision));
    return ok ? decoded : value;
  },
  // Geo types - Point (lat+lon pair)
  encodeGeoPointPair: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (Array.isArray(value) && value.length === 2) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value[0], value[1], precision));
      return ok ? encoded : value;
    }
    if (typeof value === "object" && value.lat !== void 0 && value.lon !== void 0) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value.lat, value.lon, precision));
      return ok ? encoded : value;
    }
    if (typeof value === "object" && value.latitude !== void 0 && value.longitude !== void 0) {
      const [ok, err, encoded] = tryFnSync(() => encodeGeoPoint(value.latitude, value.longitude, precision));
      return ok ? encoded : value;
    }
    return value;
  },
  decodeGeoPointPair: (value, { precision = 6 } = {}) => {
    if (value === null || value === void 0) return value;
    if (typeof value !== "string") return value;
    const [ok, err, decoded] = tryFnSync(() => decodeGeoPoint(value, precision));
    return ok ? decoded : value;
  }
};
class Schema {
  constructor(args) {
    const {
      map,
      pluginMap,
      name,
      attributes,
      passphrase,
      version = 1,
      options = {},
      _pluginAttributeMetadata,
      _pluginAttributes
    } = args;
    this.name = name;
    this.version = version;
    this.attributes = attributes || {};
    this.passphrase = passphrase ?? "secret";
    this.options = merge({}, this.defaultOptions(), options);
    this.allNestedObjectsOptional = this.options.allNestedObjectsOptional ?? false;
    this._pluginAttributeMetadata = _pluginAttributeMetadata || {};
    this._pluginAttributes = _pluginAttributes || {};
    const processedAttributes = this.preprocessAttributesForValidation(this.attributes);
    this.validator = new ValidatorManager({ autoEncrypt: false }).compile(merge(
      { $$async: true, $$strict: false },
      processedAttributes
    ));
    if (this.options.generateAutoHooks) this.generateAutoHooks();
    if (!isEmpty(map)) {
      this.map = map;
      this.reversedMap = invert(map);
    } else {
      const flatAttrs = flatten(this.attributes, { safe: true });
      const leafKeys = Object.keys(flatAttrs).filter((k) => !k.includes("$$"));
      const objectKeys = this.extractObjectKeys(this.attributes);
      const allKeys = [.../* @__PURE__ */ new Set([...leafKeys, ...objectKeys])];
      const userKeys = [];
      const pluginAttributes = [];
      for (const key of allKeys) {
        const attrDef = this.getAttributeDefinition(key);
        if (typeof attrDef === "object" && attrDef !== null && attrDef.__plugin__) {
          pluginAttributes.push({ key, pluginName: attrDef.__plugin__ });
        } else if (typeof attrDef === "string" && this._pluginAttributeMetadata && this._pluginAttributeMetadata[key]) {
          const pluginName = this._pluginAttributeMetadata[key].__plugin__;
          pluginAttributes.push({ key, pluginName });
        } else {
          userKeys.push(key);
        }
      }
      const { mapping, reversedMapping } = generateBase62Mapping(userKeys);
      this.map = mapping;
      this.reversedMap = reversedMapping;
      const { mapping: pMapping, reversedMapping: pReversedMapping } = generatePluginMapping(pluginAttributes);
      this.pluginMap = pMapping;
      this.reversedPluginMap = pReversedMapping;
      this._pluginAttributes = {};
      for (const { key, pluginName } of pluginAttributes) {
        if (!this._pluginAttributes[pluginName]) {
          this._pluginAttributes[pluginName] = [];
        }
        this._pluginAttributes[pluginName].push(key);
      }
    }
    if (!isEmpty(pluginMap)) {
      this.pluginMap = pluginMap;
      this.reversedPluginMap = invert(pluginMap);
    }
    if (!this.pluginMap) {
      this.pluginMap = {};
      this.reversedPluginMap = {};
    }
    if (!this._pluginAttributes) {
      this._pluginAttributes = {};
    }
  }
  defaultOptions() {
    return {
      autoEncrypt: true,
      autoDecrypt: true,
      arraySeparator: "|",
      generateAutoHooks: true,
      hooks: {
        beforeMap: {},
        afterMap: {},
        beforeUnmap: {},
        afterUnmap: {}
      }
    };
  }
  addHook(hook, attribute, action, params = {}) {
    if (!this.options.hooks[hook][attribute]) this.options.hooks[hook][attribute] = [];
    const hookEntry = Object.keys(params).length > 0 ? { action, params } : action;
    this.options.hooks[hook][attribute] = uniq([...this.options.hooks[hook][attribute], hookEntry]);
  }
  extractObjectKeys(obj, prefix = "") {
    const objectKeys = [];
    for (const [key, value] of Object.entries(obj)) {
      if (key.startsWith("$$")) continue;
      const fullKey = prefix ? `${prefix}.${key}` : key;
      if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        objectKeys.push(fullKey);
        if (value.$$type === "object") {
          objectKeys.push(...this.extractObjectKeys(value, fullKey));
        }
      }
    }
    return objectKeys;
  }
  _generateHooksFromOriginalAttributes(attributes, prefix = "") {
    for (const [key, value] of Object.entries(attributes)) {
      if (key.startsWith("$$")) continue;
      const fullKey = prefix ? `${prefix}.${key}` : key;
      if (typeof value === "object" && value !== null && !Array.isArray(value) && value.type) {
        if (value.type === "array" && value.items) {
          const itemsType = value.items;
          const arrayLength = typeof value.length === "number" ? value.length : null;
          if (itemsType === "string" || typeof itemsType === "string" && itemsType.includes("string")) {
            this.addHook("beforeMap", fullKey, "fromArray");
            this.addHook("afterUnmap", fullKey, "toArray");
          } else if (itemsType === "number" || typeof itemsType === "string" && itemsType.includes("number")) {
            const isIntegerArray = typeof itemsType === "string" && itemsType.includes("integer");
            const isEmbedding = !isIntegerArray && arrayLength !== null && arrayLength >= 256;
            if (isIntegerArray) {
              this.addHook("beforeMap", fullKey, "fromArrayOfNumbers");
              this.addHook("afterUnmap", fullKey, "toArrayOfNumbers");
            } else if (isEmbedding) {
              this.addHook("beforeMap", fullKey, "fromArrayOfEmbeddings");
              this.addHook("afterUnmap", fullKey, "toArrayOfEmbeddings");
            } else {
              this.addHook("beforeMap", fullKey, "fromArrayOfDecimals");
              this.addHook("afterUnmap", fullKey, "toArrayOfDecimals");
            }
          }
        }
      } else if (typeof value === "object" && value !== null && !Array.isArray(value) && !value.type) {
        this._generateHooksFromOriginalAttributes(value, fullKey);
      }
    }
  }
  generateAutoHooks() {
    this._generateHooksFromOriginalAttributes(this.attributes);
    const schema = flatten(cloneDeep(this.attributes), { safe: true });
    for (const [name, definition] of Object.entries(schema)) {
      if (name.includes("$$")) continue;
      if (this.options.hooks.beforeMap[name] || this.options.hooks.afterUnmap[name]) {
        continue;
      }
      const defStr = typeof definition === "string" ? definition : "";
      const defType = typeof definition === "object" && definition !== null ? definition.type : null;
      const isEmbeddingType = defStr.includes("embedding") || defType === "embedding";
      if (isEmbeddingType) {
        const lengthMatch = defStr.match(/embedding:(\d+)/);
        if (lengthMatch) {
          parseInt(lengthMatch[1], 10);
        } else if (defStr.includes("length:")) {
          const match = defStr.match(/length:(\d+)/);
          if (match) parseInt(match[1], 10);
        }
        this.addHook("beforeMap", name, "fromArrayOfEmbeddings");
        this.addHook("afterUnmap", name, "toArrayOfEmbeddings");
        continue;
      }
      const isArray = defStr.includes("array") || defType === "array";
      if (isArray) {
        let itemsType = null;
        if (typeof definition === "object" && definition !== null && definition.items) {
          itemsType = definition.items;
        } else if (defStr.includes("items:string")) {
          itemsType = "string";
        } else if (defStr.includes("items:number")) {
          itemsType = "number";
        }
        if (itemsType === "string" || typeof itemsType === "string" && itemsType.includes("string")) {
          this.addHook("beforeMap", name, "fromArray");
          this.addHook("afterUnmap", name, "toArray");
        } else if (itemsType === "number" || typeof itemsType === "string" && itemsType.includes("number")) {
          const isIntegerArray = defStr.includes("integer:true") || defStr.includes("|integer:") || defStr.includes("|integer") || typeof itemsType === "string" && itemsType.includes("integer");
          let arrayLength = null;
          if (typeof definition === "object" && definition !== null && typeof definition.length === "number") {
            arrayLength = definition.length;
          } else if (defStr.includes("length:")) {
            const match = defStr.match(/length:(\d+)/);
            if (match) arrayLength = parseInt(match[1], 10);
          }
          const isEmbedding = !isIntegerArray && arrayLength !== null && arrayLength >= 256;
          if (isIntegerArray) {
            this.addHook("beforeMap", name, "fromArrayOfNumbers");
            this.addHook("afterUnmap", name, "toArrayOfNumbers");
          } else if (isEmbedding) {
            this.addHook("beforeMap", name, "fromArrayOfEmbeddings");
            this.addHook("afterUnmap", name, "toArrayOfEmbeddings");
          } else {
            this.addHook("beforeMap", name, "fromArrayOfDecimals");
            this.addHook("afterUnmap", name, "toArrayOfDecimals");
          }
        }
        continue;
      }
      if (defStr.includes("secret") || defType === "secret") {
        if (this.options.autoEncrypt) {
          this.addHook("beforeMap", name, "encrypt");
        }
        if (this.options.autoDecrypt) {
          this.addHook("afterUnmap", name, "decrypt");
        }
        continue;
      }
      if (defStr.includes("ip4") || defType === "ip4") {
        this.addHook("beforeMap", name, "encodeIPv4");
        this.addHook("afterUnmap", name, "decodeIPv4");
        continue;
      }
      if (defStr.includes("ip6") || defType === "ip6") {
        this.addHook("beforeMap", name, "encodeIPv6");
        this.addHook("afterUnmap", name, "decodeIPv6");
        continue;
      }
      if (defStr.includes("money") || defType === "money" || defStr.includes("crypto") || defType === "crypto") {
        let decimals = 2;
        if (defStr.includes("crypto") || defType === "crypto") {
          decimals = 8;
        }
        const decimalsMatch = defStr.match(/(?:money|crypto):(\d+)/i);
        if (decimalsMatch) {
          decimals = parseInt(decimalsMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeMoney", { decimals });
        this.addHook("afterUnmap", name, "decodeMoney", { decimals });
        continue;
      }
      if (defStr.includes("decimal") || defType === "decimal") {
        let precision = 2;
        const precisionMatch = defStr.match(/decimal:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeDecimalFixed", { precision });
        this.addHook("afterUnmap", name, "decodeDecimalFixed", { precision });
        continue;
      }
      if (defStr.includes("geo:lat") || defType === "geo" && defStr.includes("lat")) {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:lat:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoLatitude", { precision });
        this.addHook("afterUnmap", name, "decodeGeoLatitude", { precision });
        continue;
      }
      if (defStr.includes("geo:lon") || defType === "geo" && defStr.includes("lon")) {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:lon:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoLongitude", { precision });
        this.addHook("afterUnmap", name, "decodeGeoLongitude", { precision });
        continue;
      }
      if (defStr.includes("geo:point") || defType === "geo:point") {
        let precision = 6;
        const precisionMatch = defStr.match(/geo:point:(\d+)/);
        if (precisionMatch) {
          precision = parseInt(precisionMatch[1], 10);
        }
        this.addHook("beforeMap", name, "encodeGeoPointPair", { precision });
        this.addHook("afterUnmap", name, "decodeGeoPointPair", { precision });
        continue;
      }
      if (defStr.includes("number") || defType === "number") {
        const isInteger = defStr.includes("integer:true") || defStr.includes("|integer:") || defStr.includes("|integer");
        if (isInteger) {
          this.addHook("beforeMap", name, "toBase62");
          this.addHook("afterUnmap", name, "fromBase62");
        } else {
          this.addHook("beforeMap", name, "toBase62Decimal");
          this.addHook("afterUnmap", name, "fromBase62Decimal");
        }
        continue;
      }
      if (defStr.includes("boolean") || defType === "boolean") {
        this.addHook("beforeMap", name, "fromBool");
        this.addHook("afterUnmap", name, "toBool");
        continue;
      }
      if (defStr.includes("json") || defType === "json") {
        this.addHook("beforeMap", name, "toJSON");
        this.addHook("afterUnmap", name, "fromJSON");
        continue;
      }
      if (definition === "object" || defStr.includes("object") || defType === "object") {
        this.addHook("beforeMap", name, "toJSON");
        this.addHook("afterUnmap", name, "fromJSON");
        continue;
      }
    }
  }
  static import(data) {
    let {
      map,
      pluginMap,
      _pluginAttributeMetadata,
      name,
      options,
      version,
      attributes
    } = isString(data) ? JSON.parse(data) : data;
    const [ok, err, attrs] = tryFnSync(() => Schema._importAttributes(attributes));
    if (!ok) throw new SchemaError("Failed to import schema attributes", { original: err, input: attributes });
    attributes = attrs;
    const schema = new Schema({
      map,
      pluginMap: pluginMap || {},
      name,
      options,
      version,
      attributes
    });
    if (_pluginAttributeMetadata) {
      schema._pluginAttributeMetadata = _pluginAttributeMetadata;
    }
    return schema;
  }
  /**
   * Recursively import attributes, parsing only stringified objects (legacy)
   */
  static _importAttributes(attrs) {
    if (typeof attrs === "string") {
      const [ok, err, parsed] = tryFnSync(() => JSON.parse(attrs));
      if (ok && typeof parsed === "object" && parsed !== null) {
        const [okNested, errNested, nested] = tryFnSync(() => Schema._importAttributes(parsed));
        if (!okNested) throw new SchemaError("Failed to parse nested schema attribute", { original: errNested, input: attrs });
        return nested;
      }
      return attrs;
    }
    if (Array.isArray(attrs)) {
      const [okArr, errArr, arr] = tryFnSync(() => attrs.map((a) => Schema._importAttributes(a)));
      if (!okArr) throw new SchemaError("Failed to import array schema attributes", { original: errArr, input: attrs });
      return arr;
    }
    if (typeof attrs === "object" && attrs !== null) {
      const out = {};
      for (const [k, v] of Object.entries(attrs)) {
        const [okObj, errObj, val] = tryFnSync(() => Schema._importAttributes(v));
        if (!okObj) throw new SchemaError("Failed to import object schema attribute", { original: errObj, key: k, input: v });
        out[k] = val;
      }
      return out;
    }
    return attrs;
  }
  export() {
    const data = {
      version: this.version,
      name: this.name,
      options: this.options,
      attributes: this._exportAttributes(this.attributes),
      map: this.map,
      pluginMap: this.pluginMap || {},
      _pluginAttributeMetadata: this._pluginAttributeMetadata || {},
      _pluginAttributes: this._pluginAttributes || {}
    };
    return data;
  }
  /**
   * Recursively export attributes, keeping objects as objects and only serializing leaves as string
   */
  _exportAttributes(attrs) {
    if (typeof attrs === "string") {
      return attrs;
    }
    if (Array.isArray(attrs)) {
      return attrs.map((a) => this._exportAttributes(a));
    }
    if (typeof attrs === "object" && attrs !== null) {
      const out = {};
      for (const [k, v] of Object.entries(attrs)) {
        out[k] = this._exportAttributes(v);
      }
      return out;
    }
    return attrs;
  }
  async applyHooksActions(resourceItem, hook) {
    const cloned = cloneDeep(resourceItem);
    for (const [attribute, actions] of Object.entries(this.options.hooks[hook])) {
      for (const actionEntry of actions) {
        const actionName = typeof actionEntry === "string" ? actionEntry : actionEntry.action;
        const actionParams = typeof actionEntry === "object" ? actionEntry.params : {};
        const value = get(cloned, attribute);
        if (value !== void 0 && typeof SchemaActions[actionName] === "function") {
          set(cloned, attribute, await SchemaActions[actionName](value, {
            passphrase: this.passphrase,
            separator: this.options.arraySeparator,
            ...actionParams
            // Merge custom parameters (currency, precision, etc.)
          }));
        }
      }
    }
    return cloned;
  }
  async validate(resourceItem, { mutateOriginal = false } = {}) {
    let data = mutateOriginal ? resourceItem : cloneDeep(resourceItem);
    const result = await this.validator(data);
    return result;
  }
  async mapper(resourceItem) {
    let obj = cloneDeep(resourceItem);
    obj = await this.applyHooksActions(obj, "beforeMap");
    const flattenedObj = flatten(obj, { safe: true });
    const rest = { "_v": this.version + "" };
    for (const [key, value] of Object.entries(flattenedObj)) {
      const mappedKey = this.pluginMap[key] || this.map[key] || key;
      const attrDef = this.getAttributeDefinition(key);
      if (typeof value === "number" && typeof attrDef === "string" && attrDef.includes("number")) {
        rest[mappedKey] = encode$1(value);
      } else if (typeof value === "string") {
        if (value === "[object Object]") {
          rest[mappedKey] = "{}";
        } else if (value.startsWith("{") || value.startsWith("[")) {
          rest[mappedKey] = value;
        } else {
          rest[mappedKey] = value;
        }
      } else if (Array.isArray(value) || typeof value === "object" && value !== null) {
        rest[mappedKey] = JSON.stringify(value);
      } else {
        rest[mappedKey] = value;
      }
    }
    await this.applyHooksActions(rest, "afterMap");
    return rest;
  }
  async unmapper(mappedResourceItem, mapOverride, pluginMapOverride) {
    let obj = cloneDeep(mappedResourceItem);
    delete obj._v;
    obj = await this.applyHooksActions(obj, "beforeUnmap");
    const reversedMap = mapOverride ? invert(mapOverride) : this.reversedMap;
    const reversedPluginMap = pluginMapOverride ? invert(pluginMapOverride) : this.reversedPluginMap;
    const rest = {};
    for (const [key, value] of Object.entries(obj)) {
      let originalKey = reversedPluginMap[key] || reversedMap[key] || key;
      if (!originalKey) {
        originalKey = key;
      }
      let parsedValue = value;
      const attrDef = this.getAttributeDefinition(originalKey);
      const hasAfterUnmapHook = this.options.hooks?.afterUnmap?.[originalKey];
      if (!hasAfterUnmapHook && typeof attrDef === "string" && attrDef.includes("number") && !attrDef.includes("array") && !attrDef.includes("decimal")) {
        if (typeof parsedValue === "string" && parsedValue !== "") {
          parsedValue = decode$1(parsedValue);
        } else if (typeof parsedValue === "number") ; else {
          parsedValue = void 0;
        }
      } else if (typeof value === "string") {
        if (value === "[object Object]") {
          parsedValue = {};
        } else if (value.startsWith("{") || value.startsWith("[")) {
          const [ok, err, parsed] = tryFnSync(() => JSON.parse(value));
          if (ok) parsedValue = parsed;
        }
      }
      if (this.attributes) {
        if (typeof attrDef === "string" && attrDef.includes("array")) {
          if (!hasAfterUnmapHook) {
            if (Array.isArray(parsedValue)) ; else if (typeof parsedValue === "string" && parsedValue.trim().startsWith("[")) {
              const [okArr, errArr, arr] = tryFnSync(() => JSON.parse(parsedValue));
              if (okArr && Array.isArray(arr)) {
                parsedValue = arr;
              }
            } else {
              parsedValue = SchemaActions.toArray(parsedValue, { separator: this.options.arraySeparator });
            }
          }
        }
      }
      if (this.options.hooks && this.options.hooks.afterUnmap && this.options.hooks.afterUnmap[originalKey]) {
        for (const actionEntry of this.options.hooks.afterUnmap[originalKey]) {
          const actionName = typeof actionEntry === "string" ? actionEntry : actionEntry.action;
          const actionParams = typeof actionEntry === "object" ? actionEntry.params : {};
          if (typeof SchemaActions[actionName] === "function") {
            parsedValue = await SchemaActions[actionName](parsedValue, {
              passphrase: this.passphrase,
              separator: this.options.arraySeparator,
              ...actionParams
              // Merge custom parameters (currency, precision, etc.)
            });
          }
        }
      }
      rest[originalKey] = parsedValue;
    }
    await this.applyHooksActions(rest, "afterUnmap");
    const result = unflatten(rest);
    for (const [key, value] of Object.entries(mappedResourceItem)) {
      if (key.startsWith("$")) {
        result[key] = value;
      }
    }
    return result;
  }
  // Helper to get attribute definition by dot notation key
  getAttributeDefinition(key) {
    const parts = key.split(".");
    let def = this.attributes;
    for (const part of parts) {
      if (!def) return void 0;
      def = def[part];
    }
    return def;
  }
  /**
   * Regenerate plugin attribute mapping
   * Called when plugin attributes are added or removed
   * @returns {void}
   */
  regeneratePluginMapping() {
    const flatAttrs = flatten(this.attributes, { safe: true });
    const leafKeys = Object.keys(flatAttrs).filter((k) => !k.includes("$$"));
    const objectKeys = this.extractObjectKeys(this.attributes);
    const allKeys = [.../* @__PURE__ */ new Set([...leafKeys, ...objectKeys])];
    const pluginAttributes = [];
    for (const key of allKeys) {
      const attrDef = this.getAttributeDefinition(key);
      if (typeof attrDef === "object" && attrDef !== null && attrDef.__plugin__) {
        pluginAttributes.push({ key, pluginName: attrDef.__plugin__ });
      } else if (typeof attrDef === "string" && this._pluginAttributeMetadata && this._pluginAttributeMetadata[key]) {
        const pluginName = this._pluginAttributeMetadata[key].__plugin__;
        pluginAttributes.push({ key, pluginName });
      }
    }
    const { mapping, reversedMapping } = generatePluginMapping(pluginAttributes);
    this.pluginMap = mapping;
    this.reversedPluginMap = reversedMapping;
    this._pluginAttributes = {};
    for (const { key, pluginName } of pluginAttributes) {
      if (!this._pluginAttributes[pluginName]) {
        this._pluginAttributes[pluginName] = [];
      }
      this._pluginAttributes[pluginName].push(key);
    }
  }
  /**
   * Preprocess attributes to convert nested objects into validator-compatible format
   * @param {Object} attributes - Original attributes
   * @returns {Object} Processed attributes for validator
   */
  preprocessAttributesForValidation(attributes) {
    const processed = {};
    for (const [key, value] of Object.entries(attributes)) {
      if (typeof value === "string") {
        if (value === "ip4" || value.startsWith("ip4|")) {
          processed[key] = value.replace(/^ip4/, "string");
          continue;
        }
        if (value === "ip6" || value.startsWith("ip6|")) {
          processed[key] = value.replace(/^ip6/, "string");
          continue;
        }
        if (value === "money" || value.startsWith("money:") || value.startsWith("money|") || value === "crypto" || value.startsWith("crypto:") || value.startsWith("crypto|")) {
          const rest = value.replace(/^(?:money|crypto)(?::\d+)?/, "");
          const hasMin = rest.includes("min:");
          processed[key] = hasMin ? `number${rest}` : `number|min:0${rest}`;
          continue;
        }
        if (value === "decimal" || value.startsWith("decimal:") || value.startsWith("decimal|")) {
          const rest = value.replace(/^decimal(:\d+)?/, "");
          processed[key] = `number${rest}`;
          continue;
        }
        if (value.startsWith("geo:lat")) {
          const rest = value.replace(/^geo:lat(:\d+)?/, "");
          const hasMin = rest.includes("min:");
          const hasMax = rest.includes("max:");
          let validation = "number";
          if (!hasMin) validation += "|min:-90";
          if (!hasMax) validation += "|max:90";
          processed[key] = validation + rest;
          continue;
        }
        if (value.startsWith("geo:lon")) {
          const rest = value.replace(/^geo:lon(:\d+)?/, "");
          const hasMin = rest.includes("min:");
          const hasMax = rest.includes("max:");
          let validation = "number";
          if (!hasMin) validation += "|min:-180";
          if (!hasMax) validation += "|max:180";
          processed[key] = validation + rest;
          continue;
        }
        if (value.startsWith("geo:point")) {
          processed[key] = "any";
          continue;
        }
        if (value.startsWith("embedding:")) {
          const lengthMatch = value.match(/embedding:(\d+)/);
          if (lengthMatch) {
            const length = lengthMatch[1];
            const rest = value.substring(`embedding:${length}`.length);
            processed[key] = `array|items:number|length:${length}|empty:false${rest}`;
            continue;
          }
        }
        if (value.startsWith("embedding|") || value === "embedding") {
          processed[key] = value.replace(/^embedding/, "array|items:number|empty:false");
          continue;
        }
        processed[key] = value;
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        const hasValidatorType = value.type !== void 0 && key !== "$$type";
        if (hasValidatorType) {
          const { __plugin__, __pluginCreated__, ...cleanValue } = value;
          if (cleanValue.type === "ip4") {
            processed[key] = { ...cleanValue, type: "string" };
          } else if (cleanValue.type === "ip6") {
            processed[key] = { ...cleanValue, type: "string" };
          } else if (cleanValue.type === "money" || cleanValue.type === "crypto") {
            processed[key] = { ...cleanValue, type: "number", min: cleanValue.min !== void 0 ? cleanValue.min : 0 };
          } else if (cleanValue.type === "decimal") {
            processed[key] = { ...cleanValue, type: "number" };
          } else if (cleanValue.type === "geo:lat" || cleanValue.type === "geo-lat") {
            processed[key] = {
              ...cleanValue,
              type: "number",
              min: cleanValue.min !== void 0 ? cleanValue.min : -90,
              max: cleanValue.max !== void 0 ? cleanValue.max : 90
            };
          } else if (cleanValue.type === "geo:lon" || cleanValue.type === "geo-lon") {
            processed[key] = {
              ...cleanValue,
              type: "number",
              min: cleanValue.min !== void 0 ? cleanValue.min : -180,
              max: cleanValue.max !== void 0 ? cleanValue.max : 180
            };
          } else if (cleanValue.type === "geo:point" || cleanValue.type === "geo-point") {
            processed[key] = { ...cleanValue, type: "any" };
          } else if (cleanValue.type === "object" && cleanValue.properties) {
            processed[key] = {
              ...cleanValue,
              properties: this.preprocessAttributesForValidation(cleanValue.properties)
            };
          } else {
            processed[key] = cleanValue;
          }
        } else {
          const isExplicitRequired = value.$$type && value.$$type.includes("required");
          const isExplicitOptional = value.$$type && value.$$type.includes("optional");
          const objectConfig = {
            type: "object",
            properties: this.preprocessAttributesForValidation(value),
            strict: false
          };
          if (isExplicitRequired) ; else if (isExplicitOptional || this.allNestedObjectsOptional) {
            objectConfig.optional = true;
          }
          processed[key] = objectConfig;
        }
      } else {
        processed[key] = value;
      }
    }
    return processed;
  }
}

class ResourceIdsReader extends EventEmitter {
  constructor({ resource }) {
    super();
    this.resource = resource;
    this.client = resource.client;
    this.stream = new ReadableStream({
      highWaterMark: this.client.parallelism * 3,
      start: this._start.bind(this),
      pull: this._pull.bind(this),
      cancel: this._cancel.bind(this)
    });
  }
  build() {
    return this.stream.getReader();
  }
  async _start(controller) {
    this.controller = controller;
    this.continuationToken = null;
    this.closeNextIteration = false;
  }
  async _pull(controller) {
    if (this.closeNextIteration) {
      controller.close();
      return;
    }
    const response = await this.client.listObjects({
      prefix: `resource=${this.resource.name}`,
      continuationToken: this.continuationToken
    });
    const keys = response?.Contents.map((x) => x.Key).map((x) => x.replace(this.client.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x).map((x) => x.replace(`resource=${this.resource.name}/id=`, ""));
    this.continuationToken = response.NextContinuationToken;
    this.enqueue(keys);
    if (!response.IsTruncated) this.closeNextIteration = true;
  }
  enqueue(ids) {
    ids.forEach((key) => {
      this.controller.enqueue(key);
      this.emit("id", key);
    });
  }
  _cancel(reason) {
  }
}

class ResourceIdsPageReader extends ResourceIdsReader {
  enqueue(ids) {
    this.controller.enqueue(ids);
    this.emit("page", ids);
  }
}

class ResourceReader extends EventEmitter {
  constructor({ resource, batchSize = 10, concurrency = 5 }) {
    super();
    if (!resource) {
      throw new StreamError("Resource is required for ResourceReader", {
        operation: "constructor",
        resource: resource?.name,
        suggestion: "Pass a valid Resource instance when creating ResourceReader"
      });
    }
    this.resource = resource;
    this.client = resource.client;
    this.batchSize = batchSize;
    this.concurrency = concurrency;
    this.input = new ResourceIdsPageReader({ resource: this.resource });
    this.transform = new Transform({
      objectMode: true,
      transform: this._transform.bind(this)
    });
    this.input.on("data", (chunk) => {
      this.transform.write(chunk);
    });
    this.input.on("end", () => {
      this.transform.end();
    });
    this.input.on("error", (error) => {
      this.emit("error", error);
    });
    this.transform.on("data", (data) => {
      this.emit("data", data);
    });
    this.transform.on("end", () => {
      this.emit("end");
    });
    this.transform.on("error", (error) => {
      this.emit("error", error);
    });
  }
  build() {
    return this;
  }
  async _transform(chunk, encoding, callback) {
    const [ok, err] = await tryFn(async () => {
      await PromisePool.for(chunk).withConcurrency(this.concurrency).handleError(async (error, content) => {
        this.emit("error", error, content);
      }).process(async (id) => {
        const data = await this.resource.get(id);
        this.push(data);
        return data;
      });
    });
    callback(err);
  }
  resume() {
    this.input.resume();
  }
}

class ResourceWriter extends EventEmitter {
  constructor({ resource, batchSize = 10, concurrency = 5 }) {
    super();
    this.resource = resource;
    this.client = resource.client;
    this.batchSize = batchSize;
    this.concurrency = concurrency;
    this.buffer = [];
    this.writing = false;
    this.writable = new Writable({
      objectMode: true,
      write: this._write.bind(this)
    });
    this.writable.on("finish", () => {
      this.emit("finish");
    });
    this.writable.on("error", (error) => {
      this.emit("error", error);
    });
  }
  build() {
    return this;
  }
  write(chunk) {
    this.buffer.push(chunk);
    this._maybeWrite().catch((error) => {
      this.emit("error", error);
    });
    return true;
  }
  end() {
    this.ended = true;
    this._maybeWrite().catch((error) => {
      this.emit("error", error);
    });
  }
  async _maybeWrite() {
    if (this.writing) return;
    if (this.buffer.length === 0 && !this.ended) return;
    this.writing = true;
    while (this.buffer.length > 0) {
      const batch = this.buffer.splice(0, this.batchSize);
      const [ok, err] = await tryFn(async () => {
        await PromisePool.for(batch).withConcurrency(this.concurrency).handleError(async (error, content) => {
          this.emit("error", error, content);
        }).process(async (item) => {
          const [ok2, err2, result] = await tryFn(async () => {
            const res = await this.resource.insert(item);
            return res;
          });
          if (!ok2) {
            this.emit("error", err2, item);
            return null;
          }
          return result;
        });
      });
      if (!ok) {
        this.emit("error", err);
      }
    }
    this.writing = false;
    if (this.ended) {
      this.writable.emit("finish");
    }
  }
  async _write(chunk, encoding, callback) {
    callback();
  }
}

function streamToString(stream) {
  return new Promise((resolve, reject) => {
    if (!stream) {
      return reject(new StreamError("Stream is undefined", {
        operation: "streamToString",
        suggestion: "Ensure a valid stream is passed to streamToString()"
      }));
    }
    const chunks = [];
    stream.on("data", (chunk) => chunks.push(chunk));
    stream.on("error", reject);
    stream.on("end", () => resolve(Buffer.concat(chunks).toString("utf-8")));
  });
}

const S3_METADATA_LIMIT_BYTES = 2047;
async function handleInsert$4({ resource, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on insert", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "insert"
    });
  }
  return { mappedData, body: "" };
}
async function handleUpdate$4({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on update", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "update",
      id
    });
  }
  return { mappedData, body: JSON.stringify(mappedData) };
}
async function handleUpsert$4({ resource, id, data, mappedData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    throw new MetadataLimitError("Metadata size exceeds 2KB limit on upsert", {
      totalSize,
      effectiveLimit,
      absoluteLimit: S3_METADATA_LIMIT_BYTES,
      excess: totalSize - effectiveLimit,
      resourceName: resource.name,
      operation: "upsert",
      id
    });
  }
  return { mappedData, body: "" };
}
async function handleGet$4({ resource, metadata, body }) {
  return { metadata, body };
}

var enforceLimits = /*#__PURE__*/Object.freeze({
  __proto__: null,
  S3_METADATA_LIMIT_BYTES: S3_METADATA_LIMIT_BYTES,
  handleGet: handleGet$4,
  handleInsert: handleInsert$4,
  handleUpdate: handleUpdate$4,
  handleUpsert: handleUpsert$4
});

async function handleInsert$3({ resource, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "insert",
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
    const metadataOnly = { _v: mappedData._v };
    if (resource.schema?.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
      metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
    }
    return { mappedData: metadataOnly, body: JSON.stringify(mappedData) };
  }
  return { mappedData, body: "" };
}
async function handleUpdate$3({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "update",
      id,
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
  }
  return { mappedData, body: JSON.stringify(data) };
}
async function handleUpsert$3({ resource, id, data, mappedData, originalData }) {
  const totalSize = calculateTotalSize(mappedData);
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id
    }
  });
  if (totalSize > effectiveLimit) {
    resource.emit("exceedsLimit", {
      operation: "upsert",
      id,
      totalSize,
      limit: 2047,
      excess: totalSize - 2047,
      data: originalData || data
    });
  }
  return { mappedData, body: JSON.stringify(data) };
}
async function handleGet$3({ resource, metadata, body }) {
  if (body && body.trim() !== "") {
    const [ok, error, result] = tryFn(() => {
      const bodyData = JSON.parse(body);
      return {
        metadata: {
          ...bodyData,
          ...metadata
        },
        body
      };
    });
    if (ok) {
      return result;
    } else {
      return { metadata, body };
    }
  }
  return { metadata, body };
}

var userManaged = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$3,
  handleInsert: handleInsert$3,
  handleUpdate: handleUpdate$3,
  handleUpsert: handleUpsert$3
});

const TRUNCATED_FLAG = "$truncated";
const TRUNCATED_FLAG_VALUE = "true";
const TRUNCATED_FLAG_BYTES = calculateUTF8Bytes(TRUNCATED_FLAG) + calculateUTF8Bytes(TRUNCATED_FLAG_VALUE);
async function handleInsert$2({ resource, data, mappedData, originalData }) {
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  const attributeSizes = calculateAttributeSizes(mappedData);
  const sortedFields = Object.entries(attributeSizes).sort(([, a], [, b]) => a - b);
  const resultFields = {};
  let currentSize = 0;
  let truncated = false;
  if (mappedData._v) {
    resultFields._v = mappedData._v;
    currentSize += attributeSizes._v;
  }
  for (const [fieldName, size] of sortedFields) {
    if (fieldName === "_v") continue;
    const fieldValue = mappedData[fieldName];
    const spaceNeeded = size + (truncated ? 0 : TRUNCATED_FLAG_BYTES);
    if (currentSize + spaceNeeded <= effectiveLimit) {
      resultFields[fieldName] = fieldValue;
      currentSize += size;
    } else {
      const availableSpace = effectiveLimit - currentSize - (truncated ? 0 : TRUNCATED_FLAG_BYTES);
      if (availableSpace > 0) {
        const truncatedValue = truncateValue(fieldValue, availableSpace);
        resultFields[fieldName] = truncatedValue;
        truncated = true;
        currentSize += calculateUTF8Bytes(truncatedValue);
      } else {
        resultFields[fieldName] = "";
        truncated = true;
      }
      break;
    }
  }
  let finalSize = calculateTotalSize(resultFields) + (truncated ? TRUNCATED_FLAG_BYTES : 0);
  while (finalSize > effectiveLimit) {
    const fieldNames = Object.keys(resultFields).filter((f) => f !== "_v" && f !== "$truncated");
    if (fieldNames.length === 0) {
      break;
    }
    const lastField = fieldNames[fieldNames.length - 1];
    resultFields[lastField] = "";
    finalSize = calculateTotalSize(resultFields) + TRUNCATED_FLAG_BYTES;
    truncated = true;
  }
  if (truncated) {
    resultFields[TRUNCATED_FLAG] = TRUNCATED_FLAG_VALUE;
  }
  return { mappedData: resultFields, body: "" };
}
async function handleUpdate$2({ resource, id, data, mappedData, originalData }) {
  return handleInsert$2({ resource, data, mappedData, originalData });
}
async function handleUpsert$2({ resource, id, data, mappedData }) {
  return handleInsert$2({ resource, data, mappedData });
}
async function handleGet$2({ resource, metadata, body }) {
  return { metadata, body };
}
function truncateValue(value, maxBytes) {
  if (typeof value === "string") {
    return truncateString(value, maxBytes);
  } else if (typeof value === "object" && value !== null) {
    const jsonStr = JSON.stringify(value);
    return truncateString(jsonStr, maxBytes);
  } else {
    const stringValue = String(value);
    return truncateString(stringValue, maxBytes);
  }
}
function truncateString(str, maxBytes) {
  const encoder = new TextEncoder();
  let bytes = encoder.encode(str);
  if (bytes.length <= maxBytes) {
    return str;
  }
  let length = str.length;
  while (length > 0) {
    const truncated = str.substring(0, length);
    bytes = encoder.encode(truncated);
    if (bytes.length <= maxBytes) {
      return truncated;
    }
    length--;
  }
  return "";
}

var dataTruncate = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$2,
  handleInsert: handleInsert$2,
  handleUpdate: handleUpdate$2,
  handleUpsert: handleUpsert$2
});

const OVERFLOW_FLAG = "$overflow";
const OVERFLOW_FLAG_VALUE = "true";
const OVERFLOW_FLAG_BYTES = calculateUTF8Bytes(OVERFLOW_FLAG) + calculateUTF8Bytes(OVERFLOW_FLAG_VALUE);
async function handleInsert$1({ resource, data, mappedData, originalData }) {
  const effectiveLimit = calculateEffectiveLimit({
    s3Limit: S3_METADATA_LIMIT_BYTES,
    systemConfig: {
      version: resource.version,
      timestamps: resource.config.timestamps,
      id: data.id
    }
  });
  const attributeSizes = calculateAttributeSizes(mappedData);
  const sortedFields = Object.entries(attributeSizes).sort(([, a], [, b]) => a - b);
  const metadataFields = {};
  const bodyFields = {};
  let currentSize = 0;
  let willOverflow = false;
  if (mappedData._v) {
    metadataFields._v = mappedData._v;
    currentSize += attributeSizes._v;
  }
  if (resource.schema?.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    const pluginMapStr = JSON.stringify(resource.schema.pluginMap);
    const pluginMapSize = calculateUTF8Bytes("_pluginMap") + calculateUTF8Bytes(pluginMapStr);
    metadataFields._pluginMap = pluginMapStr;
    currentSize += pluginMapSize;
  }
  let reservedLimit = effectiveLimit;
  for (const [fieldName, size] of sortedFields) {
    if (fieldName === "_v") continue;
    if (!willOverflow && currentSize + size > effectiveLimit) {
      reservedLimit -= OVERFLOW_FLAG_BYTES;
      willOverflow = true;
    }
    if (!willOverflow && currentSize + size <= reservedLimit) {
      metadataFields[fieldName] = mappedData[fieldName];
      currentSize += size;
    } else {
      bodyFields[fieldName] = mappedData[fieldName];
      willOverflow = true;
    }
  }
  if (willOverflow) {
    metadataFields[OVERFLOW_FLAG] = OVERFLOW_FLAG_VALUE;
  }
  const hasOverflow = Object.keys(bodyFields).length > 0;
  let body = hasOverflow ? JSON.stringify(bodyFields) : "";
  return { mappedData: metadataFields, body };
}
async function handleUpdate$1({ resource, id, data, mappedData, originalData }) {
  return handleInsert$1({ resource, data, mappedData, originalData });
}
async function handleUpsert$1({ resource, id, data, mappedData }) {
  return handleInsert$1({ resource, data, mappedData });
}
async function handleGet$1({ resource, metadata, body }) {
  let bodyData = {};
  if (body && body.trim() !== "") {
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(body));
    if (ok) {
      bodyData = parsed;
    } else {
      bodyData = {};
    }
  }
  const mergedData = {
    ...bodyData,
    ...metadata
  };
  delete mergedData.$overflow;
  return { metadata: mergedData, body };
}

var bodyOverflow = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet$1,
  handleInsert: handleInsert$1,
  handleUpdate: handleUpdate$1,
  handleUpsert: handleUpsert$1
});

async function handleInsert({ resource, data, mappedData }) {
  const metadataOnly = {
    "_v": mappedData._v || String(resource.version)
  };
  metadataOnly._map = JSON.stringify(resource.schema.map);
  if (resource.schema.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
  }
  const body = JSON.stringify(mappedData);
  return { mappedData: metadataOnly, body };
}
async function handleUpdate({ resource, id, data, mappedData }) {
  const metadataOnly = {
    "_v": mappedData._v || String(resource.version)
  };
  metadataOnly._map = JSON.stringify(resource.schema.map);
  if (resource.schema.pluginMap && Object.keys(resource.schema.pluginMap).length > 0) {
    metadataOnly._pluginMap = JSON.stringify(resource.schema.pluginMap);
  }
  const body = JSON.stringify(mappedData);
  return { mappedData: metadataOnly, body };
}
async function handleUpsert({ resource, id, data, mappedData }) {
  return handleInsert({ resource, data, mappedData });
}
async function handleGet({ resource, metadata, body }) {
  let bodyData = {};
  if (body && body.trim() !== "") {
    const [ok, err, parsed] = tryFnSync(() => JSON.parse(body));
    if (ok) {
      bodyData = parsed;
    } else {
      bodyData = {};
    }
  }
  const mergedData = {
    ...bodyData,
    ...metadata
    // metadata contains _v
  };
  return { metadata: mergedData, body };
}

var bodyOnly = /*#__PURE__*/Object.freeze({
  __proto__: null,
  handleGet: handleGet,
  handleInsert: handleInsert,
  handleUpdate: handleUpdate,
  handleUpsert: handleUpsert
});

const behaviors = {
  "user-managed": userManaged,
  "enforce-limits": enforceLimits,
  "truncate-data": dataTruncate,
  "body-overflow": bodyOverflow,
  "body-only": bodyOnly
};
function getBehavior(behaviorName) {
  const behavior = behaviors[behaviorName];
  if (!behavior) {
    throw new BehaviorError(`Unknown behavior: ${behaviorName}`, {
      behavior: behaviorName,
      availableBehaviors: Object.keys(behaviors),
      operation: "getBehavior"
    });
  }
  return behavior;
}
const AVAILABLE_BEHAVIORS = Object.keys(behaviors);
const DEFAULT_BEHAVIOR = "user-managed";

class Resource extends AsyncEventEmitter {
  /**
   * Create a new Resource instance
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.client - S3 client instance
   * @param {string} [config.version='v1'] - Resource version
   * @param {Object} [config.attributes={}] - Resource attributes schema
   * @param {string} [config.behavior='user-managed'] - Resource behavior strategy
   * @param {string} [config.passphrase='secret'] - Encryption passphrase
   * @param {number} [config.parallelism=10] - Parallelism for bulk operations
   * @param {Array} [config.observers=[]] - Observer instances
   * @param {boolean} [config.cache=false] - Enable caching
   * @param {boolean} [config.autoDecrypt=true] - Auto-decrypt secret fields
   * @param {boolean} [config.timestamps=false] - Enable automatic timestamps
   * @param {Object} [config.partitions={}] - Partition definitions
   * @param {boolean} [config.paranoid=true] - Security flag for dangerous operations
   * @param {boolean} [config.allNestedObjectsOptional=false] - Make nested objects optional
   * @param {Object} [config.hooks={}] - Custom hooks
   * @param {Object} [config.options={}] - Additional options
   * @param {Function} [config.idGenerator] - Custom ID generator function
   * @param {number} [config.idSize=22] - Size for auto-generated IDs
   * @param {boolean} [config.versioningEnabled=false] - Enable versioning for this resource
   * @param {Object} [config.events={}] - Event listeners to automatically add
   * @param {boolean} [config.asyncEvents=true] - Whether events should be emitted asynchronously
   * @example
   * const users = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: {
   *     name: 'string|required',
   *     email: 'string|required',
   *     password: 'secret|required'
   *   },
   *   behavior: 'user-managed',
   *   passphrase: 'my-secret-key',
   *   timestamps: true,
   *   partitions: {
   *     byRegion: {
   *       fields: { region: 'string' }
   *     }
   *   },
   *   hooks: {
   *     beforeInsert: [async (data) => {
      *       return data;
   *     }]
   *   },
   *   events: {
   *     insert: (ev) => console.log('Inserted:', ev.id),
   *     update: [
   *       (ev) => console.warn('Update detected'),
   *       (ev) => console.log('Updated:', ev.id)
   *     ],
   *     delete: (ev) => console.log('Deleted:', ev.id)
   *   }
   * });
   * 
   * // With custom ID size
   * const shortIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idSize: 8 // Generate 8-character IDs
   * });
   * 
   * // With custom ID generator function
   * const customIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idGenerator: () => `user_${Date.now()}_${Math.random().toString(36).substr(2, 5)}`
   * });
   * 
   * // With custom ID generator using size parameter
   * const longIdUsers = new Resource({
   *   name: 'users',
   *   client: s3Client,
   *   attributes: { name: 'string|required' },
   *   idGenerator: 32 // Generate 32-character IDs (same as idSize: 32)
   * });
   */
  constructor(config = {}) {
    super();
    this._instanceId = idGenerator(7);
    const validation = validateResourceConfig(config);
    if (!validation.isValid) {
      const errorDetails = validation.errors.map((err) => `  \u2022 ${err}`).join("\n");
      throw new ResourceError(
        `Invalid Resource ${config.name || "[unnamed]"} configuration:
${errorDetails}`,
        {
          resourceName: config.name,
          validation: validation.errors
        }
      );
    }
    const {
      name,
      client,
      version = "1",
      attributes = {},
      behavior = DEFAULT_BEHAVIOR,
      passphrase = "secret",
      parallelism = 10,
      observers = [],
      cache = false,
      autoDecrypt = true,
      timestamps = false,
      partitions = {},
      paranoid = true,
      allNestedObjectsOptional = true,
      hooks = {},
      idGenerator: customIdGenerator,
      idSize = 22,
      versioningEnabled = false,
      strictValidation = true,
      events = {},
      asyncEvents = true,
      asyncPartitions = true,
      strictPartitions = false,
      createdBy = "user",
      guard
    } = config;
    this.name = name;
    this.client = client;
    this.version = version;
    this.behavior = behavior;
    this.observers = observers;
    this.parallelism = parallelism;
    this.passphrase = passphrase ?? "secret";
    this.versioningEnabled = versioningEnabled;
    this.strictValidation = strictValidation;
    this.setAsyncMode(asyncEvents);
    this.idGenerator = this.configureIdGenerator(customIdGenerator, idSize);
    if (typeof customIdGenerator === "number" && customIdGenerator > 0) {
      this.idSize = customIdGenerator;
    } else if (typeof idSize === "number" && idSize > 0) {
      this.idSize = idSize;
    } else {
      this.idSize = 22;
    }
    this.idGeneratorType = this.getIdGeneratorType(customIdGenerator, this.idSize);
    this.config = {
      cache,
      hooks,
      paranoid,
      timestamps,
      partitions,
      autoDecrypt,
      allNestedObjectsOptional,
      asyncEvents,
      asyncPartitions,
      strictPartitions,
      createdBy
    };
    this.hooks = {
      // Insert hooks
      beforeInsert: [],
      afterInsert: [],
      // Update hooks
      beforeUpdate: [],
      afterUpdate: [],
      // Delete hooks
      beforeDelete: [],
      afterDelete: [],
      // Get hooks
      beforeGet: [],
      afterGet: [],
      // List hooks
      beforeList: [],
      afterList: [],
      // Query hooks
      beforeQuery: [],
      afterQuery: [],
      // Patch hooks
      beforePatch: [],
      afterPatch: [],
      // Replace hooks
      beforeReplace: [],
      afterReplace: [],
      // Exists hooks
      beforeExists: [],
      afterExists: [],
      // Count hooks
      beforeCount: [],
      afterCount: [],
      // GetMany hooks
      beforeGetMany: [],
      afterGetMany: [],
      // DeleteMany hooks
      beforeDeleteMany: [],
      afterDeleteMany: []
    };
    this.attributes = attributes || {};
    this.map = config.map;
    this.applyConfiguration({ map: this.map });
    if (hooks) {
      for (const [event, hooksArr] of Object.entries(hooks)) {
        if (Array.isArray(hooksArr) && this.hooks[event]) {
          for (const fn of hooksArr) {
            if (typeof fn === "function") {
              this.hooks[event].push(fn.bind(this));
            }
          }
        }
      }
    }
    if (events && Object.keys(events).length > 0) {
      for (const [eventName, listeners] of Object.entries(events)) {
        if (Array.isArray(listeners)) {
          for (const listener of listeners) {
            if (typeof listener === "function") {
              this.on(eventName, listener.bind(this));
            }
          }
        } else if (typeof listeners === "function") {
          this.on(eventName, listeners.bind(this));
        }
      }
    }
    this.guard = this._normalizeGuard(guard);
    this._initMiddleware();
  }
  /**
   * Configure ID generator based on provided options
   * @param {Function|number} customIdGenerator - Custom ID generator function or size
   * @param {number} idSize - Size for auto-generated IDs
   * @returns {Function} Configured ID generator function
   * @private
   */
  configureIdGenerator(customIdGenerator, idSize) {
    if (typeof customIdGenerator === "function") {
      return () => String(customIdGenerator());
    }
    if (typeof customIdGenerator === "number" && customIdGenerator > 0) {
      return customAlphabet(urlAlphabet, customIdGenerator);
    }
    if (typeof idSize === "number" && idSize > 0 && idSize !== 22) {
      return customAlphabet(urlAlphabet, idSize);
    }
    return idGenerator;
  }
  /**
   * Get a serializable representation of the ID generator type
   * @param {Function|number} customIdGenerator - Custom ID generator function or size
   * @param {number} idSize - Size for auto-generated IDs
   * @returns {string|number} Serializable ID generator type
   * @private
   */
  getIdGeneratorType(customIdGenerator, idSize) {
    if (typeof customIdGenerator === "function") {
      return "custom_function";
    }
    return idSize;
  }
  export() {
    const exported = this.schema.export();
    exported.behavior = this.behavior;
    exported.timestamps = this.config.timestamps;
    exported.partitions = this.config.partitions || {};
    exported.paranoid = this.config.paranoid;
    exported.allNestedObjectsOptional = this.config.allNestedObjectsOptional;
    exported.autoDecrypt = this.config.autoDecrypt;
    exported.cache = this.config.cache;
    exported.hooks = this.hooks;
    exported.map = this.map;
    return exported;
  }
  /**
   * Apply configuration settings (timestamps, partitions, hooks)
   * This method ensures that all configuration-dependent features are properly set up
   */
  applyConfiguration({ map } = {}) {
    if (this.config.timestamps) {
      if (!this.attributes.createdAt) {
        this.attributes.createdAt = "string|optional";
      }
      if (!this.attributes.updatedAt) {
        this.attributes.updatedAt = "string|optional";
      }
      if (!this.config.partitions) {
        this.config.partitions = {};
      }
      if (!this.config.partitions.byCreatedDate) {
        this.config.partitions.byCreatedDate = {
          fields: {
            createdAt: "date|maxlength:10"
          }
        };
      }
      if (!this.config.partitions.byUpdatedDate) {
        this.config.partitions.byUpdatedDate = {
          fields: {
            updatedAt: "date|maxlength:10"
          }
        };
      }
    }
    this.setupPartitionHooks();
    if (this.versioningEnabled) {
      if (!this.config.partitions.byVersion) {
        this.config.partitions.byVersion = {
          fields: {
            _v: "string"
          }
        };
      }
    }
    this.schema = new Schema({
      name: this.name,
      attributes: this.attributes,
      passphrase: this.passphrase,
      version: this.version,
      options: {
        autoDecrypt: this.config.autoDecrypt,
        allNestedObjectsOptional: this.config.allNestedObjectsOptional
      },
      map: map || this.map
    });
    this.validatePartitions();
  }
  /**
   * Update resource attributes and rebuild schema
   * @param {Object} newAttributes - New attributes definition
   */
  updateAttributes(newAttributes) {
    const oldAttributes = this.attributes;
    this.attributes = newAttributes;
    this.applyConfiguration();
    return { oldAttributes, newAttributes };
  }
  /**
   * Add a plugin-created attribute to the resource schema
   * This ensures plugin attributes don't interfere with user-defined attributes
   * by using a separate mapping namespace (p0, p1, p2, ...)
   *
   * @param {string} name - Attribute name (e.g., '_hasEmbedding', 'clusterId')
   * @param {Object|string} definition - Attribute definition
   * @param {string} pluginName - Name of plugin adding the attribute
   * @returns {void}
   *
   * @example
   * // VectorPlugin adding tracking field
   * resource.addPluginAttribute('_hasEmbedding', {
   *   type: 'boolean',
   *   optional: true,
   *   default: false
   * }, 'VectorPlugin');
   *
   * // Shorthand notation
   * resource.addPluginAttribute('clusterId', 'string|optional', 'VectorPlugin');
   */
  addPluginAttribute(name, definition, pluginName) {
    if (!pluginName) {
      throw new ResourceError(
        "Plugin name is required when adding plugin attributes",
        { resource: this.name, attribute: name }
      );
    }
    const existingDef = this.schema.getAttributeDefinition(name);
    if (existingDef && (!existingDef.__plugin__ || existingDef.__plugin__ !== pluginName)) {
      throw new ResourceError(
        `Attribute '${name}' already exists and is not from plugin '${pluginName}'`,
        { resource: this.name, attribute: name, plugin: pluginName }
      );
    }
    let defObject = definition;
    if (typeof definition === "object" && definition !== null) {
      defObject = { ...definition };
    }
    if (typeof defObject === "object" && defObject !== null) {
      defObject.__plugin__ = pluginName;
      defObject.__pluginCreated__ = Date.now();
    }
    this.schema.attributes[name] = defObject;
    this.attributes[name] = defObject;
    if (typeof defObject === "string") {
      if (!this.schema._pluginAttributeMetadata) {
        this.schema._pluginAttributeMetadata = {};
      }
      this.schema._pluginAttributeMetadata[name] = {
        __plugin__: pluginName,
        __pluginCreated__: Date.now()
      };
    }
    this.schema.regeneratePluginMapping();
    if (this.schema.options.generateAutoHooks) {
      this.schema.generateAutoHooks();
    }
    const processedAttributes = this.schema.preprocessAttributesForValidation(this.schema.attributes);
    this.schema.validator = new ValidatorManager({ autoEncrypt: false }).compile(merge(
      { $$async: true, $$strict: false },
      processedAttributes
    ));
    if (this.database) {
      this.database.emit("plugin-attribute-added", {
        resource: this.name,
        attribute: name,
        plugin: pluginName,
        definition: defObject
      });
    }
  }
  /**
   * Remove a plugin-created attribute from the resource schema
   * Called when a plugin is uninstalled or no longer needs the attribute
   *
   * @param {string} name - Attribute name to remove
   * @param {string} [pluginName] - Optional plugin name for safety check
   * @returns {boolean} True if attribute was removed, false if not found
   *
   * @example
   * resource.removePluginAttribute('_hasEmbedding', 'VectorPlugin');
   */
  removePluginAttribute(name, pluginName = null) {
    const attrDef = this.schema.getAttributeDefinition(name);
    const metadata = this.schema._pluginAttributeMetadata?.[name];
    const isPluginAttr = typeof attrDef === "object" && attrDef?.__plugin__ || metadata;
    if (!attrDef || !isPluginAttr) {
      return false;
    }
    const actualPlugin = attrDef?.__plugin__ || metadata?.__plugin__;
    if (pluginName && actualPlugin !== pluginName) {
      throw new ResourceError(
        `Attribute '${name}' belongs to plugin '${actualPlugin}', not '${pluginName}'`,
        { resource: this.name, attribute: name, actualPlugin, requestedPlugin: pluginName }
      );
    }
    delete this.schema.attributes[name];
    delete this.attributes[name];
    if (this.schema._pluginAttributeMetadata?.[name]) {
      delete this.schema._pluginAttributeMetadata[name];
    }
    this.schema.regeneratePluginMapping();
    if (this.database) {
      this.database.emit("plugin-attribute-removed", {
        resource: this.name,
        attribute: name,
        plugin: actualPlugin
      });
    }
    return true;
  }
  /**
   * Add a hook function for a specific event
   * @param {string} event - Hook event (beforeInsert, afterInsert, etc.)
   * @param {Function} fn - Hook function
   */
  addHook(event, fn) {
    if (this.hooks[event]) {
      this.hooks[event].push(fn.bind(this));
    }
  }
  /**
   * Execute hooks for a specific event
   * @param {string} event - Hook event
   * @param {*} data - Data to pass to hooks
   * @returns {*} Modified data
   */
  async executeHooks(event, data) {
    if (!this.hooks[event]) return data;
    let result = data;
    for (const hook of this.hooks[event]) {
      result = await hook(result);
    }
    return result;
  }
  /**
   * Setup automatic partition hooks
   */
  setupPartitionHooks() {
    if (!this.config.partitions) {
      return;
    }
    const partitions = this.config.partitions;
    if (Object.keys(partitions).length === 0) {
      return;
    }
    if (!this.hooks.afterInsert) {
      this.hooks.afterInsert = [];
    }
    this.hooks.afterInsert.push(async (data) => {
      await this.createPartitionReferences(data);
      return data;
    });
    if (!this.hooks.afterDelete) {
      this.hooks.afterDelete = [];
    }
    this.hooks.afterDelete.push(async (data) => {
      await this.deletePartitionReferences(data);
      return data;
    });
  }
  /**
   * Validate data against resource schema without saving
   * @param {Object} data - Data to validate
   * @param {Object} options - Validation options
   * @param {boolean} options.throwOnError - Throw error if validation fails (default: false)
   * @param {boolean} options.includeId - Include ID validation (default: false)
   * @param {boolean} options.mutateOriginal - Allow mutation of original data (default: false)
   * @returns {Promise<{valid: boolean, isValid: boolean, errors: Array, data: Object, original: Object}>} Validation result
   * @example
   * // Validate before insert
   * const result = await resource.validate({
   *   name: 'John Doe',
   *   email: 'invalid-email' // Will fail email validation
   * });
   *
   * if (!result.valid) {
   *   console.log('Validation errors:', result.errors);
   *   // [{ field: 'email', message: '...', ... }]
   * }
   *
   * // Throw on error
   * try {
   *   await resource.validate({ email: 'bad' }, { throwOnError: true });
   * } catch (err) {
   *   console.log('Validation failed:', err.message);
   * }
   */
  async validate(data, options = {}) {
    const {
      throwOnError = false,
      includeId = false,
      mutateOriginal = false
    } = options;
    const dataToValidate = mutateOriginal ? data : cloneDeep(data);
    if (!includeId && dataToValidate.id) {
      delete dataToValidate.id;
    }
    const result = {
      original: cloneDeep(data),
      isValid: false,
      errors: [],
      data: dataToValidate
    };
    try {
      const check = await this.schema.validate(dataToValidate, { mutateOriginal });
      if (check === true) {
        result.isValid = true;
      } else {
        result.errors = Array.isArray(check) ? check : [check];
        result.isValid = false;
        if (throwOnError) {
          const error = new Error("Validation failed");
          error.validationErrors = result.errors;
          error.invalidData = data;
          throw error;
        }
      }
    } catch (err) {
      if (!throwOnError) {
        result.errors = [{ message: err.message, error: err }];
        result.isValid = false;
      } else {
        throw err;
      }
    }
    return result;
  }
  /**
   * Validate that all partition fields exist in current resource attributes
   * @throws {Error} If partition fields don't exist in current schema (only when strictValidation is true)
   */
  validatePartitions() {
    if (!this.strictValidation) {
      return;
    }
    if (!this.config.partitions) {
      return;
    }
    const partitions = this.config.partitions;
    if (Object.keys(partitions).length === 0) {
      return;
    }
    const currentAttributes = Object.keys(this.attributes || {});
    for (const [partitionName, partitionDef] of Object.entries(partitions)) {
      if (!partitionDef.fields) {
        continue;
      }
      for (const fieldName of Object.keys(partitionDef.fields)) {
        if (!this.fieldExistsInAttributes(fieldName)) {
          throw new PartitionError(`Partition '${partitionName}' uses field '${fieldName}' which does not exist in resource attributes. Available fields: ${currentAttributes.join(", ")}.`, { resourceName: this.name, partitionName, fieldName, availableFields: currentAttributes, operation: "validatePartitions" });
        }
      }
    }
  }
  /**
   * Check if a field (including nested fields) exists in the current attributes
   * @param {string} fieldName - Field name (can be nested like 'utm.source')
   * @returns {boolean} True if field exists
   */
  fieldExistsInAttributes(fieldName) {
    if (fieldName.startsWith("_")) {
      return true;
    }
    if (!fieldName.includes(".")) {
      return Object.keys(this.attributes || {}).includes(fieldName);
    }
    const keys = fieldName.split(".");
    let currentLevel = this.attributes || {};
    for (const key of keys) {
      if (!currentLevel || typeof currentLevel !== "object" || !(key in currentLevel)) {
        return false;
      }
      currentLevel = currentLevel[key];
    }
    return true;
  }
  /**
   * Find orphaned partitions (partitions that reference non-existent fields)
   * @returns {Object} Object with orphaned partition names as keys and details as values
   * @example
   * const orphaned = resource.findOrphanedPartitions();
   * // Returns: { byRegion: { missingFields: ['region'], definition: {...} } }
   */
  findOrphanedPartitions() {
    const orphaned = {};
    if (!this.config.partitions) {
      return orphaned;
    }
    for (const [partitionName, partitionDef] of Object.entries(this.config.partitions)) {
      if (!partitionDef.fields) {
        continue;
      }
      const missingFields = [];
      for (const fieldName of Object.keys(partitionDef.fields)) {
        if (!this.fieldExistsInAttributes(fieldName)) {
          missingFields.push(fieldName);
        }
      }
      if (missingFields.length > 0) {
        orphaned[partitionName] = {
          missingFields,
          definition: partitionDef,
          allFields: Object.keys(partitionDef.fields)
        };
      }
    }
    return orphaned;
  }
  /**
   * Remove orphaned partitions (partitions that reference non-existent fields)
   * WARNING: This will modify the resource configuration and should be followed by uploadMetadataFile()
   * @param {Object} options - Options
   * @param {boolean} options.dryRun - If true, only returns what would be removed without modifying (default: false)
   * @returns {Object} Object with removed partition names and details
   * @example
   * // Dry run to see what would be removed
   * const toRemove = resource.removeOrphanedPartitions({ dryRun: true });
   * console.log('Would remove:', toRemove);
   *
   * // Actually remove orphaned partitions
   * const removed = resource.removeOrphanedPartitions();
   * await database.uploadMetadataFile(); // Save changes to S3
   */
  removeOrphanedPartitions({ dryRun = false } = {}) {
    const orphaned = this.findOrphanedPartitions();
    if (Object.keys(orphaned).length === 0) {
      return {};
    }
    if (dryRun) {
      return orphaned;
    }
    for (const partitionName of Object.keys(orphaned)) {
      delete this.config.partitions[partitionName];
    }
    this.emit("orphanedPartitionsRemoved", {
      resourceName: this.name,
      removed: Object.keys(orphaned),
      details: orphaned
    });
    return orphaned;
  }
  /**
   * Apply a single partition rule to a field value
   * @param {*} value - The field value
   * @param {string} rule - The partition rule
   * @returns {*} Transformed value
   */
  applyPartitionRule(value, rule) {
    if (value === void 0 || value === null) {
      return value;
    }
    let transformedValue = value;
    if (typeof rule === "string" && rule.includes("maxlength:")) {
      const maxLengthMatch = rule.match(/maxlength:(\d+)/);
      if (maxLengthMatch) {
        const maxLength = parseInt(maxLengthMatch[1]);
        if (typeof transformedValue === "string" && transformedValue.length > maxLength) {
          transformedValue = transformedValue.substring(0, maxLength);
        }
      }
    }
    if (rule.includes("date")) {
      if (transformedValue instanceof Date) {
        transformedValue = transformedValue.toISOString().split("T")[0];
      } else if (typeof transformedValue === "string") {
        if (transformedValue.includes("T") && transformedValue.includes("Z")) {
          transformedValue = transformedValue.split("T")[0];
        } else {
          const date = new Date(transformedValue);
          if (!isNaN(date.getTime())) {
            transformedValue = date.toISOString().split("T")[0];
          }
        }
      }
    }
    return transformedValue;
  }
  /**
   * Get the main resource key (new format without version in path)
   * @param {string} id - Resource ID
   * @returns {string} The main S3 key path
   */
  getResourceKey(id) {
    const key = join("resource=" + this.name, "data", `id=${id}`);
    return key;
  }
  /**
   * Generate partition key for a resource in a specific partition
   * @param {Object} params - Partition key parameters
   * @param {string} params.partitionName - Name of the partition
   * @param {string} params.id - Resource ID
   * @param {Object} params.data - Resource data for partition value extraction
   * @returns {string|null} The partition key path or null if required fields are missing
   * @example
   * const partitionKey = resource.getPartitionKey({
   *   partitionName: 'byUtmSource',
   *   id: 'user-123',
   *   data: { utm: { source: 'google' } }
   * });
   * // Returns: 'resource=users/partition=byUtmSource/utm.source=google/id=user-123'
   * 
   * // Returns null if required field is missing
   * const nullKey = resource.getPartitionKey({
   *   partitionName: 'byUtmSource',
   *   id: 'user-123',
   *   data: { name: 'John' } // Missing utm.source
   * });
   * // Returns: null
   */
  getPartitionKey({ partitionName, id, data }) {
    if (!this.config.partitions || !this.config.partitions[partitionName]) {
      throw new PartitionError(`Partition '${partitionName}' not found`, { resourceName: this.name, partitionName, operation: "getPartitionKey" });
    }
    const partition = this.config.partitions[partitionName];
    const partitionSegments = [];
    const sortedFields = Object.entries(partition.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const fieldValue = this.getNestedFieldValue(data, fieldName);
      const transformedValue = this.applyPartitionRule(fieldValue, rule);
      if (transformedValue === void 0 || transformedValue === null) {
        return null;
      }
      partitionSegments.push(`${fieldName}=${transformedValue}`);
    }
    if (partitionSegments.length === 0) {
      return null;
    }
    const finalId = id || data?.id;
    if (!finalId) {
      return null;
    }
    return join(`resource=${this.name}`, `partition=${partitionName}`, ...partitionSegments, `id=${finalId}`);
  }
  /**
   * Get nested field value from data object using dot notation
   * @param {Object} data - Data object
   * @param {string} fieldPath - Field path (e.g., "utm.source", "address.city")
   * @returns {*} Field value
   */
  getNestedFieldValue(data, fieldPath) {
    if (!fieldPath.includes(".")) {
      return data[fieldPath];
    }
    const keys = fieldPath.split(".");
    let currentLevel = data;
    for (const key of keys) {
      if (!currentLevel || typeof currentLevel !== "object" || !(key in currentLevel)) {
        return void 0;
      }
      currentLevel = currentLevel[key];
    }
    return currentLevel;
  }
  /**
   * Calculate estimated content length for body data
   * @param {string|Buffer} body - Body content
   * @returns {number} Estimated content length in bytes
   */
  calculateContentLength(body) {
    if (!body) return 0;
    if (Buffer.isBuffer(body)) return body.length;
    if (typeof body === "string") return Buffer.byteLength(body, "utf8");
    if (typeof body === "object") return Buffer.byteLength(JSON.stringify(body), "utf8");
    return Buffer.byteLength(String(body), "utf8");
  }
  /**
   * Emit standardized events with optional ID-specific variant
   *
   * @private
   * @param {string} event - Event name
   * @param {Object} payload - Event payload
   * @param {string} [id] - Optional ID for ID-specific events
   */
  _emitStandardized(event, payload, id = null) {
    this.emit(event, payload);
    if (id) {
      this.emit(`${event}:${id}`, payload);
    }
  }
  /**
   * Insert a new resource object
   * @param {Object} attributes - Resource attributes
   * @param {string} [attributes.id] - Custom ID (optional, auto-generated if not provided)
   * @returns {Promise<Object>} The created resource object with all attributes
   * @example
   * // Insert with auto-generated ID
   * const user = await resource.insert({
   *   name: 'John Doe',
   *   email: 'john@example.com',
   *   age: 30
   * });
      * 
   * // Insert with custom ID
   * const user = await resource.insert({
   *   id: 'user-123',
   *   name: 'John Doe',
   *   email: 'john@example.com'
   * });
   */
  async insert({ id: id$1, ...attributes }) {
    const exists = await this.exists(id$1);
    if (exists) throw new Error(`Resource with id '${id$1}' already exists`);
    this.getResourceKey(id$1 || "(auto)");
    if (this.config.timestamps) {
      attributes.createdAt = (/* @__PURE__ */ new Date()).toISOString();
      attributes.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const attributesWithDefaults = this.applyDefaults(attributes);
    const completeData = id$1 !== void 0 ? { id: id$1, ...attributesWithDefaults } : { ...attributesWithDefaults };
    const preProcessedData = await this.executeHooks("beforeInsert", completeData);
    const extraProps = Object.keys(preProcessedData).filter(
      (k) => !(k in completeData) || preProcessedData[k] !== completeData[k]
    );
    const extraData = {};
    for (const k of extraProps) extraData[k] = preProcessedData[k];
    const {
      errors,
      isValid,
      data: validated
    } = await this.validate(preProcessedData, { includeId: true });
    if (!isValid) {
      const errorMsg = errors && errors.length && errors[0].message ? errors[0].message : "Insert failed";
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: preProcessedData,
        validation: errors,
        message: errorMsg
      });
    }
    const { id: validatedId, ...validatedAttributes } = validated;
    Object.assign(validatedAttributes, extraData);
    let finalId = validatedId || id$1;
    if (!finalId) {
      finalId = this.idGenerator();
      if (!finalId || finalId.trim() === "") {
        const { idGenerator } = await Promise.resolve().then(function () { return id; });
        finalId = idGenerator();
      }
    }
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: validatedAttributes,
      mappedData,
      originalData: completeData
    });
    const finalMetadata = processedMetadata;
    const key = this.getResourceKey(finalId);
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    if (this.behavior === "body-only" && (!body || body === "")) {
      throw new Error(`[Resource.insert] Attempt to save object without body! Data: id=${finalId}, resource=${this.name}`);
    }
    const [okPut, errPut, putResult] = await tryFn(() => this.client.putObject({
      key,
      body,
      contentType,
      metadata: finalMetadata
    }));
    if (!okPut) {
      const msg = errPut && errPut.message ? errPut.message : "";
      if (msg.includes("metadata headers exceed") || msg.includes("Insert failed")) {
        const totalSize = calculateTotalSize(finalMetadata);
        const effectiveLimit = calculateEffectiveLimit({
          s3Limit: 2047,
          systemConfig: {
            version: this.version,
            timestamps: this.config.timestamps,
            id: finalId
          }
        });
        const excess = totalSize - effectiveLimit;
        errPut.totalSize = totalSize;
        errPut.limit = 2047;
        errPut.effectiveLimit = effectiveLimit;
        errPut.excess = excess;
        throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "insert", id: finalId, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
      }
      throw errPut;
    }
    const insertedObject = await this.get(finalId);
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.createPartitionReferences(insertedObject);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.createPartitionReferences(insertedObject).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "insert",
              id: finalId,
              error: err,
              message: err.message
            });
          });
        });
      } else {
        const [ok, err] = await tryFn(() => this.createPartitionReferences(insertedObject));
        if (!ok) {
          this.emit("partitionIndexError", {
            operation: "insert",
            id: finalId,
            error: err,
            message: err.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterInsert.filter(
        (hook) => !hook.toString().includes("createPartitionReferences")
      );
      let finalResult = insertedObject;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("inserted", finalResult, finalResult?.id || insertedObject?.id);
      return finalResult;
    } else {
      const finalResult = await this.executeHooks("afterInsert", insertedObject);
      this._emitStandardized("inserted", finalResult, finalResult?.id || insertedObject?.id);
      return finalResult;
    }
  }
  /**
   * Retrieve a resource object by ID
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} The resource object with all attributes and metadata
   * @example
   * const user = await resource.get('user-123');
   */
  async get(id) {
    if (isObject$1(id)) throw new Error(`id cannot be an object`);
    if (isEmpty(id)) throw new Error("id cannot be empty");
    await this.executeHooks("beforeGet", { id });
    const key = this.getResourceKey(id);
    const [ok, err, request] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "get",
        id
      });
    }
    const objectVersionRaw = request.Metadata?._v || this.version;
    const objectVersion = typeof objectVersionRaw === "string" && objectVersionRaw.startsWith("v") ? objectVersionRaw.slice(1) : objectVersionRaw;
    const schema = await this.getSchemaForVersion(objectVersion);
    let metadata = await schema.unmapper(request.Metadata);
    const behaviorImpl = getBehavior(this.behavior);
    let body = "";
    if (request.ContentLength > 0) {
      const [okBody, errBody, fullObject] = await tryFn(() => this.client.getObject(key));
      if (okBody) {
        body = await streamToString(fullObject.Body);
      } else {
        body = "";
      }
    }
    const { metadata: processedMetadata } = await behaviorImpl.handleGet({
      resource: this,
      metadata,
      body
    });
    let data = await this.composeFullObjectFromWrite({
      id,
      metadata: processedMetadata,
      body,
      behavior: this.behavior
    });
    data._contentLength = request.ContentLength;
    data._lastModified = request.LastModified;
    data._hasContent = request.ContentLength > 0;
    data._mimeType = request.ContentType || null;
    data._etag = request.ETag;
    data._v = objectVersion;
    if (request.VersionId) data._versionId = request.VersionId;
    if (request.Expiration) data._expiresAt = request.Expiration;
    data._definitionHash = this.getDefinitionHash();
    if (objectVersion !== this.version) {
      data = await this.applyVersionMapping(data, objectVersion, this.version);
    }
    data = await this.executeHooks("afterGet", data);
    this._emitStandardized("fetched", data, data.id);
    const value = data;
    return value;
  }
  /**
   * Retrieve a resource object by ID, or return null if not found
   * @param {string} id - Resource ID
   * @returns {Promise<Object|null>} The resource object or null if not found
   * @example
   * const user = await resource.getOrNull('user-123');
   * if (user) {
   *   console.log('Found user:', user.name);
   * } else {
   *   console.log('User not found');
   * }
   */
  async getOrNull(id) {
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (!ok && err && (err.name === "NoSuchKey" || err.message?.includes("NoSuchKey"))) {
      return null;
    }
    if (!ok) {
      throw err;
    }
    return data;
  }
  /**
   * Retrieve a resource object by ID, or throw ResourceNotFoundError if not found
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} The resource object
   * @throws {ResourceError} If resource does not exist
   * @example
   * // Throws error if user doesn't exist (no need for null check)
   * const user = await resource.getOrThrow('user-123');
   * console.log('User name:', user.name); // Safe to access
   */
  async getOrThrow(id) {
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (!ok && err && (err.name === "NoSuchKey" || err.message?.includes("NoSuchKey"))) {
      throw new ResourceError(`Resource '${this.name}' with id '${id}' not found`, {
        resourceName: this.name,
        operation: "getOrThrow",
        id,
        code: "RESOURCE_NOT_FOUND"
      });
    }
    if (!ok) {
      throw err;
    }
    return data;
  }
  /**
   * Check if a resource exists by ID
   * @returns {Promise<boolean>} True if resource exists, false otherwise
   */
  async exists(id) {
    await this.executeHooks("beforeExists", { id });
    const key = this.getResourceKey(id);
    const [ok, err] = await tryFn(() => this.client.headObject(key));
    await this.executeHooks("afterExists", { id, exists: ok });
    return ok;
  }
  /**
   * Update an existing resource object
   * @param {string} id - Resource ID
   * @param {Object} attributes - Attributes to update (partial update supported)
   * @returns {Promise<Object>} The updated resource object with all attributes
   * @example
   * // Update specific fields
   * const updatedUser = await resource.update('user-123', {
   *   name: 'John Updated',
   *   age: 31
   * });
   * 
   * // Update with timestamps (if enabled)
   * const updatedUser = await resource.update('user-123', {
   *   email: 'newemail@example.com'
   * });
      */
  async update(id, attributes) {
    if (isEmpty(id)) {
      throw new Error("id cannot be empty");
    }
    const exists = await this.exists(id);
    if (!exists) {
      throw new Error(`Resource with id '${id}' does not exist`);
    }
    const originalData = await this.get(id);
    const attributesClone = cloneDeep(attributes);
    let mergedData = cloneDeep(originalData);
    for (const [key2, value] of Object.entries(attributesClone)) {
      if (key2.includes(".")) {
        let ref = mergedData;
        const parts = key2.split(".");
        for (let i = 0; i < parts.length - 1; i++) {
          if (typeof ref[parts[i]] !== "object" || ref[parts[i]] === null) {
            ref[parts[i]] = {};
          }
          ref = ref[parts[i]];
        }
        ref[parts[parts.length - 1]] = cloneDeep(value);
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      mergedData.updatedAt = now;
      if (!mergedData.metadata) mergedData.metadata = {};
      mergedData.metadata.updatedAt = now;
    }
    const preProcessedData = await this.executeHooks("beforeUpdate", cloneDeep(mergedData));
    const completeData = { ...originalData, ...preProcessedData, id };
    const { isValid, errors, data } = await this.validate(cloneDeep(completeData), { includeId: true });
    if (!isValid) {
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: preProcessedData,
        validation: errors,
        message: "validation: " + (errors && errors.length ? JSON.stringify(errors) : "unknown")
      });
    }
    await this.schema.mapper(data);
    const earlyBehaviorImpl = getBehavior(this.behavior);
    const tempMappedData = await this.schema.mapper({ ...originalData, ...preProcessedData });
    tempMappedData._v = String(this.version);
    await earlyBehaviorImpl.handleUpdate({
      resource: this,
      id,
      data: { ...originalData, ...preProcessedData },
      mappedData: tempMappedData,
      originalData: { ...attributesClone, id }
    });
    const { id: validatedId, ...validatedAttributes } = data;
    const oldData = { ...originalData, id };
    const newData = { ...validatedAttributes, id };
    await this.handlePartitionReferenceUpdates(oldData, newData);
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleUpdate({
      resource: this,
      id,
      data: validatedAttributes,
      mappedData,
      originalData: { ...attributesClone, id }
    });
    const finalMetadata = processedMetadata;
    const key = this.getResourceKey(id);
    let existingContentType = void 0;
    let finalBody = body;
    if (body === "" && this.behavior !== "body-overflow") {
      const [ok2, err2, existingObject] = await tryFn(() => this.client.getObject(key));
      if (ok2 && existingObject.ContentLength > 0) {
        const existingBodyBuffer = Buffer.from(await existingObject.Body.transformToByteArray());
        const existingBodyString = existingBodyBuffer.toString();
        const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(existingBodyString)));
        if (!okParse) {
          finalBody = existingBodyBuffer;
          existingContentType = existingObject.ContentType;
        }
      }
    }
    let finalContentType = existingContentType;
    if (finalBody && finalBody !== "" && !finalContentType) {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(finalBody)));
      if (okParse) finalContentType = "application/json";
    }
    if (this.versioningEnabled && originalData._v !== this.version) {
      await this.createHistoricalVersion(id, originalData);
    }
    const [ok, err] = await tryFn(() => this.client.putObject({
      key,
      body: finalBody,
      contentType: finalContentType,
      metadata: finalMetadata
    }));
    if (!ok && err && err.message && err.message.includes("metadata headers exceed")) {
      const totalSize = calculateTotalSize(finalMetadata);
      const effectiveLimit = calculateEffectiveLimit({
        s3Limit: 2047,
        systemConfig: {
          version: this.version,
          timestamps: this.config.timestamps,
          id
        }
      });
      const excess = totalSize - effectiveLimit;
      err.totalSize = totalSize;
      err.limit = 2047;
      err.effectiveLimit = effectiveLimit;
      err.excess = excess;
      this.emit("exceedsLimit", {
        operation: "update",
        totalSize,
        limit: 2047,
        effectiveLimit,
        excess,
        data: validatedAttributes
      });
      throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "update", id, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
    } else if (!ok) {
      throw mapAwsError(err, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "update",
        id
      });
    }
    const updatedData = await this.composeFullObjectFromWrite({
      id,
      metadata: finalMetadata,
      body: finalBody,
      behavior: this.behavior
    });
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(originalData, updatedData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(originalData, updatedData).catch((err2) => {
            this.emit("partitionIndexError", {
              operation: "update",
              id,
              error: err2,
              message: err2.message
            });
          });
        });
      } else {
        const [ok2, err2] = await tryFn(() => this.handlePartitionReferenceUpdates(originalData, updatedData));
        if (!ok2) {
          this.emit("partitionIndexError", {
            operation: "update",
            id,
            error: err2,
            message: err2.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterUpdate.filter(
        (hook) => !hook.toString().includes("handlePartitionReferenceUpdates")
      );
      let finalResult = updatedData;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return finalResult;
    } else {
      const finalResult = await this.executeHooks("afterUpdate", updatedData);
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return finalResult;
    }
  }
  /**
   * Patch resource (partial update optimized for metadata-only behaviors)
   *
   * This method provides an optimized update path for resources using metadata-only behaviors
   * (enforce-limits, truncate-data). It uses HeadObject + CopyObject for atomic updates without
   * body transfer, eliminating race conditions and reducing latency by ~50%.
   *
   * For behaviors that store data in body (body-overflow, body-only), it automatically falls
   * back to the standard update() method.
   *
   * @param {string} id - Resource ID
   * @param {Object} fields - Fields to update (partial data)
   * @param {Object} options - Update options
   * @param {string} options.partition - Partition name (if using partitions)
   * @param {Object} options.partitionValues - Partition values (if using partitions)
   * @returns {Promise<Object>} Updated resource data
   *
   * @example
   * // Fast atomic update (enforce-limits behavior)
   * await resource.patch('user-123', { status: 'active', loginCount: 42 });
   *
   * @example
   * // With partitions
   * await resource.patch('order-456', { status: 'shipped' }, {
   *   partition: 'byRegion',
   *   partitionValues: { region: 'US' }
   * });
   */
  async patch(id, fields, options = {}) {
    if (isEmpty(id)) {
      throw new Error("id cannot be empty");
    }
    if (!fields || typeof fields !== "object") {
      throw new Error("fields must be a non-empty object");
    }
    await this.executeHooks("beforePatch", { id, fields, options });
    const behavior = this.behavior;
    const hasNestedFields = Object.keys(fields).some((key) => key.includes("."));
    let result;
    if ((behavior === "enforce-limits" || behavior === "truncate-data") && !hasNestedFields) {
      result = await this._patchViaCopyObject(id, fields, options);
    } else {
      result = await this.update(id, fields, options);
    }
    const finalResult = await this.executeHooks("afterPatch", result);
    return finalResult;
  }
  /**
   * Internal helper: Optimized patch using HeadObject + CopyObject
   * Only works for metadata-only behaviors (enforce-limits, truncate-data)
   * Only for simple field updates (no nested fields with dot notation)
   * @private
   */
  async _patchViaCopyObject(id, fields, options = {}) {
    const { partition, partitionValues } = options;
    const key = this.getResourceKey(id);
    const headResponse = await this.client.headObject(key);
    const currentMetadata = headResponse.Metadata || {};
    let currentData = await this.schema.unmapper(currentMetadata);
    if (!currentData.id) {
      currentData.id = id;
    }
    const fieldsClone = cloneDeep(fields);
    let mergedData = cloneDeep(currentData);
    for (const [key2, value] of Object.entries(fieldsClone)) {
      if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      mergedData.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const validationResult = await this.schema.validate(mergedData);
    if (validationResult !== true) {
      throw new ValidationError("Validation failed during patch", validationResult);
    }
    const newMetadata = await this.schema.mapper(mergedData);
    newMetadata._v = String(this.version);
    await this.client.copyObject({
      from: key,
      to: key,
      metadataDirective: "REPLACE",
      metadata: newMetadata
    });
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      const oldData = { ...currentData, id };
      const newData = { ...mergedData, id };
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(oldData, newData).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "patch",
              id,
              error: err
            });
          });
        });
      } else {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      }
    }
    return mergedData;
  }
  /**
   * Replace resource (full object replacement without GET)
   *
   * This method performs a direct PUT operation without fetching the current object.
   * Use this when you already have the complete object and want to replace it entirely,
   * saving 1 S3 request (GET).
   *
   * ⚠️ Warning: You must provide ALL required fields. Missing fields will NOT be preserved
   * from the current object. This method does not merge with existing data.
   *
   * @param {string} id - Resource ID
   * @param {Object} fullData - Complete object data (all required fields)
   * @param {Object} options - Update options
   * @param {string} options.partition - Partition name (if using partitions)
   * @param {Object} options.partitionValues - Partition values (if using partitions)
   * @returns {Promise<Object>} Replaced resource data
   *
   * @example
   * // Replace entire object (must include ALL required fields)
   * await resource.replace('user-123', {
   *   name: 'John Doe',
   *   email: 'john@example.com',
   *   status: 'active',
   *   loginCount: 42
   * });
   *
   * @example
   * // With partitions
   * await resource.replace('order-456', fullOrderData, {
   *   partition: 'byRegion',
   *   partitionValues: { region: 'US' }
   * });
   */
  async replace(id, fullData, options = {}) {
    if (isEmpty(id)) {
      throw new Error("id cannot be empty");
    }
    if (!fullData || typeof fullData !== "object") {
      throw new Error("fullData must be a non-empty object");
    }
    await this.executeHooks("beforeReplace", { id, fullData, options });
    const { partition, partitionValues } = options;
    const dataClone = cloneDeep(fullData);
    const attributesWithDefaults = this.applyDefaults(dataClone);
    if (this.config.timestamps) {
      if (!attributesWithDefaults.createdAt) {
        attributesWithDefaults.createdAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      attributesWithDefaults.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    const completeData = { id, ...attributesWithDefaults };
    const {
      errors,
      isValid,
      data: validated
    } = await this.validate(completeData, { includeId: true });
    if (!isValid) {
      const errorMsg = errors && errors.length && errors[0].message ? errors[0].message : "Replace failed";
      throw new InvalidResourceItem({
        bucket: this.client.config.bucket,
        resourceName: this.name,
        attributes: completeData,
        validation: errors,
        message: errorMsg
      });
    }
    const { id: validatedId, ...validatedAttributes } = validated;
    const mappedMetadata = await this.schema.mapper(validatedAttributes);
    mappedMetadata._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: finalMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: validatedAttributes,
      mappedData: mappedMetadata,
      originalData: completeData
    });
    const key = this.getResourceKey(id);
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    if (this.behavior === "body-only" && (!body || body === "")) {
      throw new Error(`[Resource.replace] Attempt to save object without body! Data: id=${id}, resource=${this.name}`);
    }
    const [okPut, errPut] = await tryFn(() => this.client.putObject({
      key,
      body,
      contentType,
      metadata: finalMetadata
    }));
    if (!okPut) {
      const msg = errPut && errPut.message ? errPut.message : "";
      if (msg.includes("metadata headers exceed") || msg.includes("Replace failed")) {
        const totalSize = calculateTotalSize(finalMetadata);
        const effectiveLimit = calculateEffectiveLimit({
          s3Limit: 2047,
          systemConfig: {
            version: this.version,
            timestamps: this.config.timestamps,
            id
          }
        });
        const excess = totalSize - effectiveLimit;
        errPut.totalSize = totalSize;
        errPut.limit = 2047;
        errPut.effectiveLimit = effectiveLimit;
        errPut.excess = excess;
        throw new ResourceError("metadata headers exceed", { resourceName: this.name, operation: "replace", id, totalSize, effectiveLimit, excess, suggestion: "Reduce metadata size or number of fields." });
      }
      throw errPut;
    }
    const replacedObject = { id, ...validatedAttributes };
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates({}, replacedObject);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates({}, replacedObject).catch((err) => {
            this.emit("partitionIndexError", {
              operation: "replace",
              id,
              error: err
            });
          });
        });
      } else {
        await this.handlePartitionReferenceUpdates({}, replacedObject);
      }
    }
    const finalResult = await this.executeHooks("afterReplace", replacedObject);
    return finalResult;
  }
  /**
   * Update with conditional check (If-Match ETag)
   * @param {string} id - Resource ID
   * @param {Object} attributes - Attributes to update
   * @param {Object} options - Options including ifMatch (ETag)
   * @returns {Promise<Object>} { success: boolean, data?: Object, etag?: string, error?: string }
   * @example
   * const msg = await resource.get('msg-123');
   * const result = await resource.updateConditional('msg-123', { status: 'processing' }, { ifMatch: msg._etag });
   * if (!result.success) {
   *   console.log('Update failed - object was modified by another process');
   * }
   */
  async updateConditional(id, attributes, options = {}) {
    if (isEmpty(id)) {
      throw new Error("id cannot be empty");
    }
    const { ifMatch } = options;
    if (!ifMatch) {
      throw new Error("updateConditional requires ifMatch option with ETag value");
    }
    const exists = await this.exists(id);
    if (!exists) {
      return {
        success: false,
        error: `Resource with id '${id}' does not exist`
      };
    }
    const originalData = await this.get(id);
    const attributesClone = cloneDeep(attributes);
    let mergedData = cloneDeep(originalData);
    for (const [key2, value] of Object.entries(attributesClone)) {
      if (key2.includes(".")) {
        let ref = mergedData;
        const parts = key2.split(".");
        for (let i = 0; i < parts.length - 1; i++) {
          if (typeof ref[parts[i]] !== "object" || ref[parts[i]] === null) {
            ref[parts[i]] = {};
          }
          ref = ref[parts[i]];
        }
        ref[parts[parts.length - 1]] = cloneDeep(value);
      } else if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        mergedData[key2] = merge({}, mergedData[key2], value);
      } else {
        mergedData[key2] = cloneDeep(value);
      }
    }
    if (this.config.timestamps) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      mergedData.updatedAt = now;
      if (!mergedData.metadata) mergedData.metadata = {};
      mergedData.metadata.updatedAt = now;
    }
    const preProcessedData = await this.executeHooks("beforeUpdate", cloneDeep(mergedData));
    const completeData = { ...originalData, ...preProcessedData, id };
    const { isValid, errors, data } = await this.validate(cloneDeep(completeData), { includeId: true });
    if (!isValid) {
      return {
        success: false,
        error: "Validation failed: " + (errors && errors.length ? JSON.stringify(errors) : "unknown"),
        validationErrors: errors
      };
    }
    const { id: validatedId, ...validatedAttributes } = data;
    const mappedData = await this.schema.mapper(validatedAttributes);
    mappedData._v = String(this.version);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleUpdate({
      resource: this,
      id,
      data: validatedAttributes,
      mappedData,
      originalData: { ...attributesClone, id }
    });
    const key = this.getResourceKey(id);
    let existingContentType = void 0;
    let finalBody = body;
    if (body === "" && this.behavior !== "body-overflow") {
      const [ok2, err2, existingObject] = await tryFn(() => this.client.getObject(key));
      if (ok2 && existingObject.ContentLength > 0) {
        const existingBodyBuffer = Buffer.from(await existingObject.Body.transformToByteArray());
        const existingBodyString = existingBodyBuffer.toString();
        const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(existingBodyString)));
        if (!okParse) {
          finalBody = existingBodyBuffer;
          existingContentType = existingObject.ContentType;
        }
      }
    }
    let finalContentType = existingContentType;
    if (finalBody && finalBody !== "" && !finalContentType) {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(finalBody)));
      if (okParse) finalContentType = "application/json";
    }
    const [ok, err, response] = await tryFn(() => this.client.putObject({
      key,
      body: finalBody,
      contentType: finalContentType,
      metadata: processedMetadata,
      ifMatch
      // ← Conditional write with ETag
    }));
    if (!ok) {
      if (err.name === "PreconditionFailed" || err.$metadata?.httpStatusCode === 412) {
        return {
          success: false,
          error: "ETag mismatch - object was modified by another process"
        };
      }
      return {
        success: false,
        error: err.message || "Update failed"
      };
    }
    const updatedData = await this.composeFullObjectFromWrite({
      id,
      metadata: processedMetadata,
      body: finalBody,
      behavior: this.behavior
    });
    const oldData = { ...originalData, id };
    const newData = { ...validatedAttributes, id };
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0) {
      if (this.config.strictPartitions) {
        await this.handlePartitionReferenceUpdates(oldData, newData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.handlePartitionReferenceUpdates(oldData, newData).catch((err2) => {
            this.emit("partitionIndexError", {
              operation: "updateConditional",
              id,
              error: err2,
              message: err2.message
            });
          });
        });
      } else {
        const [ok2, err2] = await tryFn(() => this.handlePartitionReferenceUpdates(oldData, newData));
        if (!ok2) {
          this.emit("partitionIndexError", {
            operation: "updateConditional",
            id,
            error: err2,
            message: err2.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterUpdate.filter(
        (hook) => !hook.toString().includes("handlePartitionReferenceUpdates")
      );
      let finalResult = updatedData;
      for (const hook of nonPartitionHooks) {
        finalResult = await hook(finalResult);
      }
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return {
        success: true,
        data: finalResult,
        etag: response.ETag
      };
    } else {
      await this.handlePartitionReferenceUpdates(oldData, newData);
      const finalResult = await this.executeHooks("afterUpdate", updatedData);
      this._emitStandardized("updated", {
        ...updatedData,
        $before: { ...originalData },
        $after: { ...finalResult }
      }, updatedData.id);
      return {
        success: true,
        data: finalResult,
        etag: response.ETag
      };
    }
  }
  /**
   * Delete a resource object by ID
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} S3 delete response
   * @example
   * await resource.delete('user-123');
   */
  async delete(id) {
    if (isEmpty(id)) {
      throw new Error("id cannot be empty");
    }
    let objectData;
    let deleteError = null;
    const [ok, err, data] = await tryFn(() => this.get(id));
    if (ok) {
      objectData = data;
    } else {
      objectData = { id };
      deleteError = err;
    }
    await this.executeHooks("beforeDelete", objectData);
    const key = this.getResourceKey(id);
    const [ok2, err2, response] = await tryFn(() => this.client.deleteObject(key));
    if (this.config.partitions && Object.keys(this.config.partitions).length > 0 && objectData) {
      if (this.config.strictPartitions) {
        await this.deletePartitionReferences(objectData);
      } else if (this.config.asyncPartitions) {
        setImmediate(() => {
          this.deletePartitionReferences(objectData).catch((err3) => {
            this.emit("partitionIndexError", {
              operation: "delete",
              id,
              error: err3,
              message: err3.message
            });
          });
        });
      } else {
        const [ok3, err3] = await tryFn(() => this.deletePartitionReferences(objectData));
        if (!ok3) {
          this.emit("partitionIndexError", {
            operation: "delete",
            id,
            error: err3,
            message: err3.message
          });
        }
      }
      const nonPartitionHooks = this.hooks.afterDelete.filter(
        (hook) => !hook.toString().includes("deletePartitionReferences")
      );
      let afterDeleteData = objectData;
      for (const hook of nonPartitionHooks) {
        afterDeleteData = await hook(afterDeleteData);
      }
    } else {
      await this.executeHooks("afterDelete", objectData);
    }
    this._emitStandardized("deleted", {
      ...objectData,
      $before: { ...objectData },
      $after: null
    }, id);
    if (deleteError) {
      throw mapAwsError(deleteError, {
        bucket: this.client.config.bucket,
        key,
        resourceName: this.name,
        operation: "delete",
        id
      });
    }
    if (!ok2) throw mapAwsError(err2, {
      key,
      resourceName: this.name,
      operation: "delete",
      id
    });
    return response;
  }
  /**
   * Insert or update a resource object (upsert operation)
   * @param {Object} params - Upsert parameters
   * @param {string} params.id - Resource ID (required for upsert)
   * @param {...Object} params - Resource attributes (any additional properties)
   * @returns {Promise<Object>} The inserted or updated resource object
   * @example
   * // Will insert if doesn't exist, update if exists
   * const user = await resource.upsert({
   *   id: 'user-123',
   *   name: 'John Doe',
   *   email: 'john@example.com'
   * });
   */
  async upsert({ id, ...attributes }) {
    const exists = await this.exists(id);
    if (exists) {
      return this.update(id, attributes);
    }
    return this.insert({ id, ...attributes });
  }
  /**
   * Count resources with optional partition filtering
   * @param {Object} [params] - Count parameters
   * @param {string} [params.partition] - Partition name to count in
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @returns {Promise<number>} Total count of matching resources
   * @example
   * // Count all resources
   * const total = await resource.count();
   * 
   * // Count in specific partition
   * const googleUsers = await resource.count({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
   * 
   * // Count in multi-field partition
   * const usElectronics = await resource.count({
   *   partition: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async count({ partition = null, partitionValues = {} } = {}) {
    await this.executeHooks("beforeCount", { partition, partitionValues });
    let prefix;
    if (partition && Object.keys(partitionValues).length > 0) {
      const partitionDef = this.config.partitions[partition];
      if (!partitionDef) {
        throw new PartitionError(`Partition '${partition}' not found`, { resourceName: this.name, partitionName: partition, operation: "count" });
      }
      const partitionSegments = [];
      const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
      for (const [fieldName, rule] of sortedFields) {
        const value = partitionValues[fieldName];
        if (value !== void 0 && value !== null) {
          const transformedValue = this.applyPartitionRule(value, rule);
          partitionSegments.push(`${fieldName}=${transformedValue}`);
        }
      }
      if (partitionSegments.length > 0) {
        prefix = `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
      } else {
        prefix = `resource=${this.name}/partition=${partition}`;
      }
    } else {
      prefix = `resource=${this.name}/data`;
    }
    const count = await this.client.count({ prefix });
    await this.executeHooks("afterCount", { count, partition, partitionValues });
    this._emitStandardized("count", count);
    return count;
  }
  /**
   * Insert multiple resources in parallel
   * @param {Object[]} objects - Array of resource objects to insert
   * @returns {Promise<Object[]>} Array of inserted resource objects
   * @example
   * const users = [
   *   { name: 'John', email: 'john@example.com' },
   *   { name: 'Jane', email: 'jane@example.com' },
   *   { name: 'Bob', email: 'bob@example.com' }
   * ];
   * const insertedUsers = await resource.insertMany(users);
      */
  async insertMany(objects) {
    const { results } = await PromisePool.for(objects).withConcurrency(this.parallelism).handleError(async (error, content2) => {
      this.emit("error", error, content2);
      this.observers.map((x) => x.emit("error", this.name, error, content2));
    }).process(async (attributes) => {
      const result = await this.insert(attributes);
      return result;
    });
    this._emitStandardized("inserted-many", objects.length);
    return results;
  }
  /**
   * Delete multiple resources by their IDs in parallel
   * @param {string[]} ids - Array of resource IDs to delete
   * @returns {Promise<Object[]>} Array of S3 delete responses
   * @example
   * const deletedIds = ['user-1', 'user-2', 'user-3'];
   * const results = await resource.deleteMany(deletedIds);
      */
  async deleteMany(ids) {
    await this.executeHooks("beforeDeleteMany", { ids });
    const packages = chunk(
      ids.map((id) => this.getResourceKey(id)),
      1e3
    );
    ids.map((id) => this.getResourceKey(id));
    const { results } = await PromisePool.for(packages).withConcurrency(this.parallelism).handleError(async (error, content2) => {
      this.emit("error", error, content2);
      this.observers.map((x) => x.emit("error", this.name, error, content2));
    }).process(async (keys) => {
      const response = await this.client.deleteObjects(keys);
      keys.forEach((key) => {
        const parts = key.split("/");
        const idPart = parts.find((part) => part.startsWith("id="));
        const id = idPart ? idPart.replace("id=", "") : null;
        if (id) {
          this.emit("deleted", id);
          this.observers.map((x) => x.emit("deleted", this.name, id));
        }
      });
      return response;
    });
    await this.executeHooks("afterDeleteMany", { ids, results });
    this._emitStandardized("deleted-many", ids.length);
    return results;
  }
  async deleteAll() {
    if (this.config.paranoid !== false) {
      throw new ResourceError("deleteAll() is a dangerous operation and requires paranoid: false option.", { resourceName: this.name, operation: "deleteAll", paranoid: this.config.paranoid, suggestion: "Set paranoid: false to allow deleteAll." });
    }
    const prefix = `resource=${this.name}/data`;
    const deletedCount = await this.client.deleteAll({ prefix });
    this._emitStandardized("deleted-all", {
      version: this.version,
      prefix,
      deletedCount
    });
    return { deletedCount, version: this.version };
  }
  /**
   * Delete all data for this resource across ALL versions
   * @returns {Promise<Object>} Deletion report
   */
  async deleteAllData() {
    if (this.config.paranoid !== false) {
      throw new ResourceError("deleteAllData() is a dangerous operation and requires paranoid: false option.", { resourceName: this.name, operation: "deleteAllData", paranoid: this.config.paranoid, suggestion: "Set paranoid: false to allow deleteAllData." });
    }
    const prefix = `resource=${this.name}`;
    const deletedCount = await this.client.deleteAll({ prefix });
    this._emitStandardized("deleted-all-data", {
      resource: this.name,
      prefix,
      deletedCount
    });
    return { deletedCount, resource: this.name };
  }
  /**
   * List resource IDs with optional partition filtering and pagination
   * @param {Object} [params] - List parameters
   * @param {string} [params.partition] - Partition name to list from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {number} [params.limit] - Maximum number of results to return
   * @param {number} [params.offset=0] - Offset for pagination
   * @returns {Promise<string[]>} Array of resource IDs (strings)
   * @example
   * // List all IDs
   * const allIds = await resource.listIds();
   * 
   * // List IDs with pagination
   * const firstPageIds = await resource.listIds({ limit: 10, offset: 0 });
   * const secondPageIds = await resource.listIds({ limit: 10, offset: 10 });
   * 
   * // List IDs from specific partition
   * const googleUserIds = await resource.listIds({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
   * 
   * // List IDs from multi-field partition
   * const usElectronicsIds = await resource.listIds({
   *   partition: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async listIds({ partition = null, partitionValues = {}, limit, offset = 0 } = {}) {
    let prefix;
    if (partition && Object.keys(partitionValues).length > 0) {
      if (!this.config.partitions || !this.config.partitions[partition]) {
        throw new PartitionError(`Partition '${partition}' not found`, { resourceName: this.name, partitionName: partition, operation: "listIds" });
      }
      const partitionDef = this.config.partitions[partition];
      const partitionSegments = [];
      const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
      for (const [fieldName, rule] of sortedFields) {
        const value = partitionValues[fieldName];
        if (value !== void 0 && value !== null) {
          const transformedValue = this.applyPartitionRule(value, rule);
          partitionSegments.push(`${fieldName}=${transformedValue}`);
        }
      }
      if (partitionSegments.length > 0) {
        prefix = `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
      } else {
        prefix = `resource=${this.name}/partition=${partition}`;
      }
    } else {
      prefix = `resource=${this.name}/data`;
    }
    const keys = await this.client.getKeysPage({
      prefix,
      offset,
      amount: limit || 1e3
      // Default to 1000 if no limit specified
    });
    const ids = keys.map((key) => {
      const parts = key.split("/");
      const idPart = parts.find((part) => part.startsWith("id="));
      return idPart ? idPart.replace("id=", "") : null;
    }).filter(Boolean);
    this._emitStandardized("listed-ids", ids.length);
    return ids;
  }
  /**
   * List resources with optional partition filtering and pagination
   * @param {Object} [params] - List parameters
   * @param {string} [params.partition] - Partition name to list from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {number} [params.limit] - Maximum number of results
   * @param {number} [params.offset=0] - Number of results to skip
   * @returns {Promise<Object[]>} Array of resource objects
   * @example
   * // List all resources
   * const allUsers = await resource.list();
   * 
   * // List with pagination
   * const first10 = await resource.list({ limit: 10, offset: 0 });
   * 
   * // List from specific partition
   * const usUsers = await resource.list({
   *   partition: 'byCountry',
   *   partitionValues: { 'profile.country': 'US' }
   * });
   */
  async list({ partition = null, partitionValues = {}, limit, offset = 0 } = {}) {
    await this.executeHooks("beforeList", { partition, partitionValues, limit, offset });
    const [ok, err, result] = await tryFn(async () => {
      if (!partition) {
        return await this.listMain({ limit, offset });
      }
      return await this.listPartition({ partition, partitionValues, limit, offset });
    });
    if (!ok) {
      return this.handleListError(err, { partition, partitionValues });
    }
    const finalResult = await this.executeHooks("afterList", result);
    return finalResult;
  }
  async listMain({ limit, offset = 0 }) {
    const [ok, err, ids] = await tryFn(() => this.listIds({ limit, offset }));
    if (!ok) throw err;
    const results = await this.processListResults(ids, "main");
    this._emitStandardized("list", { count: results.length, errors: 0 });
    return results;
  }
  async listPartition({ partition, partitionValues, limit, offset = 0 }) {
    if (!this.config.partitions?.[partition]) {
      this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 0 });
      return [];
    }
    const partitionDef = this.config.partitions[partition];
    const prefix = this.buildPartitionPrefix(partition, partitionDef, partitionValues);
    const [ok, err, keys] = await tryFn(() => this.client.getAllKeys({ prefix }));
    if (!ok) throw err;
    const ids = this.extractIdsFromKeys(keys).slice(offset);
    const filteredIds = limit ? ids.slice(0, limit) : ids;
    const results = await this.processPartitionResults(filteredIds, partition, partitionDef, keys);
    this._emitStandardized("list", { partition, partitionValues, count: results.length, errors: 0 });
    return results;
  }
  /**
   * Build partition prefix from partition definition and values
   */
  buildPartitionPrefix(partition, partitionDef, partitionValues) {
    const partitionSegments = [];
    const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const value = partitionValues[fieldName];
      if (value !== void 0 && value !== null) {
        const transformedValue = this.applyPartitionRule(value, rule);
        partitionSegments.push(`${fieldName}=${transformedValue}`);
      }
    }
    if (partitionSegments.length > 0) {
      return `resource=${this.name}/partition=${partition}/${partitionSegments.join("/")}`;
    }
    return `resource=${this.name}/partition=${partition}`;
  }
  /**
   * Extract IDs from S3 keys
   */
  extractIdsFromKeys(keys) {
    return keys.map((key) => {
      const parts = key.split("/");
      const idPart = parts.find((part) => part.startsWith("id="));
      return idPart ? idPart.replace("id=", "") : null;
    }).filter(Boolean);
  }
  /**
   * Process list results with error handling
   */
  async processListResults(ids, context = "main") {
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
    }).process(async (id) => {
      const [ok, err, result] = await tryFn(() => this.get(id));
      if (ok) {
        return result;
      }
      return this.handleResourceError(err, id, context);
    });
    this._emitStandardized("list", { count: results.length, errors: 0 });
    return results;
  }
  /**
   * Process partition results with error handling
   */
  async processPartitionResults(ids, partition, partitionDef, keys) {
    const sortedFields = Object.entries(partitionDef.fields).sort(([a], [b]) => a.localeCompare(b));
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
    }).process(async (id) => {
      const [ok, err, result] = await tryFn(async () => {
        const actualPartitionValues = this.extractPartitionValuesFromKey(id, keys, sortedFields);
        return await this.getFromPartition({
          id,
          partitionName: partition,
          partitionValues: actualPartitionValues
        });
      });
      if (ok) return result;
      return this.handleResourceError(err, id, "partition");
    });
    return results.filter((item) => item !== null);
  }
  /**
   * Extract partition values from S3 key for specific ID
   */
  extractPartitionValuesFromKey(id, keys, sortedFields) {
    const keyForId = keys.find((key) => key.includes(`id=${id}`));
    if (!keyForId) {
      throw new PartitionError(`Partition key not found for ID ${id}`, { resourceName: this.name, id, operation: "extractPartitionValuesFromKey" });
    }
    const keyParts = keyForId.split("/");
    const actualPartitionValues = {};
    for (const [fieldName] of sortedFields) {
      const fieldPart = keyParts.find((part) => part.startsWith(`${fieldName}=`));
      if (fieldPart) {
        const value = fieldPart.replace(`${fieldName}=`, "");
        actualPartitionValues[fieldName] = value;
      }
    }
    return actualPartitionValues;
  }
  /**
   * Handle resource-specific errors
   */
  handleResourceError(error, id, context) {
    if (error.message.includes("Cipher job failed") || error.message.includes("OperationError")) {
      return {
        id,
        _decryptionFailed: true,
        _error: error.message,
        ...context === "partition" && { _partition: context }
      };
    }
    throw error;
  }
  /**
   * Handle list method errors
   */
  handleListError(error, { partition, partitionValues }) {
    if (error.message.includes("Partition '") && error.message.includes("' not found")) {
      this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 1 });
      return [];
    }
    this._emitStandardized("list", { partition, partitionValues, count: 0, errors: 1 });
    return [];
  }
  /**
   * Get multiple resources by their IDs
   * @param {string[]} ids - Array of resource IDs
   * @returns {Promise<Object[]>} Array of resource objects
   * @example
   * const users = await resource.getMany(['user-1', 'user-2', 'user-3']);
      */
  async getMany(ids) {
    await this.executeHooks("beforeGetMany", { ids });
    const { results, errors } = await PromisePool.for(ids).withConcurrency(this.client.parallelism).handleError(async (error, id) => {
      this.emit("error", error, content);
      this.observers.map((x) => x.emit("error", this.name, error, content));
      return {
        id,
        _error: error.message,
        _decryptionFailed: error.message.includes("Cipher job failed") || error.message.includes("OperationError")
      };
    }).process(async (id) => {
      const [ok, err, data] = await tryFn(() => this.get(id));
      if (ok) return data;
      if (err.message.includes("Cipher job failed") || err.message.includes("OperationError")) {
        return {
          id,
          _decryptionFailed: true,
          _error: err.message
        };
      }
      throw err;
    });
    const finalResults = await this.executeHooks("afterGetMany", results);
    this._emitStandardized("fetched-many", ids.length);
    return finalResults;
  }
  /**
   * Get all resources (equivalent to list() without pagination)
   * @returns {Promise<Object[]>} Array of all resource objects
   * @example
   * const allUsers = await resource.getAll();
      */
  async getAll() {
    const [ok, err, ids] = await tryFn(() => this.listIds());
    if (!ok) throw err;
    const results = [];
    for (const id of ids) {
      const [ok2, err2, item] = await tryFn(() => this.get(id));
      if (ok2) {
        results.push(item);
      }
    }
    return results;
  }
  /**
   * Get a page of resources with pagination metadata
   * @param {Object} [params] - Page parameters
   * @param {number} [params.offset=0] - Offset for pagination
   * @param {number} [params.size=100] - Page size
   * @param {string} [params.partition] - Partition name to page from
   * @param {Object} [params.partitionValues] - Partition field values to filter by
   * @param {boolean} [params.skipCount=false] - Skip total count for performance (useful for large collections)
   * @returns {Promise<Object>} Page result with items and pagination info
   * @example
   * // Get first page of all resources
   * const page = await resource.page({ offset: 0, size: 10 });
         * 
   * // Get page from specific partition
   * const googlePage = await resource.page({
   *   partition: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' },
   *   offset: 0,
   *   size: 5
   * });
   * 
   * // Skip count for performance in large collections
   * const fastPage = await resource.page({ 
   *   offset: 0, 
   *   size: 100, 
   *   skipCount: true 
   * });
      */
  async page({ offset = 0, size = 100, partition = null, partitionValues = {}, skipCount = false } = {}) {
    const [ok, err, result] = await tryFn(async () => {
      let totalItems = null;
      let totalPages = null;
      if (!skipCount) {
        const [okCount, errCount, count] = await tryFn(() => this.count({ partition, partitionValues }));
        if (okCount) {
          totalItems = count;
          totalPages = Math.ceil(totalItems / size);
        } else {
          totalItems = null;
          totalPages = null;
        }
      }
      const page = Math.floor(offset / size);
      let items = [];
      if (size <= 0) {
        items = [];
      } else {
        const [okList, errList, listResult] = await tryFn(() => this.list({ partition, partitionValues, limit: size, offset }));
        items = okList ? listResult : [];
      }
      const result2 = {
        items,
        totalItems,
        page,
        pageSize: size,
        totalPages,
        hasMore: items.length === size && offset + size < (totalItems || Infinity),
        _debug: {
          requestedSize: size,
          requestedOffset: offset,
          actualItemsReturned: items.length,
          skipCount,
          hasTotalItems: totalItems !== null
        }
      };
      this._emitStandardized("paginated", result2);
      return result2;
    });
    if (ok) return result;
    return {
      items: [],
      totalItems: null,
      page: Math.floor(offset / size),
      pageSize: size,
      totalPages: null,
      _debug: {
        requestedSize: size,
        requestedOffset: offset,
        actualItemsReturned: 0,
        skipCount,
        hasTotalItems: false,
        error: err.message
      }
    };
  }
  readable() {
    const stream = new ResourceReader({ resource: this });
    return stream.build();
  }
  writable() {
    const stream = new ResourceWriter({ resource: this });
    return stream.build();
  }
  /**
   * Set binary content for a resource
   * @param {Object} params - Content parameters
   * @param {string} params.id - Resource ID
   * @param {Buffer|string} params.buffer - Content buffer or string
   * @param {string} [params.contentType='application/octet-stream'] - Content type
   * @returns {Promise<Object>} Updated resource data
   * @example
   * // Set image content
   * const imageBuffer = fs.readFileSync('image.jpg');
   * await resource.setContent({
   *   id: 'user-123',
   *   buffer: imageBuffer,
   *   contentType: 'image/jpeg'
   * });
   * 
   * // Set text content
   * await resource.setContent({
   *   id: 'document-456',
   *   buffer: 'Hello World',
   *   contentType: 'text/plain'
   * });
   */
  async setContent({ id, buffer, contentType = "application/octet-stream" }) {
    const [ok, err, currentData] = await tryFn(() => this.get(id));
    if (!ok || !currentData) {
      throw new ResourceError(`Resource with id '${id}' not found`, { resourceName: this.name, id, operation: "setContent" });
    }
    const updatedData = {
      ...currentData,
      _hasContent: true,
      _contentLength: buffer.length,
      _mimeType: contentType
    };
    const mappedMetadata = await this.schema.mapper(updatedData);
    const [ok2, err2] = await tryFn(() => this.client.putObject({
      key: this.getResourceKey(id),
      metadata: mappedMetadata,
      body: buffer,
      contentType
    }));
    if (!ok2) throw err2;
    this._emitStandardized("content-set", { id, contentType, contentLength: buffer.length }, id);
    return updatedData;
  }
  /**
   * Retrieve binary content associated with a resource
   * @param {string} id - Resource ID
   * @returns {Promise<Object>} Object with buffer and contentType
   * @example
   * const content = await resource.content('user-123');
   * if (content.buffer) {
         *   // Save to file
   *   fs.writeFileSync('output.jpg', content.buffer);
   * } else {
      * }
   */
  async content(id) {
    const key = this.getResourceKey(id);
    const [ok, err, response] = await tryFn(() => this.client.getObject(key));
    if (!ok) {
      if (err.name === "NoSuchKey") {
        return {
          buffer: null,
          contentType: null
        };
      }
      throw err;
    }
    const buffer = Buffer.from(await response.Body.transformToByteArray());
    const contentType = response.ContentType || null;
    this._emitStandardized("content-fetched", { id, contentLength: buffer.length, contentType }, id);
    return {
      buffer,
      contentType
    };
  }
  /**
   * Check if binary content exists for a resource
   * @param {string} id - Resource ID
   * @returns {boolean}
   */
  async hasContent(id) {
    const key = this.getResourceKey(id);
    const [ok, err, response] = await tryFn(() => this.client.headObject(key));
    if (!ok) return false;
    return response.ContentLength > 0;
  }
  /**
   * Delete binary content but preserve metadata
   * @param {string} id - Resource ID
   */
  async deleteContent(id) {
    const key = this.getResourceKey(id);
    const [ok, err, existingObject] = await tryFn(() => this.client.headObject(key));
    if (!ok) throw err;
    const existingMetadata = existingObject.Metadata || {};
    const [ok2, err2, response] = await tryFn(() => this.client.putObject({
      key,
      body: "",
      metadata: existingMetadata
    }));
    if (!ok2) throw err2;
    this._emitStandardized("content-deleted", id, id);
    return response;
  }
  /**
   * Generate definition hash for this resource
   * @returns {string} SHA256 hash of the resource definition (name + attributes)
   */
  getDefinitionHash() {
    const definition = {
      attributes: this.attributes,
      behavior: this.behavior
    };
    const stableString = jsonStableStringify(definition);
    return `sha256:${createHash("sha256").update(stableString).digest("hex")}`;
  }
  /**
   * Extract version from S3 key
   * @param {string} key - S3 object key
   * @returns {string|null} Version string or null
   */
  extractVersionFromKey(key) {
    const parts = key.split("/");
    const versionPart = parts.find((part) => part.startsWith("v="));
    return versionPart ? versionPart.replace("v=", "") : null;
  }
  /**
   * Get schema for a specific version
   * @param {string} version - Version string (e.g., 'v1', 'v2')
   * @returns {Object} Schema object for the version
   */
  async getSchemaForVersion(version) {
    return this.schema;
  }
  /**
   * Create partition references after insert
   * @param {Object} data - Inserted object data
   */
  async createPartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const promises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        const partitionMetadata = {
          _v: String(this.version)
        };
        return this.client.putObject({
          key: partitionKey,
          metadata: partitionMetadata,
          body: "",
          contentType: void 0
        });
      }
      return null;
    });
    const results = await Promise.allSettled(promises);
    const failures = results.filter((r) => r.status === "rejected");
    if (failures.length > 0) {
      this.emit("partitionIndexWarning", {
        operation: "create",
        id: data.id,
        failures: failures.map((f) => f.reason)
      });
    }
  }
  /**
   * Delete partition references after delete
   * @param {Object} data - Deleted object data
   */
  async deletePartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const keysToDelete = [];
    for (const [partitionName, partition] of Object.entries(partitions)) {
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        keysToDelete.push(partitionKey);
      }
    }
    if (keysToDelete.length > 0) {
      const [ok, err] = await tryFn(() => this.client.deleteObjects(keysToDelete));
    }
  }
  /**
   * Query resources with simple filtering and pagination
   * @param {Object} [filter={}] - Filter criteria (exact field matches)
   * @param {Object} [options] - Query options
   * @param {number} [options.limit=100] - Maximum number of results
   * @param {number} [options.offset=0] - Offset for pagination
   * @param {string} [options.partition] - Partition name to query from
   * @param {Object} [options.partitionValues] - Partition field values to filter by
   * @returns {Promise<Object[]>} Array of filtered resource objects
   * @example
   * // Query all resources (no filter)
   * const allUsers = await resource.query();
   * 
   * // Query with simple filter
   * const activeUsers = await resource.query({ status: 'active' });
   * 
   * // Query with multiple filters
   * const usElectronics = await resource.query({
   *   category: 'electronics',
   *   region: 'US'
   * });
   * 
   * // Query with pagination
   * const firstPage = await resource.query(
   *   { status: 'active' },
   *   { limit: 10, offset: 0 }
   * );
   * 
   * // Query within partition
   * const googleUsers = await resource.query(
   *   { status: 'active' },
   *   {
   *     partition: 'byUtmSource',
   *     partitionValues: { 'utm.source': 'google' },
   *     limit: 5
   *   }
   * );
   */
  async query(filter = {}, { limit = 100, offset = 0, partition = null, partitionValues = {} } = {}) {
    await this.executeHooks("beforeQuery", { filter, limit, offset, partition, partitionValues });
    if (Object.keys(filter).length === 0) {
      return await this.list({ partition, partitionValues, limit, offset });
    }
    const results = [];
    let currentOffset = offset;
    const batchSize = Math.min(limit, 50);
    while (results.length < limit) {
      const batch = await this.list({
        partition,
        partitionValues,
        limit: batchSize,
        offset: currentOffset
      });
      if (batch.length === 0) {
        break;
      }
      const filteredBatch = batch.filter((doc) => {
        return Object.entries(filter).every(([key, value]) => {
          return doc[key] === value;
        });
      });
      results.push(...filteredBatch);
      currentOffset += batchSize;
      if (batch.length < batchSize) {
        break;
      }
    }
    const finalResults = results.slice(0, limit);
    return await this.executeHooks("afterQuery", finalResults);
  }
  /**
   * Handle partition reference updates with change detection
   * @param {Object} oldData - Original object data before update
   * @param {Object} newData - Updated object data
   */
  async handlePartitionReferenceUpdates(oldData, newData) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    const updatePromises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const [ok, err] = await tryFn(() => this.handlePartitionReferenceUpdate(partitionName, partition, oldData, newData));
      if (!ok) {
        return { partitionName, error: err };
      }
      return { partitionName, success: true };
    });
    await Promise.allSettled(updatePromises);
    const id = newData.id || oldData.id;
    const cleanupPromises = Object.entries(partitions).map(async ([partitionName, partition]) => {
      const prefix = `resource=${this.name}/partition=${partitionName}`;
      const [okKeys, errKeys, keys] = await tryFn(() => this.client.getAllKeys({ prefix }));
      if (!okKeys) {
        return;
      }
      const validKey = this.getPartitionKey({ partitionName, id, data: newData });
      const staleKeys = keys.filter((key) => key.endsWith(`/id=${id}`) && key !== validKey);
      if (staleKeys.length > 0) {
        const [okDel, errDel] = await tryFn(() => this.client.deleteObjects(staleKeys));
      }
    });
    await Promise.allSettled(cleanupPromises);
  }
  /**
   * Handle partition reference update for a specific partition
   * @param {string} partitionName - Name of the partition
   * @param {Object} partition - Partition definition
   * @param {Object} oldData - Original object data before update
   * @param {Object} newData - Updated object data
   */
  async handlePartitionReferenceUpdate(partitionName, partition, oldData, newData) {
    const id = newData.id || oldData.id;
    const oldPartitionKey = this.getPartitionKey({ partitionName, id, data: oldData });
    const newPartitionKey = this.getPartitionKey({ partitionName, id, data: newData });
    if (oldPartitionKey !== newPartitionKey) {
      if (oldPartitionKey) {
        const [ok, err] = await tryFn(async () => {
          await this.client.deleteObject(oldPartitionKey);
        });
      }
      if (newPartitionKey) {
        const [ok, err] = await tryFn(async () => {
          const partitionMetadata = {
            _v: String(this.version)
          };
          await this.client.putObject({
            key: newPartitionKey,
            metadata: partitionMetadata,
            body: "",
            contentType: void 0
          });
        });
      }
    } else if (newPartitionKey) {
      const [ok, err] = await tryFn(async () => {
        const partitionMetadata = {
          _v: String(this.version)
        };
        await this.client.putObject({
          key: newPartitionKey,
          metadata: partitionMetadata,
          body: "",
          contentType: void 0
        });
      });
    }
  }
  /**
   * Update partition objects to keep them in sync
   * @param {Object} data - Updated object data
   */
  async updatePartitionReferences(data) {
    const partitions = this.config.partitions;
    if (!partitions || Object.keys(partitions).length === 0) {
      return;
    }
    for (const [partitionName, partition] of Object.entries(partitions)) {
      if (!partition || !partition.fields || typeof partition.fields !== "object") {
        continue;
      }
      const partitionKey = this.getPartitionKey({ partitionName, id: data.id, data });
      if (partitionKey) {
        const partitionMetadata = {
          _v: String(this.version)
        };
        const [ok, err] = await tryFn(async () => {
          await this.client.putObject({
            key: partitionKey,
            metadata: partitionMetadata,
            body: "",
            contentType: void 0
          });
        });
      }
    }
  }
  /**
   * Get a resource object directly from a specific partition
   * @param {Object} params - Partition parameters
   * @param {string} params.id - Resource ID
   * @param {string} params.partitionName - Name of the partition
   * @param {Object} params.partitionValues - Values for partition fields
   * @returns {Promise<Object>} The resource object with partition metadata
   * @example
   * // Get user from UTM source partition
   * const user = await resource.getFromPartition({
   *   id: 'user-123',
   *   partitionName: 'byUtmSource',
   *   partitionValues: { 'utm.source': 'google' }
   * });
         * 
   * // Get product from multi-field partition
   * const product = await resource.getFromPartition({
   *   id: 'product-456',
   *   partitionName: 'byCategoryRegion',
   *   partitionValues: { category: 'electronics', region: 'US' }
   * });
   */
  async getFromPartition({ id, partitionName, partitionValues = {} }) {
    if (!this.config.partitions || !this.config.partitions[partitionName]) {
      throw new PartitionError(`Partition '${partitionName}' not found`, { resourceName: this.name, partitionName, operation: "getFromPartition" });
    }
    const partition = this.config.partitions[partitionName];
    const partitionSegments = [];
    const sortedFields = Object.entries(partition.fields).sort(([a], [b]) => a.localeCompare(b));
    for (const [fieldName, rule] of sortedFields) {
      const value = partitionValues[fieldName];
      if (value !== void 0 && value !== null) {
        const transformedValue = this.applyPartitionRule(value, rule);
        partitionSegments.push(`${fieldName}=${transformedValue}`);
      }
    }
    if (partitionSegments.length === 0) {
      throw new PartitionError(`No partition values provided for partition '${partitionName}'`, { resourceName: this.name, partitionName, operation: "getFromPartition" });
    }
    const partitionKey = join(`resource=${this.name}`, `partition=${partitionName}`, ...partitionSegments, `id=${id}`);
    const [ok, err] = await tryFn(async () => {
      await this.client.headObject(partitionKey);
    });
    if (!ok) {
      throw new ResourceError(`Resource with id '${id}' not found in partition '${partitionName}'`, { resourceName: this.name, id, partitionName, operation: "getFromPartition" });
    }
    const data = await this.get(id);
    data._partition = partitionName;
    data._partitionValues = partitionValues;
    this._emitStandardized("partition-fetched", data, data.id);
    return data;
  }
  /**
   * Create a historical version of an object
   * @param {string} id - Resource ID
   * @param {Object} data - Object data to store historically
   */
  async createHistoricalVersion(id, data) {
    const historicalKey = join(`resource=${this.name}`, `historical`, `id=${id}`);
    const historicalData = {
      ...data,
      _v: data._v || this.version,
      _historicalTimestamp: (/* @__PURE__ */ new Date()).toISOString()
    };
    const mappedData = await this.schema.mapper(historicalData);
    const behaviorImpl = getBehavior(this.behavior);
    const { mappedData: processedMetadata, body } = await behaviorImpl.handleInsert({
      resource: this,
      data: historicalData,
      mappedData
    });
    const finalMetadata = {
      ...processedMetadata,
      _v: data._v || this.version,
      _historicalTimestamp: historicalData._historicalTimestamp
    };
    let contentType = void 0;
    if (body && body !== "") {
      const [okParse, errParse] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okParse) contentType = "application/json";
    }
    await this.client.putObject({
      key: historicalKey,
      metadata: finalMetadata,
      body,
      contentType
    });
  }
  /**
   * Apply version mapping to convert an object from one version to another
   * @param {Object} data - Object data to map
   * @param {string} fromVersion - Source version
   * @param {string} toVersion - Target version
   * @returns {Object} Mapped object data
   */
  async applyVersionMapping(data, fromVersion, toVersion) {
    if (fromVersion === toVersion) {
      return data;
    }
    const mappedData = {
      ...data,
      _v: toVersion,
      _originalVersion: fromVersion,
      _versionMapped: true
    };
    return mappedData;
  }
  /**
   * Compose the full object (metadata + body) as returned by .get(),
   * using in-memory data after insert/update, according to behavior
   */
  async composeFullObjectFromWrite({ id, metadata, body, behavior }) {
    const behaviorFlags = {};
    if (metadata && metadata["$truncated"] === "true") {
      behaviorFlags.$truncated = "true";
    }
    if (metadata && metadata["$overflow"] === "true") {
      behaviorFlags.$overflow = "true";
    }
    let unmappedMetadata = {};
    const [ok, err, unmapped] = await tryFn(() => this.schema.unmapper(metadata));
    unmappedMetadata = ok ? unmapped : metadata;
    const filterInternalFields = (obj) => {
      if (!obj || typeof obj !== "object") return obj;
      const filtered2 = {};
      const pluginAttrNames = this.schema._pluginAttributes ? Object.values(this.schema._pluginAttributes).flat() : [];
      for (const [key, value] of Object.entries(obj)) {
        if (!key.startsWith("_") || key === "_geohash" || key.startsWith("_geohash_zoom") || pluginAttrNames.includes(key)) {
          filtered2[key] = value;
        }
      }
      return filtered2;
    };
    const fixValue = (v) => {
      if (typeof v === "object" && v !== null) {
        return v;
      }
      if (typeof v === "string") {
        if (v === "[object Object]") return {};
        if (v.startsWith("{") || v.startsWith("[")) {
          const [ok2, err2, parsed] = tryFnSync(() => JSON.parse(v));
          return ok2 ? parsed : v;
        }
        return v;
      }
      return v;
    };
    if (behavior === "body-overflow") {
      const hasOverflow = metadata && metadata["$overflow"] === "true";
      let bodyData = {};
      if (hasOverflow && body) {
        const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(JSON.parse(body)));
        if (okBody) {
          let pluginMapFromMeta = null;
          if (metadata && metadata._pluginmap) {
            const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(
              () => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap)
            );
            pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
          }
          const [okUnmap, errUnmap, unmappedBody] = await tryFn(
            () => this.schema.unmapper(parsedBody, void 0, pluginMapFromMeta)
          );
          bodyData = okUnmap ? unmappedBody : {};
        }
      }
      const merged = { ...unmappedMetadata, ...bodyData, id };
      Object.keys(merged).forEach((k) => {
        merged[k] = fixValue(merged[k]);
      });
      const result2 = filterInternalFields(merged);
      if (hasOverflow) {
        result2.$overflow = "true";
      }
      return result2;
    }
    if (behavior === "body-only") {
      const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(body ? JSON.parse(body) : {}));
      let mapFromMeta = this.schema.map;
      let pluginMapFromMeta = null;
      if (metadata && metadata._map) {
        const [okMap, errMap, parsedMap] = await tryFn(() => Promise.resolve(typeof metadata._map === "string" ? JSON.parse(metadata._map) : metadata._map));
        mapFromMeta = okMap ? parsedMap : this.schema.map;
      }
      if (metadata && metadata._pluginmap) {
        const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(() => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap));
        pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
      }
      const [okUnmap, errUnmap, unmappedBody] = await tryFn(() => this.schema.unmapper(parsedBody, mapFromMeta, pluginMapFromMeta));
      const result2 = okUnmap ? { ...unmappedBody, id } : { id };
      Object.keys(result2).forEach((k) => {
        result2[k] = fixValue(result2[k]);
      });
      return result2;
    }
    if (behavior === "user-managed" && body && body.trim() !== "") {
      const [okBody, errBody, parsedBody] = await tryFn(() => Promise.resolve(JSON.parse(body)));
      if (okBody) {
        let pluginMapFromMeta = null;
        if (metadata && metadata._pluginmap) {
          const [okPluginMap, errPluginMap, parsedPluginMap] = await tryFn(
            () => Promise.resolve(typeof metadata._pluginmap === "string" ? JSON.parse(metadata._pluginmap) : metadata._pluginmap)
          );
          pluginMapFromMeta = okPluginMap ? parsedPluginMap : null;
        }
        const [okUnmap, errUnmap, unmappedBody] = await tryFn(
          () => this.schema.unmapper(parsedBody, void 0, pluginMapFromMeta)
        );
        const bodyData = okUnmap ? unmappedBody : {};
        const merged = { ...bodyData, ...unmappedMetadata, id };
        Object.keys(merged).forEach((k) => {
          merged[k] = fixValue(merged[k]);
        });
        return filterInternalFields(merged);
      }
    }
    const result = { ...unmappedMetadata, id };
    Object.keys(result).forEach((k) => {
      result[k] = fixValue(result[k]);
    });
    const filtered = filterInternalFields(result);
    if (behaviorFlags.$truncated) {
      filtered.$truncated = behaviorFlags.$truncated;
    }
    if (behaviorFlags.$overflow) {
      filtered.$overflow = behaviorFlags.$overflow;
    }
    return filtered;
  }
  // --- GUARDS SYSTEM ---
  /**
   * Normalize guard configuration
   * @param {Object|Array|undefined} guard - Guard configuration
   * @returns {Object|null} Normalized guard config
   * @private
   */
  _normalizeGuard(guard) {
    if (!guard) return null;
    if (Array.isArray(guard)) {
      return { "*": guard };
    }
    return guard;
  }
  /**
   * Execute guard for operation
   * @param {string} operation - Operation name (list, get, insert, update, etc)
   * @param {Object} context - Framework-agnostic context
   * @param {Object} context.user - Decoded JWT token
   * @param {Object} context.params - Route params
   * @param {Object} context.body - Request body
   * @param {Object} context.query - Query string
   * @param {Object} context.headers - Request headers
   * @param {Function} context.setPartition - Helper to set partition
   * @param {Object} [resource] - Resource record (for get/update/delete)
   * @returns {Promise<boolean>} True if allowed, false if denied
   */
  async executeGuard(operation, context, resource = null) {
    if (!this.guard) return true;
    let guardFn = this.guard[operation];
    if (!guardFn) {
      guardFn = this.guard["*"];
    }
    if (!guardFn) return true;
    if (typeof guardFn === "boolean") {
      return guardFn;
    }
    if (Array.isArray(guardFn)) {
      return this._checkRolesScopes(guardFn, context.user);
    }
    if (typeof guardFn === "function") {
      try {
        const result = await guardFn(context, resource);
        return result === true;
      } catch (err) {
        console.error(`Guard error for ${operation}:`, err);
        return false;
      }
    }
    return false;
  }
  /**
   * Check if user has required roles or scopes
   * @param {Array<string>} requiredRolesScopes - Required roles/scopes
   * @param {Object} user - User from JWT token
   * @returns {boolean} True if user has any of required roles/scopes
   * @private
   */
  _checkRolesScopes(requiredRolesScopes, user) {
    if (!user) return false;
    const userScopes = user.scope?.split(" ") || [];
    const clientId = user.azp || process.env.CLIENT_ID || "default";
    const clientRoles = user.resource_access?.[clientId]?.roles || [];
    const realmRoles = user.realm_access?.roles || [];
    const azureRoles = user.roles || [];
    const userRoles = [...clientRoles, ...realmRoles, ...azureRoles];
    return requiredRolesScopes.some((required) => {
      return userScopes.includes(required) || userRoles.includes(required);
    });
  }
  // --- MIDDLEWARE SYSTEM ---
  _initMiddleware() {
    this._middlewares = /* @__PURE__ */ new Map();
    this._middlewareMethods = [
      "get",
      "list",
      "listIds",
      "getAll",
      "count",
      "page",
      "insert",
      "update",
      "delete",
      "deleteMany",
      "exists",
      "getMany",
      "content",
      "hasContent",
      "query",
      "getFromPartition",
      "setContent",
      "deleteContent",
      "replace"
    ];
    for (const method of this._middlewareMethods) {
      this._middlewares.set(method, []);
      if (!this[`_original_${method}`]) {
        this[`_original_${method}`] = this[method].bind(this);
        this[method] = async (...args) => {
          const ctx = { resource: this, args, method };
          let idx = -1;
          const stack = this._middlewares.get(method);
          const dispatch = async (i) => {
            if (i <= idx) throw new Error("next() called multiple times");
            idx = i;
            if (i < stack.length) {
              return await stack[i](ctx, () => dispatch(i + 1));
            } else {
              return await this[`_original_${method}`](...ctx.args);
            }
          };
          return await dispatch(0);
        };
      }
    }
  }
  useMiddleware(method, fn) {
    if (!this._middlewares) this._initMiddleware();
    if (!this._middlewares.has(method)) throw new ResourceError(`No such method for middleware: ${method}`, { operation: "useMiddleware", method });
    this._middlewares.get(method).push(fn);
  }
  // Utility to apply schema default values
  applyDefaults(data) {
    const out = { ...data };
    for (const [key, def] of Object.entries(this.attributes)) {
      if (out[key] === void 0) {
        if (typeof def === "string" && def.includes("default:")) {
          const match = def.match(/default:([^|]+)/);
          if (match) {
            let val = match[1];
            if (def.includes("boolean")) val = val === "true";
            else if (def.includes("number")) val = Number(val);
            out[key] = val;
          }
        }
      }
    }
    return out;
  }
  // ============================================================================
  // STATE MACHINE METHODS
  // ============================================================================
  /**
   * State machine accessor object
   * Provides namespaced access to state machine operations
   * @type {Object}
   * @property {Function} send - Trigger state transition
   * @property {Function} get - Get current state
   * @property {Function} canTransition - Check if transition is valid
   * @property {Function} getValidEvents - Get valid events for current state
   * @property {Function} initialize - Initialize entity with initial state
   * @property {Function} history - Get transition history
   * @example
   * await orders.state.send('order-123', 'CONFIRM');
   * const state = await orders.state.get('order-123');
   * const canShip = await orders.state.canTransition('order-123', 'SHIP');
   */
  get state() {
    const resource = this;
    const throwIfNoStateMachine = () => {
      if (!resource._stateMachine) {
        throw new Error(
          `No state machine configured for resource '${resource.name}'. Ensure StateMachinePlugin is installed and configured for this resource.`
        );
      }
    };
    return {
      /**
       * Trigger a state transition
       * @param {string} id - Entity ID
       * @param {string} event - Event name
       * @param {Object} [eventData] - Event data
       * @returns {Promise<Object>} Transition result
       * @example
       * await orders.state.send('order-123', 'CONFIRM', { confirmedBy: 'user-456' });
       */
      send: async (id, event, eventData) => {
        throwIfNoStateMachine();
        return resource._stateMachine.send(id, event, eventData);
      },
      /**
       * Get current state of an entity
       * @param {string} id - Entity ID
       * @returns {Promise<string>} Current state
       * @example
       * const currentState = await orders.state.get('order-123');
       */
      get: async (id) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getState(id);
      },
      /**
       * Check if a transition is valid
       * @param {string} id - Entity ID
       * @param {string} event - Event name
       * @returns {Promise<boolean>} True if transition is valid
       * @example
       * const canConfirm = await orders.state.canTransition('order-123', 'CONFIRM');
       */
      canTransition: async (id, event) => {
        throwIfNoStateMachine();
        return resource._stateMachine.canTransition(id, event);
      },
      /**
       * Get all valid events for the current state
       * @param {string} id - Entity ID
       * @returns {Promise<Array<string>>} Array of valid event names
       * @example
       * const events = await orders.state.getValidEvents('order-123');
       * // Returns: ['SHIP', 'CANCEL']
       */
      getValidEvents: async (id) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getValidEvents(id);
      },
      /**
       * Initialize entity with initial state
       * @param {string} id - Entity ID
       * @param {Object} [context] - Initial context data
       * @returns {Promise<void>}
       * @example
       * await orders.state.initialize('order-456', { customerId: 'user-123' });
       */
      initialize: async (id, context) => {
        throwIfNoStateMachine();
        return resource._stateMachine.initializeEntity(id, context);
      },
      /**
       * Get transition history for an entity
       * @param {string} id - Entity ID
       * @param {Object} [options] - Query options
       * @param {number} [options.limit=100] - Maximum number of transitions
       * @param {Date} [options.fromDate] - Filter from date
       * @param {Date} [options.toDate] - Filter to date
       * @returns {Promise<Array<Object>>} Transition history
       * @example
       * const history = await orders.state.history('order-123', { limit: 50 });
       */
      history: async (id, options) => {
        throwIfNoStateMachine();
        return resource._stateMachine.getTransitionHistory(id, options);
      }
    };
  }
  /**
   * Internal method to attach state machine instance
   * This is called by StateMachinePlugin during initialization
   * @private
   * @param {Object} stateMachine - State machine instance
   */
  _attachStateMachine(stateMachine) {
    this._stateMachine = stateMachine;
  }
}
function validateResourceConfig(config) {
  const errors = [];
  if (!config.name) {
    errors.push("Resource 'name' is required");
  } else if (typeof config.name !== "string") {
    errors.push("Resource 'name' must be a string");
  } else if (config.name.trim() === "") {
    errors.push("Resource 'name' cannot be empty");
  }
  if (!config.client) {
    errors.push("S3 'client' is required");
  }
  if (!config.attributes) {
    errors.push("Resource 'attributes' are required");
  } else if (typeof config.attributes !== "object" || Array.isArray(config.attributes)) {
    errors.push("Resource 'attributes' must be an object");
  } else if (Object.keys(config.attributes).length === 0) {
    errors.push("Resource 'attributes' cannot be empty");
  }
  if (config.version !== void 0 && typeof config.version !== "string") {
    errors.push("Resource 'version' must be a string");
  }
  if (config.behavior !== void 0 && typeof config.behavior !== "string") {
    errors.push("Resource 'behavior' must be a string");
  }
  if (config.passphrase !== void 0 && typeof config.passphrase !== "string") {
    errors.push("Resource 'passphrase' must be a string");
  }
  if (config.parallelism !== void 0) {
    if (typeof config.parallelism !== "number" || !Number.isInteger(config.parallelism)) {
      errors.push("Resource 'parallelism' must be an integer");
    } else if (config.parallelism < 1) {
      errors.push("Resource 'parallelism' must be greater than 0");
    }
  }
  if (config.observers !== void 0 && !Array.isArray(config.observers)) {
    errors.push("Resource 'observers' must be an array");
  }
  const booleanFields = ["cache", "autoDecrypt", "timestamps", "paranoid", "allNestedObjectsOptional"];
  for (const field of booleanFields) {
    if (config[field] !== void 0 && typeof config[field] !== "boolean") {
      errors.push(`Resource '${field}' must be a boolean`);
    }
  }
  if (config.idGenerator !== void 0) {
    if (typeof config.idGenerator !== "function" && typeof config.idGenerator !== "number") {
      errors.push("Resource 'idGenerator' must be a function or a number (size)");
    } else if (typeof config.idGenerator === "number" && config.idGenerator <= 0) {
      errors.push("Resource 'idGenerator' size must be greater than 0");
    }
  }
  if (config.idSize !== void 0) {
    if (typeof config.idSize !== "number" || !Number.isInteger(config.idSize)) {
      errors.push("Resource 'idSize' must be an integer");
    } else if (config.idSize <= 0) {
      errors.push("Resource 'idSize' must be greater than 0");
    }
  }
  if (config.partitions !== void 0) {
    if (typeof config.partitions !== "object" || Array.isArray(config.partitions)) {
      errors.push("Resource 'partitions' must be an object");
    } else {
      for (const [partitionName, partitionDef] of Object.entries(config.partitions)) {
        if (typeof partitionDef !== "object" || Array.isArray(partitionDef)) {
          errors.push(`Partition '${partitionName}' must be an object`);
        } else if (!partitionDef.fields) {
          errors.push(`Partition '${partitionName}' must have a 'fields' property`);
        } else if (typeof partitionDef.fields !== "object" || Array.isArray(partitionDef.fields)) {
          errors.push(`Partition '${partitionName}.fields' must be an object`);
        } else {
          for (const [fieldName, fieldType] of Object.entries(partitionDef.fields)) {
            if (typeof fieldType !== "string") {
              errors.push(`Partition '${partitionName}.fields.${fieldName}' must be a string`);
            }
          }
        }
      }
    }
  }
  if (config.hooks !== void 0) {
    if (typeof config.hooks !== "object" || Array.isArray(config.hooks)) {
      errors.push("Resource 'hooks' must be an object");
    } else {
      const validHookEvents = [
        "beforeInsert",
        "afterInsert",
        "beforeUpdate",
        "afterUpdate",
        "beforeDelete",
        "afterDelete",
        "beforeGet",
        "afterGet",
        "beforeList",
        "afterList",
        "beforeQuery",
        "afterQuery",
        "beforeExists",
        "afterExists",
        "beforeCount",
        "afterCount",
        "beforePatch",
        "afterPatch",
        "beforeReplace",
        "afterReplace",
        "beforeGetMany",
        "afterGetMany",
        "beforeDeleteMany",
        "afterDeleteMany"
      ];
      for (const [event, hooksArr] of Object.entries(config.hooks)) {
        if (!validHookEvents.includes(event)) {
          errors.push(`Invalid hook event '${event}'. Valid events: ${validHookEvents.join(", ")}`);
        } else if (!Array.isArray(hooksArr)) {
          errors.push(`Resource 'hooks.${event}' must be an array`);
        } else {
          for (let i = 0; i < hooksArr.length; i++) {
            const hook = hooksArr[i];
            if (typeof hook !== "function") {
              if (typeof hook === "string") continue;
              continue;
            }
          }
        }
      }
    }
  }
  if (config.events !== void 0) {
    if (typeof config.events !== "object" || Array.isArray(config.events)) {
      errors.push("Resource 'events' must be an object");
    } else {
      for (const [eventName, listeners] of Object.entries(config.events)) {
        if (Array.isArray(listeners)) {
          for (let i = 0; i < listeners.length; i++) {
            const listener = listeners[i];
            if (typeof listener !== "function") {
              errors.push(`Resource 'events.${eventName}[${i}]' must be a function`);
            }
          }
        } else if (typeof listeners !== "function") {
          errors.push(`Resource 'events.${eventName}' must be a function or array of functions`);
        }
      }
    }
  }
  return {
    isValid: errors.length === 0,
    errors
  };
}

class MLError extends Error {
  constructor(message, context = {}) {
    super(message);
    this.name = "MLError";
    this.context = context;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
  }
  toJSON() {
    return {
      name: this.name,
      message: this.message,
      context: this.context,
      stack: this.stack
    };
  }
}
class ModelConfigError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "ModelConfigError";
  }
}
class TrainingError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "TrainingError";
  }
}
let PredictionError$1 = class PredictionError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "PredictionError";
  }
};
class ModelNotFoundError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "ModelNotFoundError";
  }
}
let ModelNotTrainedError$1 = class ModelNotTrainedError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "ModelNotTrainedError";
  }
};
class DataValidationError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "DataValidationError";
  }
}
class InsufficientDataError extends MLError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "InsufficientDataError";
  }
}
class TensorFlowDependencyError extends MLError {
  constructor(message = "TensorFlow.js is not installed. Run: pnpm add @tensorflow/tfjs-node", context = {}) {
    super(message, context);
    this.name = "TensorFlowDependencyError";
  }
}

class BaseModel {
  constructor(config = {}) {
    if (this.constructor === BaseModel) {
      throw new Error("BaseModel is an abstract class and cannot be instantiated directly");
    }
    this.config = {
      name: config.name || "unnamed",
      resource: config.resource,
      features: config.features || [],
      target: config.target,
      modelConfig: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        ...config.modelConfig
      },
      verbose: config.verbose || false
    };
    this.model = null;
    this.isTrained = false;
    this.normalizer = {
      features: {},
      target: {}
    };
    this.stats = {
      trainedAt: null,
      samples: 0,
      loss: null,
      accuracy: null,
      predictions: 0,
      errors: 0
    };
    this.tf = null;
    this._tfValidated = false;
  }
  /**
   * Validate and load TensorFlow.js (lazy loading)
   * @private
   */
  async _validateTensorFlow() {
    if (this._tfValidated) {
      return;
    }
    try {
      this.tf = require("@tensorflow/tfjs-node");
      this._tfValidated = true;
    } catch (requireError) {
      try {
        const tfModule = await import('@tensorflow/tfjs-node');
        this.tf = tfModule.default || tfModule;
        this._tfValidated = true;
      } catch (importError) {
        throw new TensorFlowDependencyError(
          "TensorFlow.js is not installed. Run: pnpm add @tensorflow/tfjs-node",
          { originalError: importError.message }
        );
      }
    }
  }
  /**
   * Abstract method: Build the model architecture
   * Must be implemented by subclasses
   * @abstract
   */
  buildModel() {
    throw new Error("buildModel() must be implemented by subclass");
  }
  /**
   * Train the model with provided data
   * @param {Array} data - Training data records
   * @returns {Object} Training results
   */
  async train(data) {
    if (!this._tfValidated) {
      await this._validateTensorFlow();
    }
    try {
      if (!data || data.length === 0) {
        throw new InsufficientDataError("No training data provided", {
          model: this.config.name
        });
      }
      const minSamples = this.config.modelConfig.batchSize || 10;
      if (data.length < minSamples) {
        throw new InsufficientDataError(
          `Insufficient training data: ${data.length} samples (minimum: ${minSamples})`,
          { model: this.config.name, samples: data.length, minimum: minSamples }
        );
      }
      const { xs, ys } = this._prepareData(data);
      if (!this.model) {
        this.buildModel();
      }
      const history = await this.model.fit(xs, ys, {
        epochs: this.config.modelConfig.epochs,
        batchSize: this.config.modelConfig.batchSize,
        validationSplit: this.config.modelConfig.validationSplit,
        verbose: this.config.verbose ? 1 : 0,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            if (this.config.verbose && epoch % 10 === 0) {
              console.log(`[MLPlugin] ${this.config.name} - Epoch ${epoch}: loss=${logs.loss.toFixed(4)}`);
            }
          }
        }
      });
      this.isTrained = true;
      this.stats.trainedAt = (/* @__PURE__ */ new Date()).toISOString();
      this.stats.samples = data.length;
      this.stats.loss = history.history.loss[history.history.loss.length - 1];
      if (history.history.acc) {
        this.stats.accuracy = history.history.acc[history.history.acc.length - 1];
      }
      xs.dispose();
      ys.dispose();
      if (this.config.verbose) {
        console.log(`[MLPlugin] ${this.config.name} - Training completed:`, {
          samples: this.stats.samples,
          loss: this.stats.loss,
          accuracy: this.stats.accuracy
        });
      }
      return {
        loss: this.stats.loss,
        accuracy: this.stats.accuracy,
        epochs: this.config.modelConfig.epochs,
        samples: this.stats.samples
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof InsufficientDataError || error instanceof DataValidationError) {
        throw error;
      }
      throw new TrainingError(`Training failed: ${error.message}`, {
        model: this.config.name,
        originalError: error.message
      });
    }
  }
  /**
   * Make a prediction with the trained model
   * @param {Object} input - Input features
   * @returns {Object} Prediction result
   */
  async predict(input) {
    if (!this._tfValidated) {
      await this._validateTensorFlow();
    }
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      this._validateInput(input);
      const features = this._extractFeatures(input);
      const normalizedFeatures = this._normalizeFeatures(features);
      const inputTensor = this.tf.tensor2d([normalizedFeatures]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const prediction = this._denormalizePrediction(predictionArray[0]);
      this.stats.predictions++;
      return {
        prediction,
        confidence: this._calculateConfidence(predictionArray[0])
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError$1 || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError$1(`Prediction failed: ${error.message}`, {
        model: this.config.name,
        input,
        originalError: error.message
      });
    }
  }
  /**
   * Make predictions for multiple inputs
   * @param {Array} inputs - Array of input objects
   * @returns {Array} Array of prediction results
   */
  async predictBatch(inputs) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError$1(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    for (const input of inputs) {
      predictions.push(await this.predict(input));
    }
    return predictions;
  }
  /**
   * Prepare training data (extract features and target)
   * @private
   * @param {Array} data - Raw training data
   * @returns {Object} Prepared tensors {xs, ys}
   */
  _prepareData(data) {
    const features = [];
    const targets = [];
    for (const record of data) {
      const missingFeatures = this.config.features.filter((f) => !(f in record));
      if (missingFeatures.length > 0) {
        throw new DataValidationError(
          `Missing features in training data: ${missingFeatures.join(", ")}`,
          { model: this.config.name, missingFeatures, record }
        );
      }
      if (!(this.config.target in record)) {
        throw new DataValidationError(
          `Missing target "${this.config.target}" in training data`,
          { model: this.config.name, target: this.config.target, record }
        );
      }
      const featureValues = this._extractFeatures(record);
      features.push(featureValues);
      targets.push(record[this.config.target]);
    }
    this._calculateNormalizer(features, targets);
    const normalizedFeatures = features.map((f) => this._normalizeFeatures(f));
    const normalizedTargets = targets.map((t) => this._normalizeTarget(t));
    return {
      xs: this.tf.tensor2d(normalizedFeatures),
      ys: this._prepareTargetTensor(normalizedTargets)
    };
  }
  /**
   * Prepare target tensor (can be overridden by subclasses)
   * @protected
   * @param {Array} targets - Normalized target values
   * @returns {Tensor} Target tensor
   */
  _prepareTargetTensor(targets) {
    return this.tf.tensor2d(targets.map((t) => [t]));
  }
  /**
   * Extract feature values from a record
   * @private
   * @param {Object} record - Data record
   * @returns {Array} Feature values
   */
  _extractFeatures(record) {
    return this.config.features.map((feature) => {
      const value = record[feature];
      if (typeof value !== "number") {
        throw new DataValidationError(
          `Feature "${feature}" must be a number, got ${typeof value}`,
          { model: this.config.name, feature, value, type: typeof value }
        );
      }
      return value;
    });
  }
  /**
   * Calculate normalization parameters (min-max scaling)
   * @private
   */
  _calculateNormalizer(features, targets) {
    const numFeatures = features[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const featureName = this.config.features[i];
      const values = features.map((f) => f[i]);
      this.normalizer.features[featureName] = {
        min: Math.min(...values),
        max: Math.max(...values)
      };
    }
    this.normalizer.target = {
      min: Math.min(...targets),
      max: Math.max(...targets)
    };
  }
  /**
   * Normalize features using min-max scaling
   * @private
   */
  _normalizeFeatures(features) {
    return features.map((value, i) => {
      const featureName = this.config.features[i];
      const { min, max } = this.normalizer.features[featureName];
      if (max === min) return 0.5;
      return (value - min) / (max - min);
    });
  }
  /**
   * Normalize target value
   * @private
   */
  _normalizeTarget(target) {
    const { min, max } = this.normalizer.target;
    if (max === min) return 0.5;
    return (target - min) / (max - min);
  }
  /**
   * Denormalize prediction
   * @private
   */
  _denormalizePrediction(normalizedValue) {
    const { min, max } = this.normalizer.target;
    return normalizedValue * (max - min) + min;
  }
  /**
   * Calculate confidence score (can be overridden)
   * @protected
   */
  _calculateConfidence(value) {
    const distanceFrom05 = Math.abs(value - 0.5);
    return Math.min(0.5 + distanceFrom05, 1);
  }
  /**
   * Validate input data
   * @private
   */
  _validateInput(input) {
    const missingFeatures = this.config.features.filter((f) => !(f in input));
    if (missingFeatures.length > 0) {
      throw new DataValidationError(
        `Missing features: ${missingFeatures.join(", ")}`,
        { model: this.config.name, missingFeatures, input }
      );
    }
  }
  /**
   * Export model to JSON (for persistence)
   * @returns {Object} Serialized model
   */
  async export() {
    if (!this.model) {
      return null;
    }
    const modelJSON = await this.model.toJSON();
    return {
      config: this.config,
      normalizer: this.normalizer,
      stats: this.stats,
      isTrained: this.isTrained,
      model: modelJSON
    };
  }
  /**
   * Import model from JSON
   * @param {Object} data - Serialized model data
   */
  async import(data) {
    this.config = data.config;
    this.normalizer = data.normalizer;
    this.stats = data.stats;
    this.isTrained = data.isTrained;
    if (data.model) {
      this.buildModel();
    }
  }
  /**
   * Dispose model and free memory
   */
  dispose() {
    if (this.model) {
      this.model.dispose();
      this.model = null;
    }
    this.isTrained = false;
  }
  /**
   * Get model statistics
   */
  getStats() {
    return {
      ...this.stats,
      isTrained: this.isTrained,
      config: this.config
    };
  }
}

class RegressionModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      polynomial: config.modelConfig?.polynomial || 1,
      // Degree (1 = linear, 2+ = polynomial)
      units: config.modelConfig?.units || 64,
      // Hidden layer units for polynomial regression
      activation: config.modelConfig?.activation || "relu"
    };
    if (this.config.modelConfig.polynomial < 1 || this.config.modelConfig.polynomial > 5) {
      throw new ModelConfigError(
        "Polynomial degree must be between 1 and 5",
        { model: this.config.name, polynomial: this.config.modelConfig.polynomial }
      );
    }
  }
  /**
   * Build regression model architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    const polynomial = this.config.modelConfig.polynomial;
    this.model = this.tf.sequential();
    if (polynomial === 1) {
      this.model.add(this.tf.layers.dense({
        inputShape: [numFeatures],
        units: 1,
        useBias: true
      }));
    } else {
      this.model.add(this.tf.layers.dense({
        inputShape: [numFeatures],
        units: this.config.modelConfig.units,
        activation: this.config.modelConfig.activation,
        useBias: true
      }));
      if (polynomial >= 3) {
        this.model.add(this.tf.layers.dense({
          units: Math.floor(this.config.modelConfig.units / 2),
          activation: this.config.modelConfig.activation
        }));
      }
      this.model.add(this.tf.layers.dense({
        units: 1
      }));
    }
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: "meanSquaredError",
      metrics: ["mse", "mae"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built regression model (polynomial degree: ${polynomial})`);
      this.model.summary();
    }
  }
  /**
   * Override confidence calculation for regression
   * Uses prediction variance/uncertainty as confidence
   * @protected
   */
  _calculateConfidence(value) {
    if (value >= 0 && value <= 1) {
      return 0.9 + Math.random() * 0.1;
    }
    const distance = Math.abs(value < 0 ? value : value - 1);
    return Math.max(0.5, 1 - distance);
  }
  /**
   * Get R² score (coefficient of determination)
   * Measures how well the model explains the variance in the data
   * @param {Array} data - Test data
   * @returns {number} R² score (0-1, higher is better)
   */
  async calculateR2Score(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    const actuals = [];
    for (const record of data) {
      const { prediction } = await this.predict(record);
      predictions.push(prediction);
      actuals.push(record[this.config.target]);
    }
    const meanActual = actuals.reduce((sum, val) => sum + val, 0) / actuals.length;
    const tss = actuals.reduce((sum, actual) => {
      return sum + Math.pow(actual - meanActual, 2);
    }, 0);
    const rss = predictions.reduce((sum, pred, i) => {
      return sum + Math.pow(actuals[i] - pred, 2);
    }, 0);
    const r2 = 1 - rss / tss;
    return r2;
  }
  /**
   * Export model with regression-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "regression",
      polynomial: this.config.modelConfig.polynomial
    };
  }
}

class ClassificationModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      units: config.modelConfig?.units || 64,
      // Hidden layer units
      activation: config.modelConfig?.activation || "relu",
      dropout: config.modelConfig?.dropout || 0.2
      // Dropout rate for regularization
    };
    this.classes = [];
    this.classToIndex = {};
    this.indexToClass = {};
  }
  /**
   * Build classification model architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    const numClasses = this.classes.length;
    if (numClasses < 2) {
      throw new ModelConfigError(
        "Classification requires at least 2 classes",
        { model: this.config.name, numClasses }
      );
    }
    this.model = this.tf.sequential();
    this.model.add(this.tf.layers.dense({
      inputShape: [numFeatures],
      units: this.config.modelConfig.units,
      activation: this.config.modelConfig.activation,
      useBias: true
    }));
    if (this.config.modelConfig.dropout > 0) {
      this.model.add(this.tf.layers.dropout({
        rate: this.config.modelConfig.dropout
      }));
    }
    this.model.add(this.tf.layers.dense({
      units: Math.floor(this.config.modelConfig.units / 2),
      activation: this.config.modelConfig.activation
    }));
    const isBinary = numClasses === 2;
    this.model.add(this.tf.layers.dense({
      units: isBinary ? 1 : numClasses,
      activation: isBinary ? "sigmoid" : "softmax"
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: isBinary ? "binaryCrossentropy" : "categoricalCrossentropy",
      metrics: ["accuracy"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built classification model (${numClasses} classes, ${isBinary ? "binary" : "multi-class"})`);
      this.model.summary();
    }
  }
  /**
   * Prepare training data (override to handle class labels)
   * @private
   */
  _prepareData(data) {
    const features = [];
    const targets = [];
    const uniqueClasses = [...new Set(data.map((r) => r[this.config.target]))];
    this.classes = uniqueClasses.sort();
    this.classes.forEach((cls, idx) => {
      this.classToIndex[cls] = idx;
      this.indexToClass[idx] = cls;
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Detected ${this.classes.length} classes:`, this.classes);
    }
    for (const record of data) {
      const missingFeatures = this.config.features.filter((f) => !(f in record));
      if (missingFeatures.length > 0) {
        throw new DataValidationError(
          `Missing features in training data: ${missingFeatures.join(", ")}`,
          { model: this.config.name, missingFeatures, record }
        );
      }
      if (!(this.config.target in record)) {
        throw new DataValidationError(
          `Missing target "${this.config.target}" in training data`,
          { model: this.config.name, target: this.config.target, record }
        );
      }
      const featureValues = this._extractFeatures(record);
      features.push(featureValues);
      const targetClass = record[this.config.target];
      if (!(targetClass in this.classToIndex)) {
        throw new DataValidationError(
          `Unknown class "${targetClass}" in training data`,
          { model: this.config.name, targetClass, knownClasses: this.classes }
        );
      }
      targets.push(this.classToIndex[targetClass]);
    }
    this._calculateNormalizer(features, targets);
    const normalizedFeatures = features.map((f) => this._normalizeFeatures(f));
    return {
      xs: this.tf.tensor2d(normalizedFeatures),
      ys: this._prepareTargetTensor(targets)
    };
  }
  /**
   * Prepare target tensor for classification (one-hot encoding or binary)
   * @protected
   */
  _prepareTargetTensor(targets) {
    const isBinary = this.classes.length === 2;
    if (isBinary) {
      return this.tf.tensor2d(targets.map((t) => [t]));
    } else {
      return this.tf.oneHot(targets, this.classes.length);
    }
  }
  /**
   * Calculate normalization parameters (skip target normalization for classification)
   * @private
   */
  _calculateNormalizer(features, targets) {
    const numFeatures = features[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const featureName = this.config.features[i];
      const values = features.map((f) => f[i]);
      this.normalizer.features[featureName] = {
        min: Math.min(...values),
        max: Math.max(...values)
      };
    }
    this.normalizer.target = { min: 0, max: 1 };
  }
  /**
   * Make a prediction (override to return class label)
   */
  async predict(input) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      this._validateInput(input);
      const features = this._extractFeatures(input);
      const normalizedFeatures = this._normalizeFeatures(features);
      const inputTensor = this.tf.tensor2d([normalizedFeatures]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const isBinary = this.classes.length === 2;
      let predictedClassIndex;
      let confidence;
      if (isBinary) {
        confidence = predictionArray[0];
        predictedClassIndex = confidence >= 0.5 ? 1 : 0;
      } else {
        predictedClassIndex = predictionArray.indexOf(Math.max(...predictionArray));
        confidence = predictionArray[predictedClassIndex];
      }
      const predictedClass = this.indexToClass[predictedClassIndex];
      this.stats.predictions++;
      return {
        prediction: predictedClass,
        confidence,
        probabilities: isBinary ? {
          [this.classes[0]]: 1 - predictionArray[0],
          [this.classes[1]]: predictionArray[0]
        } : Object.fromEntries(
          this.classes.map((cls, idx) => [cls, predictionArray[idx]])
        )
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError(`Prediction failed: ${error.message}`, {
        model: this.config.name,
        input,
        originalError: error.message
      });
    }
  }
  /**
   * Calculate confusion matrix
   * @param {Array} data - Test data
   * @returns {Object} Confusion matrix and metrics
   */
  async calculateConfusionMatrix(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const matrix = {};
    this.classes.length;
    for (const actualClass of this.classes) {
      matrix[actualClass] = {};
      for (const predictedClass of this.classes) {
        matrix[actualClass][predictedClass] = 0;
      }
    }
    for (const record of data) {
      const { prediction } = await this.predict(record);
      const actual = record[this.config.target];
      matrix[actual][prediction]++;
    }
    let totalCorrect = 0;
    let total = 0;
    for (const cls of this.classes) {
      totalCorrect += matrix[cls][cls];
      total += Object.values(matrix[cls]).reduce((sum, val) => sum + val, 0);
    }
    const accuracy = total > 0 ? totalCorrect / total : 0;
    return {
      matrix,
      accuracy,
      total,
      correct: totalCorrect
    };
  }
  /**
   * Export model with classification-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "classification",
      classes: this.classes,
      classToIndex: this.classToIndex,
      indexToClass: this.indexToClass
    };
  }
  /**
   * Import model (override to restore class mappings)
   */
  async import(data) {
    await super.import(data);
    this.classes = data.classes || [];
    this.classToIndex = data.classToIndex || {};
    this.indexToClass = data.indexToClass || {};
  }
}

class TimeSeriesModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      lookback: config.modelConfig?.lookback || 10,
      // Number of past timesteps to use
      lstmUnits: config.modelConfig?.lstmUnits || 50,
      // LSTM layer units
      denseUnits: config.modelConfig?.denseUnits || 25,
      // Dense layer units
      dropout: config.modelConfig?.dropout || 0.2,
      recurrentDropout: config.modelConfig?.recurrentDropout || 0.2
    };
    if (this.config.modelConfig.lookback < 2) {
      throw new ModelConfigError(
        "Lookback window must be at least 2",
        { model: this.config.name, lookback: this.config.modelConfig.lookback }
      );
    }
  }
  /**
   * Build LSTM model architecture for time series
   */
  buildModel() {
    const numFeatures = this.config.features.length + 1;
    const lookback = this.config.modelConfig.lookback;
    this.model = this.tf.sequential();
    this.model.add(this.tf.layers.lstm({
      inputShape: [lookback, numFeatures],
      units: this.config.modelConfig.lstmUnits,
      returnSequences: false,
      dropout: this.config.modelConfig.dropout,
      recurrentDropout: this.config.modelConfig.recurrentDropout
    }));
    this.model.add(this.tf.layers.dense({
      units: this.config.modelConfig.denseUnits,
      activation: "relu"
    }));
    if (this.config.modelConfig.dropout > 0) {
      this.model.add(this.tf.layers.dropout({
        rate: this.config.modelConfig.dropout
      }));
    }
    this.model.add(this.tf.layers.dense({
      units: 1
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: "meanSquaredError",
      metrics: ["mse", "mae"]
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built LSTM time series model (lookback: ${lookback})`);
      this.model.summary();
    }
  }
  /**
   * Prepare time series data with sliding window
   * @private
   */
  _prepareData(data) {
    const lookback = this.config.modelConfig.lookback;
    if (data.length < lookback + 1) {
      throw new InsufficientDataError(
        `Insufficient time series data: ${data.length} samples (minimum: ${lookback + 1})`,
        { model: this.config.name, samples: data.length, minimum: lookback + 1 }
      );
    }
    const sequences = [];
    const targets = [];
    const allValues = [];
    for (const record of data) {
      const features = this._extractFeatures(record);
      const target = record[this.config.target];
      allValues.push([...features, target]);
    }
    this._calculateTimeSeriesNormalizer(allValues);
    for (let i = 0; i <= data.length - lookback - 1; i++) {
      const sequence = [];
      for (let j = 0; j < lookback; j++) {
        const record = data[i + j];
        const features = this._extractFeatures(record);
        const target = record[this.config.target];
        const combined = [...features, target];
        const normalized = this._normalizeSequenceStep(combined);
        sequence.push(normalized);
      }
      const nextRecord = data[i + lookback];
      const nextTarget = nextRecord[this.config.target];
      sequences.push(sequence);
      targets.push(this._normalizeTarget(nextTarget));
    }
    return {
      xs: this.tf.tensor3d(sequences),
      // [samples, lookback, features]
      ys: this.tf.tensor2d(targets.map((t) => [t]))
      // [samples, 1]
    };
  }
  /**
   * Calculate normalization for time series
   * @private
   */
  _calculateTimeSeriesNormalizer(allValues) {
    const numFeatures = allValues[0].length;
    for (let i = 0; i < numFeatures; i++) {
      const values = allValues.map((v) => v[i]);
      const min = Math.min(...values);
      const max = Math.max(...values);
      if (i < this.config.features.length) {
        const featureName = this.config.features[i];
        this.normalizer.features[featureName] = { min, max };
      } else {
        this.normalizer.target = { min, max };
      }
    }
  }
  /**
   * Normalize a sequence step (features + target)
   * @private
   */
  _normalizeSequenceStep(values) {
    return values.map((value, i) => {
      let min, max;
      if (i < this.config.features.length) {
        const featureName = this.config.features[i];
        ({ min, max } = this.normalizer.features[featureName]);
      } else {
        ({ min, max } = this.normalizer.target);
      }
      if (max === min) return 0.5;
      return (value - min) / (max - min);
    });
  }
  /**
   * Predict next value in time series
   * @param {Array} sequence - Array of recent records (length = lookback)
   * @returns {Object} Prediction result
   */
  async predict(sequence) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    try {
      if (!Array.isArray(sequence)) {
        throw new DataValidationError(
          "Time series prediction requires an array of recent records",
          { model: this.config.name, input: typeof sequence }
        );
      }
      if (sequence.length !== this.config.modelConfig.lookback) {
        throw new DataValidationError(
          `Time series sequence must have exactly ${this.config.modelConfig.lookback} timesteps, got ${sequence.length}`,
          { model: this.config.name, expected: this.config.modelConfig.lookback, got: sequence.length }
        );
      }
      const normalizedSequence = [];
      for (const record of sequence) {
        this._validateInput(record);
        const features = this._extractFeatures(record);
        const target = record[this.config.target];
        const combined = [...features, target];
        normalizedSequence.push(this._normalizeSequenceStep(combined));
      }
      const inputTensor = this.tf.tensor3d([normalizedSequence]);
      const predictionTensor = this.model.predict(inputTensor);
      const predictionArray = await predictionTensor.data();
      inputTensor.dispose();
      predictionTensor.dispose();
      const prediction = this._denormalizePrediction(predictionArray[0]);
      this.stats.predictions++;
      return {
        prediction,
        confidence: this._calculateConfidence(predictionArray[0])
      };
    } catch (error) {
      this.stats.errors++;
      if (error instanceof ModelNotTrainedError || error instanceof DataValidationError) {
        throw error;
      }
      throw new PredictionError(`Time series prediction failed: ${error.message}`, {
        model: this.config.name,
        originalError: error.message
      });
    }
  }
  /**
   * Predict multiple future timesteps
   * @param {Array} initialSequence - Initial sequence of records
   * @param {number} steps - Number of steps to predict ahead
   * @returns {Array} Array of predictions
   */
  async predictMultiStep(initialSequence, steps = 1) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const predictions = [];
    let currentSequence = [...initialSequence];
    for (let i = 0; i < steps; i++) {
      const { prediction } = await this.predict(currentSequence);
      predictions.push(prediction);
      currentSequence.shift();
      const lastRecord = currentSequence[currentSequence.length - 1];
      const syntheticRecord = {
        ...lastRecord,
        [this.config.target]: prediction
      };
      currentSequence.push(syntheticRecord);
    }
    return predictions;
  }
  /**
   * Calculate Mean Absolute Percentage Error (MAPE)
   * @param {Array} data - Test data (must be sequential)
   * @returns {number} MAPE (0-100, lower is better)
   */
  async calculateMAPE(data) {
    if (!this.isTrained) {
      throw new ModelNotTrainedError(`Model "${this.config.name}" is not trained yet`, {
        model: this.config.name
      });
    }
    const lookback = this.config.modelConfig.lookback;
    if (data.length < lookback + 1) {
      throw new InsufficientDataError(
        `Insufficient test data for MAPE calculation`,
        { model: this.config.name, samples: data.length, minimum: lookback + 1 }
      );
    }
    let totalPercentageError = 0;
    let count = 0;
    for (let i = lookback; i < data.length; i++) {
      const sequence = data.slice(i - lookback, i);
      const { prediction } = await this.predict(sequence);
      const actual = data[i][this.config.target];
      if (actual !== 0) {
        const percentageError = Math.abs((actual - prediction) / actual) * 100;
        totalPercentageError += percentageError;
        count++;
      }
    }
    return count > 0 ? totalPercentageError / count : 0;
  }
  /**
   * Export model with time series-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "timeseries",
      lookback: this.config.modelConfig.lookback
    };
  }
}

class NeuralNetworkModel extends BaseModel {
  constructor(config = {}) {
    super(config);
    this.config.modelConfig = {
      ...this.config.modelConfig,
      layers: config.modelConfig?.layers || [
        { units: 64, activation: "relu", dropout: 0.2 },
        { units: 32, activation: "relu", dropout: 0.1 }
      ],
      // Array of hidden layer configurations
      outputActivation: config.modelConfig?.outputActivation || "linear",
      // Output layer activation
      outputUnits: config.modelConfig?.outputUnits || 1,
      // Number of output units
      loss: config.modelConfig?.loss || "meanSquaredError",
      // Loss function
      metrics: config.modelConfig?.metrics || ["mse", "mae"]
      // Metrics to track
    };
    this._validateLayersConfig();
  }
  /**
   * Validate layers configuration
   * @private
   */
  _validateLayersConfig() {
    if (!Array.isArray(this.config.modelConfig.layers) || this.config.modelConfig.layers.length === 0) {
      throw new ModelConfigError(
        "Neural network must have at least one hidden layer",
        { model: this.config.name, layers: this.config.modelConfig.layers }
      );
    }
    for (const [index, layer] of this.config.modelConfig.layers.entries()) {
      if (!layer.units || typeof layer.units !== "number" || layer.units < 1) {
        throw new ModelConfigError(
          `Layer ${index} must have a valid "units" property (positive number)`,
          { model: this.config.name, layer, index }
        );
      }
      if (layer.activation && !this._isValidActivation(layer.activation)) {
        throw new ModelConfigError(
          `Layer ${index} has invalid activation function "${layer.activation}"`,
          { model: this.config.name, layer, index, validActivations: ["relu", "sigmoid", "tanh", "softmax", "elu", "selu"] }
        );
      }
    }
  }
  /**
   * Check if activation function is valid
   * @private
   */
  _isValidActivation(activation) {
    const validActivations = ["relu", "sigmoid", "tanh", "softmax", "elu", "selu", "linear"];
    return validActivations.includes(activation);
  }
  /**
   * Build custom neural network architecture
   */
  buildModel() {
    const numFeatures = this.config.features.length;
    this.model = this.tf.sequential();
    for (const [index, layerConfig] of this.config.modelConfig.layers.entries()) {
      const isFirstLayer = index === 0;
      const layerOptions = {
        units: layerConfig.units,
        activation: layerConfig.activation || "relu",
        useBias: true
      };
      if (isFirstLayer) {
        layerOptions.inputShape = [numFeatures];
      }
      this.model.add(this.tf.layers.dense(layerOptions));
      if (layerConfig.dropout && layerConfig.dropout > 0) {
        this.model.add(this.tf.layers.dropout({
          rate: layerConfig.dropout
        }));
      }
      if (layerConfig.batchNormalization) {
        this.model.add(this.tf.layers.batchNormalization());
      }
    }
    this.model.add(this.tf.layers.dense({
      units: this.config.modelConfig.outputUnits,
      activation: this.config.modelConfig.outputActivation
    }));
    this.model.compile({
      optimizer: this.tf.train.adam(this.config.modelConfig.learningRate),
      loss: this.config.modelConfig.loss,
      metrics: this.config.modelConfig.metrics
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] ${this.config.name} - Built custom neural network:`);
      console.log(`  - Hidden layers: ${this.config.modelConfig.layers.length}`);
      console.log(`  - Total parameters:`, this._countParameters());
      this.model.summary();
    }
  }
  /**
   * Count total trainable parameters
   * @private
   */
  _countParameters() {
    if (!this.model) return 0;
    let totalParams = 0;
    for (const layer of this.model.layers) {
      if (layer.countParams) {
        totalParams += layer.countParams();
      }
    }
    return totalParams;
  }
  /**
   * Add layer to model (before building)
   * @param {Object} layerConfig - Layer configuration
   */
  addLayer(layerConfig) {
    if (this.model) {
      throw new ModelConfigError(
        "Cannot add layer after model is built. Use addLayer() before training.",
        { model: this.config.name }
      );
    }
    this.config.modelConfig.layers.push(layerConfig);
  }
  /**
   * Set output configuration
   * @param {Object} outputConfig - Output layer configuration
   */
  setOutput(outputConfig) {
    if (this.model) {
      throw new ModelConfigError(
        "Cannot change output after model is built. Use setOutput() before training.",
        { model: this.config.name }
      );
    }
    if (outputConfig.activation) {
      this.config.modelConfig.outputActivation = outputConfig.activation;
    }
    if (outputConfig.units) {
      this.config.modelConfig.outputUnits = outputConfig.units;
    }
    if (outputConfig.loss) {
      this.config.modelConfig.loss = outputConfig.loss;
    }
    if (outputConfig.metrics) {
      this.config.modelConfig.metrics = outputConfig.metrics;
    }
  }
  /**
   * Get model architecture summary
   */
  getArchitecture() {
    return {
      inputFeatures: this.config.features,
      hiddenLayers: this.config.modelConfig.layers.map((layer, index) => ({
        index,
        units: layer.units,
        activation: layer.activation || "relu",
        dropout: layer.dropout || 0,
        batchNormalization: layer.batchNormalization || false
      })),
      outputLayer: {
        units: this.config.modelConfig.outputUnits,
        activation: this.config.modelConfig.outputActivation
      },
      totalParameters: this._countParameters(),
      loss: this.config.modelConfig.loss,
      metrics: this.config.modelConfig.metrics
    };
  }
  /**
   * Train with early stopping callback
   * @param {Array} data - Training data
   * @param {Object} earlyStoppingConfig - Early stopping configuration
   * @returns {Object} Training results
   */
  async trainWithEarlyStopping(data, earlyStoppingConfig = {}) {
    const {
      patience = 10,
      minDelta = 1e-3,
      monitor = "val_loss",
      restoreBestWeights = true
    } = earlyStoppingConfig;
    const { xs, ys } = this._prepareData(data);
    if (!this.model) {
      this.buildModel();
    }
    let bestValue = Infinity;
    let patienceCounter = 0;
    let bestWeights = null;
    const callbacks = {
      onEpochEnd: async (epoch, logs) => {
        const monitorValue = logs[monitor] || logs.loss;
        if (this.config.verbose && epoch % 10 === 0) {
          console.log(`[MLPlugin] ${this.config.name} - Epoch ${epoch}: ${monitor}=${monitorValue.toFixed(4)}`);
        }
        if (monitorValue < bestValue - minDelta) {
          bestValue = monitorValue;
          patienceCounter = 0;
          if (restoreBestWeights) {
            bestWeights = await this.model.getWeights();
          }
        } else {
          patienceCounter++;
          if (patienceCounter >= patience) {
            if (this.config.verbose) {
              console.log(`[MLPlugin] ${this.config.name} - Early stopping at epoch ${epoch}`);
            }
            this.model.stopTraining = true;
          }
        }
      }
    };
    const history = await this.model.fit(xs, ys, {
      epochs: this.config.modelConfig.epochs,
      batchSize: this.config.modelConfig.batchSize,
      validationSplit: this.config.modelConfig.validationSplit,
      verbose: this.config.verbose ? 1 : 0,
      callbacks
    });
    if (restoreBestWeights && bestWeights) {
      this.model.setWeights(bestWeights);
    }
    this.isTrained = true;
    this.stats.trainedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.stats.samples = data.length;
    this.stats.loss = history.history.loss[history.history.loss.length - 1];
    xs.dispose();
    ys.dispose();
    return {
      loss: this.stats.loss,
      epochs: history.epoch.length,
      samples: this.stats.samples,
      stoppedEarly: history.epoch.length < this.config.modelConfig.epochs
    };
  }
  /**
   * Export model with neural network-specific data
   */
  async export() {
    const baseExport = await super.export();
    return {
      ...baseExport,
      type: "neural-network",
      architecture: this.getArchitecture()
    };
  }
}

class MLPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      models: options.models || {},
      verbose: options.verbose || false,
      minTrainingSamples: options.minTrainingSamples || 10,
      saveModel: options.saveModel !== false,
      // Default true
      saveTrainingData: options.saveTrainingData || false,
      enableVersioning: options.enableVersioning !== false
      // Default true
    };
    this.models = {};
    this._dependenciesValidated = false;
    this.modelVersions = /* @__PURE__ */ new Map();
    this.modelCache = /* @__PURE__ */ new Map();
    this.training = /* @__PURE__ */ new Map();
    this.insertCounters = /* @__PURE__ */ new Map();
    this.intervals = [];
    this.stats = {
      totalTrainings: 0,
      totalPredictions: 0,
      totalErrors: 0,
      startedAt: null
    };
  }
  /**
   * Install the plugin
   */
  async onInstall() {
    if (this.config.verbose) {
      console.log("[MLPlugin] Installing ML Plugin...");
    }
    if (!this._dependenciesValidated) {
      const result = await requirePluginDependency("ml-plugin", {
        throwOnError: false,
        checkVersions: true
      });
      if (!result.valid) {
        try {
          await import('@tensorflow/tfjs-node');
          if (this.config.verbose) {
            console.log("[MLPlugin] TensorFlow.js loaded successfully (fallback import)");
          }
        } catch (err) {
          throw new TensorFlowDependencyError(
            "TensorFlow.js dependency not found. Install with: pnpm add @tensorflow/tfjs-node\n" + result.messages.join("\n")
          );
        }
      }
      this._dependenciesValidated = true;
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      this._validateModelConfig(modelName, modelConfig);
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      await this._initializeModel(modelName, modelConfig);
    }
    this._buildModelCache();
    this._injectResourceMethods();
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.autoTrain) {
        this._setupAutoTraining(modelName, modelConfig);
      }
    }
    this.stats.startedAt = (/* @__PURE__ */ new Date()).toISOString();
    if (this.config.verbose) {
      console.log(`[MLPlugin] Installed with ${Object.keys(this.models).length} models`);
    }
    this.emit("db:plugin:installed", {
      plugin: "MLPlugin",
      models: Object.keys(this.models)
    });
  }
  /**
   * Start the plugin
   */
  async onStart() {
    if (this.config.enableVersioning) {
      for (const modelName of Object.keys(this.models)) {
        await this._initializeVersioning(modelName);
      }
    }
    for (const modelName of Object.keys(this.models)) {
      await this._loadModel(modelName);
    }
    if (this.config.verbose) {
      console.log("[MLPlugin] Started");
    }
  }
  /**
   * Stop the plugin
   */
  async onStop() {
    for (const handle of this.intervals) {
      clearInterval(handle);
    }
    this.intervals = [];
    for (const [modelName, model] of Object.entries(this.models)) {
      if (model && model.dispose) {
        model.dispose();
      }
    }
    if (this.config.verbose) {
      console.log("[MLPlugin] Stopped");
    }
  }
  /**
   * Uninstall the plugin
   */
  async onUninstall(options = {}) {
    await this.onStop();
    if (options.purgeData) {
      for (const modelName of Object.keys(this.models)) {
        await this._deleteModel(modelName);
        await this._deleteTrainingData(modelName);
      }
      if (this.config.verbose) {
        console.log("[MLPlugin] Purged all model data and training data");
      }
    }
  }
  /**
   * Build model cache for fast lookup
   * @private
   */
  _buildModelCache() {
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      const cacheKey = `${modelConfig.resource}_${modelConfig.target}`;
      this.modelCache.set(cacheKey, modelName);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Cached model "${modelName}" for ${modelConfig.resource}.predict(..., '${modelConfig.target}')`);
      }
    }
  }
  /**
   * Inject ML methods into Resource instances
   * @private
   */
  _injectResourceMethods() {
    if (!this.database._mlPlugin) {
      this.database._mlPlugin = this;
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "ml")) {
      Object.defineProperty(Resource.prototype, "ml", {
        get() {
          const resource = this;
          const mlPlugin = resource.database?._mlPlugin;
          if (!mlPlugin) {
            throw new Error("MLPlugin not installed");
          }
          return {
            /**
             * Auto-setup and train ML model (zero-config)
             * @param {string} target - Target attribute to predict
             * @param {Object} options - Configuration options
             * @returns {Promise<Object>} Training results
             */
            learn: async (target, options = {}) => {
              return await mlPlugin._resourceLearn(resource.name, target, options);
            },
            /**
             * Make prediction
             * @param {Object} input - Input features
             * @param {string} target - Target attribute
             * @returns {Promise<Object>} Prediction result
             */
            predict: async (input, target) => {
              return await mlPlugin._resourcePredict(resource.name, input, target);
            },
            /**
             * Train model manually
             * @param {string} target - Target attribute
             * @param {Object} options - Training options
             * @returns {Promise<Object>} Training results
             */
            train: async (target, options = {}) => {
              return await mlPlugin._resourceTrainModel(resource.name, target, options);
            },
            /**
             * List all models for this resource
             * @returns {Array} List of models
             */
            list: () => {
              return mlPlugin._resourceListModels(resource.name);
            },
            /**
             * List model versions
             * @param {string} target - Target attribute
             * @returns {Promise<Array>} List of versions
             */
            versions: async (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.listModelVersions(modelName);
            },
            /**
             * Rollback to previous version
             * @param {string} target - Target attribute
             * @param {number} version - Version to rollback to (optional)
             * @returns {Promise<Object>} Rollback info
             */
            rollback: async (target, version = null) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.rollbackVersion(modelName, version);
            },
            /**
             * Compare two versions
             * @param {string} target - Target attribute
             * @param {number} v1 - First version
             * @param {number} v2 - Second version
             * @returns {Promise<Object>} Comparison results
             */
            compare: async (target, v1, v2) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.compareVersions(modelName, v1, v2);
            },
            /**
             * Get model statistics
             * @param {string} target - Target attribute
             * @returns {Object} Model stats
             */
            stats: (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return mlPlugin.getModelStats(modelName);
            },
            /**
             * Export model
             * @param {string} target - Target attribute
             * @returns {Promise<Object>} Exported model
             */
            export: async (target) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.exportModel(modelName);
            },
            /**
             * Import model
             * @param {string} target - Target attribute
             * @param {Object} data - Model data
             * @returns {Promise<void>}
             */
            import: async (target, data) => {
              const modelName = mlPlugin._findModelForResource(resource.name, target);
              if (!modelName) {
                throw new ModelNotFoundError(
                  `No model found for resource "${resource.name}" with target "${target}"`,
                  { resourceName: resource.name, targetAttribute: target }
                );
              }
              return await mlPlugin.importModel(modelName, data);
            }
          };
        },
        configurable: true
      });
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "predict")) {
      Resource.prototype.predict = async function(input, targetAttribute) {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new Error("MLPlugin not installed");
        }
        return await mlPlugin._resourcePredict(this.name, input, targetAttribute);
      };
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "trainModel")) {
      Resource.prototype.trainModel = async function(targetAttribute, options = {}) {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new Error("MLPlugin not installed");
        }
        return await mlPlugin._resourceTrainModel(this.name, targetAttribute, options);
      };
    }
    if (!Object.prototype.hasOwnProperty.call(Resource.prototype, "listModels")) {
      Resource.prototype.listModels = function() {
        const mlPlugin = this.database?._mlPlugin;
        if (!mlPlugin) {
          throw new Error("MLPlugin not installed");
        }
        return mlPlugin._resourceListModels(this.name);
      };
    }
    if (this.config.verbose) {
      console.log("[MLPlugin] Injected ML namespace (resource.ml.*) into Resource prototype");
    }
  }
  /**
   * Find model for a resource and target attribute
   * @private
   */
  _findModelForResource(resourceName, targetAttribute) {
    const cacheKey = `${resourceName}_${targetAttribute}`;
    if (this.modelCache.has(cacheKey)) {
      return this.modelCache.get(cacheKey);
    }
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.resource === resourceName && modelConfig.target === targetAttribute) {
        this.modelCache.set(cacheKey, modelName);
        return modelName;
      }
    }
    return null;
  }
  /**
   * Auto-setup and train ML model (resource.ml.learn implementation)
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute to predict
   * @param {Object} options - Configuration options
   * @returns {Promise<Object>} Training results
   * @private
   */
  async _resourceLearn(resourceName, target, options = {}) {
    let modelName = this._findModelForResource(resourceName, target);
    if (modelName) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Model "${modelName}" already exists, retraining...`);
      }
      return await this.train(modelName, options);
    }
    modelName = `${resourceName}_${target}_auto`;
    if (this.config.verbose) {
      console.log(`[MLPlugin] Auto-creating model "${modelName}" for ${resourceName}.${target}...`);
    }
    const resource = this.database.resources[resourceName];
    if (!resource) {
      throw new ModelConfigError(
        `Resource "${resourceName}" not found`,
        { resourceName, availableResources: Object.keys(this.database.resources) }
      );
    }
    let modelType = options.type;
    if (!modelType) {
      modelType = await this._autoDetectType(resourceName, target);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-detected type: ${modelType}`);
      }
    }
    let features = options.features;
    if (!features || features.length === 0) {
      features = await this._autoSelectFeatures(resourceName, target);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-selected features: ${features.join(", ")}`);
      }
    }
    const [samplesOk, samplesErr, sampleData] = await tryFn(() => resource.list());
    const sampleCount = samplesOk && sampleData ? sampleData.length : 0;
    let defaultModelConfig = this._getDefaultModelConfig(modelType);
    const userProvidedBatchSize = options.modelConfig && options.modelConfig.batchSize !== void 0;
    if (!userProvidedBatchSize && sampleCount > 0 && sampleCount < defaultModelConfig.batchSize) {
      defaultModelConfig.batchSize = Math.max(4, Math.floor(sampleCount / 2));
      if (this.config.verbose) {
        console.log(`[MLPlugin] Auto-adjusted batchSize to ${defaultModelConfig.batchSize} based on ${sampleCount} samples`);
      }
    }
    const customModelConfig = options.modelConfig || {};
    const mergedModelConfig = {
      ...defaultModelConfig,
      ...customModelConfig,
      // Preserve auto-adjusted batchSize if user didn't provide one
      ...!userProvidedBatchSize && { batchSize: defaultModelConfig.batchSize }
    };
    const modelConfig = {
      type: modelType,
      resource: resourceName,
      features,
      target,
      autoTrain: options.autoTrain !== void 0 ? options.autoTrain : false,
      saveModel: options.saveModel !== void 0 ? options.saveModel : true,
      saveTrainingData: options.saveTrainingData !== void 0 ? options.saveTrainingData : false,
      modelConfig: mergedModelConfig,
      ...options
    };
    this.config.models[modelName] = modelConfig;
    await this._initializeModel(modelName, modelConfig);
    this._buildModelCache();
    if (this.config.verbose) {
      console.log(`[MLPlugin] Training model "${modelName}"...`);
    }
    const result = await this.train(modelName, options);
    if (this.config.verbose) {
      console.log(`[MLPlugin] \u2705 Model "${modelName}" ready!`);
    }
    return {
      modelName,
      type: modelType,
      features,
      target,
      ...result
    };
  }
  /**
   * Auto-detect model type based on target attribute
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute
   * @returns {Promise<string>} Model type
   * @private
   */
  async _autoDetectType(resourceName, target) {
    const resource = this.database.resources[resourceName];
    const [ok, err, samples] = await tryFn(() => resource.list({ limit: 100 }));
    if (!ok || !samples || samples.length === 0) {
      return "regression";
    }
    const targetValues = samples.map((s) => s[target]).filter((v) => v != null);
    if (targetValues.length === 0) {
      return "regression";
    }
    const isNumeric = targetValues.every((v) => typeof v === "number");
    if (isNumeric) {
      const hasTimestamp = samples.every((s) => s.timestamp || s.createdAt || s.date);
      if (hasTimestamp) {
        return "timeseries";
      }
      return "regression";
    }
    const isCategorical = targetValues.every((v) => typeof v === "string" || typeof v === "boolean");
    if (isCategorical) {
      return "classification";
    }
    return "regression";
  }
  /**
   * Auto-select best features for prediction
   * @param {string} resourceName - Resource name
   * @param {string} target - Target attribute
   * @returns {Promise<Array>} Selected features
   * @private
   */
  async _autoSelectFeatures(resourceName, target) {
    const resource = this.database.resources[resourceName];
    const schema = resource.schema;
    const attributes = schema?.attributes || {};
    const numericFields = [];
    for (const [fieldName, fieldDef] of Object.entries(attributes)) {
      if (fieldName === target) continue;
      if (["id", "createdAt", "updatedAt", "createdBy"].includes(fieldName)) continue;
      const fieldType = typeof fieldDef === "string" ? fieldDef.split("|")[0] : fieldDef.type;
      if (fieldType === "number" || fieldType === "integer" || fieldType === "float") {
        numericFields.push(fieldName);
      }
    }
    if (numericFields.length === 0) {
      const [ok, err, samples] = await tryFn(() => resource.list({ limit: 10 }));
      if (ok && samples && samples.length > 0) {
        const firstSample = samples[0];
        for (const [key, value] of Object.entries(firstSample)) {
          if (key === target) continue;
          if (["id", "createdAt", "updatedAt", "createdBy"].includes(key)) continue;
          if (typeof value === "number") {
            numericFields.push(key);
          }
        }
      }
    }
    if (numericFields.length === 0) {
      throw new ModelConfigError(
        `No numeric features found for target "${target}" in resource "${resourceName}"`,
        { resourceName, target, availableAttributes: Object.keys(attributes) }
      );
    }
    return numericFields;
  }
  /**
   * Get default model config for type
   * @param {string} type - Model type
   * @returns {Object} Default config
   * @private
   */
  _getDefaultModelConfig(type) {
    const defaults = {
      regression: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        polynomial: 1
      },
      classification: {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        units: 64,
        dropout: 0.2
      },
      timeseries: {
        epochs: 50,
        batchSize: 16,
        learningRate: 1e-3,
        validationSplit: 0.2,
        lookback: 10,
        lstmUnits: 50
      },
      "neural-network": {
        epochs: 50,
        batchSize: 32,
        learningRate: 0.01,
        validationSplit: 0.2,
        layers: [
          { units: 64, activation: "relu", dropout: 0.2 },
          { units: 32, activation: "relu" }
        ]
      }
    };
    return defaults[type] || defaults.regression;
  }
  /**
   * Resource predict implementation
   * @private
   */
  async _resourcePredict(resourceName, input, targetAttribute) {
    const modelName = this._findModelForResource(resourceName, targetAttribute);
    if (!modelName) {
      throw new ModelNotFoundError(
        `No model found for resource "${resourceName}" with target "${targetAttribute}"`,
        { resourceName, targetAttribute, availableModels: Object.keys(this.models) }
      );
    }
    if (this.config.verbose) {
      console.log(`[MLPlugin] Resource prediction: ${resourceName}.predict(..., '${targetAttribute}') -> model "${modelName}"`);
    }
    return await this.predict(modelName, input);
  }
  /**
   * Resource trainModel implementation
   * @private
   */
  async _resourceTrainModel(resourceName, targetAttribute, options = {}) {
    const modelName = this._findModelForResource(resourceName, targetAttribute);
    if (!modelName) {
      throw new ModelNotFoundError(
        `No model found for resource "${resourceName}" with target "${targetAttribute}"`,
        { resourceName, targetAttribute, availableModels: Object.keys(this.models) }
      );
    }
    if (this.config.verbose) {
      console.log(`[MLPlugin] Resource training: ${resourceName}.trainModel('${targetAttribute}') -> model "${modelName}"`);
    }
    return await this.train(modelName, options);
  }
  /**
   * List models for a resource
   * @private
   */
  _resourceListModels(resourceName) {
    const models = [];
    for (const [modelName, modelConfig] of Object.entries(this.config.models)) {
      if (modelConfig.resource === resourceName) {
        models.push({
          name: modelName,
          type: modelConfig.type,
          target: modelConfig.target,
          features: modelConfig.features,
          isTrained: this.models[modelName]?.isTrained || false
        });
      }
    }
    return models;
  }
  /**
   * Validate model configuration
   * @private
   */
  _validateModelConfig(modelName, config) {
    const validTypes = ["regression", "classification", "timeseries", "neural-network"];
    if (!config.type || !validTypes.includes(config.type)) {
      throw new ModelConfigError(
        `Model "${modelName}" must have a valid type: ${validTypes.join(", ")}`,
        { modelName, type: config.type, validTypes }
      );
    }
    if (!config.resource) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify a resource`,
        { modelName }
      );
    }
    if (!config.features || !Array.isArray(config.features) || config.features.length === 0) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify at least one feature`,
        { modelName, features: config.features }
      );
    }
    if (!config.target) {
      throw new ModelConfigError(
        `Model "${modelName}" must specify a target field`,
        { modelName }
      );
    }
  }
  /**
   * Initialize a model instance
   * @private
   */
  async _initializeModel(modelName, config) {
    const modelOptions = {
      name: modelName,
      resource: config.resource,
      features: config.features,
      target: config.target,
      modelConfig: config.modelConfig || {},
      verbose: this.config.verbose
    };
    try {
      switch (config.type) {
        case "regression":
          this.models[modelName] = new RegressionModel(modelOptions);
          break;
        case "classification":
          this.models[modelName] = new ClassificationModel(modelOptions);
          break;
        case "timeseries":
          this.models[modelName] = new TimeSeriesModel(modelOptions);
          break;
        case "neural-network":
          this.models[modelName] = new NeuralNetworkModel(modelOptions);
          break;
        default:
          throw new ModelConfigError(
            `Unknown model type: ${config.type}`,
            { modelName, type: config.type }
          );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Initialized model "${modelName}" (${config.type})`);
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to initialize model "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Setup auto-training for a model
   * @private
   */
  _setupAutoTraining(modelName, config) {
    const resource = this.database.resources[config.resource];
    if (!resource) {
      console.warn(`[MLPlugin] Resource "${config.resource}" not found for model "${modelName}"`);
      return;
    }
    this.insertCounters.set(modelName, 0);
    if (config.trainAfterInserts && config.trainAfterInserts > 0) {
      this.addMiddleware(resource, "insert", async (next, data, options) => {
        const result = await next(data, options);
        const currentCount = this.insertCounters.get(modelName) || 0;
        this.insertCounters.set(modelName, currentCount + 1);
        if (this.insertCounters.get(modelName) >= config.trainAfterInserts) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] Auto-training "${modelName}" after ${config.trainAfterInserts} inserts`);
          }
          this.insertCounters.set(modelName, 0);
          this.train(modelName).catch((err) => {
            console.error(`[MLPlugin] Auto-training failed for "${modelName}":`, err.message);
          });
        }
        return result;
      });
    }
    if (config.trainInterval && config.trainInterval > 0) {
      const handle = setInterval(async () => {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Auto-training "${modelName}" (interval: ${config.trainInterval}ms)`);
        }
        try {
          await this.train(modelName);
        } catch (error) {
          console.error(`[MLPlugin] Auto-training failed for "${modelName}":`, error.message);
        }
      }, config.trainInterval);
      this.intervals.push(handle);
      if (this.config.verbose) {
        console.log(`[MLPlugin] Setup interval training for "${modelName}" (every ${config.trainInterval}ms)`);
      }
    }
  }
  /**
   * Train a model
   * @param {string} modelName - Model name
   * @param {Object} options - Training options
   * @returns {Object} Training results
   */
  async train(modelName, options = {}) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    if (this.training.get(modelName)) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Model "${modelName}" is already training, skipping...`);
      }
      return { skipped: true, reason: "already_training" };
    }
    this.training.set(modelName, true);
    try {
      const modelConfig = this.config.models[modelName];
      const resource = this.database.resources[modelConfig.resource];
      if (!resource) {
        throw new ModelNotFoundError(
          `Resource "${modelConfig.resource}" not found`,
          { modelName, resource: modelConfig.resource }
        );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Fetching training data for "${modelName}"...`);
      }
      let data;
      const partition = modelConfig.partition;
      if (partition && partition.name) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Using partition "${partition.name}" with values:`, partition.values);
        }
        const [ok, err, partitionData] = await tryFn(
          () => resource.listPartition(partition.name, partition.values)
        );
        if (!ok) {
          throw new TrainingError(
            `Failed to fetch training data from partition: ${err.message}`,
            { modelName, resource: modelConfig.resource, partition: partition.name, originalError: err.message }
          );
        }
        data = partitionData;
      } else {
        const [ok, err, allData] = await tryFn(() => resource.list());
        if (!ok) {
          throw new TrainingError(
            `Failed to fetch training data: ${err.message}`,
            { modelName, resource: modelConfig.resource, originalError: err.message }
          );
        }
        data = allData;
      }
      if (modelConfig.filter && typeof modelConfig.filter === "function") {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Applying custom filter function...`);
        }
        const originalLength = data.length;
        data = data.filter(modelConfig.filter);
        if (this.config.verbose) {
          console.log(`[MLPlugin] Filter reduced dataset from ${originalLength} to ${data.length} samples`);
        }
      }
      if (modelConfig.map && typeof modelConfig.map === "function") {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Applying custom map function...`);
        }
        data = data.map(modelConfig.map);
      }
      if (!data || data.length < this.config.minTrainingSamples) {
        throw new TrainingError(
          `Insufficient training data: ${data?.length || 0} samples (minimum: ${this.config.minTrainingSamples})`,
          { modelName, samples: data?.length || 0, minimum: this.config.minTrainingSamples }
        );
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Training "${modelName}" with ${data.length} samples...`);
      }
      const shouldSaveTrainingData = modelConfig.saveTrainingData !== void 0 ? modelConfig.saveTrainingData : this.config.saveTrainingData;
      if (shouldSaveTrainingData) {
        await this._saveTrainingData(modelName, data);
      }
      const result = await model.train(data);
      const shouldSaveModel = modelConfig.saveModel !== void 0 ? modelConfig.saveModel : this.config.saveModel;
      if (shouldSaveModel) {
        await this._saveModel(modelName);
      }
      this.stats.totalTrainings++;
      if (this.config.verbose) {
        console.log(`[MLPlugin] Training completed for "${modelName}":`, result);
      }
      this.emit("plg:ml:model-trained", {
        modelName,
        type: modelConfig.type,
        result
      });
      return result;
    } catch (error) {
      this.stats.totalErrors++;
      if (error instanceof MLError) {
        throw error;
      }
      throw new TrainingError(
        `Training failed for "${modelName}": ${error.message}`,
        { modelName, originalError: error.message }
      );
    } finally {
      this.training.set(modelName, false);
    }
  }
  /**
   * Make a prediction
   * @param {string} modelName - Model name
   * @param {Object|Array} input - Input data (object for single prediction, array for time series)
   * @returns {Object} Prediction result
   */
  async predict(modelName, input) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    try {
      const result = await model.predict(input);
      this.stats.totalPredictions++;
      this.emit("plg:ml:prediction", {
        modelName,
        input,
        result
      });
      return result;
    } catch (error) {
      this.stats.totalErrors++;
      throw error;
    }
  }
  /**
   * Make predictions for multiple inputs
   * @param {string} modelName - Model name
   * @param {Array} inputs - Array of input objects
   * @returns {Array} Array of prediction results
   */
  async predictBatch(modelName, inputs) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return await model.predictBatch(inputs);
  }
  /**
   * Retrain a model (reset and train from scratch)
   * @param {string} modelName - Model name
   * @param {Object} options - Options
   * @returns {Object} Training results
   */
  async retrain(modelName, options = {}) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    if (model.dispose) {
      model.dispose();
    }
    const modelConfig = this.config.models[modelName];
    await this._initializeModel(modelName, modelConfig);
    return await this.train(modelName, options);
  }
  /**
   * Get model statistics
   * @param {string} modelName - Model name
   * @returns {Object} Model stats
   */
  getModelStats(modelName) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return model.getStats();
  }
  /**
   * Get plugin statistics
   * @returns {Object} Plugin stats
   */
  getStats() {
    return {
      ...this.stats,
      models: Object.keys(this.models).length,
      trainedModels: Object.values(this.models).filter((m) => m.isTrained).length
    };
  }
  /**
   * Export a model
   * @param {string} modelName - Model name
   * @returns {Object} Serialized model
   */
  async exportModel(modelName) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    return await model.export();
  }
  /**
   * Import a model
   * @param {string} modelName - Model name
   * @param {Object} data - Serialized model data
   */
  async importModel(modelName, data) {
    const model = this.models[modelName];
    if (!model) {
      throw new ModelNotFoundError(
        `Model "${modelName}" not found`,
        { modelName, availableModels: Object.keys(this.models) }
      );
    }
    await model.import(data);
    await this._saveModel(modelName);
    if (this.config.verbose) {
      console.log(`[MLPlugin] Imported model "${modelName}"`);
    }
  }
  /**
   * Initialize versioning for a model
   * @private
   */
  async _initializeVersioning(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, versionInfo] = await tryFn(
        () => storage.get(storage.getPluginKey(resourceName, "metadata", modelName, "versions"))
      );
      if (ok && versionInfo) {
        this.modelVersions.set(modelName, {
          currentVersion: versionInfo.currentVersion || 1,
          latestVersion: versionInfo.latestVersion || 1
        });
        if (this.config.verbose) {
          console.log(`[MLPlugin] Loaded version info for "${modelName}": v${versionInfo.currentVersion}`);
        }
      } else {
        this.modelVersions.set(modelName, {
          currentVersion: 1,
          latestVersion: 0
          // No versions yet
        });
        if (this.config.verbose) {
          console.log(`[MLPlugin] Initialized versioning for "${modelName}"`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to initialize versioning for "${modelName}":`, error.message);
      this.modelVersions.set(modelName, { currentVersion: 1, latestVersion: 0 });
    }
  }
  /**
   * Get next version number for a model
   * @private
   */
  _getNextVersion(modelName) {
    const versionInfo = this.modelVersions.get(modelName) || { latestVersion: 0 };
    return versionInfo.latestVersion + 1;
  }
  /**
   * Update version info in storage
   * @private
   */
  async _updateVersionInfo(modelName, version) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const versionInfo = this.modelVersions.get(modelName) || { currentVersion: 1, latestVersion: 0 };
      versionInfo.latestVersion = Math.max(versionInfo.latestVersion, version);
      versionInfo.currentVersion = version;
      this.modelVersions.set(modelName, versionInfo);
      await storage.set(
        storage.getPluginKey(resourceName, "metadata", modelName, "versions"),
        {
          modelName,
          currentVersion: versionInfo.currentVersion,
          latestVersion: versionInfo.latestVersion,
          updatedAt: (/* @__PURE__ */ new Date()).toISOString()
        },
        { behavior: "body-overflow" }
      );
      if (this.config.verbose) {
        console.log(`[MLPlugin] Updated version info for "${modelName}": current=v${versionInfo.currentVersion}, latest=v${versionInfo.latestVersion}`);
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to update version info for "${modelName}":`, error.message);
    }
  }
  /**
   * Save model to plugin storage
   * @private
   */
  async _saveModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const exportedModel = await this.models[modelName].export();
      if (!exportedModel) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] Model "${modelName}" not trained, skipping save`);
        }
        return;
      }
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const version = this._getNextVersion(modelName);
        const modelStats = this.models[modelName].getStats();
        await storage.set(
          storage.getPluginKey(resourceName, "models", modelName, `v${version}`),
          {
            modelName,
            version,
            type: "model",
            modelData: exportedModel,
            // TensorFlow.js model object (will go to body)
            metrics: {
              loss: modelStats.loss,
              accuracy: modelStats.accuracy,
              samples: modelStats.samples
            },
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-only" }
          // Large binary data goes to S3 body
        );
        await this._updateVersionInfo(modelName, version);
        await storage.set(
          storage.getPluginKey(resourceName, "metadata", modelName, "active"),
          {
            modelName,
            version,
            type: "reference",
            updatedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-overflow" }
          // Small metadata
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved model "${modelName}" v${version} to S3 (resource=${resourceName}/plugin=ml/models/${modelName}/v${version})`);
        }
      } else {
        await storage.set(
          storage.getPluginKey(resourceName, "models", modelName, "latest"),
          {
            modelName,
            type: "model",
            modelData: exportedModel,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-only" }
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved model "${modelName}" to S3 (resource=${resourceName}/plugin=ml/models/${modelName}/latest)`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to save model "${modelName}":`, error.message);
    }
  }
  /**
   * Save intermediate training data to plugin storage (incremental - only new samples)
   * @private
   */
  async _saveTrainingData(modelName, rawData) {
    try {
      const storage = this.getStorage();
      const model = this.models[modelName];
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const modelStats = model.getStats();
      const enableVersioning = this.config.enableVersioning;
      const processedData = rawData.map((item) => {
        const features = {};
        modelConfig.features.forEach((feature) => {
          features[feature] = item[feature];
        });
        return {
          id: item.id || `${Date.now()}_${Math.random()}`,
          // Use record ID or generate
          features,
          target: item[modelConfig.target]
        };
      });
      if (enableVersioning) {
        const version = this._getNextVersion(modelName);
        const [ok, err, existing] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
        );
        let history = [];
        let previousSampleIds = /* @__PURE__ */ new Set();
        if (ok && existing && existing.history) {
          history = existing.history;
          history.forEach((entry) => {
            if (entry.sampleIds) {
              entry.sampleIds.forEach((id) => previousSampleIds.add(id));
            }
          });
        }
        const currentSampleIds = new Set(processedData.map((d) => d.id));
        const newSamples = processedData.filter((d) => !previousSampleIds.has(d.id));
        const newSampleIds = newSamples.map((d) => d.id);
        if (newSamples.length > 0) {
          await storage.set(
            storage.getPluginKey(resourceName, "training", "data", modelName, `v${version}`),
            {
              modelName,
              version,
              samples: newSamples,
              // Only new samples
              features: modelConfig.features,
              target: modelConfig.target,
              savedAt: (/* @__PURE__ */ new Date()).toISOString()
            },
            { behavior: "body-only" }
            // Dataset goes to S3 body
          );
        }
        const historyEntry = {
          version,
          totalSamples: processedData.length,
          // Total cumulative
          newSamples: newSamples.length,
          // Only new in this version
          sampleIds: Array.from(currentSampleIds),
          // All IDs for this version
          newSampleIds,
          // IDs of new samples
          storageKey: newSamples.length > 0 ? `training/data/${modelName}/v${version}` : null,
          metrics: {
            loss: modelStats.loss,
            accuracy: modelStats.accuracy,
            r2: modelStats.r2
          },
          trainedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        history.push(historyEntry);
        await storage.set(
          storage.getPluginKey(resourceName, "training", "history", modelName),
          {
            modelName,
            type: "training_history",
            totalTrainings: history.length,
            latestVersion: version,
            history,
            // Array of metadata entries (not full data)
            updatedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-overflow" }
          // History metadata
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved training data for "${modelName}" v${version}: ${newSamples.length} new samples (total: ${processedData.length}, storage: resource=${resourceName}/plugin=ml/training/data/${modelName}/v${version})`);
        }
      } else {
        await storage.set(
          storage.getPluginKey(resourceName, "training", "data", modelName, "latest"),
          {
            modelName,
            type: "training_data",
            samples: processedData,
            features: modelConfig.features,
            target: modelConfig.target,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          { behavior: "body-only" }
        );
        if (this.config.verbose) {
          console.log(`[MLPlugin] Saved training data for "${modelName}" (${processedData.length} samples) to S3 (resource=${resourceName}/plugin=ml/training/data/${modelName}/latest)`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to save training data for "${modelName}":`, error.message);
    }
  }
  /**
   * Load model from plugin storage
   * @private
   */
  async _loadModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const [okRef, errRef, activeRef] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "metadata", modelName, "active"))
        );
        if (okRef && activeRef && activeRef.version) {
          const version = activeRef.version;
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`))
          );
          if (ok && versionData && versionData.modelData) {
            await this.models[modelName].import(versionData.modelData);
            if (this.config.verbose) {
              console.log(`[MLPlugin] Loaded model "${modelName}" v${version} (active) from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/v${version})`);
            }
            return;
          }
        }
        const versionInfo = this.modelVersions.get(modelName);
        if (versionInfo && versionInfo.latestVersion > 0) {
          const version = versionInfo.latestVersion;
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`))
          );
          if (ok && versionData && versionData.modelData) {
            await this.models[modelName].import(versionData.modelData);
            if (this.config.verbose) {
              console.log(`[MLPlugin] Loaded model "${modelName}" v${version} (latest) from S3`);
            }
            return;
          }
        }
        if (this.config.verbose) {
          console.log(`[MLPlugin] No saved model versions found for "${modelName}"`);
        }
      } else {
        const [ok, err, record] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "models", modelName, "latest"))
        );
        if (!ok || !record || !record.modelData) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] No saved model found for "${modelName}"`);
          }
          return;
        }
        await this.models[modelName].import(record.modelData);
        if (this.config.verbose) {
          console.log(`[MLPlugin] Loaded model "${modelName}" from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/latest)`);
        }
      }
    } catch (error) {
      console.error(`[MLPlugin] Failed to load model "${modelName}":`, error.message);
    }
  }
  /**
   * Load training data from plugin storage (reconstructs specific version from incremental data)
   * @param {string} modelName - Model name
   * @param {number} version - Version number (optional, defaults to latest)
   * @returns {Object|null} Training data or null if not found
   */
  async getTrainingData(modelName, version = null) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (!enableVersioning) {
        const [ok, err, record] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "data", modelName, "latest"))
        );
        if (!ok || !record) {
          if (this.config.verbose) {
            console.log(`[MLPlugin] No saved training data found for "${modelName}"`);
          }
          return null;
        }
        return {
          modelName: record.modelName,
          samples: record.samples,
          features: record.features,
          target: record.target,
          data: record.samples,
          savedAt: record.savedAt
        };
      }
      const [okHistory, errHistory, historyData] = await tryFn(
        () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
      );
      if (!okHistory || !historyData || !historyData.history) {
        if (this.config.verbose) {
          console.log(`[MLPlugin] No training history found for "${modelName}"`);
        }
        return null;
      }
      const targetVersion = version || historyData.latestVersion;
      const reconstructedSamples = [];
      for (const entry of historyData.history) {
        if (entry.version > targetVersion) break;
        if (entry.storageKey && entry.newSamples > 0) {
          const [ok, err, versionData] = await tryFn(
            () => storage.get(storage.getPluginKey(resourceName, "training", "data", modelName, `v${entry.version}`))
          );
          if (ok && versionData && versionData.samples) {
            reconstructedSamples.push(...versionData.samples);
          }
        }
      }
      const targetEntry = historyData.history.find((e) => e.version === targetVersion);
      return {
        modelName,
        version: targetVersion,
        samples: reconstructedSamples,
        totalSamples: reconstructedSamples.length,
        features: modelConfig.features,
        target: modelConfig.target,
        metrics: targetEntry?.metrics,
        savedAt: targetEntry?.trainedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load training data for "${modelName}":`, error.message);
      return null;
    }
  }
  /**
   * Delete model from plugin storage (all versions)
   * @private
   */
  async _deleteModel(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const versionInfo = this.modelVersions.get(modelName);
        if (versionInfo && versionInfo.latestVersion > 0) {
          for (let v = 1; v <= versionInfo.latestVersion; v++) {
            await storage.delete(storage.getPluginKey(resourceName, "models", modelName, `v${v}`));
          }
        }
        await storage.delete(storage.getPluginKey(resourceName, "metadata", modelName, "active"));
        await storage.delete(storage.getPluginKey(resourceName, "metadata", modelName, "versions"));
      } else {
        await storage.delete(storage.getPluginKey(resourceName, "models", modelName, "latest"));
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Deleted model "${modelName}" from S3 (resource=${resourceName}/plugin=ml/models/${modelName}/)`);
      }
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Could not delete model "${modelName}": ${error.message}`);
      }
    }
  }
  /**
   * Delete training data from plugin storage (all versions)
   * @private
   */
  async _deleteTrainingData(modelName) {
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const enableVersioning = this.config.enableVersioning;
      if (enableVersioning) {
        const [ok, err, historyData] = await tryFn(
          () => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName))
        );
        if (ok && historyData && historyData.history) {
          for (const entry of historyData.history) {
            if (entry.storageKey) {
              await storage.delete(storage.getPluginKey(resourceName, "training", "data", modelName, `v${entry.version}`));
            }
          }
        }
        await storage.delete(storage.getPluginKey(resourceName, "training", "history", modelName));
      } else {
        await storage.delete(storage.getPluginKey(resourceName, "training", "data", modelName, "latest"));
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Deleted training data for "${modelName}" from S3 (resource=${resourceName}/plugin=ml/training/)`);
      }
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[MLPlugin] Could not delete training data "${modelName}": ${error.message}`);
      }
    }
  }
  /**
   * List all versions of a model
   * @param {string} modelName - Model name
   * @returns {Array} List of version info
   */
  async listModelVersions(modelName) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const versionInfo = this.modelVersions.get(modelName) || { latestVersion: 0 };
      const versions = [];
      for (let v = 1; v <= versionInfo.latestVersion; v++) {
        const [ok, err, versionData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${v}`)));
        if (ok && versionData) {
          versions.push({
            version: v,
            savedAt: versionData.savedAt,
            isCurrent: v === versionInfo.currentVersion,
            metrics: versionData.metrics
          });
        }
      }
      return versions;
    } catch (error) {
      console.error(`[MLPlugin] Failed to list versions for "${modelName}":`, error.message);
      return [];
    }
  }
  /**
   * Load a specific version of a model
   * @param {string} modelName - Model name
   * @param {number} version - Version number
   */
  async loadModelVersion(modelName, version) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    if (!this.models[modelName]) {
      throw new ModelNotFoundError(`Model "${modelName}" not found`, { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, versionData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version}`)));
      if (!ok || !versionData) {
        throw new MLError(`Version ${version} not found for model "${modelName}"`, { modelName, version });
      }
      if (!versionData.modelData) {
        throw new MLError(`Model data not found in version ${version}`, { modelName, version });
      }
      await this.models[modelName].import(versionData.modelData);
      const versionInfo = this.modelVersions.get(modelName);
      if (versionInfo) {
        versionInfo.currentVersion = version;
        this.modelVersions.set(modelName, versionInfo);
      }
      if (this.config.verbose) {
        console.log(`[MLPlugin] Loaded model "${modelName}" v${version}`);
      }
      return {
        version,
        metrics: versionData.metrics ? JSON.parse(versionData.metrics) : {},
        savedAt: versionData.savedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load version ${version} for "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Set active version for a model (used for predictions)
   * @param {string} modelName - Model name
   * @param {number} version - Version number
   */
  async setActiveVersion(modelName, version) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    const modelConfig = this.config.models[modelName];
    const resourceName = modelConfig.resource;
    await this.loadModelVersion(modelName, version);
    await this._updateVersionInfo(modelName, version);
    const storage = this.getStorage();
    await storage.set(storage.getPluginKey(resourceName, "metadata", modelName, "active"), {
      modelName,
      version,
      type: "reference",
      updatedAt: (/* @__PURE__ */ new Date()).toISOString()
    });
    if (this.config.verbose) {
      console.log(`[MLPlugin] Set model "${modelName}" active version to v${version}`);
    }
    return { modelName, version };
  }
  /**
   * Get training history for a model
   * @param {string} modelName - Model name
   * @returns {Array} Training history
   */
  async getTrainingHistory(modelName) {
    if (!this.config.enableVersioning) {
      return await this.getTrainingData(modelName);
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok, err, historyData] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "training", "history", modelName)));
      if (!ok || !historyData) {
        return null;
      }
      return {
        modelName: historyData.modelName,
        totalTrainings: historyData.totalTrainings,
        latestVersion: historyData.latestVersion,
        history: JSON.parse(historyData.history),
        updatedAt: historyData.updatedAt
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to load training history for "${modelName}":`, error.message);
      return null;
    }
  }
  /**
   * Compare metrics between two versions
   * @param {string} modelName - Model name
   * @param {number} version1 - First version
   * @param {number} version2 - Second version
   * @returns {Object} Comparison results
   */
  async compareVersions(modelName, version1, version2) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    try {
      const storage = this.getStorage();
      const modelConfig = this.config.models[modelName];
      const resourceName = modelConfig.resource;
      const [ok1, err1, v1Data] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version1}`)));
      const [ok2, err2, v2Data] = await tryFn(() => storage.get(storage.getPluginKey(resourceName, "models", modelName, `v${version2}`)));
      if (!ok1 || !v1Data) {
        throw new MLError(`Version ${version1} not found`, { modelName, version: version1 });
      }
      if (!ok2 || !v2Data) {
        throw new MLError(`Version ${version2} not found`, { modelName, version: version2 });
      }
      const metrics1 = v1Data.metrics ? JSON.parse(v1Data.metrics) : {};
      const metrics2 = v2Data.metrics ? JSON.parse(v2Data.metrics) : {};
      return {
        modelName,
        version1: {
          version: version1,
          savedAt: v1Data.savedAt,
          metrics: metrics1
        },
        version2: {
          version: version2,
          savedAt: v2Data.savedAt,
          metrics: metrics2
        },
        improvement: {
          loss: metrics1.loss && metrics2.loss ? ((metrics1.loss - metrics2.loss) / metrics1.loss * 100).toFixed(2) + "%" : "N/A",
          accuracy: metrics1.accuracy && metrics2.accuracy ? ((metrics2.accuracy - metrics1.accuracy) / metrics1.accuracy * 100).toFixed(2) + "%" : "N/A"
        }
      };
    } catch (error) {
      console.error(`[MLPlugin] Failed to compare versions for "${modelName}":`, error.message);
      throw error;
    }
  }
  /**
   * Rollback to a previous version
   * @param {string} modelName - Model name
   * @param {number} version - Version to rollback to (defaults to previous version)
   * @returns {Object} Rollback info
   */
  async rollbackVersion(modelName, version = null) {
    if (!this.config.enableVersioning) {
      throw new MLError("Versioning is not enabled", { modelName });
    }
    const versionInfo = this.modelVersions.get(modelName);
    if (!versionInfo) {
      throw new MLError(`No version info found for model "${modelName}"`, { modelName });
    }
    const targetVersion = version !== null ? version : Math.max(1, versionInfo.currentVersion - 1);
    if (targetVersion === versionInfo.currentVersion) {
      throw new MLError("Cannot rollback to the same version", { modelName, version: targetVersion });
    }
    if (targetVersion < 1 || targetVersion > versionInfo.latestVersion) {
      throw new MLError(`Invalid version ${targetVersion}`, { modelName, version: targetVersion, latestVersion: versionInfo.latestVersion });
    }
    const result = await this.setActiveVersion(modelName, targetVersion);
    if (this.config.verbose) {
      console.log(`[MLPlugin] Rolled back model "${modelName}" from v${versionInfo.currentVersion} to v${targetVersion}`);
    }
    return {
      modelName,
      previousVersion: versionInfo.currentVersion,
      currentVersion: targetVersion,
      ...result
    };
  }
}

class SqsConsumer {
  constructor({ queueUrl, onMessage, onError, poolingInterval = 5e3, maxMessages = 10, region = "us-east-1", credentials, endpoint, driver = "sqs" }) {
    this.driver = driver;
    this.queueUrl = queueUrl;
    this.onMessage = onMessage;
    this.onError = onError;
    this.poolingInterval = poolingInterval;
    this.maxMessages = maxMessages;
    this.region = region;
    this.credentials = credentials;
    this.endpoint = endpoint;
    this.sqs = null;
    this._stopped = false;
    this._timer = null;
    this._pollPromise = null;
    this._pollResolve = null;
    this._SQSClient = null;
    this._ReceiveMessageCommand = null;
    this._DeleteMessageCommand = null;
  }
  async start() {
    await requirePluginDependency("sqs-consumer");
    const [ok, err, sdk] = await tryFn(() => import('@aws-sdk/client-sqs'));
    if (!ok) throw new Error("SqsConsumer: @aws-sdk/client-sqs is not installed. Please install it to use the SQS consumer.");
    const { SQSClient, ReceiveMessageCommand, DeleteMessageCommand } = sdk;
    this._SQSClient = SQSClient;
    this._ReceiveMessageCommand = ReceiveMessageCommand;
    this._DeleteMessageCommand = DeleteMessageCommand;
    this.sqs = new SQSClient({ region: this.region, credentials: this.credentials, endpoint: this.endpoint });
    this._stopped = false;
    this._pollPromise = new Promise((resolve) => {
      this._pollResolve = resolve;
    });
    this._poll();
  }
  async stop() {
    this._stopped = true;
    if (this._timer) {
      clearTimeout(this._timer);
      this._timer = null;
    }
    if (this._pollResolve) {
      this._pollResolve();
    }
  }
  async _poll() {
    if (this._stopped) {
      if (this._pollResolve) this._pollResolve();
      return;
    }
    const [ok, err, result] = await tryFn(async () => {
      const cmd = new this._ReceiveMessageCommand({
        QueueUrl: this.queueUrl,
        MaxNumberOfMessages: this.maxMessages,
        WaitTimeSeconds: 10,
        MessageAttributeNames: ["All"]
      });
      const { Messages } = await this.sqs.send(cmd);
      if (Messages && Messages.length > 0) {
        for (const msg of Messages) {
          const [okMsg, errMsg] = await tryFn(async () => {
            const parsedMsg = this._parseMessage(msg);
            await this.onMessage(parsedMsg, msg);
            await this.sqs.send(new this._DeleteMessageCommand({
              QueueUrl: this.queueUrl,
              ReceiptHandle: msg.ReceiptHandle
            }));
          });
          if (!okMsg && this.onError) {
            this.onError(errMsg, msg);
          }
        }
      }
    });
    if (!ok && this.onError) {
      this.onError(err);
    }
    this._timer = setTimeout(() => this._poll(), this.poolingInterval);
  }
  _parseMessage(msg) {
    let body;
    const [ok, err, parsed] = tryFn(() => JSON.parse(msg.Body));
    body = ok ? parsed : msg.Body;
    const attributes = {};
    if (msg.MessageAttributes) {
      for (const [k, v] of Object.entries(msg.MessageAttributes)) {
        attributes[k] = v.StringValue;
      }
    }
    return { $body: body, $attributes: attributes, $raw: msg };
  }
}

class RabbitMqConsumer {
  constructor({ amqpUrl, queue, prefetch = 10, reconnectInterval = 2e3, onMessage, onError, driver = "rabbitmq" }) {
    this.amqpUrl = amqpUrl;
    this.queue = queue;
    this.prefetch = prefetch;
    this.reconnectInterval = reconnectInterval;
    this.onMessage = onMessage;
    this.onError = onError;
    this.driver = driver;
    this.connection = null;
    this.channel = null;
    this._stopped = false;
  }
  async start() {
    await requirePluginDependency("rabbitmq-consumer");
    this._stopped = false;
    await this._connect();
  }
  async stop() {
    this._stopped = true;
    if (this.channel) await this.channel.close();
    if (this.connection) await this.connection.close();
  }
  async _connect() {
    const [ok, err] = await tryFn(async () => {
      const amqp = (await import('amqplib')).default;
      this.connection = await amqp.connect(this.amqpUrl);
      this.channel = await this.connection.createChannel();
      await this.channel.assertQueue(this.queue, { durable: true });
      this.channel.prefetch(this.prefetch);
      this.channel.consume(this.queue, async (msg) => {
        if (msg !== null) {
          const [okMsg, errMsg] = await tryFn(async () => {
            const content = JSON.parse(msg.content.toString());
            await this.onMessage({ $body: content, $raw: msg });
            this.channel.ack(msg);
          });
          if (!okMsg) {
            if (this.onError) this.onError(errMsg, msg);
            this.channel.nack(msg, false, false);
          }
        }
      });
    });
    if (!ok) {
      if (this.onError) this.onError(err);
      if (!this._stopped) {
        setTimeout(() => this._connect(), this.reconnectInterval);
      }
    }
  }
}

const CONSUMER_DRIVERS = {
  sqs: SqsConsumer,
  rabbitmq: RabbitMqConsumer
  // kafka: KafkaConsumer, // futuro
};
function createConsumer(driver, config) {
  const ConsumerClass = CONSUMER_DRIVERS[driver];
  if (!ConsumerClass) {
    throw new Error(`Unknown consumer driver: ${driver}. Available: ${Object.keys(CONSUMER_DRIVERS).join(", ")}`);
  }
  return new ConsumerClass(config);
}

class QueueError extends S3dbError {
  constructor(message, details = {}) {
    const { queueName, operation = "unknown", messageId, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Queue Operation Error

Operation: ${operation}
${queueName ? `Queue: ${queueName}` : ""}
${messageId ? `Message ID: ${messageId}` : ""}

Common causes:
1. Queue not properly configured
2. Message handler not registered
3. Queue resource not found
4. SQS/RabbitMQ connection failed
5. Message processing timeout

Solution:
Check queue configuration and message handler registration.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/queue.md
`.trim();
    }
    super(message, { ...rest, queueName, operation, messageId, description });
  }
}

class QueueConsumerPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.options = options;
    this.driversConfig = Array.isArray(options.consumers) ? options.consumers : [];
    this.consumers = [];
  }
  async onInstall() {
    for (const driverDef of this.driversConfig) {
      const { driver, config: driverConfig = {}, consumers: consumerDefs = [] } = driverDef;
      for (const consumerDef of consumerDefs) {
        const { resources, ...consumerConfig } = consumerDef;
        const resourceList = Array.isArray(resources) ? resources : [resources];
        for (const resource of resourceList) {
          const mergedConfig = { ...driverConfig, ...consumerConfig };
          const consumer = createConsumer(driver, {
            ...mergedConfig,
            onMessage: (msg) => this._handleMessage(msg, resource),
            onError: (err, raw) => this._handleError(err, raw, resource)
          });
          await consumer.start();
          this.consumers.push(consumer);
        }
      }
    }
  }
  async stop() {
    if (!Array.isArray(this.consumers)) this.consumers = [];
    for (const consumer of this.consumers) {
      if (consumer && typeof consumer.stop === "function") {
        await consumer.stop();
      }
    }
    this.consumers = [];
  }
  async _handleMessage(msg, configuredResource) {
    this.options;
    let body = msg.$body || msg;
    if (body.$body && !body.resource && !body.action && !body.data) {
      body = body.$body;
    }
    let resource = body.resource || msg.resource;
    let action = body.action || msg.action;
    let data = body.data || msg.data;
    if (!resource) {
      throw new QueueError("Resource not found in message", {
        operation: "handleMessage",
        queueName: configuredResource,
        messageBody: body,
        suggestion: 'Ensure message includes a "resource" field specifying the target resource name'
      });
    }
    if (!action) {
      throw new QueueError("Action not found in message", {
        operation: "handleMessage",
        queueName: configuredResource,
        resource,
        messageBody: body,
        suggestion: 'Ensure message includes an "action" field (insert, update, or delete)'
      });
    }
    const resourceObj = this.database.resources[resource];
    if (!resourceObj) {
      throw new QueueError(`Resource '${resource}' not found`, {
        operation: "handleMessage",
        queueName: configuredResource,
        resource,
        availableResources: Object.keys(this.database.resources),
        suggestion: "Check resource name or ensure resource is created before consuming messages"
      });
    }
    let result;
    const [ok, err, res] = await tryFn(async () => {
      if (action === "insert") {
        result = await resourceObj.insert(data);
      } else if (action === "update") {
        const { id: updateId, ...updateAttributes } = data;
        result = await resourceObj.update(updateId, updateAttributes);
      } else if (action === "delete") {
        result = await resourceObj.delete(data.id);
      } else {
        throw new QueueError(`Unsupported action '${action}'`, {
          operation: "handleMessage",
          queueName: configuredResource,
          resource,
          action,
          supportedActions: ["insert", "update", "delete"],
          suggestion: "Use one of the supported actions: insert, update, or delete"
        });
      }
      return result;
    });
    if (!ok) {
      throw err;
    }
    return res;
  }
  _handleError(err, raw, resourceName) {
  }
}

class RelationError extends Error {
  constructor(message, context = {}) {
    super(message);
    this.name = "RelationError";
    this.context = context;
    Error.captureStackTrace(this, this.constructor);
  }
}
class RelationConfigError extends RelationError {
  constructor(message, context = {}) {
    super(message, context);
    this.name = "RelationConfigError";
  }
}
class UnsupportedRelationTypeError extends RelationError {
  constructor(type, context = {}) {
    super(`Unsupported relation type: ${type}. Supported types: hasOne, hasMany, belongsTo, belongsToMany`, context);
    this.name = "UnsupportedRelationTypeError";
    this.relationType = type;
  }
}
class RelatedResourceNotFoundError extends RelationError {
  constructor(resourceName, context = {}) {
    super(`Related resource "${resourceName}" not found`, context);
    this.name = "RelatedResourceNotFoundError";
    this.resourceName = resourceName;
  }
}
class JunctionTableNotFoundError extends RelationError {
  constructor(junctionTable, context = {}) {
    super(`Junction table "${junctionTable}" not found for belongsToMany relation`, context);
    this.name = "JunctionTableNotFoundError";
    this.junctionTable = junctionTable;
  }
}
class CascadeError extends RelationError {
  constructor(operation, resourceName, recordId, originalError, context = {}) {
    super(
      `Cascade ${operation} failed for resource "${resourceName}" record "${recordId}": ${originalError.message}`,
      context
    );
    this.name = "CascadeError";
    this.operation = operation;
    this.resourceName = resourceName;
    this.recordId = recordId;
    this.originalError = originalError;
  }
}
class InvalidIncludePathError extends RelationError {
  constructor(path, reason, context = {}) {
    super(`Invalid include path "${path}": ${reason}`, context);
    this.name = "InvalidIncludePathError";
    this.includePath = path;
    this.reason = reason;
  }
}

class RelationPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.relations = config.relations || {};
    this.cache = config.cache !== void 0 ? config.cache : true;
    this.batchSize = config.batchSize || 100;
    this.preventN1 = config.preventN1 !== void 0 ? config.preventN1 : true;
    this.verbose = config.verbose || false;
    this.fallbackLimit = config.fallbackLimit !== void 0 ? config.fallbackLimit : null;
    this.cascadeBatchSize = config.cascadeBatchSize || 10;
    this.cascadeTransactions = config.cascadeTransactions !== void 0 ? config.cascadeTransactions : false;
    this._loaderCache = /* @__PURE__ */ new Map();
    this._partitionCache = /* @__PURE__ */ new Map();
    this.stats = {
      totalRelationLoads: 0,
      cachedLoads: 0,
      batchLoads: 0,
      cascadeOperations: 0,
      partitionCacheHits: 0,
      deduplicatedQueries: 0,
      fallbackLimitWarnings: 0
    };
  }
  /**
   * Install the plugin (lifecycle hook)
   * @override
   */
  async onInstall() {
    console.log("[RelationPlugin] onInstall() called");
    console.log("[RelationPlugin] Database connected:", !!this.database);
    console.log("[RelationPlugin] Relations:", Object.keys(this.relations));
    this._validateRelationsConfig();
    for (const [resourceName, relationsDef] of Object.entries(this.relations)) {
      await this._setupResourceRelations(resourceName, relationsDef);
    }
    this.database.addHook("afterCreateResource", async (context) => {
      const { resource } = context;
      const relationsDef = this.relations[resource.name];
      if (relationsDef) {
        await this._setupResourceRelations(resource.name, relationsDef);
      }
    });
    if (this.verbose) {
      console.log(`[RelationPlugin] Installed with ${Object.keys(this.relations).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "RelationPlugin",
      resources: Object.keys(this.relations)
    });
  }
  /**
   * Validate all relations configuration
   * @private
   */
  _validateRelationsConfig() {
    for (const [resourceName, relationsDef] of Object.entries(this.relations)) {
      for (const [relationName, config] of Object.entries(relationsDef)) {
        const validTypes = ["hasOne", "hasMany", "belongsTo", "belongsToMany"];
        if (!validTypes.includes(config.type)) {
          throw new UnsupportedRelationTypeError(config.type, {
            resource: resourceName,
            relation: relationName
          });
        }
        if (!config.resource) {
          throw new RelationConfigError(
            `Relation "${relationName}" on resource "${resourceName}" must have "resource" field`,
            { resource: resourceName, relation: relationName }
          );
        }
        if (!config.foreignKey) {
          throw new RelationConfigError(
            `Relation "${relationName}" on resource "${resourceName}" must have "foreignKey" field`,
            { resource: resourceName, relation: relationName }
          );
        }
        if (config.type === "belongsToMany") {
          if (!config.through) {
            throw new RelationConfigError(
              `belongsToMany relation "${relationName}" must have "through" (junction table) configured`,
              { resource: resourceName, relation: relationName }
            );
          }
          if (!config.otherKey) {
            throw new RelationConfigError(
              `belongsToMany relation "${relationName}" must have "otherKey" configured`,
              { resource: resourceName, relation: relationName }
            );
          }
        }
        config.localKey = config.localKey || "id";
        config.eager = config.eager !== void 0 ? config.eager : false;
        config.cascade = config.cascade || [];
      }
    }
  }
  /**
   * Setup a resource with relation capabilities
   * @private
   */
  async _setupResourceRelations(resourceName, relationsDef) {
    const resource = this.database.resources[resourceName];
    if (!resource) {
      if (this.verbose) {
        console.warn(`[RelationPlugin] Resource "${resourceName}" not found, will setup when created`);
      }
      return;
    }
    resource._relations = relationsDef;
    this._interceptGet(resource);
    this._interceptList(resource);
    this._interceptDelete(resource);
    this._interceptUpdate(resource);
    if (this.verbose) {
      console.log(
        `[RelationPlugin] Setup ${Object.keys(relationsDef).length} relations for "${resourceName}"`
      );
    }
  }
  /**
   * Intercept get() to add eager loading support
   * @private
   */
  _interceptGet(resource) {
    if (this.verbose) {
      console.log(`[RelationPlugin] Intercepting get() for resource "${resource.name}"`);
    }
    this.wrapResourceMethod(resource, "get", async (result, args) => {
      const [id, options = {}] = args;
      if (this.verbose) {
        console.log(`[RelationPlugin] get() wrapper called for "${resource.name}" with options:`, options);
      }
      if (!result || !options.include) {
        return result;
      }
      return await this._eagerLoad([result], options.include, resource).then((results) => results[0]);
    });
  }
  /**
   * Intercept list() to add eager loading support
   * @private
   */
  _interceptList(resource) {
    this.wrapResourceMethod(resource, "list", async (result, args) => {
      const [options = {}] = args;
      if (!result || result.length === 0 || !options.include) {
        return result;
      }
      return await this._eagerLoad(result, options.include, resource);
    });
  }
  /**
   * Intercept delete() to add cascade support
   * @private
   */
  _interceptDelete(resource) {
    this.addMiddleware(resource, "delete", async (next, id, options = {}) => {
      const record = await resource.get(id);
      if (!record) {
        return await next(id, options);
      }
      if (resource._relations) {
        for (const [relationName, config] of Object.entries(resource._relations)) {
          if (config.cascade && config.cascade.includes("delete")) {
            await this._cascadeDelete(record, resource, relationName, config);
          }
        }
      }
      return await next(id, options);
    });
  }
  /**
   * Intercept update() to add cascade support (for foreign key updates)
   * @private
   */
  _interceptUpdate(resource) {
    this.wrapResourceMethod(resource, "update", async (result, args) => {
      const [id, changes, options = {}] = args;
      const localKeyChanged = resource._relations && Object.values(resource._relations).some((config) => changes[config.localKey]);
      if (localKeyChanged && !options.skipCascade) {
        for (const [relationName, config] of Object.entries(resource._relations)) {
          if (config.cascade && config.cascade.includes("update") && changes[config.localKey]) {
            await this._cascadeUpdate(result, changes, resource, relationName, config);
          }
        }
      }
      return result;
    });
  }
  /**
   * Eager load relations
   * @private
   */
  async _eagerLoad(records, includes, resource) {
    if (!records || records.length === 0) {
      return records;
    }
    const normalizedIncludes = this._normalizeIncludes(includes);
    for (const [relationName, subIncludes] of Object.entries(normalizedIncludes)) {
      const config = resource._relations?.[relationName];
      if (!config) {
        throw new InvalidIncludePathError(
          relationName,
          `Relation "${relationName}" not defined on resource "${resource.name}"`
        );
      }
      records = await this._loadRelation(records, relationName, config, resource);
      if (subIncludes && typeof subIncludes === "object" && subIncludes !== true) {
        const nestedIncludes = subIncludes.include || subIncludes;
        for (const record of records) {
          const relatedData = record[relationName];
          if (relatedData) {
            const relatedResource = this.database.resources[config.resource];
            const relatedArray = Array.isArray(relatedData) ? relatedData : [relatedData];
            if (relatedArray.length > 0) {
              await this._eagerLoad(relatedArray, nestedIncludes, relatedResource);
            }
          }
        }
      }
    }
    return records;
  }
  /**
   * Normalize includes format
   * @private
   */
  _normalizeIncludes(includes) {
    if (Array.isArray(includes)) {
      return includes.reduce((acc, rel) => ({ ...acc, [rel]: true }), {});
    }
    if (typeof includes === "object") {
      return includes;
    }
    if (typeof includes === "string") {
      return { [includes]: true };
    }
    return {};
  }
  /**
   * Load a relation for an array of records
   * @private
   */
  async _loadRelation(records, relationName, config, sourceResource) {
    this.stats.totalRelationLoads++;
    switch (config.type) {
      case "hasOne":
        return await this._loadHasOne(records, relationName, config, sourceResource);
      case "hasMany":
        return await this._loadHasMany(records, relationName, config, sourceResource);
      case "belongsTo":
        return await this._loadBelongsTo(records, relationName, config, sourceResource);
      case "belongsToMany":
        return await this._loadBelongsToMany(records, relationName, config, sourceResource);
      default:
        throw new UnsupportedRelationTypeError(config.type);
    }
  }
  /**
   * Load hasOne relation (User → Profile)
   * @private
   */
  async _loadHasOne(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = null);
      return records;
    }
    const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.foreignKey);
    let relatedRecords;
    if (partitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        partitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.foreignKey, localKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      relatedMap.set(related[config.foreignKey], related);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      record[relationName] = relatedMap.get(localKeyValue) || null;
    });
    return records;
  }
  /**
   * Load hasMany relation (User → Posts)
   * @private
   */
  async _loadHasMany(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.foreignKey);
    let relatedRecords;
    if (partitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        partitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.foreignKey, localKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      const fkValue = related[config.foreignKey];
      if (!relatedMap.has(fkValue)) {
        relatedMap.set(fkValue, []);
      }
      relatedMap.get(fkValue).push(related);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      record[relationName] = relatedMap.get(localKeyValue) || [];
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Load belongsTo relation (Post → User)
   * @private
   */
  async _loadBelongsTo(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const foreignKeys = [...new Set(records.map((r) => r[config.foreignKey]).filter(Boolean))];
    if (foreignKeys.length === 0) {
      records.forEach((r) => r[relationName] = null);
      return records;
    }
    const [ok, err, parentRecords] = await tryFn(async () => {
      const partitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.localKey);
      if (partitionName) {
        return await this._batchLoadWithPartitions(
          relatedResource,
          partitionName,
          config.localKey,
          foreignKeys
        );
      } else {
        return await this._fallbackLoad(relatedResource, config.localKey, foreignKeys);
      }
    });
    if (!ok) {
      throw new RelationError(`Failed to load belongsTo relation "${relationName}": ${err.message}`, {
        sourceResource: sourceResource.name,
        relatedResource: config.resource,
        error: err
      });
    }
    const parentMap = /* @__PURE__ */ new Map();
    parentRecords.forEach((parent) => {
      parentMap.set(parent[config.localKey], parent);
    });
    records.forEach((record) => {
      const foreignKeyValue = record[config.foreignKey];
      record[relationName] = parentMap.get(foreignKeyValue) || null;
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Load belongsToMany relation via junction table (Post ↔ Tags)
   * @private
   */
  async _loadBelongsToMany(records, relationName, config, sourceResource) {
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const junctionResource = this.database.resources[config.through];
    if (!junctionResource) {
      throw new JunctionTableNotFoundError(config.through, {
        sourceResource: sourceResource.name,
        relation: relationName
      });
    }
    const localKeys = [...new Set(records.map((r) => r[config.localKey]).filter(Boolean))];
    if (localKeys.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const junctionPartitionName = config.junctionPartitionHint || this._findPartitionByField(junctionResource, config.foreignKey);
    let junctionRecords;
    if (junctionPartitionName) {
      junctionRecords = await this._batchLoadWithPartitions(
        junctionResource,
        junctionPartitionName,
        config.foreignKey,
        localKeys
      );
    } else {
      junctionRecords = await this._fallbackLoad(junctionResource, config.foreignKey, localKeys);
    }
    if (junctionRecords.length === 0) {
      records.forEach((r) => r[relationName] = []);
      return records;
    }
    const otherKeys = [...new Set(junctionRecords.map((j) => j[config.otherKey]).filter(Boolean))];
    const relatedPartitionName = config.partitionHint || this._findPartitionByField(relatedResource, config.localKey);
    let relatedRecords;
    if (relatedPartitionName) {
      relatedRecords = await this._batchLoadWithPartitions(
        relatedResource,
        relatedPartitionName,
        config.localKey,
        otherKeys
      );
    } else {
      relatedRecords = await this._fallbackLoad(relatedResource, config.localKey, otherKeys);
    }
    const relatedMap = /* @__PURE__ */ new Map();
    relatedRecords.forEach((related) => {
      relatedMap.set(related[config.localKey], related);
    });
    const junctionMap = /* @__PURE__ */ new Map();
    junctionRecords.forEach((junction) => {
      const fkValue = junction[config.foreignKey];
      if (!junctionMap.has(fkValue)) {
        junctionMap.set(fkValue, []);
      }
      junctionMap.get(fkValue).push(junction[config.otherKey]);
    });
    records.forEach((record) => {
      const localKeyValue = record[config.localKey];
      const otherKeyValues = junctionMap.get(localKeyValue) || [];
      record[relationName] = otherKeyValues.map((otherKey) => relatedMap.get(otherKey)).filter(Boolean);
    });
    if (this.preventN1) {
      this.stats.batchLoads++;
    }
    return records;
  }
  /**
   * Batch process operations with controlled parallelism
   * @private
   */
  async _batchProcess(items, operation, batchSize = null) {
    if (items.length === 0) return [];
    const actualBatchSize = batchSize || this.cascadeBatchSize;
    const results = [];
    for (let i = 0; i < items.length; i += actualBatchSize) {
      const chunk = items.slice(i, i + actualBatchSize);
      const chunkPromises = chunk.map((item) => operation(item));
      const chunkResults = await Promise.all(chunkPromises);
      results.push(...chunkResults);
    }
    return results;
  }
  /**
   * Load records using fallback (full scan) when no partition is available
   * Issues warnings when limit is reached to prevent silent data loss
   * @private
   */
  async _fallbackLoad(resource, fieldName, filterValues) {
    const options = this.fallbackLimit !== null ? { limit: this.fallbackLimit } : {};
    if (this.verbose) {
      console.log(
        `[RelationPlugin] No partition found for ${resource.name}.${fieldName}, using full scan` + (this.fallbackLimit ? ` (limited to ${this.fallbackLimit} records)` : " (no limit)")
      );
    }
    const allRecords = await resource.list(options);
    const filteredRecords = allRecords.filter((r) => filterValues.includes(r[fieldName]));
    if (this.fallbackLimit && allRecords.length >= this.fallbackLimit) {
      this.stats.fallbackLimitWarnings++;
      console.warn(
        `[RelationPlugin] WARNING: Fallback query for ${resource.name}.${fieldName} hit the limit of ${this.fallbackLimit} records. Some related records may be missing! Consider:
  1. Adding a partition on field "${fieldName}" for better performance
  2. Increasing fallbackLimit in plugin config (or set to null for no limit)
  Partition example: partitions: { by${fieldName.charAt(0).toUpperCase() + fieldName.slice(1)}: { fields: { ${fieldName}: 'string' } } }`
      );
    }
    return filteredRecords;
  }
  /**
   * Find partition by field name (for efficient relation loading)
   * Uses cache to avoid repeated lookups
   * @private
   */
  _findPartitionByField(resource, fieldName) {
    if (!resource.config.partitions) return null;
    const cacheKey = `${resource.name}:${fieldName}`;
    if (this._partitionCache.has(cacheKey)) {
      this.stats.partitionCacheHits++;
      return this._partitionCache.get(cacheKey);
    }
    let bestPartition = null;
    let bestFieldCount = Infinity;
    for (const [partitionName, partitionConfig] of Object.entries(resource.config.partitions)) {
      if (partitionConfig.fields && fieldName in partitionConfig.fields) {
        const fieldCount = Object.keys(partitionConfig.fields).length;
        if (fieldCount < bestFieldCount) {
          bestPartition = partitionName;
          bestFieldCount = fieldCount;
        }
      }
    }
    this._partitionCache.set(cacheKey, bestPartition);
    return bestPartition;
  }
  /**
   * Batch load records using partitions with controlled parallelism
   * Deduplicates keys to avoid redundant queries
   * @private
   */
  async _batchLoadWithPartitions(resource, partitionName, fieldName, keys) {
    if (keys.length === 0) return [];
    const uniqueKeys = [...new Set(keys)];
    const deduplicatedCount = keys.length - uniqueKeys.length;
    if (deduplicatedCount > 0) {
      this.stats.deduplicatedQueries += deduplicatedCount;
      if (this.verbose) {
        console.log(
          `[RelationPlugin] Deduplicated ${deduplicatedCount} queries (${keys.length} -> ${uniqueKeys.length} unique keys)`
        );
      }
    }
    if (uniqueKeys.length === 1) {
      return await resource.list({
        partition: partitionName,
        partitionValues: { [fieldName]: uniqueKeys[0] }
      });
    }
    const chunkSize = this.batchSize || 10;
    const chunks = [];
    for (let i = 0; i < uniqueKeys.length; i += chunkSize) {
      chunks.push(uniqueKeys.slice(i, i + chunkSize));
    }
    if (this.verbose) {
      console.log(
        `[RelationPlugin] Batch loading ${uniqueKeys.length} keys from ${resource.name} using partition ${partitionName} (${chunks.length} batches)`
      );
    }
    const allResults = [];
    for (const chunk of chunks) {
      const chunkPromises = chunk.map(
        (key) => resource.list({
          partition: partitionName,
          partitionValues: { [fieldName]: key }
        })
      );
      const chunkResults = await Promise.all(chunkPromises);
      allResults.push(...chunkResults.flat());
    }
    return allResults;
  }
  /**
   * Cascade delete operation
   * Uses partitions when available for efficient cascade
   * Supports transaction/rollback when enabled
   * @private
   */
  async _cascadeDelete(record, resource, relationName, config) {
    this.stats.cascadeOperations++;
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      throw new RelatedResourceNotFoundError(config.resource, {
        sourceResource: resource.name,
        relation: relationName
      });
    }
    const deletedRecords = [];
    config.type === "belongsToMany" ? this.database.resources[config.through] : null;
    try {
      if (config.type === "hasMany") {
        let relatedRecords;
        const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
        if (partitionName) {
          relatedRecords = await relatedResource.list({
            partition: partitionName,
            partitionValues: { [config.foreignKey]: record[config.localKey] }
          });
          if (this.verbose) {
            console.log(
              `[RelationPlugin] Cascade delete using partition ${partitionName} for ${config.foreignKey}`
            );
          }
        } else {
          relatedRecords = await relatedResource.query({
            [config.foreignKey]: record[config.localKey]
          });
        }
        if (this.cascadeTransactions) {
          deletedRecords.push(...relatedRecords.map((r) => ({ type: "delete", resource: relatedResource, record: r })));
        }
        await this._batchProcess(relatedRecords, async (related) => {
          return await relatedResource.delete(related.id);
        });
        if (this.verbose) {
          console.log(
            `[RelationPlugin] Cascade deleted ${relatedRecords.length} ${config.resource} for ${resource.name}:${record.id} (batched in ${Math.ceil(relatedRecords.length / this.cascadeBatchSize)} chunks)`
          );
        }
      } else if (config.type === "hasOne") {
        let relatedRecords;
        const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
        if (partitionName) {
          relatedRecords = await relatedResource.list({
            partition: partitionName,
            partitionValues: { [config.foreignKey]: record[config.localKey] }
          });
        } else {
          relatedRecords = await relatedResource.query({
            [config.foreignKey]: record[config.localKey]
          });
        }
        if (relatedRecords.length > 0) {
          if (this.cascadeTransactions) {
            deletedRecords.push({ type: "delete", resource: relatedResource, record: relatedRecords[0] });
          }
          await relatedResource.delete(relatedRecords[0].id);
        }
      } else if (config.type === "belongsToMany") {
        const junctionResource2 = this.database.resources[config.through];
        if (junctionResource2) {
          let junctionRecords;
          const partitionName = this._findPartitionByField(junctionResource2, config.foreignKey);
          if (partitionName) {
            junctionRecords = await junctionResource2.list({
              partition: partitionName,
              partitionValues: { [config.foreignKey]: record[config.localKey] }
            });
            if (this.verbose) {
              console.log(
                `[RelationPlugin] Cascade delete junction using partition ${partitionName}`
              );
            }
          } else {
            junctionRecords = await junctionResource2.query({
              [config.foreignKey]: record[config.localKey]
            });
          }
          if (this.cascadeTransactions) {
            deletedRecords.push(...junctionRecords.map((j) => ({ type: "delete", resource: junctionResource2, record: j })));
          }
          await this._batchProcess(junctionRecords, async (junction) => {
            return await junctionResource2.delete(junction.id);
          });
          if (this.verbose) {
            console.log(
              `[RelationPlugin] Cascade deleted ${junctionRecords.length} junction records from ${config.through} (batched in ${Math.ceil(junctionRecords.length / this.cascadeBatchSize)} chunks)`
            );
          }
        }
      }
    } catch (error) {
      if (this.cascadeTransactions && deletedRecords.length > 0) {
        console.error(
          `[RelationPlugin] Cascade delete failed, attempting rollback of ${deletedRecords.length} records...`
        );
        const rollbackErrors = [];
        for (const { resource: res, record: rec } of deletedRecords.reverse()) {
          try {
            await res.insert(rec);
          } catch (rollbackError) {
            rollbackErrors.push({ record: rec.id, error: rollbackError.message });
          }
        }
        if (rollbackErrors.length > 0) {
          console.error(
            `[RelationPlugin] Rollback partially failed for ${rollbackErrors.length} records:`,
            rollbackErrors
          );
        } else if (this.verbose) {
          console.log(`[RelationPlugin] Rollback successful, restored ${deletedRecords.length} records`);
        }
      }
      throw new CascadeError("delete", resource.name, record.id, error, {
        relation: relationName,
        relatedResource: config.resource
      });
    }
  }
  /**
   * Cascade update operation (update foreign keys when local key changes)
   * Uses partitions when available for efficient cascade
   * Supports transaction/rollback when enabled
   * @private
   */
  async _cascadeUpdate(record, changes, resource, relationName, config) {
    this.stats.cascadeOperations++;
    const relatedResource = this.database.resources[config.resource];
    if (!relatedResource) {
      return;
    }
    const updatedRecords = [];
    try {
      const oldLocalKeyValue = record[config.localKey];
      const newLocalKeyValue = changes[config.localKey];
      if (oldLocalKeyValue === newLocalKeyValue) {
        return;
      }
      let relatedRecords;
      const partitionName = this._findPartitionByField(relatedResource, config.foreignKey);
      if (partitionName) {
        relatedRecords = await relatedResource.list({
          partition: partitionName,
          partitionValues: { [config.foreignKey]: oldLocalKeyValue }
        });
        if (this.verbose) {
          console.log(
            `[RelationPlugin] Cascade update using partition ${partitionName} for ${config.foreignKey}`
          );
        }
      } else {
        relatedRecords = await relatedResource.query({
          [config.foreignKey]: oldLocalKeyValue
        });
      }
      if (this.cascadeTransactions) {
        updatedRecords.push(...relatedRecords.map((r) => ({
          type: "update",
          resource: relatedResource,
          id: r.id,
          oldValue: r[config.foreignKey],
          newValue: newLocalKeyValue,
          field: config.foreignKey
        })));
      }
      await this._batchProcess(relatedRecords, async (related) => {
        return await relatedResource.update(related.id, {
          [config.foreignKey]: newLocalKeyValue
        }, { skipCascade: true });
      });
      if (this.verbose) {
        console.log(
          `[RelationPlugin] Cascade updated ${relatedRecords.length} ${config.resource} records (batched in ${Math.ceil(relatedRecords.length / this.cascadeBatchSize)} chunks)`
        );
      }
    } catch (error) {
      if (this.cascadeTransactions && updatedRecords.length > 0) {
        console.error(
          `[RelationPlugin] Cascade update failed, attempting rollback of ${updatedRecords.length} records...`
        );
        const rollbackErrors = [];
        for (const { resource: res, id, field, oldValue } of updatedRecords.reverse()) {
          try {
            await res.update(id, { [field]: oldValue }, { skipCascade: true });
          } catch (rollbackError) {
            rollbackErrors.push({ id, error: rollbackError.message });
          }
        }
        if (rollbackErrors.length > 0) {
          console.error(
            `[RelationPlugin] Rollback partially failed for ${rollbackErrors.length} records:`,
            rollbackErrors
          );
        } else if (this.verbose) {
          console.log(`[RelationPlugin] Rollback successful, restored ${updatedRecords.length} records`);
        }
      }
      throw new CascadeError("update", resource.name, record.id, error, {
        relation: relationName,
        relatedResource: config.resource
      });
    }
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      ...this.stats,
      configuredResources: Object.keys(this.relations).length,
      totalRelations: Object.values(this.relations).reduce(
        (sum, rels) => sum + Object.keys(rels).length,
        0
      )
    };
  }
  /**
   * Clear loader cache and partition cache (useful between requests)
   */
  clearCache() {
    this._loaderCache.clear();
    this._partitionCache.clear();
  }
  /**
   * Cleanup on plugin stop
   */
  async onStop() {
    this.clearCache();
  }
  /**
   * Cleanup on plugin uninstall
   */
  async onUninstall() {
    this.clearCache();
  }
}

class ReplicationError extends S3dbError {
  constructor(message, details = {}) {
    const { replicatorClass = "unknown", operation = "unknown", resourceName, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Replication Operation Error

Replicator: ${replicatorClass}
Operation: ${operation}
${resourceName ? `Resource: ${resourceName}` : ""}

Common causes:
1. Invalid replicator configuration
2. Target system not accessible
3. Resource not configured for replication
4. Invalid operation type
5. Transformation function errors

Solution:
Check replicator configuration and ensure target system is accessible.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/replicator.md
`.trim();
    }
    super(message, { ...rest, replicatorClass, operation, resourceName, description });
  }
}

class BaseReplicator extends EventEmitter {
  constructor(config = {}) {
    super();
    this.config = config;
    this.name = this.constructor.name;
    this.enabled = config.enabled !== false;
  }
  /**
   * Initialize the replicator
   * @param {Object} database - The s3db database instance
   * @returns {Promise<void>}
   */
  async initialize(database) {
    this.database = database;
    this.emit("db:plugin:initialized", { replicator: this.name });
  }
  /**
   * Replicate data to the target
   * @param {string} resourceName - Name of the resource being replicated
   * @param {string} operation - Operation type (insert, update, delete)
   * @param {Object} data - The data to replicate
   * @param {string} id - Record ID
   * @returns {Promise<Object>} replicator result
   */
  async replicate(resourceName, operation, data, id) {
    throw new ReplicationError("replicate() method must be implemented by subclass", {
      operation: "replicate",
      replicatorClass: this.name,
      resourceName,
      suggestion: "Extend BaseReplicator and implement the replicate() method"
    });
  }
  /**
   * Replicate multiple records in batch
   * @param {string} resourceName - Name of the resource being replicated
   * @param {Array} records - Array of records to replicate
   * @returns {Promise<Object>} Batch replicator result
   */
  async replicateBatch(resourceName, records) {
    throw new ReplicationError("replicateBatch() method must be implemented by subclass", {
      operation: "replicateBatch",
      replicatorClass: this.name,
      resourceName,
      batchSize: records?.length,
      suggestion: "Extend BaseReplicator and implement the replicateBatch() method"
    });
  }
  /**
   * Test the connection to the target
   * @returns {Promise<boolean>} True if connection is successful
   */
  async testConnection() {
    throw new ReplicationError("testConnection() method must be implemented by subclass", {
      operation: "testConnection",
      replicatorClass: this.name,
      suggestion: "Extend BaseReplicator and implement the testConnection() method"
    });
  }
  /**
   * Get replicator status and statistics
   * @returns {Promise<Object>} Status information
   */
  async getStatus() {
    return {
      name: this.name,
      // Removed: enabled: this.enabled,
      config: this.config,
      connected: false
    };
  }
  /**
   * Cleanup resources
   * @returns {Promise<void>}
   */
  async cleanup() {
    this.emit("cleanup", { replicator: this.name });
  }
  /**
   * Validate replicator configuration
   * @returns {Object} Validation result
   */
  validateConfig() {
    return { isValid: true, errors: [] };
  }
}

function parseFieldType(typeNotation) {
  if (typeof typeNotation !== "string") {
    return { type: "string", required: false, maxLength: null, options: {} };
  }
  const parts = typeNotation.split("|");
  const baseType = parts[0];
  const options = {};
  let required = false;
  let maxLength = null;
  for (const part of parts.slice(1)) {
    if (part === "required") {
      required = true;
    } else if (part.startsWith("maxlength:")) {
      maxLength = parseInt(part.split(":")[1]);
    } else if (part.startsWith("min:")) {
      options.min = parseFloat(part.split(":")[1]);
    } else if (part.startsWith("max:")) {
      options.max = parseFloat(part.split(":")[1]);
    } else if (part.startsWith("length:")) {
      options.length = parseInt(part.split(":")[1]);
    }
  }
  return { type: baseType, required, maxLength, options };
}
function s3dbTypeToPostgres(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      if (maxLength) return `VARCHAR(${maxLength})`;
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INTEGER";
      }
      return "DOUBLE PRECISION";
    case "boolean":
      return "BOOLEAN";
    case "object":
    case "json":
      return "JSONB";
    case "array":
      return "JSONB";
    case "embedding":
      return "JSONB";
    case "ip4":
    case "ip6":
      return "INET";
    case "secret":
      return "TEXT";
    case "uuid":
      return "UUID";
    case "date":
    case "datetime":
      return "TIMESTAMP WITH TIME ZONE";
    default:
      return "TEXT";
  }
}
function s3dbTypeToBigQuery(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      return "STRING";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INT64";
      }
      return "FLOAT64";
    case "boolean":
      return "BOOL";
    case "object":
    case "json":
      return "JSON";
    case "array":
      return "JSON";
    case "embedding":
      return "JSON";
    case "ip4":
    case "ip6":
      return "STRING";
    case "secret":
      return "STRING";
    case "uuid":
      return "STRING";
    case "date":
      return "DATE";
    case "datetime":
      return "TIMESTAMP";
    default:
      return "STRING";
  }
}
function s3dbTypeToMySQL(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      if (maxLength && maxLength <= 255) return `VARCHAR(${maxLength})`;
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INT";
      }
      return "DOUBLE";
    case "boolean":
      return "TINYINT(1)";
    case "object":
    case "json":
    case "array":
      return "JSON";
    case "embedding":
      return "JSON";
    case "ip4":
      return "VARCHAR(15)";
    case "ip6":
      return "VARCHAR(45)";
    case "secret":
      return "TEXT";
    case "uuid":
      return "CHAR(36)";
    case "date":
    case "datetime":
      return "DATETIME";
    default:
      return "TEXT";
  }
}
function generatePostgresCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id VARCHAR(255) PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToPostgres(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`"${fieldName}" ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
)`;
}
function generateMySQLCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id VARCHAR(255) PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToMySQL(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`\`${fieldName}\` ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at DATETIME DEFAULT CURRENT_TIMESTAMP");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci`;
}
async function getPostgresTableSchema(client, tableName) {
  const [ok, err, result] = await tryFn(async () => {
    return await client.query(`
      SELECT column_name, data_type, is_nullable, character_maximum_length
      FROM information_schema.columns
      WHERE table_name = $1
      ORDER BY ordinal_position
    `, [tableName]);
  });
  if (!ok) return null;
  const schema = {};
  for (const row of result.rows) {
    schema[row.column_name] = {
      type: row.data_type,
      nullable: row.is_nullable === "YES",
      maxLength: row.character_maximum_length
    };
  }
  return schema;
}
async function getMySQLTableSchema(connection, tableName) {
  const [ok, err, [rows]] = await tryFn(async () => {
    return await connection.query(`
      SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, CHARACTER_MAXIMUM_LENGTH
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_NAME = ?
      ORDER BY ORDINAL_POSITION
    `, [tableName]);
  });
  if (!ok) return null;
  const schema = {};
  for (const row of rows) {
    schema[row.COLUMN_NAME] = {
      type: row.DATA_TYPE,
      nullable: row.IS_NULLABLE === "YES",
      maxLength: row.CHARACTER_MAXIMUM_LENGTH
    };
  }
  return schema;
}
function generatePostgresAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToPostgres(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN IF NOT EXISTS "${fieldName}" ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}
function generateMySQLAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToMySQL(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN \`${fieldName}\` ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}
function generateBigQuerySchema(attributes, mutability = "append-only") {
  const fields = [];
  fields.push({
    name: "id",
    type: "STRING",
    mode: "REQUIRED"
  });
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const bqType = s3dbTypeToBigQuery(fieldType);
    fields.push({
      name: fieldName,
      type: bqType,
      mode: required ? "REQUIRED" : "NULLABLE"
    });
  }
  if (!attributes.createdAt) {
    fields.push({ name: "created_at", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (!attributes.updatedAt) {
    fields.push({ name: "updated_at", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (mutability === "append-only" || mutability === "immutable") {
    fields.push({ name: "_operation_type", type: "STRING", mode: "NULLABLE" });
    fields.push({ name: "_operation_timestamp", type: "TIMESTAMP", mode: "NULLABLE" });
  }
  if (mutability === "immutable") {
    fields.push({ name: "_is_deleted", type: "BOOL", mode: "NULLABLE" });
    fields.push({ name: "_version", type: "INT64", mode: "NULLABLE" });
  }
  return fields;
}
async function getBigQueryTableSchema(bigqueryClient, datasetId, tableId) {
  const [ok, err, table] = await tryFn(async () => {
    const dataset = bigqueryClient.dataset(datasetId);
    const table2 = dataset.table(tableId);
    const [metadata] = await table2.getMetadata();
    return metadata;
  });
  if (!ok) return null;
  const schema = {};
  if (table.schema && table.schema.fields) {
    for (const field of table.schema.fields) {
      schema[field.name] = {
        type: field.type,
        mode: field.mode
      };
    }
  }
  return schema;
}
function generateBigQuerySchemaUpdate(attributes, existingSchema, mutability = "append-only") {
  const newFields = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const bqType = s3dbTypeToBigQuery(fieldType);
    newFields.push({
      name: fieldName,
      type: bqType,
      mode: required ? "REQUIRED" : "NULLABLE"
    });
  }
  if (mutability === "append-only" || mutability === "immutable") {
    if (!existingSchema["_operation_type"]) {
      newFields.push({ name: "_operation_type", type: "STRING", mode: "NULLABLE" });
    }
    if (!existingSchema["_operation_timestamp"]) {
      newFields.push({ name: "_operation_timestamp", type: "TIMESTAMP", mode: "NULLABLE" });
    }
  }
  if (mutability === "immutable") {
    if (!existingSchema["_is_deleted"]) {
      newFields.push({ name: "_is_deleted", type: "BOOL", mode: "NULLABLE" });
    }
    if (!existingSchema["_version"]) {
      newFields.push({ name: "_version", type: "INT64", mode: "NULLABLE" });
    }
  }
  return newFields;
}
function s3dbTypeToSQLite(fieldType, fieldOptions = {}) {
  const { type, maxLength, options } = parseFieldType(fieldType);
  switch (type) {
    case "string":
      return "TEXT";
    case "number":
      if (options.min !== void 0 && options.min >= 0 && options.max !== void 0 && options.max <= 2147483647) {
        return "INTEGER";
      }
      return "REAL";
    case "boolean":
      return "INTEGER";
    // 0 or 1
    case "object":
    case "json":
    case "array":
      return "TEXT";
    // Store as JSON string
    case "embedding":
      return "TEXT";
    // Store as JSON array
    case "ip4":
    case "ip6":
      return "TEXT";
    case "secret":
      return "TEXT";
    case "uuid":
      return "TEXT";
    case "date":
    case "datetime":
      return "TEXT";
    // SQLite stores dates as ISO strings or Unix timestamps
    default:
      return "TEXT";
  }
}
function generateSQLiteCreateTable(tableName, attributes) {
  const columns = [];
  columns.push("id TEXT PRIMARY KEY");
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToSQLite(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    columns.push(`${fieldName} ${sqlType} ${nullConstraint}`);
  }
  if (!attributes.createdAt) {
    columns.push("created_at TEXT DEFAULT (datetime('now'))");
  }
  if (!attributes.updatedAt) {
    columns.push("updated_at TEXT DEFAULT (datetime('now'))");
  }
  return `CREATE TABLE IF NOT EXISTS ${tableName} (
  ${columns.join(",\n  ")}
)`;
}
function generateSQLiteAlterTable(tableName, attributes, existingSchema) {
  const alterStatements = [];
  for (const [fieldName, fieldConfig] of Object.entries(attributes)) {
    if (fieldName === "id") continue;
    if (existingSchema[fieldName]) continue;
    const fieldType = typeof fieldConfig === "string" ? fieldConfig : fieldConfig.type;
    const { required } = parseFieldType(fieldType);
    const sqlType = s3dbTypeToSQLite(fieldType);
    const nullConstraint = required ? "NOT NULL" : "NULL";
    alterStatements.push(`ALTER TABLE ${tableName} ADD COLUMN ${fieldName} ${sqlType} ${nullConstraint}`);
  }
  return alterStatements;
}

class BigqueryReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.projectId = config.projectId;
    this.datasetId = config.datasetId;
    this.bigqueryClient = null;
    this.credentials = config.credentials;
    this.location = config.location || "US";
    this.logTable = config.logTable;
    this.mutability = config.mutability || "append-only";
    this._validateMutability(this.mutability);
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
    this.versionCounters = /* @__PURE__ */ new Map();
  }
  _validateMutability(mutability) {
    const validModes = ["append-only", "mutable", "immutable"];
    if (!validModes.includes(mutability)) {
      throw new Error(`Invalid mutability mode: ${mutability}. Must be one of: ${validModes.join(", ")}`);
    }
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"],
          transform: null,
          mutability: this.mutability
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"], transform: null, mutability: this.mutability };
          }
          const itemMutability = item.mutability || this.mutability;
          this._validateMutability(itemMutability);
          return {
            table: item.table,
            actions: item.actions || ["insert"],
            transform: item.transform || null,
            mutability: itemMutability
          };
        });
      } else if (typeof config === "object") {
        const configMutability = config.mutability || this.mutability;
        this._validateMutability(configMutability);
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"],
          transform: config.transform || null,
          mutability: configMutability
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.projectId) errors.push("projectId is required");
    if (!this.datasetId) errors.push("datasetId is required");
    if (Object.keys(this.resources).length === 0) errors.push("At least one resource must be configured");
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
        const validActions = ["insert", "update", "delete"];
        const invalidActions = tableConfig.actions.filter((action) => !validActions.includes(action));
        if (invalidActions.length > 0) {
          errors.push(`Invalid actions for resource '${resourceName}': ${invalidActions.join(", ")}. Valid actions: ${validActions.join(", ")}`);
        }
        if (tableConfig.transform && typeof tableConfig.transform !== "function") {
          errors.push(`Transform must be a function for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("bigquery-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@google-cloud/bigquery'));
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[BigqueryReplicator] Failed to import BigQuery SDK: ${err.message}`);
      }
      this.emit("initialization_error", { replicator: this.name, error: err.message });
      throw err;
    }
    const { BigQuery } = sdk;
    this.bigqueryClient = new BigQuery({
      projectId: this.projectId,
      credentials: this.credentials,
      location: this.location
    });
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      projectId: this.projectId,
      datasetId: this.datasetId,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[BigQueryReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const mutability = tableConfig.mutability;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes, mutability);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[BigQueryReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema in BigQuery
   */
  async syncTableSchema(tableName, attributes, mutability = "append-only") {
    const dataset = this.bigqueryClient.dataset(this.datasetId);
    const table = dataset.table(tableName);
    const [exists] = await table.exists();
    if (!exists) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const schema = generateBigQuerySchema(attributes, mutability);
      if (this.config.verbose) {
        console.log(`[BigQueryReplicator] Creating table ${tableName} with schema (mutability: ${mutability}):`, schema);
      }
      await dataset.createTable(tableName, { schema });
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes),
        mutability
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[BigQueryReplicator] Dropping and recreating table ${tableName}`);
      }
      await table.delete();
      const schema = generateBigQuerySchema(attributes, mutability);
      await dataset.createTable(tableName, { schema });
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes),
        mutability
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const existingSchema = await getBigQueryTableSchema(this.bigqueryClient, this.datasetId, tableName);
      const newFields = generateBigQuerySchemaUpdate(attributes, existingSchema, mutability);
      if (newFields.length > 0) {
        if (this.config.verbose) {
          console.log(`[BigQueryReplicator] Adding ${newFields.length} field(s) to table ${tableName}:`, newFields);
        }
        const [metadata] = await table.getMetadata();
        const currentSchema = metadata.schema.fields;
        const updatedSchema = [...currentSchema, ...newFields];
        await table.setMetadata({ schema: updatedSchema });
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: newFields.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const existingSchema = await getBigQueryTableSchema(this.bigqueryClient, this.datasetId, tableName);
      const newFields = generateBigQuerySchemaUpdate(attributes, existingSchema, mutability);
      if (newFields.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${newFields.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => ({
      table: tableConfig.table,
      transform: tableConfig.transform,
      mutability: tableConfig.mutability
    }));
  }
  applyTransform(data, transformFn) {
    let cleanData = this._cleanInternalFields(data);
    if (!transformFn) return cleanData;
    let transformedData = JSON.parse(JSON.stringify(cleanData));
    return transformFn(transformedData);
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Add tracking fields for append-only and immutable modes
   * @private
   */
  _addTrackingFields(data, operation, mutability, id) {
    const tracked = { ...data };
    if (mutability === "append-only" || mutability === "immutable") {
      tracked._operation_type = operation;
      tracked._operation_timestamp = (/* @__PURE__ */ new Date()).toISOString();
    }
    if (mutability === "immutable") {
      tracked._is_deleted = operation === "delete";
      tracked._version = this._getNextVersion(id);
    }
    return tracked;
  }
  /**
   * Get next version number for immutable mode
   * @private
   */
  _getNextVersion(id) {
    const current = this.versionCounters.get(id) || 0;
    const next = current + 1;
    this.versionCounters.set(id, next);
    return next;
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tableConfigs = this.getTablesForResource(resourceName, operation);
    if (tableConfigs.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    const [ok, err, result] = await tryFn(async () => {
      const dataset = this.bigqueryClient.dataset(this.datasetId);
      for (const tableConfig of tableConfigs) {
        const [okTable, errTable] = await tryFn(async () => {
          const table = dataset.table(tableConfig.table);
          const mutability = tableConfig.mutability;
          let job;
          const shouldConvertToInsert = (mutability === "append-only" || mutability === "immutable") && (operation === "update" || operation === "delete");
          if (operation === "insert" || shouldConvertToInsert) {
            let transformedData = this.applyTransform(data, tableConfig.transform);
            if (shouldConvertToInsert) {
              transformedData = this._addTrackingFields(transformedData, operation, mutability, id);
            }
            try {
              job = await table.insert([transformedData]);
            } catch (error) {
              const { errors: errors2, response } = error;
              if (this.config.verbose) {
                console.error("[BigqueryReplicator] BigQuery insert error details:");
                if (errors2) console.error(JSON.stringify(errors2, null, 2));
                if (response) console.error(JSON.stringify(response, null, 2));
              }
              throw error;
            }
          } else if (operation === "update" && mutability === "mutable") {
            const transformedData = this.applyTransform(data, tableConfig.transform);
            const keys = Object.keys(transformedData).filter((k) => k !== "id");
            const setClause = keys.map((k) => `${k} = @${k}`).join(", ");
            const params = { id, ...transformedData };
            const query = `UPDATE \`${this.projectId}.${this.datasetId}.${tableConfig.table}\` SET ${setClause} WHERE id = @id`;
            const maxRetries = 2;
            let lastError = null;
            for (let attempt = 1; attempt <= maxRetries; attempt++) {
              const [ok2, error] = await tryFn(async () => {
                const [updateJob] = await this.bigqueryClient.createQueryJob({
                  query,
                  params,
                  location: this.location
                });
                await updateJob.getQueryResults();
                return [updateJob];
              });
              if (ok2) {
                job = ok2;
                break;
              } else {
                lastError = error;
                if (this.config.verbose) {
                  console.warn(`[BigqueryReplicator] Update attempt ${attempt} failed: ${error.message}`);
                  if (error.errors) {
                    console.error("[BigqueryReplicator] BigQuery update error details:");
                    console.error("Errors:", JSON.stringify(error.errors, null, 2));
                  }
                }
                if (error?.message?.includes("streaming buffer") && attempt < maxRetries) {
                  const delaySeconds = 30;
                  if (this.config.verbose) {
                    console.warn(`[BigqueryReplicator] Retrying in ${delaySeconds} seconds due to streaming buffer issue`);
                  }
                  await new Promise((resolve) => setTimeout(resolve, delaySeconds * 1e3));
                  continue;
                }
                throw error;
              }
            }
            if (!job) throw lastError;
          } else if (operation === "delete" && mutability === "mutable") {
            const query = `DELETE FROM \`${this.projectId}.${this.datasetId}.${tableConfig.table}\` WHERE id = @id`;
            try {
              const [deleteJob] = await this.bigqueryClient.createQueryJob({
                query,
                params: { id },
                location: this.location
              });
              await deleteJob.getQueryResults();
              job = [deleteJob];
            } catch (error) {
              if (this.config.verbose) {
                console.error("[BigqueryReplicator] BigQuery delete error details:");
                console.error("Query:", query);
                if (error.errors) console.error("Errors:", JSON.stringify(error.errors, null, 2));
                if (error.response) console.error("Response:", JSON.stringify(error.response, null, 2));
              }
              throw error;
            }
          } else {
            throw new Error(`Unsupported operation: ${operation}`);
          }
          results.push({
            table: tableConfig.table,
            success: true,
            jobId: job[0]?.id
          });
        });
        if (!okTable) {
          errors.push({
            table: tableConfig.table,
            error: errTable.message
          });
        }
      }
      if (this.logTable) {
        const [okLog, errLog] = await tryFn(async () => {
          const logTable = dataset.table(this.logTable);
          await logTable.insert([{
            resource_name: resourceName,
            operation,
            record_id: id,
            data: JSON.stringify(data),
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            source: "s3db-replicator"
          }]);
        });
        if (!okLog) {
        }
      }
      const success = errors.length === 0;
      if (errors.length > 0) {
        console.warn(`[BigqueryReplicator] Replication completed with errors for ${resourceName}:`, errors);
      }
      this.emit("plg:replicator:replicated", {
        replicator: this.name,
        resourceName,
        operation,
        id,
        tables: tableConfigs.map((t) => t.table),
        results,
        errors,
        success
      });
      return {
        success,
        results,
        errors,
        tables: tableConfigs.map((t) => t.table)
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[BigqueryReplicator] Replication failed for ${resourceName}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, res] = await tryFn(() => this.replicate(
        resourceName,
        record.operation,
        record.data,
        record.id,
        record.beforeData
      ));
      if (ok) {
        results.push(res);
      } else {
        if (this.config.verbose) {
          console.warn(`[BigqueryReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[BigqueryReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    return {
      success: errors.length === 0,
      results,
      errors
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.bigqueryClient) await this.initialize();
      const dataset = this.bigqueryClient.dataset(this.datasetId);
      await dataset.getMetadata();
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[BigqueryReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", { replicator: this.name, error: err.message });
    return false;
  }
  async cleanup() {
  }
  getStatus() {
    return {
      ...super.getStatus(),
      projectId: this.projectId,
      datasetId: this.datasetId,
      resources: this.resources,
      logTable: this.logTable,
      schemaSync: this.schemaSync,
      mutability: this.mutability
    };
  }
}

class DynamoDBReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.region = config.region || "us-east-1";
    this.accessKeyId = config.accessKeyId;
    this.secretAccessKey = config.secretAccessKey;
    this.endpoint = config.endpoint;
    this.credentials = config.credentials;
    this.client = null;
    this.docClient = null;
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"],
          primaryKey: "id"
          // Default primary key
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"], primaryKey: "id" };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"],
            primaryKey: item.primaryKey || "id",
            sortKey: item.sortKey
            // Optional sort key
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"],
          primaryKey: config.primaryKey || "id",
          sortKey: config.sortKey
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (this.region === "") {
      errors.push("AWS region is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const { DynamoDBClient } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
    const { DynamoDBDocumentClient, PutCommand, UpdateCommand, DeleteCommand } = requirePluginDependency("@aws-sdk/lib-dynamodb", "DynamoDBReplicator");
    this.PutCommand = PutCommand;
    this.UpdateCommand = UpdateCommand;
    this.DeleteCommand = DeleteCommand;
    const [ok, err] = await tryFn(async () => {
      const clientConfig = {
        region: this.region
      };
      if (this.endpoint) {
        clientConfig.endpoint = this.endpoint;
      }
      if (this.credentials) {
        clientConfig.credentials = this.credentials;
      } else if (this.accessKeyId && this.secretAccessKey) {
        clientConfig.credentials = {
          accessKeyId: this.accessKeyId,
          secretAccessKey: this.secretAccessKey
        };
      }
      this.client = new DynamoDBClient(clientConfig);
      this.docClient = DynamoDBDocumentClient.from(this.client);
      const { ListTablesCommand } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
      await this.client.send(new ListTablesCommand({ Limit: 1 }));
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to DynamoDB", {
        operation: "initialize",
        replicatorClass: "DynamoDBReplicator",
        region: this.region,
        endpoint: this.endpoint,
        original: err,
        suggestion: "Check AWS credentials and ensure DynamoDB is accessible"
      });
    }
    this.emit("connected", {
      replicator: "DynamoDBReplicator",
      region: this.region,
      endpoint: this.endpoint || "default"
    });
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "DynamoDBReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const tableConfig of this.resources[resourceName]) {
      if (!tableConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._putItem(tableConfig.table, data);
          case "update":
            return await this._updateItem(tableConfig.table, id, data, tableConfig);
          case "delete":
            return await this._deleteItem(tableConfig.table, id, tableConfig);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "DynamoDBReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          table: tableConfig.table,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[DynamoDBReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _putItem(table, data) {
    const cleanData = this._cleanInternalFields(data);
    const command = new this.PutCommand({
      TableName: table,
      Item: cleanData
    });
    const result = await this.docClient.send(command);
    return result;
  }
  async _updateItem(table, id, data, tableConfig) {
    const cleanData = this._cleanInternalFields(data);
    const updateExpressions = [];
    const expressionAttributeNames = {};
    const expressionAttributeValues = {};
    let index = 0;
    for (const [key2, value] of Object.entries(cleanData)) {
      if (key2 === tableConfig.primaryKey || key2 === tableConfig.sortKey) {
        continue;
      }
      const attrName = `#attr${index}`;
      const attrValue = `:val${index}`;
      expressionAttributeNames[attrName] = key2;
      expressionAttributeValues[attrValue] = value;
      updateExpressions.push(`${attrName} = ${attrValue}`);
      index++;
    }
    const key = { [tableConfig.primaryKey]: id };
    if (tableConfig.sortKey && cleanData[tableConfig.sortKey]) {
      key[tableConfig.sortKey] = cleanData[tableConfig.sortKey];
    }
    const command = new this.UpdateCommand({
      TableName: table,
      Key: key,
      UpdateExpression: `SET ${updateExpressions.join(", ")}`,
      ExpressionAttributeNames: expressionAttributeNames,
      ExpressionAttributeValues: expressionAttributeValues,
      ReturnValues: "ALL_NEW"
    });
    const result = await this.docClient.send(command);
    return result;
  }
  async _deleteItem(table, id, tableConfig) {
    const key = { [tableConfig.primaryKey]: id };
    const command = new this.DeleteCommand({
      TableName: table,
      Key: key
    });
    const result = await this.docClient.send(command);
    return result;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) {
        throw new Error("Client not initialized");
      }
      const { ListTablesCommand } = requirePluginDependency("@aws-sdk/client-dynamodb", "DynamoDBReplicator");
      await this.client.send(new ListTablesCommand({ Limit: 1 }));
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "DynamoDBReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client,
      region: this.region,
      endpoint: this.endpoint || "default",
      resources: Object.keys(this.resources)
    };
  }
  async cleanup() {
    if (this.client) {
      this.client.destroy();
      this.client = null;
      this.docClient = null;
    }
    await super.cleanup();
  }
}

class MongoDBReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host || "localhost";
    this.port = config.port || 27017;
    this.database = config.database;
    this.username = config.username;
    this.password = config.password;
    this.options = config.options || {};
    this.client = null;
    this.db = null;
    this.logCollection = config.logCollection;
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          collection: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { collection: item, actions: ["insert"] };
          }
          return {
            collection: item.collection,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          collection: config.collection,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.connectionString && !this.database) {
      errors.push("Database name or connection string is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, collections] of Object.entries(this.resources)) {
      for (const collectionConfig of collections) {
        if (!collectionConfig.collection) {
          errors.push(`Collection name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(collectionConfig.actions) || collectionConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const { MongoClient } = requirePluginDependency("mongodb", "MongoDBReplicator");
    const [ok, err] = await tryFn(async () => {
      let uri;
      if (this.connectionString) {
        uri = this.connectionString;
      } else {
        const auth = this.username && this.password ? `${encodeURIComponent(this.username)}:${encodeURIComponent(this.password)}@` : "";
        uri = `mongodb://${auth}${this.host}:${this.port}/${this.database}`;
      }
      this.client = new MongoClient(uri, {
        ...this.options,
        useUnifiedTopology: true,
        useNewUrlParser: true
      });
      await this.client.connect();
      this.db = this.client.db(this.database);
      await this.db.admin().ping();
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to MongoDB database", {
        operation: "initialize",
        replicatorClass: "MongoDBReplicator",
        host: this.host,
        port: this.port,
        database: this.database,
        original: err,
        suggestion: "Check MongoDB connection credentials and ensure database is accessible"
      });
    }
    if (this.logCollection) {
      await this._createLogCollection();
    }
    this.emit("connected", {
      replicator: "MongoDBReplicator",
      host: this.host,
      database: this.database
    });
  }
  async _createLogCollection() {
    const [ok] = await tryFn(async () => {
      const collections = await this.db.listCollections({ name: this.logCollection }).toArray();
      if (collections.length === 0) {
        await this.db.createCollection(this.logCollection);
        await this.db.collection(this.logCollection).createIndexes([
          { key: { resource_name: 1 } },
          { key: { timestamp: 1 } }
        ]);
      }
    });
    if (!ok && this.config.verbose) {
      console.warn("[MongoDBReplicator] Failed to create log collection");
    }
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "MongoDBReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const collectionConfig of this.resources[resourceName]) {
      if (!collectionConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._insertDocument(collectionConfig.collection, data);
          case "update":
            return await this._updateDocument(collectionConfig.collection, id, data);
          case "delete":
            return await this._deleteDocument(collectionConfig.collection, id);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "MongoDBReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
        if (this.logCollection) {
          await this._logOperation(resourceName, operation, id, data);
        }
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          collection: collectionConfig.collection,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[MongoDBReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _insertDocument(collectionName, data) {
    const cleanData = this._cleanInternalFields(data);
    const collection = this.db.collection(collectionName);
    const result = await collection.insertOne(cleanData);
    return result;
  }
  async _updateDocument(collectionName, id, data) {
    const cleanData = this._cleanInternalFields(data);
    const collection = this.db.collection(collectionName);
    delete cleanData._id;
    const result = await collection.updateOne(
      { _id: id },
      { $set: cleanData }
    );
    return result;
  }
  async _deleteDocument(collectionName, id) {
    const collection = this.db.collection(collectionName);
    const result = await collection.deleteOne({ _id: id });
    return result;
  }
  async _logOperation(resourceName, operation, id, data) {
    const [ok] = await tryFn(async () => {
      const collection = this.db.collection(this.logCollection);
      await collection.insertOne({
        resource_name: resourceName,
        operation,
        record_id: id,
        data,
        timestamp: /* @__PURE__ */ new Date()
      });
    });
    if (!ok && this.config.verbose) {
      console.warn("[MongoDBReplicator] Failed to log operation");
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key === "_id") {
        return;
      }
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) {
        throw new Error("Client not initialized");
      }
      await this.db.admin().ping();
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "MongoDBReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client && !!this.db,
      host: this.host,
      database: this.database,
      resources: Object.keys(this.resources)
    };
  }
  async cleanup() {
    if (this.client) {
      await this.client.close();
      this.client = null;
      this.db = null;
    }
    await super.cleanup();
  }
}

class MySQLReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host || "localhost";
    this.port = config.port || 3306;
    this.database = config.database;
    this.user = config.user;
    this.password = config.password;
    this.pool = null;
    this.ssl = config.ssl;
    this.connectionLimit = config.connectionLimit || 10;
    this.logTable = config.logTable;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false,
      dropMissingColumns: config.schemaSync?.dropMissingColumns || false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.database) {
      errors.push("Database name is required");
    }
    if (!this.user) {
      errors.push("Database user is required");
    }
    if (!this.password) {
      errors.push("Database password is required");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok, err] = await tryFn(async () => {
      const poolConfig = {
        host: this.host,
        port: this.port,
        user: this.user,
        password: this.password,
        database: this.database,
        connectionLimit: this.connectionLimit,
        waitForConnections: true,
        queueLimit: 0
      };
      if (this.ssl) {
        poolConfig.ssl = this.ssl;
      }
      this.pool = mysql.createPool(poolConfig);
      const connection = await this.pool.promise().getConnection();
      await connection.ping();
      connection.release();
    });
    if (!ok) {
      throw new ReplicationError("Failed to connect to MySQL database", {
        operation: "initialize",
        replicatorClass: "MySQLReplicator",
        host: this.host,
        port: this.port,
        database: this.database,
        original: err,
        suggestion: "Check MySQL connection credentials and ensure database is accessible"
      });
    }
    if (this.logTable) {
      await this._createLogTable();
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "MySQLReplicator",
      host: this.host,
      database: this.database
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[MySQLReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[MySQLReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const connection = await this.pool.promise().getConnection();
    try {
      const existingSchema = await getMySQLTableSchema(connection, tableName);
      if (!existingSchema) {
        if (!this.schemaSync.autoCreateTable) {
          throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
        }
        if (this.schemaSync.strategy === "validate-only") {
          throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
        }
        const createSQL = generateMySQLCreateTable(tableName, attributes);
        if (this.config.verbose) {
          console.log(`[MySQLReplicator] Creating table ${tableName}:
${createSQL}`);
        }
        await connection.query(createSQL);
        this.emit("table_created", {
          replicator: this.name,
          tableName,
          attributes: Object.keys(attributes)
        });
        return;
      }
      if (this.schemaSync.strategy === "drop-create") {
        if (this.config.verbose) {
          console.warn(`[MySQLReplicator] Dropping and recreating table ${tableName}`);
        }
        await connection.query(`DROP TABLE IF EXISTS ${tableName}`);
        const createSQL = generateMySQLCreateTable(tableName, attributes);
        await connection.query(createSQL);
        this.emit("table_recreated", {
          replicator: this.name,
          tableName,
          attributes: Object.keys(attributes)
        });
        return;
      }
      if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
        const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          if (this.config.verbose) {
            console.log(`[MySQLReplicator] Altering table ${tableName}:`, alterStatements);
          }
          for (const stmt of alterStatements) {
            await connection.query(stmt);
          }
          this.emit("table_altered", {
            replicator: this.name,
            tableName,
            addedColumns: alterStatements.length
          });
        }
      }
      if (this.schemaSync.strategy === "validate-only") {
        const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
        }
      }
    } finally {
      connection.release();
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  async _createLogTable() {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok] = await tryFn(async () => {
      await this.pool.promise().query(`
        CREATE TABLE IF NOT EXISTS ${mysql.escapeId(this.logTable)} (
          id INT AUTO_INCREMENT PRIMARY KEY,
          resource_name VARCHAR(255) NOT NULL,
          operation VARCHAR(50) NOT NULL,
          record_id VARCHAR(255),
          data JSON,
          timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          INDEX idx_resource (resource_name),
          INDEX idx_timestamp (timestamp)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
      `);
    });
    if (!ok && this.config.verbose) {
      console.warn("[MySQLReplicator] Failed to create log table");
    }
  }
  async replicate(resourceName, operation, data, id) {
    if (!this.resources[resourceName]) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "MySQLReplicator",
        resourceName,
        configuredResources: Object.keys(this.resources),
        suggestion: "Add resource to replicator resources configuration"
      });
    }
    const results = [];
    for (const tableConfig of this.resources[resourceName]) {
      if (!tableConfig.actions.includes(operation)) {
        continue;
      }
      const [ok, error, result] = await tryFn(async () => {
        switch (operation) {
          case "insert":
            return await this._insertRecord(tableConfig.table, data);
          case "update":
            return await this._updateRecord(tableConfig.table, id, data);
          case "delete":
            return await this._deleteRecord(tableConfig.table, id);
          default:
            throw new ReplicationError(`Unsupported operation: ${operation}`, {
              operation: "replicate",
              replicatorClass: "MySQLReplicator",
              invalidOperation: operation,
              supportedOperations: ["insert", "update", "delete"]
            });
        }
      });
      if (ok) {
        results.push(result);
        if (this.logTable) {
          await this._logOperation(resourceName, operation, id, data);
        }
      } else {
        this.emit("replication_error", {
          resource: resourceName,
          operation,
          table: tableConfig.table,
          error: error.message
        });
        if (this.config.verbose) {
          console.error(`[MySQLReplicator] Failed to replicate ${operation} for ${resourceName}:`, error);
        }
      }
    }
    return results.length > 0 ? results[0] : null;
  }
  async _insertRecord(table, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const cleanData = this._cleanInternalFields(data);
    const columns = Object.keys(cleanData);
    const values = Object.values(cleanData);
    const placeholders = values.map(() => "?").join(", ");
    const query = `INSERT INTO ${mysql.escapeId(table)} (${columns.map((c) => mysql.escapeId(c)).join(", ")}) VALUES (${placeholders})`;
    const [result] = await this.pool.promise().query(query, values);
    return result;
  }
  async _updateRecord(table, id, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const cleanData = this._cleanInternalFields(data);
    const updates = Object.keys(cleanData).map((col) => `${mysql.escapeId(col)} = ?`).join(", ");
    const values = [...Object.values(cleanData), id];
    const query = `UPDATE ${mysql.escapeId(table)} SET ${updates} WHERE id = ?`;
    const [result] = await this.pool.promise().query(query, values);
    return result;
  }
  async _deleteRecord(table, id) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const query = `DELETE FROM ${mysql.escapeId(table)} WHERE id = ?`;
    const [result] = await this.pool.promise().query(query, [id]);
    return result;
  }
  async _logOperation(resourceName, operation, id, data) {
    const mysql = requirePluginDependency("mysql2", "MySQLReplicator");
    const [ok] = await tryFn(async () => {
      const query = `INSERT INTO ${mysql.escapeId(this.logTable)} (resource_name, operation, record_id, data) VALUES (?, ?, ?, ?)`;
      await this.pool.promise().query(query, [resourceName, operation, id, JSON.stringify(data)]);
    });
    if (!ok && this.config.verbose) {
      console.warn("[MySQLReplicator] Failed to log operation");
    }
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(
        () => this.replicate(resourceName, record.operation, record.data, record.id)
      );
      if (ok) {
        results.push(result);
      } else {
        errors.push({ id: record.id, error: err.message });
      }
    }
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.pool) {
        throw new Error("Pool not initialized");
      }
      const connection = await this.pool.promise().getConnection();
      await connection.ping();
      connection.release();
      return true;
    });
    if (!ok) {
      this.emit("connection_error", { replicator: "MySQLReplicator", error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.pool,
      host: this.host,
      database: this.database,
      resources: Object.keys(this.resources),
      poolConnections: this.pool ? this.pool.pool.allConnections.length : 0,
      schemaSync: this.schemaSync
    };
  }
  async cleanup() {
    if (this.pool) {
      await this.pool.end();
      this.pool = null;
    }
    await super.cleanup();
  }
}

class PlanetScaleReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.host = config.host;
    this.username = config.username;
    this.password = config.password;
    this.connection = null;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.host) errors.push("Host is required");
    if (!this.username) errors.push("Username is required");
    if (!this.password) errors.push("Password is required");
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("planetscale-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@planetscale/database'));
    if (!ok) {
      throw new ReplicationError("Failed to import PlanetScale SDK", {
        operation: "initialize",
        replicatorClass: "PlanetScaleReplicator",
        original: err,
        suggestion: "Install @planetscale/database: pnpm add @planetscale/database"
      });
    }
    const { connect } = sdk;
    this.connection = connect({
      host: this.host,
      username: this.username,
      password: this.password
    });
    const [okTest, errTest] = await tryFn(async () => {
      await this.connection.execute("SELECT 1");
    });
    if (!okTest) {
      throw new ReplicationError("Failed to connect to PlanetScale database", {
        operation: "initialize",
        replicatorClass: "PlanetScaleReplicator",
        host: this.host,
        original: errTest,
        suggestion: "Check PlanetScale credentials"
      });
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "PlanetScaleReplicator",
      host: this.host
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[PlanetScaleReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[PlanetScaleReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const existingSchema = await getMySQLTableSchema(this.connection, tableName);
    if (!existingSchema) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generateMySQLCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[PlanetScaleReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.connection.execute(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[PlanetScaleReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.connection.execute(`DROP TABLE IF EXISTS ${tableName}`);
      const createSQL = generateMySQLCreateTable(tableName, attributes);
      await this.connection.execute(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        if (this.config.verbose) {
          console.log(`[PlanetScaleReplicator] Altering table ${tableName}:`, alterStatements);
        }
        for (const stmt of alterStatements) {
          await this.connection.execute(stmt);
        }
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: alterStatements.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const alterStatements = generateMySQLAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    for (const table of tables) {
      const [okTable, errTable] = await tryFn(async () => {
        if (operation === "insert") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData);
          const values = keys.map((k) => cleanData[k]);
          const placeholders = keys.map(() => "?").join(", ");
          const sql = `INSERT INTO ${table} (${keys.map((k) => `\`${k}\``).join(", ")}) VALUES (${placeholders}) ON DUPLICATE KEY UPDATE id=id`;
          await this.connection.execute(sql, values);
        } else if (operation === "update") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData).filter((k) => k !== "id");
          const setClause = keys.map((k) => `\`${k}\`=?`).join(", ");
          const values = keys.map((k) => cleanData[k]);
          values.push(id);
          const sql = `UPDATE ${table} SET ${setClause} WHERE id=?`;
          await this.connection.execute(sql, values);
        } else if (operation === "delete") {
          const sql = `DELETE FROM ${table} WHERE id=?`;
          await this.connection.execute(sql, [id]);
        }
        results.push({ table, success: true });
      });
      if (!okTable) {
        errors.push({ table, error: errTable.message });
      }
    }
    const success = errors.length === 0;
    this.emit("plg:replicator:replicated", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      tables,
      results,
      errors,
      success
    });
    return { success, results, errors, tables };
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    this.connection = null;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.connection,
      host: this.host,
      resources: Object.keys(this.resources),
      schemaSync: this.schemaSync
    };
  }
}

class PostgresReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.connectionString = config.connectionString;
    this.host = config.host;
    this.port = config.port || 5432;
    this.database = config.database;
    this.user = config.user;
    this.password = config.password;
    this.client = null;
    this.ssl = config.ssl;
    this.logTable = config.logTable;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false,
      dropMissingColumns: config.schemaSync?.dropMissingColumns || false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.connectionString && (!this.host || !this.database)) {
      errors.push("Either connectionString or host+database must be provided");
    }
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
        const validActions = ["insert", "update", "delete"];
        const invalidActions = tableConfig.actions.filter((action) => !validActions.includes(action));
        if (invalidActions.length > 0) {
          errors.push(`Invalid actions for resource '${resourceName}': ${invalidActions.join(", ")}. Valid actions: ${validActions.join(", ")}`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("postgresql-replicator");
    const [ok, err, sdk] = await tryFn(() => import('pg'));
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[PostgresReplicator] Failed to import pg SDK: ${err.message}`);
      }
      this.emit("initialization_error", {
        replicator: this.name,
        error: err.message
      });
      throw err;
    }
    const { Client } = sdk;
    const config = this.connectionString ? {
      connectionString: this.connectionString,
      ssl: this.ssl
    } : {
      host: this.host,
      port: this.port,
      database: this.database,
      user: this.user,
      password: this.password,
      ssl: this.ssl
    };
    this.client = new Client(config);
    await this.client.connect();
    if (this.logTable) {
      await this.createLogTableIfNotExists();
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      database: this.database || "postgres",
      resources: Object.keys(this.resources)
    });
  }
  async createLogTableIfNotExists() {
    const createTableQuery = `
      CREATE TABLE IF NOT EXISTS ${this.logTable} (
        id SERIAL PRIMARY KEY,
        resource_name VARCHAR(255) NOT NULL,
        operation VARCHAR(50) NOT NULL,
        record_id VARCHAR(255) NOT NULL,
        data JSONB,
        timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
        source VARCHAR(100) DEFAULT 's3db-replicator',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
      );
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_resource_name ON ${this.logTable}(resource_name);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_operation ON ${this.logTable}(operation);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_record_id ON ${this.logTable}(record_id);
      CREATE INDEX IF NOT EXISTS idx_${this.logTable}_timestamp ON ${this.logTable}(timestamp);
    `;
    await this.client.query(createTableQuery);
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[PostgresReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[PostgresReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const existingSchema = await getPostgresTableSchema(this.client, tableName);
    if (!existingSchema) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generatePostgresCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[PostgresReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.client.query(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[PostgresReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.client.query(`DROP TABLE IF EXISTS ${tableName} CASCADE`);
      const createSQL = generatePostgresCreateTable(tableName, attributes);
      await this.client.query(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const alterStatements = generatePostgresAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        if (this.config.verbose) {
          console.log(`[PostgresReplicator] Altering table ${tableName}:`, alterStatements);
        }
        for (const stmt of alterStatements) {
          await this.client.query(stmt);
        }
        this.emit("table_altered", {
          replicator: this.name,
          tableName,
          addedColumns: alterStatements.length
        });
      }
    }
    if (this.schemaSync.strategy === "validate-only") {
      const alterStatements = generatePostgresAlterTable(tableName, attributes, existingSchema);
      if (alterStatements.length > 0) {
        throw new Error(`Table ${tableName} schema mismatch. Missing columns: ${alterStatements.length}`);
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    const [ok, err, result] = await tryFn(async () => {
      for (const table of tables) {
        const [okTable, errTable] = await tryFn(async () => {
          let result2;
          if (operation === "insert") {
            const cleanData = this._cleanInternalFields(data);
            const keys = Object.keys(cleanData);
            const values = keys.map((k) => cleanData[k]);
            const columns = keys.map((k) => `"${k}"`).join(", ");
            const params = keys.map((_, i) => `$${i + 1}`).join(", ");
            const sql = `INSERT INTO ${table} (${columns}) VALUES (${params}) ON CONFLICT (id) DO NOTHING RETURNING *`;
            result2 = await this.client.query(sql, values);
          } else if (operation === "update") {
            const cleanData = this._cleanInternalFields(data);
            const keys = Object.keys(cleanData).filter((k) => k !== "id");
            const setClause = keys.map((k, i) => `"${k}"=$${i + 1}`).join(", ");
            const values = keys.map((k) => cleanData[k]);
            values.push(id);
            const sql = `UPDATE ${table} SET ${setClause} WHERE id=$${keys.length + 1} RETURNING *`;
            result2 = await this.client.query(sql, values);
          } else if (operation === "delete") {
            const sql = `DELETE FROM ${table} WHERE id=$1 RETURNING *`;
            result2 = await this.client.query(sql, [id]);
          } else {
            throw new Error(`Unsupported operation: ${operation}`);
          }
          results.push({
            table,
            success: true,
            rows: result2.rows,
            rowCount: result2.rowCount
          });
        });
        if (!okTable) {
          errors.push({
            table,
            error: errTable.message
          });
        }
      }
      if (this.logTable) {
        const [okLog, errLog] = await tryFn(async () => {
          await this.client.query(
            `INSERT INTO ${this.logTable} (resource_name, operation, record_id, data, timestamp, source) VALUES ($1, $2, $3, $4, $5, $6)`,
            [resourceName, operation, id, JSON.stringify(data), (/* @__PURE__ */ new Date()).toISOString(), "s3db-replicator"]
          );
        });
        if (!okLog) {
        }
      }
      const success = errors.length === 0;
      if (errors.length > 0) {
        console.warn(`[PostgresReplicator] Replication completed with errors for ${resourceName}:`, errors);
      }
      this.emit("plg:replicator:replicated", {
        replicator: this.name,
        resourceName,
        operation,
        id,
        tables,
        results,
        errors,
        success
      });
      return {
        success,
        results,
        errors,
        tables
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[PostgresReplicator] Replication failed for ${resourceName}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resourceName, records) {
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, res] = await tryFn(() => this.replicate(
        resourceName,
        record.operation,
        record.data,
        record.id,
        record.beforeData
      ));
      if (ok) {
        results.push(res);
      } else {
        if (this.config.verbose) {
          console.warn(`[PostgresReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[PostgresReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    return {
      success: errors.length === 0,
      results,
      errors
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.client) await this.initialize();
      await this.client.query("SELECT 1");
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[PostgresReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", { replicator: this.name, error: err.message });
    return false;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    if (this.client) await this.client.end();
  }
  getStatus() {
    return {
      ...super.getStatus(),
      database: this.database || "postgres",
      resources: this.resources,
      logTable: this.logTable,
      schemaSync: this.schemaSync
    };
  }
}

const S3_DEFAULT_REGION = "us-east-1";
const S3_DEFAULT_ENDPOINT = "https://s3.us-east-1.amazonaws.com";
class ConnectionString {
  constructor(connectionString) {
    let uri;
    const [ok, err, parsed] = tryFn(() => new URL(connectionString));
    if (!ok) {
      throw new ConnectionStringError("Invalid connection string: " + connectionString, { original: err, input: connectionString });
    }
    uri = parsed;
    this.region = S3_DEFAULT_REGION;
    if (uri.protocol === "s3:") this.defineFromS3(uri);
    else this.defineFromCustomUri(uri);
    for (const [k, v] of uri.searchParams.entries()) {
      this[k] = v;
    }
  }
  defineFromS3(uri) {
    const [okBucket, errBucket, bucket] = tryFnSync(() => decodeURIComponent(uri.hostname));
    if (!okBucket) throw new ConnectionStringError("Invalid bucket in connection string", { original: errBucket, input: uri.hostname });
    this.bucket = bucket || "s3db";
    const [okUser, errUser, user] = tryFnSync(() => decodeURIComponent(uri.username));
    if (!okUser) throw new ConnectionStringError("Invalid accessKeyId in connection string", { original: errUser, input: uri.username });
    this.accessKeyId = user;
    const [okPass, errPass, pass] = tryFnSync(() => decodeURIComponent(uri.password));
    if (!okPass) throw new ConnectionStringError("Invalid secretAccessKey in connection string", { original: errPass, input: uri.password });
    this.secretAccessKey = pass;
    this.endpoint = S3_DEFAULT_ENDPOINT;
    if (["/", "", null].includes(uri.pathname)) {
      this.keyPrefix = "";
    } else {
      let [, ...subpath] = uri.pathname.split("/");
      this.keyPrefix = [...subpath || []].join("/");
    }
  }
  defineFromCustomUri(uri) {
    this.forcePathStyle = true;
    this.endpoint = uri.origin;
    const [okUser, errUser, user] = tryFnSync(() => decodeURIComponent(uri.username));
    if (!okUser) throw new ConnectionStringError("Invalid accessKeyId in connection string", { original: errUser, input: uri.username });
    this.accessKeyId = user;
    const [okPass, errPass, pass] = tryFnSync(() => decodeURIComponent(uri.password));
    if (!okPass) throw new ConnectionStringError("Invalid secretAccessKey in connection string", { original: errPass, input: uri.password });
    this.secretAccessKey = pass;
    if (["/", "", null].includes(uri.pathname)) {
      this.bucket = "s3db";
      this.keyPrefix = "";
    } else {
      let [, bucket, ...subpath] = uri.pathname.split("/");
      if (!bucket) {
        this.bucket = "s3db";
      } else {
        const [okBucket, errBucket, bucketDecoded] = tryFnSync(() => decodeURIComponent(bucket));
        if (!okBucket) throw new ConnectionStringError("Invalid bucket in connection string", { original: errBucket, input: bucket });
        this.bucket = bucketDecoded;
      }
      this.keyPrefix = [...subpath || []].join("/");
    }
  }
}

class S3Client extends EventEmitter {
  constructor({
    verbose = false,
    id = null,
    AwsS3Client: AwsS3Client2,
    connectionString,
    parallelism = 10,
    httpClientOptions = {}
  }) {
    super();
    this.verbose = verbose;
    this.id = id ?? idGenerator(77);
    this.parallelism = parallelism;
    this.config = new ConnectionString(connectionString);
    this.httpClientOptions = {
      keepAlive: true,
      // Enabled for better performance
      keepAliveMsecs: 1e3,
      // 1 second keep-alive
      maxSockets: httpClientOptions.maxSockets || 500,
      // High concurrency support
      maxFreeSockets: httpClientOptions.maxFreeSockets || 100,
      // Better connection reuse
      timeout: 6e4,
      // 60 second timeout
      ...httpClientOptions
    };
    this.client = AwsS3Client2 || this.createClient();
  }
  createClient() {
    const httpAgent = new Agent(this.httpClientOptions);
    const httpsAgent = new Agent$1(this.httpClientOptions);
    const httpHandler = new NodeHttpHandler({
      httpAgent,
      httpsAgent
    });
    let options = {
      region: this.config.region,
      endpoint: this.config.endpoint,
      requestHandler: httpHandler
    };
    if (this.config.forcePathStyle) options.forcePathStyle = true;
    if (this.config.accessKeyId) {
      options.credentials = {
        accessKeyId: this.config.accessKeyId,
        secretAccessKey: this.config.secretAccessKey
      };
    }
    const client = new S3Client$1(options);
    client.middlewareStack.add(
      (next, context) => async (args) => {
        if (context.commandName === "DeleteObjectsCommand") {
          const body = args.request.body;
          if (body && typeof body === "string") {
            const contentMd5 = await md5(body);
            args.request.headers["Content-MD5"] = contentMd5;
          }
        }
        return next(args);
      },
      {
        step: "build",
        name: "addContentMd5ForDeleteObjects",
        priority: "high"
      }
    );
    return client;
  }
  async sendCommand(command) {
    this.emit("cl:request", command.constructor.name, command.input);
    const [ok, err, response] = await tryFn(() => this.client.send(command));
    if (!ok) {
      const bucket = this.config.bucket;
      const key = command.input && command.input.Key;
      throw mapAwsError(err, {
        bucket,
        key,
        commandName: command.constructor.name,
        commandInput: command.input
      });
    }
    this.emit("cl:response", command.constructor.name, response, command.input);
    return response;
  }
  async putObject({ key, metadata, contentType, body, contentEncoding, contentLength, ifMatch }) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    keyPrefix ? path$1.join(keyPrefix, key) : key;
    const stringMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        stringMetadata[validKey] = encoded;
      }
    }
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path$1.join(keyPrefix, key) : key,
      Metadata: stringMetadata,
      Body: body || Buffer.alloc(0)
    };
    if (contentType !== void 0) options.ContentType = contentType;
    if (contentEncoding !== void 0) options.ContentEncoding = contentEncoding;
    if (contentLength !== void 0) options.ContentLength = contentLength;
    if (ifMatch !== void 0) options.IfMatch = ifMatch;
    const [ok, err, response] = await tryFn(() => this.sendCommand(new PutObjectCommand(options)));
    this.emit("cl:PutObject", err || response, { key, metadata, contentType, body, contentEncoding, contentLength });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "PutObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async getObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path$1.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(async () => {
      const res = await this.sendCommand(new GetObjectCommand(options));
      if (res.Metadata) {
        const decodedMetadata = {};
        for (const [key2, value] of Object.entries(res.Metadata)) {
          decodedMetadata[key2] = metadataDecode(value);
        }
        res.Metadata = decodedMetadata;
      }
      return res;
    });
    this.emit("cl:GetObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "GetObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async headObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path$1.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(async () => {
      const res = await this.sendCommand(new HeadObjectCommand(options));
      if (res.Metadata) {
        const decodedMetadata = {};
        for (const [key2, value] of Object.entries(res.Metadata)) {
          decodedMetadata[key2] = metadataDecode(value);
        }
        res.Metadata = decodedMetadata;
      }
      return res;
    });
    this.emit("cl:HeadObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "HeadObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async copyObject({ from, to, metadata, metadataDirective, contentType }) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path$1.join(keyPrefix, to) : to,
      CopySource: path$1.join(this.config.bucket, keyPrefix ? path$1.join(keyPrefix, from) : from)
    };
    if (metadataDirective) {
      options.MetadataDirective = metadataDirective;
    }
    if (metadata && typeof metadata === "object") {
      const encodedMetadata = {};
      for (const [key, value] of Object.entries(metadata)) {
        const { encoded } = metadataEncode(value);
        encodedMetadata[key] = encoded;
      }
      options.Metadata = encodedMetadata;
    }
    if (contentType) {
      options.ContentType = contentType;
    }
    const [ok, err, response] = await tryFn(() => this.sendCommand(new CopyObjectCommand(options)));
    this.emit("cl:CopyObject", err || response, { from, to, metadataDirective });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key: to,
        commandName: "CopyObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async exists(key) {
    const [ok, err] = await tryFn(() => this.headObject(key));
    if (ok) return true;
    if (err.name === "NoSuchKey" || err.name === "NotFound") return false;
    throw err;
  }
  async deleteObject(key) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    keyPrefix ? path$1.join(keyPrefix, key) : key;
    const options = {
      Bucket: this.config.bucket,
      Key: keyPrefix ? path$1.join(keyPrefix, key) : key
    };
    const [ok, err, response] = await tryFn(() => this.sendCommand(new DeleteObjectCommand(options)));
    this.emit("cl:DeleteObject", err || response, { key });
    if (!ok) {
      throw mapAwsError(err, {
        bucket: this.config.bucket,
        key,
        commandName: "DeleteObjectCommand",
        commandInput: options
      });
    }
    return response;
  }
  async deleteObjects(keys) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    const packages = chunk(keys, 1e3);
    const { results, errors } = await PromisePool.for(packages).withConcurrency(this.parallelism).process(async (keys2) => {
      for (const key of keys2) {
        keyPrefix ? path$1.join(keyPrefix, key) : key;
        this.config.bucket;
        await this.exists(key);
      }
      const options = {
        Bucket: this.config.bucket,
        Delete: {
          Objects: keys2.map((key) => ({
            Key: keyPrefix ? path$1.join(keyPrefix, key) : key
          }))
        }
      };
      let response;
      const [ok, err, res] = await tryFn(() => this.sendCommand(new DeleteObjectsCommand(options)));
      if (!ok) throw err;
      response = res;
      if (response && response.Errors && response.Errors.length > 0) ;
      if (response && response.Deleted && response.Deleted.length !== keys2.length) ;
      return response;
    });
    const report = {
      deleted: results,
      notFound: errors
    };
    this.emit("cl:DeleteObjects", report, keys);
    return report;
  }
  /**
   * Delete all objects under a specific prefix using efficient pagination
   * @param {Object} options - Delete options
   * @param {string} options.prefix - S3 prefix to delete
   * @returns {Promise<number>} Number of objects deleted
   */
  async deleteAll({ prefix } = {}) {
    const keyPrefix = typeof this.config.keyPrefix === "string" ? this.config.keyPrefix : "";
    let continuationToken;
    let totalDeleted = 0;
    do {
      const listCommand = new ListObjectsV2Command({
        Bucket: this.config.bucket,
        Prefix: keyPrefix ? path$1.join(keyPrefix, prefix || "") : prefix || "",
        ContinuationToken: continuationToken
      });
      const listResponse = await this.client.send(listCommand);
      if (listResponse.Contents && listResponse.Contents.length > 0) {
        const deleteCommand = new DeleteObjectsCommand({
          Bucket: this.config.bucket,
          Delete: {
            Objects: listResponse.Contents.map((obj) => ({ Key: obj.Key }))
          }
        });
        const deleteResponse = await this.client.send(deleteCommand);
        const deletedCount = deleteResponse.Deleted ? deleteResponse.Deleted.length : 0;
        totalDeleted += deletedCount;
        this.emit("cl:DeleteAll", {
          prefix,
          batch: deletedCount,
          total: totalDeleted
        });
      }
      continuationToken = listResponse.IsTruncated ? listResponse.NextContinuationToken : void 0;
    } while (continuationToken);
    this.emit("cl:DeleteAllComplete", {
      prefix,
      totalDeleted
    });
    return totalDeleted;
  }
  async moveObject({ from, to }) {
    const [ok, err] = await tryFn(async () => {
      await this.copyObject({ from, to });
      await this.deleteObject(from);
    });
    if (!ok) {
      throw new UnknownError("Unknown error in moveObject", { bucket: this.config.bucket, from, to, original: err });
    }
    return true;
  }
  async listObjects({
    prefix,
    maxKeys = 1e3,
    continuationToken
  } = {}) {
    const options = {
      Bucket: this.config.bucket,
      MaxKeys: maxKeys,
      ContinuationToken: continuationToken,
      Prefix: this.config.keyPrefix ? path$1.join(this.config.keyPrefix, prefix || "") : prefix || ""
    };
    const [ok, err, response] = await tryFn(() => this.sendCommand(new ListObjectsV2Command(options)));
    if (!ok) {
      throw new UnknownError("Unknown error in listObjects", { prefix, bucket: this.config.bucket, original: err });
    }
    this.emit("cl:ListObjects", response, options);
    return response;
  }
  async count({ prefix } = {}) {
    let count = 0;
    let truncated = true;
    let continuationToken;
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const response = await this.listObjects(options);
      count += response.KeyCount || 0;
      truncated = response.IsTruncated || false;
      continuationToken = response.NextContinuationToken;
    }
    this.emit("cl:Count", count, { prefix });
    return count;
  }
  async getAllKeys({ prefix } = {}) {
    let keys = [];
    let truncated = true;
    let continuationToken;
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const response = await this.listObjects(options);
      if (response.Contents) {
        keys = keys.concat(response.Contents.map((x) => x.Key));
      }
      truncated = response.IsTruncated || false;
      continuationToken = response.NextContinuationToken;
    }
    if (this.config.keyPrefix) {
      keys = keys.map((x) => x.replace(this.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x);
    }
    this.emit("cl:GetAllKeys", keys, { prefix });
    return keys;
  }
  async getContinuationTokenAfterOffset(params = {}) {
    const {
      prefix,
      offset = 1e3
    } = params;
    if (offset === 0) return null;
    let truncated = true;
    let continuationToken;
    let skipped = 0;
    while (truncated) {
      let maxKeys = offset < 1e3 ? offset : offset - skipped > 1e3 ? 1e3 : offset - skipped;
      const options = {
        prefix,
        maxKeys,
        continuationToken
      };
      const res = await this.listObjects(options);
      if (res.Contents) {
        skipped += res.Contents.length;
      }
      truncated = res.IsTruncated || false;
      continuationToken = res.NextContinuationToken;
      if (skipped >= offset) {
        break;
      }
    }
    this.emit("cl:GetContinuationTokenAfterOffset", continuationToken || null, params);
    return continuationToken || null;
  }
  async getKeysPage(params = {}) {
    const {
      prefix,
      offset = 0,
      amount = 100
    } = params;
    let keys = [];
    let truncated = true;
    let continuationToken;
    if (offset > 0) {
      continuationToken = await this.getContinuationTokenAfterOffset({
        prefix,
        offset
      });
      if (!continuationToken) {
        this.emit("cl:GetKeysPage", [], params);
        return [];
      }
    }
    while (truncated) {
      const options = {
        prefix,
        continuationToken
      };
      const res = await this.listObjects(options);
      if (res.Contents) {
        keys = keys.concat(res.Contents.map((x) => x.Key));
      }
      truncated = res.IsTruncated || false;
      continuationToken = res.NextContinuationToken;
      if (keys.length >= amount) {
        keys = keys.slice(0, amount);
        break;
      }
    }
    if (this.config.keyPrefix) {
      keys = keys.map((x) => x.replace(this.config.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace(`/`, "") : x);
    }
    this.emit("cl:GetKeysPage", keys, params);
    return keys;
  }
  async moveAllObjects({ prefixFrom, prefixTo }) {
    const keys = await this.getAllKeys({ prefix: prefixFrom });
    const { results, errors } = await PromisePool.for(keys).withConcurrency(this.parallelism).process(async (key) => {
      const to = key.replace(prefixFrom, prefixTo);
      const [ok, err] = await tryFn(async () => {
        await this.moveObject({
          from: key,
          to
        });
      });
      if (!ok) {
        throw new UnknownError("Unknown error in moveAllObjects", { bucket: this.config.bucket, from: key, to, original: err });
      }
      return to;
    });
    this.emit("cl:MoveAllObjects", { results, errors }, { prefixFrom, prefixTo });
    if (errors.length > 0) {
      throw new UnknownError("Some objects could not be moved", {
        bucket: this.config.bucket,
        operation: "moveAllObjects",
        prefixFrom,
        prefixTo,
        totalKeys: keys.length,
        failedCount: errors.length,
        successCount: results.length,
        errors: errors.map((e) => ({ message: e.message, raw: e.raw })),
        suggestion: "Check S3 permissions and retry failed objects individually"
      });
    }
    return results;
  }
}

class Database extends EventEmitter {
  constructor(options) {
    super();
    this.id = (() => {
      const [ok, err, id] = tryFn(() => idGenerator(7));
      return ok && id ? id : `db-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    })();
    this.version = "1";
    this.s3dbVersion = (() => {
      const [ok, err, version] = tryFn(() => true ? "13.5.1" : "latest");
      return ok ? version : "latest";
    })();
    this._resourcesMap = {};
    this.resources = new Proxy(this._resourcesMap, {
      get: (target, prop) => {
        if (typeof prop === "symbol" || prop === "constructor" || prop === "toJSON") {
          return target[prop];
        }
        if (target[prop]) {
          return target[prop];
        }
        return void 0;
      },
      // Support Object.keys(), Object.entries(), etc.
      ownKeys: (target) => {
        return Object.keys(target);
      },
      getOwnPropertyDescriptor: (target, prop) => {
        return Object.getOwnPropertyDescriptor(target, prop);
      }
    });
    this.savedMetadata = null;
    this.options = options;
    this.verbose = options.verbose || false;
    this.parallelism = parseInt(options.parallelism + "") || 10;
    this.pluginList = options.plugins || [];
    this.pluginRegistry = {};
    this.plugins = this.pluginRegistry;
    this.cache = options.cache;
    this.passphrase = options.passphrase || "secret";
    this.versioningEnabled = options.versioningEnabled || false;
    this.persistHooks = options.persistHooks || false;
    this.strictValidation = options.strictValidation !== false;
    this.strictHooks = options.strictHooks || false;
    this._initHooks();
    let connectionString = options.connectionString;
    if (!connectionString && (options.bucket || options.accessKeyId || options.secretAccessKey)) {
      const { bucket, region, accessKeyId, secretAccessKey, endpoint, forcePathStyle } = options;
      if (endpoint) {
        const url = new URL(endpoint);
        if (accessKeyId) url.username = encodeURIComponent(accessKeyId);
        if (secretAccessKey) url.password = encodeURIComponent(secretAccessKey);
        url.pathname = `/${bucket || "s3db"}`;
        if (forcePathStyle) {
          url.searchParams.set("forcePathStyle", "true");
        }
        connectionString = url.toString();
      } else if (accessKeyId && secretAccessKey) {
        const params = new URLSearchParams();
        params.set("region", region || "us-east-1");
        if (forcePathStyle) {
          params.set("forcePathStyle", "true");
        }
        connectionString = `s3://${encodeURIComponent(accessKeyId)}:${encodeURIComponent(secretAccessKey)}@${bucket || "s3db"}?${params.toString()}`;
      }
    }
    this.client = options.client || new S3Client({
      verbose: this.verbose,
      parallelism: this.parallelism,
      connectionString
    });
    this.connectionString = connectionString;
    this.bucket = this.client.bucket;
    this.keyPrefix = this.client.keyPrefix;
    this._registerExitListener();
  }
  /**
   * Register process exit listener for automatic cleanup
   * @private
   */
  _registerExitListener() {
    if (!this._exitListenerRegistered && typeof process !== "undefined") {
      this._exitListenerRegistered = true;
      this._exitListener = async () => {
        if (this.isConnected()) {
          await tryFn(() => this.disconnect());
        }
      };
      process.on("exit", this._exitListener);
    }
  }
  async connect() {
    this._registerExitListener();
    await this.startPlugins();
    let metadata = null;
    let needsHealing = false;
    let healingLog = [];
    if (await this.client.exists(`s3db.json`)) {
      const [ok, error] = await tryFn(async () => {
        const request = await this.client.getObject(`s3db.json`);
        const rawContent = await streamToString(request?.Body);
        const [parseOk, parseError, parsedData] = tryFn(() => JSON.parse(rawContent));
        if (!parseOk) {
          healingLog.push("JSON parsing failed - attempting recovery");
          needsHealing = true;
          metadata = await this._attemptJsonRecovery(rawContent, healingLog);
          if (!metadata) {
            await this._createCorruptedBackup(rawContent);
            healingLog.push("Created backup of corrupted file - starting with blank metadata");
            metadata = this.blankMetadataStructure();
          }
        } else {
          metadata = parsedData;
        }
        const healedMetadata = await this._validateAndHealMetadata(metadata, healingLog);
        if (healedMetadata !== metadata) {
          metadata = healedMetadata;
          needsHealing = true;
        }
      });
      if (!ok) {
        healingLog.push(`Critical error reading s3db.json: ${error.message}`);
        await this._createCorruptedBackup();
        metadata = this.blankMetadataStructure();
        needsHealing = true;
      }
    } else {
      metadata = this.blankMetadataStructure();
      await this.uploadMetadataFile();
    }
    if (needsHealing) {
      await this._uploadHealedMetadata(metadata, healingLog);
    }
    this.savedMetadata = metadata;
    const definitionChanges = this.detectDefinitionChanges(metadata);
    for (const [name, resourceMetadata] of Object.entries(metadata.resources || {})) {
      const currentVersion = resourceMetadata.currentVersion || "v1";
      const versionData = resourceMetadata.versions?.[currentVersion];
      if (versionData) {
        let restoredIdGenerator, restoredIdSize;
        if (versionData.idGenerator !== void 0) {
          if (versionData.idGenerator === "custom_function") {
            restoredIdGenerator = void 0;
            restoredIdSize = versionData.idSize || 22;
          } else if (typeof versionData.idGenerator === "number") {
            restoredIdGenerator = versionData.idGenerator;
            restoredIdSize = versionData.idSize || versionData.idGenerator;
          }
        } else {
          restoredIdSize = versionData.idSize || 22;
        }
        this._resourcesMap[name] = new Resource({
          name,
          client: this.client,
          database: this,
          // ensure reference
          version: currentVersion,
          attributes: versionData.attributes,
          behavior: versionData.behavior || "user-managed",
          parallelism: this.parallelism,
          passphrase: this.passphrase,
          observers: [this],
          cache: this.cache,
          timestamps: versionData.timestamps !== void 0 ? versionData.timestamps : false,
          partitions: resourceMetadata.partitions || versionData.partitions || {},
          paranoid: versionData.paranoid !== void 0 ? versionData.paranoid : true,
          allNestedObjectsOptional: versionData.allNestedObjectsOptional !== void 0 ? versionData.allNestedObjectsOptional : true,
          autoDecrypt: versionData.autoDecrypt !== void 0 ? versionData.autoDecrypt : true,
          asyncEvents: versionData.asyncEvents !== void 0 ? versionData.asyncEvents : true,
          hooks: this.persistHooks ? this._deserializeHooks(versionData.hooks || {}) : versionData.hooks || {},
          versioningEnabled: this.versioningEnabled,
          strictValidation: this.strictValidation,
          map: versionData.map,
          idGenerator: restoredIdGenerator,
          idSize: restoredIdSize
        });
      }
    }
    if (definitionChanges.length > 0) {
      this.emit("db:resource-definitions-changed", {
        changes: definitionChanges,
        metadata: this.savedMetadata
      });
    }
    this.emit("db:connected", /* @__PURE__ */ new Date());
  }
  /**
   * Detect changes in resource definitions compared to saved metadata
   * @param {Object} savedMetadata - The metadata loaded from s3db.json
   * @returns {Array} Array of change objects
   */
  detectDefinitionChanges(savedMetadata) {
    const changes = [];
    for (const [name, currentResource] of Object.entries(this.resources)) {
      const currentHash = this.generateDefinitionHash(currentResource.export());
      const savedResource = savedMetadata.resources?.[name];
      if (!savedResource) {
        changes.push({
          type: "new",
          resourceName: name,
          currentHash,
          savedHash: null
        });
      } else {
        const currentVersion = savedResource.currentVersion || "v1";
        const versionData = savedResource.versions?.[currentVersion];
        const savedHash = versionData?.hash;
        if (savedHash !== currentHash) {
          changes.push({
            type: "changed",
            resourceName: name,
            currentHash,
            savedHash,
            fromVersion: currentVersion,
            toVersion: this.getNextVersion(savedResource.versions)
          });
        }
      }
    }
    for (const [name, savedResource] of Object.entries(savedMetadata.resources || {})) {
      if (!this._resourcesMap[name]) {
        const currentVersion = savedResource.currentVersion || "v1";
        const versionData = savedResource.versions?.[currentVersion];
        changes.push({
          type: "deleted",
          resourceName: name,
          currentHash: null,
          savedHash: versionData?.hash,
          deletedVersion: currentVersion
        });
      }
    }
    return changes;
  }
  /**
   * Generate a consistent hash for a resource definition
   * @param {Object} definition - Resource definition to hash
   * @param {string} behavior - Resource behavior
   * @returns {string} SHA256 hash
   */
  generateDefinitionHash(definition, behavior = void 0) {
    const attributes = definition.attributes;
    const stableAttributes = { ...attributes };
    if (definition.timestamps) {
      delete stableAttributes.createdAt;
      delete stableAttributes.updatedAt;
    }
    const hashObj = {
      attributes: stableAttributes,
      behavior: behavior || definition.behavior || "user-managed",
      partitions: definition.partitions || {}
    };
    const stableString = jsonStableStringify(hashObj);
    return `sha256:${createHash("sha256").update(stableString).digest("hex")}`;
  }
  /**
   * Get the next version number for a resource
   * @param {Object} versions - Existing versions object
   * @returns {string} Next version string (e.g., 'v1', 'v2')
   */
  getNextVersion(versions = {}) {
    const versionNumbers = Object.keys(versions).filter((v) => v.startsWith("v")).map((v) => parseInt(v.substring(1))).filter((n) => !isNaN(n));
    const maxVersion = versionNumbers.length > 0 ? Math.max(...versionNumbers) : 0;
    return `v${maxVersion + 1}`;
  }
  /**
   * Serialize hooks to strings for JSON persistence
   * @param {Object} hooks - Hooks object with event names as keys and function arrays as values
   * @returns {Object} Serialized hooks object
   * @private
   */
  _serializeHooks(hooks) {
    if (!hooks || typeof hooks !== "object") return hooks;
    const serialized = {};
    for (const [event, hookArray] of Object.entries(hooks)) {
      if (Array.isArray(hookArray)) {
        serialized[event] = hookArray.map((hook) => {
          if (typeof hook === "function") {
            const [ok, err, data] = tryFn(() => ({
              __s3db_serialized_function: true,
              code: hook.toString(),
              name: hook.name || "anonymous"
            }));
            if (!ok) {
              if (this.verbose) {
                console.warn(`Failed to serialize hook for event '${event}':`, err.message);
              }
              return null;
            }
            return data;
          }
          return hook;
        });
      } else {
        serialized[event] = hookArray;
      }
    }
    return serialized;
  }
  /**
   * Deserialize hooks from strings back to functions
   * @param {Object} serializedHooks - Serialized hooks object
   * @returns {Object} Deserialized hooks object
   * @private
   */
  _deserializeHooks(serializedHooks) {
    if (!serializedHooks || typeof serializedHooks !== "object") return serializedHooks;
    const deserialized = {};
    for (const [event, hookArray] of Object.entries(serializedHooks)) {
      if (Array.isArray(hookArray)) {
        deserialized[event] = hookArray.map((hook) => {
          if (hook && typeof hook === "object" && hook.__s3db_serialized_function) {
            const [ok, err, fn] = tryFn(() => {
              const func = new Function("return " + hook.code)();
              return typeof func === "function" ? func : null;
            });
            if (!ok || fn === null) {
              if (this.verbose) {
                console.warn(`Failed to deserialize hook '${hook.name}' for event '${event}':`, err?.message || "Invalid function");
              }
              return null;
            }
            return fn;
          }
          return hook;
        }).filter((hook) => hook !== null);
      } else {
        deserialized[event] = hookArray;
      }
    }
    return deserialized;
  }
  async startPlugins() {
    const db = this;
    if (!isEmpty(this.pluginList)) {
      const plugins = this.pluginList.map((p) => isFunction$1(p) ? new p(this) : p);
      const installProms = plugins.map(async (plugin) => {
        await plugin.install(db);
        const pluginName = this._getPluginName(plugin);
        this.pluginRegistry[pluginName] = plugin;
      });
      await Promise.all(installProms);
      const startProms = plugins.map(async (plugin) => {
        await plugin.start();
      });
      await Promise.all(startProms);
    }
  }
  /**
   * Register and setup a plugin
   * @param {Plugin} plugin - Plugin instance to register
   * @param {string} [name] - Optional name for the plugin (defaults to plugin.constructor.name)
   */
  /**
   * Get the normalized plugin name
   * @private
   */
  _getPluginName(plugin, customName = null) {
    return customName || plugin.constructor.name.replace("Plugin", "").toLowerCase();
  }
  async usePlugin(plugin, name = null) {
    const pluginName = this._getPluginName(plugin, name);
    this.plugins[pluginName] = plugin;
    if (this.isConnected()) {
      await plugin.install(this);
      await plugin.start();
    }
    return plugin;
  }
  /**
   * Uninstall a plugin and optionally purge its data
   * @param {string} name - Plugin name
   * @param {Object} options - Uninstall options
   * @param {boolean} options.purgeData - Delete all plugin data from S3 (default: false)
   */
  async uninstallPlugin(name, options = {}) {
    const pluginName = name.toLowerCase().replace("plugin", "");
    const plugin = this.plugins[pluginName] || this.pluginRegistry[pluginName];
    if (!plugin) {
      throw new DatabaseError(`Plugin '${name}' not found`, {
        operation: "uninstallPlugin",
        pluginName: name,
        availablePlugins: Object.keys(this.pluginRegistry),
        suggestion: "Check plugin name or list available plugins using Object.keys(db.pluginRegistry)"
      });
    }
    if (plugin.stop) {
      await plugin.stop();
    }
    if (plugin.uninstall) {
      await plugin.uninstall(options);
    }
    delete this.plugins[pluginName];
    delete this.pluginRegistry[pluginName];
    const index = this.pluginList.indexOf(plugin);
    if (index > -1) {
      this.pluginList.splice(index, 1);
    }
    this.emit("db:plugin:uninstalled", { name: pluginName, plugin });
  }
  async uploadMetadataFile() {
    const metadata = {
      version: this.version,
      s3dbVersion: this.s3dbVersion,
      lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
      resources: {}
    };
    Object.entries(this.resources).forEach(([name, resource]) => {
      const resourceDef = resource.export();
      const definitionHash = this.generateDefinitionHash(resourceDef);
      const existingResource = this.savedMetadata?.resources?.[name];
      const currentVersion = existingResource?.currentVersion || "v1";
      const existingVersionData = existingResource?.versions?.[currentVersion];
      let version, isNewVersion;
      if (!existingVersionData || existingVersionData.hash !== definitionHash) {
        version = this.getNextVersion(existingResource?.versions);
        isNewVersion = true;
      } else {
        version = currentVersion;
        isNewVersion = false;
      }
      metadata.resources[name] = {
        currentVersion: version,
        partitions: resource.config.partitions || {},
        createdBy: existingResource?.createdBy || resource.config.createdBy || "user",
        versions: {
          ...existingResource?.versions,
          // Preserve previous versions
          [version]: {
            hash: definitionHash,
            attributes: resourceDef.attributes,
            behavior: resourceDef.behavior || "user-managed",
            timestamps: resource.config.timestamps,
            partitions: resource.config.partitions,
            paranoid: resource.config.paranoid,
            allNestedObjectsOptional: resource.config.allNestedObjectsOptional,
            autoDecrypt: resource.config.autoDecrypt,
            cache: resource.config.cache,
            asyncEvents: resource.config.asyncEvents,
            hooks: this.persistHooks ? this._serializeHooks(resource.config.hooks) : resource.config.hooks,
            idSize: resource.idSize,
            idGenerator: resource.idGeneratorType,
            createdAt: isNewVersion ? (/* @__PURE__ */ new Date()).toISOString() : existingVersionData?.createdAt
          }
        }
      };
      if (resource.version !== version) {
        resource.version = version;
        resource.emit("versionUpdated", { oldVersion: currentVersion, newVersion: version });
      }
    });
    await this.client.putObject({
      key: "s3db.json",
      body: JSON.stringify(metadata, null, 2),
      contentType: "application/json"
    });
    this.savedMetadata = metadata;
    this.emit("db:metadata-uploaded", metadata);
  }
  blankMetadataStructure() {
    return {
      version: `1`,
      s3dbVersion: this.s3dbVersion,
      lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
      resources: {}
    };
  }
  /**
   * Attempt to recover JSON from corrupted content
   */
  async _attemptJsonRecovery(content, healingLog) {
    if (!content || typeof content !== "string") {
      healingLog.push("Content is empty or not a string");
      return null;
    }
    const fixes = [
      // Remove trailing commas
      () => content.replace(/,(\s*[}\]])/g, "$1"),
      // Add missing quotes to keys
      () => content.replace(/([{,]\s*)([a-zA-Z_$][a-zA-Z0-9_$]*)\s*:/g, '$1"$2":'),
      // Fix incomplete objects by adding closing braces
      () => {
        let openBraces = 0;
        let openBrackets = 0;
        let inString = false;
        let escaped = false;
        for (let i = 0; i < content.length; i++) {
          const char = content[i];
          if (escaped) {
            escaped = false;
            continue;
          }
          if (char === "\\") {
            escaped = true;
            continue;
          }
          if (char === '"') {
            inString = !inString;
            continue;
          }
          if (!inString) {
            if (char === "{") openBraces++;
            else if (char === "}") openBraces--;
            else if (char === "[") openBrackets++;
            else if (char === "]") openBrackets--;
          }
        }
        let fixed = content;
        while (openBrackets > 0) {
          fixed += "]";
          openBrackets--;
        }
        while (openBraces > 0) {
          fixed += "}";
          openBraces--;
        }
        return fixed;
      }
    ];
    for (const [index, fix] of fixes.entries()) {
      const [ok, err, parsed] = tryFn(() => {
        const fixedContent = fix();
        return JSON.parse(fixedContent);
      });
      if (ok) {
        healingLog.push(`JSON recovery successful using fix #${index + 1}`);
        return parsed;
      }
    }
    healingLog.push("All JSON recovery attempts failed");
    return null;
  }
  /**
   * Validate and heal metadata structure
   */
  async _validateAndHealMetadata(metadata, healingLog) {
    if (!metadata || typeof metadata !== "object") {
      healingLog.push("Metadata is not an object - using blank structure");
      return this.blankMetadataStructure();
    }
    let healed = { ...metadata };
    let changed = false;
    if (!healed.version || typeof healed.version !== "string") {
      if (healed.version && typeof healed.version === "number") {
        healed.version = String(healed.version);
        healingLog.push("Converted version from number to string");
        changed = true;
      } else {
        healed.version = "1";
        healingLog.push("Added missing or invalid version field");
        changed = true;
      }
    }
    if (!healed.s3dbVersion || typeof healed.s3dbVersion !== "string") {
      if (healed.s3dbVersion && typeof healed.s3dbVersion !== "string") {
        healed.s3dbVersion = String(healed.s3dbVersion);
        healingLog.push("Converted s3dbVersion to string");
        changed = true;
      } else {
        healed.s3dbVersion = this.s3dbVersion;
        healingLog.push("Added missing s3dbVersion field");
        changed = true;
      }
    }
    if (!healed.resources || typeof healed.resources !== "object" || Array.isArray(healed.resources)) {
      healed.resources = {};
      healingLog.push("Fixed invalid resources field");
      changed = true;
    }
    if (!healed.lastUpdated) {
      healed.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
      healingLog.push("Added missing lastUpdated field");
      changed = true;
    }
    const validResources = {};
    for (const [name, resource] of Object.entries(healed.resources)) {
      const healedResource = this._healResourceStructure(name, resource, healingLog);
      if (healedResource) {
        validResources[name] = healedResource;
        if (healedResource !== resource) {
          changed = true;
        }
      } else {
        healingLog.push(`Removed invalid resource: ${name}`);
        changed = true;
      }
    }
    healed.resources = validResources;
    return changed ? healed : metadata;
  }
  /**
   * Heal individual resource structure
   */
  _healResourceStructure(name, resource, healingLog) {
    if (!resource || typeof resource !== "object") {
      healingLog.push(`Resource ${name}: invalid structure`);
      return null;
    }
    let healed = { ...resource };
    let changed = false;
    if (!healed.currentVersion) {
      healed.currentVersion = "v1";
      healingLog.push(`Resource ${name}: added missing currentVersion`);
      changed = true;
    }
    if (!healed.versions || typeof healed.versions !== "object" || Array.isArray(healed.versions)) {
      healed.versions = {};
      healingLog.push(`Resource ${name}: fixed invalid versions object`);
      changed = true;
    }
    if (!healed.partitions || typeof healed.partitions !== "object" || Array.isArray(healed.partitions)) {
      healed.partitions = {};
      healingLog.push(`Resource ${name}: fixed invalid partitions object`);
      changed = true;
    }
    const currentVersion = healed.currentVersion;
    if (!healed.versions[currentVersion]) {
      const availableVersions = Object.keys(healed.versions);
      if (availableVersions.length > 0) {
        healed.currentVersion = availableVersions[0];
        healingLog.push(`Resource ${name}: changed currentVersion from ${currentVersion} to ${healed.currentVersion}`);
        changed = true;
      } else {
        healingLog.push(`Resource ${name}: no valid versions found - removing resource`);
        return null;
      }
    }
    const versionData = healed.versions[healed.currentVersion];
    if (!versionData || typeof versionData !== "object") {
      healingLog.push(`Resource ${name}: invalid version data - removing resource`);
      return null;
    }
    if (!versionData.attributes || typeof versionData.attributes !== "object") {
      healingLog.push(`Resource ${name}: missing or invalid attributes - removing resource`);
      return null;
    }
    if (versionData.hooks) {
      const healedHooks = this._healHooksStructure(versionData.hooks, name, healingLog);
      if (healedHooks !== versionData.hooks) {
        healed.versions[healed.currentVersion].hooks = healedHooks;
        changed = true;
      }
    }
    return changed ? healed : resource;
  }
  /**
   * Heal hooks structure
   */
  _healHooksStructure(hooks, resourceName, healingLog) {
    if (!hooks || typeof hooks !== "object") {
      healingLog.push(`Resource ${resourceName}: invalid hooks structure - using empty hooks`);
      return {};
    }
    const healed = {};
    let changed = false;
    for (const [event, hookArray] of Object.entries(hooks)) {
      if (Array.isArray(hookArray)) {
        const validHooks = hookArray.filter(
          (hook) => hook !== null && hook !== void 0 && hook !== ""
        );
        healed[event] = validHooks;
        if (validHooks.length !== hookArray.length) {
          healingLog.push(`Resource ${resourceName}: cleaned invalid hooks for event ${event}`);
          changed = true;
        }
      } else {
        healingLog.push(`Resource ${resourceName}: hooks for event ${event} is not an array - removing`);
        changed = true;
      }
    }
    return changed ? healed : hooks;
  }
  /**
   * Create backup of corrupted file
   */
  async _createCorruptedBackup(content = null) {
    const [ok, err] = await tryFn(async () => {
      const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
      const backupKey = `s3db.json.corrupted.${timestamp}.backup`;
      if (!content) {
        const [readOk, readErr, readData] = await tryFn(async () => {
          const request = await this.client.getObject(`s3db.json`);
          return await streamToString(request?.Body);
        });
        content = readOk ? readData : "Unable to read corrupted file content";
      }
      await this.client.putObject({
        key: backupKey,
        body: content,
        contentType: "application/json"
      });
      if (this.verbose) {
        console.warn(`S3DB: Created backup of corrupted s3db.json as ${backupKey}`);
      }
    });
    if (!ok && this.verbose) {
      console.warn(`S3DB: Failed to create backup: ${err.message}`);
    }
  }
  /**
   * Upload healed metadata with logging
   */
  async _uploadHealedMetadata(metadata, healingLog) {
    const [ok, err] = await tryFn(async () => {
      if (this.verbose && healingLog.length > 0) {
        console.warn("S3DB Self-Healing Operations:");
        healingLog.forEach((log) => console.warn(`  - ${log}`));
      }
      metadata.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
      await this.client.putObject({
        key: "s3db.json",
        body: JSON.stringify(metadata, null, 2),
        contentType: "application/json"
      });
      this.emit("db:metadata-healed", { healingLog, metadata });
      if (this.verbose) {
        console.warn("S3DB: Successfully uploaded healed metadata");
      }
    });
    if (!ok) {
      if (this.verbose) {
        console.error(`S3DB: Failed to upload healed metadata: ${err.message}`);
      }
      throw err;
    }
  }
  /**
   * Check if a resource exists by name
   * @param {string} name - Resource name
   * @returns {boolean} True if resource exists, false otherwise
   */
  resourceExists(name) {
    return !!this._resourcesMap[name];
  }
  /**
   * Check if a resource exists with the same definition hash
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.attributes - Resource attributes
   * @param {string} [config.behavior] - Resource behavior
   * @returns {Object} Result with exists and hash information
   */
  resourceExistsWithSameHash({ name, attributes, behavior = "user-managed", partitions = {} }) {
    if (!this._resourcesMap[name]) {
      return { exists: false, sameHash: false, hash: null };
    }
    const existingResource = this._resourcesMap[name];
    const existingHash = this.generateDefinitionHash(existingResource.export());
    const mockResource = new Resource({
      name,
      attributes,
      behavior,
      partitions,
      client: this.client,
      version: existingResource.version,
      passphrase: this.passphrase,
      versioningEnabled: this.versioningEnabled
    });
    const newHash = this.generateDefinitionHash(mockResource.export());
    return {
      exists: true,
      sameHash: existingHash === newHash,
      hash: newHash,
      existingHash
    };
  }
  /**
   * Create or update a resource in the database
   * @param {Object} config - Resource configuration
   * @param {string} config.name - Resource name
   * @param {Object} config.attributes - Resource attributes schema
   * @param {string} [config.behavior='user-managed'] - Resource behavior strategy
   * @param {Object} [config.hooks] - Resource hooks
   * @param {boolean} [config.asyncEvents=true] - Whether events should be emitted asynchronously
   * @param {boolean} [config.timestamps=false] - Enable automatic timestamps
   * @param {Object} [config.partitions={}] - Partition definitions
   * @param {boolean} [config.paranoid=true] - Security flag for dangerous operations
   * @param {boolean} [config.cache=false] - Enable caching
   * @param {boolean} [config.autoDecrypt=true] - Auto-decrypt secret fields
   * @param {Function|number} [config.idGenerator] - Custom ID generator or size
   * @param {number} [config.idSize=22] - Size for auto-generated IDs
   * @param {string} [config.createdBy='user'] - Who created this resource ('user', 'plugin', or plugin name)
   * @returns {Promise<Resource>} The created or updated resource
   */
  /**
   * Normalize partitions config from array or object format
   * @param {Array|Object} partitions - Partitions config
   * @param {Object} attributes - Resource attributes
   * @returns {Object} Normalized partitions object
   * @private
   */
  _normalizePartitions(partitions, attributes) {
    if (!Array.isArray(partitions)) {
      return partitions || {};
    }
    const normalized = {};
    for (const fieldName of partitions) {
      if (typeof fieldName !== "string") {
        throw new Error(`Partition field must be a string, got ${typeof fieldName}`);
      }
      if (!attributes[fieldName]) {
        throw new Error(`Partition field '${fieldName}' not found in attributes`);
      }
      const partitionName = `by${fieldName.charAt(0).toUpperCase()}${fieldName.slice(1)}`;
      const fieldDef = attributes[fieldName];
      let fieldType = "string";
      if (typeof fieldDef === "string") {
        fieldType = fieldDef.split("|")[0].trim();
      } else if (typeof fieldDef === "object" && fieldDef.type) {
        fieldType = fieldDef.type;
      }
      normalized[partitionName] = {
        fields: {
          [fieldName]: fieldType
        }
      };
    }
    return normalized;
  }
  async createResource({ name, attributes, behavior = "user-managed", hooks, middlewares, ...config }) {
    const normalizedPartitions = this._normalizePartitions(config.partitions, attributes);
    if (this._resourcesMap[name]) {
      const existingResource = this._resourcesMap[name];
      Object.assign(existingResource.config, {
        cache: this.cache,
        ...config,
        partitions: normalizedPartitions
      });
      if (behavior) {
        existingResource.behavior = behavior;
      }
      existingResource.versioningEnabled = this.versioningEnabled;
      existingResource.updateAttributes(attributes);
      if (hooks) {
        for (const [event, hooksArr] of Object.entries(hooks)) {
          if (Array.isArray(hooksArr) && existingResource.hooks[event]) {
            for (const fn of hooksArr) {
              if (typeof fn === "function") {
                existingResource.hooks[event].push(fn.bind(existingResource));
              }
            }
          }
        }
      }
      if (middlewares) {
        this._applyMiddlewares(existingResource, middlewares);
      }
      const newHash = this.generateDefinitionHash(existingResource.export(), existingResource.behavior);
      const existingMetadata2 = this.savedMetadata?.resources?.[name];
      const currentVersion = existingMetadata2?.currentVersion || "v1";
      const existingVersionData = existingMetadata2?.versions?.[currentVersion];
      if (!existingVersionData || existingVersionData.hash !== newHash) {
        await this.uploadMetadataFile();
      }
      this.emit("db:resource-updated", name);
      return existingResource;
    }
    const existingMetadata = this.savedMetadata?.resources?.[name];
    const version = existingMetadata?.currentVersion || "v1";
    const resource = new Resource({
      name,
      client: this.client,
      version: config.version !== void 0 ? config.version : version,
      attributes,
      behavior,
      parallelism: this.parallelism,
      passphrase: config.passphrase !== void 0 ? config.passphrase : this.passphrase,
      observers: [this],
      cache: config.cache !== void 0 ? config.cache : this.cache,
      timestamps: config.timestamps !== void 0 ? config.timestamps : false,
      partitions: normalizedPartitions,
      paranoid: config.paranoid !== void 0 ? config.paranoid : true,
      allNestedObjectsOptional: config.allNestedObjectsOptional !== void 0 ? config.allNestedObjectsOptional : true,
      autoDecrypt: config.autoDecrypt !== void 0 ? config.autoDecrypt : true,
      hooks: hooks || {},
      versioningEnabled: this.versioningEnabled,
      strictValidation: config.strictValidation !== void 0 ? config.strictValidation : this.strictValidation,
      map: config.map,
      idGenerator: config.idGenerator,
      idSize: config.idSize,
      asyncEvents: config.asyncEvents,
      asyncPartitions: config.asyncPartitions !== void 0 ? config.asyncPartitions : true,
      events: config.events || {},
      createdBy: config.createdBy || "user"
    });
    resource.database = this;
    this._resourcesMap[name] = resource;
    if (middlewares) {
      this._applyMiddlewares(resource, middlewares);
    }
    await this.uploadMetadataFile();
    this.emit("db:resource-created", name);
    return resource;
  }
  /**
   * Apply middlewares to a resource
   * @param {Resource} resource - Resource instance
   * @param {Array|Object} middlewares - Middlewares config
   * @private
   */
  _applyMiddlewares(resource, middlewares) {
    if (Array.isArray(middlewares)) {
      const methods = resource._middlewareMethods || [
        "get",
        "list",
        "listIds",
        "getAll",
        "count",
        "page",
        "insert",
        "update",
        "delete",
        "deleteMany",
        "exists",
        "getMany",
        "content",
        "hasContent",
        "query",
        "getFromPartition",
        "setContent",
        "deleteContent",
        "replace",
        "patch"
      ];
      for (const method of methods) {
        for (const middleware of middlewares) {
          if (typeof middleware === "function") {
            resource.useMiddleware(method, middleware);
          }
        }
      }
      return;
    }
    if (typeof middlewares === "object" && middlewares !== null) {
      for (const [method, fns] of Object.entries(middlewares)) {
        if (method === "*") {
          const methods = resource._middlewareMethods || [
            "get",
            "list",
            "listIds",
            "getAll",
            "count",
            "page",
            "insert",
            "update",
            "delete",
            "deleteMany",
            "exists",
            "getMany",
            "content",
            "hasContent",
            "query",
            "getFromPartition",
            "setContent",
            "deleteContent",
            "replace",
            "patch"
          ];
          const middlewareArray = Array.isArray(fns) ? fns : [fns];
          for (const targetMethod of methods) {
            for (const middleware of middlewareArray) {
              if (typeof middleware === "function") {
                resource.useMiddleware(targetMethod, middleware);
              }
            }
          }
        } else {
          const middlewareArray = Array.isArray(fns) ? fns : [fns];
          for (const middleware of middlewareArray) {
            if (typeof middleware === "function") {
              resource.useMiddleware(method, middleware);
            }
          }
        }
      }
    }
  }
  /**
   * List all resource names
   * @returns {Array} Array of resource names
   */
  async listResources() {
    return Object.keys(this.resources).map((name) => ({ name }));
  }
  /**
   * Get a specific resource by name
   * @param {string} name - Resource name
   * @returns {Resource} Resource instance
   */
  async getResource(name) {
    if (!this._resourcesMap[name]) {
      throw new ResourceNotFound({
        bucket: this.client.config.bucket,
        resourceName: name,
        id: name
      });
    }
    return this._resourcesMap[name];
  }
  /**
   * Get database configuration
   * @returns {Object} Configuration object
   */
  get config() {
    return {
      version: this.version,
      s3dbVersion: this.s3dbVersion,
      bucket: this.bucket,
      keyPrefix: this.keyPrefix,
      parallelism: this.parallelism,
      verbose: this.verbose
    };
  }
  isConnected() {
    return !!this.savedMetadata;
  }
  async disconnect() {
    await this.emit("disconnected", /* @__PURE__ */ new Date());
    await tryFn(async () => {
      if (this.pluginList && this.pluginList.length > 0) {
        for (const plugin of this.pluginList) {
          if (plugin && typeof plugin.removeAllListeners === "function") {
            plugin.removeAllListeners();
          }
        }
        const stopProms = this.pluginList.map(async (plugin) => {
          await tryFn(async () => {
            if (plugin && typeof plugin.stop === "function") {
              await plugin.stop();
            }
          });
        });
        await Promise.all(stopProms);
      }
      if (this.resources && Object.keys(this.resources).length > 0) {
        for (const [name, resource] of Object.entries(this.resources)) {
          await tryFn(() => {
            if (resource && typeof resource.removeAllListeners === "function") {
              resource.removeAllListeners();
            }
            if (resource._pluginWrappers) {
              resource._pluginWrappers.clear();
            }
            if (resource._pluginMiddlewares) {
              resource._pluginMiddlewares = {};
            }
            if (resource.observers && Array.isArray(resource.observers)) {
              resource.observers = [];
            }
          });
        }
        Object.keys(this.resources).forEach((k) => delete this._resourcesMap[k]);
      }
      if (this.client && typeof this.client.removeAllListeners === "function") {
        this.client.removeAllListeners();
      }
      await this.emit("db:disconnected", /* @__PURE__ */ new Date());
      this.removeAllListeners();
      if (this._exitListener && typeof process !== "undefined") {
        process.off("exit", this._exitListener);
        this._exitListener = null;
        this._exitListenerRegistered = false;
      }
      this.savedMetadata = null;
      this.plugins = {};
      this.pluginList = [];
    });
  }
  /**
   * Initialize hooks system for database operations
   * @private
   */
  _initHooks() {
    this._hooks = /* @__PURE__ */ new Map();
    this._hookEvents = [
      "beforeConnect",
      "afterConnect",
      "beforeCreateResource",
      "afterCreateResource",
      "beforeUploadMetadata",
      "afterUploadMetadata",
      "beforeDisconnect",
      "afterDisconnect",
      "resourceCreated",
      "resourceUpdated"
    ];
    for (const event of this._hookEvents) {
      this._hooks.set(event, []);
    }
    this._wrapHookableMethods();
  }
  /**
   * Wrap methods that can have hooks
   * @private
   */
  _wrapHookableMethods() {
    if (this._hooksInstalled) return;
    this._originalConnect = this.connect.bind(this);
    this._originalCreateResource = this.createResource.bind(this);
    this._originalUploadMetadataFile = this.uploadMetadataFile.bind(this);
    this._originalDisconnect = this.disconnect.bind(this);
    this.connect = async (...args) => {
      await this._executeHooks("beforeConnect", { args });
      const result = await this._originalConnect(...args);
      await this._executeHooks("afterConnect", { result, args });
      return result;
    };
    this.createResource = async (config) => {
      await this._executeHooks("beforeCreateResource", { config });
      const resource = await this._originalCreateResource(config);
      await this._executeHooks("afterCreateResource", { resource, config });
      return resource;
    };
    this.uploadMetadataFile = async (...args) => {
      await this._executeHooks("beforeUploadMetadata", { args });
      const result = await this._originalUploadMetadataFile(...args);
      await this._executeHooks("afterUploadMetadata", { result, args });
      return result;
    };
    this.disconnect = async (...args) => {
      await this._executeHooks("beforeDisconnect", { args });
      const result = await this._originalDisconnect(...args);
      await this._executeHooks("afterDisconnect", { result, args });
      return result;
    };
    this._hooksInstalled = true;
  }
  /**
   * Add a hook for a specific database event
   * @param {string} event - Hook event name
   * @param {Function} fn - Hook function
   * @example
   * database.addHook('afterCreateResource', async ({ resource }) => {
   *   console.log('Resource created:', resource.name);
   * });
   */
  addHook(event, fn) {
    if (!this._hooks) this._initHooks();
    if (!this._hooks.has(event)) {
      throw new DatabaseError(`Unknown hook event: ${event}`, {
        operation: "addHook",
        invalidEvent: event,
        availableEvents: this._hookEvents,
        suggestion: `Use one of the available hook events: ${this._hookEvents.join(", ")}`
      });
    }
    if (typeof fn !== "function") {
      throw new DatabaseError("Hook function must be a function", {
        operation: "addHook",
        event,
        receivedType: typeof fn,
        suggestion: "Provide a function that will be called when the hook event occurs"
      });
    }
    this._hooks.get(event).push(fn);
  }
  /**
   * Execute hooks for a specific event
   * @param {string} event - Hook event name
   * @param {Object} context - Context data to pass to hooks
   * @private
   */
  async _executeHooks(event, context = {}) {
    if (!this._hooks || !this._hooks.has(event)) return;
    const hooks = this._hooks.get(event);
    for (const hook of hooks) {
      const [ok, error] = await tryFn(() => hook({ database: this, ...context }));
      if (!ok) {
        this.emit("hookError", { event, error, context });
        if (this.strictHooks) {
          throw new DatabaseError(`Hook execution failed for event '${event}': ${error.message}`, {
            event,
            originalError: error,
            context
          });
        }
      }
    }
  }
  /**
   * Remove a hook for a specific event
   * @param {string} event - Hook event name
   * @param {Function} fn - Hook function to remove
   */
  removeHook(event, fn) {
    if (!this._hooks || !this._hooks.has(event)) return;
    const hooks = this._hooks.get(event);
    const index = hooks.indexOf(fn);
    if (index > -1) {
      hooks.splice(index, 1);
    }
  }
  /**
   * Get all hooks for a specific event
   * @param {string} event - Hook event name
   * @returns {Function[]} Array of hook functions
   */
  getHooks(event) {
    if (!this._hooks || !this._hooks.has(event)) return [];
    return [...this._hooks.get(event)];
  }
  /**
   * Clear all hooks for a specific event
   * @param {string} event - Hook event name
   */
  clearHooks(event) {
    if (!this._hooks || !this._hooks.has(event)) return;
    this._hooks.get(event).length = 0;
  }
}
class S3db extends Database {
}

function normalizeResourceName$1(name) {
  return typeof name === "string" ? name.trim().toLowerCase() : name;
}
class S3dbReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.instanceId = Math.random().toString(36).slice(2, 10);
    this.client = client;
    this.connectionString = config.connectionString;
    let normalizedResources = resources;
    if (!resources) normalizedResources = {};
    else if (Array.isArray(resources)) {
      normalizedResources = {};
      for (const res of resources) {
        if (typeof res === "string") normalizedResources[normalizeResourceName$1(res)] = res;
      }
    } else if (typeof resources === "string") {
      normalizedResources[normalizeResourceName$1(resources)] = resources;
    }
    this.resourcesMap = this._normalizeResources(normalizedResources);
  }
  _normalizeResources(resources) {
    if (!resources) return {};
    if (Array.isArray(resources)) {
      const map = {};
      for (const res of resources) {
        if (typeof res === "string") map[normalizeResourceName$1(res)] = res;
        else if (typeof res === "object" && res.resource) {
          map[normalizeResourceName$1(res.resource)] = res;
        }
      }
      return map;
    }
    if (typeof resources === "object") {
      const map = {};
      for (const [src, dest] of Object.entries(resources)) {
        const normSrc = normalizeResourceName$1(src);
        if (typeof dest === "string") map[normSrc] = dest;
        else if (Array.isArray(dest)) {
          map[normSrc] = dest.map((item) => {
            if (typeof item === "string") return item;
            if (typeof item === "object" && item.resource) {
              return item;
            }
            return item;
          });
        } else if (typeof dest === "function") map[normSrc] = dest;
        else if (typeof dest === "object" && dest.resource) {
          map[normSrc] = dest;
        }
      }
      return map;
    }
    if (typeof resources === "function") {
      return resources;
    }
    return {};
  }
  validateConfig() {
    const errors = [];
    if (!this.client && !this.connectionString) {
      errors.push("You must provide a client or a connectionString");
    }
    if (!this.resourcesMap || typeof this.resourcesMap === "object" && Object.keys(this.resourcesMap).length === 0) {
      errors.push("You must provide a resources map or array");
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    const [ok, err] = await tryFn(async () => {
      if (this.client) {
        this.targetDatabase = this.client;
      } else if (this.connectionString) {
        const targetConfig = {
          connectionString: this.connectionString,
          region: this.region,
          keyPrefix: this.keyPrefix,
          verbose: this.config.verbose || false
        };
        this.targetDatabase = new S3db(targetConfig);
        await this.targetDatabase.connect();
      } else {
        throw new ReplicationError("S3dbReplicator requires client or connectionString", {
          operation: "initialize",
          replicatorClass: "S3dbReplicator",
          suggestion: 'Provide either a client instance or connectionString in config: { client: db } or { connectionString: "s3://..." }'
        });
      }
      this.emit("connected", {
        replicator: this.name,
        target: this.connectionString || "client-provided"
      });
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[S3dbReplicator] Initialization failed: ${err.message}`);
      }
      throw err;
    }
  }
  // Support both object and parameter signatures for flexibility
  async replicate(resourceOrObj, operation, data, recordId, beforeData) {
    let resource, op, payload, id;
    if (typeof resourceOrObj === "object" && resourceOrObj.resource) {
      resource = resourceOrObj.resource;
      op = resourceOrObj.operation;
      payload = resourceOrObj.data;
      id = resourceOrObj.id;
    } else {
      resource = resourceOrObj;
      op = operation;
      payload = data;
      id = recordId;
    }
    const normResource = normalizeResourceName$1(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) {
      throw new ReplicationError("Resource not configured for replication", {
        operation: "replicate",
        replicatorClass: "S3dbReplicator",
        resourceName: resource,
        configuredResources: Object.keys(this.resourcesMap),
        suggestion: 'Add resource to replicator resources map: { resources: { [resourceName]: "destination" } }'
      });
    }
    if (Array.isArray(entry)) {
      const results = [];
      for (const destConfig of entry) {
        const [ok, error, result] = await tryFn(async () => {
          return await this._replicateToSingleDestination(destConfig, normResource, op, payload, id);
        });
        if (!ok) {
          if (this.config && this.config.verbose) {
            console.warn(`[S3dbReplicator] Failed to replicate to destination ${JSON.stringify(destConfig)}: ${error.message}`);
          }
          throw error;
        }
        results.push(result);
      }
      return results;
    } else {
      const [ok, error, result] = await tryFn(async () => {
        return await this._replicateToSingleDestination(entry, normResource, op, payload, id);
      });
      if (!ok) {
        if (this.config && this.config.verbose) {
          console.warn(`[S3dbReplicator] Failed to replicate to destination ${JSON.stringify(entry)}: ${error.message}`);
        }
        throw error;
      }
      return result;
    }
  }
  async _replicateToSingleDestination(destConfig, sourceResource, operation, data, recordId) {
    let destResourceName;
    if (typeof destConfig === "string") {
      destResourceName = destConfig;
    } else if (typeof destConfig === "object" && destConfig.resource) {
      destResourceName = destConfig.resource;
    } else {
      destResourceName = sourceResource;
    }
    if (typeof destConfig === "object" && destConfig.actions && Array.isArray(destConfig.actions)) {
      if (!destConfig.actions.includes(operation)) {
        return { skipped: true, reason: "action_not_supported", action: operation, destination: destResourceName };
      }
    }
    const destResourceObj = this._getDestResourceObj(destResourceName);
    let transformedData;
    if (typeof destConfig === "object" && destConfig.transform && typeof destConfig.transform === "function") {
      transformedData = destConfig.transform(data);
      if (transformedData && data && data.id && !transformedData.id) {
        transformedData.id = data.id;
      }
    } else {
      transformedData = data;
    }
    if (!transformedData && data) transformedData = data;
    let result;
    if (operation === "insert") {
      result = await destResourceObj.insert(transformedData);
    } else if (operation === "update") {
      result = await destResourceObj.update(recordId, transformedData);
    } else if (operation === "delete") {
      result = await destResourceObj.delete(recordId);
    } else {
      throw new ReplicationError(`Invalid replication operation: ${operation}`, {
        operation: "replicate",
        replicatorClass: "S3dbReplicator",
        invalidOperation: operation,
        supportedOperations: ["insert", "update", "delete"],
        resourceName: sourceResource,
        suggestion: "Use one of the supported operations: insert, update, delete"
      });
    }
    return result;
  }
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const normResource = normalizeResourceName$1(resource);
    const entry = this.resourcesMap[normResource];
    let result;
    if (!entry) return cleanData;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "object" && item.transform && typeof item.transform === "function") {
          result = item.transform(cleanData);
          break;
        }
      }
      if (!result) result = cleanData;
    } else if (typeof entry === "object") {
      if (typeof entry.transform === "function") {
        result = entry.transform(cleanData);
      }
    } else if (typeof entry === "function") {
      result = entry(cleanData);
    } else {
      result = cleanData;
    }
    if (result && cleanData && cleanData.id && !result.id) result.id = cleanData.id;
    if (!result && cleanData) result = cleanData;
    return result;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  _resolveDestResource(resource, data) {
    const normResource = normalizeResourceName$1(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) return resource;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "string") return item;
        if (typeof item === "object" && item.resource) return item.resource;
      }
      return resource;
    }
    if (typeof entry === "string") return entry;
    if (typeof entry === "function") return resource;
    if (typeof entry === "object" && entry.resource) return entry.resource;
    return resource;
  }
  _getDestResourceObj(resource) {
    const db = this.targetDatabase || this.client;
    const available = Object.keys(db.resources || {});
    const norm = normalizeResourceName$1(resource);
    const found = available.find((r) => normalizeResourceName$1(r) === norm);
    if (!found) {
      throw new ReplicationError("Destination resource not found in target database", {
        operation: "_getDestResourceObj",
        replicatorClass: "S3dbReplicator",
        destinationResource: resource,
        availableResources: available,
        suggestion: "Create the resource in target database or check resource name spelling"
      });
    }
    return db.resources[found];
  }
  async replicateBatch(resourceName, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const results = [];
    const errors = [];
    for (const record of records) {
      const [ok, err, result] = await tryFn(() => this.replicate({
        resource: resourceName,
        operation: record.operation,
        id: record.id,
        data: record.data,
        beforeData: record.beforeData
      }));
      if (ok) {
        results.push(result);
      } else {
        if (this.config.verbose) {
          console.warn(`[S3dbReplicator] Batch replication failed for record ${record.id}: ${err.message}`);
        }
        errors.push({ id: record.id, error: err.message });
      }
    }
    if (errors.length > 0) {
      console.warn(`[S3dbReplicator] Batch replication completed with ${errors.length} error(s) for ${resourceName}:`, errors);
    }
    this.emit("batch_replicated", {
      replicator: this.name,
      resourceName,
      total: records.length,
      successful: results.length,
      errors: errors.length
    });
    return {
      success: errors.length === 0,
      results,
      errors,
      total: records.length
    };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.targetDatabase) {
        throw new ReplicationError("No target database configured for connection test", {
          operation: "testConnection",
          replicatorClass: "S3dbReplicator",
          suggestion: "Initialize replicator with client or connectionString before testing connection"
        });
      }
      if (typeof this.targetDatabase.connect === "function") {
        await this.targetDatabase.connect();
      }
      return true;
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[S3dbReplicator] Connection test failed: ${err.message}`);
      }
      this.emit("connection_error", { replicator: this.name, error: err.message });
      return false;
    }
    return true;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.targetDatabase,
      targetDatabase: this.connectionString || "client-provided",
      resources: Object.keys(this.resourcesMap || {}),
      totalreplicators: this.listenerCount("replicated"),
      totalErrors: this.listenerCount("replicator_error")
    };
  }
  async cleanup() {
    if (this.targetDatabase) {
      this.targetDatabase.removeAllListeners();
    }
    await super.cleanup();
  }
  shouldReplicateResource(resource, action) {
    const normResource = normalizeResourceName$1(resource);
    const entry = this.resourcesMap[normResource];
    if (!entry) return false;
    if (!action) return true;
    if (Array.isArray(entry)) {
      for (const item of entry) {
        if (typeof item === "object" && item.resource) {
          if (item.actions && Array.isArray(item.actions)) {
            if (item.actions.includes(action)) return true;
          } else {
            return true;
          }
        } else if (typeof item === "string") {
          return true;
        }
      }
      return false;
    }
    if (typeof entry === "object" && entry.resource) {
      if (entry.actions && Array.isArray(entry.actions)) {
        return entry.actions.includes(action);
      }
      return true;
    }
    if (typeof entry === "string" || typeof entry === "function") {
      return true;
    }
    return false;
  }
}

class SqsReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.client = client;
    this.queueUrl = config.queueUrl;
    this.queues = config.queues || {};
    this.defaultQueue = config.defaultQueue || null;
    this.region = config.region || "us-east-1";
    this.sqsClient = client || null;
    this.messageGroupId = config.messageGroupId;
    this.deduplicationId = config.deduplicationId;
    this.resourceQueueMap = config.resourceQueueMap || null;
    if (Array.isArray(resources)) {
      this.resources = {};
      for (const resource of resources) {
        if (typeof resource === "string") {
          this.resources[resource] = true;
        } else if (typeof resource === "object" && resource.name) {
          this.resources[resource.name] = resource;
        }
      }
    } else if (typeof resources === "object") {
      this.resources = resources;
      for (const [resourceName, resourceConfig] of Object.entries(resources)) {
        if (resourceConfig && resourceConfig.queueUrl) {
          this.queues[resourceName] = resourceConfig.queueUrl;
        }
      }
    } else {
      this.resources = {};
    }
  }
  validateConfig() {
    const errors = [];
    if (!this.queueUrl && Object.keys(this.queues).length === 0 && !this.defaultQueue && !this.resourceQueueMap) {
      errors.push("Either queueUrl, queues object, defaultQueue, or resourceQueueMap must be provided");
    }
    return {
      isValid: errors.length === 0,
      errors
    };
  }
  getQueueUrlsForResource(resource) {
    if (this.resourceQueueMap && this.resourceQueueMap[resource]) {
      return this.resourceQueueMap[resource];
    }
    if (this.queues[resource]) {
      return [this.queues[resource]];
    }
    if (this.queueUrl) {
      return [this.queueUrl];
    }
    if (this.defaultQueue) {
      return [this.defaultQueue];
    }
    throw new Error(`No queue URL found for resource '${resource}'`);
  }
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const entry = this.resources[resource];
    let result = cleanData;
    if (!entry) return cleanData;
    if (typeof entry.transform === "function") {
      result = entry.transform(cleanData);
    }
    return result || cleanData;
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Create standardized message structure
   */
  createMessage(resource, operation, data, id, beforeData = null) {
    const baseMessage = {
      resource,
      // padronizado para 'resource'
      action: operation,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      source: "s3db-replicator"
    };
    switch (operation) {
      case "insert":
        return {
          ...baseMessage,
          data
        };
      case "update":
        return {
          ...baseMessage,
          before: beforeData,
          data
        };
      case "delete":
        return {
          ...baseMessage,
          data
        };
      default:
        return {
          ...baseMessage,
          data
        };
    }
  }
  async initialize(database, client) {
    await super.initialize(database);
    await requirePluginDependency("sqs-replicator");
    if (!this.sqsClient) {
      const [ok, err, sdk] = await tryFn(() => import('@aws-sdk/client-sqs'));
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[SqsReplicator] Failed to import SQS SDK: ${err.message}`);
        }
        this.emit("initialization_error", {
          replicator: this.name,
          error: err.message
        });
        throw err;
      }
      const { SQSClient } = sdk;
      this.sqsClient = client || new SQSClient({
        region: this.region,
        credentials: this.config.credentials
      });
      this.emit("db:plugin:initialized", {
        replicator: this.name,
        queueUrl: this.queueUrl,
        queues: this.queues,
        defaultQueue: this.defaultQueue
      });
    }
  }
  async replicate(resource, operation, data, id, beforeData = null) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const { SendMessageCommand } = await import('@aws-sdk/client-sqs');
      const queueUrls = this.getQueueUrlsForResource(resource);
      const transformedData = this._applyTransformer(resource, data);
      const message = this.createMessage(resource, operation, transformedData, id, beforeData);
      const results = [];
      for (const queueUrl of queueUrls) {
        const command = new SendMessageCommand({
          QueueUrl: queueUrl,
          MessageBody: JSON.stringify(message),
          MessageGroupId: this.messageGroupId,
          MessageDeduplicationId: this.deduplicationId ? `${resource}:${operation}:${id}` : void 0
        });
        const result2 = await this.sqsClient.send(command);
        results.push({ queueUrl, messageId: result2.MessageId });
        this.emit("plg:replicator:replicated", {
          replicator: this.name,
          resource,
          operation,
          id,
          queueUrl,
          messageId: result2.MessageId,
          success: true
        });
      }
      return { success: true, results };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Replication failed for ${resource}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resource,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resource, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const { SendMessageBatchCommand } = await import('@aws-sdk/client-sqs');
      const queueUrls = this.getQueueUrlsForResource(resource);
      const batchSize = 10;
      const batches = [];
      for (let i = 0; i < records.length; i += batchSize) {
        batches.push(records.slice(i, i + batchSize));
      }
      const results = [];
      const errors = [];
      for (const batch of batches) {
        const [okBatch, errBatch] = await tryFn(async () => {
          const entries = batch.map((record, index) => ({
            Id: `${record.id}-${index}`,
            MessageBody: JSON.stringify(this.createMessage(
              resource,
              record.operation,
              record.data,
              record.id,
              record.beforeData
            )),
            MessageGroupId: this.messageGroupId,
            MessageDeduplicationId: this.deduplicationId ? `${resource}:${record.operation}:${record.id}` : void 0
          }));
          const command = new SendMessageBatchCommand({
            QueueUrl: queueUrls[0],
            // Assuming all queueUrls in a batch are the same for batching
            Entries: entries
          });
          const result2 = await this.sqsClient.send(command);
          results.push(result2);
        });
        if (!okBatch) {
          errors.push({ batch: batch.length, error: errBatch.message });
          if (errBatch.message && (errBatch.message.includes("Batch error") || errBatch.message.includes("Connection") || errBatch.message.includes("Network"))) {
            throw errBatch;
          }
        }
      }
      if (errors.length > 0) {
        console.warn(`[SqsReplicator] Batch replication completed with ${errors.length} error(s) for ${resource}:`, errors);
      }
      this.emit("batch_replicated", {
        replicator: this.name,
        resource,
        queueUrl: queueUrls[0],
        // Assuming all queueUrls in a batch are the same for batching
        total: records.length,
        successful: results.length,
        errors: errors.length
      });
      return {
        success: errors.length === 0,
        results,
        errors,
        total: records.length,
        queueUrl: queueUrls[0]
        // Assuming all queueUrls in a batch are the same for batching
      };
    });
    if (ok) return result;
    const errorMessage = err?.message || err || "Unknown error";
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Batch replication failed for ${resource}: ${errorMessage}`);
    }
    this.emit("batch_replicator_error", {
      replicator: this.name,
      resource,
      error: errorMessage
    });
    return { success: false, error: errorMessage };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      if (!this.sqsClient) {
        await this.initialize(this.database);
      }
      const { GetQueueAttributesCommand } = await import('@aws-sdk/client-sqs');
      const command = new GetQueueAttributesCommand({
        QueueUrl: this.queueUrl,
        AttributeNames: ["QueueArn"]
      });
      await this.sqsClient.send(command);
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[SqsReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", {
      replicator: this.name,
      error: err.message
    });
    return false;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.sqsClient,
      queueUrl: this.queueUrl,
      region: this.region,
      resources: Object.keys(this.resources || {}),
      totalreplicators: this.listenerCount("replicated"),
      totalErrors: this.listenerCount("replicator_error")
    };
  }
  async cleanup() {
    if (this.sqsClient) {
      this.sqsClient.destroy();
    }
    await super.cleanup();
  }
  shouldReplicateResource(resource) {
    const result = this.resourceQueueMap && Object.keys(this.resourceQueueMap).includes(resource) || this.queues && Object.keys(this.queues).includes(resource) || !!(this.defaultQueue || this.queueUrl) || this.resources && Object.keys(this.resources).includes(resource) || false;
    return result;
  }
}

class TursoReplicator extends BaseReplicator {
  constructor(config = {}, resources = {}) {
    super(config);
    this.url = config.url;
    this.authToken = config.authToken;
    this.client = null;
    this.schemaSync = {
      enabled: config.schemaSync?.enabled || false,
      strategy: config.schemaSync?.strategy || "alter",
      onMismatch: config.schemaSync?.onMismatch || "error",
      autoCreateTable: config.schemaSync?.autoCreateTable !== false,
      autoCreateColumns: config.schemaSync?.autoCreateColumns !== false
    };
    this.resources = this.parseResourcesConfig(resources);
  }
  parseResourcesConfig(resources) {
    const parsed = {};
    for (const [resourceName, config] of Object.entries(resources)) {
      if (typeof config === "string") {
        parsed[resourceName] = [{
          table: config,
          actions: ["insert"]
        }];
      } else if (Array.isArray(config)) {
        parsed[resourceName] = config.map((item) => {
          if (typeof item === "string") {
            return { table: item, actions: ["insert"] };
          }
          return {
            table: item.table,
            actions: item.actions || ["insert"]
          };
        });
      } else if (typeof config === "object") {
        parsed[resourceName] = [{
          table: config.table,
          actions: config.actions || ["insert"]
        }];
      }
    }
    return parsed;
  }
  validateConfig() {
    const errors = [];
    if (!this.url) errors.push("URL is required");
    if (!this.authToken) errors.push("Auth token is required");
    if (Object.keys(this.resources).length === 0) {
      errors.push("At least one resource must be configured");
    }
    for (const [resourceName, tables] of Object.entries(this.resources)) {
      for (const tableConfig of tables) {
        if (!tableConfig.table) {
          errors.push(`Table name is required for resource '${resourceName}'`);
        }
        if (!Array.isArray(tableConfig.actions) || tableConfig.actions.length === 0) {
          errors.push(`Actions array is required for resource '${resourceName}'`);
        }
      }
    }
    return { isValid: errors.length === 0, errors };
  }
  async initialize(database) {
    await super.initialize(database);
    await requirePluginDependency("turso-replicator");
    const [ok, err, sdk] = await tryFn(() => import('@libsql/client'));
    if (!ok) {
      throw new ReplicationError("Failed to import Turso SDK", {
        operation: "initialize",
        replicatorClass: "TursoReplicator",
        original: err,
        suggestion: "Install @libsql/client: pnpm add @libsql/client"
      });
    }
    const { createClient } = sdk;
    this.client = createClient({
      url: this.url,
      authToken: this.authToken
    });
    const [okTest, errTest] = await tryFn(async () => {
      await this.client.execute("SELECT 1");
    });
    if (!okTest) {
      throw new ReplicationError("Failed to connect to Turso database", {
        operation: "initialize",
        replicatorClass: "TursoReplicator",
        url: this.url,
        original: errTest,
        suggestion: "Check Turso URL and auth token"
      });
    }
    if (this.schemaSync.enabled) {
      await this.syncSchemas(database);
    }
    this.emit("connected", {
      replicator: "TursoReplicator",
      url: this.url
    });
  }
  /**
   * Sync table schemas based on S3DB resource definitions
   */
  async syncSchemas(database) {
    for (const [resourceName, tableConfigs] of Object.entries(this.resources)) {
      const [okRes, errRes, resource] = await tryFn(async () => {
        return await database.getResource(resourceName);
      });
      if (!okRes) {
        if (this.config.verbose) {
          console.warn(`[TursoReplicator] Could not get resource ${resourceName} for schema sync: ${errRes.message}`);
        }
        continue;
      }
      const allAttributes = resource.config.versions[resource.config.currentVersion]?.attributes || {};
      const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
      const attributes = Object.fromEntries(
        Object.entries(allAttributes).filter(([name]) => !pluginAttrNames.includes(name))
      );
      for (const tableConfig of tableConfigs) {
        const tableName = tableConfig.table;
        const [okSync, errSync] = await tryFn(async () => {
          await this.syncTableSchema(tableName, attributes);
        });
        if (!okSync) {
          const message = `Schema sync failed for table ${tableName}: ${errSync.message}`;
          if (this.schemaSync.onMismatch === "error") {
            throw new Error(message);
          } else if (this.schemaSync.onMismatch === "warn") {
            console.warn(`[TursoReplicator] ${message}`);
          }
        }
      }
    }
    this.emit("schema_sync_completed", {
      replicator: this.name,
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Sync a single table schema
   */
  async syncTableSchema(tableName, attributes) {
    const [okCheck, errCheck, result] = await tryFn(async () => {
      return await this.client.execute({
        sql: "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
        args: [tableName]
      });
    });
    const tableExists = okCheck && result.rows.length > 0;
    if (!tableExists) {
      if (!this.schemaSync.autoCreateTable) {
        throw new Error(`Table ${tableName} does not exist and autoCreateTable is disabled`);
      }
      if (this.schemaSync.strategy === "validate-only") {
        throw new Error(`Table ${tableName} does not exist (validate-only mode)`);
      }
      const createSQL = generateSQLiteCreateTable(tableName, attributes);
      if (this.config.verbose) {
        console.log(`[TursoReplicator] Creating table ${tableName}:
${createSQL}`);
      }
      await this.client.execute(createSQL);
      this.emit("table_created", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "drop-create") {
      if (this.config.verbose) {
        console.warn(`[TursoReplicator] Dropping and recreating table ${tableName}`);
      }
      await this.client.execute(`DROP TABLE IF EXISTS ${tableName}`);
      const createSQL = generateSQLiteCreateTable(tableName, attributes);
      await this.client.execute(createSQL);
      this.emit("table_recreated", {
        replicator: this.name,
        tableName,
        attributes: Object.keys(attributes)
      });
      return;
    }
    if (this.schemaSync.strategy === "alter" && this.schemaSync.autoCreateColumns) {
      const [okPragma, errPragma, pragmaResult] = await tryFn(async () => {
        return await this.client.execute(`PRAGMA table_info(${tableName})`);
      });
      if (okPragma) {
        const existingSchema = {};
        for (const row of pragmaResult.rows) {
          existingSchema[row.name] = { type: row.type };
        }
        const alterStatements = generateSQLiteAlterTable(tableName, attributes, existingSchema);
        if (alterStatements.length > 0) {
          if (this.config.verbose) {
            console.log(`[TursoReplicator] Altering table ${tableName}:`, alterStatements);
          }
          for (const stmt of alterStatements) {
            await this.client.execute(stmt);
          }
          this.emit("table_altered", {
            replicator: this.name,
            tableName,
            addedColumns: alterStatements.length
          });
        }
      }
    }
  }
  shouldReplicateResource(resourceName) {
    return this.resources.hasOwnProperty(resourceName);
  }
  shouldReplicateAction(resourceName, operation) {
    if (!this.resources[resourceName]) return false;
    return this.resources[resourceName].some(
      (tableConfig) => tableConfig.actions.includes(operation)
    );
  }
  getTablesForResource(resourceName, operation) {
    if (!this.resources[resourceName]) return [];
    return this.resources[resourceName].filter((tableConfig) => tableConfig.actions.includes(operation)).map((tableConfig) => tableConfig.table);
  }
  async replicate(resourceName, operation, data, id, beforeData = null) {
    if (!this.enabled || !this.shouldReplicateResource(resourceName)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    if (!this.shouldReplicateAction(resourceName, operation)) {
      return { skipped: true, reason: "action_not_included" };
    }
    const tables = this.getTablesForResource(resourceName, operation);
    if (tables.length === 0) {
      return { skipped: true, reason: "no_tables_for_action" };
    }
    const results = [];
    const errors = [];
    for (const table of tables) {
      const [okTable, errTable] = await tryFn(async () => {
        if (operation === "insert") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData);
          const values = keys.map((k) => cleanData[k]);
          const placeholders = keys.map((_, i) => `?`).join(", ");
          const sql = `INSERT OR IGNORE INTO ${table} (${keys.join(", ")}) VALUES (${placeholders})`;
          await this.client.execute({ sql, args: values });
        } else if (operation === "update") {
          const cleanData = this._cleanInternalFields(data);
          const keys = Object.keys(cleanData).filter((k) => k !== "id");
          const setClause = keys.map((k) => `${k}=?`).join(", ");
          const values = keys.map((k) => cleanData[k]);
          values.push(id);
          const sql = `UPDATE ${table} SET ${setClause} WHERE id=?`;
          await this.client.execute({ sql, args: values });
        } else if (operation === "delete") {
          const sql = `DELETE FROM ${table} WHERE id=?`;
          await this.client.execute({ sql, args: [id] });
        }
        results.push({ table, success: true });
      });
      if (!okTable) {
        errors.push({ table, error: errTable.message });
      }
    }
    const success = errors.length === 0;
    this.emit("plg:replicator:replicated", {
      replicator: this.name,
      resourceName,
      operation,
      id,
      tables,
      results,
      errors,
      success
    });
    return { success, results, errors, tables };
  }
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  async cleanup() {
    if (this.client) {
      this.client.close();
      this.client = null;
    }
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      connected: !!this.client,
      url: this.url,
      resources: Object.keys(this.resources),
      schemaSync: this.schemaSync
    };
  }
}

class WebhookReplicator extends BaseReplicator {
  constructor(config = {}, resources = [], client = null) {
    super(config);
    this.url = config.url;
    if (!this.url) {
      throw new Error('WebhookReplicator requires a "url" configuration');
    }
    this.method = (config.method || "POST").toUpperCase();
    this.headers = config.headers || {};
    this.timeout = config.timeout || 5e3;
    this.retries = config.retries ?? 3;
    this.retryDelay = config.retryDelay || 1e3;
    this.retryStrategy = config.retryStrategy || "exponential";
    this.retryOnStatus = config.retryOnStatus || [429, 500, 502, 503, 504];
    this.batch = config.batch || false;
    this.batchSize = config.batchSize || 100;
    this.auth = config.auth || null;
    if (Array.isArray(resources)) {
      this.resources = {};
      for (const resource of resources) {
        if (typeof resource === "string") {
          this.resources[resource] = true;
        } else if (typeof resource === "object" && resource.name) {
          this.resources[resource.name] = resource;
        }
      }
    } else if (typeof resources === "object") {
      this.resources = resources;
    } else {
      this.resources = {};
    }
    this.stats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      retriedRequests: 0,
      totalRetries: 0
    };
  }
  validateConfig() {
    const errors = [];
    if (!this.url) {
      errors.push("URL is required");
    }
    try {
      new URL(this.url);
    } catch (err) {
      errors.push(`Invalid URL format: ${this.url}`);
    }
    if (this.auth) {
      if (!this.auth.type) {
        errors.push("auth.type is required when auth is configured");
      } else if (!["bearer", "basic", "apikey"].includes(this.auth.type)) {
        errors.push("auth.type must be one of: bearer, basic, apikey");
      }
      if (this.auth.type === "bearer" && !this.auth.token) {
        errors.push("auth.token is required for bearer authentication");
      }
      if (this.auth.type === "basic" && (!this.auth.username || !this.auth.password)) {
        errors.push("auth.username and auth.password are required for basic authentication");
      }
      if (this.auth.type === "apikey" && (!this.auth.header || !this.auth.value)) {
        errors.push("auth.header and auth.value are required for API key authentication");
      }
    }
    return {
      isValid: errors.length === 0,
      errors
    };
  }
  /**
   * Build headers with authentication
   * @returns {Object} Headers object
   */
  _buildHeaders() {
    const headers = {
      "Content-Type": "application/json",
      "User-Agent": "s3db-webhook-replicator",
      ...this.headers
    };
    if (this.auth) {
      switch (this.auth.type) {
        case "bearer":
          headers["Authorization"] = `Bearer ${this.auth.token}`;
          break;
        case "basic":
          const credentials = Buffer.from(`${this.auth.username}:${this.auth.password}`).toString("base64");
          headers["Authorization"] = `Basic ${credentials}`;
          break;
        case "apikey":
          headers[this.auth.header] = this.auth.value;
          break;
      }
    }
    return headers;
  }
  /**
   * Apply resource transformer if configured
   * @param {string} resource - Resource name
   * @param {Object} data - Data to transform
   * @returns {Object} Transformed data
   */
  _applyTransformer(resource, data) {
    let cleanData = this._cleanInternalFields(data);
    const entry = this.resources[resource];
    let result = cleanData;
    if (!entry) return cleanData;
    if (typeof entry.transform === "function") {
      result = entry.transform(cleanData);
    }
    return result || cleanData;
  }
  /**
   * Remove internal fields from data
   * @param {Object} data - Data object
   * @returns {Object} Cleaned data
   */
  _cleanInternalFields(data) {
    if (!data || typeof data !== "object") return data;
    const cleanData = { ...data };
    Object.keys(cleanData).forEach((key) => {
      if (key.startsWith("$") || key.startsWith("_")) {
        delete cleanData[key];
      }
    });
    return cleanData;
  }
  /**
   * Create standardized webhook payload
   * @param {string} resource - Resource name
   * @param {string} operation - Operation type
   * @param {Object} data - Record data
   * @param {string} id - Record ID
   * @param {Object} beforeData - Before data (for updates)
   * @returns {Object} Webhook payload
   */
  createPayload(resource, operation, data, id, beforeData = null) {
    const basePayload = {
      resource,
      action: operation,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      source: "s3db-webhook-replicator"
    };
    switch (operation) {
      case "insert":
        return {
          ...basePayload,
          data
        };
      case "update":
        return {
          ...basePayload,
          before: beforeData,
          data
        };
      case "delete":
        return {
          ...basePayload,
          data
        };
      default:
        return {
          ...basePayload,
          data
        };
    }
  }
  /**
   * Make HTTP request with retries
   * @param {Object} payload - Request payload
   * @param {number} attempt - Current attempt number
   * @returns {Promise<Object>} Response
   */
  async _makeRequest(payload, attempt = 0) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);
    try {
      const response = await fetch(this.url, {
        method: this.method,
        headers: this._buildHeaders(),
        body: JSON.stringify(payload),
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      this.stats.totalRequests++;
      if (response.ok) {
        this.stats.successfulRequests++;
        return {
          success: true,
          status: response.status,
          statusText: response.statusText
        };
      }
      if (this.retryOnStatus.includes(response.status) && attempt < this.retries) {
        this.stats.retriedRequests++;
        this.stats.totalRetries++;
        const delay = this.retryStrategy === "exponential" ? this.retryDelay * Math.pow(2, attempt) : this.retryDelay;
        if (this.config.verbose) {
          console.log(`[WebhookReplicator] Retrying request (attempt ${attempt + 1}/${this.retries}) after ${delay}ms - Status: ${response.status}`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
        return this._makeRequest(payload, attempt + 1);
      }
      this.stats.failedRequests++;
      const errorText = await response.text().catch(() => "");
      return {
        success: false,
        status: response.status,
        statusText: response.statusText,
        error: errorText || `HTTP ${response.status}: ${response.statusText}`
      };
    } catch (error) {
      clearTimeout(timeoutId);
      if (attempt < this.retries) {
        this.stats.retriedRequests++;
        this.stats.totalRetries++;
        const delay = this.retryStrategy === "exponential" ? this.retryDelay * Math.pow(2, attempt) : this.retryDelay;
        if (this.config.verbose) {
          console.log(`[WebhookReplicator] Retrying request (attempt ${attempt + 1}/${this.retries}) after ${delay}ms - Error: ${error.message}`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
        return this._makeRequest(payload, attempt + 1);
      }
      this.stats.failedRequests++;
      this.stats.totalRequests++;
      return {
        success: false,
        error: error.message
      };
    }
  }
  async initialize(database) {
    await super.initialize(database);
    const validation = this.validateConfig();
    if (!validation.isValid) {
      const error = new Error(`WebhookReplicator configuration is invalid: ${validation.errors.join(", ")}`);
      if (this.config.verbose) {
        console.error(`[WebhookReplicator] ${error.message}`);
      }
      this.emit("initialization_error", {
        replicator: this.name,
        error: error.message,
        errors: validation.errors
      });
      throw error;
    }
    this.emit("db:plugin:initialized", {
      replicator: this.name,
      url: this.url,
      method: this.method,
      authType: this.auth?.type || "none",
      resources: Object.keys(this.resources || {})
    });
  }
  async replicate(resource, operation, data, id, beforeData = null) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      const transformedData = this._applyTransformer(resource, data);
      const payload = this.createPayload(resource, operation, transformedData, id, beforeData);
      const response = await this._makeRequest(payload);
      if (response.success) {
        this.emit("plg:replicator:replicated", {
          replicator: this.name,
          resource,
          operation,
          id,
          url: this.url,
          status: response.status,
          success: true
        });
        return { success: true, status: response.status };
      }
      throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Replication failed for ${resource}: ${err.message}`);
    }
    this.emit("plg:replicator:error", {
      replicator: this.name,
      resource,
      operation,
      id,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async replicateBatch(resource, records) {
    if (this.enabled === false) {
      return { skipped: true, reason: "replicator_disabled" };
    }
    if (!this.shouldReplicateResource(resource)) {
      return { skipped: true, reason: "resource_not_included" };
    }
    const [ok, err, result] = await tryFn(async () => {
      if (this.batch) {
        const payloads = records.map(
          (record) => this.createPayload(
            resource,
            record.operation,
            this._applyTransformer(resource, record.data),
            record.id,
            record.beforeData
          )
        );
        const response = await this._makeRequest({ batch: payloads });
        if (response.success) {
          this.emit("batch_replicated", {
            replicator: this.name,
            resource,
            url: this.url,
            total: records.length,
            successful: records.length,
            errors: 0,
            status: response.status
          });
          return {
            success: true,
            total: records.length,
            successful: records.length,
            errors: 0,
            status: response.status
          };
        }
        throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
      }
      const results = await Promise.allSettled(
        records.map(
          (record) => this.replicate(resource, record.operation, record.data, record.id, record.beforeData)
        )
      );
      const successful = results.filter((r) => r.status === "fulfilled" && r.value.success).length;
      const failed = results.length - successful;
      this.emit("batch_replicated", {
        replicator: this.name,
        resource,
        url: this.url,
        total: records.length,
        successful,
        errors: failed
      });
      return {
        success: failed === 0,
        total: records.length,
        successful,
        errors: failed,
        results
      };
    });
    if (ok) return result;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Batch replication failed for ${resource}: ${err.message}`);
    }
    this.emit("batch_replicator_error", {
      replicator: this.name,
      resource,
      error: err.message
    });
    return { success: false, error: err.message };
  }
  async testConnection() {
    const [ok, err] = await tryFn(async () => {
      const testPayload = {
        test: true,
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        source: "s3db-webhook-replicator"
      };
      const response = await this._makeRequest(testPayload);
      if (!response.success) {
        throw new Error(response.error || `HTTP ${response.status}: ${response.statusText}`);
      }
      return true;
    });
    if (ok) return true;
    if (this.config.verbose) {
      console.warn(`[WebhookReplicator] Connection test failed: ${err.message}`);
    }
    this.emit("connection_error", {
      replicator: this.name,
      error: err.message
    });
    return false;
  }
  async getStatus() {
    const baseStatus = await super.getStatus();
    return {
      ...baseStatus,
      url: this.url,
      method: this.method,
      authType: this.auth?.type || "none",
      timeout: this.timeout,
      retries: this.retries,
      retryStrategy: this.retryStrategy,
      batchMode: this.batch,
      resources: Object.keys(this.resources || {}),
      stats: { ...this.stats }
    };
  }
  shouldReplicateResource(resource) {
    if (!this.resources || Object.keys(this.resources).length === 0) {
      return true;
    }
    return Object.keys(this.resources).includes(resource);
  }
}

const REPLICATOR_DRIVERS = {
  s3db: S3dbReplicator,
  sqs: SqsReplicator,
  bigquery: BigqueryReplicator,
  postgres: PostgresReplicator,
  mysql: MySQLReplicator,
  mariadb: MySQLReplicator,
  // MariaDB uses the same driver as MySQL
  planetscale: PlanetScaleReplicator,
  turso: TursoReplicator,
  dynamodb: DynamoDBReplicator,
  mongodb: MongoDBReplicator,
  webhook: WebhookReplicator
};
function createReplicator(driver, config = {}, resources = [], client = null) {
  const ReplicatorClass = REPLICATOR_DRIVERS[driver];
  if (!ReplicatorClass) {
    throw new ReplicationError(`Unknown replicator driver: ${driver}`, {
      operation: "createReplicator",
      driver,
      availableDrivers: Object.keys(REPLICATOR_DRIVERS),
      suggestion: `Use one of the available drivers: ${Object.keys(REPLICATOR_DRIVERS).join(", ")}`
    });
  }
  return new ReplicatorClass(config, resources, client);
}
function validateReplicatorConfig(driver, config, resources = [], client = null) {
  const replicator = createReplicator(driver, config, resources, client);
  return replicator.validateConfig();
}

function normalizeResourceName(name) {
  return typeof name === "string" ? name.trim().toLowerCase() : name;
}
class ReplicatorPlugin extends Plugin {
  constructor(options = {}) {
    super();
    if (!options.replicators || !Array.isArray(options.replicators)) {
      throw new ReplicationError("ReplicatorPlugin requires replicators array", {
        operation: "constructor",
        pluginName: "ReplicatorPlugin",
        providedOptions: Object.keys(options),
        suggestion: 'Provide replicators array: new ReplicatorPlugin({ replicators: [{ driver: "s3db", resources: [...] }] })'
      });
    }
    for (const rep of options.replicators) {
      if (!rep.driver) {
        throw new ReplicationError("Each replicator must have a driver", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          replicatorConfig: rep,
          suggestion: 'Each replicator entry must specify a driver: { driver: "s3db", resources: {...} }'
        });
      }
      if (!rep.resources || typeof rep.resources !== "object") {
        throw new ReplicationError("Each replicator must have resources config", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          driver: rep.driver,
          replicatorConfig: rep,
          suggestion: 'Provide resources as object or array: { driver: "s3db", resources: ["users"] } or { resources: { users: "people" } }'
        });
      }
      if (Object.keys(rep.resources).length === 0) {
        throw new ReplicationError("Each replicator must have at least one resource configured", {
          operation: "constructor",
          pluginName: "ReplicatorPlugin",
          driver: rep.driver,
          replicatorConfig: rep,
          suggestion: 'Add at least one resource to replicate: { driver: "s3db", resources: ["users"] }'
        });
      }
    }
    this.config = {
      replicators: options.replicators || [],
      logErrors: options.logErrors !== false,
      replicatorLogResource: options.replicatorLogResource || "replicator_log",
      persistReplicatorLog: options.persistReplicatorLog || false,
      enabled: options.enabled !== false,
      batchSize: options.batchSize || 100,
      maxRetries: options.maxRetries || 3,
      timeout: options.timeout || 3e4,
      verbose: options.verbose || false
    };
    this.replicators = [];
    this.database = null;
    this.eventListenersInstalled = /* @__PURE__ */ new Set();
    this.eventHandlers = /* @__PURE__ */ new Map();
    this.stats = {
      totalReplications: 0,
      totalErrors: 0,
      lastSync: null
    };
    this._afterCreateResourceHook = null;
  }
  // Helper to filter out internal S3DB fields
  filterInternalFields(obj) {
    if (!obj || typeof obj !== "object") return obj;
    const filtered = {};
    for (const [key, value] of Object.entries(obj)) {
      if (!key.startsWith("_") && key !== "$overflow" && key !== "$before" && key !== "$after") {
        filtered[key] = value;
      }
    }
    return filtered;
  }
  async getCompleteData(resource, data) {
    const [ok, err, completeRecord] = await tryFn(() => resource.get(data.id));
    return ok ? completeRecord : data;
  }
  installEventListeners(resource, database, plugin) {
    if (!resource || this.eventListenersInstalled.has(resource.name) || resource.name === this.config.replicatorLogResource) {
      return;
    }
    const insertHandler = async (data) => {
      const [ok, error] = await tryFn(async () => {
        const completeData = { ...data, createdAt: (/* @__PURE__ */ new Date()).toISOString() };
        await plugin.processReplicatorEvent("insert", resource.name, completeData.id, completeData);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Insert event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "insert", error: error.message, resource: resource.name });
      }
    };
    const updateHandler = async (data, beforeData) => {
      const [ok, error] = await tryFn(async () => {
        const completeData = await plugin.getCompleteData(resource, data);
        const dataWithTimestamp = { ...completeData, updatedAt: (/* @__PURE__ */ new Date()).toISOString() };
        await plugin.processReplicatorEvent("update", resource.name, completeData.id, dataWithTimestamp, beforeData);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Update event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "update", error: error.message, resource: resource.name });
      }
    };
    const deleteHandler = async (data) => {
      const [ok, error] = await tryFn(async () => {
        await plugin.processReplicatorEvent("delete", resource.name, data.id, data);
      });
      if (!ok) {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Delete event failed for resource ${resource.name}: ${error.message}`);
        }
        this.emit("plg:replicator:error", { operation: "delete", error: error.message, resource: resource.name });
      }
    };
    this.eventHandlers.set(resource.name, {
      inserted: insertHandler,
      updated: updateHandler,
      deleted: deleteHandler
    });
    resource.on("inserted", insertHandler);
    resource.on("updated", updateHandler);
    resource.on("deleted", deleteHandler);
    this.eventListenersInstalled.add(resource.name);
  }
  async onInstall() {
    if (this.config.persistReplicatorLog) {
      const [ok, err, logResource] = await tryFn(() => this.database.createResource({
        name: this.config.replicatorLogResource || "plg_replicator_logs",
        attributes: {
          id: "string|required",
          resource: "string|required",
          action: "string|required",
          data: "json",
          timestamp: "number|required",
          createdAt: "string|required"
        },
        behavior: "truncate-data"
      }));
      if (ok) {
        this.replicatorLogResource = logResource;
      } else {
        this.replicatorLogResource = this.database.resources[this.config.replicatorLogResource || "plg_replicator_logs"];
      }
    }
    await this.initializeReplicators(this.database);
    this.installDatabaseHooks();
    for (const resource of Object.values(this.database.resources)) {
      if (resource.name !== (this.config.replicatorLogResource || "plg_replicator_logs")) {
        this.installEventListeners(resource, this.database, this);
      }
    }
  }
  async start() {
  }
  installDatabaseHooks() {
    this._afterCreateResourceHook = (resource) => {
      if (resource.name !== (this.config.replicatorLogResource || "plg_replicator_logs")) {
        this.installEventListeners(resource, this.database, this);
      }
    };
    this.database.addHook("afterCreateResource", this._afterCreateResourceHook);
  }
  removeDatabaseHooks() {
    if (this._afterCreateResourceHook) {
      this.database.removeHook("afterCreateResource", this._afterCreateResourceHook);
      this._afterCreateResourceHook = null;
    }
  }
  createReplicator(driver, config, resources, client) {
    return createReplicator(driver, config, resources, client);
  }
  async initializeReplicators(database) {
    for (const replicatorConfig of this.config.replicators) {
      const { driver, config = {}, resources, client, ...otherConfig } = replicatorConfig;
      const replicatorResources = resources || config.resources || {};
      const mergedConfig = { ...config, ...otherConfig };
      const replicator = this.createReplicator(driver, mergedConfig, replicatorResources, client);
      if (replicator) {
        await replicator.initialize(database);
        this.replicators.push(replicator);
      }
    }
  }
  async uploadMetadataFile(database) {
    if (typeof this.database.uploadMetadataFile === "function") {
      await this.database.uploadMetadataFile();
    }
  }
  async retryWithBackoff(operation, maxRetries = 3) {
    let lastError;
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      const [ok, error, result] = await tryFn(operation);
      if (ok) {
        return result;
      } else {
        lastError = error;
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Retry attempt ${attempt}/${maxRetries} failed: ${error.message}`);
        }
        if (attempt === maxRetries) {
          throw error;
        }
        const delay = Math.pow(2, attempt - 1) * 1e3;
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Waiting ${delay}ms before retry...`);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
    throw lastError;
  }
  async logError(replicator, resourceName, operation, recordId, data, error) {
    const [ok, logError] = await tryFn(async () => {
      const logResourceName = this.config.replicatorLogResource;
      if (this.database && this.database.resources && this.database.resources[logResourceName]) {
        const logResource = this.database.resources[logResourceName];
        await logResource.insert({
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          data: JSON.stringify(data),
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          status: "error"
        });
      }
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to log error for ${resourceName}: ${logError.message}`);
      }
      this.emit("plg:replicator:log-error", {
        replicator: replicator.name || replicator.id,
        resourceName,
        operation,
        recordId,
        originalError: error.message,
        logError: logError.message
      });
    }
  }
  async processReplicatorEvent(operation, resourceName, recordId, data, beforeData = null) {
    if (!this.config.enabled) return;
    const applicableReplicators = this.replicators.filter((replicator) => {
      const should = replicator.shouldReplicateResource && replicator.shouldReplicateResource(resourceName, operation);
      return should;
    });
    if (applicableReplicators.length === 0) {
      return;
    }
    const promises = applicableReplicators.map(async (replicator) => {
      const [ok, error, result] = await tryFn(async () => {
        const result2 = await this.retryWithBackoff(
          () => replicator.replicate(resourceName, operation, data, recordId, beforeData),
          this.config.maxRetries
        );
        this.emit("plg:replicator:replicated", {
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          result: result2,
          success: true
        });
        return result2;
      });
      if (ok) {
        return result;
      } else {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Replication failed for ${replicator.name || replicator.id} on ${resourceName}: ${error.message}`);
        }
        this.emit("plg:replicator:error", {
          replicator: replicator.name || replicator.id,
          resourceName,
          operation,
          recordId,
          error: error.message
        });
        if (this.config.logErrors && this.database) {
          await this.logError(replicator, resourceName, operation, recordId, data, error);
        }
        throw error;
      }
    });
    return Promise.allSettled(promises);
  }
  async processReplicatorItem(item) {
    const applicableReplicators = this.replicators.filter((replicator) => {
      const should = replicator.shouldReplicateResource && replicator.shouldReplicateResource(item.resourceName, item.operation);
      return should;
    });
    if (applicableReplicators.length === 0) {
      return;
    }
    const promises = applicableReplicators.map(async (replicator) => {
      const [wrapperOk, wrapperError] = await tryFn(async () => {
        const [ok, err, result] = await tryFn(
          () => replicator.replicate(item.resourceName, item.operation, item.data, item.recordId, item.beforeData)
        );
        if (!ok) {
          if (this.config.verbose) {
            console.warn(`[ReplicatorPlugin] Replicator item processing failed for ${replicator.name || replicator.id} on ${item.resourceName}: ${err.message}`);
          }
          this.emit("plg:replicator:error", {
            replicator: replicator.name || replicator.id,
            resourceName: item.resourceName,
            operation: item.operation,
            recordId: item.recordId,
            error: err.message
          });
          if (this.config.logErrors && this.database) {
            await this.logError(replicator, item.resourceName, item.operation, item.recordId, item.data, err);
          }
          return { success: false, error: err.message };
        }
        this.emit("plg:replicator:replicated", {
          replicator: replicator.name || replicator.id,
          resourceName: item.resourceName,
          operation: item.operation,
          recordId: item.recordId,
          result,
          success: true
        });
        return { success: true, result };
      });
      if (wrapperOk) {
        return wrapperOk;
      } else {
        if (this.config.verbose) {
          console.warn(`[ReplicatorPlugin] Wrapper processing failed for ${replicator.name || replicator.id} on ${item.resourceName}: ${wrapperError.message}`);
        }
        this.emit("plg:replicator:error", {
          replicator: replicator.name || replicator.id,
          resourceName: item.resourceName,
          operation: item.operation,
          recordId: item.recordId,
          error: wrapperError.message
        });
        if (this.config.logErrors && this.database) {
          await this.logError(replicator, item.resourceName, item.operation, item.recordId, item.data, wrapperError);
        }
        return { success: false, error: wrapperError.message };
      }
    });
    return Promise.allSettled(promises);
  }
  async logReplicator(item) {
    const logRes = this.replicatorLog || this.database.resources[normalizeResourceName(this.config.replicatorLogResource)];
    if (!logRes) {
      this.emit("plg:replicator:log-failed", { error: "replicator log resource not found", item });
      return;
    }
    const logItem = {
      id: item.id || `repl-${Date.now()}-${Math.random().toString(36).slice(2)}`,
      resource: item.resource || item.resourceName || "",
      action: item.operation || item.action || "",
      data: item.data || {},
      timestamp: typeof item.timestamp === "number" ? item.timestamp : Date.now(),
      createdAt: item.createdAt || (/* @__PURE__ */ new Date()).toISOString().slice(0, 10)
    };
    const [ok, err] = await tryFn(async () => {
      await logRes.insert(logItem);
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to log replicator item: ${err.message}`);
      }
      this.emit("plg:replicator:log-failed", { error: err, item });
    }
  }
  async updateReplicatorLog(logId, updates) {
    if (!this.replicatorLog) return;
    const [ok, err] = await tryFn(async () => {
      await this.replicatorLog.patch(logId, {
        ...updates,
        lastAttempt: (/* @__PURE__ */ new Date()).toISOString()
      });
    });
    if (!ok) {
      this.emit("plg:replicator:update-log-failed", { error: err.message, logId, updates });
    }
  }
  // Utility methods
  async getReplicatorStats() {
    const replicatorStats = await Promise.all(
      this.replicators.map(async (replicator) => {
        const status = await replicator.getStatus();
        return {
          id: replicator.id,
          driver: replicator.driver,
          config: replicator.config,
          status
        };
      })
    );
    return {
      replicators: replicatorStats,
      stats: this.stats,
      lastSync: this.stats.lastSync
    };
  }
  async getReplicatorLogs(options = {}) {
    if (!this.replicatorLog) {
      return [];
    }
    const {
      resourceName,
      operation,
      status,
      limit = 100,
      offset = 0
    } = options;
    const filter = {};
    if (resourceName) {
      filter.resourceName = resourceName;
    }
    if (operation) {
      filter.operation = operation;
    }
    if (status) {
      filter.status = status;
    }
    const logs = await this.replicatorLog.query(filter, { limit, offset });
    return logs || [];
  }
  async retryFailedReplicators() {
    if (!this.replicatorLog) {
      return { retried: 0 };
    }
    const failedLogs = await this.replicatorLog.query({
      status: "failed"
    });
    let retried = 0;
    for (const log of failedLogs || []) {
      const [ok, err] = await tryFn(async () => {
        await this.processReplicatorEvent(
          log.operation,
          log.resourceName,
          log.recordId,
          log.data
        );
      });
      if (ok) {
        retried++;
      }
    }
    return { retried };
  }
  async syncAllData(replicatorId) {
    const replicator = this.replicators.find((r) => r.id === replicatorId);
    if (!replicator) {
      throw new ReplicationError("Replicator not found", {
        operation: "syncAllData",
        pluginName: "ReplicatorPlugin",
        replicatorId,
        availableReplicators: this.replicators.map((r) => r.id),
        suggestion: "Check replicator ID or use getReplicatorStats() to list available replicators"
      });
    }
    this.stats.lastSync = (/* @__PURE__ */ new Date()).toISOString();
    for (const resourceName in this.database.resources) {
      if (normalizeResourceName(resourceName) === normalizeResourceName("plg_replicator_logs")) continue;
      if (replicator.shouldReplicateResource(resourceName)) {
        this.emit("plg:replicator:sync-resource", { resourceName, replicatorId });
        const resource = this.database.resources[resourceName];
        let offset = 0;
        const pageSize = this.config.batchSize || 100;
        while (true) {
          const [ok, err, page] = await tryFn(() => resource.page({ offset, size: pageSize }));
          if (!ok || !page) break;
          const records = Array.isArray(page) ? page : page.items || [];
          if (records.length === 0) break;
          for (const record of records) {
            await replicator.replicate(resourceName, "insert", record, record.id);
          }
          offset += pageSize;
        }
      }
    }
    this.emit("plg:replicator:sync-completed", { replicatorId, stats: this.stats });
  }
  async stop() {
    const [ok, error] = await tryFn(async () => {
      if (this.replicators && this.replicators.length > 0) {
        const cleanupPromises = this.replicators.map(async (replicator) => {
          const [replicatorOk, replicatorError] = await tryFn(async () => {
            if (replicator && typeof replicator.stop === "function") {
              await replicator.stop();
            }
          });
          if (!replicatorOk) {
            if (this.config.verbose) {
              console.warn(`[ReplicatorPlugin] Failed to stop replicator ${replicator.name || replicator.id}: ${replicatorError.message}`);
            }
            this.emit("plg:replicator:stop-error", {
              replicator: replicator.name || replicator.id || "unknown",
              driver: replicator.driver || "unknown",
              error: replicatorError.message
            });
          }
        });
        await Promise.allSettled(cleanupPromises);
      }
      this.removeDatabaseHooks();
      if (this.database && this.database.resources) {
        for (const resourceName of this.eventListenersInstalled) {
          const resource = this.database.resources[resourceName];
          const handlers = this.eventHandlers.get(resourceName);
          if (resource && handlers) {
            resource.off("inserted", handlers.inserted);
            resource.off("updated", handlers.updated);
            resource.off("deleted", handlers.deleted);
          }
        }
      }
      this.replicators = [];
      this.database = null;
      this.eventListenersInstalled.clear();
      this.eventHandlers.clear();
      this.removeAllListeners();
    });
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[ReplicatorPlugin] Failed to stop plugin: ${error.message}`);
      }
      this.emit("plg:replicator:plugin-stop-error", {
        error: error.message
      });
    }
  }
}

class S3QueuePlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    if (!options.resource) {
      throw new Error('S3QueuePlugin requires "resource" option');
    }
    this.config = {
      resource: options.resource,
      visibilityTimeout: options.visibilityTimeout || 3e4,
      // 30 seconds
      pollInterval: options.pollInterval || 1e3,
      // 1 second
      maxAttempts: options.maxAttempts || 3,
      concurrency: options.concurrency || 1,
      deadLetterResource: options.deadLetterResource || null,
      autoStart: options.autoStart !== false,
      onMessage: options.onMessage,
      onError: options.onError,
      onComplete: options.onComplete,
      verbose: options.verbose || false,
      ...options
    };
    this.queueResource = null;
    this.targetResource = null;
    this.deadLetterResourceObj = null;
    this.workers = [];
    this.isRunning = false;
    this.workerId = `worker-${Date.now()}-${Math.random().toString(36).slice(2, 9)}`;
    this.processedCache = /* @__PURE__ */ new Map();
    this.cacheCleanupInterval = null;
    this.lockCleanupInterval = null;
  }
  async onInstall() {
    this.targetResource = this.database.resources[this.config.resource];
    if (!this.targetResource) {
      throw new Error(`S3QueuePlugin: resource '${this.config.resource}' not found`);
    }
    const queueName = `${this.config.resource}_queue`;
    const [ok, err] = await tryFn(
      () => this.database.createResource({
        name: queueName,
        attributes: {
          id: "string|required",
          originalId: "string|required",
          // ID do registro original
          status: "string|required",
          // pending/processing/completed/failed/dead
          visibleAt: "number|required",
          // Timestamp de visibilidade
          claimedBy: "string|optional",
          // Worker que claimed
          claimedAt: "number|optional",
          // Timestamp do claim
          attempts: "number|default:0",
          maxAttempts: "number|default:3",
          error: "string|optional",
          result: "json|optional",
          createdAt: "string|required",
          completedAt: "number|optional"
        },
        behavior: "body-overflow",
        timestamps: true,
        asyncPartitions: true,
        partitions: {
          byStatus: { fields: { status: "string" } },
          byDate: { fields: { createdAt: "string|maxlength:10" } }
        }
      })
    );
    if (!ok && !this.database.resources[queueName]) {
      throw new Error(`Failed to create queue resource: ${err?.message}`);
    }
    this.queueResource = this.database.resources[queueName];
    this.addHelperMethods();
    if (this.config.deadLetterResource) {
      await this.createDeadLetterResource();
    }
    if (this.config.verbose) {
      console.log(`[S3QueuePlugin] Setup completed for resource '${this.config.resource}'`);
    }
  }
  async onStart() {
    if (this.config.autoStart && this.config.onMessage) {
      await this.startProcessing();
    }
  }
  async onStop() {
    await this.stopProcessing();
  }
  addHelperMethods() {
    const plugin = this;
    const resource = this.targetResource;
    resource.enqueue = async function(data, options = {}) {
      const recordData = {
        id: data.id || idGenerator(),
        ...data
      };
      const record = await resource.insert(recordData);
      const queueEntry = {
        id: idGenerator(),
        originalId: record.id,
        status: "pending",
        visibleAt: Date.now(),
        attempts: 0,
        maxAttempts: options.maxAttempts || plugin.config.maxAttempts,
        createdAt: (/* @__PURE__ */ new Date()).toISOString().slice(0, 10)
      };
      await plugin.queueResource.insert(queueEntry);
      plugin.emit("plg:s3-queue:message-enqueued", { id: record.id, queueId: queueEntry.id });
      return record;
    };
    resource.queueStats = async function() {
      return await plugin.getStats();
    };
    resource.startProcessing = async function(handler, options = {}) {
      return await plugin.startProcessing(handler, options);
    };
    resource.stopProcessing = async function() {
      return await plugin.stopProcessing();
    };
  }
  async startProcessing(handler = null, options = {}) {
    if (this.isRunning) {
      if (this.config.verbose) {
        console.log("[S3QueuePlugin] Already running");
      }
      return;
    }
    const messageHandler = handler || this.config.onMessage;
    if (!messageHandler) {
      throw new Error("S3QueuePlugin: onMessage handler required");
    }
    this.isRunning = true;
    const concurrency = options.concurrency || this.config.concurrency;
    this.cacheCleanupInterval = setInterval(() => {
      const now = Date.now();
      const maxAge = 3e4;
      for (const [queueId, timestamp] of this.processedCache.entries()) {
        if (now - timestamp > maxAge) {
          this.processedCache.delete(queueId);
        }
      }
    }, 5e3);
    for (let i = 0; i < concurrency; i++) {
      const worker = this.createWorker(messageHandler, i);
      this.workers.push(worker);
    }
    if (this.config.verbose) {
      console.log(`[S3QueuePlugin] Started ${concurrency} workers`);
    }
    this.emit("plg:s3-queue:workers-started", { concurrency, workerId: this.workerId });
  }
  async stopProcessing() {
    if (!this.isRunning) return;
    this.isRunning = false;
    if (this.cacheCleanupInterval) {
      clearInterval(this.cacheCleanupInterval);
      this.cacheCleanupInterval = null;
    }
    await Promise.all(this.workers);
    this.workers = [];
    this.processedCache.clear();
    if (this.config.verbose) {
      console.log("[S3QueuePlugin] Stopped all workers");
    }
    this.emit("plg:s3-queue:workers-stopped", { workerId: this.workerId });
  }
  createWorker(handler, workerIndex) {
    return (async () => {
      while (this.isRunning) {
        try {
          const message = await this.claimMessage();
          if (message) {
            await this.processMessage(message, handler);
          } else {
            await new Promise((resolve) => setTimeout(resolve, this.config.pollInterval));
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[Worker ${workerIndex}] Error:`, error.message);
          }
          await new Promise((resolve) => setTimeout(resolve, 1e3));
        }
      }
    })();
  }
  async claimMessage() {
    const now = Date.now();
    const [ok, err, messages] = await tryFn(
      () => this.queueResource.query({
        status: "pending"
      })
    );
    if (!ok || !messages || messages.length === 0) {
      return null;
    }
    const available = messages.filter((m) => m.visibleAt <= now);
    if (available.length === 0) {
      return null;
    }
    for (const msg of available) {
      const claimed = await this.attemptClaim(msg);
      if (claimed) {
        return claimed;
      }
    }
    return null;
  }
  /**
   * Acquire a distributed lock using PluginStorage TTL
   * This ensures only one worker can claim a message at a time
   */
  async acquireLock(messageId) {
    const storage = this.getStorage();
    const lockKey = `msg-${messageId}`;
    try {
      const lock = await storage.acquireLock(lockKey, {
        ttl: 5,
        // 5 seconds
        timeout: 0,
        // Don't wait if locked
        workerId: this.workerId
      });
      return lock !== null;
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[acquireLock] Error: ${error.message}`);
      }
      return false;
    }
  }
  /**
   * Release a distributed lock via PluginStorage
   */
  async releaseLock(messageId) {
    const storage = this.getStorage();
    const lockKey = `msg-${messageId}`;
    try {
      await storage.releaseLock(lockKey);
    } catch (error) {
      if (this.config.verbose) {
        console.log(`[releaseLock] Failed to release lock for ${messageId}: ${error.message}`);
      }
    }
  }
  /**
   * Clean up stale locks - NO LONGER NEEDED
   * TTL handles automatic expiration, no manual cleanup required
   */
  async cleanupStaleLocks() {
    return;
  }
  async attemptClaim(msg) {
    const now = Date.now();
    const lockAcquired = await this.acquireLock(msg.id);
    if (!lockAcquired) {
      return null;
    }
    if (this.processedCache.has(msg.id)) {
      await this.releaseLock(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Message ${msg.id} already processed (in cache)`);
      }
      return null;
    }
    this.processedCache.set(msg.id, Date.now());
    await this.releaseLock(msg.id);
    const [okGet, errGet, msgWithETag] = await tryFn(
      () => this.queueResource.get(msg.id)
    );
    if (!okGet || !msgWithETag) {
      this.processedCache.delete(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Message ${msg.id} not found or error: ${errGet?.message}`);
      }
      return null;
    }
    if (msgWithETag.status !== "pending" || msgWithETag.visibleAt > now) {
      this.processedCache.delete(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Message ${msg.id} not claimable: status=${msgWithETag.status}, visibleAt=${msgWithETag.visibleAt}, now=${now}`);
      }
      return null;
    }
    if (this.config.verbose) {
      console.log(`[attemptClaim] Attempting to claim ${msg.id} with ETag: ${msgWithETag._etag}`);
    }
    const [ok, err, result] = await tryFn(
      () => this.queueResource.updateConditional(msgWithETag.id, {
        status: "processing",
        claimedBy: this.workerId,
        claimedAt: now,
        visibleAt: now + this.config.visibilityTimeout,
        attempts: msgWithETag.attempts + 1
      }, {
        ifMatch: msgWithETag._etag
        // ← ATOMIC CLAIM using ETag!
      })
    );
    if (!ok || !result.success) {
      this.processedCache.delete(msg.id);
      if (this.config.verbose) {
        console.log(`[attemptClaim] Failed to claim ${msg.id}: ${err?.message || result.error}`);
      }
      return null;
    }
    if (this.config.verbose) {
      console.log(`[attemptClaim] Successfully claimed ${msg.id}`);
    }
    const [okRecord, errRecord, record] = await tryFn(
      () => this.targetResource.get(msgWithETag.originalId)
    );
    if (!okRecord) {
      await this.failMessage(msgWithETag.id, "Original record not found");
      return null;
    }
    return {
      queueId: msgWithETag.id,
      record,
      attempts: msgWithETag.attempts + 1,
      maxAttempts: msgWithETag.maxAttempts
    };
  }
  async processMessage(message, handler) {
    const startTime = Date.now();
    try {
      const result = await handler(message.record, {
        queueId: message.queueId,
        attempts: message.attempts,
        workerId: this.workerId
      });
      await this.completeMessage(message.queueId, result);
      const duration = Date.now() - startTime;
      this.emit("plg:s3-queue:message-completed", {
        queueId: message.queueId,
        originalId: message.record.id,
        duration,
        attempts: message.attempts
      });
      if (this.config.onComplete) {
        await this.config.onComplete(message.record, result);
      }
    } catch (error) {
      const shouldRetry = message.attempts < message.maxAttempts;
      if (shouldRetry) {
        await this.retryMessage(message.queueId, message.attempts, error.message);
        this.emit("plg:s3-queue:message-retry", {
          queueId: message.queueId,
          originalId: message.record.id,
          attempts: message.attempts,
          error: error.message
        });
      } else {
        await this.moveToDeadLetter(message.queueId, message.record, error.message);
        this.emit("plg:s3-queue:message-dead", {
          queueId: message.queueId,
          originalId: message.record.id,
          error: error.message
        });
      }
      if (this.config.onError) {
        await this.config.onError(error, message.record);
      }
    }
  }
  async completeMessage(queueId, result) {
    await this.queueResource.update(queueId, {
      status: "completed",
      completedAt: Date.now(),
      result
    });
  }
  async failMessage(queueId, error) {
    await this.queueResource.update(queueId, {
      status: "failed",
      error
    });
  }
  async retryMessage(queueId, attempts, error) {
    const backoff = Math.min(Math.pow(2, attempts) * 1e3, 3e4);
    await this.queueResource.update(queueId, {
      status: "pending",
      visibleAt: Date.now() + backoff,
      error
    });
    this.processedCache.delete(queueId);
  }
  async moveToDeadLetter(queueId, record, error) {
    if (this.config.deadLetterResource && this.deadLetterResourceObj) {
      const msg = await this.queueResource.get(queueId);
      await this.deadLetterResourceObj.insert({
        id: idGenerator(),
        originalId: record.id,
        queueId,
        data: record,
        error,
        attempts: msg.attempts,
        createdAt: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
    await this.queueResource.update(queueId, {
      status: "dead",
      error
    });
  }
  async getStats() {
    const [ok, err, allMessages] = await tryFn(
      () => this.queueResource.list()
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn("[S3QueuePlugin] Failed to get stats:", err.message);
      }
      return null;
    }
    const stats = {
      total: allMessages.length,
      pending: 0,
      processing: 0,
      completed: 0,
      failed: 0,
      dead: 0
    };
    for (const msg of allMessages) {
      if (stats[msg.status] !== void 0) {
        stats[msg.status]++;
      }
    }
    return stats;
  }
  async createDeadLetterResource() {
    const [ok, err] = await tryFn(
      () => this.database.createResource({
        name: this.config.deadLetterResource,
        attributes: {
          id: "string|required",
          originalId: "string|required",
          queueId: "string|required",
          data: "json|required",
          error: "string|required",
          attempts: "number|required",
          createdAt: "string|required"
        },
        behavior: "body-overflow",
        timestamps: true
      })
    );
    if (ok || this.database.resources[this.config.deadLetterResource]) {
      this.deadLetterResourceObj = this.database.resources[this.config.deadLetterResource];
      if (this.config.verbose) {
        console.log(`[S3QueuePlugin] Dead letter queue created: ${this.config.deadLetterResource}`);
      }
    }
  }
}

class SchedulerError extends S3dbError {
  constructor(message, details = {}) {
    const { taskId, operation = "unknown", cronExpression, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
Scheduler Operation Error

Operation: ${operation}
${taskId ? `Task ID: ${taskId}` : ""}
${cronExpression ? `Cron: ${cronExpression}` : ""}

Common causes:
1. Invalid cron expression format
2. Task not found or already exists
3. Scheduler not properly initialized
4. Job execution failure
5. Resource conflicts

Solution:
Check task configuration and ensure scheduler is properly initialized.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/scheduler.md
`.trim();
    }
    super(message, { ...rest, taskId, operation, cronExpression, description });
  }
}

class SchedulerPlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      timezone: options.timezone || "UTC",
      jobs: options.jobs || {},
      defaultTimeout: options.defaultTimeout || 3e5,
      // 5 minutes
      defaultRetries: options.defaultRetries || 1,
      jobHistoryResource: options.jobHistoryResource || "plg_job_executions",
      persistJobs: options.persistJobs !== false,
      verbose: options.verbose || false,
      onJobStart: options.onJobStart || null,
      onJobComplete: options.onJobComplete || null,
      onJobError: options.onJobError || null,
      ...options
    };
    this.database = null;
    this.jobs = /* @__PURE__ */ new Map();
    this.activeJobs = /* @__PURE__ */ new Map();
    this.timers = /* @__PURE__ */ new Map();
    this.statistics = /* @__PURE__ */ new Map();
    this._validateConfiguration();
  }
  /**
   * Helper to detect test environment
   * @private
   */
  _isTestEnvironment() {
    return process.env.NODE_ENV === "test" || process.env.JEST_WORKER_ID !== void 0 || global.expect !== void 0;
  }
  _validateConfiguration() {
    if (Object.keys(this.config.jobs).length === 0) {
      throw new SchedulerError("At least one job must be defined", {
        operation: "validateConfiguration",
        jobCount: 0,
        suggestion: 'Provide at least one job in the jobs configuration: { jobs: { myJob: { schedule: "* * * * *", action: async () => {...} } } }'
      });
    }
    for (const [jobName, job] of Object.entries(this.config.jobs)) {
      if (!job.schedule) {
        throw new SchedulerError(`Job '${jobName}' must have a schedule`, {
          operation: "validateConfiguration",
          taskId: jobName,
          providedConfig: Object.keys(job),
          suggestion: 'Add a schedule property with a valid cron expression: { schedule: "0 * * * *", action: async () => {...} }'
        });
      }
      if (!job.action || typeof job.action !== "function") {
        throw new SchedulerError(`Job '${jobName}' must have an action function`, {
          operation: "validateConfiguration",
          taskId: jobName,
          actionType: typeof job.action,
          suggestion: 'Provide an action function: { schedule: "...", action: async (db, ctx) => {...} }'
        });
      }
      if (!this._isValidCronExpression(job.schedule)) {
        throw new SchedulerError(`Job '${jobName}' has invalid cron expression`, {
          operation: "validateConfiguration",
          taskId: jobName,
          cronExpression: job.schedule,
          suggestion: "Use valid cron format (5 fields: minute hour day month weekday) or shortcuts (@hourly, @daily, @weekly, @monthly, @yearly)"
        });
      }
    }
  }
  _isValidCronExpression(expr) {
    if (typeof expr !== "string") return false;
    const shortcuts = ["@yearly", "@annually", "@monthly", "@weekly", "@daily", "@hourly"];
    if (shortcuts.includes(expr)) return true;
    const parts = expr.trim().split(/\s+/);
    if (parts.length !== 5) return false;
    return true;
  }
  async onInstall() {
    if (this.config.persistJobs) {
      await this._createJobHistoryResource();
    }
    for (const [jobName, jobConfig] of Object.entries(this.config.jobs)) {
      this.jobs.set(jobName, {
        ...jobConfig,
        enabled: jobConfig.enabled !== false,
        retries: jobConfig.retries || this.config.defaultRetries,
        timeout: jobConfig.timeout || this.config.defaultTimeout,
        lastRun: null,
        nextRun: null,
        runCount: 0,
        successCount: 0,
        errorCount: 0
      });
      this.statistics.set(jobName, {
        totalRuns: 0,
        totalSuccesses: 0,
        totalErrors: 0,
        avgDuration: 0,
        lastRun: null,
        lastSuccess: null,
        lastError: null
      });
    }
    await this._startScheduling();
    this.emit("db:plugin:initialized", { jobs: this.jobs.size });
  }
  async _createJobHistoryResource() {
    const [ok] = await tryFn(() => this.database.createResource({
      name: this.config.jobHistoryResource,
      attributes: {
        id: "string|required",
        jobName: "string|required",
        status: "string|required",
        // success, error, timeout
        startTime: "number|required",
        endTime: "number",
        duration: "number",
        result: "json|default:null",
        error: "string|default:null",
        retryCount: "number|default:0",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      partitions: {
        byJob: { fields: { jobName: "string" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
  }
  async _startScheduling() {
    for (const [jobName, job] of this.jobs) {
      if (job.enabled) {
        this._scheduleNextExecution(jobName);
      }
    }
  }
  _scheduleNextExecution(jobName) {
    const job = this.jobs.get(jobName);
    if (!job || !job.enabled) return;
    const nextRun = this._calculateNextRun(job.schedule);
    job.nextRun = nextRun;
    const delay = nextRun.getTime() - Date.now();
    if (delay > 0) {
      const timer = setTimeout(() => {
        this._executeJob(jobName);
      }, delay);
      this.timers.set(jobName, timer);
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Scheduled job '${jobName}' for ${nextRun.toISOString()}`);
      }
    }
  }
  _calculateNextRun(schedule) {
    const now = /* @__PURE__ */ new Date();
    if (schedule === "@yearly" || schedule === "@annually") {
      const next2 = new Date(now);
      next2.setFullYear(next2.getFullYear() + 1);
      next2.setMonth(0, 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@monthly") {
      const next2 = new Date(now);
      next2.setMonth(next2.getMonth() + 1, 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@weekly") {
      const next2 = new Date(now);
      next2.setDate(next2.getDate() + (7 - next2.getDay()));
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@daily") {
      const next2 = new Date(now);
      next2.setDate(next2.getDate() + 1);
      next2.setHours(0, 0, 0, 0);
      return next2;
    }
    if (schedule === "@hourly") {
      const next2 = new Date(now);
      next2.setHours(next2.getHours() + 1, 0, 0, 0);
      return next2;
    }
    const [minute, hour, day, month, weekday] = schedule.split(/\s+/);
    const next = new Date(now);
    next.setMinutes(parseInt(minute) || 0);
    next.setSeconds(0);
    next.setMilliseconds(0);
    if (hour !== "*") {
      next.setHours(parseInt(hour));
    }
    if (next <= now) {
      if (hour !== "*") {
        next.setDate(next.getDate() + 1);
      } else {
        next.setHours(next.getHours() + 1);
      }
    }
    if (this._isTestEnvironment()) {
      next.setTime(next.getTime() + 1e3);
    }
    return next;
  }
  async _executeJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      return;
    }
    if (this.activeJobs.has(jobName)) {
      return;
    }
    this.activeJobs.set(jobName, "acquiring-lock");
    const storage = this.getStorage();
    const lockKey = `job-${jobName}`;
    const lock = await storage.acquireLock(lockKey, {
      ttl: Math.ceil(job.timeout / 1e3) + 60,
      // Job timeout + 60 seconds buffer
      timeout: 0,
      // Don't wait if locked
      workerId: process.pid ? String(process.pid) : "unknown"
    });
    if (!lock) {
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Job '${jobName}' already running on another instance`);
      }
      this.activeJobs.delete(jobName);
      return;
    }
    const executionId = `${jobName}_${idGenerator()}`;
    const startTime = Date.now();
    const context = {
      jobName,
      executionId,
      scheduledTime: new Date(startTime),
      database: this.database
    };
    this.activeJobs.set(jobName, executionId);
    try {
      if (this.config.onJobStart) {
        await this._executeHook(this.config.onJobStart, jobName, context);
      }
      this.emit("plg:scheduler:job-start", { jobName, executionId, startTime });
      let attempt = 0;
      let lastError = null;
      let result = null;
      let status = "success";
      const isTestEnvironment = this._isTestEnvironment();
      while (attempt <= job.retries) {
        try {
          const actualTimeout = isTestEnvironment ? Math.min(job.timeout, 1e3) : job.timeout;
          let timeoutId;
          const timeoutPromise = new Promise((_, reject) => {
            timeoutId = setTimeout(() => reject(new Error("Job execution timeout")), actualTimeout);
          });
          const jobPromise = job.action(this.database, context, this);
          try {
            result = await Promise.race([jobPromise, timeoutPromise]);
            clearTimeout(timeoutId);
          } catch (raceError) {
            clearTimeout(timeoutId);
            throw raceError;
          }
          status = "success";
          break;
        } catch (error) {
          lastError = error;
          attempt++;
          if (attempt <= job.retries) {
            if (this.config.verbose) {
              console.warn(`[SchedulerPlugin] Job '${jobName}' failed (attempt ${attempt + 1}):`, error.message);
            }
            const baseDelay = Math.min(Math.pow(2, attempt) * 1e3, 5e3);
            const delay = isTestEnvironment ? 1 : baseDelay;
            await new Promise((resolve) => setTimeout(resolve, delay));
          }
        }
      }
      const endTime = Date.now();
      const duration = Math.max(1, endTime - startTime);
      if (lastError && attempt > job.retries) {
        status = lastError.message.includes("timeout") ? "timeout" : "error";
      }
      job.lastRun = new Date(endTime);
      job.runCount++;
      if (status === "success") {
        job.successCount++;
      } else {
        job.errorCount++;
      }
      const stats = this.statistics.get(jobName);
      stats.totalRuns++;
      stats.lastRun = new Date(endTime);
      if (status === "success") {
        stats.totalSuccesses++;
        stats.lastSuccess = new Date(endTime);
      } else {
        stats.totalErrors++;
        stats.lastError = { time: new Date(endTime), message: lastError?.message };
      }
      stats.avgDuration = (stats.avgDuration * (stats.totalRuns - 1) + duration) / stats.totalRuns;
      if (this.config.persistJobs) {
        await this._persistJobExecution(jobName, executionId, startTime, endTime, duration, status, result, lastError, attempt);
      }
      if (status === "success" && this.config.onJobComplete) {
        await this._executeHook(this.config.onJobComplete, jobName, result, duration);
      } else if (status !== "success" && this.config.onJobError) {
        await this._executeHook(this.config.onJobError, jobName, lastError, attempt);
      }
      this.emit("plg:scheduler:job-complete", {
        jobName,
        executionId,
        status,
        duration,
        result,
        error: lastError?.message,
        retryCount: attempt
      });
      this.activeJobs.delete(jobName);
      if (job.enabled) {
        this._scheduleNextExecution(jobName);
      }
      if (lastError && status !== "success") {
        throw lastError;
      }
    } finally {
      await tryFn(() => storage.releaseLock(lockKey));
    }
  }
  async _persistJobExecution(jobName, executionId, startTime, endTime, duration, status, result, error, retryCount) {
    const [ok, err] = await tryFn(
      () => this.database.resources[this.config.jobHistoryResource].insert({
        id: executionId,
        jobName,
        status,
        startTime,
        endTime,
        duration,
        result: result ? JSON.stringify(result) : null,
        error: error?.message || null,
        retryCount,
        createdAt: new Date(startTime).toISOString().slice(0, 10)
      })
    );
    if (!ok && this.config.verbose) {
      console.warn("[SchedulerPlugin] Failed to persist job execution:", err.message);
    }
  }
  async _executeHook(hook, ...args) {
    if (typeof hook === "function") {
      const [ok, err] = await tryFn(() => hook(...args));
      if (!ok && this.config.verbose) {
        console.warn("[SchedulerPlugin] Hook execution failed:", err.message);
      }
    }
  }
  /**
   * Manually trigger a job execution
   * Note: Race conditions are prevented by distributed locking in _executeJob()
   */
  async runJob(jobName, context = {}) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "runJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    if (this.activeJobs.has(jobName)) {
      throw new SchedulerError(`Job '${jobName}' is already running`, {
        operation: "runJob",
        taskId: jobName,
        executionId: this.activeJobs.get(jobName),
        suggestion: "Wait for current execution to complete or check job status with getJobStatus()"
      });
    }
    await this._executeJob(jobName);
  }
  /**
   * Enable a job
   */
  enableJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "enableJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    job.enabled = true;
    this._scheduleNextExecution(jobName);
    this.emit("plg:scheduler:job-enabled", { jobName });
  }
  /**
   * Disable a job
   */
  disableJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "disableJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    job.enabled = false;
    const timer = this.timers.get(jobName);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(jobName);
    }
    this.emit("plg:scheduler:job-disabled", { jobName });
  }
  /**
   * Get job status and statistics
   */
  getJobStatus(jobName) {
    const job = this.jobs.get(jobName);
    const stats = this.statistics.get(jobName);
    if (!job || !stats) {
      return null;
    }
    return {
      name: jobName,
      enabled: job.enabled,
      schedule: job.schedule,
      description: job.description,
      lastRun: job.lastRun,
      nextRun: job.nextRun,
      isRunning: this.activeJobs.has(jobName),
      statistics: {
        totalRuns: stats.totalRuns,
        totalSuccesses: stats.totalSuccesses,
        totalErrors: stats.totalErrors,
        successRate: stats.totalRuns > 0 ? stats.totalSuccesses / stats.totalRuns * 100 : 0,
        avgDuration: Math.round(stats.avgDuration),
        lastSuccess: stats.lastSuccess,
        lastError: stats.lastError
      }
    };
  }
  /**
   * Get all jobs status
   */
  getAllJobsStatus() {
    const jobs = [];
    for (const jobName of this.jobs.keys()) {
      jobs.push(this.getJobStatus(jobName));
    }
    return jobs;
  }
  /**
   * Get job execution history
   */
  async getJobHistory(jobName, options = {}) {
    if (!this.config.persistJobs) {
      return [];
    }
    const { limit = 50, status = null } = options;
    const queryParams = {
      jobName
      // Uses byJob partition for efficient lookup
    };
    if (status) {
      queryParams.status = status;
    }
    const [ok, err, history] = await tryFn(
      () => this.database.resources[this.config.jobHistoryResource].query(queryParams)
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[SchedulerPlugin] Failed to get job history:`, err.message);
      }
      return [];
    }
    let filtered = history.sort((a, b) => b.startTime - a.startTime).slice(0, limit);
    return filtered.map((h) => {
      let result = null;
      if (h.result) {
        try {
          result = JSON.parse(h.result);
        } catch (e) {
          result = h.result;
        }
      }
      return {
        id: h.id,
        status: h.status,
        startTime: new Date(h.startTime),
        endTime: h.endTime ? new Date(h.endTime) : null,
        duration: h.duration,
        result,
        error: h.error,
        retryCount: h.retryCount
      };
    });
  }
  /**
   * Add a new job at runtime
   */
  addJob(jobName, jobConfig) {
    if (this.jobs.has(jobName)) {
      throw new SchedulerError(`Job '${jobName}' already exists`, {
        operation: "addJob",
        taskId: jobName,
        existingJobs: Array.from(this.jobs.keys()),
        suggestion: "Use a different job name or remove the existing job first with removeJob()"
      });
    }
    if (!jobConfig.schedule || !jobConfig.action) {
      throw new SchedulerError("Job must have schedule and action", {
        operation: "addJob",
        taskId: jobName,
        providedConfig: Object.keys(jobConfig),
        suggestion: 'Provide both schedule and action: { schedule: "0 * * * *", action: async (db, ctx) => {...} }'
      });
    }
    if (!this._isValidCronExpression(jobConfig.schedule)) {
      throw new SchedulerError("Invalid cron expression", {
        operation: "addJob",
        taskId: jobName,
        cronExpression: jobConfig.schedule,
        suggestion: "Use valid cron format (5 fields) or shortcuts (@hourly, @daily, @weekly, @monthly, @yearly)"
      });
    }
    const job = {
      ...jobConfig,
      enabled: jobConfig.enabled !== false,
      retries: jobConfig.retries || this.config.defaultRetries,
      timeout: jobConfig.timeout || this.config.defaultTimeout,
      lastRun: null,
      nextRun: null,
      runCount: 0,
      successCount: 0,
      errorCount: 0
    };
    this.jobs.set(jobName, job);
    this.statistics.set(jobName, {
      totalRuns: 0,
      totalSuccesses: 0,
      totalErrors: 0,
      avgDuration: 0,
      lastRun: null,
      lastSuccess: null,
      lastError: null
    });
    if (job.enabled) {
      this._scheduleNextExecution(jobName);
    }
    this.emit("plg:scheduler:job-added", { jobName });
  }
  /**
   * Remove a job
   */
  removeJob(jobName) {
    const job = this.jobs.get(jobName);
    if (!job) {
      throw new SchedulerError(`Job '${jobName}' not found`, {
        operation: "removeJob",
        taskId: jobName,
        availableJobs: Array.from(this.jobs.keys()),
        suggestion: "Check job name or use getAllJobsStatus() to list available jobs"
      });
    }
    const timer = this.timers.get(jobName);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(jobName);
    }
    this.jobs.delete(jobName);
    this.statistics.delete(jobName);
    this.activeJobs.delete(jobName);
    this.emit("plg:scheduler:job-removed", { jobName });
  }
  /**
   * Get plugin instance by name (for job actions that need other plugins)
   */
  getPlugin(pluginName) {
    return null;
  }
  async start() {
    if (this.config.verbose) {
      console.log(`[SchedulerPlugin] Started with ${this.jobs.size} jobs`);
    }
  }
  async stop() {
    for (const timer of this.timers.values()) {
      clearTimeout(timer);
    }
    this.timers.clear();
    if (!this._isTestEnvironment() && this.activeJobs.size > 0) {
      if (this.config.verbose) {
        console.log(`[SchedulerPlugin] Waiting for ${this.activeJobs.size} active jobs to complete...`);
      }
      const timeout = 5e3;
      const start = Date.now();
      while (this.activeJobs.size > 0 && Date.now() - start < timeout) {
        await new Promise((resolve) => setTimeout(resolve, 100));
      }
      if (this.activeJobs.size > 0) {
        console.warn(`[SchedulerPlugin] ${this.activeJobs.size} jobs still running after timeout`);
      }
    }
    if (this._isTestEnvironment()) {
      this.activeJobs.clear();
    }
    this.jobs.clear();
    this.statistics.clear();
    this.activeJobs.clear();
    this.removeAllListeners();
  }
}

var scheduler_plugin = /*#__PURE__*/Object.freeze({
  __proto__: null,
  SchedulerPlugin: SchedulerPlugin
});

class StateMachineError extends S3dbError {
  constructor(message, details = {}) {
    const { currentState, targetState, resourceName, operation = "unknown", retriable, ...rest } = details;
    let description = details.description;
    if (!description) {
      description = `
State Machine Operation Error

Operation: ${operation}
${currentState ? `Current State: ${currentState}` : ""}
${targetState ? `Target State: ${targetState}` : ""}
${resourceName ? `Resource: ${resourceName}` : ""}

Common causes:
1. Invalid state transition
2. State machine not configured
3. Transition conditions not met
4. State not defined in configuration
5. Missing transition handler

Solution:
Check state machine configuration and valid transitions.

Docs: https://github.com/forattini-dev/s3db.js/blob/main/docs/plugins/state-machine.md
`.trim();
    }
    super(message, { ...rest, currentState, targetState, resourceName, operation, description });
    if (retriable !== void 0) {
      this.retriable = retriable;
    }
  }
}

const RETRIABLE = "RETRIABLE";
const NON_RETRIABLE = "NON_RETRIABLE";
const RETRIABLE_NETWORK_CODES = /* @__PURE__ */ new Set([
  "ECONNREFUSED",
  "ETIMEDOUT",
  "ECONNRESET",
  "EPIPE",
  "ENOTFOUND",
  "NetworkError",
  "NETWORK_ERROR",
  "TimeoutError",
  "TIMEOUT"
]);
const RETRIABLE_AWS_CODES = /* @__PURE__ */ new Set([
  "ThrottlingException",
  "TooManyRequestsException",
  "RequestLimitExceeded",
  "ProvisionedThroughputExceededException",
  "RequestThrottledException",
  "SlowDown",
  "ServiceUnavailable"
]);
const RETRIABLE_AWS_CONFLICTS = /* @__PURE__ */ new Set([
  "ConditionalCheckFailedException",
  "TransactionConflictException"
]);
const RETRIABLE_STATUS_CODES = /* @__PURE__ */ new Set([
  429,
  // Too Many Requests
  500,
  // Internal Server Error
  502,
  // Bad Gateway
  503,
  // Service Unavailable
  504,
  // Gateway Timeout
  507,
  // Insufficient Storage
  509
  // Bandwidth Limit Exceeded
]);
const NON_RETRIABLE_ERROR_NAMES = /* @__PURE__ */ new Set([
  "ValidationError",
  "StateMachineError",
  "SchemaError",
  "AuthenticationError",
  "PermissionError",
  "BusinessLogicError",
  "InvalidStateTransition"
]);
const NON_RETRIABLE_STATUS_CODES = /* @__PURE__ */ new Set([
  400,
  // Bad Request
  401,
  // Unauthorized
  403,
  // Forbidden
  404,
  // Not Found
  405,
  // Method Not Allowed
  406,
  // Not Acceptable
  409,
  // Conflict
  410,
  // Gone
  422
  // Unprocessable Entity
]);
class ErrorClassifier {
  /**
   * Classify an error as RETRIABLE or NON_RETRIABLE
   *
   * @param {Error} error - The error to classify
   * @param {Object} options - Classification options
   * @param {Array<string>} options.retryableErrors - Custom retriable error names/codes
   * @param {Array<string>} options.nonRetriableErrors - Custom non-retriable error names/codes
   * @returns {string} 'RETRIABLE' or 'NON_RETRIABLE'
   */
  static classify(error, options = {}) {
    if (!error) return NON_RETRIABLE;
    const {
      retryableErrors = [],
      nonRetriableErrors = []
    } = options;
    if (retryableErrors.length > 0) {
      const isCustomRetriable = retryableErrors.some(
        (errType) => error.code === errType || error.name === errType || error.message?.includes(errType)
      );
      if (isCustomRetriable) return RETRIABLE;
    }
    if (nonRetriableErrors.length > 0) {
      const isCustomNonRetriable = nonRetriableErrors.some(
        (errType) => error.code === errType || error.name === errType || error.message?.includes(errType)
      );
      if (isCustomNonRetriable) return NON_RETRIABLE;
    }
    if (error.retriable === false) return NON_RETRIABLE;
    if (error.retriable === true) return RETRIABLE;
    if (NON_RETRIABLE_ERROR_NAMES.has(error.name)) {
      return NON_RETRIABLE;
    }
    if (error.statusCode && NON_RETRIABLE_STATUS_CODES.has(error.statusCode)) {
      return NON_RETRIABLE;
    }
    if (error.code && RETRIABLE_NETWORK_CODES.has(error.code)) {
      return RETRIABLE;
    }
    if (error.code && RETRIABLE_AWS_CODES.has(error.code)) {
      return RETRIABLE;
    }
    if (error.code && RETRIABLE_AWS_CONFLICTS.has(error.code)) {
      return RETRIABLE;
    }
    if (error.statusCode && RETRIABLE_STATUS_CODES.has(error.statusCode)) {
      return RETRIABLE;
    }
    if (error.message && typeof error.message === "string") {
      const lowerMessage = error.message.toLowerCase();
      if (lowerMessage.includes("timeout") || lowerMessage.includes("timed out") || lowerMessage.includes("network") || lowerMessage.includes("connection")) {
        return RETRIABLE;
      }
    }
    return RETRIABLE;
  }
  /**
   * Check if an error is retriable
   *
   * @param {Error} error - The error to check
   * @param {Object} options - Classification options
   * @returns {boolean} true if retriable
   */
  static isRetriable(error, options = {}) {
    return this.classify(error, options) === RETRIABLE;
  }
  /**
   * Check if an error is non-retriable
   *
   * @param {Error} error - The error to check
   * @param {Object} options - Classification options
   * @returns {boolean} true if non-retriable
   */
  static isNonRetriable(error, options = {}) {
    return this.classify(error, options) === NON_RETRIABLE;
  }
}

class StateMachinePlugin extends Plugin {
  constructor(options = {}) {
    super();
    this.config = {
      stateMachines: options.stateMachines || {},
      actions: options.actions || {},
      guards: options.guards || {},
      persistTransitions: options.persistTransitions !== false,
      transitionLogResource: options.transitionLogResource || "plg_state_transitions",
      stateResource: options.stateResource || "plg_entity_states",
      retryAttempts: options.retryAttempts || 3,
      retryDelay: options.retryDelay || 100,
      verbose: options.verbose || false,
      // Distributed lock configuration (prevents concurrent transitions)
      workerId: options.workerId || "default",
      lockTimeout: options.lockTimeout || 1e3,
      // Wait up to 1s for lock
      lockTTL: options.lockTTL || 5,
      // Lock expires after 5s (prevent deadlock)
      // Global retry configuration for action execution
      retryConfig: options.retryConfig || null,
      // Trigger system configuration
      enableScheduler: options.enableScheduler || false,
      schedulerConfig: options.schedulerConfig || {},
      enableDateTriggers: options.enableDateTriggers !== false,
      enableFunctionTriggers: options.enableFunctionTriggers !== false,
      enableEventTriggers: options.enableEventTriggers !== false,
      triggerCheckInterval: options.triggerCheckInterval || 6e4
      // Check triggers every 60s by default
    };
    this.database = null;
    this.machines = /* @__PURE__ */ new Map();
    this.triggerIntervals = [];
    this.schedulerPlugin = null;
    this._pendingEventHandlers = /* @__PURE__ */ new Set();
    this._validateConfiguration();
  }
  /**
   * Wait for all pending event handlers to complete
   * Useful when working with async events (asyncEvents: true)
   * @param {number} timeout - Maximum time to wait in milliseconds (default: 5000)
   * @returns {Promise<void>}
   */
  async waitForPendingEvents(timeout = 5e3) {
    if (this._pendingEventHandlers.size === 0) {
      return;
    }
    const startTime = Date.now();
    while (this._pendingEventHandlers.size > 0) {
      if (Date.now() - startTime > timeout) {
        throw new StateMachineError(
          `Timeout waiting for ${this._pendingEventHandlers.size} pending event handlers`,
          {
            operation: "waitForPendingEvents",
            pendingCount: this._pendingEventHandlers.size,
            timeout
          }
        );
      }
      if (this._pendingEventHandlers.size > 0) {
        await Promise.race(Array.from(this._pendingEventHandlers));
      }
      await new Promise((resolve) => setImmediate(resolve));
    }
  }
  _validateConfiguration() {
    if (!this.config.stateMachines || Object.keys(this.config.stateMachines).length === 0) {
      throw new StateMachineError("At least one state machine must be defined", {
        operation: "validateConfiguration",
        machineCount: 0,
        suggestion: "Provide at least one state machine in the stateMachines configuration"
      });
    }
    for (const [machineName, machine] of Object.entries(this.config.stateMachines)) {
      if (!machine.states || Object.keys(machine.states).length === 0) {
        throw new StateMachineError(`Machine '${machineName}' must have states defined`, {
          operation: "validateConfiguration",
          machineId: machineName,
          suggestion: "Define at least one state in the states configuration"
        });
      }
      if (!machine.initialState) {
        throw new StateMachineError(`Machine '${machineName}' must have an initialState`, {
          operation: "validateConfiguration",
          machineId: machineName,
          availableStates: Object.keys(machine.states),
          suggestion: "Specify an initialState property matching one of the defined states"
        });
      }
      if (!machine.states[machine.initialState]) {
        throw new StateMachineError(`Initial state '${machine.initialState}' not found in machine '${machineName}'`, {
          operation: "validateConfiguration",
          machineId: machineName,
          initialState: machine.initialState,
          availableStates: Object.keys(machine.states),
          suggestion: "Set initialState to one of the defined states"
        });
      }
    }
  }
  async onInstall() {
    if (this.config.persistTransitions) {
      await this._createStateResources();
    }
    for (const [machineName, machineConfig] of Object.entries(this.config.stateMachines)) {
      this.machines.set(machineName, {
        config: machineConfig,
        currentStates: /* @__PURE__ */ new Map()
        // entityId -> currentState
      });
    }
    await this._attachStateMachinesToResources();
    await this._setupTriggers();
    this.emit("db:plugin:initialized", { machines: Array.from(this.machines.keys()) });
  }
  async _createStateResources() {
    const [logOk] = await tryFn(() => this.database.createResource({
      name: this.config.transitionLogResource,
      attributes: {
        id: "string|required",
        machineId: "string|required",
        entityId: "string|required",
        fromState: "string",
        toState: "string|required",
        event: "string|required",
        context: "json",
        timestamp: "number|required",
        createdAt: "string|required"
      },
      behavior: "body-overflow",
      partitions: {
        byMachine: { fields: { machineId: "string" } },
        byDate: { fields: { createdAt: "string|maxlength:10" } }
      }
    }));
    const [stateOk] = await tryFn(() => this.database.createResource({
      name: this.config.stateResource,
      attributes: {
        id: "string|required",
        machineId: "string|required",
        entityId: "string|required",
        currentState: "string|required",
        context: "json|default:{}",
        lastTransition: "string|default:null",
        triggerCounts: "json|default:{}",
        // Track trigger execution counts
        updatedAt: "string|required"
      },
      behavior: "body-overflow"
    }));
  }
  /**
   * Send an event to trigger a state transition
   */
  async send(machineId, entityId, event, context = {}) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "send",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    const lockName = await this._acquireTransitionLock(machineId, entityId);
    try {
      const currentState = await this.getState(machineId, entityId);
      const stateConfig = machine.config.states[currentState];
      if (!stateConfig || !stateConfig.on || !stateConfig.on[event]) {
        throw new StateMachineError(`Event '${event}' not valid for state '${currentState}' in machine '${machineId}'`, {
          operation: "send",
          machineId,
          entityId,
          event,
          currentState,
          validEvents: stateConfig && stateConfig.on ? Object.keys(stateConfig.on) : [],
          suggestion: "Use getValidEvents() to check which events are valid for the current state"
        });
      }
      const targetState = stateConfig.on[event];
      if (stateConfig.guards && stateConfig.guards[event]) {
        const guardName = stateConfig.guards[event];
        const guard = this.config.guards[guardName];
        if (guard) {
          const [guardOk, guardErr, guardResult] = await tryFn(
            () => guard(context, event, { database: this.database, machineId, entityId })
          );
          if (!guardOk || !guardResult) {
            throw new StateMachineError(`Transition blocked by guard '${guardName}'`, {
              operation: "send",
              machineId,
              entityId,
              event,
              currentState,
              guardName,
              guardError: guardErr?.message || "Guard returned false",
              suggestion: "Check guard conditions or modify the context to satisfy guard requirements"
            });
          }
        }
      }
      if (stateConfig.exit) {
        await this._executeAction(stateConfig.exit, context, event, machineId, entityId);
      }
      await this._transition(machineId, entityId, currentState, targetState, event, context);
      const targetStateConfig = machine.config.states[targetState];
      if (targetStateConfig && targetStateConfig.entry) {
        await this._executeAction(targetStateConfig.entry, context, event, machineId, entityId);
      }
      this.emit("plg:state-machine:transition", {
        machineId,
        entityId,
        from: currentState,
        to: targetState,
        event,
        context
      });
      return {
        from: currentState,
        to: targetState,
        event,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      };
    } finally {
      await this._releaseTransitionLock(lockName);
    }
  }
  async _executeAction(actionName, context, event, machineId, entityId) {
    const action = this.config.actions[actionName];
    if (!action) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Action '${actionName}' not found`);
      }
      return;
    }
    const machine = this.machines.get(machineId);
    const currentState = await this.getState(machineId, entityId);
    const stateConfig = machine?.config?.states?.[currentState];
    const retryConfig = {
      ...this.config.retryConfig || {},
      ...machine?.config?.retryConfig || {},
      ...stateConfig?.retryConfig || {}
    };
    const maxAttempts = retryConfig.maxAttempts ?? 0;
    const retryEnabled = maxAttempts > 0;
    let attempt = 0;
    while (attempt <= maxAttempts) {
      try {
        const result = await action(context, event, { database: this.database, machineId, entityId });
        if (attempt > 0) {
          this.emit("plg:state-machine:action-retry-success", {
            machineId,
            entityId,
            action: actionName,
            attempts: attempt + 1,
            state: currentState
          });
          if (this.config.verbose) {
            console.log(`[StateMachinePlugin] Action '${actionName}' succeeded after ${attempt + 1} attempts`);
          }
        }
        return result;
      } catch (error) {
        if (!retryEnabled) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed:`, error.message);
          }
          this.emit("plg:state-machine:action-error", { actionName, error: error.message, machineId, entityId });
          return;
        }
        const classification = ErrorClassifier.classify(error, {
          retryableErrors: retryConfig.retryableErrors,
          nonRetriableErrors: retryConfig.nonRetriableErrors
        });
        if (classification === "NON_RETRIABLE") {
          this.emit("plg:state-machine:action-error-non-retriable", {
            machineId,
            entityId,
            action: actionName,
            error: error.message,
            state: currentState
          });
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed with non-retriable error:`, error.message);
          }
          throw error;
        }
        if (attempt >= maxAttempts) {
          this.emit("plg:state-machine:action-retry-exhausted", {
            machineId,
            entityId,
            action: actionName,
            attempts: attempt + 1,
            error: error.message,
            state: currentState
          });
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Action '${actionName}' failed after ${attempt + 1} attempts:`, error.message);
          }
          throw error;
        }
        attempt++;
        const delay = this._calculateBackoff(attempt, retryConfig);
        if (retryConfig.onRetry) {
          try {
            await retryConfig.onRetry(attempt, error, context);
          } catch (hookError) {
            if (this.config.verbose) {
              console.warn(`[StateMachinePlugin] onRetry hook failed:`, hookError.message);
            }
          }
        }
        this.emit("plg:state-machine:action-retry-attempt", {
          machineId,
          entityId,
          action: actionName,
          attempt,
          delay,
          error: error.message,
          state: currentState
        });
        if (this.config.verbose) {
          console.warn(`[StateMachinePlugin] Action '${actionName}' failed (attempt ${attempt + 1}/${maxAttempts + 1}), retrying in ${delay}ms:`, error.message);
        }
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }
  async _transition(machineId, entityId, fromState, toState, event, context) {
    const timestamp = Date.now();
    const now = (/* @__PURE__ */ new Date()).toISOString();
    const machine = this.machines.get(machineId);
    machine.currentStates.set(entityId, toState);
    if (this.config.persistTransitions) {
      const transitionId = `${machineId}_${entityId}_${timestamp}`;
      let logOk = false;
      let lastLogErr;
      for (let attempt = 0; attempt < this.config.retryAttempts; attempt++) {
        const [ok, err] = await tryFn(
          () => this.database.resources[this.config.transitionLogResource].insert({
            id: transitionId,
            machineId,
            entityId,
            fromState,
            toState,
            event,
            context,
            timestamp,
            createdAt: now.slice(0, 10)
            // YYYY-MM-DD for partitioning
          })
        );
        if (ok) {
          logOk = true;
          break;
        }
        lastLogErr = err;
        if (attempt < this.config.retryAttempts - 1) {
          const delay = this.config.retryDelay * Math.pow(2, attempt);
          await new Promise((resolve) => setTimeout(resolve, delay));
        }
      }
      if (!logOk && this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to log transition after ${this.config.retryAttempts} attempts:`, lastLogErr.message);
      }
      const stateId = `${machineId}_${entityId}`;
      const stateData = {
        machineId,
        entityId,
        currentState: toState,
        context,
        lastTransition: transitionId,
        updatedAt: now
      };
      const [updateOk] = await tryFn(
        () => this.database.resources[this.config.stateResource].update(stateId, stateData)
      );
      if (!updateOk) {
        const [insertOk, insertErr] = await tryFn(
          () => this.database.resources[this.config.stateResource].insert({ id: stateId, ...stateData })
        );
        if (!insertOk && this.config.verbose) {
          console.warn(`[StateMachinePlugin] Failed to upsert state:`, insertErr.message);
        }
      }
    }
  }
  /**
   * Acquire distributed lock for transition
   * Prevents concurrent transitions for the same entity
   * @private
   */
  async _acquireTransitionLock(machineId, entityId) {
    const storage = this.getStorage();
    const lockName = `transition-${machineId}-${entityId}`;
    const lock = await storage.acquireLock(lockName, {
      ttl: this.config.lockTTL,
      timeout: this.config.lockTimeout,
      workerId: this.config.workerId
    });
    if (!lock) {
      throw new StateMachineError("Could not acquire transition lock - concurrent transition in progress", {
        operation: "send",
        machineId,
        entityId,
        lockTimeout: this.config.lockTimeout,
        workerId: this.config.workerId,
        suggestion: "Wait for current transition to complete or increase lockTimeout"
      });
    }
    return lockName;
  }
  /**
   * Release distributed lock for transition
   * @private
   */
  async _releaseTransitionLock(lockName) {
    const storage = this.getStorage();
    const [ok, err] = await tryFn(() => storage.releaseLock(lockName));
    if (!ok && this.config.verbose) {
      console.warn(`[StateMachinePlugin] Failed to release lock '${lockName}':`, err.message);
    }
  }
  /**
   * Calculate backoff delay for retry attempts
   * @private
   */
  _calculateBackoff(attempt, retryConfig) {
    const {
      backoffStrategy = "exponential",
      baseDelay = 1e3,
      maxDelay = 3e4
    } = retryConfig || {};
    let delay;
    if (backoffStrategy === "exponential") {
      delay = Math.min(baseDelay * Math.pow(2, attempt - 1), maxDelay);
    } else if (backoffStrategy === "linear") {
      delay = Math.min(baseDelay * attempt, maxDelay);
    } else {
      delay = baseDelay;
    }
    const jitter = delay * 0.2 * (Math.random() - 0.5);
    return Math.round(delay + jitter);
  }
  /**
   * Get current state for an entity
   */
  async getState(machineId, entityId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "getState",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    if (machine.currentStates.has(entityId)) {
      return machine.currentStates.get(entityId);
    }
    if (this.config.persistTransitions) {
      const stateId = `${machineId}_${entityId}`;
      const [ok, err, stateRecord] = await tryFn(
        () => this.database.resources[this.config.stateResource].get(stateId)
      );
      if (ok && stateRecord) {
        machine.currentStates.set(entityId, stateRecord.currentState);
        return stateRecord.currentState;
      }
    }
    const initialState = machine.config.initialState;
    machine.currentStates.set(entityId, initialState);
    return initialState;
  }
  /**
   * Get valid events for current state
   * Can accept either a state name (sync) or entityId (async to fetch latest state)
   */
  async getValidEvents(machineId, stateOrEntityId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "getValidEvents",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    let state;
    if (machine.config.states[stateOrEntityId]) {
      state = stateOrEntityId;
    } else {
      state = await this.getState(machineId, stateOrEntityId);
    }
    const stateConfig = machine.config.states[state];
    return stateConfig && stateConfig.on ? Object.keys(stateConfig.on) : [];
  }
  /**
   * Get transition history for an entity
   */
  async getTransitionHistory(machineId, entityId, options = {}) {
    if (!this.config.persistTransitions) {
      return [];
    }
    const { limit = 50, offset = 0 } = options;
    const [ok, err, transitions] = await tryFn(
      () => this.database.resources[this.config.transitionLogResource].query({
        machineId,
        entityId
      }, {
        limit,
        offset
      })
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to get transition history:`, err.message);
      }
      return [];
    }
    const sorted = (transitions || []).sort((a, b) => b.timestamp - a.timestamp);
    return sorted.map((t) => ({
      from: t.fromState,
      to: t.toState,
      event: t.event,
      context: t.context,
      timestamp: new Date(t.timestamp).toISOString()
    }));
  }
  /**
   * Initialize entity state (useful for new entities)
   */
  async initializeEntity(machineId, entityId, context = {}) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "initializeEntity",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    const initialState = machine.config.initialState;
    machine.currentStates.set(entityId, initialState);
    if (this.config.persistTransitions) {
      const now = (/* @__PURE__ */ new Date()).toISOString();
      const stateId = `${machineId}_${entityId}`;
      const [ok, err] = await tryFn(
        () => this.database.resources[this.config.stateResource].insert({
          id: stateId,
          machineId,
          entityId,
          currentState: initialState,
          context,
          lastTransition: null,
          updatedAt: now
        })
      );
      if (!ok && err && !err.message?.includes("already exists")) {
        throw new StateMachineError("Failed to initialize entity state", {
          operation: "initializeEntity",
          machineId,
          entityId,
          initialState,
          original: err,
          suggestion: "Check state resource configuration and database permissions"
        });
      }
    }
    const initialStateConfig = machine.config.states[initialState];
    if (initialStateConfig && initialStateConfig.entry) {
      await this._executeAction(initialStateConfig.entry, context, "INIT", machineId, entityId);
    }
    this.emit("plg:state-machine:entity-initialized", { machineId, entityId, initialState });
    return initialState;
  }
  /**
   * Get machine definition
   */
  getMachineDefinition(machineId) {
    const machine = this.machines.get(machineId);
    return machine ? machine.config : null;
  }
  /**
   * Get all available machines
   */
  getMachines() {
    return Array.from(this.machines.keys());
  }
  /**
   * Visualize state machine (returns DOT format for graphviz)
   */
  visualize(machineId) {
    const machine = this.machines.get(machineId);
    if (!machine) {
      throw new StateMachineError(`State machine '${machineId}' not found`, {
        operation: "visualize",
        machineId,
        availableMachines: Array.from(this.machines.keys()),
        suggestion: "Check machine ID or use getMachines() to list available machines"
      });
    }
    let dot = `digraph ${machineId} {
`;
    dot += `  rankdir=LR;
`;
    dot += `  node [shape=circle];
`;
    for (const [stateName, stateConfig] of Object.entries(machine.config.states)) {
      const shape = stateConfig.type === "final" ? "doublecircle" : "circle";
      const color = stateConfig.meta?.color || "lightblue";
      dot += `  ${stateName} [shape=${shape}, fillcolor=${color}, style=filled];
`;
    }
    for (const [stateName, stateConfig] of Object.entries(machine.config.states)) {
      if (stateConfig.on) {
        for (const [event, targetState] of Object.entries(stateConfig.on)) {
          dot += `  ${stateName} -> ${targetState} [label="${event}"];
`;
        }
      }
    }
    dot += `  start [shape=point];
`;
    dot += `  start -> ${machine.config.initialState};
`;
    dot += `}
`;
    return dot;
  }
  /**
   * Get all entities currently in a specific state
   * @private
   */
  async _getEntitiesInState(machineId, stateName) {
    if (!this.config.persistTransitions) {
      const machine = this.machines.get(machineId);
      if (!machine) return [];
      const entities = [];
      for (const [entityId, currentState] of machine.currentStates) {
        if (currentState === stateName) {
          entities.push({ entityId, currentState, context: {}, triggerCounts: {} });
        }
      }
      return entities;
    }
    const [ok, err, records] = await tryFn(
      () => this.database.resources[this.config.stateResource].query({
        machineId,
        currentState: stateName
      })
    );
    if (!ok) {
      if (this.config.verbose) {
        console.warn(`[StateMachinePlugin] Failed to query entities in state '${stateName}':`, err.message);
      }
      return [];
    }
    return records || [];
  }
  /**
   * Increment trigger execution count for an entity
   * @private
   */
  async _incrementTriggerCount(machineId, entityId, triggerName) {
    if (!this.config.persistTransitions) {
      return;
    }
    const stateId = `${machineId}_${entityId}`;
    const [ok, err, stateRecord] = await tryFn(
      () => this.database.resources[this.config.stateResource].get(stateId)
    );
    if (ok && stateRecord) {
      const triggerCounts = stateRecord.triggerCounts || {};
      triggerCounts[triggerName] = (triggerCounts[triggerName] || 0) + 1;
      await tryFn(
        () => this.database.resources[this.config.stateResource].patch(stateId, { triggerCounts })
      );
    }
  }
  /**
   * Setup trigger system for all state machines
   * @private
   */
  async _setupTriggers() {
    if (!this.config.enableScheduler && !this.config.enableDateTriggers && !this.config.enableFunctionTriggers && !this.config.enableEventTriggers) {
      return;
    }
    const cronJobs = {};
    for (const [machineId, machineData] of this.machines) {
      const machineConfig = machineData.config;
      for (const [stateName, stateConfig] of Object.entries(machineConfig.states)) {
        const triggers = stateConfig.triggers || [];
        for (let i = 0; i < triggers.length; i++) {
          const trigger = triggers[i];
          const triggerName = `${trigger.action}_${i}`;
          if (trigger.type === "cron" && this.config.enableScheduler) {
            const jobName = `${machineId}_${stateName}_${triggerName}`;
            cronJobs[jobName] = await this._createCronJob(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "date" && this.config.enableDateTriggers) {
            await this._setupDateTrigger(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "function" && this.config.enableFunctionTriggers) {
            await this._setupFunctionTrigger(machineId, stateName, trigger, triggerName);
          } else if (trigger.type === "event" && this.config.enableEventTriggers) {
            await this._setupEventTrigger(machineId, stateName, trigger, triggerName);
          }
        }
      }
    }
    if (Object.keys(cronJobs).length > 0 && this.config.enableScheduler) {
      const { SchedulerPlugin } = await Promise.resolve().then(function () { return scheduler_plugin; });
      this.schedulerPlugin = new SchedulerPlugin({
        jobs: cronJobs,
        persistJobs: false,
        // Don't persist trigger jobs
        verbose: this.config.verbose,
        ...this.config.schedulerConfig
      });
      await this.database.usePlugin(this.schedulerPlugin);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Installed SchedulerPlugin with ${Object.keys(cronJobs).length} cron triggers`);
      }
    }
  }
  /**
   * Create a SchedulerPlugin job for a cron trigger
   * @private
   */
  async _createCronJob(machineId, stateName, trigger, triggerName) {
    return {
      schedule: trigger.schedule,
      description: `Trigger '${triggerName}' for ${machineId}.${stateName}`,
      action: async (database, context) => {
        const entities = await this._getEntitiesInState(machineId, stateName);
        let executedCount = 0;
        for (const entity of entities) {
          try {
            if (trigger.condition) {
              const shouldTrigger = await trigger.condition(entity.context, entity.entityId);
              if (!shouldTrigger) continue;
            }
            if (trigger.maxTriggers !== void 0) {
              const triggerCount = entity.triggerCounts?.[triggerName] || 0;
              if (triggerCount >= trigger.maxTriggers) {
                if (trigger.onMaxTriggersReached) {
                  await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
                }
                continue;
              }
            }
            const result = await this._executeAction(
              trigger.action,
              entity.context,
              "TRIGGER",
              machineId,
              entity.entityId
            );
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            executedCount++;
            if (trigger.eventOnSuccess) {
              await this.send(machineId, entity.entityId, trigger.eventOnSuccess, {
                ...entity.context,
                triggerResult: result
              });
            } else if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "cron"
            });
          } catch (error) {
            if (trigger.event) {
              await tryFn(() => this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerError: error.message
              }));
            }
            if (this.config.verbose) {
              console.error(`[StateMachinePlugin] Trigger '${triggerName}' failed for entity ${entity.entityId}:`, error.message);
            }
          }
        }
        return { processed: entities.length, executed: executedCount };
      }
    };
  }
  /**
   * Setup a date-based trigger
   * @private
   */
  async _setupDateTrigger(machineId, stateName, trigger, triggerName) {
    const checkInterval = setInterval(async () => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          const triggerDateValue = entity.context?.[trigger.field];
          if (!triggerDateValue) continue;
          const triggerDate = new Date(triggerDateValue);
          const now = /* @__PURE__ */ new Date();
          if (now >= triggerDate) {
            if (trigger.maxTriggers !== void 0) {
              const triggerCount = entity.triggerCounts?.[triggerName] || 0;
              if (triggerCount >= trigger.maxTriggers) {
                if (trigger.onMaxTriggersReached) {
                  await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
                }
                continue;
              }
            }
            const result = await this._executeAction(trigger.action, entity.context, "TRIGGER", machineId, entity.entityId);
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "date"
            });
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Date trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    }, this.config.triggerCheckInterval);
    this.triggerIntervals.push(checkInterval);
  }
  /**
   * Setup a function-based trigger
   * @private
   */
  async _setupFunctionTrigger(machineId, stateName, trigger, triggerName) {
    const interval = trigger.interval || this.config.triggerCheckInterval;
    const checkInterval = setInterval(async () => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          if (trigger.maxTriggers !== void 0) {
            const triggerCount = entity.triggerCounts?.[triggerName] || 0;
            if (triggerCount >= trigger.maxTriggers) {
              if (trigger.onMaxTriggersReached) {
                await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
              }
              continue;
            }
          }
          const shouldTrigger = await trigger.condition(entity.context, entity.entityId);
          if (shouldTrigger) {
            const result = await this._executeAction(trigger.action, entity.context, "TRIGGER", machineId, entity.entityId);
            await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
            if (trigger.event) {
              await this.send(machineId, entity.entityId, trigger.event, {
                ...entity.context,
                triggerResult: result
              });
            }
            this.emit("plg:state-machine:trigger-executed", {
              machineId,
              entityId: entity.entityId,
              state: stateName,
              trigger: triggerName,
              type: "function"
            });
          }
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Function trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    }, interval);
    this.triggerIntervals.push(checkInterval);
  }
  /**
   * Setup an event-based trigger
   * Supports both old API (trigger.event) and new API (trigger.eventName + eventSource)
   * @private
   */
  async _setupEventTrigger(machineId, stateName, trigger, triggerName) {
    const baseEventName = trigger.eventName || trigger.event;
    const eventSource = trigger.eventSource;
    if (!baseEventName) {
      throw new StateMachineError(`Event trigger '${triggerName}' must have either 'event' or 'eventName' property`, {
        operation: "_setupEventTrigger",
        machineId,
        stateName,
        triggerName
      });
    }
    const eventHandler = async (eventData) => {
      const entities = await this._getEntitiesInState(machineId, stateName);
      for (const entity of entities) {
        try {
          let resolvedEventName;
          if (typeof baseEventName === "function") {
            resolvedEventName = baseEventName(entity.context);
          } else {
            resolvedEventName = baseEventName;
          }
          if (eventSource && typeof baseEventName === "function") {
            const eventIdMatch = eventData?.id || eventData?.entityId;
            if (eventIdMatch && entity.entityId !== eventIdMatch) {
              continue;
            }
          }
          if (trigger.condition) {
            const shouldTrigger = await trigger.condition(entity.context, entity.entityId, eventData);
            if (!shouldTrigger) continue;
          }
          if (trigger.maxTriggers !== void 0) {
            const triggerCount = entity.triggerCounts?.[triggerName] || 0;
            if (triggerCount >= trigger.maxTriggers) {
              if (trigger.onMaxTriggersReached) {
                await this.send(machineId, entity.entityId, trigger.onMaxTriggersReached, entity.context);
              }
              continue;
            }
          }
          if (trigger.targetState) {
            await this._transition(
              machineId,
              entity.entityId,
              stateName,
              trigger.targetState,
              "TRIGGER",
              { ...entity.context, eventData, triggerName }
            );
            const machine = this.machines.get(machineId);
            const resourceConfig = machine.config;
            if (resourceConfig.resource && resourceConfig.stateField) {
              let resource;
              if (typeof resourceConfig.resource === "string") {
                resource = await this.database.getResource(resourceConfig.resource);
              } else {
                resource = resourceConfig.resource;
              }
              if (resource) {
                const [ok] = await tryFn(
                  () => resource.patch(entity.entityId, { [resourceConfig.stateField]: trigger.targetState })
                );
                if (!ok && this.config.verbose) {
                  console.warn(`[StateMachinePlugin] Failed to update resource stateField for entity ${entity.entityId}`);
                }
              }
            }
            const targetStateConfig = machine.config.states[trigger.targetState];
            if (targetStateConfig?.entry) {
              await this._executeAction(
                targetStateConfig.entry,
                { ...entity.context, eventData },
                "TRIGGER",
                machineId,
                entity.entityId
              );
            }
            this.emit("plg:state-machine:transition", {
              machineId,
              entityId: entity.entityId,
              from: stateName,
              to: trigger.targetState,
              event: "TRIGGER",
              context: { ...entity.context, eventData, triggerName }
            });
          } else if (trigger.action) {
            const result = await this._executeAction(
              trigger.action,
              { ...entity.context, eventData },
              "TRIGGER",
              machineId,
              entity.entityId
            );
            if (trigger.sendEvent) {
              await this.send(machineId, entity.entityId, trigger.sendEvent, {
                ...entity.context,
                triggerResult: result,
                eventData
              });
            }
          }
          await this._incrementTriggerCount(machineId, entity.entityId, triggerName);
          this.emit("plg:state-machine:trigger-executed", {
            machineId,
            entityId: entity.entityId,
            state: stateName,
            trigger: triggerName,
            type: "event",
            eventName: resolvedEventName,
            targetState: trigger.targetState
          });
        } catch (error) {
          if (this.config.verbose) {
            console.error(`[StateMachinePlugin] Event trigger '${triggerName}' failed:`, error.message);
          }
        }
      }
    };
    if (eventSource) {
      const baseEvent = typeof baseEventName === "function" ? "updated" : baseEventName;
      const wrappedHandler = async (...args) => {
        const handlerPromise = eventHandler(...args);
        if (!this._pendingEventHandlers) {
          this._pendingEventHandlers = /* @__PURE__ */ new Set();
        }
        this._pendingEventHandlers.add(handlerPromise);
        try {
          await handlerPromise;
        } finally {
          this._pendingEventHandlers.delete(handlerPromise);
        }
      };
      eventSource.on(baseEvent, wrappedHandler);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Listening to resource event '${baseEvent}' from '${eventSource.name}' for trigger '${triggerName}' (async-safe)`);
      }
    } else {
      const staticEventName = typeof baseEventName === "function" ? "updated" : baseEventName;
      if (staticEventName.startsWith("db:")) {
        const dbEventName = staticEventName.substring(3);
        this.database.on(dbEventName, eventHandler);
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Listening to database event '${dbEventName}' for trigger '${triggerName}'`);
        }
      } else {
        this.on(staticEventName, eventHandler);
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Listening to plugin event '${staticEventName}' for trigger '${triggerName}'`);
        }
      }
    }
  }
  /**
   * Attach state machine instances to their associated resources
   * This enables the resource API: resource.state(id, event)
   * @private
   */
  async _attachStateMachinesToResources() {
    for (const [machineName, machineConfig] of Object.entries(this.config.stateMachines)) {
      const resourceConfig = machineConfig.config || machineConfig;
      if (!resourceConfig.resource) {
        if (this.config.verbose) {
          console.log(`[StateMachinePlugin] Machine '${machineName}' has no resource configured, skipping attachment`);
        }
        continue;
      }
      let resource;
      if (typeof resourceConfig.resource === "string") {
        resource = this.database.resources[resourceConfig.resource];
        if (!resource) {
          console.warn(
            `[StateMachinePlugin] Resource '${resourceConfig.resource}' not found for machine '${machineName}'. Resource API will not be available.`
          );
          continue;
        }
      } else {
        resource = resourceConfig.resource;
      }
      const machineProxy = {
        send: async (id, event, eventData) => {
          return this.send(machineName, id, event, eventData);
        },
        getState: async (id) => {
          return this.getState(machineName, id);
        },
        canTransition: async (id, event) => {
          return this.canTransition(machineName, id, event);
        },
        getValidEvents: async (id) => {
          return this.getValidEvents(machineName, id);
        },
        initializeEntity: async (id, context) => {
          return this.initializeEntity(machineName, id, context);
        },
        getTransitionHistory: async (id, options) => {
          return this.getTransitionHistory(machineName, id, options);
        }
      };
      resource._attachStateMachine(machineProxy);
      if (this.config.verbose) {
        console.log(`[StateMachinePlugin] Attached machine '${machineName}' to resource '${resource.name}'`);
      }
    }
  }
  async start() {
    if (this.config.verbose) {
      console.log(`[StateMachinePlugin] Started with ${this.machines.size} state machines`);
    }
  }
  async stop() {
    for (const interval of this.triggerIntervals) {
      clearInterval(interval);
    }
    this.triggerIntervals = [];
    if (this.schedulerPlugin) {
      await this.schedulerPlugin.stop();
      this.schedulerPlugin = null;
    }
    this.machines.clear();
    this.removeAllListeners();
  }
}

class TfStateError extends Error {
  constructor(message, context = {}) {
    super(message);
    this.name = "TfStateError";
    this.context = context;
    Error.captureStackTrace(this, this.constructor);
  }
}
class InvalidStateFileError extends TfStateError {
  constructor(filePath, reason, context = {}) {
    super(`Invalid Tfstate file "${filePath}": ${reason}`, context);
    this.name = "InvalidStateFileError";
    this.filePath = filePath;
    this.reason = reason;
  }
}
class UnsupportedStateVersionError extends TfStateError {
  constructor(version, supportedVersions, context = {}) {
    super(
      `Tfstate version ${version} is not supported. Supported versions: ${supportedVersions.join(", ")}`,
      context
    );
    this.name = "UnsupportedStateVersionError";
    this.version = version;
    this.supportedVersions = supportedVersions;
  }
}
class StateFileNotFoundError extends TfStateError {
  constructor(filePath, context = {}) {
    super(`Tfstate file not found: ${filePath}`, context);
    this.name = "StateFileNotFoundError";
    this.filePath = filePath;
  }
}
class ResourceExtractionError extends TfStateError {
  constructor(resourceAddress, originalError, context = {}) {
    super(
      `Failed to extract resource "${resourceAddress}": ${originalError.message}`,
      context
    );
    this.name = "ResourceExtractionError";
    this.resourceAddress = resourceAddress;
    this.originalError = originalError;
  }
}
class StateDiffError extends TfStateError {
  constructor(oldSerial, newSerial, originalError, context = {}) {
    super(
      `Failed to calculate diff between state serials ${oldSerial} and ${newSerial}: ${originalError.message}`,
      context
    );
    this.name = "StateDiffError";
    this.oldSerial = oldSerial;
    this.newSerial = newSerial;
    this.originalError = originalError;
  }
}
class FileWatchError extends TfStateError {
  constructor(path, originalError, context = {}) {
    super(`Failed to watch path "${path}": ${originalError.message}`, context);
    this.name = "FileWatchError";
    this.path = path;
    this.originalError = originalError;
  }
}

class TfStateDriver {
  constructor(config = {}) {
    this.config = config;
    this.selector = config.selector || "**/*.tfstate";
  }
  /**
   * Initialize the driver
   * Called during plugin installation
   */
  async initialize() {
    throw new Error("Driver must implement initialize()");
  }
  /**
   * List all state files matching the selector
   * @returns {Promise<Array>} Array of state file metadata { path, lastModified, size }
   */
  async listStateFiles() {
    throw new Error("Driver must implement listStateFiles()");
  }
  /**
   * Read a state file content
   * @param {string} path - Path to the state file
   * @returns {Promise<Object>} Parsed state file content
   */
  async readStateFile(path) {
    throw new Error("Driver must implement readStateFile()");
  }
  /**
   * Get state file metadata
   * @param {string} path - Path to the state file
   * @returns {Promise<Object>} Metadata { path, lastModified, size, etag }
   */
  async getStateFileMetadata(path) {
    throw new Error("Driver must implement getStateFileMetadata()");
  }
  /**
   * Check if a state file has been modified since last check
   * @param {string} path - Path to the state file
   * @param {Date} since - Check modifications since this date
   * @returns {Promise<boolean>} True if modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    return new Date(metadata.lastModified) > new Date(since);
  }
  /**
   * Match a path against the selector pattern
   * @param {string} path - Path to check
   * @returns {boolean} True if matches
   */
  matchesSelector(path) {
    const pattern = this.selector.replace(/\*\*/g, "__DOUBLE_STAR__").replace(/\*/g, "[^/]*").replace(/__DOUBLE_STAR__/g, ".*").replace(/\?/g, ".").replace(/\[([^\]]+)\]/g, "[$1]");
    const regex = new RegExp(`^${pattern}$`);
    return regex.test(path);
  }
  /**
   * Close/cleanup driver resources
   */
  async close() {
  }
}

class S3TfStateDriver extends TfStateDriver {
  constructor(config = {}) {
    super(config);
    if (config.connectionString) {
      this.connectionConfig = this._parseConnectionString(config.connectionString);
    } else {
      this.connectionConfig = {
        bucket: config.bucket,
        prefix: config.prefix || "",
        credentials: config.credentials,
        region: config.region
      };
    }
    this.client = null;
  }
  /**
   * Parse S3 connection string
   * Format: s3://accessKey:secretKey@bucket/prefix
   * @private
   */
  _parseConnectionString(connectionString) {
    try {
      const url = new URL(connectionString);
      if (url.protocol !== "s3:") {
        throw new Error("Connection string must use s3:// protocol");
      }
      const credentials = {};
      if (url.username) {
        credentials.accessKeyId = decodeURIComponent(url.username);
      }
      if (url.password) {
        credentials.secretAccessKey = decodeURIComponent(url.password);
      }
      const bucket = url.hostname;
      const prefix = url.pathname ? url.pathname.substring(1) : "";
      const region = url.searchParams.get("region") || "us-east-1";
      return {
        bucket,
        prefix,
        credentials: Object.keys(credentials).length > 0 ? credentials : void 0,
        region
      };
    } catch (error) {
      throw new Error(`Invalid S3 connection string: ${error.message}`);
    }
  }
  /**
   * Initialize S3 client
   */
  async initialize() {
    const { bucket, credentials, region } = this.connectionConfig;
    this.client = new S3Client({
      bucketName: bucket,
      credentials,
      region
    });
    await this.client.connect();
  }
  /**
   * List all state files in S3 matching the selector
   */
  async listStateFiles() {
    const { bucket, prefix } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.listObjectsV2({
        Bucket: bucket,
        Prefix: prefix
      });
    });
    if (!ok) {
      throw new Error(`Failed to list S3 objects: ${err.message}`);
    }
    const objects = data.Contents || [];
    const stateFiles = objects.filter((obj) => {
      const relativePath = obj.Key.startsWith(prefix) ? obj.Key.substring(prefix.length) : obj.Key;
      return this.matchesSelector(relativePath) && relativePath.endsWith(".tfstate");
    }).map((obj) => ({
      path: obj.Key,
      lastModified: obj.LastModified,
      size: obj.Size,
      etag: obj.ETag
    }));
    return stateFiles;
  }
  /**
   * Read a state file from S3
   */
  async readStateFile(path) {
    const { bucket } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.getObject({
        Bucket: bucket,
        Key: path
      });
    });
    if (!ok) {
      throw new Error(`Failed to read state file ${path}: ${err.message}`);
    }
    try {
      const content = data.Body.toString("utf-8");
      return JSON.parse(content);
    } catch (parseError) {
      throw new Error(`Failed to parse state file ${path}: ${parseError.message}`);
    }
  }
  /**
   * Get state file metadata from S3
   */
  async getStateFileMetadata(path) {
    const { bucket } = this.connectionConfig;
    const [ok, err, data] = await tryFn(async () => {
      return await this.client.headObject({
        Bucket: bucket,
        Key: path
      });
    });
    if (!ok) {
      throw new Error(`Failed to get metadata for ${path}: ${err.message}`);
    }
    return {
      path,
      lastModified: data.LastModified,
      size: data.ContentLength,
      etag: data.ETag
    };
  }
  /**
   * Check if state file has been modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    const lastModified = new Date(metadata.lastModified);
    const sinceDate = new Date(since);
    return lastModified > sinceDate;
  }
  /**
   * Close S3 client
   */
  async close() {
    if (this.client) {
      await this.client.disconnect();
      this.client = null;
    }
  }
}

const balanced = (a, b, str) => {
    const ma = a instanceof RegExp ? maybeMatch(a, str) : a;
    const mb = b instanceof RegExp ? maybeMatch(b, str) : b;
    const r = ma !== null && mb != null && range(ma, mb, str);
    return (r && {
        start: r[0],
        end: r[1],
        pre: str.slice(0, r[0]),
        body: str.slice(r[0] + ma.length, r[1]),
        post: str.slice(r[1] + mb.length),
    });
};
const maybeMatch = (reg, str) => {
    const m = str.match(reg);
    return m ? m[0] : null;
};
const range = (a, b, str) => {
    let begs, beg, left, right = undefined, result;
    let ai = str.indexOf(a);
    let bi = str.indexOf(b, ai + 1);
    let i = ai;
    if (ai >= 0 && bi > 0) {
        if (a === b) {
            return [ai, bi];
        }
        begs = [];
        left = str.length;
        while (i >= 0 && !result) {
            if (i === ai) {
                begs.push(i);
                ai = str.indexOf(a, i + 1);
            }
            else if (begs.length === 1) {
                const r = begs.pop();
                if (r !== undefined)
                    result = [r, bi];
            }
            else {
                beg = begs.pop();
                if (beg !== undefined && beg < left) {
                    left = beg;
                    right = bi;
                }
                bi = str.indexOf(b, i + 1);
            }
            i = ai < bi && ai >= 0 ? ai : bi;
        }
        if (begs.length && right !== undefined) {
            result = [left, right];
        }
    }
    return result;
};

const escSlash = '\0SLASH' + Math.random() + '\0';
const escOpen = '\0OPEN' + Math.random() + '\0';
const escClose = '\0CLOSE' + Math.random() + '\0';
const escComma = '\0COMMA' + Math.random() + '\0';
const escPeriod = '\0PERIOD' + Math.random() + '\0';
const escSlashPattern = new RegExp(escSlash, 'g');
const escOpenPattern = new RegExp(escOpen, 'g');
const escClosePattern = new RegExp(escClose, 'g');
const escCommaPattern = new RegExp(escComma, 'g');
const escPeriodPattern = new RegExp(escPeriod, 'g');
const slashPattern = /\\\\/g;
const openPattern = /\\{/g;
const closePattern = /\\}/g;
const commaPattern = /\\,/g;
const periodPattern = /\\./g;
function numeric(str) {
    return !isNaN(str) ? parseInt(str, 10) : str.charCodeAt(0);
}
function escapeBraces(str) {
    return str
        .replace(slashPattern, escSlash)
        .replace(openPattern, escOpen)
        .replace(closePattern, escClose)
        .replace(commaPattern, escComma)
        .replace(periodPattern, escPeriod);
}
function unescapeBraces(str) {
    return str
        .replace(escSlashPattern, '\\')
        .replace(escOpenPattern, '{')
        .replace(escClosePattern, '}')
        .replace(escCommaPattern, ',')
        .replace(escPeriodPattern, '.');
}
/**
 * Basically just str.split(","), but handling cases
 * where we have nested braced sections, which should be
 * treated as individual members, like {a,{b,c},d}
 */
function parseCommaParts(str) {
    if (!str) {
        return [''];
    }
    const parts = [];
    const m = balanced('{', '}', str);
    if (!m) {
        return str.split(',');
    }
    const { pre, body, post } = m;
    const p = pre.split(',');
    p[p.length - 1] += '{' + body + '}';
    const postParts = parseCommaParts(post);
    if (post.length) {
        p[p.length - 1] += postParts.shift();
        p.push.apply(p, postParts);
    }
    parts.push.apply(parts, p);
    return parts;
}
function expand(str) {
    if (!str) {
        return [];
    }
    // I don't know why Bash 4.3 does this, but it does.
    // Anything starting with {} will have the first two bytes preserved
    // but *only* at the top level, so {},a}b will not expand to anything,
    // but a{},b}c will be expanded to [a}c,abc].
    // One could argue that this is a bug in Bash, but since the goal of
    // this module is to match Bash's rules, we escape a leading {}
    if (str.slice(0, 2) === '{}') {
        str = '\\{\\}' + str.slice(2);
    }
    return expand_(escapeBraces(str), true).map(unescapeBraces);
}
function embrace(str) {
    return '{' + str + '}';
}
function isPadded(el) {
    return /^-?0\d/.test(el);
}
function lte(i, y) {
    return i <= y;
}
function gte(i, y) {
    return i >= y;
}
function expand_(str, isTop) {
    /** @type {string[]} */
    const expansions = [];
    const m = balanced('{', '}', str);
    if (!m)
        return [str];
    // no need to expand pre, since it is guaranteed to be free of brace-sets
    const pre = m.pre;
    const post = m.post.length ? expand_(m.post, false) : [''];
    if (/\$$/.test(m.pre)) {
        for (let k = 0; k < post.length; k++) {
            const expansion = pre + '{' + m.body + '}' + post[k];
            expansions.push(expansion);
        }
    }
    else {
        const isNumericSequence = /^-?\d+\.\.-?\d+(?:\.\.-?\d+)?$/.test(m.body);
        const isAlphaSequence = /^[a-zA-Z]\.\.[a-zA-Z](?:\.\.-?\d+)?$/.test(m.body);
        const isSequence = isNumericSequence || isAlphaSequence;
        const isOptions = m.body.indexOf(',') >= 0;
        if (!isSequence && !isOptions) {
            // {a},b}
            if (m.post.match(/,(?!,).*\}/)) {
                str = m.pre + '{' + m.body + escClose + m.post;
                return expand_(str);
            }
            return [str];
        }
        let n;
        if (isSequence) {
            n = m.body.split(/\.\./);
        }
        else {
            n = parseCommaParts(m.body);
            if (n.length === 1 && n[0] !== undefined) {
                // x{{a,b}}y ==> x{a}y x{b}y
                n = expand_(n[0], false).map(embrace);
                //XXX is this necessary? Can't seem to hit it in tests.
                /* c8 ignore start */
                if (n.length === 1) {
                    return post.map(p => m.pre + n[0] + p);
                }
                /* c8 ignore stop */
            }
        }
        // at this point, n is the parts, and we know it's not a comma set
        // with a single entry.
        let N;
        if (isSequence && n[0] !== undefined && n[1] !== undefined) {
            const x = numeric(n[0]);
            const y = numeric(n[1]);
            const width = Math.max(n[0].length, n[1].length);
            let incr = n.length === 3 && n[2] !== undefined ? Math.abs(numeric(n[2])) : 1;
            let test = lte;
            const reverse = y < x;
            if (reverse) {
                incr *= -1;
                test = gte;
            }
            const pad = n.some(isPadded);
            N = [];
            for (let i = x; test(i, y); i += incr) {
                let c;
                if (isAlphaSequence) {
                    c = String.fromCharCode(i);
                    if (c === '\\') {
                        c = '';
                    }
                }
                else {
                    c = String(i);
                    if (pad) {
                        const need = width - c.length;
                        if (need > 0) {
                            const z = new Array(need + 1).join('0');
                            if (i < 0) {
                                c = '-' + z + c.slice(1);
                            }
                            else {
                                c = z + c;
                            }
                        }
                    }
                }
                N.push(c);
            }
        }
        else {
            N = [];
            for (let j = 0; j < n.length; j++) {
                N.push.apply(N, expand_(n[j], false));
            }
        }
        for (let j = 0; j < N.length; j++) {
            for (let k = 0; k < post.length; k++) {
                const expansion = pre + N[j] + post[k];
                if (!isTop || isSequence || expansion) {
                    expansions.push(expansion);
                }
            }
        }
    }
    return expansions;
}

const MAX_PATTERN_LENGTH = 1024 * 64;
const assertValidPattern = (pattern) => {
    if (typeof pattern !== 'string') {
        throw new TypeError('invalid pattern');
    }
    if (pattern.length > MAX_PATTERN_LENGTH) {
        throw new TypeError('pattern is too long');
    }
};

// translate the various posix character classes into unicode properties
// this works across all unicode locales
// { <posix class>: [<translation>, /u flag required, negated]
const posixClasses = {
    '[:alnum:]': ['\\p{L}\\p{Nl}\\p{Nd}', true],
    '[:alpha:]': ['\\p{L}\\p{Nl}', true],
    '[:ascii:]': ['\\x' + '00-\\x' + '7f', false],
    '[:blank:]': ['\\p{Zs}\\t', true],
    '[:cntrl:]': ['\\p{Cc}', true],
    '[:digit:]': ['\\p{Nd}', true],
    '[:graph:]': ['\\p{Z}\\p{C}', true, true],
    '[:lower:]': ['\\p{Ll}', true],
    '[:print:]': ['\\p{C}', true],
    '[:punct:]': ['\\p{P}', true],
    '[:space:]': ['\\p{Z}\\t\\r\\n\\v\\f', true],
    '[:upper:]': ['\\p{Lu}', true],
    '[:word:]': ['\\p{L}\\p{Nl}\\p{Nd}\\p{Pc}', true],
    '[:xdigit:]': ['A-Fa-f0-9', false],
};
// only need to escape a few things inside of brace expressions
// escapes: [ \ ] -
const braceEscape = (s) => s.replace(/[[\]\\-]/g, '\\$&');
// escape all regexp magic characters
const regexpEscape = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
// everything has already been escaped, we just have to join
const rangesToString = (ranges) => ranges.join('');
// takes a glob string at a posix brace expression, and returns
// an equivalent regular expression source, and boolean indicating
// whether the /u flag needs to be applied, and the number of chars
// consumed to parse the character class.
// This also removes out of order ranges, and returns ($.) if the
// entire class just no good.
const parseClass = (glob, position) => {
    const pos = position;
    /* c8 ignore start */
    if (glob.charAt(pos) !== '[') {
        throw new Error('not in a brace expression');
    }
    /* c8 ignore stop */
    const ranges = [];
    const negs = [];
    let i = pos + 1;
    let sawStart = false;
    let uflag = false;
    let escaping = false;
    let negate = false;
    let endPos = pos;
    let rangeStart = '';
    WHILE: while (i < glob.length) {
        const c = glob.charAt(i);
        if ((c === '!' || c === '^') && i === pos + 1) {
            negate = true;
            i++;
            continue;
        }
        if (c === ']' && sawStart && !escaping) {
            endPos = i + 1;
            break;
        }
        sawStart = true;
        if (c === '\\') {
            if (!escaping) {
                escaping = true;
                i++;
                continue;
            }
            // escaped \ char, fall through and treat like normal char
        }
        if (c === '[' && !escaping) {
            // either a posix class, a collation equivalent, or just a [
            for (const [cls, [unip, u, neg]] of Object.entries(posixClasses)) {
                if (glob.startsWith(cls, i)) {
                    // invalid, [a-[] is fine, but not [a-[:alpha]]
                    if (rangeStart) {
                        return ['$.', false, glob.length - pos, true];
                    }
                    i += cls.length;
                    if (neg)
                        negs.push(unip);
                    else
                        ranges.push(unip);
                    uflag = uflag || u;
                    continue WHILE;
                }
            }
        }
        // now it's just a normal character, effectively
        escaping = false;
        if (rangeStart) {
            // throw this range away if it's not valid, but others
            // can still match.
            if (c > rangeStart) {
                ranges.push(braceEscape(rangeStart) + '-' + braceEscape(c));
            }
            else if (c === rangeStart) {
                ranges.push(braceEscape(c));
            }
            rangeStart = '';
            i++;
            continue;
        }
        // now might be the start of a range.
        // can be either c-d or c-] or c<more...>] or c] at this point
        if (glob.startsWith('-]', i + 1)) {
            ranges.push(braceEscape(c + '-'));
            i += 2;
            continue;
        }
        if (glob.startsWith('-', i + 1)) {
            rangeStart = c;
            i += 2;
            continue;
        }
        // not the start of a range, just a single character
        ranges.push(braceEscape(c));
        i++;
    }
    if (endPos < i) {
        // didn't see the end of the class, not a valid class,
        // but might still be valid as a literal match.
        return ['', false, 0, false];
    }
    // if we got no ranges and no negates, then we have a range that
    // cannot possibly match anything, and that poisons the whole glob
    if (!ranges.length && !negs.length) {
        return ['$.', false, glob.length - pos, true];
    }
    // if we got one positive range, and it's a single character, then that's
    // not actually a magic pattern, it's just that one literal character.
    // we should not treat that as "magic", we should just return the literal
    // character. [_] is a perfectly valid way to escape glob magic chars.
    if (negs.length === 0 &&
        ranges.length === 1 &&
        /^\\?.$/.test(ranges[0]) &&
        !negate) {
        const r = ranges[0].length === 2 ? ranges[0].slice(-1) : ranges[0];
        return [regexpEscape(r), false, endPos - pos, false];
    }
    const sranges = '[' + (negate ? '^' : '') + rangesToString(ranges) + ']';
    const snegs = '[' + (negate ? '' : '^') + rangesToString(negs) + ']';
    const comb = ranges.length && negs.length
        ? '(' + sranges + '|' + snegs + ')'
        : ranges.length
            ? sranges
            : snegs;
    return [comb, uflag, endPos - pos, true];
};

/**
 * Un-escape a string that has been escaped with {@link escape}.
 *
 * If the {@link windowsPathsNoEscape} option is used, then square-brace
 * escapes are removed, but not backslash escapes.  For example, it will turn
 * the string `'[*]'` into `*`, but it will not turn `'\\*'` into `'*'`,
 * becuase `\` is a path separator in `windowsPathsNoEscape` mode.
 *
 * When `windowsPathsNoEscape` is not set, then both brace escapes and
 * backslash escapes are removed.
 *
 * Slashes (and backslashes in `windowsPathsNoEscape` mode) cannot be escaped
 * or unescaped.
 */
const unescape = (s, { windowsPathsNoEscape = false, } = {}) => {
    return windowsPathsNoEscape
        ? s.replace(/\[([^\/\\])\]/g, '$1')
        : s.replace(/((?!\\).|^)\[([^\/\\])\]/g, '$1$2').replace(/\\([^\/])/g, '$1');
};

// parse a single path portion
const types = new Set(['!', '?', '+', '*', '@']);
const isExtglobType = (c) => types.has(c);
// Patterns that get prepended to bind to the start of either the
// entire string, or just a single path portion, to prevent dots
// and/or traversal patterns, when needed.
// Exts don't need the ^ or / bit, because the root binds that already.
const startNoTraversal = '(?!(?:^|/)\\.\\.?(?:$|/))';
const startNoDot = '(?!\\.)';
// characters that indicate a start of pattern needs the "no dots" bit,
// because a dot *might* be matched. ( is not in the list, because in
// the case of a child extglob, it will handle the prevention itself.
const addPatternStart = new Set(['[', '.']);
// cases where traversal is A-OK, no dot prevention needed
const justDots = new Set(['..', '.']);
const reSpecials = new Set('().*{}+?[]^$\\!');
const regExpEscape$1 = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
// any single thing other than /
const qmark$1 = '[^/]';
// * => any number of characters
const star$1 = qmark$1 + '*?';
// use + when we need to ensure that *something* matches, because the * is
// the only thing in the path portion.
const starNoEmpty = qmark$1 + '+?';
// remove the \ chars that we added if we end up doing a nonmagic compare
// const deslash = (s: string) => s.replace(/\\(.)/g, '$1')
class AST {
    type;
    #root;
    #hasMagic;
    #uflag = false;
    #parts = [];
    #parent;
    #parentIndex;
    #negs;
    #filledNegs = false;
    #options;
    #toString;
    // set to true if it's an extglob with no children
    // (which really means one child of '')
    #emptyExt = false;
    constructor(type, parent, options = {}) {
        this.type = type;
        // extglobs are inherently magical
        if (type)
            this.#hasMagic = true;
        this.#parent = parent;
        this.#root = this.#parent ? this.#parent.#root : this;
        this.#options = this.#root === this ? options : this.#root.#options;
        this.#negs = this.#root === this ? [] : this.#root.#negs;
        if (type === '!' && !this.#root.#filledNegs)
            this.#negs.push(this);
        this.#parentIndex = this.#parent ? this.#parent.#parts.length : 0;
    }
    get hasMagic() {
        /* c8 ignore start */
        if (this.#hasMagic !== undefined)
            return this.#hasMagic;
        /* c8 ignore stop */
        for (const p of this.#parts) {
            if (typeof p === 'string')
                continue;
            if (p.type || p.hasMagic)
                return (this.#hasMagic = true);
        }
        // note: will be undefined until we generate the regexp src and find out
        return this.#hasMagic;
    }
    // reconstructs the pattern
    toString() {
        if (this.#toString !== undefined)
            return this.#toString;
        if (!this.type) {
            return (this.#toString = this.#parts.map(p => String(p)).join(''));
        }
        else {
            return (this.#toString =
                this.type + '(' + this.#parts.map(p => String(p)).join('|') + ')');
        }
    }
    #fillNegs() {
        /* c8 ignore start */
        if (this !== this.#root)
            throw new Error('should only call on root');
        if (this.#filledNegs)
            return this;
        /* c8 ignore stop */
        // call toString() once to fill this out
        this.toString();
        this.#filledNegs = true;
        let n;
        while ((n = this.#negs.pop())) {
            if (n.type !== '!')
                continue;
            // walk up the tree, appending everthing that comes AFTER parentIndex
            let p = n;
            let pp = p.#parent;
            while (pp) {
                for (let i = p.#parentIndex + 1; !pp.type && i < pp.#parts.length; i++) {
                    for (const part of n.#parts) {
                        /* c8 ignore start */
                        if (typeof part === 'string') {
                            throw new Error('string part in extglob AST??');
                        }
                        /* c8 ignore stop */
                        part.copyIn(pp.#parts[i]);
                    }
                }
                p = pp;
                pp = p.#parent;
            }
        }
        return this;
    }
    push(...parts) {
        for (const p of parts) {
            if (p === '')
                continue;
            /* c8 ignore start */
            if (typeof p !== 'string' && !(p instanceof AST && p.#parent === this)) {
                throw new Error('invalid part: ' + p);
            }
            /* c8 ignore stop */
            this.#parts.push(p);
        }
    }
    toJSON() {
        const ret = this.type === null
            ? this.#parts.slice().map(p => (typeof p === 'string' ? p : p.toJSON()))
            : [this.type, ...this.#parts.map(p => p.toJSON())];
        if (this.isStart() && !this.type)
            ret.unshift([]);
        if (this.isEnd() &&
            (this === this.#root ||
                (this.#root.#filledNegs && this.#parent?.type === '!'))) {
            ret.push({});
        }
        return ret;
    }
    isStart() {
        if (this.#root === this)
            return true;
        // if (this.type) return !!this.#parent?.isStart()
        if (!this.#parent?.isStart())
            return false;
        if (this.#parentIndex === 0)
            return true;
        // if everything AHEAD of this is a negation, then it's still the "start"
        const p = this.#parent;
        for (let i = 0; i < this.#parentIndex; i++) {
            const pp = p.#parts[i];
            if (!(pp instanceof AST && pp.type === '!')) {
                return false;
            }
        }
        return true;
    }
    isEnd() {
        if (this.#root === this)
            return true;
        if (this.#parent?.type === '!')
            return true;
        if (!this.#parent?.isEnd())
            return false;
        if (!this.type)
            return this.#parent?.isEnd();
        // if not root, it'll always have a parent
        /* c8 ignore start */
        const pl = this.#parent ? this.#parent.#parts.length : 0;
        /* c8 ignore stop */
        return this.#parentIndex === pl - 1;
    }
    copyIn(part) {
        if (typeof part === 'string')
            this.push(part);
        else
            this.push(part.clone(this));
    }
    clone(parent) {
        const c = new AST(this.type, parent);
        for (const p of this.#parts) {
            c.copyIn(p);
        }
        return c;
    }
    static #parseAST(str, ast, pos, opt) {
        let escaping = false;
        let inBrace = false;
        let braceStart = -1;
        let braceNeg = false;
        if (ast.type === null) {
            // outside of a extglob, append until we find a start
            let i = pos;
            let acc = '';
            while (i < str.length) {
                const c = str.charAt(i++);
                // still accumulate escapes at this point, but we do ignore
                // starts that are escaped
                if (escaping || c === '\\') {
                    escaping = !escaping;
                    acc += c;
                    continue;
                }
                if (inBrace) {
                    if (i === braceStart + 1) {
                        if (c === '^' || c === '!') {
                            braceNeg = true;
                        }
                    }
                    else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
                        inBrace = false;
                    }
                    acc += c;
                    continue;
                }
                else if (c === '[') {
                    inBrace = true;
                    braceStart = i;
                    braceNeg = false;
                    acc += c;
                    continue;
                }
                if (!opt.noext && isExtglobType(c) && str.charAt(i) === '(') {
                    ast.push(acc);
                    acc = '';
                    const ext = new AST(c, ast);
                    i = AST.#parseAST(str, ext, i, opt);
                    ast.push(ext);
                    continue;
                }
                acc += c;
            }
            ast.push(acc);
            return i;
        }
        // some kind of extglob, pos is at the (
        // find the next | or )
        let i = pos + 1;
        let part = new AST(null, ast);
        const parts = [];
        let acc = '';
        while (i < str.length) {
            const c = str.charAt(i++);
            // still accumulate escapes at this point, but we do ignore
            // starts that are escaped
            if (escaping || c === '\\') {
                escaping = !escaping;
                acc += c;
                continue;
            }
            if (inBrace) {
                if (i === braceStart + 1) {
                    if (c === '^' || c === '!') {
                        braceNeg = true;
                    }
                }
                else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
                    inBrace = false;
                }
                acc += c;
                continue;
            }
            else if (c === '[') {
                inBrace = true;
                braceStart = i;
                braceNeg = false;
                acc += c;
                continue;
            }
            if (isExtglobType(c) && str.charAt(i) === '(') {
                part.push(acc);
                acc = '';
                const ext = new AST(c, part);
                part.push(ext);
                i = AST.#parseAST(str, ext, i, opt);
                continue;
            }
            if (c === '|') {
                part.push(acc);
                acc = '';
                parts.push(part);
                part = new AST(null, ast);
                continue;
            }
            if (c === ')') {
                if (acc === '' && ast.#parts.length === 0) {
                    ast.#emptyExt = true;
                }
                part.push(acc);
                acc = '';
                ast.push(...parts, part);
                return i;
            }
            acc += c;
        }
        // unfinished extglob
        // if we got here, it was a malformed extglob! not an extglob, but
        // maybe something else in there.
        ast.type = null;
        ast.#hasMagic = undefined;
        ast.#parts = [str.substring(pos - 1)];
        return i;
    }
    static fromGlob(pattern, options = {}) {
        const ast = new AST(null, undefined, options);
        AST.#parseAST(pattern, ast, 0, options);
        return ast;
    }
    // returns the regular expression if there's magic, or the unescaped
    // string if not.
    toMMPattern() {
        // should only be called on root
        /* c8 ignore start */
        if (this !== this.#root)
            return this.#root.toMMPattern();
        /* c8 ignore stop */
        const glob = this.toString();
        const [re, body, hasMagic, uflag] = this.toRegExpSource();
        // if we're in nocase mode, and not nocaseMagicOnly, then we do
        // still need a regular expression if we have to case-insensitively
        // match capital/lowercase characters.
        const anyMagic = hasMagic ||
            this.#hasMagic ||
            (this.#options.nocase &&
                !this.#options.nocaseMagicOnly &&
                glob.toUpperCase() !== glob.toLowerCase());
        if (!anyMagic) {
            return body;
        }
        const flags = (this.#options.nocase ? 'i' : '') + (uflag ? 'u' : '');
        return Object.assign(new RegExp(`^${re}$`, flags), {
            _src: re,
            _glob: glob,
        });
    }
    get options() {
        return this.#options;
    }
    // returns the string match, the regexp source, whether there's magic
    // in the regexp (so a regular expression is required) and whether or
    // not the uflag is needed for the regular expression (for posix classes)
    // TODO: instead of injecting the start/end at this point, just return
    // the BODY of the regexp, along with the start/end portions suitable
    // for binding the start/end in either a joined full-path makeRe context
    // (where we bind to (^|/), or a standalone matchPart context (where
    // we bind to ^, and not /).  Otherwise slashes get duped!
    //
    // In part-matching mode, the start is:
    // - if not isStart: nothing
    // - if traversal possible, but not allowed: ^(?!\.\.?$)
    // - if dots allowed or not possible: ^
    // - if dots possible and not allowed: ^(?!\.)
    // end is:
    // - if not isEnd(): nothing
    // - else: $
    //
    // In full-path matching mode, we put the slash at the START of the
    // pattern, so start is:
    // - if first pattern: same as part-matching mode
    // - if not isStart(): nothing
    // - if traversal possible, but not allowed: /(?!\.\.?(?:$|/))
    // - if dots allowed or not possible: /
    // - if dots possible and not allowed: /(?!\.)
    // end is:
    // - if last pattern, same as part-matching mode
    // - else nothing
    //
    // Always put the (?:$|/) on negated tails, though, because that has to be
    // there to bind the end of the negated pattern portion, and it's easier to
    // just stick it in now rather than try to inject it later in the middle of
    // the pattern.
    //
    // We can just always return the same end, and leave it up to the caller
    // to know whether it's going to be used joined or in parts.
    // And, if the start is adjusted slightly, can do the same there:
    // - if not isStart: nothing
    // - if traversal possible, but not allowed: (?:/|^)(?!\.\.?$)
    // - if dots allowed or not possible: (?:/|^)
    // - if dots possible and not allowed: (?:/|^)(?!\.)
    //
    // But it's better to have a simpler binding without a conditional, for
    // performance, so probably better to return both start options.
    //
    // Then the caller just ignores the end if it's not the first pattern,
    // and the start always gets applied.
    //
    // But that's always going to be $ if it's the ending pattern, or nothing,
    // so the caller can just attach $ at the end of the pattern when building.
    //
    // So the todo is:
    // - better detect what kind of start is needed
    // - return both flavors of starting pattern
    // - attach $ at the end of the pattern when creating the actual RegExp
    //
    // Ah, but wait, no, that all only applies to the root when the first pattern
    // is not an extglob. If the first pattern IS an extglob, then we need all
    // that dot prevention biz to live in the extglob portions, because eg
    // +(*|.x*) can match .xy but not .yx.
    //
    // So, return the two flavors if it's #root and the first child is not an
    // AST, otherwise leave it to the child AST to handle it, and there,
    // use the (?:^|/) style of start binding.
    //
    // Even simplified further:
    // - Since the start for a join is eg /(?!\.) and the start for a part
    // is ^(?!\.), we can just prepend (?!\.) to the pattern (either root
    // or start or whatever) and prepend ^ or / at the Regexp construction.
    toRegExpSource(allowDot) {
        const dot = allowDot ?? !!this.#options.dot;
        if (this.#root === this)
            this.#fillNegs();
        if (!this.type) {
            const noEmpty = this.isStart() && this.isEnd();
            const src = this.#parts
                .map(p => {
                const [re, _, hasMagic, uflag] = typeof p === 'string'
                    ? AST.#parseGlob(p, this.#hasMagic, noEmpty)
                    : p.toRegExpSource(allowDot);
                this.#hasMagic = this.#hasMagic || hasMagic;
                this.#uflag = this.#uflag || uflag;
                return re;
            })
                .join('');
            let start = '';
            if (this.isStart()) {
                if (typeof this.#parts[0] === 'string') {
                    // this is the string that will match the start of the pattern,
                    // so we need to protect against dots and such.
                    // '.' and '..' cannot match unless the pattern is that exactly,
                    // even if it starts with . or dot:true is set.
                    const dotTravAllowed = this.#parts.length === 1 && justDots.has(this.#parts[0]);
                    if (!dotTravAllowed) {
                        const aps = addPatternStart;
                        // check if we have a possibility of matching . or ..,
                        // and prevent that.
                        const needNoTrav = 
                        // dots are allowed, and the pattern starts with [ or .
                        (dot && aps.has(src.charAt(0))) ||
                            // the pattern starts with \., and then [ or .
                            (src.startsWith('\\.') && aps.has(src.charAt(2))) ||
                            // the pattern starts with \.\., and then [ or .
                            (src.startsWith('\\.\\.') && aps.has(src.charAt(4)));
                        // no need to prevent dots if it can't match a dot, or if a
                        // sub-pattern will be preventing it anyway.
                        const needNoDot = !dot && !allowDot && aps.has(src.charAt(0));
                        start = needNoTrav ? startNoTraversal : needNoDot ? startNoDot : '';
                    }
                }
            }
            // append the "end of path portion" pattern to negation tails
            let end = '';
            if (this.isEnd() &&
                this.#root.#filledNegs &&
                this.#parent?.type === '!') {
                end = '(?:$|\\/)';
            }
            const final = start + src + end;
            return [
                final,
                unescape(src),
                (this.#hasMagic = !!this.#hasMagic),
                this.#uflag,
            ];
        }
        // We need to calculate the body *twice* if it's a repeat pattern
        // at the start, once in nodot mode, then again in dot mode, so a
        // pattern like *(?) can match 'x.y'
        const repeated = this.type === '*' || this.type === '+';
        // some kind of extglob
        const start = this.type === '!' ? '(?:(?!(?:' : '(?:';
        let body = this.#partsToRegExp(dot);
        if (this.isStart() && this.isEnd() && !body && this.type !== '!') {
            // invalid extglob, has to at least be *something* present, if it's
            // the entire path portion.
            const s = this.toString();
            this.#parts = [s];
            this.type = null;
            this.#hasMagic = undefined;
            return [s, unescape(this.toString()), false, false];
        }
        // XXX abstract out this map method
        let bodyDotAllowed = !repeated || allowDot || dot || !startNoDot
            ? ''
            : this.#partsToRegExp(true);
        if (bodyDotAllowed === body) {
            bodyDotAllowed = '';
        }
        if (bodyDotAllowed) {
            body = `(?:${body})(?:${bodyDotAllowed})*?`;
        }
        // an empty !() is exactly equivalent to a starNoEmpty
        let final = '';
        if (this.type === '!' && this.#emptyExt) {
            final = (this.isStart() && !dot ? startNoDot : '') + starNoEmpty;
        }
        else {
            const close = this.type === '!'
                ? // !() must match something,but !(x) can match ''
                    '))' +
                        (this.isStart() && !dot && !allowDot ? startNoDot : '') +
                        star$1 +
                        ')'
                : this.type === '@'
                    ? ')'
                    : this.type === '?'
                        ? ')?'
                        : this.type === '+' && bodyDotAllowed
                            ? ')'
                            : this.type === '*' && bodyDotAllowed
                                ? `)?`
                                : `)${this.type}`;
            final = start + body + close;
        }
        return [
            final,
            unescape(body),
            (this.#hasMagic = !!this.#hasMagic),
            this.#uflag,
        ];
    }
    #partsToRegExp(dot) {
        return this.#parts
            .map(p => {
            // extglob ASTs should only contain parent ASTs
            /* c8 ignore start */
            if (typeof p === 'string') {
                throw new Error('string type in extglob ast??');
            }
            /* c8 ignore stop */
            // can ignore hasMagic, because extglobs are already always magic
            const [re, _, _hasMagic, uflag] = p.toRegExpSource(dot);
            this.#uflag = this.#uflag || uflag;
            return re;
        })
            .filter(p => !(this.isStart() && this.isEnd()) || !!p)
            .join('|');
    }
    static #parseGlob(glob, hasMagic, noEmpty = false) {
        let escaping = false;
        let re = '';
        let uflag = false;
        for (let i = 0; i < glob.length; i++) {
            const c = glob.charAt(i);
            if (escaping) {
                escaping = false;
                re += (reSpecials.has(c) ? '\\' : '') + c;
                continue;
            }
            if (c === '\\') {
                if (i === glob.length - 1) {
                    re += '\\\\';
                }
                else {
                    escaping = true;
                }
                continue;
            }
            if (c === '[') {
                const [src, needUflag, consumed, magic] = parseClass(glob, i);
                if (consumed) {
                    re += src;
                    uflag = uflag || needUflag;
                    i += consumed - 1;
                    hasMagic = hasMagic || magic;
                    continue;
                }
            }
            if (c === '*') {
                if (noEmpty && glob === '*')
                    re += starNoEmpty;
                else
                    re += star$1;
                hasMagic = true;
                continue;
            }
            if (c === '?') {
                re += qmark$1;
                hasMagic = true;
                continue;
            }
            re += regExpEscape$1(c);
        }
        return [re, unescape(glob), !!hasMagic, uflag];
    }
}

/**
 * Escape all magic characters in a glob pattern.
 *
 * If the {@link windowsPathsNoEscape | GlobOptions.windowsPathsNoEscape}
 * option is used, then characters are escaped by wrapping in `[]`, because
 * a magic character wrapped in a character class can only be satisfied by
 * that exact character.  In this mode, `\` is _not_ escaped, because it is
 * not interpreted as a magic character, but instead as a path separator.
 */
const escape = (s, { windowsPathsNoEscape = false, } = {}) => {
    // don't need to escape +@! because we escape the parens
    // that make those magic, and escaping ! as [!] isn't valid,
    // because [!]] is a valid glob class meaning not ']'.
    return windowsPathsNoEscape
        ? s.replace(/[?*()[\]]/g, '[$&]')
        : s.replace(/[?*()[\]\\]/g, '\\$&');
};

const minimatch = (p, pattern, options = {}) => {
    assertValidPattern(pattern);
    // shortcut: comments match nothing.
    if (!options.nocomment && pattern.charAt(0) === '#') {
        return false;
    }
    return new Minimatch(pattern, options).match(p);
};
// Optimized checking for the most common glob patterns.
const starDotExtRE = /^\*+([^+@!?\*\[\(]*)$/;
const starDotExtTest = (ext) => (f) => !f.startsWith('.') && f.endsWith(ext);
const starDotExtTestDot = (ext) => (f) => f.endsWith(ext);
const starDotExtTestNocase = (ext) => {
    ext = ext.toLowerCase();
    return (f) => !f.startsWith('.') && f.toLowerCase().endsWith(ext);
};
const starDotExtTestNocaseDot = (ext) => {
    ext = ext.toLowerCase();
    return (f) => f.toLowerCase().endsWith(ext);
};
const starDotStarRE = /^\*+\.\*+$/;
const starDotStarTest = (f) => !f.startsWith('.') && f.includes('.');
const starDotStarTestDot = (f) => f !== '.' && f !== '..' && f.includes('.');
const dotStarRE = /^\.\*+$/;
const dotStarTest = (f) => f !== '.' && f !== '..' && f.startsWith('.');
const starRE = /^\*+$/;
const starTest = (f) => f.length !== 0 && !f.startsWith('.');
const starTestDot = (f) => f.length !== 0 && f !== '.' && f !== '..';
const qmarksRE = /^\?+([^+@!?\*\[\(]*)?$/;
const qmarksTestNocase = ([$0, ext = '']) => {
    const noext = qmarksTestNoExt([$0]);
    if (!ext)
        return noext;
    ext = ext.toLowerCase();
    return (f) => noext(f) && f.toLowerCase().endsWith(ext);
};
const qmarksTestNocaseDot = ([$0, ext = '']) => {
    const noext = qmarksTestNoExtDot([$0]);
    if (!ext)
        return noext;
    ext = ext.toLowerCase();
    return (f) => noext(f) && f.toLowerCase().endsWith(ext);
};
const qmarksTestDot = ([$0, ext = '']) => {
    const noext = qmarksTestNoExtDot([$0]);
    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);
};
const qmarksTest = ([$0, ext = '']) => {
    const noext = qmarksTestNoExt([$0]);
    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);
};
const qmarksTestNoExt = ([$0]) => {
    const len = $0.length;
    return (f) => f.length === len && !f.startsWith('.');
};
const qmarksTestNoExtDot = ([$0]) => {
    const len = $0.length;
    return (f) => f.length === len && f !== '.' && f !== '..';
};
/* c8 ignore start */
const defaultPlatform$2 = (typeof process === 'object' && process
    ? (typeof process.env === 'object' &&
        process.env &&
        process.env.__MINIMATCH_TESTING_PLATFORM__) ||
        process.platform
    : 'posix');
const path = {
    win32: { sep: '\\' },
    posix: { sep: '/' },
};
/* c8 ignore stop */
const sep = defaultPlatform$2 === 'win32' ? path.win32.sep : path.posix.sep;
minimatch.sep = sep;
const GLOBSTAR = Symbol('globstar **');
minimatch.GLOBSTAR = GLOBSTAR;
// any single thing other than /
// don't need to escape / when using new RegExp()
const qmark = '[^/]';
// * => any number of characters
const star = qmark + '*?';
// ** when dots are allowed.  Anything goes, except .. and .
// not (^ or / followed by one or two dots followed by $ or /),
// followed by anything, any number of times.
const twoStarDot = '(?:(?!(?:\\/|^)(?:\\.{1,2})($|\\/)).)*?';
// not a ^ or / followed by a dot,
// followed by anything, any number of times.
const twoStarNoDot = '(?:(?!(?:\\/|^)\\.).)*?';
const filter = (pattern, options = {}) => (p) => minimatch(p, pattern, options);
minimatch.filter = filter;
const ext = (a, b = {}) => Object.assign({}, a, b);
const defaults = (def) => {
    if (!def || typeof def !== 'object' || !Object.keys(def).length) {
        return minimatch;
    }
    const orig = minimatch;
    const m = (p, pattern, options = {}) => orig(p, pattern, ext(def, options));
    return Object.assign(m, {
        Minimatch: class Minimatch extends orig.Minimatch {
            constructor(pattern, options = {}) {
                super(pattern, ext(def, options));
            }
            static defaults(options) {
                return orig.defaults(ext(def, options)).Minimatch;
            }
        },
        AST: class AST extends orig.AST {
            /* c8 ignore start */
            constructor(type, parent, options = {}) {
                super(type, parent, ext(def, options));
            }
            /* c8 ignore stop */
            static fromGlob(pattern, options = {}) {
                return orig.AST.fromGlob(pattern, ext(def, options));
            }
        },
        unescape: (s, options = {}) => orig.unescape(s, ext(def, options)),
        escape: (s, options = {}) => orig.escape(s, ext(def, options)),
        filter: (pattern, options = {}) => orig.filter(pattern, ext(def, options)),
        defaults: (options) => orig.defaults(ext(def, options)),
        makeRe: (pattern, options = {}) => orig.makeRe(pattern, ext(def, options)),
        braceExpand: (pattern, options = {}) => orig.braceExpand(pattern, ext(def, options)),
        match: (list, pattern, options = {}) => orig.match(list, pattern, ext(def, options)),
        sep: orig.sep,
        GLOBSTAR: GLOBSTAR,
    });
};
minimatch.defaults = defaults;
// Brace expansion:
// a{b,c}d -> abd acd
// a{b,}c -> abc ac
// a{0..3}d -> a0d a1d a2d a3d
// a{b,c{d,e}f}g -> abg acdfg acefg
// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg
//
// Invalid sets are not expanded.
// a{2..}b -> a{2..}b
// a{b}c -> a{b}c
const braceExpand = (pattern, options = {}) => {
    assertValidPattern(pattern);
    // Thanks to Yeting Li <https://github.com/yetingli> for
    // improving this regexp to avoid a ReDOS vulnerability.
    if (options.nobrace || !/\{(?:(?!\{).)*\}/.test(pattern)) {
        // shortcut. no need to expand.
        return [pattern];
    }
    return expand(pattern);
};
minimatch.braceExpand = braceExpand;
// parse a component of the expanded set.
// At this point, no pattern may contain "/" in it
// so we're going to return a 2d array, where each entry is the full
// pattern, split on '/', and then turned into a regular expression.
// A regexp is made at the end which joins each array with an
// escaped /, and another full one which joins each regexp with |.
//
// Following the lead of Bash 4.1, note that "**" only has special meaning
// when it is the *only* thing in a path portion.  Otherwise, any series
// of * is equivalent to a single *.  Globstar behavior is enabled by
// default, and can be disabled by setting options.noglobstar.
const makeRe = (pattern, options = {}) => new Minimatch(pattern, options).makeRe();
minimatch.makeRe = makeRe;
const match = (list, pattern, options = {}) => {
    const mm = new Minimatch(pattern, options);
    list = list.filter(f => mm.match(f));
    if (mm.options.nonull && !list.length) {
        list.push(pattern);
    }
    return list;
};
minimatch.match = match;
// replace stuff like \* with *
const globMagic = /[?*]|[+@!]\(.*?\)|\[|\]/;
const regExpEscape = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
class Minimatch {
    options;
    set;
    pattern;
    windowsPathsNoEscape;
    nonegate;
    negate;
    comment;
    empty;
    preserveMultipleSlashes;
    partial;
    globSet;
    globParts;
    nocase;
    isWindows;
    platform;
    windowsNoMagicRoot;
    regexp;
    constructor(pattern, options = {}) {
        assertValidPattern(pattern);
        options = options || {};
        this.options = options;
        this.pattern = pattern;
        this.platform = options.platform || defaultPlatform$2;
        this.isWindows = this.platform === 'win32';
        this.windowsPathsNoEscape =
            !!options.windowsPathsNoEscape || options.allowWindowsEscape === false;
        if (this.windowsPathsNoEscape) {
            this.pattern = this.pattern.replace(/\\/g, '/');
        }
        this.preserveMultipleSlashes = !!options.preserveMultipleSlashes;
        this.regexp = null;
        this.negate = false;
        this.nonegate = !!options.nonegate;
        this.comment = false;
        this.empty = false;
        this.partial = !!options.partial;
        this.nocase = !!this.options.nocase;
        this.windowsNoMagicRoot =
            options.windowsNoMagicRoot !== undefined
                ? options.windowsNoMagicRoot
                : !!(this.isWindows && this.nocase);
        this.globSet = [];
        this.globParts = [];
        this.set = [];
        // make the set of regexps etc.
        this.make();
    }
    hasMagic() {
        if (this.options.magicalBraces && this.set.length > 1) {
            return true;
        }
        for (const pattern of this.set) {
            for (const part of pattern) {
                if (typeof part !== 'string')
                    return true;
            }
        }
        return false;
    }
    debug(..._) { }
    make() {
        const pattern = this.pattern;
        const options = this.options;
        // empty patterns and comments match nothing.
        if (!options.nocomment && pattern.charAt(0) === '#') {
            this.comment = true;
            return;
        }
        if (!pattern) {
            this.empty = true;
            return;
        }
        // step 1: figure out negation, etc.
        this.parseNegate();
        // step 2: expand braces
        this.globSet = [...new Set(this.braceExpand())];
        if (options.debug) {
            this.debug = (...args) => console.error(...args);
        }
        this.debug(this.pattern, this.globSet);
        // step 3: now we have a set, so turn each one into a series of
        // path-portion matching patterns.
        // These will be regexps, except in the case of "**", which is
        // set to the GLOBSTAR object for globstar behavior,
        // and will not contain any / characters
        //
        // First, we preprocess to make the glob pattern sets a bit simpler
        // and deduped.  There are some perf-killing patterns that can cause
        // problems with a glob walk, but we can simplify them down a bit.
        const rawGlobParts = this.globSet.map(s => this.slashSplit(s));
        this.globParts = this.preprocess(rawGlobParts);
        this.debug(this.pattern, this.globParts);
        // glob --> regexps
        let set = this.globParts.map((s, _, __) => {
            if (this.isWindows && this.windowsNoMagicRoot) {
                // check if it's a drive or unc path.
                const isUNC = s[0] === '' &&
                    s[1] === '' &&
                    (s[2] === '?' || !globMagic.test(s[2])) &&
                    !globMagic.test(s[3]);
                const isDrive = /^[a-z]:/i.test(s[0]);
                if (isUNC) {
                    return [...s.slice(0, 4), ...s.slice(4).map(ss => this.parse(ss))];
                }
                else if (isDrive) {
                    return [s[0], ...s.slice(1).map(ss => this.parse(ss))];
                }
            }
            return s.map(ss => this.parse(ss));
        });
        this.debug(this.pattern, set);
        // filter out everything that didn't compile properly.
        this.set = set.filter(s => s.indexOf(false) === -1);
        // do not treat the ? in UNC paths as magic
        if (this.isWindows) {
            for (let i = 0; i < this.set.length; i++) {
                const p = this.set[i];
                if (p[0] === '' &&
                    p[1] === '' &&
                    this.globParts[i][2] === '?' &&
                    typeof p[3] === 'string' &&
                    /^[a-z]:$/i.test(p[3])) {
                    p[2] = '?';
                }
            }
        }
        this.debug(this.pattern, this.set);
    }
    // various transforms to equivalent pattern sets that are
    // faster to process in a filesystem walk.  The goal is to
    // eliminate what we can, and push all ** patterns as far
    // to the right as possible, even if it increases the number
    // of patterns that we have to process.
    preprocess(globParts) {
        // if we're not in globstar mode, then turn all ** into *
        if (this.options.noglobstar) {
            for (let i = 0; i < globParts.length; i++) {
                for (let j = 0; j < globParts[i].length; j++) {
                    if (globParts[i][j] === '**') {
                        globParts[i][j] = '*';
                    }
                }
            }
        }
        const { optimizationLevel = 1 } = this.options;
        if (optimizationLevel >= 2) {
            // aggressive optimization for the purpose of fs walking
            globParts = this.firstPhasePreProcess(globParts);
            globParts = this.secondPhasePreProcess(globParts);
        }
        else if (optimizationLevel >= 1) {
            // just basic optimizations to remove some .. parts
            globParts = this.levelOneOptimize(globParts);
        }
        else {
            // just collapse multiple ** portions into one
            globParts = this.adjascentGlobstarOptimize(globParts);
        }
        return globParts;
    }
    // just get rid of adjascent ** portions
    adjascentGlobstarOptimize(globParts) {
        return globParts.map(parts => {
            let gs = -1;
            while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
                let i = gs;
                while (parts[i + 1] === '**') {
                    i++;
                }
                if (i !== gs) {
                    parts.splice(gs, i - gs);
                }
            }
            return parts;
        });
    }
    // get rid of adjascent ** and resolve .. portions
    levelOneOptimize(globParts) {
        return globParts.map(parts => {
            parts = parts.reduce((set, part) => {
                const prev = set[set.length - 1];
                if (part === '**' && prev === '**') {
                    return set;
                }
                if (part === '..') {
                    if (prev && prev !== '..' && prev !== '.' && prev !== '**') {
                        set.pop();
                        return set;
                    }
                }
                set.push(part);
                return set;
            }, []);
            return parts.length === 0 ? [''] : parts;
        });
    }
    levelTwoFileOptimize(parts) {
        if (!Array.isArray(parts)) {
            parts = this.slashSplit(parts);
        }
        let didSomething = false;
        do {
            didSomething = false;
            // <pre>/<e>/<rest> -> <pre>/<rest>
            if (!this.preserveMultipleSlashes) {
                for (let i = 1; i < parts.length - 1; i++) {
                    const p = parts[i];
                    // don't squeeze out UNC patterns
                    if (i === 1 && p === '' && parts[0] === '')
                        continue;
                    if (p === '.' || p === '') {
                        didSomething = true;
                        parts.splice(i, 1);
                        i--;
                    }
                }
                if (parts[0] === '.' &&
                    parts.length === 2 &&
                    (parts[1] === '.' || parts[1] === '')) {
                    didSomething = true;
                    parts.pop();
                }
            }
            // <pre>/<p>/../<rest> -> <pre>/<rest>
            let dd = 0;
            while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
                const p = parts[dd - 1];
                if (p && p !== '.' && p !== '..' && p !== '**') {
                    didSomething = true;
                    parts.splice(dd - 1, 2);
                    dd -= 2;
                }
            }
        } while (didSomething);
        return parts.length === 0 ? [''] : parts;
    }
    // First phase: single-pattern processing
    // <pre> is 1 or more portions
    // <rest> is 1 or more portions
    // <p> is any portion other than ., .., '', or **
    // <e> is . or ''
    //
    // **/.. is *brutal* for filesystem walking performance, because
    // it effectively resets the recursive walk each time it occurs,
    // and ** cannot be reduced out by a .. pattern part like a regexp
    // or most strings (other than .., ., and '') can be.
    //
    // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
    // <pre>/<e>/<rest> -> <pre>/<rest>
    // <pre>/<p>/../<rest> -> <pre>/<rest>
    // **/**/<rest> -> **/<rest>
    //
    // **/*/<rest> -> */**/<rest> <== not valid because ** doesn't follow
    // this WOULD be allowed if ** did follow symlinks, or * didn't
    firstPhasePreProcess(globParts) {
        let didSomething = false;
        do {
            didSomething = false;
            // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
            for (let parts of globParts) {
                let gs = -1;
                while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
                    let gss = gs;
                    while (parts[gss + 1] === '**') {
                        // <pre>/**/**/<rest> -> <pre>/**/<rest>
                        gss++;
                    }
                    // eg, if gs is 2 and gss is 4, that means we have 3 **
                    // parts, and can remove 2 of them.
                    if (gss > gs) {
                        parts.splice(gs + 1, gss - gs);
                    }
                    let next = parts[gs + 1];
                    const p = parts[gs + 2];
                    const p2 = parts[gs + 3];
                    if (next !== '..')
                        continue;
                    if (!p ||
                        p === '.' ||
                        p === '..' ||
                        !p2 ||
                        p2 === '.' ||
                        p2 === '..') {
                        continue;
                    }
                    didSomething = true;
                    // edit parts in place, and push the new one
                    parts.splice(gs, 1);
                    const other = parts.slice(0);
                    other[gs] = '**';
                    globParts.push(other);
                    gs--;
                }
                // <pre>/<e>/<rest> -> <pre>/<rest>
                if (!this.preserveMultipleSlashes) {
                    for (let i = 1; i < parts.length - 1; i++) {
                        const p = parts[i];
                        // don't squeeze out UNC patterns
                        if (i === 1 && p === '' && parts[0] === '')
                            continue;
                        if (p === '.' || p === '') {
                            didSomething = true;
                            parts.splice(i, 1);
                            i--;
                        }
                    }
                    if (parts[0] === '.' &&
                        parts.length === 2 &&
                        (parts[1] === '.' || parts[1] === '')) {
                        didSomething = true;
                        parts.pop();
                    }
                }
                // <pre>/<p>/../<rest> -> <pre>/<rest>
                let dd = 0;
                while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
                    const p = parts[dd - 1];
                    if (p && p !== '.' && p !== '..' && p !== '**') {
                        didSomething = true;
                        const needDot = dd === 1 && parts[dd + 1] === '**';
                        const splin = needDot ? ['.'] : [];
                        parts.splice(dd - 1, 2, ...splin);
                        if (parts.length === 0)
                            parts.push('');
                        dd -= 2;
                    }
                }
            }
        } while (didSomething);
        return globParts;
    }
    // second phase: multi-pattern dedupes
    // {<pre>/*/<rest>,<pre>/<p>/<rest>} -> <pre>/*/<rest>
    // {<pre>/<rest>,<pre>/<rest>} -> <pre>/<rest>
    // {<pre>/**/<rest>,<pre>/<rest>} -> <pre>/**/<rest>
    //
    // {<pre>/**/<rest>,<pre>/**/<p>/<rest>} -> <pre>/**/<rest>
    // ^-- not valid because ** doens't follow symlinks
    secondPhasePreProcess(globParts) {
        for (let i = 0; i < globParts.length - 1; i++) {
            for (let j = i + 1; j < globParts.length; j++) {
                const matched = this.partsMatch(globParts[i], globParts[j], !this.preserveMultipleSlashes);
                if (matched) {
                    globParts[i] = [];
                    globParts[j] = matched;
                    break;
                }
            }
        }
        return globParts.filter(gs => gs.length);
    }
    partsMatch(a, b, emptyGSMatch = false) {
        let ai = 0;
        let bi = 0;
        let result = [];
        let which = '';
        while (ai < a.length && bi < b.length) {
            if (a[ai] === b[bi]) {
                result.push(which === 'b' ? b[bi] : a[ai]);
                ai++;
                bi++;
            }
            else if (emptyGSMatch && a[ai] === '**' && b[bi] === a[ai + 1]) {
                result.push(a[ai]);
                ai++;
            }
            else if (emptyGSMatch && b[bi] === '**' && a[ai] === b[bi + 1]) {
                result.push(b[bi]);
                bi++;
            }
            else if (a[ai] === '*' &&
                b[bi] &&
                (this.options.dot || !b[bi].startsWith('.')) &&
                b[bi] !== '**') {
                if (which === 'b')
                    return false;
                which = 'a';
                result.push(a[ai]);
                ai++;
                bi++;
            }
            else if (b[bi] === '*' &&
                a[ai] &&
                (this.options.dot || !a[ai].startsWith('.')) &&
                a[ai] !== '**') {
                if (which === 'a')
                    return false;
                which = 'b';
                result.push(b[bi]);
                ai++;
                bi++;
            }
            else {
                return false;
            }
        }
        // if we fall out of the loop, it means they two are identical
        // as long as their lengths match
        return a.length === b.length && result;
    }
    parseNegate() {
        if (this.nonegate)
            return;
        const pattern = this.pattern;
        let negate = false;
        let negateOffset = 0;
        for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {
            negate = !negate;
            negateOffset++;
        }
        if (negateOffset)
            this.pattern = pattern.slice(negateOffset);
        this.negate = negate;
    }
    // set partial to true to test if, for example,
    // "/a/b" matches the start of "/*/b/*/d"
    // Partial means, if you run out of file before you run
    // out of pattern, then that's fine, as long as all
    // the parts match.
    matchOne(file, pattern, partial = false) {
        const options = this.options;
        // UNC paths like //?/X:/... can match X:/... and vice versa
        // Drive letters in absolute drive or unc paths are always compared
        // case-insensitively.
        if (this.isWindows) {
            const fileDrive = typeof file[0] === 'string' && /^[a-z]:$/i.test(file[0]);
            const fileUNC = !fileDrive &&
                file[0] === '' &&
                file[1] === '' &&
                file[2] === '?' &&
                /^[a-z]:$/i.test(file[3]);
            const patternDrive = typeof pattern[0] === 'string' && /^[a-z]:$/i.test(pattern[0]);
            const patternUNC = !patternDrive &&
                pattern[0] === '' &&
                pattern[1] === '' &&
                pattern[2] === '?' &&
                typeof pattern[3] === 'string' &&
                /^[a-z]:$/i.test(pattern[3]);
            const fdi = fileUNC ? 3 : fileDrive ? 0 : undefined;
            const pdi = patternUNC ? 3 : patternDrive ? 0 : undefined;
            if (typeof fdi === 'number' && typeof pdi === 'number') {
                const [fd, pd] = [file[fdi], pattern[pdi]];
                if (fd.toLowerCase() === pd.toLowerCase()) {
                    pattern[pdi] = fd;
                    if (pdi > fdi) {
                        pattern = pattern.slice(pdi);
                    }
                    else if (fdi > pdi) {
                        file = file.slice(fdi);
                    }
                }
            }
        }
        // resolve and reduce . and .. portions in the file as well.
        // dont' need to do the second phase, because it's only one string[]
        const { optimizationLevel = 1 } = this.options;
        if (optimizationLevel >= 2) {
            file = this.levelTwoFileOptimize(file);
        }
        this.debug('matchOne', this, { file, pattern });
        this.debug('matchOne', file.length, pattern.length);
        for (var fi = 0, pi = 0, fl = file.length, pl = pattern.length; fi < fl && pi < pl; fi++, pi++) {
            this.debug('matchOne loop');
            var p = pattern[pi];
            var f = file[fi];
            this.debug(pattern, p, f);
            // should be impossible.
            // some invalid regexp stuff in the set.
            /* c8 ignore start */
            if (p === false) {
                return false;
            }
            /* c8 ignore stop */
            if (p === GLOBSTAR) {
                this.debug('GLOBSTAR', [pattern, p, f]);
                // "**"
                // a/**/b/**/c would match the following:
                // a/b/x/y/z/c
                // a/x/y/z/b/c
                // a/b/x/b/x/c
                // a/b/c
                // To do this, take the rest of the pattern after
                // the **, and see if it would match the file remainder.
                // If so, return success.
                // If not, the ** "swallows" a segment, and try again.
                // This is recursively awful.
                //
                // a/**/b/**/c matching a/b/x/y/z/c
                // - a matches a
                // - doublestar
                //   - matchOne(b/x/y/z/c, b/**/c)
                //     - b matches b
                //     - doublestar
                //       - matchOne(x/y/z/c, c) -> no
                //       - matchOne(y/z/c, c) -> no
                //       - matchOne(z/c, c) -> no
                //       - matchOne(c, c) yes, hit
                var fr = fi;
                var pr = pi + 1;
                if (pr === pl) {
                    this.debug('** at the end');
                    // a ** at the end will just swallow the rest.
                    // We have found a match.
                    // however, it will not swallow /.x, unless
                    // options.dot is set.
                    // . and .. are *never* matched by **, for explosively
                    // exponential reasons.
                    for (; fi < fl; fi++) {
                        if (file[fi] === '.' ||
                            file[fi] === '..' ||
                            (!options.dot && file[fi].charAt(0) === '.'))
                            return false;
                    }
                    return true;
                }
                // ok, let's see if we can swallow whatever we can.
                while (fr < fl) {
                    var swallowee = file[fr];
                    this.debug('\nglobstar while', file, fr, pattern, pr, swallowee);
                    // XXX remove this slice.  Just pass the start index.
                    if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {
                        this.debug('globstar found match!', fr, fl, swallowee);
                        // found a match.
                        return true;
                    }
                    else {
                        // can't swallow "." or ".." ever.
                        // can only swallow ".foo" when explicitly asked.
                        if (swallowee === '.' ||
                            swallowee === '..' ||
                            (!options.dot && swallowee.charAt(0) === '.')) {
                            this.debug('dot detected!', file, fr, pattern, pr);
                            break;
                        }
                        // ** swallows a segment, and continue.
                        this.debug('globstar swallow a segment, and continue');
                        fr++;
                    }
                }
                // no match was found.
                // However, in partial mode, we can't say this is necessarily over.
                /* c8 ignore start */
                if (partial) {
                    // ran out of file
                    this.debug('\n>>> no match, partial?', file, fr, pattern, pr);
                    if (fr === fl) {
                        return true;
                    }
                }
                /* c8 ignore stop */
                return false;
            }
            // something other than **
            // non-magic patterns just have to match exactly
            // patterns with magic have been turned into regexps.
            let hit;
            if (typeof p === 'string') {
                hit = f === p;
                this.debug('string match', p, f, hit);
            }
            else {
                hit = p.test(f);
                this.debug('pattern match', p, f, hit);
            }
            if (!hit)
                return false;
        }
        // Note: ending in / means that we'll get a final ""
        // at the end of the pattern.  This can only match a
        // corresponding "" at the end of the file.
        // If the file ends in /, then it can only match a
        // a pattern that ends in /, unless the pattern just
        // doesn't have any more for it. But, a/b/ should *not*
        // match "a/b/*", even though "" matches against the
        // [^/]*? pattern, except in partial mode, where it might
        // simply not be reached yet.
        // However, a/b/ should still satisfy a/*
        // now either we fell off the end of the pattern, or we're done.
        if (fi === fl && pi === pl) {
            // ran out of pattern and filename at the same time.
            // an exact hit!
            return true;
        }
        else if (fi === fl) {
            // ran out of file, but still had pattern left.
            // this is ok if we're doing the match as part of
            // a glob fs traversal.
            return partial;
        }
        else if (pi === pl) {
            // ran out of pattern, still have file left.
            // this is only acceptable if we're on the very last
            // empty segment of a file with a trailing slash.
            // a/* should match a/b/
            return fi === fl - 1 && file[fi] === '';
            /* c8 ignore start */
        }
        else {
            // should be unreachable.
            throw new Error('wtf?');
        }
        /* c8 ignore stop */
    }
    braceExpand() {
        return braceExpand(this.pattern, this.options);
    }
    parse(pattern) {
        assertValidPattern(pattern);
        const options = this.options;
        // shortcuts
        if (pattern === '**')
            return GLOBSTAR;
        if (pattern === '')
            return '';
        // far and away, the most common glob pattern parts are
        // *, *.*, and *.<ext>  Add a fast check method for those.
        let m;
        let fastTest = null;
        if ((m = pattern.match(starRE))) {
            fastTest = options.dot ? starTestDot : starTest;
        }
        else if ((m = pattern.match(starDotExtRE))) {
            fastTest = (options.nocase
                ? options.dot
                    ? starDotExtTestNocaseDot
                    : starDotExtTestNocase
                : options.dot
                    ? starDotExtTestDot
                    : starDotExtTest)(m[1]);
        }
        else if ((m = pattern.match(qmarksRE))) {
            fastTest = (options.nocase
                ? options.dot
                    ? qmarksTestNocaseDot
                    : qmarksTestNocase
                : options.dot
                    ? qmarksTestDot
                    : qmarksTest)(m);
        }
        else if ((m = pattern.match(starDotStarRE))) {
            fastTest = options.dot ? starDotStarTestDot : starDotStarTest;
        }
        else if ((m = pattern.match(dotStarRE))) {
            fastTest = dotStarTest;
        }
        const re = AST.fromGlob(pattern, this.options).toMMPattern();
        if (fastTest && typeof re === 'object') {
            // Avoids overriding in frozen environments
            Reflect.defineProperty(re, 'test', { value: fastTest });
        }
        return re;
    }
    makeRe() {
        if (this.regexp || this.regexp === false)
            return this.regexp;
        // at this point, this.set is a 2d array of partial
        // pattern strings, or "**".
        //
        // It's better to use .match().  This function shouldn't
        // be used, really, but it's pretty convenient sometimes,
        // when you just want to work with a regex.
        const set = this.set;
        if (!set.length) {
            this.regexp = false;
            return this.regexp;
        }
        const options = this.options;
        const twoStar = options.noglobstar
            ? star
            : options.dot
                ? twoStarDot
                : twoStarNoDot;
        const flags = new Set(options.nocase ? ['i'] : []);
        // regexpify non-globstar patterns
        // if ** is only item, then we just do one twoStar
        // if ** is first, and there are more, prepend (\/|twoStar\/)? to next
        // if ** is last, append (\/twoStar|) to previous
        // if ** is in the middle, append (\/|\/twoStar\/) to previous
        // then filter out GLOBSTAR symbols
        let re = set
            .map(pattern => {
            const pp = pattern.map(p => {
                if (p instanceof RegExp) {
                    for (const f of p.flags.split(''))
                        flags.add(f);
                }
                return typeof p === 'string'
                    ? regExpEscape(p)
                    : p === GLOBSTAR
                        ? GLOBSTAR
                        : p._src;
            });
            pp.forEach((p, i) => {
                const next = pp[i + 1];
                const prev = pp[i - 1];
                if (p !== GLOBSTAR || prev === GLOBSTAR) {
                    return;
                }
                if (prev === undefined) {
                    if (next !== undefined && next !== GLOBSTAR) {
                        pp[i + 1] = '(?:\\/|' + twoStar + '\\/)?' + next;
                    }
                    else {
                        pp[i] = twoStar;
                    }
                }
                else if (next === undefined) {
                    pp[i - 1] = prev + '(?:\\/|' + twoStar + ')?';
                }
                else if (next !== GLOBSTAR) {
                    pp[i - 1] = prev + '(?:\\/|\\/' + twoStar + '\\/)' + next;
                    pp[i + 1] = GLOBSTAR;
                }
            });
            return pp.filter(p => p !== GLOBSTAR).join('/');
        })
            .join('|');
        // need to wrap in parens if we had more than one thing with |,
        // otherwise only the first will be anchored to ^ and the last to $
        const [open, close] = set.length > 1 ? ['(?:', ')'] : ['', ''];
        // must match entire pattern
        // ending in a * or ** will make it less strict.
        re = '^' + open + re + close + '$';
        // can match anything, as long as it's not this.
        if (this.negate)
            re = '^(?!' + re + ').+$';
        try {
            this.regexp = new RegExp(re, [...flags].join(''));
            /* c8 ignore start */
        }
        catch (ex) {
            // should be impossible
            this.regexp = false;
        }
        /* c8 ignore stop */
        return this.regexp;
    }
    slashSplit(p) {
        // if p starts with // on windows, we preserve that
        // so that UNC paths aren't broken.  Otherwise, any number of
        // / characters are coalesced into one, unless
        // preserveMultipleSlashes is set to true.
        if (this.preserveMultipleSlashes) {
            return p.split('/');
        }
        else if (this.isWindows && /^\/\/[^\/]+/.test(p)) {
            // add an extra '' for the one we lose
            return ['', ...p.split(/\/+/)];
        }
        else {
            return p.split(/\/+/);
        }
    }
    match(f, partial = this.partial) {
        this.debug('match', f, this.pattern);
        // short-circuit in the case of busted things.
        // comments, etc.
        if (this.comment) {
            return false;
        }
        if (this.empty) {
            return f === '';
        }
        if (f === '/' && partial) {
            return true;
        }
        const options = this.options;
        // windows: need to use /, not \
        if (this.isWindows) {
            f = f.split('\\').join('/');
        }
        // treat the test path as a set of pathparts.
        const ff = this.slashSplit(f);
        this.debug(this.pattern, 'split', ff);
        // just ONE of the pattern sets in this.set needs to match
        // in order for it to be valid.  If negating, then just one
        // match means that we have failed.
        // Either way, return on the first hit.
        const set = this.set;
        this.debug(this.pattern, 'set', set);
        // Find the basename of the path by looking for the last non-empty segment
        let filename = ff[ff.length - 1];
        if (!filename) {
            for (let i = ff.length - 2; !filename && i >= 0; i--) {
                filename = ff[i];
            }
        }
        for (let i = 0; i < set.length; i++) {
            const pattern = set[i];
            let file = ff;
            if (options.matchBase && pattern.length === 1) {
                file = [filename];
            }
            const hit = this.matchOne(file, pattern, partial);
            if (hit) {
                if (options.flipNegate) {
                    return true;
                }
                return !this.negate;
            }
        }
        // didn't get any hits.  this is success if it's a negative
        // pattern, failure otherwise.
        if (options.flipNegate) {
            return false;
        }
        return this.negate;
    }
    static defaults(def) {
        return minimatch.defaults(def).Minimatch;
    }
}
/* c8 ignore stop */
minimatch.AST = AST;
minimatch.Minimatch = Minimatch;
minimatch.escape = escape;
minimatch.unescape = unescape;

/**
 * @module LRUCache
 */
const defaultPerf = (typeof performance === 'object' &&
    performance &&
    typeof performance.now === 'function') ?
    performance
    : Date;
const warned = new Set();
/* c8 ignore start */
const PROCESS = (typeof process === 'object' && !!process ?
    process
    : {});
/* c8 ignore start */
const emitWarning = (msg, type, code, fn) => {
    typeof PROCESS.emitWarning === 'function' ?
        PROCESS.emitWarning(msg, type, code, fn)
        : console.error(`[${code}] ${type}: ${msg}`);
};
let AC = globalThis.AbortController;
let AS = globalThis.AbortSignal;
/* c8 ignore start */
if (typeof AC === 'undefined') {
    //@ts-ignore
    AS = class AbortSignal {
        onabort;
        _onabort = [];
        reason;
        aborted = false;
        addEventListener(_, fn) {
            this._onabort.push(fn);
        }
    };
    //@ts-ignore
    AC = class AbortController {
        constructor() {
            warnACPolyfill();
        }
        signal = new AS();
        abort(reason) {
            if (this.signal.aborted)
                return;
            //@ts-ignore
            this.signal.reason = reason;
            //@ts-ignore
            this.signal.aborted = true;
            //@ts-ignore
            for (const fn of this.signal._onabort) {
                fn(reason);
            }
            this.signal.onabort?.(reason);
        }
    };
    let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1';
    const warnACPolyfill = () => {
        if (!printACPolyfillWarning)
            return;
        printACPolyfillWarning = false;
        emitWarning('AbortController is not defined. If using lru-cache in ' +
            'node 14, load an AbortController polyfill from the ' +
            '`node-abort-controller` package. A minimal polyfill is ' +
            'provided for use by LRUCache.fetch(), but it should not be ' +
            'relied upon in other contexts (eg, passing it to other APIs that ' +
            'use AbortController/AbortSignal might have undesirable effects). ' +
            'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.', 'NO_ABORT_CONTROLLER', 'ENOTSUP', warnACPolyfill);
    };
}
/* c8 ignore stop */
const shouldWarn = (code) => !warned.has(code);
const isPosInt = (n) => n && n === Math.floor(n) && n > 0 && isFinite(n);
/* c8 ignore start */
// This is a little bit ridiculous, tbh.
// The maximum array length is 2^32-1 or thereabouts on most JS impls.
// And well before that point, you're caching the entire world, I mean,
// that's ~32GB of just integers for the next/prev links, plus whatever
// else to hold that many keys and values.  Just filling the memory with
// zeroes at init time is brutal when you get that big.
// But why not be complete?
// Maybe in the future, these limits will have expanded.
const getUintArray = (max) => !isPosInt(max) ? null
    : max <= Math.pow(2, 8) ? Uint8Array
        : max <= Math.pow(2, 16) ? Uint16Array
            : max <= Math.pow(2, 32) ? Uint32Array
                : max <= Number.MAX_SAFE_INTEGER ? ZeroArray
                    : null;
/* c8 ignore stop */
class ZeroArray extends Array {
    constructor(size) {
        super(size);
        this.fill(0);
    }
}
class Stack {
    heap;
    length;
    // private constructor
    static #constructing = false;
    static create(max) {
        const HeapCls = getUintArray(max);
        if (!HeapCls)
            return [];
        Stack.#constructing = true;
        const s = new Stack(max, HeapCls);
        Stack.#constructing = false;
        return s;
    }
    constructor(max, HeapCls) {
        /* c8 ignore start */
        if (!Stack.#constructing) {
            throw new TypeError('instantiate Stack using Stack.create(n)');
        }
        /* c8 ignore stop */
        this.heap = new HeapCls(max);
        this.length = 0;
    }
    push(n) {
        this.heap[this.length++] = n;
    }
    pop() {
        return this.heap[--this.length];
    }
}
/**
 * Default export, the thing you're using this module to get.
 *
 * The `K` and `V` types define the key and value types, respectively. The
 * optional `FC` type defines the type of the `context` object passed to
 * `cache.fetch()` and `cache.memo()`.
 *
 * Keys and values **must not** be `null` or `undefined`.
 *
 * All properties from the options object (with the exception of `max`,
 * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are
 * added as normal public members. (The listed options are read-only getters.)
 *
 * Changing any of these will alter the defaults for subsequent method calls.
 */
class LRUCache {
    // options that cannot be changed without disaster
    #max;
    #maxSize;
    #dispose;
    #onInsert;
    #disposeAfter;
    #fetchMethod;
    #memoMethod;
    #perf;
    /**
     * {@link LRUCache.OptionsBase.perf}
     */
    get perf() {
        return this.#perf;
    }
    /**
     * {@link LRUCache.OptionsBase.ttl}
     */
    ttl;
    /**
     * {@link LRUCache.OptionsBase.ttlResolution}
     */
    ttlResolution;
    /**
     * {@link LRUCache.OptionsBase.ttlAutopurge}
     */
    ttlAutopurge;
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnGet}
     */
    updateAgeOnGet;
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnHas}
     */
    updateAgeOnHas;
    /**
     * {@link LRUCache.OptionsBase.allowStale}
     */
    allowStale;
    /**
     * {@link LRUCache.OptionsBase.noDisposeOnSet}
     */
    noDisposeOnSet;
    /**
     * {@link LRUCache.OptionsBase.noUpdateTTL}
     */
    noUpdateTTL;
    /**
     * {@link LRUCache.OptionsBase.maxEntrySize}
     */
    maxEntrySize;
    /**
     * {@link LRUCache.OptionsBase.sizeCalculation}
     */
    sizeCalculation;
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}
     */
    noDeleteOnFetchRejection;
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}
     */
    noDeleteOnStaleGet;
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}
     */
    allowStaleOnFetchAbort;
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}
     */
    allowStaleOnFetchRejection;
    /**
     * {@link LRUCache.OptionsBase.ignoreFetchAbort}
     */
    ignoreFetchAbort;
    // computed properties
    #size;
    #calculatedSize;
    #keyMap;
    #keyList;
    #valList;
    #next;
    #prev;
    #head;
    #tail;
    #free;
    #disposed;
    #sizes;
    #starts;
    #ttls;
    #hasDispose;
    #hasFetchMethod;
    #hasDisposeAfter;
    #hasOnInsert;
    /**
     * Do not call this method unless you need to inspect the
     * inner workings of the cache.  If anything returned by this
     * object is modified in any way, strange breakage may occur.
     *
     * These fields are private for a reason!
     *
     * @internal
     */
    static unsafeExposeInternals(c) {
        return {
            // properties
            starts: c.#starts,
            ttls: c.#ttls,
            sizes: c.#sizes,
            keyMap: c.#keyMap,
            keyList: c.#keyList,
            valList: c.#valList,
            next: c.#next,
            prev: c.#prev,
            get head() {
                return c.#head;
            },
            get tail() {
                return c.#tail;
            },
            free: c.#free,
            // methods
            isBackgroundFetch: (p) => c.#isBackgroundFetch(p),
            backgroundFetch: (k, index, options, context) => c.#backgroundFetch(k, index, options, context),
            moveToTail: (index) => c.#moveToTail(index),
            indexes: (options) => c.#indexes(options),
            rindexes: (options) => c.#rindexes(options),
            isStale: (index) => c.#isStale(index),
        };
    }
    // Protected read-only members
    /**
     * {@link LRUCache.OptionsBase.max} (read-only)
     */
    get max() {
        return this.#max;
    }
    /**
     * {@link LRUCache.OptionsBase.maxSize} (read-only)
     */
    get maxSize() {
        return this.#maxSize;
    }
    /**
     * The total computed size of items in the cache (read-only)
     */
    get calculatedSize() {
        return this.#calculatedSize;
    }
    /**
     * The number of items stored in the cache (read-only)
     */
    get size() {
        return this.#size;
    }
    /**
     * {@link LRUCache.OptionsBase.fetchMethod} (read-only)
     */
    get fetchMethod() {
        return this.#fetchMethod;
    }
    get memoMethod() {
        return this.#memoMethod;
    }
    /**
     * {@link LRUCache.OptionsBase.dispose} (read-only)
     */
    get dispose() {
        return this.#dispose;
    }
    /**
     * {@link LRUCache.OptionsBase.onInsert} (read-only)
     */
    get onInsert() {
        return this.#onInsert;
    }
    /**
     * {@link LRUCache.OptionsBase.disposeAfter} (read-only)
     */
    get disposeAfter() {
        return this.#disposeAfter;
    }
    constructor(options) {
        const { max = 0, ttl, ttlResolution = 1, ttlAutopurge, updateAgeOnGet, updateAgeOnHas, allowStale, dispose, onInsert, disposeAfter, noDisposeOnSet, noUpdateTTL, maxSize = 0, maxEntrySize = 0, sizeCalculation, fetchMethod, memoMethod, noDeleteOnFetchRejection, noDeleteOnStaleGet, allowStaleOnFetchRejection, allowStaleOnFetchAbort, ignoreFetchAbort, perf, } = options;
        if (perf !== undefined) {
            if (typeof perf?.now !== 'function') {
                throw new TypeError('perf option must have a now() method if specified');
            }
        }
        this.#perf = perf ?? defaultPerf;
        if (max !== 0 && !isPosInt(max)) {
            throw new TypeError('max option must be a nonnegative integer');
        }
        const UintArray = max ? getUintArray(max) : Array;
        if (!UintArray) {
            throw new Error('invalid max value: ' + max);
        }
        this.#max = max;
        this.#maxSize = maxSize;
        this.maxEntrySize = maxEntrySize || this.#maxSize;
        this.sizeCalculation = sizeCalculation;
        if (this.sizeCalculation) {
            if (!this.#maxSize && !this.maxEntrySize) {
                throw new TypeError('cannot set sizeCalculation without setting maxSize or maxEntrySize');
            }
            if (typeof this.sizeCalculation !== 'function') {
                throw new TypeError('sizeCalculation set to non-function');
            }
        }
        if (memoMethod !== undefined &&
            typeof memoMethod !== 'function') {
            throw new TypeError('memoMethod must be a function if defined');
        }
        this.#memoMethod = memoMethod;
        if (fetchMethod !== undefined &&
            typeof fetchMethod !== 'function') {
            throw new TypeError('fetchMethod must be a function if specified');
        }
        this.#fetchMethod = fetchMethod;
        this.#hasFetchMethod = !!fetchMethod;
        this.#keyMap = new Map();
        this.#keyList = new Array(max).fill(undefined);
        this.#valList = new Array(max).fill(undefined);
        this.#next = new UintArray(max);
        this.#prev = new UintArray(max);
        this.#head = 0;
        this.#tail = 0;
        this.#free = Stack.create(max);
        this.#size = 0;
        this.#calculatedSize = 0;
        if (typeof dispose === 'function') {
            this.#dispose = dispose;
        }
        if (typeof onInsert === 'function') {
            this.#onInsert = onInsert;
        }
        if (typeof disposeAfter === 'function') {
            this.#disposeAfter = disposeAfter;
            this.#disposed = [];
        }
        else {
            this.#disposeAfter = undefined;
            this.#disposed = undefined;
        }
        this.#hasDispose = !!this.#dispose;
        this.#hasOnInsert = !!this.#onInsert;
        this.#hasDisposeAfter = !!this.#disposeAfter;
        this.noDisposeOnSet = !!noDisposeOnSet;
        this.noUpdateTTL = !!noUpdateTTL;
        this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection;
        this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection;
        this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort;
        this.ignoreFetchAbort = !!ignoreFetchAbort;
        // NB: maxEntrySize is set to maxSize if it's set
        if (this.maxEntrySize !== 0) {
            if (this.#maxSize !== 0) {
                if (!isPosInt(this.#maxSize)) {
                    throw new TypeError('maxSize must be a positive integer if specified');
                }
            }
            if (!isPosInt(this.maxEntrySize)) {
                throw new TypeError('maxEntrySize must be a positive integer if specified');
            }
            this.#initializeSizeTracking();
        }
        this.allowStale = !!allowStale;
        this.noDeleteOnStaleGet = !!noDeleteOnStaleGet;
        this.updateAgeOnGet = !!updateAgeOnGet;
        this.updateAgeOnHas = !!updateAgeOnHas;
        this.ttlResolution =
            isPosInt(ttlResolution) || ttlResolution === 0 ?
                ttlResolution
                : 1;
        this.ttlAutopurge = !!ttlAutopurge;
        this.ttl = ttl || 0;
        if (this.ttl) {
            if (!isPosInt(this.ttl)) {
                throw new TypeError('ttl must be a positive integer if specified');
            }
            this.#initializeTTLTracking();
        }
        // do not allow completely unbounded caches
        if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {
            throw new TypeError('At least one of max, maxSize, or ttl is required');
        }
        if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {
            const code = 'LRU_CACHE_UNBOUNDED';
            if (shouldWarn(code)) {
                warned.add(code);
                const msg = 'TTL caching without ttlAutopurge, max, or maxSize can ' +
                    'result in unbounded memory consumption.';
                emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache);
            }
        }
    }
    /**
     * Return the number of ms left in the item's TTL. If item is not in cache,
     * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.
     */
    getRemainingTTL(key) {
        return this.#keyMap.has(key) ? Infinity : 0;
    }
    #initializeTTLTracking() {
        const ttls = new ZeroArray(this.#max);
        const starts = new ZeroArray(this.#max);
        this.#ttls = ttls;
        this.#starts = starts;
        this.#setItemTTL = (index, ttl, start = this.#perf.now()) => {
            starts[index] = ttl !== 0 ? start : 0;
            ttls[index] = ttl;
            if (ttl !== 0 && this.ttlAutopurge) {
                const t = setTimeout(() => {
                    if (this.#isStale(index)) {
                        this.#delete(this.#keyList[index], 'expire');
                    }
                }, ttl + 1);
                // unref() not supported on all platforms
                /* c8 ignore start */
                if (t.unref) {
                    t.unref();
                }
                /* c8 ignore stop */
            }
        };
        this.#updateItemAge = index => {
            starts[index] = ttls[index] !== 0 ? this.#perf.now() : 0;
        };
        this.#statusTTL = (status, index) => {
            if (ttls[index]) {
                const ttl = ttls[index];
                const start = starts[index];
                /* c8 ignore next */
                if (!ttl || !start)
                    return;
                status.ttl = ttl;
                status.start = start;
                status.now = cachedNow || getNow();
                const age = status.now - start;
                status.remainingTTL = ttl - age;
            }
        };
        // debounce calls to perf.now() to 1s so we're not hitting
        // that costly call repeatedly.
        let cachedNow = 0;
        const getNow = () => {
            const n = this.#perf.now();
            if (this.ttlResolution > 0) {
                cachedNow = n;
                const t = setTimeout(() => (cachedNow = 0), this.ttlResolution);
                // not available on all platforms
                /* c8 ignore start */
                if (t.unref) {
                    t.unref();
                }
                /* c8 ignore stop */
            }
            return n;
        };
        this.getRemainingTTL = key => {
            const index = this.#keyMap.get(key);
            if (index === undefined) {
                return 0;
            }
            const ttl = ttls[index];
            const start = starts[index];
            if (!ttl || !start) {
                return Infinity;
            }
            const age = (cachedNow || getNow()) - start;
            return ttl - age;
        };
        this.#isStale = index => {
            const s = starts[index];
            const t = ttls[index];
            return !!t && !!s && (cachedNow || getNow()) - s > t;
        };
    }
    // conditionally set private methods related to TTL
    #updateItemAge = () => { };
    #statusTTL = () => { };
    #setItemTTL = () => { };
    /* c8 ignore stop */
    #isStale = () => false;
    #initializeSizeTracking() {
        const sizes = new ZeroArray(this.#max);
        this.#calculatedSize = 0;
        this.#sizes = sizes;
        this.#removeItemSize = index => {
            this.#calculatedSize -= sizes[index];
            sizes[index] = 0;
        };
        this.#requireSize = (k, v, size, sizeCalculation) => {
            // provisionally accept background fetches.
            // actual value size will be checked when they return.
            if (this.#isBackgroundFetch(v)) {
                return 0;
            }
            if (!isPosInt(size)) {
                if (sizeCalculation) {
                    if (typeof sizeCalculation !== 'function') {
                        throw new TypeError('sizeCalculation must be a function');
                    }
                    size = sizeCalculation(v, k);
                    if (!isPosInt(size)) {
                        throw new TypeError('sizeCalculation return invalid (expect positive integer)');
                    }
                }
                else {
                    throw new TypeError('invalid size value (must be positive integer). ' +
                        'When maxSize or maxEntrySize is used, sizeCalculation ' +
                        'or size must be set.');
                }
            }
            return size;
        };
        this.#addItemSize = (index, size, status) => {
            sizes[index] = size;
            if (this.#maxSize) {
                const maxSize = this.#maxSize - sizes[index];
                while (this.#calculatedSize > maxSize) {
                    this.#evict(true);
                }
            }
            this.#calculatedSize += sizes[index];
            if (status) {
                status.entrySize = size;
                status.totalCalculatedSize = this.#calculatedSize;
            }
        };
    }
    #removeItemSize = _i => { };
    #addItemSize = (_i, _s, _st) => { };
    #requireSize = (_k, _v, size, sizeCalculation) => {
        if (size || sizeCalculation) {
            throw new TypeError('cannot set size without setting maxSize or maxEntrySize on cache');
        }
        return 0;
    };
    *#indexes({ allowStale = this.allowStale } = {}) {
        if (this.#size) {
            for (let i = this.#tail; true;) {
                if (!this.#isValidIndex(i)) {
                    break;
                }
                if (allowStale || !this.#isStale(i)) {
                    yield i;
                }
                if (i === this.#head) {
                    break;
                }
                else {
                    i = this.#prev[i];
                }
            }
        }
    }
    *#rindexes({ allowStale = this.allowStale } = {}) {
        if (this.#size) {
            for (let i = this.#head; true;) {
                if (!this.#isValidIndex(i)) {
                    break;
                }
                if (allowStale || !this.#isStale(i)) {
                    yield i;
                }
                if (i === this.#tail) {
                    break;
                }
                else {
                    i = this.#next[i];
                }
            }
        }
    }
    #isValidIndex(index) {
        return (index !== undefined &&
            this.#keyMap.get(this.#keyList[index]) === index);
    }
    /**
     * Return a generator yielding `[key, value]` pairs,
     * in order from most recently used to least recently used.
     */
    *entries() {
        for (const i of this.#indexes()) {
            if (this.#valList[i] !== undefined &&
                this.#keyList[i] !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield [this.#keyList[i], this.#valList[i]];
            }
        }
    }
    /**
     * Inverse order version of {@link LRUCache.entries}
     *
     * Return a generator yielding `[key, value]` pairs,
     * in order from least recently used to most recently used.
     */
    *rentries() {
        for (const i of this.#rindexes()) {
            if (this.#valList[i] !== undefined &&
                this.#keyList[i] !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield [this.#keyList[i], this.#valList[i]];
            }
        }
    }
    /**
     * Return a generator yielding the keys in the cache,
     * in order from most recently used to least recently used.
     */
    *keys() {
        for (const i of this.#indexes()) {
            const k = this.#keyList[i];
            if (k !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield k;
            }
        }
    }
    /**
     * Inverse order version of {@link LRUCache.keys}
     *
     * Return a generator yielding the keys in the cache,
     * in order from least recently used to most recently used.
     */
    *rkeys() {
        for (const i of this.#rindexes()) {
            const k = this.#keyList[i];
            if (k !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield k;
            }
        }
    }
    /**
     * Return a generator yielding the values in the cache,
     * in order from most recently used to least recently used.
     */
    *values() {
        for (const i of this.#indexes()) {
            const v = this.#valList[i];
            if (v !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield this.#valList[i];
            }
        }
    }
    /**
     * Inverse order version of {@link LRUCache.values}
     *
     * Return a generator yielding the values in the cache,
     * in order from least recently used to most recently used.
     */
    *rvalues() {
        for (const i of this.#rindexes()) {
            const v = this.#valList[i];
            if (v !== undefined &&
                !this.#isBackgroundFetch(this.#valList[i])) {
                yield this.#valList[i];
            }
        }
    }
    /**
     * Iterating over the cache itself yields the same results as
     * {@link LRUCache.entries}
     */
    [Symbol.iterator]() {
        return this.entries();
    }
    /**
     * A String value that is used in the creation of the default string
     * description of an object. Called by the built-in method
     * `Object.prototype.toString`.
     */
    [Symbol.toStringTag] = 'LRUCache';
    /**
     * Find a value for which the supplied fn method returns a truthy value,
     * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.
     */
    find(fn, getOptions = {}) {
        for (const i of this.#indexes()) {
            const v = this.#valList[i];
            const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
            if (value === undefined)
                continue;
            if (fn(value, this.#keyList[i], this)) {
                return this.get(this.#keyList[i], getOptions);
            }
        }
    }
    /**
     * Call the supplied function on each item in the cache, in order from most
     * recently used to least recently used.
     *
     * `fn` is called as `fn(value, key, cache)`.
     *
     * If `thisp` is provided, function will be called in the `this`-context of
     * the provided object, or the cache if no `thisp` object is provided.
     *
     * Does not update age or recenty of use, or iterate over stale values.
     */
    forEach(fn, thisp = this) {
        for (const i of this.#indexes()) {
            const v = this.#valList[i];
            const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
            if (value === undefined)
                continue;
            fn.call(thisp, value, this.#keyList[i], this);
        }
    }
    /**
     * The same as {@link LRUCache.forEach} but items are iterated over in
     * reverse order.  (ie, less recently used items are iterated over first.)
     */
    rforEach(fn, thisp = this) {
        for (const i of this.#rindexes()) {
            const v = this.#valList[i];
            const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
            if (value === undefined)
                continue;
            fn.call(thisp, value, this.#keyList[i], this);
        }
    }
    /**
     * Delete any stale entries. Returns true if anything was removed,
     * false otherwise.
     */
    purgeStale() {
        let deleted = false;
        for (const i of this.#rindexes({ allowStale: true })) {
            if (this.#isStale(i)) {
                this.#delete(this.#keyList[i], 'expire');
                deleted = true;
            }
        }
        return deleted;
    }
    /**
     * Get the extended info about a given entry, to get its value, size, and
     * TTL info simultaneously. Returns `undefined` if the key is not present.
     *
     * Unlike {@link LRUCache#dump}, which is designed to be portable and survive
     * serialization, the `start` value is always the current timestamp, and the
     * `ttl` is a calculated remaining time to live (negative if expired).
     *
     * Always returns stale values, if their info is found in the cache, so be
     * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})
     * if relevant.
     */
    info(key) {
        const i = this.#keyMap.get(key);
        if (i === undefined)
            return undefined;
        const v = this.#valList[i];
        /* c8 ignore start - this isn't tested for the info function,
         * but it's the same logic as found in other places. */
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
        if (value === undefined)
            return undefined;
        /* c8 ignore end */
        const entry = { value };
        if (this.#ttls && this.#starts) {
            const ttl = this.#ttls[i];
            const start = this.#starts[i];
            if (ttl && start) {
                const remain = ttl - (this.#perf.now() - start);
                entry.ttl = remain;
                entry.start = Date.now();
            }
        }
        if (this.#sizes) {
            entry.size = this.#sizes[i];
        }
        return entry;
    }
    /**
     * Return an array of [key, {@link LRUCache.Entry}] tuples which can be
     * passed to {@link LRUCache#load}.
     *
     * The `start` fields are calculated relative to a portable `Date.now()`
     * timestamp, even if `performance.now()` is available.
     *
     * Stale entries are always included in the `dump`, even if
     * {@link LRUCache.OptionsBase.allowStale} is false.
     *
     * Note: this returns an actual array, not a generator, so it can be more
     * easily passed around.
     */
    dump() {
        const arr = [];
        for (const i of this.#indexes({ allowStale: true })) {
            const key = this.#keyList[i];
            const v = this.#valList[i];
            const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
            if (value === undefined || key === undefined)
                continue;
            const entry = { value };
            if (this.#ttls && this.#starts) {
                entry.ttl = this.#ttls[i];
                // always dump the start relative to a portable timestamp
                // it's ok for this to be a bit slow, it's a rare operation.
                const age = this.#perf.now() - this.#starts[i];
                entry.start = Math.floor(Date.now() - age);
            }
            if (this.#sizes) {
                entry.size = this.#sizes[i];
            }
            arr.unshift([key, entry]);
        }
        return arr;
    }
    /**
     * Reset the cache and load in the items in entries in the order listed.
     *
     * The shape of the resulting cache may be different if the same options are
     * not used in both caches.
     *
     * The `start` fields are assumed to be calculated relative to a portable
     * `Date.now()` timestamp, even if `performance.now()` is available.
     */
    load(arr) {
        this.clear();
        for (const [key, entry] of arr) {
            if (entry.start) {
                // entry.start is a portable timestamp, but we may be using
                // node's performance.now(), so calculate the offset, so that
                // we get the intended remaining TTL, no matter how long it's
                // been on ice.
                //
                // it's ok for this to be a bit slow, it's a rare operation.
                const age = Date.now() - entry.start;
                entry.start = this.#perf.now() - age;
            }
            this.set(key, entry.value, entry);
        }
    }
    /**
     * Add a value to the cache.
     *
     * Note: if `undefined` is specified as a value, this is an alias for
     * {@link LRUCache#delete}
     *
     * Fields on the {@link LRUCache.SetOptions} options param will override
     * their corresponding values in the constructor options for the scope
     * of this single `set()` operation.
     *
     * If `start` is provided, then that will set the effective start
     * time for the TTL calculation. Note that this must be a previous
     * value of `performance.now()` if supported, or a previous value of
     * `Date.now()` if not.
     *
     * Options object may also include `size`, which will prevent
     * calling the `sizeCalculation` function and just use the specified
     * number if it is a positive integer, and `noDisposeOnSet` which
     * will prevent calling a `dispose` function in the case of
     * overwrites.
     *
     * If the `size` (or return value of `sizeCalculation`) for a given
     * entry is greater than `maxEntrySize`, then the item will not be
     * added to the cache.
     *
     * Will update the recency of the entry.
     *
     * If the value is `undefined`, then this is an alias for
     * `cache.delete(key)`. `undefined` is never stored in the cache.
     */
    set(k, v, setOptions = {}) {
        if (v === undefined) {
            this.delete(k);
            return this;
        }
        const { ttl = this.ttl, start, noDisposeOnSet = this.noDisposeOnSet, sizeCalculation = this.sizeCalculation, status, } = setOptions;
        let { noUpdateTTL = this.noUpdateTTL } = setOptions;
        const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation);
        // if the item doesn't fit, don't do anything
        // NB: maxEntrySize set to maxSize by default
        if (this.maxEntrySize && size > this.maxEntrySize) {
            if (status) {
                status.set = 'miss';
                status.maxEntrySizeExceeded = true;
            }
            // have to delete, in case something is there already.
            this.#delete(k, 'set');
            return this;
        }
        let index = this.#size === 0 ? undefined : this.#keyMap.get(k);
        if (index === undefined) {
            // addition
            index = (this.#size === 0 ? this.#tail
                : this.#free.length !== 0 ? this.#free.pop()
                    : this.#size === this.#max ? this.#evict(false)
                        : this.#size);
            this.#keyList[index] = k;
            this.#valList[index] = v;
            this.#keyMap.set(k, index);
            this.#next[this.#tail] = index;
            this.#prev[index] = this.#tail;
            this.#tail = index;
            this.#size++;
            this.#addItemSize(index, size, status);
            if (status)
                status.set = 'add';
            noUpdateTTL = false;
            if (this.#hasOnInsert) {
                this.#onInsert?.(v, k, 'add');
            }
        }
        else {
            // update
            this.#moveToTail(index);
            const oldVal = this.#valList[index];
            if (v !== oldVal) {
                if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {
                    oldVal.__abortController.abort(new Error('replaced'));
                    const { __staleWhileFetching: s } = oldVal;
                    if (s !== undefined && !noDisposeOnSet) {
                        if (this.#hasDispose) {
                            this.#dispose?.(s, k, 'set');
                        }
                        if (this.#hasDisposeAfter) {
                            this.#disposed?.push([s, k, 'set']);
                        }
                    }
                }
                else if (!noDisposeOnSet) {
                    if (this.#hasDispose) {
                        this.#dispose?.(oldVal, k, 'set');
                    }
                    if (this.#hasDisposeAfter) {
                        this.#disposed?.push([oldVal, k, 'set']);
                    }
                }
                this.#removeItemSize(index);
                this.#addItemSize(index, size, status);
                this.#valList[index] = v;
                if (status) {
                    status.set = 'replace';
                    const oldValue = oldVal && this.#isBackgroundFetch(oldVal) ?
                        oldVal.__staleWhileFetching
                        : oldVal;
                    if (oldValue !== undefined)
                        status.oldValue = oldValue;
                }
            }
            else if (status) {
                status.set = 'update';
            }
            if (this.#hasOnInsert) {
                this.onInsert?.(v, k, v === oldVal ? 'update' : 'replace');
            }
        }
        if (ttl !== 0 && !this.#ttls) {
            this.#initializeTTLTracking();
        }
        if (this.#ttls) {
            if (!noUpdateTTL) {
                this.#setItemTTL(index, ttl, start);
            }
            if (status)
                this.#statusTTL(status, index);
        }
        if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {
            const dt = this.#disposed;
            let task;
            while ((task = dt?.shift())) {
                this.#disposeAfter?.(...task);
            }
        }
        return this;
    }
    /**
     * Evict the least recently used item, returning its value or
     * `undefined` if cache is empty.
     */
    pop() {
        try {
            while (this.#size) {
                const val = this.#valList[this.#head];
                this.#evict(true);
                if (this.#isBackgroundFetch(val)) {
                    if (val.__staleWhileFetching) {
                        return val.__staleWhileFetching;
                    }
                }
                else if (val !== undefined) {
                    return val;
                }
            }
        }
        finally {
            if (this.#hasDisposeAfter && this.#disposed) {
                const dt = this.#disposed;
                let task;
                while ((task = dt?.shift())) {
                    this.#disposeAfter?.(...task);
                }
            }
        }
    }
    #evict(free) {
        const head = this.#head;
        const k = this.#keyList[head];
        const v = this.#valList[head];
        if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {
            v.__abortController.abort(new Error('evicted'));
        }
        else if (this.#hasDispose || this.#hasDisposeAfter) {
            if (this.#hasDispose) {
                this.#dispose?.(v, k, 'evict');
            }
            if (this.#hasDisposeAfter) {
                this.#disposed?.push([v, k, 'evict']);
            }
        }
        this.#removeItemSize(head);
        // if we aren't about to use the index, then null these out
        if (free) {
            this.#keyList[head] = undefined;
            this.#valList[head] = undefined;
            this.#free.push(head);
        }
        if (this.#size === 1) {
            this.#head = this.#tail = 0;
            this.#free.length = 0;
        }
        else {
            this.#head = this.#next[head];
        }
        this.#keyMap.delete(k);
        this.#size--;
        return head;
    }
    /**
     * Check if a key is in the cache, without updating the recency of use.
     * Will return false if the item is stale, even though it is technically
     * in the cache.
     *
     * Check if a key is in the cache, without updating the recency of
     * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set
     * to `true` in either the options or the constructor.
     *
     * Will return `false` if the item is stale, even though it is technically in
     * the cache. The difference can be determined (if it matters) by using a
     * `status` argument, and inspecting the `has` field.
     *
     * Will not update item age unless
     * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.
     */
    has(k, hasOptions = {}) {
        const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions;
        const index = this.#keyMap.get(k);
        if (index !== undefined) {
            const v = this.#valList[index];
            if (this.#isBackgroundFetch(v) &&
                v.__staleWhileFetching === undefined) {
                return false;
            }
            if (!this.#isStale(index)) {
                if (updateAgeOnHas) {
                    this.#updateItemAge(index);
                }
                if (status) {
                    status.has = 'hit';
                    this.#statusTTL(status, index);
                }
                return true;
            }
            else if (status) {
                status.has = 'stale';
                this.#statusTTL(status, index);
            }
        }
        else if (status) {
            status.has = 'miss';
        }
        return false;
    }
    /**
     * Like {@link LRUCache#get} but doesn't update recency or delete stale
     * items.
     *
     * Returns `undefined` if the item is stale, unless
     * {@link LRUCache.OptionsBase.allowStale} is set.
     */
    peek(k, peekOptions = {}) {
        const { allowStale = this.allowStale } = peekOptions;
        const index = this.#keyMap.get(k);
        if (index === undefined ||
            (!allowStale && this.#isStale(index))) {
            return;
        }
        const v = this.#valList[index];
        // either stale and allowed, or forcing a refresh of non-stale value
        return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
    }
    #backgroundFetch(k, index, options, context) {
        const v = index === undefined ? undefined : this.#valList[index];
        if (this.#isBackgroundFetch(v)) {
            return v;
        }
        const ac = new AC();
        const { signal } = options;
        // when/if our AC signals, then stop listening to theirs.
        signal?.addEventListener('abort', () => ac.abort(signal.reason), {
            signal: ac.signal,
        });
        const fetchOpts = {
            signal: ac.signal,
            options,
            context,
        };
        const cb = (v, updateCache = false) => {
            const { aborted } = ac.signal;
            const ignoreAbort = options.ignoreFetchAbort && v !== undefined;
            if (options.status) {
                if (aborted && !updateCache) {
                    options.status.fetchAborted = true;
                    options.status.fetchError = ac.signal.reason;
                    if (ignoreAbort)
                        options.status.fetchAbortIgnored = true;
                }
                else {
                    options.status.fetchResolved = true;
                }
            }
            if (aborted && !ignoreAbort && !updateCache) {
                return fetchFail(ac.signal.reason);
            }
            // either we didn't abort, and are still here, or we did, and ignored
            const bf = p;
            // if nothing else has been written there but we're set to update the
            // cache and ignore the abort, or if it's still pending on this specific
            // background request, then write it to the cache.
            const vl = this.#valList[index];
            if (vl === p || ignoreAbort && updateCache && vl === undefined) {
                if (v === undefined) {
                    if (bf.__staleWhileFetching !== undefined) {
                        this.#valList[index] = bf.__staleWhileFetching;
                    }
                    else {
                        this.#delete(k, 'fetch');
                    }
                }
                else {
                    if (options.status)
                        options.status.fetchUpdated = true;
                    this.set(k, v, fetchOpts.options);
                }
            }
            return v;
        };
        const eb = (er) => {
            if (options.status) {
                options.status.fetchRejected = true;
                options.status.fetchError = er;
            }
            return fetchFail(er);
        };
        const fetchFail = (er) => {
            const { aborted } = ac.signal;
            const allowStaleAborted = aborted && options.allowStaleOnFetchAbort;
            const allowStale = allowStaleAborted || options.allowStaleOnFetchRejection;
            const noDelete = allowStale || options.noDeleteOnFetchRejection;
            const bf = p;
            if (this.#valList[index] === p) {
                // if we allow stale on fetch rejections, then we need to ensure that
                // the stale value is not removed from the cache when the fetch fails.
                const del = !noDelete || bf.__staleWhileFetching === undefined;
                if (del) {
                    this.#delete(k, 'fetch');
                }
                else if (!allowStaleAborted) {
                    // still replace the *promise* with the stale value,
                    // since we are done with the promise at this point.
                    // leave it untouched if we're still waiting for an
                    // aborted background fetch that hasn't yet returned.
                    this.#valList[index] = bf.__staleWhileFetching;
                }
            }
            if (allowStale) {
                if (options.status && bf.__staleWhileFetching !== undefined) {
                    options.status.returnedStale = true;
                }
                return bf.__staleWhileFetching;
            }
            else if (bf.__returned === bf) {
                throw er;
            }
        };
        const pcall = (res, rej) => {
            const fmp = this.#fetchMethod?.(k, v, fetchOpts);
            if (fmp && fmp instanceof Promise) {
                fmp.then(v => res(v === undefined ? undefined : v), rej);
            }
            // ignored, we go until we finish, regardless.
            // defer check until we are actually aborting,
            // so fetchMethod can override.
            ac.signal.addEventListener('abort', () => {
                if (!options.ignoreFetchAbort ||
                    options.allowStaleOnFetchAbort) {
                    res(undefined);
                    // when it eventually resolves, update the cache.
                    if (options.allowStaleOnFetchAbort) {
                        res = v => cb(v, true);
                    }
                }
            });
        };
        if (options.status)
            options.status.fetchDispatched = true;
        const p = new Promise(pcall).then(cb, eb);
        const bf = Object.assign(p, {
            __abortController: ac,
            __staleWhileFetching: v,
            __returned: undefined,
        });
        if (index === undefined) {
            // internal, don't expose status.
            this.set(k, bf, { ...fetchOpts.options, status: undefined });
            index = this.#keyMap.get(k);
        }
        else {
            this.#valList[index] = bf;
        }
        return bf;
    }
    #isBackgroundFetch(p) {
        if (!this.#hasFetchMethod)
            return false;
        const b = p;
        return (!!b &&
            b instanceof Promise &&
            b.hasOwnProperty('__staleWhileFetching') &&
            b.__abortController instanceof AC);
    }
    async fetch(k, fetchOptions = {}) {
        const { 
        // get options
        allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, 
        // set options
        ttl = this.ttl, noDisposeOnSet = this.noDisposeOnSet, size = 0, sizeCalculation = this.sizeCalculation, noUpdateTTL = this.noUpdateTTL, 
        // fetch exclusive options
        noDeleteOnFetchRejection = this.noDeleteOnFetchRejection, allowStaleOnFetchRejection = this.allowStaleOnFetchRejection, ignoreFetchAbort = this.ignoreFetchAbort, allowStaleOnFetchAbort = this.allowStaleOnFetchAbort, context, forceRefresh = false, status, signal, } = fetchOptions;
        if (!this.#hasFetchMethod) {
            if (status)
                status.fetch = 'get';
            return this.get(k, {
                allowStale,
                updateAgeOnGet,
                noDeleteOnStaleGet,
                status,
            });
        }
        const options = {
            allowStale,
            updateAgeOnGet,
            noDeleteOnStaleGet,
            ttl,
            noDisposeOnSet,
            size,
            sizeCalculation,
            noUpdateTTL,
            noDeleteOnFetchRejection,
            allowStaleOnFetchRejection,
            allowStaleOnFetchAbort,
            ignoreFetchAbort,
            status,
            signal,
        };
        let index = this.#keyMap.get(k);
        if (index === undefined) {
            if (status)
                status.fetch = 'miss';
            const p = this.#backgroundFetch(k, index, options, context);
            return (p.__returned = p);
        }
        else {
            // in cache, maybe already fetching
            const v = this.#valList[index];
            if (this.#isBackgroundFetch(v)) {
                const stale = allowStale && v.__staleWhileFetching !== undefined;
                if (status) {
                    status.fetch = 'inflight';
                    if (stale)
                        status.returnedStale = true;
                }
                return stale ? v.__staleWhileFetching : (v.__returned = v);
            }
            // if we force a refresh, that means do NOT serve the cached value,
            // unless we are already in the process of refreshing the cache.
            const isStale = this.#isStale(index);
            if (!forceRefresh && !isStale) {
                if (status)
                    status.fetch = 'hit';
                this.#moveToTail(index);
                if (updateAgeOnGet) {
                    this.#updateItemAge(index);
                }
                if (status)
                    this.#statusTTL(status, index);
                return v;
            }
            // ok, it is stale or a forced refresh, and not already fetching.
            // refresh the cache.
            const p = this.#backgroundFetch(k, index, options, context);
            const hasStale = p.__staleWhileFetching !== undefined;
            const staleVal = hasStale && allowStale;
            if (status) {
                status.fetch = isStale ? 'stale' : 'refresh';
                if (staleVal && isStale)
                    status.returnedStale = true;
            }
            return staleVal ? p.__staleWhileFetching : (p.__returned = p);
        }
    }
    async forceFetch(k, fetchOptions = {}) {
        const v = await this.fetch(k, fetchOptions);
        if (v === undefined)
            throw new Error('fetch() returned undefined');
        return v;
    }
    memo(k, memoOptions = {}) {
        const memoMethod = this.#memoMethod;
        if (!memoMethod) {
            throw new Error('no memoMethod provided to constructor');
        }
        const { context, forceRefresh, ...options } = memoOptions;
        const v = this.get(k, options);
        if (!forceRefresh && v !== undefined)
            return v;
        const vv = memoMethod(k, v, {
            options,
            context,
        });
        this.set(k, vv, options);
        return vv;
    }
    /**
     * Return a value from the cache. Will update the recency of the cache
     * entry found.
     *
     * If the key is not found, get() will return `undefined`.
     */
    get(k, getOptions = {}) {
        const { allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, status, } = getOptions;
        const index = this.#keyMap.get(k);
        if (index !== undefined) {
            const value = this.#valList[index];
            const fetching = this.#isBackgroundFetch(value);
            if (status)
                this.#statusTTL(status, index);
            if (this.#isStale(index)) {
                if (status)
                    status.get = 'stale';
                // delete only if not an in-flight background fetch
                if (!fetching) {
                    if (!noDeleteOnStaleGet) {
                        this.#delete(k, 'expire');
                    }
                    if (status && allowStale)
                        status.returnedStale = true;
                    return allowStale ? value : undefined;
                }
                else {
                    if (status &&
                        allowStale &&
                        value.__staleWhileFetching !== undefined) {
                        status.returnedStale = true;
                    }
                    return allowStale ? value.__staleWhileFetching : undefined;
                }
            }
            else {
                if (status)
                    status.get = 'hit';
                // if we're currently fetching it, we don't actually have it yet
                // it's not stale, which means this isn't a staleWhileRefetching.
                // If it's not stale, and fetching, AND has a __staleWhileFetching
                // value, then that means the user fetched with {forceRefresh:true},
                // so it's safe to return that value.
                if (fetching) {
                    return value.__staleWhileFetching;
                }
                this.#moveToTail(index);
                if (updateAgeOnGet) {
                    this.#updateItemAge(index);
                }
                return value;
            }
        }
        else if (status) {
            status.get = 'miss';
        }
    }
    #connect(p, n) {
        this.#prev[n] = p;
        this.#next[p] = n;
    }
    #moveToTail(index) {
        // if tail already, nothing to do
        // if head, move head to next[index]
        // else
        //   move next[prev[index]] to next[index] (head has no prev)
        //   move prev[next[index]] to prev[index]
        // prev[index] = tail
        // next[tail] = index
        // tail = index
        if (index !== this.#tail) {
            if (index === this.#head) {
                this.#head = this.#next[index];
            }
            else {
                this.#connect(this.#prev[index], this.#next[index]);
            }
            this.#connect(this.#tail, index);
            this.#tail = index;
        }
    }
    /**
     * Deletes a key out of the cache.
     *
     * Returns true if the key was deleted, false otherwise.
     */
    delete(k) {
        return this.#delete(k, 'delete');
    }
    #delete(k, reason) {
        let deleted = false;
        if (this.#size !== 0) {
            const index = this.#keyMap.get(k);
            if (index !== undefined) {
                deleted = true;
                if (this.#size === 1) {
                    this.#clear(reason);
                }
                else {
                    this.#removeItemSize(index);
                    const v = this.#valList[index];
                    if (this.#isBackgroundFetch(v)) {
                        v.__abortController.abort(new Error('deleted'));
                    }
                    else if (this.#hasDispose || this.#hasDisposeAfter) {
                        if (this.#hasDispose) {
                            this.#dispose?.(v, k, reason);
                        }
                        if (this.#hasDisposeAfter) {
                            this.#disposed?.push([v, k, reason]);
                        }
                    }
                    this.#keyMap.delete(k);
                    this.#keyList[index] = undefined;
                    this.#valList[index] = undefined;
                    if (index === this.#tail) {
                        this.#tail = this.#prev[index];
                    }
                    else if (index === this.#head) {
                        this.#head = this.#next[index];
                    }
                    else {
                        const pi = this.#prev[index];
                        this.#next[pi] = this.#next[index];
                        const ni = this.#next[index];
                        this.#prev[ni] = this.#prev[index];
                    }
                    this.#size--;
                    this.#free.push(index);
                }
            }
        }
        if (this.#hasDisposeAfter && this.#disposed?.length) {
            const dt = this.#disposed;
            let task;
            while ((task = dt?.shift())) {
                this.#disposeAfter?.(...task);
            }
        }
        return deleted;
    }
    /**
     * Clear the cache entirely, throwing away all values.
     */
    clear() {
        return this.#clear('delete');
    }
    #clear(reason) {
        for (const index of this.#rindexes({ allowStale: true })) {
            const v = this.#valList[index];
            if (this.#isBackgroundFetch(v)) {
                v.__abortController.abort(new Error('deleted'));
            }
            else {
                const k = this.#keyList[index];
                if (this.#hasDispose) {
                    this.#dispose?.(v, k, reason);
                }
                if (this.#hasDisposeAfter) {
                    this.#disposed?.push([v, k, reason]);
                }
            }
        }
        this.#keyMap.clear();
        this.#valList.fill(undefined);
        this.#keyList.fill(undefined);
        if (this.#ttls && this.#starts) {
            this.#ttls.fill(0);
            this.#starts.fill(0);
        }
        if (this.#sizes) {
            this.#sizes.fill(0);
        }
        this.#head = 0;
        this.#tail = 0;
        this.#free.length = 0;
        this.#calculatedSize = 0;
        this.#size = 0;
        if (this.#hasDisposeAfter && this.#disposed) {
            const dt = this.#disposed;
            let task;
            while ((task = dt?.shift())) {
                this.#disposeAfter?.(...task);
            }
        }
    }
}

const proc = typeof process === 'object' && process
    ? process
    : {
        stdout: null,
        stderr: null,
    };
/**
 * Return true if the argument is a Minipass stream, Node stream, or something
 * else that Minipass can interact with.
 */
const isStream = (s) => !!s &&
    typeof s === 'object' &&
    (s instanceof Minipass ||
        s instanceof Stream ||
        isReadable(s) ||
        isWritable(s));
/**
 * Return true if the argument is a valid {@link Minipass.Readable}
 */
const isReadable = (s) => !!s &&
    typeof s === 'object' &&
    s instanceof EventEmitter$1 &&
    typeof s.pipe === 'function' &&
    // node core Writable streams have a pipe() method, but it throws
    s.pipe !== Stream.Writable.prototype.pipe;
/**
 * Return true if the argument is a valid {@link Minipass.Writable}
 */
const isWritable = (s) => !!s &&
    typeof s === 'object' &&
    s instanceof EventEmitter$1 &&
    typeof s.write === 'function' &&
    typeof s.end === 'function';
const EOF = Symbol('EOF');
const MAYBE_EMIT_END = Symbol('maybeEmitEnd');
const EMITTED_END = Symbol('emittedEnd');
const EMITTING_END = Symbol('emittingEnd');
const EMITTED_ERROR = Symbol('emittedError');
const CLOSED = Symbol('closed');
const READ = Symbol('read');
const FLUSH = Symbol('flush');
const FLUSHCHUNK = Symbol('flushChunk');
const ENCODING = Symbol('encoding');
const DECODER = Symbol('decoder');
const FLOWING = Symbol('flowing');
const PAUSED = Symbol('paused');
const RESUME = Symbol('resume');
const BUFFER = Symbol('buffer');
const PIPES = Symbol('pipes');
const BUFFERLENGTH = Symbol('bufferLength');
const BUFFERPUSH = Symbol('bufferPush');
const BUFFERSHIFT = Symbol('bufferShift');
const OBJECTMODE = Symbol('objectMode');
// internal event when stream is destroyed
const DESTROYED = Symbol('destroyed');
// internal event when stream has an error
const ERROR = Symbol('error');
const EMITDATA = Symbol('emitData');
const EMITEND = Symbol('emitEnd');
const EMITEND2 = Symbol('emitEnd2');
const ASYNC = Symbol('async');
const ABORT = Symbol('abort');
const ABORTED = Symbol('aborted');
const SIGNAL = Symbol('signal');
const DATALISTENERS = Symbol('dataListeners');
const DISCARDED = Symbol('discarded');
const defer = (fn) => Promise.resolve().then(fn);
const nodefer = (fn) => fn();
const isEndish = (ev) => ev === 'end' || ev === 'finish' || ev === 'prefinish';
const isArrayBufferLike = (b) => b instanceof ArrayBuffer ||
    (!!b &&
        typeof b === 'object' &&
        b.constructor &&
        b.constructor.name === 'ArrayBuffer' &&
        b.byteLength >= 0);
const isArrayBufferView = (b) => !Buffer.isBuffer(b) && ArrayBuffer.isView(b);
/**
 * Internal class representing a pipe to a destination stream.
 *
 * @internal
 */
class Pipe {
    src;
    dest;
    opts;
    ondrain;
    constructor(src, dest, opts) {
        this.src = src;
        this.dest = dest;
        this.opts = opts;
        this.ondrain = () => src[RESUME]();
        this.dest.on('drain', this.ondrain);
    }
    unpipe() {
        this.dest.removeListener('drain', this.ondrain);
    }
    // only here for the prototype
    /* c8 ignore start */
    proxyErrors(_er) { }
    /* c8 ignore stop */
    end() {
        this.unpipe();
        if (this.opts.end)
            this.dest.end();
    }
}
/**
 * Internal class representing a pipe to a destination stream where
 * errors are proxied.
 *
 * @internal
 */
class PipeProxyErrors extends Pipe {
    unpipe() {
        this.src.removeListener('error', this.proxyErrors);
        super.unpipe();
    }
    constructor(src, dest, opts) {
        super(src, dest, opts);
        this.proxyErrors = er => dest.emit('error', er);
        src.on('error', this.proxyErrors);
    }
}
const isObjectModeOptions = (o) => !!o.objectMode;
const isEncodingOptions = (o) => !o.objectMode && !!o.encoding && o.encoding !== 'buffer';
/**
 * Main export, the Minipass class
 *
 * `RType` is the type of data emitted, defaults to Buffer
 *
 * `WType` is the type of data to be written, if RType is buffer or string,
 * then any {@link Minipass.ContiguousData} is allowed.
 *
 * `Events` is the set of event handler signatures that this object
 * will emit, see {@link Minipass.Events}
 */
class Minipass extends EventEmitter$1 {
    [FLOWING] = false;
    [PAUSED] = false;
    [PIPES] = [];
    [BUFFER] = [];
    [OBJECTMODE];
    [ENCODING];
    [ASYNC];
    [DECODER];
    [EOF] = false;
    [EMITTED_END] = false;
    [EMITTING_END] = false;
    [CLOSED] = false;
    [EMITTED_ERROR] = null;
    [BUFFERLENGTH] = 0;
    [DESTROYED] = false;
    [SIGNAL];
    [ABORTED] = false;
    [DATALISTENERS] = 0;
    [DISCARDED] = false;
    /**
     * true if the stream can be written
     */
    writable = true;
    /**
     * true if the stream can be read
     */
    readable = true;
    /**
     * If `RType` is Buffer, then options do not need to be provided.
     * Otherwise, an options object must be provided to specify either
     * {@link Minipass.SharedOptions.objectMode} or
     * {@link Minipass.SharedOptions.encoding}, as appropriate.
     */
    constructor(...args) {
        const options = (args[0] ||
            {});
        super();
        if (options.objectMode && typeof options.encoding === 'string') {
            throw new TypeError('Encoding and objectMode may not be used together');
        }
        if (isObjectModeOptions(options)) {
            this[OBJECTMODE] = true;
            this[ENCODING] = null;
        }
        else if (isEncodingOptions(options)) {
            this[ENCODING] = options.encoding;
            this[OBJECTMODE] = false;
        }
        else {
            this[OBJECTMODE] = false;
            this[ENCODING] = null;
        }
        this[ASYNC] = !!options.async;
        this[DECODER] = this[ENCODING]
            ? new StringDecoder(this[ENCODING])
            : null;
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposeBuffer === true) {
            Object.defineProperty(this, 'buffer', { get: () => this[BUFFER] });
        }
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposePipes === true) {
            Object.defineProperty(this, 'pipes', { get: () => this[PIPES] });
        }
        const { signal } = options;
        if (signal) {
            this[SIGNAL] = signal;
            if (signal.aborted) {
                this[ABORT]();
            }
            else {
                signal.addEventListener('abort', () => this[ABORT]());
            }
        }
    }
    /**
     * The amount of data stored in the buffer waiting to be read.
     *
     * For Buffer strings, this will be the total byte length.
     * For string encoding streams, this will be the string character length,
     * according to JavaScript's `string.length` logic.
     * For objectMode streams, this is a count of the items waiting to be
     * emitted.
     */
    get bufferLength() {
        return this[BUFFERLENGTH];
    }
    /**
     * The `BufferEncoding` currently in use, or `null`
     */
    get encoding() {
        return this[ENCODING];
    }
    /**
     * @deprecated - This is a read only property
     */
    set encoding(_enc) {
        throw new Error('Encoding must be set at instantiation time');
    }
    /**
     * @deprecated - Encoding may only be set at instantiation time
     */
    setEncoding(_enc) {
        throw new Error('Encoding must be set at instantiation time');
    }
    /**
     * True if this is an objectMode stream
     */
    get objectMode() {
        return this[OBJECTMODE];
    }
    /**
     * @deprecated - This is a read-only property
     */
    set objectMode(_om) {
        throw new Error('objectMode must be set at instantiation time');
    }
    /**
     * true if this is an async stream
     */
    get ['async']() {
        return this[ASYNC];
    }
    /**
     * Set to true to make this stream async.
     *
     * Once set, it cannot be unset, as this would potentially cause incorrect
     * behavior.  Ie, a sync stream can be made async, but an async stream
     * cannot be safely made sync.
     */
    set ['async'](a) {
        this[ASYNC] = this[ASYNC] || !!a;
    }
    // drop everything and get out of the flow completely
    [ABORT]() {
        this[ABORTED] = true;
        this.emit('abort', this[SIGNAL]?.reason);
        this.destroy(this[SIGNAL]?.reason);
    }
    /**
     * True if the stream has been aborted.
     */
    get aborted() {
        return this[ABORTED];
    }
    /**
     * No-op setter. Stream aborted status is set via the AbortSignal provided
     * in the constructor options.
     */
    set aborted(_) { }
    write(chunk, encoding, cb) {
        if (this[ABORTED])
            return false;
        if (this[EOF])
            throw new Error('write after end');
        if (this[DESTROYED]) {
            this.emit('error', Object.assign(new Error('Cannot call write after a stream was destroyed'), { code: 'ERR_STREAM_DESTROYED' }));
            return true;
        }
        if (typeof encoding === 'function') {
            cb = encoding;
            encoding = 'utf8';
        }
        if (!encoding)
            encoding = 'utf8';
        const fn = this[ASYNC] ? defer : nodefer;
        // convert array buffers and typed array views into buffers
        // at some point in the future, we may want to do the opposite!
        // leave strings and buffers as-is
        // anything is only allowed if in object mode, so throw
        if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {
            if (isArrayBufferView(chunk)) {
                //@ts-ignore - sinful unsafe type changing
                chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength);
            }
            else if (isArrayBufferLike(chunk)) {
                //@ts-ignore - sinful unsafe type changing
                chunk = Buffer.from(chunk);
            }
            else if (typeof chunk !== 'string') {
                throw new Error('Non-contiguous data written to non-objectMode stream');
            }
        }
        // handle object mode up front, since it's simpler
        // this yields better performance, fewer checks later.
        if (this[OBJECTMODE]) {
            // maybe impossible?
            /* c8 ignore start */
            if (this[FLOWING] && this[BUFFERLENGTH] !== 0)
                this[FLUSH](true);
            /* c8 ignore stop */
            if (this[FLOWING])
                this.emit('data', chunk);
            else
                this[BUFFERPUSH](chunk);
            if (this[BUFFERLENGTH] !== 0)
                this.emit('readable');
            if (cb)
                fn(cb);
            return this[FLOWING];
        }
        // at this point the chunk is a buffer or string
        // don't buffer it up or send it to the decoder
        if (!chunk.length) {
            if (this[BUFFERLENGTH] !== 0)
                this.emit('readable');
            if (cb)
                fn(cb);
            return this[FLOWING];
        }
        // fast-path writing strings of same encoding to a stream with
        // an empty buffer, skipping the buffer/decoder dance
        if (typeof chunk === 'string' &&
            // unless it is a string already ready for us to use
            !(encoding === this[ENCODING] && !this[DECODER]?.lastNeed)) {
            //@ts-ignore - sinful unsafe type change
            chunk = Buffer.from(chunk, encoding);
        }
        if (Buffer.isBuffer(chunk) && this[ENCODING]) {
            //@ts-ignore - sinful unsafe type change
            chunk = this[DECODER].write(chunk);
        }
        // Note: flushing CAN potentially switch us into not-flowing mode
        if (this[FLOWING] && this[BUFFERLENGTH] !== 0)
            this[FLUSH](true);
        if (this[FLOWING])
            this.emit('data', chunk);
        else
            this[BUFFERPUSH](chunk);
        if (this[BUFFERLENGTH] !== 0)
            this.emit('readable');
        if (cb)
            fn(cb);
        return this[FLOWING];
    }
    /**
     * Low-level explicit read method.
     *
     * In objectMode, the argument is ignored, and one item is returned if
     * available.
     *
     * `n` is the number of bytes (or in the case of encoding streams,
     * characters) to consume. If `n` is not provided, then the entire buffer
     * is returned, or `null` is returned if no data is available.
     *
     * If `n` is greater that the amount of data in the internal buffer,
     * then `null` is returned.
     */
    read(n) {
        if (this[DESTROYED])
            return null;
        this[DISCARDED] = false;
        if (this[BUFFERLENGTH] === 0 ||
            n === 0 ||
            (n && n > this[BUFFERLENGTH])) {
            this[MAYBE_EMIT_END]();
            return null;
        }
        if (this[OBJECTMODE])
            n = null;
        if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {
            // not object mode, so if we have an encoding, then RType is string
            // otherwise, must be Buffer
            this[BUFFER] = [
                (this[ENCODING]
                    ? this[BUFFER].join('')
                    : Buffer.concat(this[BUFFER], this[BUFFERLENGTH])),
            ];
        }
        const ret = this[READ](n || null, this[BUFFER][0]);
        this[MAYBE_EMIT_END]();
        return ret;
    }
    [READ](n, chunk) {
        if (this[OBJECTMODE])
            this[BUFFERSHIFT]();
        else {
            const c = chunk;
            if (n === c.length || n === null)
                this[BUFFERSHIFT]();
            else if (typeof c === 'string') {
                this[BUFFER][0] = c.slice(n);
                chunk = c.slice(0, n);
                this[BUFFERLENGTH] -= n;
            }
            else {
                this[BUFFER][0] = c.subarray(n);
                chunk = c.subarray(0, n);
                this[BUFFERLENGTH] -= n;
            }
        }
        this.emit('data', chunk);
        if (!this[BUFFER].length && !this[EOF])
            this.emit('drain');
        return chunk;
    }
    end(chunk, encoding, cb) {
        if (typeof chunk === 'function') {
            cb = chunk;
            chunk = undefined;
        }
        if (typeof encoding === 'function') {
            cb = encoding;
            encoding = 'utf8';
        }
        if (chunk !== undefined)
            this.write(chunk, encoding);
        if (cb)
            this.once('end', cb);
        this[EOF] = true;
        this.writable = false;
        // if we haven't written anything, then go ahead and emit,
        // even if we're not reading.
        // we'll re-emit if a new 'end' listener is added anyway.
        // This makes MP more suitable to write-only use cases.
        if (this[FLOWING] || !this[PAUSED])
            this[MAYBE_EMIT_END]();
        return this;
    }
    // don't let the internal resume be overwritten
    [RESUME]() {
        if (this[DESTROYED])
            return;
        if (!this[DATALISTENERS] && !this[PIPES].length) {
            this[DISCARDED] = true;
        }
        this[PAUSED] = false;
        this[FLOWING] = true;
        this.emit('resume');
        if (this[BUFFER].length)
            this[FLUSH]();
        else if (this[EOF])
            this[MAYBE_EMIT_END]();
        else
            this.emit('drain');
    }
    /**
     * Resume the stream if it is currently in a paused state
     *
     * If called when there are no pipe destinations or `data` event listeners,
     * this will place the stream in a "discarded" state, where all data will
     * be thrown away. The discarded state is removed if a pipe destination or
     * data handler is added, if pause() is called, or if any synchronous or
     * asynchronous iteration is started.
     */
    resume() {
        return this[RESUME]();
    }
    /**
     * Pause the stream
     */
    pause() {
        this[FLOWING] = false;
        this[PAUSED] = true;
        this[DISCARDED] = false;
    }
    /**
     * true if the stream has been forcibly destroyed
     */
    get destroyed() {
        return this[DESTROYED];
    }
    /**
     * true if the stream is currently in a flowing state, meaning that
     * any writes will be immediately emitted.
     */
    get flowing() {
        return this[FLOWING];
    }
    /**
     * true if the stream is currently in a paused state
     */
    get paused() {
        return this[PAUSED];
    }
    [BUFFERPUSH](chunk) {
        if (this[OBJECTMODE])
            this[BUFFERLENGTH] += 1;
        else
            this[BUFFERLENGTH] += chunk.length;
        this[BUFFER].push(chunk);
    }
    [BUFFERSHIFT]() {
        if (this[OBJECTMODE])
            this[BUFFERLENGTH] -= 1;
        else
            this[BUFFERLENGTH] -= this[BUFFER][0].length;
        return this[BUFFER].shift();
    }
    [FLUSH](noDrain = false) {
        do { } while (this[FLUSHCHUNK](this[BUFFERSHIFT]()) &&
            this[BUFFER].length);
        if (!noDrain && !this[BUFFER].length && !this[EOF])
            this.emit('drain');
    }
    [FLUSHCHUNK](chunk) {
        this.emit('data', chunk);
        return this[FLOWING];
    }
    /**
     * Pipe all data emitted by this stream into the destination provided.
     *
     * Triggers the flow of data.
     */
    pipe(dest, opts) {
        if (this[DESTROYED])
            return dest;
        this[DISCARDED] = false;
        const ended = this[EMITTED_END];
        opts = opts || {};
        if (dest === proc.stdout || dest === proc.stderr)
            opts.end = false;
        else
            opts.end = opts.end !== false;
        opts.proxyErrors = !!opts.proxyErrors;
        // piping an ended stream ends immediately
        if (ended) {
            if (opts.end)
                dest.end();
        }
        else {
            // "as" here just ignores the WType, which pipes don't care about,
            // since they're only consuming from us, and writing to the dest
            this[PIPES].push(!opts.proxyErrors
                ? new Pipe(this, dest, opts)
                : new PipeProxyErrors(this, dest, opts));
            if (this[ASYNC])
                defer(() => this[RESUME]());
            else
                this[RESUME]();
        }
        return dest;
    }
    /**
     * Fully unhook a piped destination stream.
     *
     * If the destination stream was the only consumer of this stream (ie,
     * there are no other piped destinations or `'data'` event listeners)
     * then the flow of data will stop until there is another consumer or
     * {@link Minipass#resume} is explicitly called.
     */
    unpipe(dest) {
        const p = this[PIPES].find(p => p.dest === dest);
        if (p) {
            if (this[PIPES].length === 1) {
                if (this[FLOWING] && this[DATALISTENERS] === 0) {
                    this[FLOWING] = false;
                }
                this[PIPES] = [];
            }
            else
                this[PIPES].splice(this[PIPES].indexOf(p), 1);
            p.unpipe();
        }
    }
    /**
     * Alias for {@link Minipass#on}
     */
    addListener(ev, handler) {
        return this.on(ev, handler);
    }
    /**
     * Mostly identical to `EventEmitter.on`, with the following
     * behavior differences to prevent data loss and unnecessary hangs:
     *
     * - Adding a 'data' event handler will trigger the flow of data
     *
     * - Adding a 'readable' event handler when there is data waiting to be read
     *   will cause 'readable' to be emitted immediately.
     *
     * - Adding an 'endish' event handler ('end', 'finish', etc.) which has
     *   already passed will cause the event to be emitted immediately and all
     *   handlers removed.
     *
     * - Adding an 'error' event handler after an error has been emitted will
     *   cause the event to be re-emitted immediately with the error previously
     *   raised.
     */
    on(ev, handler) {
        const ret = super.on(ev, handler);
        if (ev === 'data') {
            this[DISCARDED] = false;
            this[DATALISTENERS]++;
            if (!this[PIPES].length && !this[FLOWING]) {
                this[RESUME]();
            }
        }
        else if (ev === 'readable' && this[BUFFERLENGTH] !== 0) {
            super.emit('readable');
        }
        else if (isEndish(ev) && this[EMITTED_END]) {
            super.emit(ev);
            this.removeAllListeners(ev);
        }
        else if (ev === 'error' && this[EMITTED_ERROR]) {
            const h = handler;
            if (this[ASYNC])
                defer(() => h.call(this, this[EMITTED_ERROR]));
            else
                h.call(this, this[EMITTED_ERROR]);
        }
        return ret;
    }
    /**
     * Alias for {@link Minipass#off}
     */
    removeListener(ev, handler) {
        return this.off(ev, handler);
    }
    /**
     * Mostly identical to `EventEmitter.off`
     *
     * If a 'data' event handler is removed, and it was the last consumer
     * (ie, there are no pipe destinations or other 'data' event listeners),
     * then the flow of data will stop until there is another consumer or
     * {@link Minipass#resume} is explicitly called.
     */
    off(ev, handler) {
        const ret = super.off(ev, handler);
        // if we previously had listeners, and now we don't, and we don't
        // have any pipes, then stop the flow, unless it's been explicitly
        // put in a discarded flowing state via stream.resume().
        if (ev === 'data') {
            this[DATALISTENERS] = this.listeners('data').length;
            if (this[DATALISTENERS] === 0 &&
                !this[DISCARDED] &&
                !this[PIPES].length) {
                this[FLOWING] = false;
            }
        }
        return ret;
    }
    /**
     * Mostly identical to `EventEmitter.removeAllListeners`
     *
     * If all 'data' event handlers are removed, and they were the last consumer
     * (ie, there are no pipe destinations), then the flow of data will stop
     * until there is another consumer or {@link Minipass#resume} is explicitly
     * called.
     */
    removeAllListeners(ev) {
        const ret = super.removeAllListeners(ev);
        if (ev === 'data' || ev === undefined) {
            this[DATALISTENERS] = 0;
            if (!this[DISCARDED] && !this[PIPES].length) {
                this[FLOWING] = false;
            }
        }
        return ret;
    }
    /**
     * true if the 'end' event has been emitted
     */
    get emittedEnd() {
        return this[EMITTED_END];
    }
    [MAYBE_EMIT_END]() {
        if (!this[EMITTING_END] &&
            !this[EMITTED_END] &&
            !this[DESTROYED] &&
            this[BUFFER].length === 0 &&
            this[EOF]) {
            this[EMITTING_END] = true;
            this.emit('end');
            this.emit('prefinish');
            this.emit('finish');
            if (this[CLOSED])
                this.emit('close');
            this[EMITTING_END] = false;
        }
    }
    /**
     * Mostly identical to `EventEmitter.emit`, with the following
     * behavior differences to prevent data loss and unnecessary hangs:
     *
     * If the stream has been destroyed, and the event is something other
     * than 'close' or 'error', then `false` is returned and no handlers
     * are called.
     *
     * If the event is 'end', and has already been emitted, then the event
     * is ignored. If the stream is in a paused or non-flowing state, then
     * the event will be deferred until data flow resumes. If the stream is
     * async, then handlers will be called on the next tick rather than
     * immediately.
     *
     * If the event is 'close', and 'end' has not yet been emitted, then
     * the event will be deferred until after 'end' is emitted.
     *
     * If the event is 'error', and an AbortSignal was provided for the stream,
     * and there are no listeners, then the event is ignored, matching the
     * behavior of node core streams in the presense of an AbortSignal.
     *
     * If the event is 'finish' or 'prefinish', then all listeners will be
     * removed after emitting the event, to prevent double-firing.
     */
    emit(ev, ...args) {
        const data = args[0];
        // error and close are only events allowed after calling destroy()
        if (ev !== 'error' &&
            ev !== 'close' &&
            ev !== DESTROYED &&
            this[DESTROYED]) {
            return false;
        }
        else if (ev === 'data') {
            return !this[OBJECTMODE] && !data
                ? false
                : this[ASYNC]
                    ? (defer(() => this[EMITDATA](data)), true)
                    : this[EMITDATA](data);
        }
        else if (ev === 'end') {
            return this[EMITEND]();
        }
        else if (ev === 'close') {
            this[CLOSED] = true;
            // don't emit close before 'end' and 'finish'
            if (!this[EMITTED_END] && !this[DESTROYED])
                return false;
            const ret = super.emit('close');
            this.removeAllListeners('close');
            return ret;
        }
        else if (ev === 'error') {
            this[EMITTED_ERROR] = data;
            super.emit(ERROR, data);
            const ret = !this[SIGNAL] || this.listeners('error').length
                ? super.emit('error', data)
                : false;
            this[MAYBE_EMIT_END]();
            return ret;
        }
        else if (ev === 'resume') {
            const ret = super.emit('resume');
            this[MAYBE_EMIT_END]();
            return ret;
        }
        else if (ev === 'finish' || ev === 'prefinish') {
            const ret = super.emit(ev);
            this.removeAllListeners(ev);
            return ret;
        }
        // Some other unknown event
        const ret = super.emit(ev, ...args);
        this[MAYBE_EMIT_END]();
        return ret;
    }
    [EMITDATA](data) {
        for (const p of this[PIPES]) {
            if (p.dest.write(data) === false)
                this.pause();
        }
        const ret = this[DISCARDED] ? false : super.emit('data', data);
        this[MAYBE_EMIT_END]();
        return ret;
    }
    [EMITEND]() {
        if (this[EMITTED_END])
            return false;
        this[EMITTED_END] = true;
        this.readable = false;
        return this[ASYNC]
            ? (defer(() => this[EMITEND2]()), true)
            : this[EMITEND2]();
    }
    [EMITEND2]() {
        if (this[DECODER]) {
            const data = this[DECODER].end();
            if (data) {
                for (const p of this[PIPES]) {
                    p.dest.write(data);
                }
                if (!this[DISCARDED])
                    super.emit('data', data);
            }
        }
        for (const p of this[PIPES]) {
            p.end();
        }
        const ret = super.emit('end');
        this.removeAllListeners('end');
        return ret;
    }
    /**
     * Return a Promise that resolves to an array of all emitted data once
     * the stream ends.
     */
    async collect() {
        const buf = Object.assign([], {
            dataLength: 0,
        });
        if (!this[OBJECTMODE])
            buf.dataLength = 0;
        // set the promise first, in case an error is raised
        // by triggering the flow here.
        const p = this.promise();
        this.on('data', c => {
            buf.push(c);
            if (!this[OBJECTMODE])
                buf.dataLength += c.length;
        });
        await p;
        return buf;
    }
    /**
     * Return a Promise that resolves to the concatenation of all emitted data
     * once the stream ends.
     *
     * Not allowed on objectMode streams.
     */
    async concat() {
        if (this[OBJECTMODE]) {
            throw new Error('cannot concat in objectMode');
        }
        const buf = await this.collect();
        return (this[ENCODING]
            ? buf.join('')
            : Buffer.concat(buf, buf.dataLength));
    }
    /**
     * Return a void Promise that resolves once the stream ends.
     */
    async promise() {
        return new Promise((resolve, reject) => {
            this.on(DESTROYED, () => reject(new Error('stream destroyed')));
            this.on('error', er => reject(er));
            this.on('end', () => resolve());
        });
    }
    /**
     * Asynchronous `for await of` iteration.
     *
     * This will continue emitting all chunks until the stream terminates.
     */
    [Symbol.asyncIterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false;
        let stopped = false;
        const stop = async () => {
            this.pause();
            stopped = true;
            return { value: undefined, done: true };
        };
        const next = () => {
            if (stopped)
                return stop();
            const res = this.read();
            if (res !== null)
                return Promise.resolve({ done: false, value: res });
            if (this[EOF])
                return stop();
            let resolve;
            let reject;
            const onerr = (er) => {
                this.off('data', ondata);
                this.off('end', onend);
                this.off(DESTROYED, ondestroy);
                stop();
                reject(er);
            };
            const ondata = (value) => {
                this.off('error', onerr);
                this.off('end', onend);
                this.off(DESTROYED, ondestroy);
                this.pause();
                resolve({ value, done: !!this[EOF] });
            };
            const onend = () => {
                this.off('error', onerr);
                this.off('data', ondata);
                this.off(DESTROYED, ondestroy);
                stop();
                resolve({ done: true, value: undefined });
            };
            const ondestroy = () => onerr(new Error('stream destroyed'));
            return new Promise((res, rej) => {
                reject = rej;
                resolve = res;
                this.once(DESTROYED, ondestroy);
                this.once('error', onerr);
                this.once('end', onend);
                this.once('data', ondata);
            });
        };
        return {
            next,
            throw: stop,
            return: stop,
            [Symbol.asyncIterator]() {
                return this;
            },
        };
    }
    /**
     * Synchronous `for of` iteration.
     *
     * The iteration will terminate when the internal buffer runs out, even
     * if the stream has not yet terminated.
     */
    [Symbol.iterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false;
        let stopped = false;
        const stop = () => {
            this.pause();
            this.off(ERROR, stop);
            this.off(DESTROYED, stop);
            this.off('end', stop);
            stopped = true;
            return { done: true, value: undefined };
        };
        const next = () => {
            if (stopped)
                return stop();
            const value = this.read();
            return value === null ? stop() : { done: false, value };
        };
        this.once('end', stop);
        this.once(ERROR, stop);
        this.once(DESTROYED, stop);
        return {
            next,
            throw: stop,
            return: stop,
            [Symbol.iterator]() {
                return this;
            },
        };
    }
    /**
     * Destroy a stream, preventing it from being used for any further purpose.
     *
     * If the stream has a `close()` method, then it will be called on
     * destruction.
     *
     * After destruction, any attempt to write data, read data, or emit most
     * events will be ignored.
     *
     * If an error argument is provided, then it will be emitted in an
     * 'error' event.
     */
    destroy(er) {
        if (this[DESTROYED]) {
            if (er)
                this.emit('error', er);
            else
                this.emit(DESTROYED);
            return this;
        }
        this[DESTROYED] = true;
        this[DISCARDED] = true;
        // throw away all buffered data, it's never coming out
        this[BUFFER].length = 0;
        this[BUFFERLENGTH] = 0;
        const wc = this;
        if (typeof wc.close === 'function' && !this[CLOSED])
            wc.close();
        if (er)
            this.emit('error', er);
        // if no error to emit, still reject pending promises
        else
            this.emit(DESTROYED);
        return this;
    }
    /**
     * Alias for {@link isStream}
     *
     * Former export location, maintained for backwards compatibility.
     *
     * @deprecated
     */
    static get isStream() {
        return isStream;
    }
}

const realpathSync = realpathSync$1.native;
const defaultFS = {
    lstatSync,
    readdir: readdir$2,
    readdirSync,
    readlinkSync,
    realpathSync,
    promises: {
        lstat,
        readdir: readdir$1,
        readlink,
        realpath,
    },
};
// if they just gave us require('fs') then use our default
const fsFromOption = (fsOption) => !fsOption || fsOption === defaultFS || fsOption === actualFS ?
    defaultFS
    : {
        ...defaultFS,
        ...fsOption,
        promises: {
            ...defaultFS.promises,
            ...(fsOption.promises || {}),
        },
    };
// turn something like //?/c:/ into c:\
const uncDriveRegexp = /^\\\\\?\\([a-z]:)\\?$/i;
const uncToDrive = (rootPath) => rootPath.replace(/\//g, '\\').replace(uncDriveRegexp, '$1\\');
// windows paths are separated by either / or \
const eitherSep = /[\\\/]/;
const UNKNOWN = 0; // may not even exist, for all we know
const IFIFO = 0b0001;
const IFCHR = 0b0010;
const IFDIR = 0b0100;
const IFBLK = 0b0110;
const IFREG = 0b1000;
const IFLNK = 0b1010;
const IFSOCK = 0b1100;
const IFMT = 0b1111;
// mask to unset low 4 bits
const IFMT_UNKNOWN = ~IFMT;
// set after successfully calling readdir() and getting entries.
const READDIR_CALLED = 0b0000_0001_0000;
// set after a successful lstat()
const LSTAT_CALLED = 0b0000_0010_0000;
// set if an entry (or one of its parents) is definitely not a dir
const ENOTDIR = 0b0000_0100_0000;
// set if an entry (or one of its parents) does not exist
// (can also be set on lstat errors like EACCES or ENAMETOOLONG)
const ENOENT = 0b0000_1000_0000;
// cannot have child entries -- also verify &IFMT is either IFDIR or IFLNK
// set if we fail to readlink
const ENOREADLINK = 0b0001_0000_0000;
// set if we know realpath() will fail
const ENOREALPATH = 0b0010_0000_0000;
const ENOCHILD = ENOTDIR | ENOENT | ENOREALPATH;
const TYPEMASK = 0b0011_1111_1111;
const entToType = (s) => s.isFile() ? IFREG
    : s.isDirectory() ? IFDIR
        : s.isSymbolicLink() ? IFLNK
            : s.isCharacterDevice() ? IFCHR
                : s.isBlockDevice() ? IFBLK
                    : s.isSocket() ? IFSOCK
                        : s.isFIFO() ? IFIFO
                            : UNKNOWN;
// normalize unicode path names
const normalizeCache = new Map();
const normalize$1 = (s) => {
    const c = normalizeCache.get(s);
    if (c)
        return c;
    const n = s.normalize('NFKD');
    normalizeCache.set(s, n);
    return n;
};
const normalizeNocaseCache = new Map();
const normalizeNocase = (s) => {
    const c = normalizeNocaseCache.get(s);
    if (c)
        return c;
    const n = normalize$1(s.toLowerCase());
    normalizeNocaseCache.set(s, n);
    return n;
};
/**
 * An LRUCache for storing resolved path strings or Path objects.
 * @internal
 */
class ResolveCache extends LRUCache {
    constructor() {
        super({ max: 256 });
    }
}
// In order to prevent blowing out the js heap by allocating hundreds of
// thousands of Path entries when walking extremely large trees, the "children"
// in this tree are represented by storing an array of Path entries in an
// LRUCache, indexed by the parent.  At any time, Path.children() may return an
// empty array, indicating that it doesn't know about any of its children, and
// thus has to rebuild that cache.  This is fine, it just means that we don't
// benefit as much from having the cached entries, but huge directory walks
// don't blow out the stack, and smaller ones are still as fast as possible.
//
//It does impose some complexity when building up the readdir data, because we
//need to pass a reference to the children array that we started with.
/**
 * an LRUCache for storing child entries.
 * @internal
 */
class ChildrenCache extends LRUCache {
    constructor(maxSize = 16 * 1024) {
        super({
            maxSize,
            // parent + children
            sizeCalculation: a => a.length + 1,
        });
    }
}
const setAsCwd = Symbol('PathScurry setAsCwd');
/**
 * Path objects are sort of like a super-powered
 * {@link https://nodejs.org/docs/latest/api/fs.html#class-fsdirent fs.Dirent}
 *
 * Each one represents a single filesystem entry on disk, which may or may not
 * exist. It includes methods for reading various types of information via
 * lstat, readlink, and readdir, and caches all information to the greatest
 * degree possible.
 *
 * Note that fs operations that would normally throw will instead return an
 * "empty" value. This is in order to prevent excessive overhead from error
 * stack traces.
 */
class PathBase {
    /**
     * the basename of this path
     *
     * **Important**: *always* test the path name against any test string
     * usingthe {@link isNamed} method, and not by directly comparing this
     * string. Otherwise, unicode path strings that the system sees as identical
     * will not be properly treated as the same path, leading to incorrect
     * behavior and possible security issues.
     */
    name;
    /**
     * the Path entry corresponding to the path root.
     *
     * @internal
     */
    root;
    /**
     * All roots found within the current PathScurry family
     *
     * @internal
     */
    roots;
    /**
     * a reference to the parent path, or undefined in the case of root entries
     *
     * @internal
     */
    parent;
    /**
     * boolean indicating whether paths are compared case-insensitively
     * @internal
     */
    nocase;
    /**
     * boolean indicating that this path is the current working directory
     * of the PathScurry collection that contains it.
     */
    isCWD = false;
    // potential default fs override
    #fs;
    // Stats fields
    #dev;
    get dev() {
        return this.#dev;
    }
    #mode;
    get mode() {
        return this.#mode;
    }
    #nlink;
    get nlink() {
        return this.#nlink;
    }
    #uid;
    get uid() {
        return this.#uid;
    }
    #gid;
    get gid() {
        return this.#gid;
    }
    #rdev;
    get rdev() {
        return this.#rdev;
    }
    #blksize;
    get blksize() {
        return this.#blksize;
    }
    #ino;
    get ino() {
        return this.#ino;
    }
    #size;
    get size() {
        return this.#size;
    }
    #blocks;
    get blocks() {
        return this.#blocks;
    }
    #atimeMs;
    get atimeMs() {
        return this.#atimeMs;
    }
    #mtimeMs;
    get mtimeMs() {
        return this.#mtimeMs;
    }
    #ctimeMs;
    get ctimeMs() {
        return this.#ctimeMs;
    }
    #birthtimeMs;
    get birthtimeMs() {
        return this.#birthtimeMs;
    }
    #atime;
    get atime() {
        return this.#atime;
    }
    #mtime;
    get mtime() {
        return this.#mtime;
    }
    #ctime;
    get ctime() {
        return this.#ctime;
    }
    #birthtime;
    get birthtime() {
        return this.#birthtime;
    }
    #matchName;
    #depth;
    #fullpath;
    #fullpathPosix;
    #relative;
    #relativePosix;
    #type;
    #children;
    #linkTarget;
    #realpath;
    /**
     * This property is for compatibility with the Dirent class as of
     * Node v20, where Dirent['parentPath'] refers to the path of the
     * directory that was passed to readdir. For root entries, it's the path
     * to the entry itself.
     */
    get parentPath() {
        return (this.parent || this).fullpath();
    }
    /**
     * Deprecated alias for Dirent['parentPath'] Somewhat counterintuitively,
     * this property refers to the *parent* path, not the path object itself.
     *
     * @deprecated
     */
    get path() {
        return this.parentPath;
    }
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
        this.name = name;
        this.#matchName = nocase ? normalizeNocase(name) : normalize$1(name);
        this.#type = type & TYPEMASK;
        this.nocase = nocase;
        this.roots = roots;
        this.root = root || this;
        this.#children = children;
        this.#fullpath = opts.fullpath;
        this.#relative = opts.relative;
        this.#relativePosix = opts.relativePosix;
        this.parent = opts.parent;
        if (this.parent) {
            this.#fs = this.parent.#fs;
        }
        else {
            this.#fs = fsFromOption(opts.fs);
        }
    }
    /**
     * Returns the depth of the Path object from its root.
     *
     * For example, a path at `/foo/bar` would have a depth of 2.
     */
    depth() {
        if (this.#depth !== undefined)
            return this.#depth;
        if (!this.parent)
            return (this.#depth = 0);
        return (this.#depth = this.parent.depth() + 1);
    }
    /**
     * @internal
     */
    childrenCache() {
        return this.#children;
    }
    /**
     * Get the Path object referenced by the string path, resolved from this Path
     */
    resolve(path) {
        if (!path) {
            return this;
        }
        const rootPath = this.getRootString(path);
        const dir = path.substring(rootPath.length);
        const dirParts = dir.split(this.splitSep);
        const result = rootPath ?
            this.getRoot(rootPath).#resolveParts(dirParts)
            : this.#resolveParts(dirParts);
        return result;
    }
    #resolveParts(dirParts) {
        let p = this;
        for (const part of dirParts) {
            p = p.child(part);
        }
        return p;
    }
    /**
     * Returns the cached children Path objects, if still available.  If they
     * have fallen out of the cache, then returns an empty array, and resets the
     * READDIR_CALLED bit, so that future calls to readdir() will require an fs
     * lookup.
     *
     * @internal
     */
    children() {
        const cached = this.#children.get(this);
        if (cached) {
            return cached;
        }
        const children = Object.assign([], { provisional: 0 });
        this.#children.set(this, children);
        this.#type &= ~READDIR_CALLED;
        return children;
    }
    /**
     * Resolves a path portion and returns or creates the child Path.
     *
     * Returns `this` if pathPart is `''` or `'.'`, or `parent` if pathPart is
     * `'..'`.
     *
     * This should not be called directly.  If `pathPart` contains any path
     * separators, it will lead to unsafe undefined behavior.
     *
     * Use `Path.resolve()` instead.
     *
     * @internal
     */
    child(pathPart, opts) {
        if (pathPart === '' || pathPart === '.') {
            return this;
        }
        if (pathPart === '..') {
            return this.parent || this;
        }
        // find the child
        const children = this.children();
        const name = this.nocase ? normalizeNocase(pathPart) : normalize$1(pathPart);
        for (const p of children) {
            if (p.#matchName === name) {
                return p;
            }
        }
        // didn't find it, create provisional child, since it might not
        // actually exist.  If we know the parent isn't a dir, then
        // in fact it CAN'T exist.
        const s = this.parent ? this.sep : '';
        const fullpath = this.#fullpath ? this.#fullpath + s + pathPart : undefined;
        const pchild = this.newChild(pathPart, UNKNOWN, {
            ...opts,
            parent: this,
            fullpath,
        });
        if (!this.canReaddir()) {
            pchild.#type |= ENOENT;
        }
        // don't have to update provisional, because if we have real children,
        // then provisional is set to children.length, otherwise a lower number
        children.push(pchild);
        return pchild;
    }
    /**
     * The relative path from the cwd. If it does not share an ancestor with
     * the cwd, then this ends up being equivalent to the fullpath()
     */
    relative() {
        if (this.isCWD)
            return '';
        if (this.#relative !== undefined) {
            return this.#relative;
        }
        const name = this.name;
        const p = this.parent;
        if (!p) {
            return (this.#relative = this.name);
        }
        const pv = p.relative();
        return pv + (!pv || !p.parent ? '' : this.sep) + name;
    }
    /**
     * The relative path from the cwd, using / as the path separator.
     * If it does not share an ancestor with
     * the cwd, then this ends up being equivalent to the fullpathPosix()
     * On posix systems, this is identical to relative().
     */
    relativePosix() {
        if (this.sep === '/')
            return this.relative();
        if (this.isCWD)
            return '';
        if (this.#relativePosix !== undefined)
            return this.#relativePosix;
        const name = this.name;
        const p = this.parent;
        if (!p) {
            return (this.#relativePosix = this.fullpathPosix());
        }
        const pv = p.relativePosix();
        return pv + (!pv || !p.parent ? '' : '/') + name;
    }
    /**
     * The fully resolved path string for this Path entry
     */
    fullpath() {
        if (this.#fullpath !== undefined) {
            return this.#fullpath;
        }
        const name = this.name;
        const p = this.parent;
        if (!p) {
            return (this.#fullpath = this.name);
        }
        const pv = p.fullpath();
        const fp = pv + (!p.parent ? '' : this.sep) + name;
        return (this.#fullpath = fp);
    }
    /**
     * On platforms other than windows, this is identical to fullpath.
     *
     * On windows, this is overridden to return the forward-slash form of the
     * full UNC path.
     */
    fullpathPosix() {
        if (this.#fullpathPosix !== undefined)
            return this.#fullpathPosix;
        if (this.sep === '/')
            return (this.#fullpathPosix = this.fullpath());
        if (!this.parent) {
            const p = this.fullpath().replace(/\\/g, '/');
            if (/^[a-z]:\//i.test(p)) {
                return (this.#fullpathPosix = `//?/${p}`);
            }
            else {
                return (this.#fullpathPosix = p);
            }
        }
        const p = this.parent;
        const pfpp = p.fullpathPosix();
        const fpp = pfpp + (!pfpp || !p.parent ? '' : '/') + this.name;
        return (this.#fullpathPosix = fpp);
    }
    /**
     * Is the Path of an unknown type?
     *
     * Note that we might know *something* about it if there has been a previous
     * filesystem operation, for example that it does not exist, or is not a
     * link, or whether it has child entries.
     */
    isUnknown() {
        return (this.#type & IFMT) === UNKNOWN;
    }
    isType(type) {
        return this[`is${type}`]();
    }
    getType() {
        return (this.isUnknown() ? 'Unknown'
            : this.isDirectory() ? 'Directory'
                : this.isFile() ? 'File'
                    : this.isSymbolicLink() ? 'SymbolicLink'
                        : this.isFIFO() ? 'FIFO'
                            : this.isCharacterDevice() ? 'CharacterDevice'
                                : this.isBlockDevice() ? 'BlockDevice'
                                    : /* c8 ignore start */ this.isSocket() ? 'Socket'
                                        : 'Unknown');
        /* c8 ignore stop */
    }
    /**
     * Is the Path a regular file?
     */
    isFile() {
        return (this.#type & IFMT) === IFREG;
    }
    /**
     * Is the Path a directory?
     */
    isDirectory() {
        return (this.#type & IFMT) === IFDIR;
    }
    /**
     * Is the path a character device?
     */
    isCharacterDevice() {
        return (this.#type & IFMT) === IFCHR;
    }
    /**
     * Is the path a block device?
     */
    isBlockDevice() {
        return (this.#type & IFMT) === IFBLK;
    }
    /**
     * Is the path a FIFO pipe?
     */
    isFIFO() {
        return (this.#type & IFMT) === IFIFO;
    }
    /**
     * Is the path a socket?
     */
    isSocket() {
        return (this.#type & IFMT) === IFSOCK;
    }
    /**
     * Is the path a symbolic link?
     */
    isSymbolicLink() {
        return (this.#type & IFLNK) === IFLNK;
    }
    /**
     * Return the entry if it has been subject of a successful lstat, or
     * undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* simply
     * mean that we haven't called lstat on it.
     */
    lstatCached() {
        return this.#type & LSTAT_CALLED ? this : undefined;
    }
    /**
     * Return the cached link target if the entry has been the subject of a
     * successful readlink, or undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * readlink() has been called at some point.
     */
    readlinkCached() {
        return this.#linkTarget;
    }
    /**
     * Returns the cached realpath target if the entry has been the subject
     * of a successful realpath, or undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * realpath() has been called at some point.
     */
    realpathCached() {
        return this.#realpath;
    }
    /**
     * Returns the cached child Path entries array if the entry has been the
     * subject of a successful readdir(), or [] otherwise.
     *
     * Does not read the filesystem, so an empty array *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * readdir() has been called recently enough to still be valid.
     */
    readdirCached() {
        const children = this.children();
        return children.slice(0, children.provisional);
    }
    /**
     * Return true if it's worth trying to readlink.  Ie, we don't (yet) have
     * any indication that readlink will definitely fail.
     *
     * Returns false if the path is known to not be a symlink, if a previous
     * readlink failed, or if the entry does not exist.
     */
    canReadlink() {
        if (this.#linkTarget)
            return true;
        if (!this.parent)
            return false;
        // cases where it cannot possibly succeed
        const ifmt = this.#type & IFMT;
        return !((ifmt !== UNKNOWN && ifmt !== IFLNK) ||
            this.#type & ENOREADLINK ||
            this.#type & ENOENT);
    }
    /**
     * Return true if readdir has previously been successfully called on this
     * path, indicating that cachedReaddir() is likely valid.
     */
    calledReaddir() {
        return !!(this.#type & READDIR_CALLED);
    }
    /**
     * Returns true if the path is known to not exist. That is, a previous lstat
     * or readdir failed to verify its existence when that would have been
     * expected, or a parent entry was marked either enoent or enotdir.
     */
    isENOENT() {
        return !!(this.#type & ENOENT);
    }
    /**
     * Return true if the path is a match for the given path name.  This handles
     * case sensitivity and unicode normalization.
     *
     * Note: even on case-sensitive systems, it is **not** safe to test the
     * equality of the `.name` property to determine whether a given pathname
     * matches, due to unicode normalization mismatches.
     *
     * Always use this method instead of testing the `path.name` property
     * directly.
     */
    isNamed(n) {
        return !this.nocase ?
            this.#matchName === normalize$1(n)
            : this.#matchName === normalizeNocase(n);
    }
    /**
     * Return the Path object corresponding to the target of a symbolic link.
     *
     * If the Path is not a symbolic link, or if the readlink call fails for any
     * reason, `undefined` is returned.
     *
     * Result is cached, and thus may be outdated if the filesystem is mutated.
     */
    async readlink() {
        const target = this.#linkTarget;
        if (target) {
            return target;
        }
        if (!this.canReadlink()) {
            return undefined;
        }
        /* c8 ignore start */
        // already covered by the canReadlink test, here for ts grumples
        if (!this.parent) {
            return undefined;
        }
        /* c8 ignore stop */
        try {
            const read = await this.#fs.promises.readlink(this.fullpath());
            const linkTarget = (await this.parent.realpath())?.resolve(read);
            if (linkTarget) {
                return (this.#linkTarget = linkTarget);
            }
        }
        catch (er) {
            this.#readlinkFail(er.code);
            return undefined;
        }
    }
    /**
     * Synchronous {@link PathBase.readlink}
     */
    readlinkSync() {
        const target = this.#linkTarget;
        if (target) {
            return target;
        }
        if (!this.canReadlink()) {
            return undefined;
        }
        /* c8 ignore start */
        // already covered by the canReadlink test, here for ts grumples
        if (!this.parent) {
            return undefined;
        }
        /* c8 ignore stop */
        try {
            const read = this.#fs.readlinkSync(this.fullpath());
            const linkTarget = this.parent.realpathSync()?.resolve(read);
            if (linkTarget) {
                return (this.#linkTarget = linkTarget);
            }
        }
        catch (er) {
            this.#readlinkFail(er.code);
            return undefined;
        }
    }
    #readdirSuccess(children) {
        // succeeded, mark readdir called bit
        this.#type |= READDIR_CALLED;
        // mark all remaining provisional children as ENOENT
        for (let p = children.provisional; p < children.length; p++) {
            const c = children[p];
            if (c)
                c.#markENOENT();
        }
    }
    #markENOENT() {
        // mark as UNKNOWN and ENOENT
        if (this.#type & ENOENT)
            return;
        this.#type = (this.#type | ENOENT) & IFMT_UNKNOWN;
        this.#markChildrenENOENT();
    }
    #markChildrenENOENT() {
        // all children are provisional and do not exist
        const children = this.children();
        children.provisional = 0;
        for (const p of children) {
            p.#markENOENT();
        }
    }
    #markENOREALPATH() {
        this.#type |= ENOREALPATH;
        this.#markENOTDIR();
    }
    // save the information when we know the entry is not a dir
    #markENOTDIR() {
        // entry is not a directory, so any children can't exist.
        // this *should* be impossible, since any children created
        // after it's been marked ENOTDIR should be marked ENOENT,
        // so it won't even get to this point.
        /* c8 ignore start */
        if (this.#type & ENOTDIR)
            return;
        /* c8 ignore stop */
        let t = this.#type;
        // this could happen if we stat a dir, then delete it,
        // then try to read it or one of its children.
        if ((t & IFMT) === IFDIR)
            t &= IFMT_UNKNOWN;
        this.#type = t | ENOTDIR;
        this.#markChildrenENOENT();
    }
    #readdirFail(code = '') {
        // markENOTDIR and markENOENT also set provisional=0
        if (code === 'ENOTDIR' || code === 'EPERM') {
            this.#markENOTDIR();
        }
        else if (code === 'ENOENT') {
            this.#markENOENT();
        }
        else {
            this.children().provisional = 0;
        }
    }
    #lstatFail(code = '') {
        // Windows just raises ENOENT in this case, disable for win CI
        /* c8 ignore start */
        if (code === 'ENOTDIR') {
            // already know it has a parent by this point
            const p = this.parent;
            p.#markENOTDIR();
        }
        else if (code === 'ENOENT') {
            /* c8 ignore stop */
            this.#markENOENT();
        }
    }
    #readlinkFail(code = '') {
        let ter = this.#type;
        ter |= ENOREADLINK;
        if (code === 'ENOENT')
            ter |= ENOENT;
        // windows gets a weird error when you try to readlink a file
        if (code === 'EINVAL' || code === 'UNKNOWN') {
            // exists, but not a symlink, we don't know WHAT it is, so remove
            // all IFMT bits.
            ter &= IFMT_UNKNOWN;
        }
        this.#type = ter;
        // windows just gets ENOENT in this case.  We do cover the case,
        // just disabled because it's impossible on Windows CI
        /* c8 ignore start */
        if (code === 'ENOTDIR' && this.parent) {
            this.parent.#markENOTDIR();
        }
        /* c8 ignore stop */
    }
    #readdirAddChild(e, c) {
        return (this.#readdirMaybePromoteChild(e, c) ||
            this.#readdirAddNewChild(e, c));
    }
    #readdirAddNewChild(e, c) {
        // alloc new entry at head, so it's never provisional
        const type = entToType(e);
        const child = this.newChild(e.name, type, { parent: this });
        const ifmt = child.#type & IFMT;
        if (ifmt !== IFDIR && ifmt !== IFLNK && ifmt !== UNKNOWN) {
            child.#type |= ENOTDIR;
        }
        c.unshift(child);
        c.provisional++;
        return child;
    }
    #readdirMaybePromoteChild(e, c) {
        for (let p = c.provisional; p < c.length; p++) {
            const pchild = c[p];
            const name = this.nocase ? normalizeNocase(e.name) : normalize$1(e.name);
            if (name !== pchild.#matchName) {
                continue;
            }
            return this.#readdirPromoteChild(e, pchild, p, c);
        }
    }
    #readdirPromoteChild(e, p, index, c) {
        const v = p.name;
        // retain any other flags, but set ifmt from dirent
        p.#type = (p.#type & IFMT_UNKNOWN) | entToType(e);
        // case sensitivity fixing when we learn the true name.
        if (v !== e.name)
            p.name = e.name;
        // just advance provisional index (potentially off the list),
        // otherwise we have to splice/pop it out and re-insert at head
        if (index !== c.provisional) {
            if (index === c.length - 1)
                c.pop();
            else
                c.splice(index, 1);
            c.unshift(p);
        }
        c.provisional++;
        return p;
    }
    /**
     * Call lstat() on this Path, and update all known information that can be
     * determined.
     *
     * Note that unlike `fs.lstat()`, the returned value does not contain some
     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
     * information is required, you will need to call `fs.lstat` yourself.
     *
     * If the Path refers to a nonexistent file, or if the lstat call fails for
     * any reason, `undefined` is returned.  Otherwise the updated Path object is
     * returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async lstat() {
        if ((this.#type & ENOENT) === 0) {
            try {
                this.#applyStat(await this.#fs.promises.lstat(this.fullpath()));
                return this;
            }
            catch (er) {
                this.#lstatFail(er.code);
            }
        }
    }
    /**
     * synchronous {@link PathBase.lstat}
     */
    lstatSync() {
        if ((this.#type & ENOENT) === 0) {
            try {
                this.#applyStat(this.#fs.lstatSync(this.fullpath()));
                return this;
            }
            catch (er) {
                this.#lstatFail(er.code);
            }
        }
    }
    #applyStat(st) {
        const { atime, atimeMs, birthtime, birthtimeMs, blksize, blocks, ctime, ctimeMs, dev, gid, ino, mode, mtime, mtimeMs, nlink, rdev, size, uid, } = st;
        this.#atime = atime;
        this.#atimeMs = atimeMs;
        this.#birthtime = birthtime;
        this.#birthtimeMs = birthtimeMs;
        this.#blksize = blksize;
        this.#blocks = blocks;
        this.#ctime = ctime;
        this.#ctimeMs = ctimeMs;
        this.#dev = dev;
        this.#gid = gid;
        this.#ino = ino;
        this.#mode = mode;
        this.#mtime = mtime;
        this.#mtimeMs = mtimeMs;
        this.#nlink = nlink;
        this.#rdev = rdev;
        this.#size = size;
        this.#uid = uid;
        const ifmt = entToType(st);
        // retain any other flags, but set the ifmt
        this.#type = (this.#type & IFMT_UNKNOWN) | ifmt | LSTAT_CALLED;
        if (ifmt !== UNKNOWN && ifmt !== IFDIR && ifmt !== IFLNK) {
            this.#type |= ENOTDIR;
        }
    }
    #onReaddirCB = [];
    #readdirCBInFlight = false;
    #callOnReaddirCB(children) {
        this.#readdirCBInFlight = false;
        const cbs = this.#onReaddirCB.slice();
        this.#onReaddirCB.length = 0;
        cbs.forEach(cb => cb(null, children));
    }
    /**
     * Standard node-style callback interface to get list of directory entries.
     *
     * If the Path cannot or does not contain any children, then an empty array
     * is returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     *
     * @param cb The callback called with (er, entries).  Note that the `er`
     * param is somewhat extraneous, as all readdir() errors are handled and
     * simply result in an empty set of entries being returned.
     * @param allowZalgo Boolean indicating that immediately known results should
     * *not* be deferred with `queueMicrotask`. Defaults to `false`. Release
     * zalgo at your peril, the dark pony lord is devious and unforgiving.
     */
    readdirCB(cb, allowZalgo = false) {
        if (!this.canReaddir()) {
            if (allowZalgo)
                cb(null, []);
            else
                queueMicrotask(() => cb(null, []));
            return;
        }
        const children = this.children();
        if (this.calledReaddir()) {
            const c = children.slice(0, children.provisional);
            if (allowZalgo)
                cb(null, c);
            else
                queueMicrotask(() => cb(null, c));
            return;
        }
        // don't have to worry about zalgo at this point.
        this.#onReaddirCB.push(cb);
        if (this.#readdirCBInFlight) {
            return;
        }
        this.#readdirCBInFlight = true;
        // else read the directory, fill up children
        // de-provisionalize any provisional children.
        const fullpath = this.fullpath();
        this.#fs.readdir(fullpath, { withFileTypes: true }, (er, entries) => {
            if (er) {
                this.#readdirFail(er.code);
                children.provisional = 0;
            }
            else {
                // if we didn't get an error, we always get entries.
                //@ts-ignore
                for (const e of entries) {
                    this.#readdirAddChild(e, children);
                }
                this.#readdirSuccess(children);
            }
            this.#callOnReaddirCB(children.slice(0, children.provisional));
            return;
        });
    }
    #asyncReaddirInFlight;
    /**
     * Return an array of known child entries.
     *
     * If the Path cannot or does not contain any children, then an empty array
     * is returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async readdir() {
        if (!this.canReaddir()) {
            return [];
        }
        const children = this.children();
        if (this.calledReaddir()) {
            return children.slice(0, children.provisional);
        }
        // else read the directory, fill up children
        // de-provisionalize any provisional children.
        const fullpath = this.fullpath();
        if (this.#asyncReaddirInFlight) {
            await this.#asyncReaddirInFlight;
        }
        else {
            /* c8 ignore start */
            let resolve = () => { };
            /* c8 ignore stop */
            this.#asyncReaddirInFlight = new Promise(res => (resolve = res));
            try {
                for (const e of await this.#fs.promises.readdir(fullpath, {
                    withFileTypes: true,
                })) {
                    this.#readdirAddChild(e, children);
                }
                this.#readdirSuccess(children);
            }
            catch (er) {
                this.#readdirFail(er.code);
                children.provisional = 0;
            }
            this.#asyncReaddirInFlight = undefined;
            resolve();
        }
        return children.slice(0, children.provisional);
    }
    /**
     * synchronous {@link PathBase.readdir}
     */
    readdirSync() {
        if (!this.canReaddir()) {
            return [];
        }
        const children = this.children();
        if (this.calledReaddir()) {
            return children.slice(0, children.provisional);
        }
        // else read the directory, fill up children
        // de-provisionalize any provisional children.
        const fullpath = this.fullpath();
        try {
            for (const e of this.#fs.readdirSync(fullpath, {
                withFileTypes: true,
            })) {
                this.#readdirAddChild(e, children);
            }
            this.#readdirSuccess(children);
        }
        catch (er) {
            this.#readdirFail(er.code);
            children.provisional = 0;
        }
        return children.slice(0, children.provisional);
    }
    canReaddir() {
        if (this.#type & ENOCHILD)
            return false;
        const ifmt = IFMT & this.#type;
        // we always set ENOTDIR when setting IFMT, so should be impossible
        /* c8 ignore start */
        if (!(ifmt === UNKNOWN || ifmt === IFDIR || ifmt === IFLNK)) {
            return false;
        }
        /* c8 ignore stop */
        return true;
    }
    shouldWalk(dirs, walkFilter) {
        return ((this.#type & IFDIR) === IFDIR &&
            !(this.#type & ENOCHILD) &&
            !dirs.has(this) &&
            (!walkFilter || walkFilter(this)));
    }
    /**
     * Return the Path object corresponding to path as resolved
     * by realpath(3).
     *
     * If the realpath call fails for any reason, `undefined` is returned.
     *
     * Result is cached, and thus may be outdated if the filesystem is mutated.
     * On success, returns a Path object.
     */
    async realpath() {
        if (this.#realpath)
            return this.#realpath;
        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)
            return undefined;
        try {
            const rp = await this.#fs.promises.realpath(this.fullpath());
            return (this.#realpath = this.resolve(rp));
        }
        catch (_) {
            this.#markENOREALPATH();
        }
    }
    /**
     * Synchronous {@link realpath}
     */
    realpathSync() {
        if (this.#realpath)
            return this.#realpath;
        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)
            return undefined;
        try {
            const rp = this.#fs.realpathSync(this.fullpath());
            return (this.#realpath = this.resolve(rp));
        }
        catch (_) {
            this.#markENOREALPATH();
        }
    }
    /**
     * Internal method to mark this Path object as the scurry cwd,
     * called by {@link PathScurry#chdir}
     *
     * @internal
     */
    [setAsCwd](oldCwd) {
        if (oldCwd === this)
            return;
        oldCwd.isCWD = false;
        this.isCWD = true;
        const changed = new Set([]);
        let rp = [];
        let p = this;
        while (p && p.parent) {
            changed.add(p);
            p.#relative = rp.join(this.sep);
            p.#relativePosix = rp.join('/');
            p = p.parent;
            rp.push('..');
        }
        // now un-memoize parents of old cwd
        p = oldCwd;
        while (p && p.parent && !changed.has(p)) {
            p.#relative = undefined;
            p.#relativePosix = undefined;
            p = p.parent;
        }
    }
}
/**
 * Path class used on win32 systems
 *
 * Uses `'\\'` as the path separator for returned paths, either `'\\'` or `'/'`
 * as the path separator for parsing paths.
 */
class PathWin32 extends PathBase {
    /**
     * Separator for generating path strings.
     */
    sep = '\\';
    /**
     * Separator for parsing path strings.
     */
    splitSep = eitherSep;
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
        super(name, type, root, roots, nocase, children, opts);
    }
    /**
     * @internal
     */
    newChild(name, type = UNKNOWN, opts = {}) {
        return new PathWin32(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);
    }
    /**
     * @internal
     */
    getRootString(path) {
        return win32.parse(path).root;
    }
    /**
     * @internal
     */
    getRoot(rootPath) {
        rootPath = uncToDrive(rootPath.toUpperCase());
        if (rootPath === this.root.name) {
            return this.root;
        }
        // ok, not that one, check if it matches another we know about
        for (const [compare, root] of Object.entries(this.roots)) {
            if (this.sameRoot(rootPath, compare)) {
                return (this.roots[rootPath] = root);
            }
        }
        // otherwise, have to create a new one.
        return (this.roots[rootPath] = new PathScurryWin32(rootPath, this).root);
    }
    /**
     * @internal
     */
    sameRoot(rootPath, compare = this.root.name) {
        // windows can (rarely) have case-sensitive filesystem, but
        // UNC and drive letters are always case-insensitive, and canonically
        // represented uppercase.
        rootPath = rootPath
            .toUpperCase()
            .replace(/\//g, '\\')
            .replace(uncDriveRegexp, '$1\\');
        return rootPath === compare;
    }
}
/**
 * Path class used on all posix systems.
 *
 * Uses `'/'` as the path separator.
 */
class PathPosix extends PathBase {
    /**
     * separator for parsing path strings
     */
    splitSep = '/';
    /**
     * separator for generating path strings
     */
    sep = '/';
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
        super(name, type, root, roots, nocase, children, opts);
    }
    /**
     * @internal
     */
    getRootString(path) {
        return path.startsWith('/') ? '/' : '';
    }
    /**
     * @internal
     */
    getRoot(_rootPath) {
        return this.root;
    }
    /**
     * @internal
     */
    newChild(name, type = UNKNOWN, opts = {}) {
        return new PathPosix(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);
    }
}
/**
 * The base class for all PathScurry classes, providing the interface for path
 * resolution and filesystem operations.
 *
 * Typically, you should *not* instantiate this class directly, but rather one
 * of the platform-specific classes, or the exported {@link PathScurry} which
 * defaults to the current platform.
 */
class PathScurryBase {
    /**
     * The root Path entry for the current working directory of this Scurry
     */
    root;
    /**
     * The string path for the root of this Scurry's current working directory
     */
    rootPath;
    /**
     * A collection of all roots encountered, referenced by rootPath
     */
    roots;
    /**
     * The Path entry corresponding to this PathScurry's current working directory.
     */
    cwd;
    #resolveCache;
    #resolvePosixCache;
    #children;
    /**
     * Perform path comparisons case-insensitively.
     *
     * Defaults true on Darwin and Windows systems, false elsewhere.
     */
    nocase;
    #fs;
    /**
     * This class should not be instantiated directly.
     *
     * Use PathScurryWin32, PathScurryDarwin, PathScurryPosix, or PathScurry
     *
     * @internal
     */
    constructor(cwd = process.cwd(), pathImpl, sep, { nocase, childrenCacheSize = 16 * 1024, fs = defaultFS, } = {}) {
        this.#fs = fsFromOption(fs);
        if (cwd instanceof URL || cwd.startsWith('file://')) {
            cwd = fileURLToPath(cwd);
        }
        // resolve and split root, and then add to the store.
        // this is the only time we call path.resolve()
        const cwdPath = pathImpl.resolve(cwd);
        this.roots = Object.create(null);
        this.rootPath = this.parseRootPath(cwdPath);
        this.#resolveCache = new ResolveCache();
        this.#resolvePosixCache = new ResolveCache();
        this.#children = new ChildrenCache(childrenCacheSize);
        const split = cwdPath.substring(this.rootPath.length).split(sep);
        // resolve('/') leaves '', splits to [''], we don't want that.
        if (split.length === 1 && !split[0]) {
            split.pop();
        }
        /* c8 ignore start */
        if (nocase === undefined) {
            throw new TypeError('must provide nocase setting to PathScurryBase ctor');
        }
        /* c8 ignore stop */
        this.nocase = nocase;
        this.root = this.newRoot(this.#fs);
        this.roots[this.rootPath] = this.root;
        let prev = this.root;
        let len = split.length - 1;
        const joinSep = pathImpl.sep;
        let abs = this.rootPath;
        let sawFirst = false;
        for (const part of split) {
            const l = len--;
            prev = prev.child(part, {
                relative: new Array(l).fill('..').join(joinSep),
                relativePosix: new Array(l).fill('..').join('/'),
                fullpath: (abs += (sawFirst ? '' : joinSep) + part),
            });
            sawFirst = true;
        }
        this.cwd = prev;
    }
    /**
     * Get the depth of a provided path, string, or the cwd
     */
    depth(path = this.cwd) {
        if (typeof path === 'string') {
            path = this.cwd.resolve(path);
        }
        return path.depth();
    }
    /**
     * Return the cache of child entries.  Exposed so subclasses can create
     * child Path objects in a platform-specific way.
     *
     * @internal
     */
    childrenCache() {
        return this.#children;
    }
    /**
     * Resolve one or more path strings to a resolved string
     *
     * Same interface as require('path').resolve.
     *
     * Much faster than path.resolve() when called multiple times for the same
     * path, because the resolved Path objects are cached.  Much slower
     * otherwise.
     */
    resolve(...paths) {
        // first figure out the minimum number of paths we have to test
        // we always start at cwd, but any absolutes will bump the start
        let r = '';
        for (let i = paths.length - 1; i >= 0; i--) {
            const p = paths[i];
            if (!p || p === '.')
                continue;
            r = r ? `${p}/${r}` : p;
            if (this.isAbsolute(p)) {
                break;
            }
        }
        const cached = this.#resolveCache.get(r);
        if (cached !== undefined) {
            return cached;
        }
        const result = this.cwd.resolve(r).fullpath();
        this.#resolveCache.set(r, result);
        return result;
    }
    /**
     * Resolve one or more path strings to a resolved string, returning
     * the posix path.  Identical to .resolve() on posix systems, but on
     * windows will return a forward-slash separated UNC path.
     *
     * Same interface as require('path').resolve.
     *
     * Much faster than path.resolve() when called multiple times for the same
     * path, because the resolved Path objects are cached.  Much slower
     * otherwise.
     */
    resolvePosix(...paths) {
        // first figure out the minimum number of paths we have to test
        // we always start at cwd, but any absolutes will bump the start
        let r = '';
        for (let i = paths.length - 1; i >= 0; i--) {
            const p = paths[i];
            if (!p || p === '.')
                continue;
            r = r ? `${p}/${r}` : p;
            if (this.isAbsolute(p)) {
                break;
            }
        }
        const cached = this.#resolvePosixCache.get(r);
        if (cached !== undefined) {
            return cached;
        }
        const result = this.cwd.resolve(r).fullpathPosix();
        this.#resolvePosixCache.set(r, result);
        return result;
    }
    /**
     * find the relative path from the cwd to the supplied path string or entry
     */
    relative(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return entry.relative();
    }
    /**
     * find the relative path from the cwd to the supplied path string or
     * entry, using / as the path delimiter, even on Windows.
     */
    relativePosix(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return entry.relativePosix();
    }
    /**
     * Return the basename for the provided string or Path object
     */
    basename(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return entry.name;
    }
    /**
     * Return the dirname for the provided string or Path object
     */
    dirname(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return (entry.parent || entry).fullpath();
    }
    async readdir(entry = this.cwd, opts = {
        withFileTypes: true,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes } = opts;
        if (!entry.canReaddir()) {
            return [];
        }
        else {
            const p = await entry.readdir();
            return withFileTypes ? p : p.map(e => e.name);
        }
    }
    readdirSync(entry = this.cwd, opts = {
        withFileTypes: true,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true } = opts;
        if (!entry.canReaddir()) {
            return [];
        }
        else if (withFileTypes) {
            return entry.readdirSync();
        }
        else {
            return entry.readdirSync().map(e => e.name);
        }
    }
    /**
     * Call lstat() on the string or Path object, and update all known
     * information that can be determined.
     *
     * Note that unlike `fs.lstat()`, the returned value does not contain some
     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
     * information is required, you will need to call `fs.lstat` yourself.
     *
     * If the Path refers to a nonexistent file, or if the lstat call fails for
     * any reason, `undefined` is returned.  Otherwise the updated Path object is
     * returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async lstat(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return entry.lstat();
    }
    /**
     * synchronous {@link PathScurryBase.lstat}
     */
    lstatSync(entry = this.cwd) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        return entry.lstatSync();
    }
    async readlink(entry = this.cwd, { withFileTypes } = {
        withFileTypes: false,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            withFileTypes = entry.withFileTypes;
            entry = this.cwd;
        }
        const e = await entry.readlink();
        return withFileTypes ? e : e?.fullpath();
    }
    readlinkSync(entry = this.cwd, { withFileTypes } = {
        withFileTypes: false,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            withFileTypes = entry.withFileTypes;
            entry = this.cwd;
        }
        const e = entry.readlinkSync();
        return withFileTypes ? e : e?.fullpath();
    }
    async realpath(entry = this.cwd, { withFileTypes } = {
        withFileTypes: false,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            withFileTypes = entry.withFileTypes;
            entry = this.cwd;
        }
        const e = await entry.realpath();
        return withFileTypes ? e : e?.fullpath();
    }
    realpathSync(entry = this.cwd, { withFileTypes } = {
        withFileTypes: false,
    }) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            withFileTypes = entry.withFileTypes;
            entry = this.cwd;
        }
        const e = entry.realpathSync();
        return withFileTypes ? e : e?.fullpath();
    }
    async walk(entry = this.cwd, opts = {}) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
        const results = [];
        if (!filter || filter(entry)) {
            results.push(withFileTypes ? entry : entry.fullpath());
        }
        const dirs = new Set();
        const walk = (dir, cb) => {
            dirs.add(dir);
            dir.readdirCB((er, entries) => {
                /* c8 ignore start */
                if (er) {
                    return cb(er);
                }
                /* c8 ignore stop */
                let len = entries.length;
                if (!len)
                    return cb();
                const next = () => {
                    if (--len === 0) {
                        cb();
                    }
                };
                for (const e of entries) {
                    if (!filter || filter(e)) {
                        results.push(withFileTypes ? e : e.fullpath());
                    }
                    if (follow && e.isSymbolicLink()) {
                        e.realpath()
                            .then(r => (r?.isUnknown() ? r.lstat() : r))
                            .then(r => r?.shouldWalk(dirs, walkFilter) ? walk(r, next) : next());
                    }
                    else {
                        if (e.shouldWalk(dirs, walkFilter)) {
                            walk(e, next);
                        }
                        else {
                            next();
                        }
                    }
                }
            }, true); // zalgooooooo
        };
        const start = entry;
        return new Promise((res, rej) => {
            walk(start, er => {
                /* c8 ignore start */
                if (er)
                    return rej(er);
                /* c8 ignore stop */
                res(results);
            });
        });
    }
    walkSync(entry = this.cwd, opts = {}) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
        const results = [];
        if (!filter || filter(entry)) {
            results.push(withFileTypes ? entry : entry.fullpath());
        }
        const dirs = new Set([entry]);
        for (const dir of dirs) {
            const entries = dir.readdirSync();
            for (const e of entries) {
                if (!filter || filter(e)) {
                    results.push(withFileTypes ? e : e.fullpath());
                }
                let r = e;
                if (e.isSymbolicLink()) {
                    if (!(follow && (r = e.realpathSync())))
                        continue;
                    if (r.isUnknown())
                        r.lstatSync();
                }
                if (r.shouldWalk(dirs, walkFilter)) {
                    dirs.add(r);
                }
            }
        }
        return results;
    }
    /**
     * Support for `for await`
     *
     * Alias for {@link PathScurryBase.iterate}
     *
     * Note: As of Node 19, this is very slow, compared to other methods of
     * walking.  Consider using {@link PathScurryBase.stream} if memory overhead
     * and backpressure are concerns, or {@link PathScurryBase.walk} if not.
     */
    [Symbol.asyncIterator]() {
        return this.iterate();
    }
    iterate(entry = this.cwd, options = {}) {
        // iterating async over the stream is significantly more performant,
        // especially in the warm-cache scenario, because it buffers up directory
        // entries in the background instead of waiting for a yield for each one.
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            options = entry;
            entry = this.cwd;
        }
        return this.stream(entry, options)[Symbol.asyncIterator]();
    }
    /**
     * Iterating over a PathScurry performs a synchronous walk.
     *
     * Alias for {@link PathScurryBase.iterateSync}
     */
    [Symbol.iterator]() {
        return this.iterateSync();
    }
    *iterateSync(entry = this.cwd, opts = {}) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
        if (!filter || filter(entry)) {
            yield withFileTypes ? entry : entry.fullpath();
        }
        const dirs = new Set([entry]);
        for (const dir of dirs) {
            const entries = dir.readdirSync();
            for (const e of entries) {
                if (!filter || filter(e)) {
                    yield withFileTypes ? e : e.fullpath();
                }
                let r = e;
                if (e.isSymbolicLink()) {
                    if (!(follow && (r = e.realpathSync())))
                        continue;
                    if (r.isUnknown())
                        r.lstatSync();
                }
                if (r.shouldWalk(dirs, walkFilter)) {
                    dirs.add(r);
                }
            }
        }
    }
    stream(entry = this.cwd, opts = {}) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
        const results = new Minipass({ objectMode: true });
        if (!filter || filter(entry)) {
            results.write(withFileTypes ? entry : entry.fullpath());
        }
        const dirs = new Set();
        const queue = [entry];
        let processing = 0;
        const process = () => {
            let paused = false;
            while (!paused) {
                const dir = queue.shift();
                if (!dir) {
                    if (processing === 0)
                        results.end();
                    return;
                }
                processing++;
                dirs.add(dir);
                const onReaddir = (er, entries, didRealpaths = false) => {
                    /* c8 ignore start */
                    if (er)
                        return results.emit('error', er);
                    /* c8 ignore stop */
                    if (follow && !didRealpaths) {
                        const promises = [];
                        for (const e of entries) {
                            if (e.isSymbolicLink()) {
                                promises.push(e
                                    .realpath()
                                    .then((r) => r?.isUnknown() ? r.lstat() : r));
                            }
                        }
                        if (promises.length) {
                            Promise.all(promises).then(() => onReaddir(null, entries, true));
                            return;
                        }
                    }
                    for (const e of entries) {
                        if (e && (!filter || filter(e))) {
                            if (!results.write(withFileTypes ? e : e.fullpath())) {
                                paused = true;
                            }
                        }
                    }
                    processing--;
                    for (const e of entries) {
                        const r = e.realpathCached() || e;
                        if (r.shouldWalk(dirs, walkFilter)) {
                            queue.push(r);
                        }
                    }
                    if (paused && !results.flowing) {
                        results.once('drain', process);
                    }
                    else if (!sync) {
                        process();
                    }
                };
                // zalgo containment
                let sync = true;
                dir.readdirCB(onReaddir, true);
                sync = false;
            }
        };
        process();
        return results;
    }
    streamSync(entry = this.cwd, opts = {}) {
        if (typeof entry === 'string') {
            entry = this.cwd.resolve(entry);
        }
        else if (!(entry instanceof PathBase)) {
            opts = entry;
            entry = this.cwd;
        }
        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
        const results = new Minipass({ objectMode: true });
        const dirs = new Set();
        if (!filter || filter(entry)) {
            results.write(withFileTypes ? entry : entry.fullpath());
        }
        const queue = [entry];
        let processing = 0;
        const process = () => {
            let paused = false;
            while (!paused) {
                const dir = queue.shift();
                if (!dir) {
                    if (processing === 0)
                        results.end();
                    return;
                }
                processing++;
                dirs.add(dir);
                const entries = dir.readdirSync();
                for (const e of entries) {
                    if (!filter || filter(e)) {
                        if (!results.write(withFileTypes ? e : e.fullpath())) {
                            paused = true;
                        }
                    }
                }
                processing--;
                for (const e of entries) {
                    let r = e;
                    if (e.isSymbolicLink()) {
                        if (!(follow && (r = e.realpathSync())))
                            continue;
                        if (r.isUnknown())
                            r.lstatSync();
                    }
                    if (r.shouldWalk(dirs, walkFilter)) {
                        queue.push(r);
                    }
                }
            }
            if (paused && !results.flowing)
                results.once('drain', process);
        };
        process();
        return results;
    }
    chdir(path = this.cwd) {
        const oldCwd = this.cwd;
        this.cwd = typeof path === 'string' ? this.cwd.resolve(path) : path;
        this.cwd[setAsCwd](oldCwd);
    }
}
/**
 * Windows implementation of {@link PathScurryBase}
 *
 * Defaults to case insensitve, uses `'\\'` to generate path strings.  Uses
 * {@link PathWin32} for Path objects.
 */
class PathScurryWin32 extends PathScurryBase {
    /**
     * separator for generating path strings
     */
    sep = '\\';
    constructor(cwd = process.cwd(), opts = {}) {
        const { nocase = true } = opts;
        super(cwd, win32, '\\', { ...opts, nocase });
        this.nocase = nocase;
        for (let p = this.cwd; p; p = p.parent) {
            p.nocase = this.nocase;
        }
    }
    /**
     * @internal
     */
    parseRootPath(dir) {
        // if the path starts with a single separator, it's not a UNC, and we'll
        // just get separator as the root, and driveFromUNC will return \
        // In that case, mount \ on the root from the cwd.
        return win32.parse(dir).root.toUpperCase();
    }
    /**
     * @internal
     */
    newRoot(fs) {
        return new PathWin32(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });
    }
    /**
     * Return true if the provided path string is an absolute path
     */
    isAbsolute(p) {
        return (p.startsWith('/') || p.startsWith('\\') || /^[a-z]:(\/|\\)/i.test(p));
    }
}
/**
 * {@link PathScurryBase} implementation for all posix systems other than Darwin.
 *
 * Defaults to case-sensitive matching, uses `'/'` to generate path strings.
 *
 * Uses {@link PathPosix} for Path objects.
 */
class PathScurryPosix extends PathScurryBase {
    /**
     * separator for generating path strings
     */
    sep = '/';
    constructor(cwd = process.cwd(), opts = {}) {
        const { nocase = false } = opts;
        super(cwd, posix, '/', { ...opts, nocase });
        this.nocase = nocase;
    }
    /**
     * @internal
     */
    parseRootPath(_dir) {
        return '/';
    }
    /**
     * @internal
     */
    newRoot(fs) {
        return new PathPosix(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });
    }
    /**
     * Return true if the provided path string is an absolute path
     */
    isAbsolute(p) {
        return p.startsWith('/');
    }
}
/**
 * {@link PathScurryBase} implementation for Darwin (macOS) systems.
 *
 * Defaults to case-insensitive matching, uses `'/'` for generating path
 * strings.
 *
 * Uses {@link PathPosix} for Path objects.
 */
class PathScurryDarwin extends PathScurryPosix {
    constructor(cwd = process.cwd(), opts = {}) {
        const { nocase = true } = opts;
        super(cwd, { ...opts, nocase });
    }
}
/**
 * Default {@link PathBase} implementation for the current platform.
 *
 * {@link PathWin32} on Windows systems, {@link PathPosix} on all others.
 */
process.platform === 'win32' ? PathWin32 : PathPosix;
/**
 * Default {@link PathScurryBase} implementation for the current platform.
 *
 * {@link PathScurryWin32} on Windows systems, {@link PathScurryDarwin} on
 * Darwin (macOS) systems, {@link PathScurryPosix} on all others.
 */
const PathScurry = process.platform === 'win32' ? PathScurryWin32
    : process.platform === 'darwin' ? PathScurryDarwin
        : PathScurryPosix;

// this is just a very light wrapper around 2 arrays with an offset index
const isPatternList = (pl) => pl.length >= 1;
const isGlobList = (gl) => gl.length >= 1;
/**
 * An immutable-ish view on an array of glob parts and their parsed
 * results
 */
class Pattern {
    #patternList;
    #globList;
    #index;
    length;
    #platform;
    #rest;
    #globString;
    #isDrive;
    #isUNC;
    #isAbsolute;
    #followGlobstar = true;
    constructor(patternList, globList, index, platform) {
        if (!isPatternList(patternList)) {
            throw new TypeError('empty pattern list');
        }
        if (!isGlobList(globList)) {
            throw new TypeError('empty glob list');
        }
        if (globList.length !== patternList.length) {
            throw new TypeError('mismatched pattern list and glob list lengths');
        }
        this.length = patternList.length;
        if (index < 0 || index >= this.length) {
            throw new TypeError('index out of range');
        }
        this.#patternList = patternList;
        this.#globList = globList;
        this.#index = index;
        this.#platform = platform;
        // normalize root entries of absolute patterns on initial creation.
        if (this.#index === 0) {
            // c: => ['c:/']
            // C:/ => ['C:/']
            // C:/x => ['C:/', 'x']
            // //host/share => ['//host/share/']
            // //host/share/ => ['//host/share/']
            // //host/share/x => ['//host/share/', 'x']
            // /etc => ['/', 'etc']
            // / => ['/']
            if (this.isUNC()) {
                // '' / '' / 'host' / 'share'
                const [p0, p1, p2, p3, ...prest] = this.#patternList;
                const [g0, g1, g2, g3, ...grest] = this.#globList;
                if (prest[0] === '') {
                    // ends in /
                    prest.shift();
                    grest.shift();
                }
                const p = [p0, p1, p2, p3, ''].join('/');
                const g = [g0, g1, g2, g3, ''].join('/');
                this.#patternList = [p, ...prest];
                this.#globList = [g, ...grest];
                this.length = this.#patternList.length;
            }
            else if (this.isDrive() || this.isAbsolute()) {
                const [p1, ...prest] = this.#patternList;
                const [g1, ...grest] = this.#globList;
                if (prest[0] === '') {
                    // ends in /
                    prest.shift();
                    grest.shift();
                }
                const p = p1 + '/';
                const g = g1 + '/';
                this.#patternList = [p, ...prest];
                this.#globList = [g, ...grest];
                this.length = this.#patternList.length;
            }
        }
    }
    /**
     * The first entry in the parsed list of patterns
     */
    pattern() {
        return this.#patternList[this.#index];
    }
    /**
     * true of if pattern() returns a string
     */
    isString() {
        return typeof this.#patternList[this.#index] === 'string';
    }
    /**
     * true of if pattern() returns GLOBSTAR
     */
    isGlobstar() {
        return this.#patternList[this.#index] === GLOBSTAR;
    }
    /**
     * true if pattern() returns a regexp
     */
    isRegExp() {
        return this.#patternList[this.#index] instanceof RegExp;
    }
    /**
     * The /-joined set of glob parts that make up this pattern
     */
    globString() {
        return (this.#globString =
            this.#globString ||
                (this.#index === 0 ?
                    this.isAbsolute() ?
                        this.#globList[0] + this.#globList.slice(1).join('/')
                        : this.#globList.join('/')
                    : this.#globList.slice(this.#index).join('/')));
    }
    /**
     * true if there are more pattern parts after this one
     */
    hasMore() {
        return this.length > this.#index + 1;
    }
    /**
     * The rest of the pattern after this part, or null if this is the end
     */
    rest() {
        if (this.#rest !== undefined)
            return this.#rest;
        if (!this.hasMore())
            return (this.#rest = null);
        this.#rest = new Pattern(this.#patternList, this.#globList, this.#index + 1, this.#platform);
        this.#rest.#isAbsolute = this.#isAbsolute;
        this.#rest.#isUNC = this.#isUNC;
        this.#rest.#isDrive = this.#isDrive;
        return this.#rest;
    }
    /**
     * true if the pattern represents a //unc/path/ on windows
     */
    isUNC() {
        const pl = this.#patternList;
        return this.#isUNC !== undefined ?
            this.#isUNC
            : (this.#isUNC =
                this.#platform === 'win32' &&
                    this.#index === 0 &&
                    pl[0] === '' &&
                    pl[1] === '' &&
                    typeof pl[2] === 'string' &&
                    !!pl[2] &&
                    typeof pl[3] === 'string' &&
                    !!pl[3]);
    }
    // pattern like C:/...
    // split = ['C:', ...]
    // XXX: would be nice to handle patterns like `c:*` to test the cwd
    // in c: for *, but I don't know of a way to even figure out what that
    // cwd is without actually chdir'ing into it?
    /**
     * True if the pattern starts with a drive letter on Windows
     */
    isDrive() {
        const pl = this.#patternList;
        return this.#isDrive !== undefined ?
            this.#isDrive
            : (this.#isDrive =
                this.#platform === 'win32' &&
                    this.#index === 0 &&
                    this.length > 1 &&
                    typeof pl[0] === 'string' &&
                    /^[a-z]:$/i.test(pl[0]));
    }
    // pattern = '/' or '/...' or '/x/...'
    // split = ['', ''] or ['', ...] or ['', 'x', ...]
    // Drive and UNC both considered absolute on windows
    /**
     * True if the pattern is rooted on an absolute path
     */
    isAbsolute() {
        const pl = this.#patternList;
        return this.#isAbsolute !== undefined ?
            this.#isAbsolute
            : (this.#isAbsolute =
                (pl[0] === '' && pl.length > 1) ||
                    this.isDrive() ||
                    this.isUNC());
    }
    /**
     * consume the root of the pattern, and return it
     */
    root() {
        const p = this.#patternList[0];
        return (typeof p === 'string' && this.isAbsolute() && this.#index === 0) ?
            p
            : '';
    }
    /**
     * Check to see if the current globstar pattern is allowed to follow
     * a symbolic link.
     */
    checkFollowGlobstar() {
        return !(this.#index === 0 ||
            !this.isGlobstar() ||
            !this.#followGlobstar);
    }
    /**
     * Mark that the current globstar pattern is following a symbolic link
     */
    markFollowGlobstar() {
        if (this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar)
            return false;
        this.#followGlobstar = false;
        return true;
    }
}

// give it a pattern, and it'll be able to tell you if
// a given path should be ignored.
// Ignoring a path ignores its children if the pattern ends in /**
// Ignores are always parsed in dot:true mode
const defaultPlatform$1 = (typeof process === 'object' &&
    process &&
    typeof process.platform === 'string') ?
    process.platform
    : 'linux';
/**
 * Class used to process ignored patterns
 */
class Ignore {
    relative;
    relativeChildren;
    absolute;
    absoluteChildren;
    platform;
    mmopts;
    constructor(ignored, { nobrace, nocase, noext, noglobstar, platform = defaultPlatform$1, }) {
        this.relative = [];
        this.absolute = [];
        this.relativeChildren = [];
        this.absoluteChildren = [];
        this.platform = platform;
        this.mmopts = {
            dot: true,
            nobrace,
            nocase,
            noext,
            noglobstar,
            optimizationLevel: 2,
            platform,
            nocomment: true,
            nonegate: true,
        };
        for (const ign of ignored)
            this.add(ign);
    }
    add(ign) {
        // this is a little weird, but it gives us a clean set of optimized
        // minimatch matchers, without getting tripped up if one of them
        // ends in /** inside a brace section, and it's only inefficient at
        // the start of the walk, not along it.
        // It'd be nice if the Pattern class just had a .test() method, but
        // handling globstars is a bit of a pita, and that code already lives
        // in minimatch anyway.
        // Another way would be if maybe Minimatch could take its set/globParts
        // as an option, and then we could at least just use Pattern to test
        // for absolute-ness.
        // Yet another way, Minimatch could take an array of glob strings, and
        // a cwd option, and do the right thing.
        const mm = new Minimatch(ign, this.mmopts);
        for (let i = 0; i < mm.set.length; i++) {
            const parsed = mm.set[i];
            const globParts = mm.globParts[i];
            /* c8 ignore start */
            if (!parsed || !globParts) {
                throw new Error('invalid pattern object');
            }
            // strip off leading ./ portions
            // https://github.com/isaacs/node-glob/issues/570
            while (parsed[0] === '.' && globParts[0] === '.') {
                parsed.shift();
                globParts.shift();
            }
            /* c8 ignore stop */
            const p = new Pattern(parsed, globParts, 0, this.platform);
            const m = new Minimatch(p.globString(), this.mmopts);
            const children = globParts[globParts.length - 1] === '**';
            const absolute = p.isAbsolute();
            if (absolute)
                this.absolute.push(m);
            else
                this.relative.push(m);
            if (children) {
                if (absolute)
                    this.absoluteChildren.push(m);
                else
                    this.relativeChildren.push(m);
            }
        }
    }
    ignored(p) {
        const fullpath = p.fullpath();
        const fullpaths = `${fullpath}/`;
        const relative = p.relative() || '.';
        const relatives = `${relative}/`;
        for (const m of this.relative) {
            if (m.match(relative) || m.match(relatives))
                return true;
        }
        for (const m of this.absolute) {
            if (m.match(fullpath) || m.match(fullpaths))
                return true;
        }
        return false;
    }
    childrenIgnored(p) {
        const fullpath = p.fullpath() + '/';
        const relative = (p.relative() || '.') + '/';
        for (const m of this.relativeChildren) {
            if (m.match(relative))
                return true;
        }
        for (const m of this.absoluteChildren) {
            if (m.match(fullpath))
                return true;
        }
        return false;
    }
}

// synchronous utility for filtering entries and calculating subwalks
/**
 * A cache of which patterns have been processed for a given Path
 */
class HasWalkedCache {
    store;
    constructor(store = new Map()) {
        this.store = store;
    }
    copy() {
        return new HasWalkedCache(new Map(this.store));
    }
    hasWalked(target, pattern) {
        return this.store.get(target.fullpath())?.has(pattern.globString());
    }
    storeWalked(target, pattern) {
        const fullpath = target.fullpath();
        const cached = this.store.get(fullpath);
        if (cached)
            cached.add(pattern.globString());
        else
            this.store.set(fullpath, new Set([pattern.globString()]));
    }
}
/**
 * A record of which paths have been matched in a given walk step,
 * and whether they only are considered a match if they are a directory,
 * and whether their absolute or relative path should be returned.
 */
class MatchRecord {
    store = new Map();
    add(target, absolute, ifDir) {
        const n = (absolute ? 2 : 0) | (ifDir ? 1 : 0);
        const current = this.store.get(target);
        this.store.set(target, current === undefined ? n : n & current);
    }
    // match, absolute, ifdir
    entries() {
        return [...this.store.entries()].map(([path, n]) => [
            path,
            !!(n & 2),
            !!(n & 1),
        ]);
    }
}
/**
 * A collection of patterns that must be processed in a subsequent step
 * for a given path.
 */
class SubWalks {
    store = new Map();
    add(target, pattern) {
        if (!target.canReaddir()) {
            return;
        }
        const subs = this.store.get(target);
        if (subs) {
            if (!subs.find(p => p.globString() === pattern.globString())) {
                subs.push(pattern);
            }
        }
        else
            this.store.set(target, [pattern]);
    }
    get(target) {
        const subs = this.store.get(target);
        /* c8 ignore start */
        if (!subs) {
            throw new Error('attempting to walk unknown path');
        }
        /* c8 ignore stop */
        return subs;
    }
    entries() {
        return this.keys().map(k => [k, this.store.get(k)]);
    }
    keys() {
        return [...this.store.keys()].filter(t => t.canReaddir());
    }
}
/**
 * The class that processes patterns for a given path.
 *
 * Handles child entry filtering, and determining whether a path's
 * directory contents must be read.
 */
class Processor {
    hasWalkedCache;
    matches = new MatchRecord();
    subwalks = new SubWalks();
    patterns;
    follow;
    dot;
    opts;
    constructor(opts, hasWalkedCache) {
        this.opts = opts;
        this.follow = !!opts.follow;
        this.dot = !!opts.dot;
        this.hasWalkedCache =
            hasWalkedCache ? hasWalkedCache.copy() : new HasWalkedCache();
    }
    processPatterns(target, patterns) {
        this.patterns = patterns;
        const processingSet = patterns.map(p => [target, p]);
        // map of paths to the magic-starting subwalks they need to walk
        // first item in patterns is the filter
        for (let [t, pattern] of processingSet) {
            this.hasWalkedCache.storeWalked(t, pattern);
            const root = pattern.root();
            const absolute = pattern.isAbsolute() && this.opts.absolute !== false;
            // start absolute patterns at root
            if (root) {
                t = t.resolve(root === '/' && this.opts.root !== undefined ?
                    this.opts.root
                    : root);
                const rest = pattern.rest();
                if (!rest) {
                    this.matches.add(t, true, false);
                    continue;
                }
                else {
                    pattern = rest;
                }
            }
            if (t.isENOENT())
                continue;
            let p;
            let rest;
            let changed = false;
            while (typeof (p = pattern.pattern()) === 'string' &&
                (rest = pattern.rest())) {
                const c = t.resolve(p);
                t = c;
                pattern = rest;
                changed = true;
            }
            p = pattern.pattern();
            rest = pattern.rest();
            if (changed) {
                if (this.hasWalkedCache.hasWalked(t, pattern))
                    continue;
                this.hasWalkedCache.storeWalked(t, pattern);
            }
            // now we have either a final string for a known entry,
            // more strings for an unknown entry,
            // or a pattern starting with magic, mounted on t.
            if (typeof p === 'string') {
                // must not be final entry, otherwise we would have
                // concatenated it earlier.
                const ifDir = p === '..' || p === '' || p === '.';
                this.matches.add(t.resolve(p), absolute, ifDir);
                continue;
            }
            else if (p === GLOBSTAR) {
                // if no rest, match and subwalk pattern
                // if rest, process rest and subwalk pattern
                // if it's a symlink, but we didn't get here by way of a
                // globstar match (meaning it's the first time THIS globstar
                // has traversed a symlink), then we follow it. Otherwise, stop.
                if (!t.isSymbolicLink() ||
                    this.follow ||
                    pattern.checkFollowGlobstar()) {
                    this.subwalks.add(t, pattern);
                }
                const rp = rest?.pattern();
                const rrest = rest?.rest();
                if (!rest || ((rp === '' || rp === '.') && !rrest)) {
                    // only HAS to be a dir if it ends in **/ or **/.
                    // but ending in ** will match files as well.
                    this.matches.add(t, absolute, rp === '' || rp === '.');
                }
                else {
                    if (rp === '..') {
                        // this would mean you're matching **/.. at the fs root,
                        // and no thanks, I'm not gonna test that specific case.
                        /* c8 ignore start */
                        const tp = t.parent || t;
                        /* c8 ignore stop */
                        if (!rrest)
                            this.matches.add(tp, absolute, true);
                        else if (!this.hasWalkedCache.hasWalked(tp, rrest)) {
                            this.subwalks.add(tp, rrest);
                        }
                    }
                }
            }
            else if (p instanceof RegExp) {
                this.subwalks.add(t, pattern);
            }
        }
        return this;
    }
    subwalkTargets() {
        return this.subwalks.keys();
    }
    child() {
        return new Processor(this.opts, this.hasWalkedCache);
    }
    // return a new Processor containing the subwalks for each
    // child entry, and a set of matches, and
    // a hasWalkedCache that's a copy of this one
    // then we're going to call
    filterEntries(parent, entries) {
        const patterns = this.subwalks.get(parent);
        // put matches and entry walks into the results processor
        const results = this.child();
        for (const e of entries) {
            for (const pattern of patterns) {
                const absolute = pattern.isAbsolute();
                const p = pattern.pattern();
                const rest = pattern.rest();
                if (p === GLOBSTAR) {
                    results.testGlobstar(e, pattern, rest, absolute);
                }
                else if (p instanceof RegExp) {
                    results.testRegExp(e, p, rest, absolute);
                }
                else {
                    results.testString(e, p, rest, absolute);
                }
            }
        }
        return results;
    }
    testGlobstar(e, pattern, rest, absolute) {
        if (this.dot || !e.name.startsWith('.')) {
            if (!pattern.hasMore()) {
                this.matches.add(e, absolute, false);
            }
            if (e.canReaddir()) {
                // if we're in follow mode or it's not a symlink, just keep
                // testing the same pattern. If there's more after the globstar,
                // then this symlink consumes the globstar. If not, then we can
                // follow at most ONE symlink along the way, so we mark it, which
                // also checks to ensure that it wasn't already marked.
                if (this.follow || !e.isSymbolicLink()) {
                    this.subwalks.add(e, pattern);
                }
                else if (e.isSymbolicLink()) {
                    if (rest && pattern.checkFollowGlobstar()) {
                        this.subwalks.add(e, rest);
                    }
                    else if (pattern.markFollowGlobstar()) {
                        this.subwalks.add(e, pattern);
                    }
                }
            }
        }
        // if the NEXT thing matches this entry, then also add
        // the rest.
        if (rest) {
            const rp = rest.pattern();
            if (typeof rp === 'string' &&
                // dots and empty were handled already
                rp !== '..' &&
                rp !== '' &&
                rp !== '.') {
                this.testString(e, rp, rest.rest(), absolute);
            }
            else if (rp === '..') {
                /* c8 ignore start */
                const ep = e.parent || e;
                /* c8 ignore stop */
                this.subwalks.add(ep, rest);
            }
            else if (rp instanceof RegExp) {
                this.testRegExp(e, rp, rest.rest(), absolute);
            }
        }
    }
    testRegExp(e, p, rest, absolute) {
        if (!p.test(e.name))
            return;
        if (!rest) {
            this.matches.add(e, absolute, false);
        }
        else {
            this.subwalks.add(e, rest);
        }
    }
    testString(e, p, rest, absolute) {
        // should never happen?
        if (!e.isNamed(p))
            return;
        if (!rest) {
            this.matches.add(e, absolute, false);
        }
        else {
            this.subwalks.add(e, rest);
        }
    }
}

/**
 * Single-use utility classes to provide functionality to the {@link Glob}
 * methods.
 *
 * @module
 */
const makeIgnore = (ignore, opts) => typeof ignore === 'string' ? new Ignore([ignore], opts)
    : Array.isArray(ignore) ? new Ignore(ignore, opts)
        : ignore;
/**
 * basic walking utilities that all the glob walker types use
 */
class GlobUtil {
    path;
    patterns;
    opts;
    seen = new Set();
    paused = false;
    aborted = false;
    #onResume = [];
    #ignore;
    #sep;
    signal;
    maxDepth;
    includeChildMatches;
    constructor(patterns, path, opts) {
        this.patterns = patterns;
        this.path = path;
        this.opts = opts;
        this.#sep = !opts.posix && opts.platform === 'win32' ? '\\' : '/';
        this.includeChildMatches = opts.includeChildMatches !== false;
        if (opts.ignore || !this.includeChildMatches) {
            this.#ignore = makeIgnore(opts.ignore ?? [], opts);
            if (!this.includeChildMatches &&
                typeof this.#ignore.add !== 'function') {
                const m = 'cannot ignore child matches, ignore lacks add() method.';
                throw new Error(m);
            }
        }
        // ignore, always set with maxDepth, but it's optional on the
        // GlobOptions type
        /* c8 ignore start */
        this.maxDepth = opts.maxDepth || Infinity;
        /* c8 ignore stop */
        if (opts.signal) {
            this.signal = opts.signal;
            this.signal.addEventListener('abort', () => {
                this.#onResume.length = 0;
            });
        }
    }
    #ignored(path) {
        return this.seen.has(path) || !!this.#ignore?.ignored?.(path);
    }
    #childrenIgnored(path) {
        return !!this.#ignore?.childrenIgnored?.(path);
    }
    // backpressure mechanism
    pause() {
        this.paused = true;
    }
    resume() {
        /* c8 ignore start */
        if (this.signal?.aborted)
            return;
        /* c8 ignore stop */
        this.paused = false;
        let fn = undefined;
        while (!this.paused && (fn = this.#onResume.shift())) {
            fn();
        }
    }
    onResume(fn) {
        if (this.signal?.aborted)
            return;
        /* c8 ignore start */
        if (!this.paused) {
            fn();
        }
        else {
            /* c8 ignore stop */
            this.#onResume.push(fn);
        }
    }
    // do the requisite realpath/stat checking, and return the path
    // to add or undefined to filter it out.
    async matchCheck(e, ifDir) {
        if (ifDir && this.opts.nodir)
            return undefined;
        let rpc;
        if (this.opts.realpath) {
            rpc = e.realpathCached() || (await e.realpath());
            if (!rpc)
                return undefined;
            e = rpc;
        }
        const needStat = e.isUnknown() || this.opts.stat;
        const s = needStat ? await e.lstat() : e;
        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
            const target = await s.realpath();
            /* c8 ignore start */
            if (target && (target.isUnknown() || this.opts.stat)) {
                await target.lstat();
            }
            /* c8 ignore stop */
        }
        return this.matchCheckTest(s, ifDir);
    }
    matchCheckTest(e, ifDir) {
        return (e &&
            (this.maxDepth === Infinity || e.depth() <= this.maxDepth) &&
            (!ifDir || e.canReaddir()) &&
            (!this.opts.nodir || !e.isDirectory()) &&
            (!this.opts.nodir ||
                !this.opts.follow ||
                !e.isSymbolicLink() ||
                !e.realpathCached()?.isDirectory()) &&
            !this.#ignored(e)) ?
            e
            : undefined;
    }
    matchCheckSync(e, ifDir) {
        if (ifDir && this.opts.nodir)
            return undefined;
        let rpc;
        if (this.opts.realpath) {
            rpc = e.realpathCached() || e.realpathSync();
            if (!rpc)
                return undefined;
            e = rpc;
        }
        const needStat = e.isUnknown() || this.opts.stat;
        const s = needStat ? e.lstatSync() : e;
        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
            const target = s.realpathSync();
            if (target && (target?.isUnknown() || this.opts.stat)) {
                target.lstatSync();
            }
        }
        return this.matchCheckTest(s, ifDir);
    }
    matchFinish(e, absolute) {
        if (this.#ignored(e))
            return;
        // we know we have an ignore if this is false, but TS doesn't
        if (!this.includeChildMatches && this.#ignore?.add) {
            const ign = `${e.relativePosix()}/**`;
            this.#ignore.add(ign);
        }
        const abs = this.opts.absolute === undefined ? absolute : this.opts.absolute;
        this.seen.add(e);
        const mark = this.opts.mark && e.isDirectory() ? this.#sep : '';
        // ok, we have what we need!
        if (this.opts.withFileTypes) {
            this.matchEmit(e);
        }
        else if (abs) {
            const abs = this.opts.posix ? e.fullpathPosix() : e.fullpath();
            this.matchEmit(abs + mark);
        }
        else {
            const rel = this.opts.posix ? e.relativePosix() : e.relative();
            const pre = this.opts.dotRelative && !rel.startsWith('..' + this.#sep) ?
                '.' + this.#sep
                : '';
            this.matchEmit(!rel ? '.' + mark : pre + rel + mark);
        }
    }
    async match(e, absolute, ifDir) {
        const p = await this.matchCheck(e, ifDir);
        if (p)
            this.matchFinish(p, absolute);
    }
    matchSync(e, absolute, ifDir) {
        const p = this.matchCheckSync(e, ifDir);
        if (p)
            this.matchFinish(p, absolute);
    }
    walkCB(target, patterns, cb) {
        /* c8 ignore start */
        if (this.signal?.aborted)
            cb();
        /* c8 ignore stop */
        this.walkCB2(target, patterns, new Processor(this.opts), cb);
    }
    walkCB2(target, patterns, processor, cb) {
        if (this.#childrenIgnored(target))
            return cb();
        if (this.signal?.aborted)
            cb();
        if (this.paused) {
            this.onResume(() => this.walkCB2(target, patterns, processor, cb));
            return;
        }
        processor.processPatterns(target, patterns);
        // done processing.  all of the above is sync, can be abstracted out.
        // subwalks is a map of paths to the entry filters they need
        // matches is a map of paths to [absolute, ifDir] tuples.
        let tasks = 1;
        const next = () => {
            if (--tasks === 0)
                cb();
        };
        for (const [m, absolute, ifDir] of processor.matches.entries()) {
            if (this.#ignored(m))
                continue;
            tasks++;
            this.match(m, absolute, ifDir).then(() => next());
        }
        for (const t of processor.subwalkTargets()) {
            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
                continue;
            }
            tasks++;
            const childrenCached = t.readdirCached();
            if (t.calledReaddir())
                this.walkCB3(t, childrenCached, processor, next);
            else {
                t.readdirCB((_, entries) => this.walkCB3(t, entries, processor, next), true);
            }
        }
        next();
    }
    walkCB3(target, entries, processor, cb) {
        processor = processor.filterEntries(target, entries);
        let tasks = 1;
        const next = () => {
            if (--tasks === 0)
                cb();
        };
        for (const [m, absolute, ifDir] of processor.matches.entries()) {
            if (this.#ignored(m))
                continue;
            tasks++;
            this.match(m, absolute, ifDir).then(() => next());
        }
        for (const [target, patterns] of processor.subwalks.entries()) {
            tasks++;
            this.walkCB2(target, patterns, processor.child(), next);
        }
        next();
    }
    walkCBSync(target, patterns, cb) {
        /* c8 ignore start */
        if (this.signal?.aborted)
            cb();
        /* c8 ignore stop */
        this.walkCB2Sync(target, patterns, new Processor(this.opts), cb);
    }
    walkCB2Sync(target, patterns, processor, cb) {
        if (this.#childrenIgnored(target))
            return cb();
        if (this.signal?.aborted)
            cb();
        if (this.paused) {
            this.onResume(() => this.walkCB2Sync(target, patterns, processor, cb));
            return;
        }
        processor.processPatterns(target, patterns);
        // done processing.  all of the above is sync, can be abstracted out.
        // subwalks is a map of paths to the entry filters they need
        // matches is a map of paths to [absolute, ifDir] tuples.
        let tasks = 1;
        const next = () => {
            if (--tasks === 0)
                cb();
        };
        for (const [m, absolute, ifDir] of processor.matches.entries()) {
            if (this.#ignored(m))
                continue;
            this.matchSync(m, absolute, ifDir);
        }
        for (const t of processor.subwalkTargets()) {
            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
                continue;
            }
            tasks++;
            const children = t.readdirSync();
            this.walkCB3Sync(t, children, processor, next);
        }
        next();
    }
    walkCB3Sync(target, entries, processor, cb) {
        processor = processor.filterEntries(target, entries);
        let tasks = 1;
        const next = () => {
            if (--tasks === 0)
                cb();
        };
        for (const [m, absolute, ifDir] of processor.matches.entries()) {
            if (this.#ignored(m))
                continue;
            this.matchSync(m, absolute, ifDir);
        }
        for (const [target, patterns] of processor.subwalks.entries()) {
            tasks++;
            this.walkCB2Sync(target, patterns, processor.child(), next);
        }
        next();
    }
}
class GlobWalker extends GlobUtil {
    matches = new Set();
    constructor(patterns, path, opts) {
        super(patterns, path, opts);
    }
    matchEmit(e) {
        this.matches.add(e);
    }
    async walk() {
        if (this.signal?.aborted)
            throw this.signal.reason;
        if (this.path.isUnknown()) {
            await this.path.lstat();
        }
        await new Promise((res, rej) => {
            this.walkCB(this.path, this.patterns, () => {
                if (this.signal?.aborted) {
                    rej(this.signal.reason);
                }
                else {
                    res(this.matches);
                }
            });
        });
        return this.matches;
    }
    walkSync() {
        if (this.signal?.aborted)
            throw this.signal.reason;
        if (this.path.isUnknown()) {
            this.path.lstatSync();
        }
        // nothing for the callback to do, because this never pauses
        this.walkCBSync(this.path, this.patterns, () => {
            if (this.signal?.aborted)
                throw this.signal.reason;
        });
        return this.matches;
    }
}
class GlobStream extends GlobUtil {
    results;
    constructor(patterns, path, opts) {
        super(patterns, path, opts);
        this.results = new Minipass({
            signal: this.signal,
            objectMode: true,
        });
        this.results.on('drain', () => this.resume());
        this.results.on('resume', () => this.resume());
    }
    matchEmit(e) {
        this.results.write(e);
        if (!this.results.flowing)
            this.pause();
    }
    stream() {
        const target = this.path;
        if (target.isUnknown()) {
            target.lstat().then(() => {
                this.walkCB(target, this.patterns, () => this.results.end());
            });
        }
        else {
            this.walkCB(target, this.patterns, () => this.results.end());
        }
        return this.results;
    }
    streamSync() {
        if (this.path.isUnknown()) {
            this.path.lstatSync();
        }
        this.walkCBSync(this.path, this.patterns, () => this.results.end());
        return this.results;
    }
}

// if no process global, just call it linux.
// so we default to case-sensitive, / separators
const defaultPlatform = (typeof process === 'object' &&
    process &&
    typeof process.platform === 'string') ?
    process.platform
    : 'linux';
/**
 * An object that can perform glob pattern traversals.
 */
class Glob {
    absolute;
    cwd;
    root;
    dot;
    dotRelative;
    follow;
    ignore;
    magicalBraces;
    mark;
    matchBase;
    maxDepth;
    nobrace;
    nocase;
    nodir;
    noext;
    noglobstar;
    pattern;
    platform;
    realpath;
    scurry;
    stat;
    signal;
    windowsPathsNoEscape;
    withFileTypes;
    includeChildMatches;
    /**
     * The options provided to the constructor.
     */
    opts;
    /**
     * An array of parsed immutable {@link Pattern} objects.
     */
    patterns;
    /**
     * All options are stored as properties on the `Glob` object.
     *
     * See {@link GlobOptions} for full options descriptions.
     *
     * Note that a previous `Glob` object can be passed as the
     * `GlobOptions` to another `Glob` instantiation to re-use settings
     * and caches with a new pattern.
     *
     * Traversal functions can be called multiple times to run the walk
     * again.
     */
    constructor(pattern, opts) {
        /* c8 ignore start */
        if (!opts)
            throw new TypeError('glob options required');
        /* c8 ignore stop */
        this.withFileTypes = !!opts.withFileTypes;
        this.signal = opts.signal;
        this.follow = !!opts.follow;
        this.dot = !!opts.dot;
        this.dotRelative = !!opts.dotRelative;
        this.nodir = !!opts.nodir;
        this.mark = !!opts.mark;
        if (!opts.cwd) {
            this.cwd = '';
        }
        else if (opts.cwd instanceof URL || opts.cwd.startsWith('file://')) {
            opts.cwd = fileURLToPath(opts.cwd);
        }
        this.cwd = opts.cwd || '';
        this.root = opts.root;
        this.magicalBraces = !!opts.magicalBraces;
        this.nobrace = !!opts.nobrace;
        this.noext = !!opts.noext;
        this.realpath = !!opts.realpath;
        this.absolute = opts.absolute;
        this.includeChildMatches = opts.includeChildMatches !== false;
        this.noglobstar = !!opts.noglobstar;
        this.matchBase = !!opts.matchBase;
        this.maxDepth =
            typeof opts.maxDepth === 'number' ? opts.maxDepth : Infinity;
        this.stat = !!opts.stat;
        this.ignore = opts.ignore;
        if (this.withFileTypes && this.absolute !== undefined) {
            throw new Error('cannot set absolute and withFileTypes:true');
        }
        if (typeof pattern === 'string') {
            pattern = [pattern];
        }
        this.windowsPathsNoEscape =
            !!opts.windowsPathsNoEscape ||
                opts.allowWindowsEscape ===
                    false;
        if (this.windowsPathsNoEscape) {
            pattern = pattern.map(p => p.replace(/\\/g, '/'));
        }
        if (this.matchBase) {
            if (opts.noglobstar) {
                throw new TypeError('base matching requires globstar');
            }
            pattern = pattern.map(p => (p.includes('/') ? p : `./**/${p}`));
        }
        this.pattern = pattern;
        this.platform = opts.platform || defaultPlatform;
        this.opts = { ...opts, platform: this.platform };
        if (opts.scurry) {
            this.scurry = opts.scurry;
            if (opts.nocase !== undefined &&
                opts.nocase !== opts.scurry.nocase) {
                throw new Error('nocase option contradicts provided scurry option');
            }
        }
        else {
            const Scurry = opts.platform === 'win32' ? PathScurryWin32
                : opts.platform === 'darwin' ? PathScurryDarwin
                    : opts.platform ? PathScurryPosix
                        : PathScurry;
            this.scurry = new Scurry(this.cwd, {
                nocase: opts.nocase,
                fs: opts.fs,
            });
        }
        this.nocase = this.scurry.nocase;
        // If you do nocase:true on a case-sensitive file system, then
        // we need to use regexps instead of strings for non-magic
        // path portions, because statting `aBc` won't return results
        // for the file `AbC` for example.
        const nocaseMagicOnly = this.platform === 'darwin' || this.platform === 'win32';
        const mmo = {
            // default nocase based on platform
            ...opts,
            dot: this.dot,
            matchBase: this.matchBase,
            nobrace: this.nobrace,
            nocase: this.nocase,
            nocaseMagicOnly,
            nocomment: true,
            noext: this.noext,
            nonegate: true,
            optimizationLevel: 2,
            platform: this.platform,
            windowsPathsNoEscape: this.windowsPathsNoEscape,
            debug: !!this.opts.debug,
        };
        const mms = this.pattern.map(p => new Minimatch(p, mmo));
        const [matchSet, globParts] = mms.reduce((set, m) => {
            set[0].push(...m.set);
            set[1].push(...m.globParts);
            return set;
        }, [[], []]);
        this.patterns = matchSet.map((set, i) => {
            const g = globParts[i];
            /* c8 ignore start */
            if (!g)
                throw new Error('invalid pattern object');
            /* c8 ignore stop */
            return new Pattern(set, g, 0, this.platform);
        });
    }
    async walk() {
        // Walkers always return array of Path objects, so we just have to
        // coerce them into the right shape.  It will have already called
        // realpath() if the option was set to do so, so we know that's cached.
        // start out knowing the cwd, at least
        return [
            ...(await new GlobWalker(this.patterns, this.scurry.cwd, {
                ...this.opts,
                maxDepth: this.maxDepth !== Infinity ?
                    this.maxDepth + this.scurry.cwd.depth()
                    : Infinity,
                platform: this.platform,
                nocase: this.nocase,
                includeChildMatches: this.includeChildMatches,
            }).walk()),
        ];
    }
    walkSync() {
        return [
            ...new GlobWalker(this.patterns, this.scurry.cwd, {
                ...this.opts,
                maxDepth: this.maxDepth !== Infinity ?
                    this.maxDepth + this.scurry.cwd.depth()
                    : Infinity,
                platform: this.platform,
                nocase: this.nocase,
                includeChildMatches: this.includeChildMatches,
            }).walkSync(),
        ];
    }
    stream() {
        return new GlobStream(this.patterns, this.scurry.cwd, {
            ...this.opts,
            maxDepth: this.maxDepth !== Infinity ?
                this.maxDepth + this.scurry.cwd.depth()
                : Infinity,
            platform: this.platform,
            nocase: this.nocase,
            includeChildMatches: this.includeChildMatches,
        }).stream();
    }
    streamSync() {
        return new GlobStream(this.patterns, this.scurry.cwd, {
            ...this.opts,
            maxDepth: this.maxDepth !== Infinity ?
                this.maxDepth + this.scurry.cwd.depth()
                : Infinity,
            platform: this.platform,
            nocase: this.nocase,
            includeChildMatches: this.includeChildMatches,
        }).streamSync();
    }
    /**
     * Default sync iteration function. Returns a Generator that
     * iterates over the results.
     */
    iterateSync() {
        return this.streamSync()[Symbol.iterator]();
    }
    [Symbol.iterator]() {
        return this.iterateSync();
    }
    /**
     * Default async iteration function. Returns an AsyncGenerator that
     * iterates over the results.
     */
    iterate() {
        return this.stream()[Symbol.asyncIterator]();
    }
    [Symbol.asyncIterator]() {
        return this.iterate();
    }
}

/**
 * Return true if the patterns provided contain any magic glob characters,
 * given the options provided.
 *
 * Brace expansion is not considered "magic" unless the `magicalBraces` option
 * is set, as brace expansion just turns one string into an array of strings.
 * So a pattern like `'x{a,b}y'` would return `false`, because `'xay'` and
 * `'xby'` both do not contain any magic glob characters, and it's treated the
 * same as if you had called it on `['xay', 'xby']`. When `magicalBraces:true`
 * is in the options, brace expansion _is_ treated as a pattern having magic.
 */
const hasMagic = (pattern, options = {}) => {
    if (!Array.isArray(pattern)) {
        pattern = [pattern];
    }
    for (const p of pattern) {
        if (new Minimatch(p, options).hasMagic())
            return true;
    }
    return false;
};

function globStreamSync(pattern, options = {}) {
    return new Glob(pattern, options).streamSync();
}
function globStream(pattern, options = {}) {
    return new Glob(pattern, options).stream();
}
function globSync(pattern, options = {}) {
    return new Glob(pattern, options).walkSync();
}
async function glob_(pattern, options = {}) {
    return new Glob(pattern, options).walk();
}
function globIterateSync(pattern, options = {}) {
    return new Glob(pattern, options).iterateSync();
}
function globIterate(pattern, options = {}) {
    return new Glob(pattern, options).iterate();
}
// aliases: glob.sync.stream() glob.stream.sync() glob.sync() etc
const streamSync = globStreamSync;
const stream = Object.assign(globStream, { sync: globStreamSync });
const iterateSync = globIterateSync;
const iterate = Object.assign(globIterate, {
    sync: globIterateSync,
});
const sync = Object.assign(globSync, {
    stream: globStreamSync,
    iterate: globIterateSync,
});
const glob = Object.assign(glob_, {
    glob: glob_,
    globSync,
    sync,
    globStream,
    stream,
    globStreamSync,
    streamSync,
    globIterate,
    iterate,
    globIterateSync,
    iterateSync,
    Glob,
    hasMagic,
    escape,
    unescape,
});
glob.glob = glob;

class FilesystemTfStateDriver extends TfStateDriver {
  constructor(config = {}) {
    super(config);
    this.basePath = config.basePath || config.path || process.cwd();
  }
  /**
   * Initialize filesystem driver
   */
  async initialize() {
    try {
      const stats = await stat(this.basePath);
      if (!stats.isDirectory()) {
        throw new Error(`Base path is not a directory: ${this.basePath}`);
      }
    } catch (error) {
      throw new Error(`Invalid base path: ${this.basePath} - ${error.message}`);
    }
  }
  /**
   * List all state files matching the selector
   */
  async listStateFiles() {
    const pattern = join(this.basePath, this.selector);
    try {
      const files = await glob(pattern, {
        nodir: true,
        absolute: false,
        cwd: this.basePath
      });
      const stateFiles = await Promise.all(
        files.map(async (file) => {
          const fullPath = join(this.basePath, file);
          const stats = await stat(fullPath);
          return {
            path: file,
            fullPath,
            lastModified: stats.mtime,
            size: stats.size,
            etag: `${stats.mtime.getTime()}-${stats.size}`
            // Pseudo-etag
          };
        })
      );
      return stateFiles;
    } catch (error) {
      throw new Error(`Failed to list state files: ${error.message}`);
    }
  }
  /**
   * Read a state file from filesystem
   */
  async readStateFile(path) {
    const fullPath = path.startsWith(this.basePath) ? path : join(this.basePath, path);
    try {
      const content = await readFile$1(fullPath, "utf-8");
      return JSON.parse(content);
    } catch (error) {
      if (error.code === "ENOENT") {
        throw new Error(`State file not found: ${path}`);
      }
      throw new Error(`Failed to read state file ${path}: ${error.message}`);
    }
  }
  /**
   * Get state file metadata from filesystem
   */
  async getStateFileMetadata(path) {
    const fullPath = path.startsWith(this.basePath) ? path : join(this.basePath, path);
    try {
      const stats = await stat(fullPath);
      return {
        path,
        fullPath,
        lastModified: stats.mtime,
        size: stats.size,
        etag: `${stats.mtime.getTime()}-${stats.size}`
      };
    } catch (error) {
      if (error.code === "ENOENT") {
        throw new Error(`State file not found: ${path}`);
      }
      throw new Error(`Failed to get metadata for ${path}: ${error.message}`);
    }
  }
  /**
   * Check if state file has been modified
   */
  async hasBeenModified(path, since) {
    const metadata = await this.getStateFileMetadata(path);
    const lastModified = new Date(metadata.lastModified);
    const sinceDate = new Date(since);
    return lastModified > sinceDate;
  }
  /**
   * Close filesystem driver (no-op)
   */
  async close() {
  }
}

class TfStatePlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.driverType = config.driver || null;
    this.driverConfig = config.config || {};
    const resources = config.resources || {};
    this.resourceName = resources.resources || config.resourceName || "plg_tfstate_resources";
    this.stateFilesName = resources.stateFiles || config.stateFilesName || "plg_tfstate_state_files";
    this.diffsName = resources.diffs || config.diffsName || "plg_tfstate_state_diffs";
    const monitor = config.monitor || {};
    this.monitorEnabled = monitor.enabled || false;
    this.monitorCron = monitor.cron || "*/5 * * * *";
    const diffs = config.diffs || {};
    this.trackDiffs = diffs.enabled !== void 0 ? diffs.enabled : config.trackDiffs !== void 0 ? config.trackDiffs : true;
    this.diffsLookback = diffs.lookback || 10;
    this.asyncPartitions = config.asyncPartitions !== void 0 ? config.asyncPartitions : true;
    this.autoSync = config.autoSync || false;
    this.watchPaths = config.watchPaths || [];
    this.filters = config.filters || {};
    this.verbose = config.verbose || false;
    this.supportedVersions = [3, 4];
    this.driver = null;
    this.resource = null;
    this.stateFilesResource = null;
    this.diffsResource = null;
    this.watchers = [];
    this.cronTask = null;
    this.lastProcessedSerial = null;
    this._partitionCache = /* @__PURE__ */ new Map();
    this.stats = {
      statesProcessed: 0,
      resourcesExtracted: 0,
      resourcesInserted: 0,
      diffsCalculated: 0,
      errors: 0,
      lastProcessedSerial: null,
      partitionCacheHits: 0,
      partitionQueriesOptimized: 0
    };
  }
  /**
   * Install the plugin
   * @override
   */
  async onInstall() {
    if (this.verbose) {
      console.log("[TfStatePlugin] Installing...");
    }
    if (this.driverType) {
      if (this.verbose) {
        console.log(`[TfStatePlugin] Initializing ${this.driverType} driver...`);
      }
      if (this.driverType === "s3") {
        this.driver = new S3TfStateDriver(this.driverConfig);
      } else if (this.driverType === "filesystem") {
        this.driver = new FilesystemTfStateDriver(this.driverConfig);
      } else {
        throw new TfStateError(`Unsupported driver type: ${this.driverType}`);
      }
      await this.driver.initialize();
      if (this.verbose) {
        console.log(`[TfStatePlugin] Driver initialized successfully`);
      }
    }
    this.lineagesName = "plg_tfstate_lineages";
    this.lineagesResource = await this.database.createResource({
      name: this.lineagesName,
      attributes: {
        id: "string|required",
        // = lineage UUID from Tfstate
        latestSerial: "number",
        // Track latest for quick access
        latestStateId: "string",
        // FK to stateFilesResource
        totalStates: "number",
        // Counter
        firstImportedAt: "number",
        lastImportedAt: "number",
        metadata: "json"
        // Custom tags, project info, etc.
      },
      timestamps: true,
      asyncPartitions: this.asyncPartitions,
      // Configurable async partitions
      partitions: {},
      // No partitions - simple tracking resource
      createdBy: "TfStatePlugin"
    });
    this.stateFilesResource = await this.database.createResource({
      name: this.stateFilesName,
      attributes: {
        id: "string|required",
        lineageId: "string|required",
        // NEW: FK to lineages (= lineage UUID)
        sourceFile: "string|required",
        // Full path or s3:// URI
        serial: "number|required",
        lineage: "string|required",
        // Denormalized for queries
        terraformVersion: "string",
        stateVersion: "number|required",
        resourceCount: "number",
        sha256Hash: "string|required",
        // SHA256 hash for deduplication
        importedAt: "number|required"
      },
      timestamps: true,
      asyncPartitions: this.asyncPartitions,
      // Configurable async partitions
      partitions: {
        byLineage: { fields: { lineageId: "string" } },
        // NEW: Primary lookup
        byLineageSerial: { fields: { lineageId: "string", serial: "number" } },
        // NEW: Composite key
        bySourceFile: { fields: { sourceFile: "string" } },
        // Legacy support
        bySerial: { fields: { serial: "number" } },
        bySha256: { fields: { sha256Hash: "string" } }
      },
      createdBy: "TfStatePlugin"
    });
    this.resource = await this.database.createResource({
      name: this.resourceName,
      attributes: {
        id: "string|required",
        stateFileId: "string|required",
        // FK to stateFilesResource
        lineageId: "string|required",
        // NEW: FK to lineages
        // Denormalized fields for fast queries
        stateSerial: "number|required",
        sourceFile: "string|required",
        // Resource data
        resourceType: "string|required",
        resourceName: "string|required",
        resourceAddress: "string|required",
        providerName: "string|required",
        mode: "string",
        // managed or data
        attributes: "json",
        dependencies: "array",
        importedAt: "number|required"
      },
      timestamps: true,
      asyncPartitions: this.asyncPartitions,
      // Configurable async partitions
      partitions: {
        byLineageSerial: { fields: { lineageId: "string", stateSerial: "number" } },
        // NEW: Efficient diff queries
        byLineage: { fields: { lineageId: "string" } },
        // NEW: All resources for lineage
        byType: { fields: { resourceType: "string" } },
        byProvider: { fields: { providerName: "string" } },
        bySerial: { fields: { stateSerial: "number" } },
        bySourceFile: { fields: { sourceFile: "string" } },
        // Legacy support
        byProviderAndType: { fields: { providerName: "string", resourceType: "string" } },
        byLineageType: { fields: { lineageId: "string", resourceType: "string" } }
        // NEW: Type queries per lineage
      },
      createdBy: "TfStatePlugin"
    });
    if (this.trackDiffs) {
      this.diffsResource = await this.database.createResource({
        name: this.diffsName,
        attributes: {
          id: "string|required",
          lineageId: "string|required",
          // NEW: FK to lineages
          oldSerial: "number|required",
          newSerial: "number|required",
          oldStateId: "string",
          // NEW: FK to stateFilesResource
          newStateId: "string|required",
          // NEW: FK to stateFilesResource
          calculatedAt: "number|required",
          // Summary statistics
          summary: {
            type: "object",
            props: {
              addedCount: "number",
              modifiedCount: "number",
              deletedCount: "number"
            }
          },
          // Detailed changes
          changes: {
            type: "object",
            props: {
              added: "array",
              modified: "array",
              deleted: "array"
            }
          }
        },
        behavior: "body-only",
        // Force all data to body for reliable nested object handling
        timestamps: true,
        asyncPartitions: this.asyncPartitions,
        // Configurable async partitions
        partitions: {
          byLineage: { fields: { lineageId: "string" } },
          // NEW: All diffs for lineage
          byLineageNewSerial: { fields: { lineageId: "string", newSerial: "number" } },
          // NEW: Specific version lookup
          byNewSerial: { fields: { newSerial: "number" } },
          byOldSerial: { fields: { oldSerial: "number" } }
        },
        createdBy: "TfStatePlugin"
      });
    }
    if (this.verbose) {
      const resourcesCreated = [this.lineagesName, this.stateFilesName, this.resourceName];
      if (this.trackDiffs) resourcesCreated.push(this.diffsName);
      console.log(`[TfStatePlugin] Created resources: ${resourcesCreated.join(", ")}`);
    }
    if (this.autoSync && this.watchPaths.length > 0) {
      await this._setupFileWatchers();
    }
    if (this.monitorEnabled && this.driver) {
      await this._setupCronMonitoring();
    }
    this.emit("installed", {
      plugin: "TfStatePlugin",
      stateFilesName: this.stateFilesName,
      resourceName: this.resourceName,
      diffsName: this.diffsName,
      monitorEnabled: this.monitorEnabled,
      driverType: this.driverType
    });
  }
  /**
   * Start the plugin
   * @override
   */
  async onStart() {
    if (this.verbose) {
      console.log("[TfStatePlugin] Started");
    }
  }
  /**
   * Stop the plugin
   * @override
   */
  async onStop() {
    if (this.cronTask) {
      this.cronTask.stop();
      this.cronTask = null;
      if (this.verbose) {
        console.log("[TfStatePlugin] Stopped cron monitoring");
      }
    }
    for (const watcher of this.watchers) {
      try {
        if (watcher && typeof watcher.return === "function") {
          await watcher.return();
        } else if (watcher && typeof watcher.close === "function") {
          await watcher.close();
        }
      } catch (error) {
        if (this.verbose) {
          console.warn("[TfStatePlugin] Error closing watcher:", error.message);
        }
      }
    }
    this.watchers = [];
    if (this.driver) {
      await this.driver.close();
      this.driver = null;
      if (this.verbose) {
        console.log("[TfStatePlugin] Driver closed");
      }
    }
    if (this.verbose) {
      console.log("[TfStatePlugin] Stopped");
    }
  }
  /**
   * Import multiple Terraform/OpenTofu states from local filesystem using glob pattern
   * @param {string} pattern - Glob pattern for matching state files
   * @param {Object} options - Optional parallelism settings
   * @returns {Promise<Object>} Consolidated import result with statistics
   *
   * @example
   * await plugin.importStatesGlob('./terraform/ ** /*.tfstate');
   * await plugin.importStatesGlob('./environments/ * /terraform.tfstate', { parallelism: 10 });
   */
  async importStatesGlob(pattern, options = {}) {
    const startTime = Date.now();
    const parallelism = options.parallelism || 5;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Finding local files matching: ${pattern}`);
    }
    try {
      const matchingFiles = await this._findFilesGlob(pattern);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${matchingFiles.length} matching files`);
      }
      if (matchingFiles.length === 0) {
        return {
          filesProcessed: 0,
          totalResourcesExtracted: 0,
          totalResourcesInserted: 0,
          files: [],
          duration: Date.now() - startTime
        };
      }
      const results = [];
      const files = [];
      for (let i = 0; i < matchingFiles.length; i += parallelism) {
        const batch = matchingFiles.slice(i, i + parallelism);
        const batchPromises = batch.map(async (filePath) => {
          try {
            const result = await this.importState(filePath);
            return { success: true, file: filePath, result };
          } catch (error) {
            if (this.verbose) {
              console.error(`[TfStatePlugin] Failed to import ${filePath}:`, error.message);
            }
            return { success: false, file: filePath, error: error.message };
          }
        });
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      const successful = results.filter((r) => r.success);
      const failed = results.filter((r) => !r.success);
      successful.forEach((r) => {
        if (!r.result.skipped) {
          files.push({
            file: r.file,
            serial: r.result.serial,
            resourcesExtracted: r.result.resourcesExtracted,
            resourcesInserted: r.result.resourcesInserted
          });
        }
      });
      const totalResourcesExtracted = successful.filter((r) => !r.result.skipped).reduce((sum, r) => sum + (r.result.resourcesExtracted || 0), 0);
      const totalResourcesInserted = successful.filter((r) => !r.result.skipped).reduce((sum, r) => sum + (r.result.resourcesInserted || 0), 0);
      const duration = Date.now() - startTime;
      const consolidatedResult = {
        filesProcessed: successful.length,
        filesFailed: failed.length,
        totalResourcesExtracted,
        totalResourcesInserted,
        files,
        failedFiles: failed.map((f) => ({ file: f.file, error: f.error })),
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Glob import completed:`, consolidatedResult);
      }
      this.emit("globImportCompleted", consolidatedResult);
      return consolidatedResult;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] Glob import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Find files matching glob pattern
   * @private
   */
  async _findFilesGlob(pattern) {
    const files = [];
    const baseMatch = pattern.match(/^([^*?[\]]+)/);
    const baseDir = baseMatch ? baseMatch[1] : ".";
    pattern.slice(baseDir.length);
    const findFiles = async (dir) => {
      try {
        const entries = await readdir(dir, { withFileTypes: true });
        for (const entry of entries) {
          const fullPath = join(dir, entry.name);
          if (entry.isDirectory()) {
            await findFiles(fullPath);
          } else if (entry.isFile() && entry.name.endsWith(".tfstate")) {
            if (this._matchesGlobPattern(fullPath, pattern)) {
              files.push(fullPath);
            }
          }
        }
      } catch (error) {
        if (error.code !== "EACCES" && error.code !== "EPERM") {
          throw error;
        }
      }
    };
    await findFiles(baseDir);
    return files;
  }
  /**
   * Import Terraform/OpenTofu state from remote S3 bucket
   * @param {string} bucket - S3 bucket name
   * @param {string} key - S3 object key (path to .tfstate file)
   * @param {Object} options - Optional S3 client override
   * @returns {Promise<Object>} Import result with statistics
   */
  async importStateFromS3(bucket, key, options = {}) {
    const startTime = Date.now();
    const sourceFile = `s3://${bucket}/${key}`;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Importing from S3: ${sourceFile}`);
    }
    try {
      const client = options.client || this.database.client;
      const [ok, err, data] = await tryFn(async () => {
        return await client.getObject(key);
      });
      if (!ok) {
        throw new StateFileNotFoundError(sourceFile, {
          originalError: err
        });
      }
      const stateContent = data.Body.toString("utf-8");
      let state;
      try {
        state = JSON.parse(stateContent);
      } catch (parseError) {
        throw new InvalidStateFileError(sourceFile, "Invalid JSON", {
          originalError: parseError
        });
      }
      this._validateState(state, sourceFile);
      this._validateStateVersion(state);
      const sha256Hash = this._calculateSHA256(state);
      const partitionName = this._findPartitionByField(this.stateFilesResource, "sha256Hash");
      let existingByHash;
      if (partitionName) {
        this.stats.partitionQueriesOptimized++;
        existingByHash = await this.stateFilesResource.list({
          partition: partitionName,
          partitionValues: { sha256Hash },
          limit: 1
        });
      } else {
        existingByHash = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
      }
      if (existingByHash.length > 0) {
        const existing = existingByHash[0];
        if (this.verbose) {
          console.log(`[TfStatePlugin] State already imported (SHA256 match), skipping`);
        }
        return {
          skipped: true,
          reason: "duplicate",
          serial: state.serial,
          stateFileId: existing.id,
          sha256Hash,
          source: sourceFile
        };
      }
      const currentTime = Date.now();
      const stateFileRecord = {
        id: idGenerator(),
        sourceFile,
        serial: state.serial,
        lineage: state.lineage,
        terraformVersion: state.terraform_version,
        stateVersion: state.version,
        resourceCount: (state.resources || []).length,
        sha256Hash,
        importedAt: currentTime
      };
      const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
        return await this.stateFilesResource.insert(stateFileRecord);
      });
      if (!insertOk) {
        throw new TfStateError(`Failed to save state file metadata: ${insertErr.message}`, {
          originalError: insertErr
        });
      }
      const stateFileId = stateFileResult.id;
      const resources = await this._extractResources(state, sourceFile, stateFileId);
      let diff = null;
      let diffRecord = null;
      if (this.trackDiffs) {
        diff = await this._calculateDiff(state, sourceFile, stateFileId);
        if (diff && !diff.isFirst) {
          diffRecord = await this._saveDiff(diff, sourceFile, stateFileId);
        }
      }
      const inserted = await this._insertResources(resources);
      this.lastProcessedSerial = state.serial;
      this.stats.statesProcessed++;
      this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
      this.stats.resourcesInserted += inserted.length;
      this.stats.lastProcessedSerial = state.serial;
      if (diff && !diff.isFirst) this.stats.diffsCalculated++;
      const duration = Date.now() - startTime;
      const result = {
        serial: state.serial,
        lineage: state.lineage,
        terraformVersion: state.terraform_version,
        resourcesExtracted: resources.totalExtracted || resources.length,
        resourcesInserted: inserted.length,
        stateFileId,
        sha256Hash,
        source: sourceFile,
        diff: diff ? {
          added: diff.added.length,
          modified: diff.modified.length,
          deleted: diff.deleted.length,
          isFirst: diff.isFirst || false
        } : null,
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] S3 import completed:`, result);
      }
      this.emit("stateImported", result);
      return result;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] S3 import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Import multiple Terraform/OpenTofu states from S3 using glob pattern
   * @param {string} bucket - S3 bucket name
   * @param {string} pattern - Glob pattern for matching state files
   * @param {Object} options - Optional S3 client override and parallelism settings
   * @returns {Promise<Object>} Consolidated import result with statistics
   */
  async importStatesFromS3Glob(bucket, pattern, options = {}) {
    const startTime = Date.now();
    const client = options.client || this.database.client;
    const parallelism = options.parallelism || 5;
    if (this.verbose) {
      console.log(`[TfStatePlugin] Listing S3 objects: s3://${bucket}/${pattern}`);
    }
    try {
      const [ok, err, data] = await tryFn(async () => {
        const params = {};
        const prefixMatch = pattern.match(/^([^*?[\]]+)/);
        if (prefixMatch) {
          params.prefix = prefixMatch[1];
        }
        return await client.listObjects(params);
      });
      if (!ok) {
        throw new TfStateError(`Failed to list objects in s3://${bucket}`, {
          originalError: err
        });
      }
      const allObjects = data.Contents || [];
      const matchingObjects = allObjects.filter((obj) => {
        return this._matchesGlobPattern(obj.Key, pattern);
      });
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${matchingObjects.length} matching files`);
      }
      if (matchingObjects.length === 0) {
        return {
          filesProcessed: 0,
          totalResourcesExtracted: 0,
          totalResourcesInserted: 0,
          files: [],
          duration: Date.now() - startTime
        };
      }
      const results = [];
      const files = [];
      for (let i = 0; i < matchingObjects.length; i += parallelism) {
        const batch = matchingObjects.slice(i, i + parallelism);
        const batchPromises = batch.map(async (obj) => {
          try {
            const result = await this.importStateFromS3(bucket, obj.Key, options);
            return { success: true, key: obj.Key, result };
          } catch (error) {
            if (this.verbose) {
              console.error(`[TfStatePlugin] Failed to import ${obj.Key}:`, error.message);
            }
            return { success: false, key: obj.Key, error: error.message };
          }
        });
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      const successful = results.filter((r) => r.success);
      const failed = results.filter((r) => !r.success);
      successful.forEach((r) => {
        files.push({
          file: r.key,
          serial: r.result.serial,
          resourcesExtracted: r.result.resourcesExtracted,
          resourcesInserted: r.result.resourcesInserted
        });
      });
      const totalResourcesExtracted = successful.reduce((sum, r) => sum + r.result.resourcesExtracted, 0);
      const totalResourcesInserted = successful.reduce((sum, r) => sum + r.result.resourcesInserted, 0);
      const duration = Date.now() - startTime;
      const consolidatedResult = {
        filesProcessed: successful.length,
        filesFailed: failed.length,
        totalResourcesExtracted,
        totalResourcesInserted,
        files,
        failedFiles: failed.map((f) => ({ file: f.key, error: f.error })),
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Glob import completed:`, consolidatedResult);
      }
      this.emit("globImportCompleted", consolidatedResult);
      return consolidatedResult;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error(`[TfStatePlugin] Glob import failed:`, error);
      }
      throw error;
    }
  }
  /**
   * Match S3 key against glob pattern
   * Simple glob matching supporting *, **, ?, and []
   * @private
   */
  _matchesGlobPattern(key, pattern) {
    let regexPattern = pattern.replace(/\*\*/g, "\0\0").replace(/\*/g, "\0").replace(/\?/g, "");
    regexPattern = regexPattern.replace(/[.+^${}()|\\]/g, "\\$&");
    regexPattern = regexPattern.replace(/\x00\x00/g, "__DOUBLE_STAR__").replace(/\x00/g, "[^/]*").replace(/\x01/g, ".");
    regexPattern = regexPattern.replace(/__DOUBLE_STAR__\//g, "(?:.*/)?");
    regexPattern = regexPattern.replace(/__DOUBLE_STAR__/g, ".*");
    const regex = new RegExp(`^${regexPattern}$`);
    return regex.test(key);
  }
  /**
   * Ensure lineage record exists and is up-to-date
   * Creates or updates the lineage tracking record
   * @private
   */
  async _ensureLineage(lineageUuid, stateMeta) {
    if (!lineageUuid) {
      throw new TfStateError("Lineage UUID is required for state tracking");
    }
    const [getOk, getErr, existingLineage] = await tryFn(async () => {
      return await this.lineagesResource.get(lineageUuid);
    });
    const currentTime = Date.now();
    if (existingLineage) {
      const updates = {
        lastImportedAt: currentTime
      };
      if (stateMeta.serial > (existingLineage.latestSerial || 0)) {
        updates.latestSerial = stateMeta.serial;
        updates.latestStateId = stateMeta.stateFileId;
      }
      if (existingLineage.totalStates !== void 0) {
        updates.totalStates = existingLineage.totalStates + 1;
      } else {
        updates.totalStates = 1;
      }
      await this.lineagesResource.update(lineageUuid, updates);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Updated lineage: ${lineageUuid} (serial ${stateMeta.serial})`);
      }
      return { ...existingLineage, ...updates };
    } else {
      const lineageRecord = {
        id: lineageUuid,
        latestSerial: stateMeta.serial,
        latestStateId: stateMeta.stateFileId,
        totalStates: 1,
        firstImportedAt: currentTime,
        lastImportedAt: currentTime,
        metadata: {}
      };
      await this.lineagesResource.insert(lineageRecord);
      if (this.verbose) {
        console.log(`[TfStatePlugin] Created new lineage: ${lineageUuid}`);
      }
      return lineageRecord;
    }
  }
  /**
   * Import Terraform/OpenTofu state from file
   * @param {string} filePath - Path to .tfstate file
   * @returns {Promise<Object>} Import result with statistics
   */
  async importState(filePath) {
    const startTime = Date.now();
    if (this.verbose) {
      console.log(`[TfStatePlugin] Importing state from: ${filePath}`);
    }
    const state = await this._readStateFile(filePath);
    this._validateStateVersion(state);
    const sha256Hash = this._calculateSHA256(state);
    const existingByHash = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
    if (existingByHash.length > 0) {
      const existing = existingByHash[0];
      if (this.verbose) {
        console.log(`[TfStatePlugin] State already imported (SHA256 match), skipping`);
      }
      return {
        skipped: true,
        reason: "duplicate",
        serial: state.serial,
        stateFileId: existing.id,
        sha256Hash
      };
    }
    const currentTime = Date.now();
    const lineageUuid = state.lineage;
    if (!lineageUuid) {
      throw new TfStateError("State file missing lineage field - cannot track state progression", {
        filePath,
        serial: state.serial
      });
    }
    const stateFileRecord = {
      id: idGenerator(),
      lineageId: lineageUuid,
      // NEW: FK to lineages
      sourceFile: filePath,
      serial: state.serial,
      lineage: state.lineage,
      // Denormalized for queries
      terraformVersion: state.terraform_version,
      stateVersion: state.version,
      resourceCount: (state.resources || []).length,
      sha256Hash,
      importedAt: currentTime
    };
    const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
      return await this.stateFilesResource.insert(stateFileRecord);
    });
    if (!insertOk) {
      throw new TfStateError(`Failed to save state file metadata: ${insertErr.message}`, {
        originalError: insertErr
      });
    }
    const stateFileId = stateFileResult.id;
    await this._ensureLineage(lineageUuid, {
      serial: state.serial,
      stateFileId
    });
    const resources = await this._extractResources(state, filePath, stateFileId, lineageUuid);
    const inserted = await this._insertResources(resources);
    let diff = null;
    if (this.trackDiffs) {
      diff = await this._calculateDiff(state, lineageUuid, stateFileId);
      if (diff && !diff.isFirst) {
        await this._saveDiff(diff, lineageUuid, stateFileId);
      }
    }
    this.lastProcessedSerial = state.serial;
    this.stats.statesProcessed++;
    this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
    this.stats.resourcesInserted += inserted.length;
    this.stats.lastProcessedSerial = state.serial;
    if (diff && !diff.isFirst) this.stats.diffsCalculated++;
    const duration = Date.now() - startTime;
    const result = {
      serial: state.serial,
      lineage: state.lineage,
      terraformVersion: state.terraform_version,
      resourcesExtracted: resources.totalExtracted || resources.length,
      resourcesInserted: inserted.length,
      stateFileId,
      sha256Hash,
      diff: diff ? {
        added: diff.added.length,
        modified: diff.modified.length,
        deleted: diff.deleted.length,
        isFirst: diff.isFirst || false
      } : null,
      duration
    };
    if (this.verbose) {
      console.log(`[TfStatePlugin] Import completed:`, result);
    }
    this.emit("stateImported", result);
    return result;
  }
  /**
   * Read and parse Tfstate file
   * @private
   */
  async _readStateFile(filePath) {
    if (!existsSync(filePath)) {
      throw new StateFileNotFoundError(filePath);
    }
    const [ok, err, content] = await tryFn(async () => {
      return await readFile$1(filePath, "utf-8");
    });
    if (!ok) {
      throw new InvalidStateFileError(filePath, `Failed to read file: ${err.message}`);
    }
    const [parseOk, parseErr, state] = await tryFn(async () => {
      return JSON.parse(content);
    });
    if (!parseOk) {
      throw new InvalidStateFileError(filePath, `Invalid JSON: ${parseErr.message}`);
    }
    return state;
  }
  /**
   * Validate basic state structure
   * @private
   */
  _validateState(state, filePath) {
    if (!state || typeof state !== "object") {
      throw new InvalidStateFileError(filePath, "State must be a valid JSON object");
    }
    if (!state.version) {
      throw new InvalidStateFileError(filePath, "Missing version field");
    }
    if (state.serial === void 0) {
      throw new InvalidStateFileError(filePath, "Missing serial field");
    }
  }
  /**
   * Validate Tfstate version
   * @private
   */
  _validateStateVersion(state) {
    const version = state.version;
    if (!version) {
      throw new InvalidStateFileError("unknown", "Missing version field");
    }
    if (!this.supportedVersions.includes(version)) {
      throw new UnsupportedStateVersionError(version, this.supportedVersions);
    }
  }
  /**
   * Extract resources from Tfstate
   * @private
   */
  async _extractResources(state, filePath, stateFileId, lineageId) {
    const resources = [];
    let totalExtracted = 0;
    const stateSerial = state.serial;
    const stateVersion = state.version;
    const importedAt = Date.now();
    const stateResources = state.resources || [];
    for (const resource of stateResources) {
      try {
        const instances = resource.instances || [resource];
        for (const instance of instances) {
          totalExtracted++;
          const extracted = this._extractResourceInstance(
            resource,
            instance,
            stateSerial,
            stateVersion,
            importedAt,
            filePath,
            // Pass source file path
            stateFileId,
            // Pass state file ID (foreign key)
            lineageId
            // NEW: Pass lineage ID (foreign key)
          );
          if (this._shouldIncludeResource(extracted)) {
            resources.push(extracted);
          }
        }
      } catch (error) {
        this.stats.errors++;
        if (this.verbose) {
          console.error(`[TfStatePlugin] Failed to extract resource:`, error);
        }
        throw new ResourceExtractionError(resource.name || "unknown", error);
      }
    }
    resources.totalExtracted = totalExtracted;
    return resources;
  }
  /**
   * Extract single resource instance
   * @private
   */
  _extractResourceInstance(resource, instance, stateSerial, stateVersion, importedAt, sourceFile, stateFileId, lineageId) {
    const resourceType = resource.type;
    const resourceName = resource.name;
    const mode = resource.mode || "managed";
    const providerName = this._detectProvider(resourceType);
    const resourceAddress = mode === "data" ? `data.${resourceType}.${resourceName}` : `${resourceType}.${resourceName}`;
    const attributes = instance.attributes || instance.attributes_flat || {};
    const dependencies = resource.depends_on || instance.depends_on || [];
    return {
      id: idGenerator(),
      stateFileId,
      // Foreign key to state_files
      lineageId,
      // NEW: Foreign key to lineages
      stateSerial,
      // Denormalized for fast queries
      sourceFile: sourceFile || null,
      // Denormalized for informational purposes
      resourceType,
      resourceName,
      resourceAddress,
      providerName,
      mode,
      attributes,
      dependencies,
      importedAt
    };
  }
  /**
   * Detect provider from resource type
   * @private
   */
  _detectProvider(resourceType) {
    if (!resourceType) return "unknown";
    const prefix = resourceType.split("_")[0];
    const providerMap = {
      "aws": "aws",
      "google": "google",
      "azurerm": "azure",
      "azuread": "azure",
      "azuredevops": "azure",
      "kubernetes": "kubernetes",
      "helm": "kubernetes",
      "random": "random",
      "null": "null",
      "local": "local",
      "time": "time",
      "tls": "tls",
      "http": "http",
      "external": "external",
      "terraform": "terraform",
      "datadog": "datadog",
      "cloudflare": "cloudflare",
      "github": "github",
      "gitlab": "gitlab",
      "vault": "vault"
    };
    return providerMap[prefix] || "unknown";
  }
  /**
   * Check if resource should be included based on filters
   * @private
   */
  _shouldIncludeResource(resource) {
    const { types, providers, exclude, include } = this.filters;
    if (include && include.length > 0) {
      const matches = include.some((pattern) => {
        return this._matchesPattern(resource.resourceAddress, pattern);
      });
      if (!matches) return false;
    }
    if (types && types.length > 0) {
      if (!types.includes(resource.resourceType)) {
        return false;
      }
    }
    if (providers && providers.length > 0) {
      if (!providers.includes(resource.providerName)) {
        return false;
      }
    }
    if (exclude && exclude.length > 0) {
      const matches = exclude.some((pattern) => {
        return this._matchesPattern(resource.resourceAddress, pattern);
      });
      if (matches) return false;
    }
    return true;
  }
  /**
   * Match resource address against pattern (supports wildcards)
   * @private
   */
  _matchesPattern(address, pattern) {
    const regexPattern = pattern.replace(/\.\*/g, "___WILDCARD___").replace(/\*/g, "[^.]*").replace(/\./g, "\\.").replace(/___WILDCARD___/g, ".*");
    const regex = new RegExp(`^${regexPattern}$`);
    return regex.test(address);
  }
  /**
   * Calculate diff between current and previous state
   * NEW: Uses lineage-based tracking for O(1) lookup
   * @private
   */
  async _calculateDiff(currentState, lineageId, currentStateFileId) {
    if (!this.diffsResource) return null;
    const currentSerial = currentState.serial;
    const previousStateFiles = await this.stateFilesResource.listPartition({
      partition: "byLineageSerial",
      partitionValues: { lineageId, serial: currentSerial - 1 }
    });
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Diff calculation (lineage-based): found ${previousStateFiles.length} previous states for lineage=${lineageId}, serial=${currentSerial - 1}`
      );
    }
    if (previousStateFiles.length === 0) {
      if (this.verbose) {
        console.log(`[TfStatePlugin] First state for lineage ${lineageId}, no previous state`);
      }
      return {
        added: [],
        modified: [],
        deleted: [],
        isFirst: true,
        oldSerial: null,
        newSerial: currentSerial,
        oldStateId: null,
        newStateId: currentStateFileId,
        lineageId
      };
    }
    const previousStateFile = previousStateFiles[0];
    const previousSerial = previousStateFile.serial;
    const previousStateFileId = previousStateFile.id;
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Using previous state: serial ${previousSerial} (id: ${previousStateFileId})`
      );
    }
    const [ok, err, diff] = await tryFn(async () => {
      return await this._computeDiff(previousSerial, currentSerial, lineageId);
    });
    if (!ok) {
      throw new StateDiffError(previousSerial, currentSerial, err);
    }
    diff.oldSerial = previousSerial;
    diff.newSerial = currentSerial;
    diff.oldStateId = previousStateFileId;
    diff.newStateId = currentStateFileId;
    diff.lineageId = lineageId;
    return diff;
  }
  /**
   * Compute diff between two state serials
   * NEW: Uses lineage-based partition for efficient resource lookup
   * @private
   */
  async _computeDiff(oldSerial, newSerial, lineageId) {
    const partitionName = "byLineageSerial";
    let oldResources, newResources;
    this.stats.partitionQueriesOptimized += 2;
    [oldResources, newResources] = await Promise.all([
      this.resource.listPartition({
        partition: partitionName,
        partitionValues: { lineageId, stateSerial: oldSerial }
      }),
      this.resource.listPartition({
        partition: partitionName,
        partitionValues: { lineageId, stateSerial: newSerial }
      })
    ]);
    if (this.verbose) {
      console.log(
        `[TfStatePlugin] Diff computation using lineage partition: ${oldResources.length} old + ${newResources.length} new resources`
      );
    }
    if (oldResources.length === 0 && newResources.length === 0) {
      if (this.verbose) {
        console.log("[TfStatePlugin] No resources found for either serial");
      }
      return {
        added: [],
        modified: [],
        deleted: []
      };
    }
    const oldMap = new Map(oldResources.map((r) => [r.resourceAddress, r]));
    const newMap = new Map(newResources.map((r) => [r.resourceAddress, r]));
    const added = [];
    const modified = [];
    const deleted = [];
    for (const [address, newResource] of newMap) {
      if (!oldMap.has(address)) {
        added.push({
          address,
          type: newResource.resourceType,
          name: newResource.resourceName
        });
      } else {
        const oldResource = oldMap.get(address);
        if (JSON.stringify(oldResource.attributes) !== JSON.stringify(newResource.attributes)) {
          modified.push({
            address,
            type: newResource.resourceType,
            name: newResource.resourceName,
            changes: this._computeAttributeChanges(oldResource.attributes, newResource.attributes)
          });
        }
      }
    }
    for (const [address, oldResource] of oldMap) {
      if (!newMap.has(address)) {
        deleted.push({
          address,
          type: oldResource.resourceType,
          name: oldResource.resourceName
        });
      }
    }
    return { added, modified, deleted, oldSerial, newSerial };
  }
  /**
   * Compute changes between old and new attributes
   * @private
   */
  _computeAttributeChanges(oldAttrs, newAttrs) {
    const changes = [];
    const allKeys = /* @__PURE__ */ new Set([...Object.keys(oldAttrs || {}), ...Object.keys(newAttrs || {})]);
    for (const key of allKeys) {
      const oldValue = oldAttrs?.[key];
      const newValue = newAttrs?.[key];
      if (JSON.stringify(oldValue) !== JSON.stringify(newValue)) {
        changes.push({
          field: key,
          oldValue,
          newValue
        });
      }
    }
    return changes;
  }
  /**
   * Save diff to diffsResource
   * NEW: Includes lineage-based fields for efficient querying
   * @private
   */
  async _saveDiff(diff, lineageId, newStateFileId) {
    const diffRecord = {
      id: idGenerator(),
      lineageId: diff.lineageId || lineageId,
      // NEW: FK to lineages
      oldSerial: diff.oldSerial,
      newSerial: diff.newSerial,
      oldStateId: diff.oldStateId,
      // NEW: FK to state_files
      newStateId: diff.newStateId || newStateFileId,
      // NEW: FK to state_files
      calculatedAt: Date.now(),
      summary: {
        addedCount: diff.added.length,
        modifiedCount: diff.modified.length,
        deletedCount: diff.deleted.length
      },
      changes: {
        added: diff.added,
        modified: diff.modified,
        deleted: diff.deleted
      }
    };
    const [ok, err, result] = await tryFn(async () => {
      return await this.diffsResource.insert(diffRecord);
    });
    if (!ok) {
      if (this.verbose) {
        console.error(`[TfStatePlugin] Failed to save diff:`, err);
      }
      throw new TfStateError(`Failed to save diff: ${err.message}`, {
        originalError: err
      });
    }
    return result;
  }
  /**
   * Calculate SHA256 hash of state content
   * @private
   */
  _calculateSHA256(state) {
    const stateString = JSON.stringify(state);
    return createHash("sha256").update(stateString).digest("hex");
  }
  /**
   * Insert resources into database with controlled parallelism
   * @private
   */
  async _insertResources(resources) {
    if (resources.length === 0) return [];
    const inserted = [];
    const parallelism = this.database.parallelism || 10;
    for (let i = 0; i < resources.length; i += parallelism) {
      const batch = resources.slice(i, i + parallelism);
      const batchPromises = batch.map(async (resource) => {
        const [ok, err, result] = await tryFn(async () => {
          return await this.resource.insert(resource);
        });
        if (ok) {
          return { success: true, result };
        } else {
          this.stats.errors++;
          if (this.verbose) {
            console.error(`[TfStatePlugin] Failed to insert resource ${resource.resourceAddress}:`, err);
          }
          return { success: false, error: err };
        }
      });
      const batchResults = await Promise.all(batchPromises);
      batchResults.forEach((br) => {
        if (br.success) {
          inserted.push(br.result);
        }
      });
    }
    if (this.verbose && resources.length > parallelism) {
      console.log(`[TfStatePlugin] Batch inserted ${inserted.length}/${resources.length} resources (parallelism: ${parallelism})`);
    }
    return inserted;
  }
  /**
   * Setup cron-based monitoring for state file changes
   * @private
   */
  async _setupCronMonitoring() {
    if (!this.driver) {
      throw new TfStateError("Cannot setup monitoring without a driver");
    }
    if (this.verbose) {
      console.log(`[TfStatePlugin] Setting up cron monitoring: ${this.monitorCron}`);
    }
    await requirePluginDependency("tfstate-plugin");
    const [ok, err, cronModule] = await tryFn(() => import('node-cron'));
    if (!ok) {
      throw new TfStateError(`Failed to import node-cron: ${err.message}`);
    }
    const cron = cronModule.default;
    if (!cron.validate(this.monitorCron)) {
      throw new TfStateError(`Invalid cron expression: ${this.monitorCron}`);
    }
    this.cronTask = cron.schedule(this.monitorCron, async () => {
      try {
        await this._monitorStateFiles();
      } catch (error) {
        this.stats.errors++;
        if (this.verbose) {
          console.error("[TfStatePlugin] Monitoring error:", error);
        }
        this.emit("monitoringError", { error: error.message });
      }
    });
    if (this.verbose) {
      console.log("[TfStatePlugin] Cron monitoring started");
    }
    this.emit("monitoringStarted", { cron: this.monitorCron });
  }
  /**
   * Monitor state files for changes
   * Called by cron task
   * @private
   */
  async _monitorStateFiles() {
    if (!this.driver) return;
    if (this.verbose) {
      console.log("[TfStatePlugin] Checking for state file changes...");
    }
    const startTime = Date.now();
    try {
      const stateFiles = await this.driver.listStateFiles();
      if (this.verbose) {
        console.log(`[TfStatePlugin] Found ${stateFiles.length} state files`);
      }
      let changedFiles = 0;
      let newFiles = 0;
      for (const fileMetadata of stateFiles) {
        try {
          const existing = await this.stateFilesResource.query({
            sourceFile: fileMetadata.path
          }, { limit: 1, sort: { serial: -1 } });
          let shouldProcess = false;
          if (existing.length === 0) {
            shouldProcess = true;
            newFiles++;
          } else {
            const lastImported = existing[0].importedAt;
            const hasChanged = await this.driver.hasBeenModified(
              fileMetadata.path,
              new Date(lastImported)
            );
            if (hasChanged) {
              shouldProcess = true;
              changedFiles++;
            }
          }
          if (shouldProcess) {
            const state = await this.driver.readStateFile(fileMetadata.path);
            this._validateState(state, fileMetadata.path);
            this._validateStateVersion(state);
            const sha256Hash = this._calculateSHA256(state);
            const duplicates = await this.stateFilesResource.query({ sha256Hash }, { limit: 1 });
            if (duplicates.length > 0) {
              if (this.verbose) {
                console.log(`[TfStatePlugin] Skipped duplicate: ${fileMetadata.path}`);
              }
              continue;
            }
            const currentTime = Date.now();
            const stateFileRecord = {
              id: idGenerator(),
              sourceFile: fileMetadata.path,
              serial: state.serial,
              lineage: state.lineage,
              terraformVersion: state.terraform_version,
              stateVersion: state.version,
              resourceCount: (state.resources || []).length,
              sha256Hash,
              importedAt: currentTime
            };
            const [insertOk, insertErr, stateFileResult] = await tryFn(async () => {
              return await this.stateFilesResource.insert(stateFileRecord);
            });
            if (!insertOk) {
              throw new TfStateError(`Failed to save state file: ${insertErr.message}`);
            }
            const stateFileId = stateFileResult.id;
            const resources = await this._extractResources(state, fileMetadata.path, stateFileId);
            if (this.trackDiffs) {
              const diff = await this._calculateDiff(state, fileMetadata.path, stateFileId);
              if (diff && !diff.isFirst) {
                await this._saveDiff(diff, fileMetadata.path, stateFileId);
                this.stats.diffsCalculated++;
              }
            }
            const inserted = await this._insertResources(resources);
            this.stats.statesProcessed++;
            this.stats.resourcesExtracted += resources.totalExtracted || resources.length;
            this.stats.resourcesInserted += inserted.length;
            this.stats.lastProcessedSerial = state.serial;
            if (this.verbose) {
              console.log(`[TfStatePlugin] Processed ${fileMetadata.path}: ${resources.totalExtracted || resources.length} resources`);
            }
            this.emit("stateFileProcessed", {
              path: fileMetadata.path,
              serial: state.serial,
              resourcesExtracted: resources.totalExtracted || resources.length,
              resourcesInserted: inserted.length
            });
          }
        } catch (error) {
          this.stats.errors++;
          if (this.verbose) {
            console.error(`[TfStatePlugin] Failed to process ${fileMetadata.path}:`, error);
          }
          this.emit("processingError", {
            path: fileMetadata.path,
            error: error.message
          });
        }
      }
      const duration = Date.now() - startTime;
      const result = {
        totalFiles: stateFiles.length,
        newFiles,
        changedFiles,
        duration
      };
      if (this.verbose) {
        console.log(`[TfStatePlugin] Monitoring completed:`, result);
      }
      this.emit("monitoringCompleted", result);
      return result;
    } catch (error) {
      this.stats.errors++;
      if (this.verbose) {
        console.error("[TfStatePlugin] Monitoring failed:", error);
      }
      throw error;
    }
  }
  /**
   * Setup file watchers for auto-sync
   * @private
   */
  async _setupFileWatchers() {
    for (const path of this.watchPaths) {
      try {
        const watcher = watch(path);
        (async () => {
          for await (const event of watcher) {
            if (event.eventType === "change" && event.filename.endsWith(".tfstate")) {
              const filePath = `${path}/${event.filename}`;
              if (this.verbose) {
                console.log(`[TfStatePlugin] Detected change: ${filePath}`);
              }
              try {
                await this.importState(filePath);
              } catch (error) {
                this.stats.errors++;
                console.error(`[TfStatePlugin] Auto-import failed:`, error);
                this.emit("importError", { filePath, error });
              }
            }
          }
        })();
        this.watchers.push(watcher);
        if (this.verbose) {
          console.log(`[TfStatePlugin] Watching: ${path}`);
        }
      } catch (error) {
        throw new FileWatchError(path, error);
      }
    }
  }
  /**
   * Export resources to Tfstate format
   * @param {Object} options - Export options
   * @param {number} options.serial - Specific serial to export (default: latest)
   * @param {string[]} options.resourceTypes - Filter by resource types
   * @param {string} options.terraformVersion - Terraform version for output (default: '1.5.0')
   * @param {string} options.lineage - State lineage (default: auto-generated)
   * @param {Object} options.outputs - Terraform outputs to include
   * @returns {Promise<Object>} Tfstate object
   *
   * @example
   * // Export latest state
   * const state = await plugin.exportState();
   *
   * // Export specific serial
   * const state = await plugin.exportState({ serial: 5 });
   *
   * // Export only EC2 instances
   * const state = await plugin.exportState({
   *   resourceTypes: ['aws_instance']
   * });
   */
  async exportState(options = {}) {
    const {
      serial,
      resourceTypes,
      terraformVersion = "1.5.0",
      lineage,
      outputs = {},
      sourceFile
      // Optional: export from specific source file
    } = options;
    let targetSerial = serial;
    if (!targetSerial) {
      const queryFilter = sourceFile ? { sourceFile } : {};
      const latestStateFiles = await this.stateFilesResource.query(queryFilter, {
        limit: 1,
        sort: { serial: -1 }
      });
      if (latestStateFiles.length > 0) {
        targetSerial = latestStateFiles[0].serial;
      }
      if (!targetSerial) {
        targetSerial = this.lastProcessedSerial || 1;
      }
    }
    const partitionName = this._findPartitionByField(this.resource, "stateSerial");
    let resources;
    if (partitionName) {
      this.stats.partitionQueriesOptimized++;
      resources = await this.resource.list({
        partition: partitionName,
        partitionValues: { stateSerial: targetSerial }
      });
      if (this.verbose) {
        console.log(`[TfStatePlugin] Export using partition ${partitionName}: ${resources.length} resources`);
      }
      if (resourceTypes && resourceTypes.length > 0) {
        resources = resources.filter((r) => resourceTypes.includes(r.resourceType));
      }
    } else {
      if (this.verbose) {
        console.log("[TfStatePlugin] No partition found for stateSerial, using full scan");
      }
      const allResources = await this.resource.list({ limit: 1e5 });
      resources = allResources.filter((r) => {
        if (r.stateSerial !== targetSerial) return false;
        if (resourceTypes && resourceTypes.length > 0) {
          return resourceTypes.includes(r.resourceType);
        }
        return true;
      });
    }
    if (this.verbose) {
      console.log(`[TfStatePlugin] Exporting ${resources.length} resources from serial ${targetSerial}`);
    }
    const resourceMap = /* @__PURE__ */ new Map();
    for (const resource of resources) {
      const key = `${resource.mode}.${resource.resourceType}.${resource.resourceName}`;
      if (!resourceMap.has(key)) {
        resourceMap.set(key, {
          mode: resource.mode || "managed",
          type: resource.resourceType,
          name: resource.resourceName,
          provider: resource.providerName,
          instances: []
        });
      }
      resourceMap.get(key).instances.push({
        attributes: resource.attributes,
        dependencies: resource.dependencies || []
      });
    }
    for (const resourceGroup of resourceMap.values()) {
      resourceGroup.instances.sort((a, b) => {
        const aId = a.attributes?.id;
        const bId = b.attributes?.id;
        if (aId && bId) {
          return String(aId).localeCompare(String(bId));
        }
        return JSON.stringify(a.attributes).localeCompare(JSON.stringify(b.attributes));
      });
    }
    const terraformResources = Array.from(resourceMap.values());
    const stateLineage = lineage || `s3db-export-${Date.now()}`;
    const state = {
      version: 4,
      terraform_version: terraformVersion,
      serial: targetSerial,
      lineage: stateLineage,
      outputs,
      resources: terraformResources
    };
    if (this.verbose) {
      console.log(`[TfStatePlugin] Export complete:`, {
        serial: targetSerial,
        resourceCount: resources.length,
        groupedResourceCount: terraformResources.length
      });
    }
    this.emit("stateExported", { serial: targetSerial, resourceCount: resources.length });
    return state;
  }
  /**
   * Export state to local file
   * @param {string} filePath - Output file path
   * @param {Object} options - Export options (see exportState)
   * @returns {Promise<Object>} Export result with file path and stats
   *
   * @example
   * // Export to file
   * await plugin.exportStateToFile('./exported-state.tfstate');
   *
   * // Export specific serial
   * await plugin.exportStateToFile('./state-v5.tfstate', { serial: 5 });
   */
  async exportStateToFile(filePath, options = {}) {
    const state = await this.exportState(options);
    const { writeFileSync } = await import('fs');
    writeFileSync(filePath, JSON.stringify(state, null, 2));
    if (this.verbose) {
      console.log(`[TfStatePlugin] State exported to file: ${filePath}`);
    }
    return {
      filePath,
      serial: state.serial,
      resourceCount: state.resources.reduce((sum, r) => sum + r.instances.length, 0),
      groupedResourceCount: state.resources.length
    };
  }
  /**
   * Export state to S3
   * @param {string} bucket - S3 bucket name
   * @param {string} key - S3 object key
   * @param {Object} options - Export options (see exportState)
   * @param {Object} options.client - Optional S3 client override
   * @returns {Promise<Object>} Export result with S3 location and stats
   *
   * @example
   * // Export to S3
   * await plugin.exportStateToS3('my-bucket', 'terraform/exported.tfstate');
   *
   * // Export with custom options
   * await plugin.exportStateToS3('my-bucket', 'terraform/prod.tfstate', {
   *   serial: 10,
   *   terraformVersion: '1.6.0',
   *   lineage: 'prod-infrastructure'
   * });
   */
  async exportStateToS3(bucket, key, options = {}) {
    const state = await this.exportState(options);
    const client = options.client || this.database.client;
    await client.putObject({
      key,
      body: JSON.stringify(state, null, 2),
      contentType: "application/json"
    });
    if (this.verbose) {
      console.log(`[TfStatePlugin] State exported to S3: s3://${bucket}/${key}`);
    }
    this.emit("stateExportedToS3", { bucket, key, serial: state.serial });
    return {
      bucket,
      key,
      location: `s3://${bucket}/${key}`,
      serial: state.serial,
      resourceCount: state.resources.reduce((sum, r) => sum + r.instances.length, 0),
      groupedResourceCount: state.resources.length
    };
  }
  /**
   * Get diffs with lookback support
   * Retrieves the last N diffs for a given state file
   * @param {string} sourceFile - Source file path
   * @param {Object} options - Query options
   * @param {number} options.lookback - Number of historical diffs to retrieve (default: this.diffsLookback)
   * @param {boolean} options.includeDetails - Include detailed changes (default: false, only summary)
   * @returns {Promise<Array>} Array of diffs ordered by serial (newest first)
   *
   * @example
   * // Get last 10 diffs
   * const diffs = await plugin.getDiffsWithLookback('terraform.tfstate');
   *
   * // Get last 5 diffs with details
   * const diffs = await plugin.getDiffsWithLookback('terraform.tfstate', {
   *   lookback: 5,
   *   includeDetails: true
   * });
   */
  async getDiffsWithLookback(sourceFile, options = {}) {
    if (!this.diffsResource) {
      throw new TfStateError("Diff tracking is not enabled for this plugin");
    }
    const lookback = options.lookback || this.diffsLookback;
    const includeDetails = options.includeDetails || false;
    const diffs = await this.diffsResource.query(
      { sourceFile },
      {
        limit: lookback,
        sort: { newSerial: -1 }
        // Newest first
      }
    );
    if (!includeDetails) {
      return diffs.map((diff) => ({
        id: diff.id,
        oldSerial: diff.oldSerial,
        newSerial: diff.newSerial,
        calculatedAt: diff.calculatedAt,
        summary: diff.summary
      }));
    }
    return diffs;
  }
  /**
   * Get diff timeline for a state file
   * Shows progression of changes over time
   * @param {string} sourceFile - Source file path
   * @param {Object} options - Query options
   * @param {number} options.lookback - Number of diffs to include in timeline
   * @returns {Promise<Object>} Timeline with statistics and diff history
   *
   * @example
   * const timeline = await plugin.getDiffTimeline('terraform.tfstate', { lookback: 20 });
   * console.log(timeline.summary); // Overall statistics
   * console.log(timeline.diffs); // Chronological diff history
   */
  async getDiffTimeline(sourceFile, options = {}) {
    const diffs = await this.getDiffsWithLookback(sourceFile, {
      ...options,
      includeDetails: false
    });
    const timeline = {
      sourceFile,
      totalDiffs: diffs.length,
      summary: {
        totalAdded: 0,
        totalModified: 0,
        totalDeleted: 0,
        serialRange: {
          oldest: diffs.length > 0 ? Math.min(...diffs.map((d) => d.oldSerial)) : null,
          newest: diffs.length > 0 ? Math.max(...diffs.map((d) => d.newSerial)) : null
        },
        timeRange: {
          first: diffs.length > 0 ? Math.min(...diffs.map((d) => d.calculatedAt)) : null,
          last: diffs.length > 0 ? Math.max(...diffs.map((d) => d.calculatedAt)) : null
        }
      },
      diffs: diffs.reverse()
      // Oldest first for timeline view
    };
    for (const diff of diffs) {
      if (diff.summary) {
        timeline.summary.totalAdded += diff.summary.addedCount || 0;
        timeline.summary.totalModified += diff.summary.modifiedCount || 0;
        timeline.summary.totalDeleted += diff.summary.deletedCount || 0;
      }
    }
    return timeline;
  }
  /**
   * Compare two specific state serials
   * @param {string} sourceFile - Source file path
   * @param {number} oldSerial - Old state serial
   * @param {number} newSerial - New state serial
   * @returns {Promise<Object>} Diff object or null if not found
   *
   * @example
   * const diff = await plugin.compareStates('terraform.tfstate', 5, 10);
   */
  async compareStates(sourceFile, oldSerial, newSerial) {
    if (!this.diffsResource) {
      throw new TfStateError("Diff tracking is not enabled for this plugin");
    }
    const diffs = await this.diffsResource.query({
      sourceFile,
      oldSerial,
      newSerial
    }, { limit: 1 });
    if (diffs.length === 0) {
      const [ok, err, result] = await tryFn(async () => {
        return await this._computeDiff(oldSerial, newSerial);
      });
      if (!ok) {
        throw new StateDiffError(oldSerial, newSerial, err);
      }
      result.sourceFile = sourceFile;
      result.oldSerial = oldSerial;
      result.newSerial = newSerial;
      return result;
    }
    return diffs[0];
  }
  /**
   * Trigger monitoring check manually
   * Useful for testing or on-demand synchronization
   * @returns {Promise<Object>} Monitoring result
   *
   * @example
   * const result = await plugin.triggerMonitoring();
   * console.log(`Processed ${result.newFiles} new files`);
   */
  async triggerMonitoring() {
    if (!this.driver) {
      throw new TfStateError("Driver not initialized. Use driver-based configuration to enable monitoring.");
    }
    return await this._monitorStateFiles();
  }
  /**
   * Get resources by type (uses partition for fast queries)
   * @param {string} type - Resource type (e.g., 'aws_instance')
   * @returns {Promise<Array>} Resources of the specified type
   *
   * @example
   * const ec2Instances = await plugin.getResourcesByType('aws_instance');
   */
  async getResourcesByType(type) {
    return await this.resource.listPartition({
      partition: "byType",
      partitionValues: { resourceType: type }
    });
  }
  /**
   * Get resources by provider (uses partition for fast queries)
   * @param {string} provider - Provider name (e.g., 'aws', 'google', 'azure')
   * @returns {Promise<Array>} Resources from the specified provider
   *
   * @example
   * const awsResources = await plugin.getResourcesByProvider('aws');
   */
  async getResourcesByProvider(provider) {
    return await this.resource.listPartition({
      partition: "byProvider",
      partitionValues: { providerName: provider }
    });
  }
  /**
   * Get resources by provider and type (uses partition for ultra-fast queries)
   * @param {string} provider - Provider name (e.g., 'aws')
   * @param {string} type - Resource type (e.g., 'aws_instance')
   * @returns {Promise<Array>} Resources matching both provider and type
   *
   * @example
   * const awsRds = await plugin.getResourcesByProviderAndType('aws', 'aws_db_instance');
   */
  async getResourcesByProviderAndType(provider, type) {
    return await this.resource.listPartition({
      partition: "byProviderAndType",
      partitionValues: {
        providerName: provider,
        resourceType: type
      }
    });
  }
  /**
   * Get diff between two state serials
   * Alias for compareStates() for API consistency
   * @param {string} sourceFile - Source file path
   * @param {number} oldSerial - Old state serial
   * @param {number} newSerial - New state serial
   * @returns {Promise<Object>} Diff object
   *
   * @example
   * const diff = await plugin.getDiff('terraform.tfstate', 1, 2);
   */
  async getDiff(sourceFile, oldSerial, newSerial) {
    return await this.compareStates(sourceFile, oldSerial, newSerial);
  }
  /**
   * Get statistics by provider
   * @returns {Promise<Object>} Provider counts { aws: 150, google: 30, ... }
   *
   * @example
   * const stats = await plugin.getStatsByProvider();
   * console.log(`AWS resources: ${stats.aws}`);
   */
  async getStatsByProvider() {
    const allResources = await this.resource.list({ limit: 1e5 });
    const providerCounts = {};
    for (const resource of allResources) {
      const provider = resource.providerName || "unknown";
      providerCounts[provider] = (providerCounts[provider] || 0) + 1;
    }
    return providerCounts;
  }
  /**
   * Get statistics by resource type
   * @returns {Promise<Object>} Type counts { aws_instance: 20, aws_s3_bucket: 50, ... }
   *
   * @example
   * const stats = await plugin.getStatsByType();
   * console.log(`EC2 instances: ${stats.aws_instance}`);
   */
  async getStatsByType() {
    const allResources = await this.resource.list({ limit: 1e5 });
    const typeCounts = {};
    for (const resource of allResources) {
      const type = resource.resourceType;
      typeCounts[type] = (typeCounts[type] || 0) + 1;
    }
    return typeCounts;
  }
  /**
   * Find partition by field name (for efficient queries)
   * Uses cache to avoid repeated lookups
   * @private
   */
  _findPartitionByField(resource, fieldName) {
    if (!resource.config.partitions) return null;
    const cacheKey = `${resource.name}:${fieldName}`;
    if (this._partitionCache.has(cacheKey)) {
      this.stats.partitionCacheHits++;
      return this._partitionCache.get(cacheKey);
    }
    let bestPartition = null;
    let bestFieldCount = Infinity;
    for (const [partitionName, partitionConfig] of Object.entries(resource.config.partitions)) {
      if (partitionConfig.fields && fieldName in partitionConfig.fields) {
        const fieldCount = Object.keys(partitionConfig.fields).length;
        if (fieldCount < bestFieldCount) {
          bestPartition = partitionName;
          bestFieldCount = fieldCount;
        }
      }
    }
    this._partitionCache.set(cacheKey, bestPartition);
    return bestPartition;
  }
  /**
   * Get plugin statistics
   * @returns {Promise<Object>} Statistics with provider/type breakdowns
   *
   * @example
   * const stats = await plugin.getStats();
   * console.log(`Total: ${stats.totalResources} resources`);
   * console.log(`Providers:`, stats.providers);
   */
  async getStats() {
    const stateFiles = await this.stateFilesResource.list({ limit: 1e5 });
    const allResources = await this.resource.list({ limit: 1e5 });
    const providers = {};
    const types = {};
    for (const resource of allResources) {
      const provider = resource.providerName || "unknown";
      const type = resource.resourceType;
      providers[provider] = (providers[provider] || 0) + 1;
      types[type] = (types[type] || 0) + 1;
    }
    const latestSerial = stateFiles.length > 0 ? Math.max(...stateFiles.map((sf) => sf.serial)) : null;
    const diffsCount = this.trackDiffs && this.diffsResource ? (await this.diffsResource.list({ limit: 1e5 })).length : 0;
    return {
      totalStates: stateFiles.length,
      totalResources: allResources.length,
      totalDiffs: diffsCount,
      latestSerial,
      providers,
      types,
      // Runtime stats
      statesProcessed: this.stats.statesProcessed,
      resourcesExtracted: this.stats.resourcesExtracted,
      resourcesInserted: this.stats.resourcesInserted,
      diffsCalculated: this.stats.diffsCalculated,
      errors: this.stats.errors,
      partitionCacheHits: this.stats.partitionCacheHits,
      partitionQueriesOptimized: this.stats.partitionQueriesOptimized
    };
  }
}

const ONE_HOUR_SEC = 3600;
const ONE_DAY_SEC = 86400;
const THIRTY_DAYS_SEC = 2592e3;
const TEN_SECONDS_MS = 1e4;
const ONE_MINUTE_MS = 6e4;
const TEN_MINUTES_MS = 6e5;
const ONE_HOUR_MS = 36e5;
const ONE_DAY_MS = 864e5;
const ONE_WEEK_MS = 6048e5;
const SECONDS_TO_MS = 1e3;
const GRANULARITIES = {
  minute: {
    threshold: ONE_HOUR_SEC,
    // TTL < 1 hour
    interval: TEN_SECONDS_MS,
    // Check every 10 seconds
    cohortsToCheck: 3,
    // Check last 3 minutes
    cohortFormat: (date) => date.toISOString().substring(0, 16)
    // '2024-10-25T14:30'
  },
  hour: {
    threshold: ONE_DAY_SEC,
    // TTL < 24 hours
    interval: TEN_MINUTES_MS,
    // Check every 10 minutes
    cohortsToCheck: 2,
    // Check last 2 hours
    cohortFormat: (date) => date.toISOString().substring(0, 13)
    // '2024-10-25T14'
  },
  day: {
    threshold: THIRTY_DAYS_SEC,
    // TTL < 30 days
    interval: ONE_HOUR_MS,
    // Check every 1 hour
    cohortsToCheck: 2,
    // Check last 2 days
    cohortFormat: (date) => date.toISOString().substring(0, 10)
    // '2024-10-25'
  },
  week: {
    threshold: Infinity,
    // TTL >= 30 days
    interval: ONE_DAY_MS,
    // Check every 24 hours
    cohortsToCheck: 2,
    // Check last 2 weeks
    cohortFormat: (date) => {
      const year = date.getUTCFullYear();
      const week = getWeekNumber(date);
      return `${year}-W${String(week).padStart(2, "0")}`;
    }
  }
};
function getWeekNumber(date) {
  const d = new Date(Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()));
  const dayNum = d.getUTCDay() || 7;
  d.setUTCDate(d.getUTCDate() + 4 - dayNum);
  const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));
  return Math.ceil(((d - yearStart) / ONE_DAY_MS + 1) / 7);
}
function detectGranularity(ttl) {
  if (!ttl) return "day";
  if (ttl < GRANULARITIES.minute.threshold) return "minute";
  if (ttl < GRANULARITIES.hour.threshold) return "hour";
  if (ttl < GRANULARITIES.day.threshold) return "day";
  return "week";
}
function getExpiredCohorts(granularity, count) {
  const config = GRANULARITIES[granularity];
  const cohorts = [];
  const now = /* @__PURE__ */ new Date();
  for (let i = 0; i < count; i++) {
    let checkDate;
    switch (granularity) {
      case "minute":
        checkDate = new Date(now.getTime() - i * ONE_MINUTE_MS);
        break;
      case "hour":
        checkDate = new Date(now.getTime() - i * ONE_HOUR_MS);
        break;
      case "day":
        checkDate = new Date(now.getTime() - i * ONE_DAY_MS);
        break;
      case "week":
        checkDate = new Date(now.getTime() - i * ONE_WEEK_MS);
        break;
    }
    cohorts.push(config.cohortFormat(checkDate));
  }
  return cohorts;
}
class TTLPlugin extends Plugin {
  constructor(config = {}) {
    super(config);
    this.verbose = config.verbose !== void 0 ? config.verbose : false;
    this.resources = config.resources || {};
    this.batchSize = config.batchSize || 100;
    this.stats = {
      totalScans: 0,
      totalExpired: 0,
      totalDeleted: 0,
      totalArchived: 0,
      totalSoftDeleted: 0,
      totalCallbacks: 0,
      totalErrors: 0,
      lastScanAt: null,
      lastScanDuration: 0
    };
    this.intervals = [];
    this.isRunning = false;
    this.expirationIndex = null;
  }
  /**
   * Install the plugin
   */
  async install(database) {
    await super.install(database);
    for (const [resourceName, config] of Object.entries(this.resources)) {
      this._validateResourceConfig(resourceName, config);
    }
    await this._createExpirationIndex();
    for (const [resourceName, config] of Object.entries(this.resources)) {
      this._setupResourceHooks(resourceName, config);
    }
    this._startIntervals();
    if (this.verbose) {
      console.log(`[TTLPlugin] Installed with ${Object.keys(this.resources).length} resources`);
    }
    this.emit("db:plugin:installed", {
      plugin: "TTLPlugin",
      resources: Object.keys(this.resources)
    });
  }
  /**
   * Validate resource configuration
   */
  _validateResourceConfig(resourceName, config) {
    if (!config.ttl && !config.field) {
      throw new Error(
        `[TTLPlugin] Resource "${resourceName}" must have either "ttl" (seconds) or "field" (timestamp field name)`
      );
    }
    const validStrategies = ["soft-delete", "hard-delete", "archive", "callback"];
    if (!config.onExpire || !validStrategies.includes(config.onExpire)) {
      throw new Error(
        `[TTLPlugin] Resource "${resourceName}" must have an "onExpire" value. Valid options: ${validStrategies.join(", ")}`
      );
    }
    if (config.onExpire === "soft-delete" && !config.deleteField) {
      config.deleteField = "deletedat";
    }
    if (config.onExpire === "archive" && !config.archiveResource) {
      throw new Error(
        `[TTLPlugin] Resource "${resourceName}" with onExpire="archive" must have an "archiveResource" specified`
      );
    }
    if (config.onExpire === "callback" && typeof config.callback !== "function") {
      throw new Error(
        `[TTLPlugin] Resource "${resourceName}" with onExpire="callback" must have a "callback" function`
      );
    }
    if (!config.field) {
      config.field = "_createdAt";
    }
    if (config.field === "_createdAt" && this.database) {
      const resource = this.database.resources[resourceName];
      if (resource && resource.config && resource.config.timestamps === false) {
        console.warn(
          `[TTLPlugin] WARNING: Resource "${resourceName}" uses TTL with field "_createdAt" but timestamps are disabled. TTL will be calculated from indexing time, not creation time.`
        );
      }
    }
    config.granularity = detectGranularity(config.ttl);
  }
  /**
   * Create expiration index (plugin resource)
   */
  async _createExpirationIndex() {
    this.expirationIndex = await this.database.createResource({
      name: "plg_ttl_expiration_index",
      attributes: {
        resourceName: "string|required",
        recordId: "string|required",
        expiresAtCohort: "string|required",
        expiresAtTimestamp: "number|required",
        // Exact expiration timestamp for precise checking
        granularity: "string|required",
        createdAt: "number"
      },
      partitions: {
        byExpiresAtCohort: {
          fields: { expiresAtCohort: "string" }
        }
      },
      asyncPartitions: false
      // Sync partitions for deterministic behavior
    });
    if (this.verbose) {
      console.log("[TTLPlugin] Created expiration index with partition");
    }
  }
  /**
   * Setup hooks for a resource
   */
  _setupResourceHooks(resourceName, config) {
    if (!this.database.resources[resourceName]) {
      if (this.verbose) {
        console.warn(`[TTLPlugin] Resource "${resourceName}" not found, skipping hooks`);
      }
      return;
    }
    const resource = this.database.resources[resourceName];
    if (typeof resource.insert !== "function" || typeof resource.delete !== "function") {
      if (this.verbose) {
        console.warn(`[TTLPlugin] Resource "${resourceName}" missing insert/delete methods, skipping hooks`);
      }
      return;
    }
    this.addMiddleware(resource, "insert", async (next, data, options) => {
      const result = await next(data, options);
      await this._addToIndex(resourceName, result, config);
      return result;
    });
    this.addMiddleware(resource, "delete", async (next, id, options) => {
      const result = await next(id, options);
      await this._removeFromIndex(resourceName, id);
      return result;
    });
    if (this.verbose) {
      console.log(`[TTLPlugin] Setup hooks for resource "${resourceName}"`);
    }
  }
  /**
   * Add record to expiration index
   */
  async _addToIndex(resourceName, record, config) {
    try {
      let baseTime = record[config.field];
      if (!baseTime && config.field === "_createdAt") {
        baseTime = Date.now();
      }
      if (!baseTime) {
        if (this.verbose) {
          console.warn(
            `[TTLPlugin] Record ${record.id} in ${resourceName} missing field "${config.field}", skipping index`
          );
        }
        return;
      }
      const baseTimestamp = typeof baseTime === "number" ? baseTime : new Date(baseTime).getTime();
      const expiresAt = config.ttl ? new Date(baseTimestamp + config.ttl * SECONDS_TO_MS) : new Date(baseTimestamp);
      const cohortConfig = GRANULARITIES[config.granularity];
      const cohort = cohortConfig.cohortFormat(expiresAt);
      const indexId = `${resourceName}:${record.id}`;
      await this.expirationIndex.insert({
        id: indexId,
        resourceName,
        recordId: record.id,
        expiresAtCohort: cohort,
        expiresAtTimestamp: expiresAt.getTime(),
        // Store exact timestamp for precise checking
        granularity: config.granularity,
        createdAt: Date.now()
      });
      if (this.verbose) {
        console.log(
          `[TTLPlugin] Added ${resourceName}:${record.id} to index (cohort: ${cohort}, granularity: ${config.granularity})`
        );
      }
    } catch (error) {
      console.error(`[TTLPlugin] Error adding to index:`, error);
      this.stats.totalErrors++;
    }
  }
  /**
   * Remove record from expiration index (O(1) using deterministic ID)
   */
  async _removeFromIndex(resourceName, recordId) {
    try {
      const indexId = `${resourceName}:${recordId}`;
      const [ok, err] = await tryFn(() => this.expirationIndex.delete(indexId));
      if (this.verbose && ok) {
        console.log(`[TTLPlugin] Removed index entry for ${resourceName}:${recordId}`);
      }
      if (!ok && err?.code !== "NoSuchKey") {
        throw err;
      }
    } catch (error) {
      console.error(`[TTLPlugin] Error removing from index:`, error);
    }
  }
  /**
   * Start interval-based cleanup for each granularity
   */
  _startIntervals() {
    const byGranularity = {
      minute: [],
      hour: [],
      day: [],
      week: []
    };
    for (const [name, config] of Object.entries(this.resources)) {
      byGranularity[config.granularity].push({ name, config });
    }
    for (const [granularity, resources] of Object.entries(byGranularity)) {
      if (resources.length === 0) continue;
      const granularityConfig = GRANULARITIES[granularity];
      const handle = setInterval(
        () => this._cleanupGranularity(granularity, resources),
        granularityConfig.interval
      );
      this.intervals.push(handle);
      if (this.verbose) {
        console.log(
          `[TTLPlugin] Started ${granularity} interval (${granularityConfig.interval}ms) for ${resources.length} resources`
        );
      }
    }
    this.isRunning = true;
  }
  /**
   * Stop all intervals
   */
  _stopIntervals() {
    for (const handle of this.intervals) {
      clearInterval(handle);
    }
    this.intervals = [];
    this.isRunning = false;
    if (this.verbose) {
      console.log("[TTLPlugin] Stopped all intervals");
    }
  }
  /**
   * Cleanup expired records for a specific granularity
   */
  async _cleanupGranularity(granularity, resources) {
    const startTime = Date.now();
    this.stats.totalScans++;
    try {
      const granularityConfig = GRANULARITIES[granularity];
      const cohorts = getExpiredCohorts(granularity, granularityConfig.cohortsToCheck);
      if (this.verbose) {
        console.log(`[TTLPlugin] Cleaning ${granularity} granularity, checking cohorts:`, cohorts);
      }
      for (const cohort of cohorts) {
        const expired = await this.expirationIndex.listPartition({
          partition: "byExpiresAtCohort",
          partitionValues: { expiresAtCohort: cohort }
        });
        const resourceNames = new Set(resources.map((r) => r.name));
        const filtered = expired.filter((e) => resourceNames.has(e.resourceName));
        if (this.verbose && filtered.length > 0) {
          console.log(`[TTLPlugin] Found ${filtered.length} expired records in cohort ${cohort}`);
        }
        for (let i = 0; i < filtered.length; i += this.batchSize) {
          const batch = filtered.slice(i, i + this.batchSize);
          for (const entry of batch) {
            const config = this.resources[entry.resourceName];
            await this._processExpiredEntry(entry, config);
          }
        }
      }
      this.stats.lastScanAt = (/* @__PURE__ */ new Date()).toISOString();
      this.stats.lastScanDuration = Date.now() - startTime;
      this.emit("plg:ttl:scan-completed", {
        granularity,
        duration: this.stats.lastScanDuration,
        cohorts
      });
    } catch (error) {
      console.error(`[TTLPlugin] Error in ${granularity} cleanup:`, error);
      this.stats.totalErrors++;
      this.emit("plg:ttl:cleanup-error", { granularity, error });
    }
  }
  /**
   * Process a single expired index entry
   */
  async _processExpiredEntry(entry, config) {
    try {
      if (!this.database.resources[entry.resourceName]) {
        if (this.verbose) {
          console.warn(`[TTLPlugin] Resource "${entry.resourceName}" not found during cleanup, skipping`);
        }
        return;
      }
      const resource = this.database.resources[entry.resourceName];
      const [ok, err, record] = await tryFn(() => resource.get(entry.recordId));
      if (!ok || !record) {
        await this.expirationIndex.delete(entry.id);
        return;
      }
      if (entry.expiresAtTimestamp && Date.now() < entry.expiresAtTimestamp) {
        return;
      }
      switch (config.onExpire) {
        case "soft-delete":
          await this._softDelete(resource, record, config);
          this.stats.totalSoftDeleted++;
          break;
        case "hard-delete":
          await this._hardDelete(resource, record);
          this.stats.totalDeleted++;
          break;
        case "archive":
          await this._archive(resource, record, config);
          this.stats.totalArchived++;
          this.stats.totalDeleted++;
          break;
        case "callback":
          const shouldDelete = await config.callback(record, resource);
          this.stats.totalCallbacks++;
          if (shouldDelete) {
            await this._hardDelete(resource, record);
            this.stats.totalDeleted++;
          }
          break;
      }
      await this.expirationIndex.delete(entry.id);
      this.stats.totalExpired++;
      this.emit("plg:ttl:record-expired", { resource: entry.resourceName, record });
    } catch (error) {
      console.error(`[TTLPlugin] Error processing expired entry:`, error);
      this.stats.totalErrors++;
    }
  }
  /**
   * Soft delete: Mark record as deleted
   */
  async _softDelete(resource, record, config) {
    const deleteField = config.deleteField || "deletedat";
    const updates = {
      [deleteField]: (/* @__PURE__ */ new Date()).toISOString(),
      isdeleted: "true"
      // Add isdeleted field for partition compatibility
    };
    await resource.update(record.id, updates);
    if (this.verbose) {
      console.log(`[TTLPlugin] Soft-deleted record ${record.id} in ${resource.name}`);
    }
  }
  /**
   * Hard delete: Remove record from S3
   */
  async _hardDelete(resource, record) {
    await resource.delete(record.id);
    if (this.verbose) {
      console.log(`[TTLPlugin] Hard-deleted record ${record.id} in ${resource.name}`);
    }
  }
  /**
   * Archive: Copy to another resource then delete
   */
  async _archive(resource, record, config) {
    if (!this.database.resources[config.archiveResource]) {
      throw new Error(`Archive resource "${config.archiveResource}" not found`);
    }
    const archiveResource = this.database.resources[config.archiveResource];
    const archiveData = {};
    for (const [key, value] of Object.entries(record)) {
      if (!key.startsWith("_")) {
        archiveData[key] = value;
      }
    }
    archiveData.archivedAt = (/* @__PURE__ */ new Date()).toISOString();
    archiveData.archivedFrom = resource.name;
    archiveData.originalId = record.id;
    if (!config.keepOriginalId) {
      delete archiveData.id;
    }
    await archiveResource.insert(archiveData);
    await resource.delete(record.id);
    if (this.verbose) {
      console.log(`[TTLPlugin] Archived record ${record.id} from ${resource.name} to ${config.archiveResource}`);
    }
  }
  /**
   * Manual cleanup of a specific resource
   */
  async cleanupResource(resourceName) {
    const config = this.resources[resourceName];
    if (!config) {
      throw new Error(`Resource "${resourceName}" not configured in TTLPlugin`);
    }
    const granularity = config.granularity;
    await this._cleanupGranularity(granularity, [{ name: resourceName, config }]);
    return {
      resource: resourceName,
      granularity
    };
  }
  /**
   * Manual cleanup of all resources
   */
  async runCleanup() {
    const byGranularity = {
      minute: [],
      hour: [],
      day: [],
      week: []
    };
    for (const [name, config] of Object.entries(this.resources)) {
      byGranularity[config.granularity].push({ name, config });
    }
    for (const [granularity, resources] of Object.entries(byGranularity)) {
      if (resources.length > 0) {
        await this._cleanupGranularity(granularity, resources);
      }
    }
  }
  /**
   * Get plugin statistics
   */
  getStats() {
    return {
      ...this.stats,
      resources: Object.keys(this.resources).length,
      isRunning: this.isRunning,
      intervals: this.intervals.length
    };
  }
  /**
   * Uninstall the plugin
   */
  async uninstall() {
    this._stopIntervals();
    await super.uninstall();
    if (this.verbose) {
      console.log("[TTLPlugin] Uninstalled");
    }
  }
}

function cosineDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let dotProduct2 = 0;
  let normA = 0;
  let normB = 0;
  for (let i = 0; i < a.length; i++) {
    dotProduct2 += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  const denominator = Math.sqrt(normA) * Math.sqrt(normB);
  if (denominator === 0) {
    return a.every((v) => v === 0) && b.every((v) => v === 0) ? 0 : 1;
  }
  const similarity = dotProduct2 / denominator;
  return 1 - similarity;
}
function euclideanDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = a[i] - b[i];
    sum += diff * diff;
  }
  return Math.sqrt(sum);
}
function manhattanDistance(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    sum += Math.abs(a[i] - b[i]);
  }
  return sum;
}
function dotProduct(a, b) {
  if (a.length !== b.length) {
    throw new Error(`Dimension mismatch: ${a.length} vs ${b.length}`);
  }
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    sum += a[i] * b[i];
  }
  return sum;
}
function normalize(vector) {
  const magnitude2 = Math.sqrt(
    vector.reduce((sum, val) => sum + val * val, 0)
  );
  if (magnitude2 === 0) {
    return vector.slice();
  }
  return vector.map((val) => val / magnitude2);
}

function kmeans(vectors, k, options = {}) {
  const {
    maxIterations = 100,
    tolerance = 1e-4,
    distanceFn = euclideanDistance,
    seed = null,
    onIteration = null
  } = options;
  if (vectors.length === 0) {
    throw new Error("Cannot cluster empty vector array");
  }
  if (k < 1) {
    throw new Error(`k must be at least 1, got ${k}`);
  }
  if (k > vectors.length) {
    throw new Error(`k (${k}) cannot be greater than number of vectors (${vectors.length})`);
  }
  const dimensions = vectors[0].length;
  for (let i = 1; i < vectors.length; i++) {
    if (vectors[i].length !== dimensions) {
      throw new Error(`All vectors must have same dimensions. Expected ${dimensions}, got ${vectors[i].length} at index ${i}`);
    }
  }
  const centroids = initializeCentroidsKMeansPlusPlus(vectors, k, distanceFn, seed);
  let assignments = new Array(vectors.length);
  let iterations = 0;
  let converged = false;
  let previousInertia = Infinity;
  while (!converged && iterations < maxIterations) {
    const newAssignments = vectors.map((vector) => {
      let minDist = Infinity;
      let nearestCluster = 0;
      for (let i = 0; i < k; i++) {
        const dist = distanceFn(vector, centroids[i]);
        if (dist < minDist) {
          minDist = dist;
          nearestCluster = i;
        }
      }
      return nearestCluster;
    });
    let inertia2 = 0;
    vectors.forEach((vector, i) => {
      const dist = distanceFn(vector, centroids[newAssignments[i]]);
      inertia2 += dist * dist;
    });
    const inertiaChange = Math.abs(previousInertia - inertia2);
    converged = inertiaChange < tolerance;
    assignments = newAssignments;
    previousInertia = inertia2;
    if (onIteration) {
      onIteration(iterations + 1, inertia2, converged);
    }
    if (!converged) {
      const clusterSums = Array(k).fill(null).map(() => new Array(dimensions).fill(0));
      const clusterCounts = new Array(k).fill(0);
      vectors.forEach((vector, i) => {
        const cluster = assignments[i];
        clusterCounts[cluster]++;
        vector.forEach((val, j) => {
          clusterSums[cluster][j] += val;
        });
      });
      for (let i = 0; i < k; i++) {
        if (clusterCounts[i] > 0) {
          centroids[i] = clusterSums[i].map((sum) => sum / clusterCounts[i]);
        } else {
          const randomIdx = Math.floor(Math.random() * vectors.length);
          centroids[i] = [...vectors[randomIdx]];
        }
      }
    }
    iterations++;
  }
  let inertia = 0;
  vectors.forEach((vector, i) => {
    const dist = distanceFn(vector, centroids[assignments[i]]);
    inertia += dist * dist;
  });
  return {
    centroids,
    assignments,
    iterations,
    converged,
    inertia
  };
}
function initializeCentroidsKMeansPlusPlus(vectors, k, distanceFn, seed) {
  const centroids = [];
  const n = vectors.length;
  const firstIndex = seed !== null ? seed % n : Math.floor(Math.random() * n);
  centroids.push([...vectors[firstIndex]]);
  for (let i = 1; i < k; i++) {
    const distances = vectors.map((vector) => {
      return Math.min(...centroids.map((c) => distanceFn(vector, c)));
    });
    const squaredDistances = distances.map((d) => d * d);
    const totalSquared = squaredDistances.reduce((a, b) => a + b, 0);
    if (totalSquared === 0) {
      const randomIdx = Math.floor(Math.random() * n);
      centroids.push([...vectors[randomIdx]]);
      continue;
    }
    let threshold = Math.random() * totalSquared;
    let cumulativeSum = 0;
    for (let j = 0; j < n; j++) {
      cumulativeSum += squaredDistances[j];
      if (cumulativeSum >= threshold) {
        centroids.push([...vectors[j]]);
        break;
      }
    }
  }
  return centroids;
}
async function findOptimalK(vectors, options = {}) {
  const {
    minK = 2,
    maxK = Math.min(10, Math.floor(Math.sqrt(vectors.length / 2))),
    distanceFn = euclideanDistance,
    nReferences = 10,
    stabilityRuns = 5,
    ...kmeansOptions
  } = options;
  const metricsModule = await Promise.resolve().then(function () { return metrics; });
  const {
    silhouetteScore,
    daviesBouldinIndex,
    calinskiHarabaszIndex,
    gapStatistic,
    clusteringStability
  } = metricsModule;
  const results = [];
  for (let k = minK; k <= maxK; k++) {
    const kmeansResult = kmeans(vectors, k, { ...kmeansOptions, distanceFn });
    const silhouette = silhouetteScore(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const daviesBouldin = daviesBouldinIndex(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const calinskiHarabasz = calinskiHarabaszIndex(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn
    );
    const gap = await gapStatistic(
      vectors,
      kmeansResult.assignments,
      kmeansResult.centroids,
      distanceFn,
      nReferences
    );
    const stability = clusteringStability(
      vectors,
      k,
      { ...kmeansOptions, distanceFn, nRuns: stabilityRuns }
    );
    results.push({
      k,
      inertia: kmeansResult.inertia,
      silhouette,
      daviesBouldin,
      calinskiHarabasz,
      gap: gap.gap,
      gapSk: gap.sk,
      stability: stability.stability,
      cvInertia: stability.cvInertia,
      iterations: kmeansResult.iterations,
      converged: kmeansResult.converged
    });
  }
  const elbowK = findElbowPoint(results.map((r) => r.inertia));
  const recommendations = {
    elbow: minK + elbowK,
    silhouette: results.reduce(
      (best, curr) => curr.silhouette > best.silhouette ? curr : best
    ).k,
    daviesBouldin: results.reduce(
      (best, curr) => curr.daviesBouldin < best.daviesBouldin ? curr : best
    ).k,
    calinskiHarabasz: results.reduce(
      (best, curr) => curr.calinskiHarabasz > best.calinskiHarabasz ? curr : best
    ).k,
    gap: results.reduce(
      (best, curr) => curr.gap > best.gap ? curr : best
    ).k,
    stability: results.reduce(
      (best, curr) => curr.stability > best.stability ? curr : best
    ).k
  };
  const votes = Object.values(recommendations);
  const consensus = votes.reduce((acc, k) => {
    acc[k] = (acc[k] || 0) + 1;
    return acc;
  }, {});
  const consensusK = parseInt(
    Object.entries(consensus).reduce((a, b) => b[1] > a[1] ? b : a)[0]
  );
  return {
    results,
    recommendations,
    consensus: consensusK,
    summary: {
      analysisRange: `${minK}-${maxK}`,
      totalVectors: vectors.length,
      dimensions: vectors[0].length,
      recommendation: consensusK,
      confidence: consensus[consensusK] / votes.length
    }
  };
}
function findElbowPoint(inertias) {
  const n = inertias.length;
  if (n < 3) return 0;
  let maxCurvature = -Infinity;
  let elbowIndex = 0;
  for (let i = 1; i < n - 1; i++) {
    const curvature = inertias[i - 1] - 2 * inertias[i] + inertias[i + 1];
    if (curvature > maxCurvature) {
      maxCurvature = curvature;
      elbowIndex = i;
    }
  }
  return elbowIndex;
}

class VectorError extends PluginError {
  constructor(message, details = {}) {
    super(message, {
      pluginName: "VectorPlugin",
      ...details,
      description: details.description || `
Vector Plugin Error

Operation: ${details.operation || "unknown"}

Common causes:
1. Vector dimension mismatch between vectors
2. Invalid distance metric specified (must be: cosine, euclidean, manhattan)
3. Empty vector array provided for clustering
4. k value larger than number of available vectors
5. Vector field not found or invalid in resource
6. Large vectors without proper behavior (use 'body-overflow' or 'body-only')

Available distance metrics:
- cosine: Best for normalized vectors, semantic similarity. Range: [0, 2]
- euclidean: Standard L2 distance, geometric proximity. Range: [0, \u221E)
- manhattan: L1 distance, faster computation. Range: [0, \u221E)

Storage considerations:
- Vectors > 250 dimensions may exceed S3 metadata limit (2KB)
- Use behavior: 'body-overflow' or 'body-only' for large vectors
- OpenAI ada-002 (1536 dims): ~10KB, requires body storage
- Sentence Transformers (384 dims): ~2.7KB, requires body storage
      `.trim()
    });
  }
}

class VectorPlugin extends Plugin {
  constructor(options = {}) {
    super(options);
    this.config = {
      dimensions: 1536,
      // Default to OpenAI text-embedding-3-small/3-large
      distanceMetric: "cosine",
      // Default metric
      storageThreshold: 1500,
      // Bytes - warn if vectors exceed this
      autoFixBehavior: false,
      // Automatically set body-overflow
      autoDetectVectorField: true,
      // Auto-detect embedding:XXX fields
      emitEvents: true,
      // Emit events for monitoring
      verboseEvents: false,
      // Emit detailed progress events
      eventThrottle: 100,
      // Throttle progress events (ms)
      ...options
    };
    this.distanceFunctions = {
      cosine: cosineDistance,
      euclidean: euclideanDistance,
      manhattan: manhattanDistance
    };
    this._vectorFieldCache = /* @__PURE__ */ new Map();
    this._throttleState = /* @__PURE__ */ new Map();
  }
  async onInstall() {
    this.emit("db:plugin:installed", { plugin: "VectorPlugin" });
    this.validateVectorStorage();
    this.installResourceMethods();
  }
  async onStart() {
    this.emit("db:plugin:started", { plugin: "VectorPlugin" });
  }
  async onStop() {
    this.emit("db:plugin:stopped", { plugin: "VectorPlugin" });
  }
  async onUninstall(options) {
    for (const resource of Object.values(this.database.resources)) {
      delete resource.vectorSearch;
      delete resource.cluster;
      delete resource.vectorDistance;
      delete resource.similarTo;
      delete resource.findSimilar;
      delete resource.distance;
    }
    this.emit("db:plugin:uninstalled", { plugin: "VectorPlugin" });
  }
  /**
   * Validate vector storage configuration for all resources
   *
   * Detects large vector fields and warns if proper behavior is not set.
   * Can optionally auto-fix by setting body-overflow behavior.
   * Auto-creates partitions for optional embedding fields to enable O(1) filtering.
   */
  validateVectorStorage() {
    for (const resource of Object.values(this.database.resources)) {
      const vectorFields = this.findVectorFields(resource.schema.attributes);
      if (vectorFields.length === 0) continue;
      const totalVectorSize = vectorFields.reduce((sum, f) => sum + f.estimatedBytes, 0);
      if (totalVectorSize > this.config.storageThreshold) {
        const hasCorrectBehavior = ["body-overflow", "body-only"].includes(resource.behavior);
        if (!hasCorrectBehavior) {
          const warning = {
            resource: resource.name,
            vectorFields: vectorFields.map((f) => ({
              field: f.name,
              dimensions: f.length,
              estimatedBytes: f.estimatedBytes
            })),
            totalEstimatedBytes: totalVectorSize,
            metadataLimit: 2047,
            currentBehavior: resource.behavior || "default",
            recommendation: "body-overflow"
          };
          this.emit("plg:vector:storage-warning", warning);
          if (this.config.autoFixBehavior) {
            resource.behavior = "body-overflow";
            this.emit("plg:vector:behavior-fixed", {
              resource: resource.name,
              newBehavior: "body-overflow"
            });
          } else {
            console.warn(`\u26A0\uFE0F  VectorPlugin: Resource '${resource.name}' has large vector fields (${totalVectorSize} bytes estimated)`);
            console.warn(`   Current behavior: '${resource.behavior || "default"}'`);
            console.warn(`   Recommendation: Add behavior: 'body-overflow' or 'body-only' to resource configuration`);
            console.warn(`   Large vectors will exceed S3 metadata limit (2047 bytes) and cause errors.`);
          }
        }
      }
      this.setupEmbeddingPartitions(resource, vectorFields);
    }
  }
  /**
   * Setup automatic partitions for optional embedding fields
   *
   * Creates a partition that separates records with embeddings from those without.
   * This enables O(1) filtering instead of O(n) full scans when searching/clustering.
   *
   * @param {Resource} resource - Resource instance
   * @param {Array} vectorFields - Detected vector fields with metadata
   */
  setupEmbeddingPartitions(resource, vectorFields) {
    if (!resource.config) return;
    for (const vectorField of vectorFields) {
      const isOptional = this.isFieldOptional(resource.schema.attributes, vectorField.name);
      if (!isOptional) continue;
      const partitionName = `byHas${this.capitalize(vectorField.name.replace(/\./g, "_"))}`;
      const trackingFieldName = `_has${this.capitalize(vectorField.name.replace(/\./g, "_"))}`;
      if (resource.config.partitions && resource.config.partitions[partitionName]) {
        this.emit("plg:vector:partition-exists", {
          resource: resource.name,
          vectorField: vectorField.name,
          partition: partitionName,
          timestamp: Date.now()
        });
        continue;
      }
      if (!resource.config.partitions) {
        resource.config.partitions = {};
      }
      resource.config.partitions[partitionName] = {
        fields: {
          [trackingFieldName]: "boolean"
        }
      };
      if (!resource.schema.attributes[trackingFieldName]) {
        resource.addPluginAttribute(trackingFieldName, {
          type: "boolean",
          optional: true,
          default: false
        }, "VectorPlugin");
      }
      this.emit("plg:vector:partition-created", {
        resource: resource.name,
        vectorField: vectorField.name,
        partition: partitionName,
        trackingField: trackingFieldName,
        timestamp: Date.now()
      });
      console.log(`\u2705 VectorPlugin: Created partition '${partitionName}' for optional embedding field '${vectorField.name}' in resource '${resource.name}'`);
      this.installEmbeddingHooks(resource, vectorField.name, trackingFieldName);
    }
  }
  /**
   * Check if a field is optional in the schema
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} fieldPath - Field path (supports dot notation)
   * @returns {boolean} True if field is optional
   */
  isFieldOptional(attributes, fieldPath) {
    const parts = fieldPath.split(".");
    let current = attributes;
    for (let i = 0; i < parts.length; i++) {
      const part = parts[i];
      const attr = current[part];
      if (!attr) return true;
      if (typeof attr === "string") {
        const flags = attr.split("|");
        if (flags.includes("required")) return false;
        if (flags.includes("optional") || flags.some((f) => f.startsWith("optional:"))) return true;
        return !flags.includes("required");
      }
      if (typeof attr === "object") {
        if (i === parts.length - 1) {
          if (attr.optional === true) return true;
          if (attr.optional === false) return false;
          return attr.optional !== false;
        }
        if (attr.type === "object" && attr.props) {
          current = attr.props;
        } else {
          return true;
        }
      }
    }
    return true;
  }
  /**
   * Capitalize first letter of string
   *
   * @param {string} str - Input string
   * @returns {string} Capitalized string
   */
  capitalize(str) {
    return str.charAt(0).toUpperCase() + str.slice(1);
  }
  /**
   * Install hooks to maintain embedding partition tracking field
   *
   * @param {Resource} resource - Resource instance
   * @param {string} vectorField - Vector field name
   * @param {string} trackingField - Tracking field name
   */
  installEmbeddingHooks(resource, vectorField, trackingField) {
    resource.registerHook("beforeInsert", async (data) => {
      const hasVector = this.hasVectorValue(data, vectorField);
      this.setNestedValue(data, trackingField, hasVector);
      return data;
    });
    resource.registerHook("beforeUpdate", async (id, updates) => {
      if (vectorField in updates || this.hasNestedKey(updates, vectorField)) {
        const hasVector = this.hasVectorValue(updates, vectorField);
        this.setNestedValue(updates, trackingField, hasVector);
      }
      return updates;
    });
    this.emit("plg:vector:hooks-installed", {
      resource: resource.name,
      vectorField,
      trackingField,
      hooks: ["beforeInsert", "beforeUpdate"],
      timestamp: Date.now()
    });
  }
  /**
   * Check if data has a valid vector value for the given field
   *
   * @param {Object} data - Data object
   * @param {string} fieldPath - Field path (supports dot notation)
   * @returns {boolean} True if vector exists and is valid
   */
  hasVectorValue(data, fieldPath) {
    const value = this.getNestedValue(data, fieldPath);
    return value != null && Array.isArray(value) && value.length > 0;
  }
  /**
   * Check if object has a nested key
   *
   * @param {Object} obj - Object to check
   * @param {string} path - Dot-notation path
   * @returns {boolean} True if key exists
   */
  hasNestedKey(obj, path) {
    const parts = path.split(".");
    let current = obj;
    for (const part of parts) {
      if (current == null || typeof current !== "object") return false;
      if (!(part in current)) return false;
      current = current[part];
    }
    return true;
  }
  /**
   * Get nested value from object using dot notation
   *
   * @param {Object} obj - Object to traverse
   * @param {string} path - Dot-notation path
   * @returns {*} Value at path or undefined
   */
  getNestedValue(obj, path) {
    const parts = path.split(".");
    let current = obj;
    for (const part of parts) {
      if (current == null || typeof current !== "object") return void 0;
      current = current[part];
    }
    return current;
  }
  /**
   * Set nested value in object using dot notation
   *
   * @param {Object} obj - Object to modify
   * @param {string} path - Dot-notation path
   * @param {*} value - Value to set
   */
  setNestedValue(obj, path, value) {
    const parts = path.split(".");
    let current = obj;
    for (let i = 0; i < parts.length - 1; i++) {
      const part = parts[i];
      if (!(part in current) || typeof current[part] !== "object") {
        current[part] = {};
      }
      current = current[part];
    }
    current[parts[parts.length - 1]] = value;
  }
  /**
   * Get auto-created embedding partition for a vector field
   *
   * Returns partition configuration if an auto-partition exists for the given vector field.
   * Auto-partitions enable O(1) filtering to only records with embeddings.
   *
   * @param {Resource} resource - Resource instance
   * @param {string} vectorField - Vector field name
   * @returns {Object|null} Partition config or null
   */
  getAutoEmbeddingPartition(resource, vectorField) {
    if (!resource.config) return null;
    const partitionName = `byHas${this.capitalize(vectorField.replace(/\./g, "_"))}`;
    const trackingFieldName = `_has${this.capitalize(vectorField.replace(/\./g, "_"))}`;
    if (resource.config.partitions && resource.config.partitions[partitionName]) {
      return {
        partitionName,
        partitionValues: { [trackingFieldName]: true }
      };
    }
    return null;
  }
  /**
   * Auto-detect vector field from resource schema
   *
   * Looks for fields with type 'embedding:XXX' pattern.
   * Caches result per resource for performance.
   *
   * @param {Resource} resource - Resource instance
   * @returns {string|null} Detected vector field name or null
   */
  detectVectorField(resource) {
    if (this._vectorFieldCache.has(resource.name)) {
      return this._vectorFieldCache.get(resource.name);
    }
    const vectorField = this._findEmbeddingField(resource.schema.attributes);
    this._vectorFieldCache.set(resource.name, vectorField);
    if (vectorField && this.config.emitEvents) {
      this.emit("plg:vector:field-detected", {
        resource: resource.name,
        vectorField,
        timestamp: Date.now()
      });
    }
    return vectorField;
  }
  /**
   * Recursively find embedding:XXX field in attributes
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} path - Current path (for nested objects)
   * @returns {string|null} Field path or null
   */
  _findEmbeddingField(attributes, path = "") {
    for (const [key, attr] of Object.entries(attributes)) {
      const fullPath = path ? `${path}.${key}` : key;
      if (typeof attr === "string" && attr.startsWith("embedding:")) {
        return fullPath;
      }
      if (attr.type === "array" && attr.items === "number" && attr.length) {
        return fullPath;
      }
      if (attr.type === "object" && attr.props) {
        const nested = this._findEmbeddingField(attr.props, fullPath);
        if (nested) return nested;
      }
    }
    return null;
  }
  /**
   * Emit event with throttling support
   *
   * @param {string} eventName - Event name
   * @param {Object} data - Event data
   * @param {string} throttleKey - Unique key for throttling (optional)
   */
  _emitEvent(eventName, data, throttleKey = null) {
    if (!this.config.emitEvents) return;
    if (throttleKey) {
      const now = Date.now();
      const lastEmit = this._throttleState.get(throttleKey);
      if (lastEmit && now - lastEmit < this.config.eventThrottle) {
        return;
      }
      this._throttleState.set(throttleKey, now);
    }
    this.emit(eventName, data);
  }
  /**
   * Find vector fields in resource attributes
   *
   * @param {Object} attributes - Resource attributes
   * @param {string} path - Current path (for nested objects)
   * @returns {Array} Array of vector field info
   */
  findVectorFields(attributes, path = "") {
    const vectors = [];
    for (const [key, attr] of Object.entries(attributes)) {
      const fullPath = path ? `${path}.${key}` : key;
      if (attr.type === "array" && attr.items === "number" && attr.length) {
        vectors.push({
          name: fullPath,
          length: attr.length,
          estimatedBytes: this.estimateVectorBytes(attr.length)
        });
      }
      if (attr.type === "object" && attr.props) {
        vectors.push(...this.findVectorFields(attr.props, fullPath));
      }
    }
    return vectors;
  }
  /**
   * Estimate bytes required to store a vector in JSON format
   *
   * Conservative estimate: ~7 bytes per number + array overhead
   *
   * @param {number} dimensions - Number of dimensions
   * @returns {number} Estimated bytes
   */
  estimateVectorBytes(dimensions) {
    return dimensions * 7 + 50;
  }
  /**
   * Install vector methods on all resources
   */
  installResourceMethods() {
    for (const resource of Object.values(this.database.resources)) {
      const searchMethod = this.createVectorSearchMethod(resource);
      const clusterMethod = this.createClusteringMethod(resource);
      const distanceMethod = this.createDistanceMethod();
      resource.vectorSearch = searchMethod;
      resource.cluster = clusterMethod;
      resource.vectorDistance = distanceMethod;
      resource.similarTo = searchMethod;
      resource.findSimilar = searchMethod;
      resource.distance = distanceMethod;
    }
  }
  /**
   * Create vector search method for a resource
   *
   * Performs K-nearest neighbors search to find similar vectors.
   *
   * @param {Resource} resource - Resource instance
   * @returns {Function} Vector search method
   */
  createVectorSearchMethod(resource) {
    return async (queryVector, options = {}) => {
      const startTime = Date.now();
      let vectorField = options.vectorField;
      if (!vectorField && this.config.autoDetectVectorField) {
        vectorField = this.detectVectorField(resource);
        if (!vectorField) {
          vectorField = "vector";
        }
      } else if (!vectorField) {
        vectorField = "vector";
      }
      let {
        limit = 10,
        distanceMetric = this.config.distanceMetric,
        threshold = null,
        partition = null,
        partitionValues = null
      } = options;
      const distanceFn = this.distanceFunctions[distanceMetric];
      if (!distanceFn) {
        const error = new VectorError(`Invalid distance metric: ${distanceMetric}`, {
          operation: "vectorSearch",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: distanceMetric
        });
        this._emitEvent("vector:search-error", {
          resource: resource.name,
          error: error.message,
          timestamp: Date.now()
        });
        throw error;
      }
      if (!partition) {
        const autoPartition = this.getAutoEmbeddingPartition(resource, vectorField);
        if (autoPartition) {
          partition = autoPartition.partitionName;
          partitionValues = autoPartition.partitionValues;
          this._emitEvent("vector:auto-partition-used", {
            resource: resource.name,
            vectorField,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
        }
      }
      this._emitEvent("vector:search-start", {
        resource: resource.name,
        vectorField,
        limit,
        distanceMetric,
        partition,
        partitionValues,
        threshold,
        queryDimensions: queryVector.length,
        timestamp: startTime
      });
      try {
        let allRecords;
        if (partition && partitionValues) {
          this._emitEvent("vector:partition-filter", {
            resource: resource.name,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
          allRecords = await resource.list({ partition, partitionValues });
        } else {
          allRecords = resource.getAll ? await resource.getAll() : await resource.list();
        }
        const totalRecords = allRecords.length;
        let processedRecords = 0;
        let dimensionMismatches = 0;
        if (!partition && totalRecords > 1e3) {
          const warning = {
            resource: resource.name,
            operation: "vectorSearch",
            totalRecords,
            vectorField,
            recommendation: "Use partitions to filter data before vector search for better performance"
          };
          this._emitEvent("vector:performance-warning", warning);
          console.warn(`\u26A0\uFE0F  VectorPlugin: Performing vectorSearch on ${totalRecords} records without partition filter`);
          console.warn(`   Resource: '${resource.name}'`);
          console.warn(`   Recommendation: Use partition parameter to reduce search space`);
          console.warn(`   Example: resource.vectorSearch(vector, { partition: 'byCategory', partitionValues: { category: 'books' } })`);
        }
        const results = allRecords.filter((record) => record[vectorField] && Array.isArray(record[vectorField])).map((record, index) => {
          try {
            const distance = distanceFn(queryVector, record[vectorField]);
            processedRecords++;
            if (this.config.verboseEvents && processedRecords % 100 === 0) {
              this._emitEvent("vector:search-progress", {
                resource: resource.name,
                processed: processedRecords,
                total: totalRecords,
                progress: processedRecords / totalRecords * 100,
                timestamp: Date.now()
              }, `search-${resource.name}`);
            }
            return { record, distance };
          } catch (err) {
            dimensionMismatches++;
            if (this.config.verboseEvents) {
              this._emitEvent("vector:dimension-mismatch", {
                resource: resource.name,
                recordIndex: index,
                expected: queryVector.length,
                got: record[vectorField]?.length,
                timestamp: Date.now()
              });
            }
            return null;
          }
        }).filter((result) => result !== null).filter((result) => threshold === null || result.distance <= threshold).sort((a, b) => a.distance - b.distance).slice(0, limit);
        const duration = Date.now() - startTime;
        const throughput = totalRecords / (duration / 1e3);
        this._emitEvent("vector:search-complete", {
          resource: resource.name,
          vectorField,
          resultsCount: results.length,
          totalRecords,
          processedRecords,
          dimensionMismatches,
          duration,
          throughput: throughput.toFixed(2),
          timestamp: Date.now()
        });
        if (this.config.verboseEvents) {
          this._emitEvent("vector:performance", {
            operation: "search",
            resource: resource.name,
            duration,
            throughput: throughput.toFixed(2),
            recordsPerSecond: (processedRecords / (duration / 1e3)).toFixed(2),
            timestamp: Date.now()
          });
        }
        return results;
      } catch (error) {
        this._emitEvent("vector:search-error", {
          resource: resource.name,
          error: error.message,
          stack: error.stack,
          timestamp: Date.now()
        });
        throw error;
      }
    };
  }
  /**
   * Create clustering method for a resource
   *
   * Performs k-means clustering on resource vectors.
   *
   * @param {Resource} resource - Resource instance
   * @returns {Function} Clustering method
   */
  createClusteringMethod(resource) {
    return async (options = {}) => {
      const startTime = Date.now();
      let vectorField = options.vectorField;
      if (!vectorField && this.config.autoDetectVectorField) {
        vectorField = this.detectVectorField(resource);
        if (!vectorField) {
          vectorField = "vector";
        }
      } else if (!vectorField) {
        vectorField = "vector";
      }
      let {
        k = 5,
        distanceMetric = this.config.distanceMetric,
        partition = null,
        partitionValues = null,
        ...kmeansOptions
      } = options;
      const distanceFn = this.distanceFunctions[distanceMetric];
      if (!distanceFn) {
        const error = new VectorError(`Invalid distance metric: ${distanceMetric}`, {
          operation: "cluster",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: distanceMetric
        });
        this._emitEvent("vector:cluster-error", {
          resource: resource.name,
          error: error.message,
          timestamp: Date.now()
        });
        throw error;
      }
      if (!partition) {
        const autoPartition = this.getAutoEmbeddingPartition(resource, vectorField);
        if (autoPartition) {
          partition = autoPartition.partitionName;
          partitionValues = autoPartition.partitionValues;
          this._emitEvent("vector:auto-partition-used", {
            resource: resource.name,
            vectorField,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
        }
      }
      this._emitEvent("vector:cluster-start", {
        resource: resource.name,
        vectorField,
        k,
        distanceMetric,
        partition,
        partitionValues,
        maxIterations: kmeansOptions.maxIterations || 100,
        timestamp: startTime
      });
      try {
        let allRecords;
        if (partition && partitionValues) {
          this._emitEvent("vector:partition-filter", {
            resource: resource.name,
            partition,
            partitionValues,
            timestamp: Date.now()
          });
          allRecords = await resource.list({ partition, partitionValues });
        } else {
          allRecords = resource.getAll ? await resource.getAll() : await resource.list();
        }
        const recordsWithVectors = allRecords.filter(
          (record) => record[vectorField] && Array.isArray(record[vectorField])
        );
        if (!partition && allRecords.length > 1e3) {
          const warning = {
            resource: resource.name,
            operation: "cluster",
            totalRecords: allRecords.length,
            recordsWithVectors: recordsWithVectors.length,
            vectorField,
            recommendation: "Use partitions to filter data before clustering for better performance"
          };
          this._emitEvent("vector:performance-warning", warning);
          console.warn(`\u26A0\uFE0F  VectorPlugin: Performing clustering on ${allRecords.length} records without partition filter`);
          console.warn(`   Resource: '${resource.name}'`);
          console.warn(`   Records with vectors: ${recordsWithVectors.length}`);
          console.warn(`   Recommendation: Use partition parameter to reduce clustering space`);
          console.warn(`   Example: resource.cluster({ k: 5, partition: 'byCategory', partitionValues: { category: 'books' } })`);
        }
        if (recordsWithVectors.length === 0) {
          const error = new VectorError("No vectors found in resource", {
            operation: "cluster",
            resourceName: resource.name,
            vectorField
          });
          this._emitEvent("vector:empty-dataset", {
            resource: resource.name,
            vectorField,
            totalRecords: allRecords.length,
            timestamp: Date.now()
          });
          throw error;
        }
        const vectors = recordsWithVectors.map((record) => record[vectorField]);
        const result = kmeans(vectors, k, {
          ...kmeansOptions,
          distanceFn,
          onIteration: this.config.verboseEvents ? (iteration, inertia, converged) => {
            this._emitEvent("vector:cluster-iteration", {
              resource: resource.name,
              k,
              iteration,
              inertia,
              converged,
              timestamp: Date.now()
            }, `cluster-${resource.name}`);
          } : void 0
        });
        if (result.converged) {
          this._emitEvent("vector:cluster-converged", {
            resource: resource.name,
            k,
            iterations: result.iterations,
            inertia: result.inertia,
            timestamp: Date.now()
          });
        }
        const clusters = Array(k).fill(null).map(() => []);
        recordsWithVectors.forEach((record, i) => {
          const clusterIndex = result.assignments[i];
          clusters[clusterIndex].push(record);
        });
        const duration = Date.now() - startTime;
        const clusterSizes = clusters.map((c) => c.length);
        this._emitEvent("vector:cluster-complete", {
          resource: resource.name,
          vectorField,
          k,
          vectorCount: vectors.length,
          iterations: result.iterations,
          converged: result.converged,
          inertia: result.inertia,
          clusterSizes,
          duration,
          timestamp: Date.now()
        });
        if (this.config.verboseEvents) {
          this._emitEvent("vector:performance", {
            operation: "clustering",
            resource: resource.name,
            k,
            duration,
            iterationsPerSecond: (result.iterations / (duration / 1e3)).toFixed(2),
            vectorsPerSecond: (vectors.length / (duration / 1e3)).toFixed(2),
            timestamp: Date.now()
          });
        }
        return {
          clusters,
          centroids: result.centroids,
          inertia: result.inertia,
          iterations: result.iterations,
          converged: result.converged
        };
      } catch (error) {
        this._emitEvent("vector:cluster-error", {
          resource: resource.name,
          error: error.message,
          stack: error.stack,
          timestamp: Date.now()
        });
        throw error;
      }
    };
  }
  /**
   * Create distance calculation method
   *
   * @returns {Function} Distance method
   */
  createDistanceMethod() {
    return (vector1, vector2, metric = this.config.distanceMetric) => {
      const distanceFn = this.distanceFunctions[metric];
      if (!distanceFn) {
        throw new VectorError(`Invalid distance metric: ${metric}`, {
          operation: "vectorDistance",
          availableMetrics: Object.keys(this.distanceFunctions),
          providedMetric: metric
        });
      }
      return distanceFn(vector1, vector2);
    };
  }
  /**
   * Static utility: Normalize vector
   *
   * @param {number[]} vector - Input vector
   * @returns {number[]} Normalized vector
   */
  static normalize(vector) {
    return normalize(vector);
  }
  /**
   * Static utility: Calculate dot product
   *
   * @param {number[]} vector1 - First vector
   * @param {number[]} vector2 - Second vector
   * @returns {number} Dot product
   */
  static dotProduct(vector1, vector2) {
    return dotProduct(vector1, vector2);
  }
  /**
   * Static utility: Find optimal K for clustering
   *
   * Analyzes clustering quality across a range of K values using
   * multiple evaluation metrics.
   *
   * @param {number[][]} vectors - Vectors to analyze
   * @param {Object} options - Configuration options
   * @returns {Promise<Object>} Analysis results with recommendations
   */
  static async findOptimalK(vectors, options) {
    return findOptimalK(vectors, options);
  }
}

class MemoryStorage {
  constructor(config = {}) {
    this.objects = /* @__PURE__ */ new Map();
    this.bucket = config.bucket || "s3db";
    this.enforceLimits = config.enforceLimits || false;
    this.metadataLimit = config.metadataLimit || 2048;
    this.maxObjectSize = config.maxObjectSize || 5 * 1024 * 1024 * 1024;
    this.persistPath = config.persistPath;
    this.autoPersist = config.autoPersist || false;
    this.verbose = config.verbose || false;
  }
  /**
   * Generate ETag (MD5 hash) for object body
   */
  _generateETag(body) {
    const buffer = Buffer.isBuffer(body) ? body : Buffer.from(body || "");
    return createHash("md5").update(buffer).digest("hex");
  }
  /**
   * Calculate metadata size in bytes
   */
  _calculateMetadataSize(metadata) {
    if (!metadata) return 0;
    let size = 0;
    for (const [key, value] of Object.entries(metadata)) {
      size += Buffer.byteLength(key, "utf8");
      size += Buffer.byteLength(String(value), "utf8");
    }
    return size;
  }
  /**
   * Validate limits if enforceLimits is enabled
   */
  _validateLimits(body, metadata) {
    if (!this.enforceLimits) return;
    const metadataSize = this._calculateMetadataSize(metadata);
    if (metadataSize > this.metadataLimit) {
      throw new Error(
        `Metadata size (${metadataSize} bytes) exceeds limit of ${this.metadataLimit} bytes`
      );
    }
    const bodySize = Buffer.isBuffer(body) ? body.length : Buffer.byteLength(body || "", "utf8");
    if (bodySize > this.maxObjectSize) {
      throw new Error(
        `Object size (${bodySize} bytes) exceeds limit of ${this.maxObjectSize} bytes`
      );
    }
  }
  /**
   * Store an object
   */
  async put(key, { body, metadata, contentType, contentEncoding, contentLength, ifMatch }) {
    this._validateLimits(body, metadata);
    if (ifMatch !== void 0) {
      const existing = this.objects.get(key);
      if (existing && existing.etag !== ifMatch) {
        throw new Error(`Precondition failed: ETag mismatch for key "${key}"`);
      }
    }
    const buffer = Buffer.isBuffer(body) ? body : Buffer.from(body || "");
    const etag = this._generateETag(buffer);
    const lastModified = (/* @__PURE__ */ new Date()).toISOString();
    const size = buffer.length;
    const objectData = {
      body: buffer,
      metadata: metadata || {},
      contentType: contentType || "application/octet-stream",
      etag,
      lastModified,
      size,
      contentEncoding,
      contentLength: contentLength || size
    };
    this.objects.set(key, objectData);
    if (this.verbose) {
      console.log(`[MemoryStorage] PUT ${key} (${size} bytes, etag: ${etag})`);
    }
    if (this.autoPersist && this.persistPath) {
      await this.saveToDisk();
    }
    return {
      ETag: etag,
      VersionId: null,
      // Memory storage doesn't support versioning
      ServerSideEncryption: null,
      Location: `/${this.bucket}/${key}`
    };
  }
  /**
   * Retrieve an object
   */
  async get(key) {
    const obj = this.objects.get(key);
    if (!obj) {
      const error = new Error(`Object not found: ${key}`);
      error.name = "NoSuchKey";
      error.$metadata = {
        httpStatusCode: 404,
        requestId: "memory-" + Date.now(),
        attempts: 1,
        totalRetryDelay: 0
      };
      throw error;
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] GET ${key} (${obj.size} bytes)`);
    }
    const bodyStream = Readable.from(obj.body);
    return {
      Body: bodyStream,
      Metadata: { ...obj.metadata },
      ContentType: obj.contentType,
      ContentLength: obj.size,
      ETag: obj.etag,
      LastModified: new Date(obj.lastModified),
      ContentEncoding: obj.contentEncoding
    };
  }
  /**
   * Get object metadata only (like S3 HeadObject)
   */
  async head(key) {
    const obj = this.objects.get(key);
    if (!obj) {
      const error = new Error(`Object not found: ${key}`);
      error.name = "NoSuchKey";
      error.$metadata = {
        httpStatusCode: 404,
        requestId: "memory-" + Date.now(),
        attempts: 1,
        totalRetryDelay: 0
      };
      throw error;
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] HEAD ${key}`);
    }
    return {
      Metadata: { ...obj.metadata },
      ContentType: obj.contentType,
      ContentLength: obj.size,
      ETag: obj.etag,
      LastModified: new Date(obj.lastModified),
      ContentEncoding: obj.contentEncoding
    };
  }
  /**
   * Copy an object
   */
  async copy(from, to, { metadata, metadataDirective, contentType }) {
    const source = this.objects.get(from);
    if (!source) {
      const error = new Error(`Source object not found: ${from}`);
      error.name = "NoSuchKey";
      throw error;
    }
    let finalMetadata = { ...source.metadata };
    if (metadataDirective === "REPLACE" && metadata) {
      finalMetadata = metadata;
    } else if (metadata) {
      finalMetadata = { ...finalMetadata, ...metadata };
    }
    const result = await this.put(to, {
      body: source.body,
      metadata: finalMetadata,
      contentType: contentType || source.contentType,
      contentEncoding: source.contentEncoding
    });
    if (this.verbose) {
      console.log(`[MemoryStorage] COPY ${from} \u2192 ${to}`);
    }
    return result;
  }
  /**
   * Check if object exists
   */
  exists(key) {
    return this.objects.has(key);
  }
  /**
   * Delete an object
   */
  async delete(key) {
    const existed = this.objects.has(key);
    this.objects.delete(key);
    if (this.verbose) {
      console.log(`[MemoryStorage] DELETE ${key} (existed: ${existed})`);
    }
    if (this.autoPersist && this.persistPath) {
      await this.saveToDisk();
    }
    return {
      DeleteMarker: false,
      VersionId: null
    };
  }
  /**
   * Delete multiple objects (batch)
   */
  async deleteMultiple(keys) {
    const deleted = [];
    const errors = [];
    for (const key of keys) {
      try {
        await this.delete(key);
        deleted.push({ Key: key });
      } catch (error) {
        errors.push({
          Key: key,
          Code: error.name || "InternalError",
          Message: error.message
        });
      }
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] DELETE BATCH (${deleted.length} deleted, ${errors.length} errors)`);
    }
    return { Deleted: deleted, Errors: errors };
  }
  /**
   * List objects with prefix/delimiter support
   */
  async list({ prefix = "", delimiter = null, maxKeys = 1e3, continuationToken = null }) {
    const allKeys = Array.from(this.objects.keys());
    let filteredKeys = prefix ? allKeys.filter((key) => key.startsWith(prefix)) : allKeys;
    filteredKeys.sort();
    let startIndex = 0;
    if (continuationToken) {
      startIndex = parseInt(continuationToken) || 0;
    }
    const paginatedKeys = filteredKeys.slice(startIndex, startIndex + maxKeys);
    const isTruncated = startIndex + maxKeys < filteredKeys.length;
    const nextContinuationToken = isTruncated ? String(startIndex + maxKeys) : null;
    const commonPrefixes = /* @__PURE__ */ new Set();
    const contents = [];
    for (const key of paginatedKeys) {
      if (delimiter && prefix) {
        const suffix = key.substring(prefix.length);
        const delimiterIndex = suffix.indexOf(delimiter);
        if (delimiterIndex !== -1) {
          const commonPrefix = prefix + suffix.substring(0, delimiterIndex + 1);
          commonPrefixes.add(commonPrefix);
          continue;
        }
      }
      const obj = this.objects.get(key);
      contents.push({
        Key: key,
        Size: obj.size,
        LastModified: new Date(obj.lastModified),
        ETag: obj.etag,
        StorageClass: "STANDARD"
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] LIST prefix="${prefix}" (${contents.length} objects, ${commonPrefixes.size} prefixes)`);
    }
    return {
      Contents: contents,
      CommonPrefixes: Array.from(commonPrefixes).map((prefix2) => ({ Prefix: prefix2 })),
      IsTruncated: isTruncated,
      NextContinuationToken: nextContinuationToken,
      KeyCount: contents.length + commonPrefixes.size,
      MaxKeys: maxKeys,
      Prefix: prefix,
      Delimiter: delimiter
    };
  }
  /**
   * Create a snapshot of current state
   */
  snapshot() {
    const snapshot = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      bucket: this.bucket,
      objectCount: this.objects.size,
      objects: {}
    };
    for (const [key, obj] of this.objects.entries()) {
      snapshot.objects[key] = {
        body: obj.body.toString("base64"),
        metadata: obj.metadata,
        contentType: obj.contentType,
        etag: obj.etag,
        lastModified: obj.lastModified,
        size: obj.size,
        contentEncoding: obj.contentEncoding,
        contentLength: obj.contentLength
      };
    }
    return snapshot;
  }
  /**
   * Restore from a snapshot
   */
  restore(snapshot) {
    if (!snapshot || !snapshot.objects) {
      throw new Error("Invalid snapshot format");
    }
    this.objects.clear();
    for (const [key, obj] of Object.entries(snapshot.objects)) {
      this.objects.set(key, {
        body: Buffer.from(obj.body, "base64"),
        metadata: obj.metadata,
        contentType: obj.contentType,
        etag: obj.etag,
        lastModified: obj.lastModified,
        size: obj.size,
        contentEncoding: obj.contentEncoding,
        contentLength: obj.contentLength
      });
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] Restored snapshot with ${this.objects.size} objects`);
    }
  }
  /**
   * Save current state to disk
   */
  async saveToDisk(customPath) {
    const path = customPath || this.persistPath;
    if (!path) {
      throw new Error("No persist path configured");
    }
    const snapshot = this.snapshot();
    const json = JSON.stringify(snapshot, null, 2);
    const [ok, err] = await tryFn(() => writeFile(path, json, "utf-8"));
    if (!ok) {
      throw new Error(`Failed to save to disk: ${err.message}`);
    }
    if (this.verbose) {
      console.log(`[MemoryStorage] Saved ${this.objects.size} objects to ${path}`);
    }
    return path;
  }
  /**
   * Load state from disk
   */
  async loadFromDisk(customPath) {
    const path = customPath || this.persistPath;
    if (!path) {
      throw new Error("No persist path configured");
    }
    const [ok, err, json] = await tryFn(() => readFile$1(path, "utf-8"));
    if (!ok) {
      throw new Error(`Failed to load from disk: ${err.message}`);
    }
    const snapshot = JSON.parse(json);
    this.restore(snapshot);
    if (this.verbose) {
      console.log(`[MemoryStorage] Loaded ${this.objects.size} objects from ${path}`);
    }
    return snapshot;
  }
  /**
   * Get storage statistics
   */
  getStats() {
    let totalSize = 0;
    const keys = [];
    for (const [key, obj] of this.objects.entries()) {
      totalSize += obj.size;
      keys.push(key);
    }
    return {
      objectCount: this.objects.size,
      totalSize,
      totalSizeFormatted: this._formatBytes(totalSize),
      keys: keys.sort(),
      bucket: this.bucket
    };
  }
  /**
   * Format bytes for human reading
   */
  _formatBytes(bytes) {
    if (bytes === 0) return "0 Bytes";
    const k = 1024;
    const sizes = ["Bytes", "KB", "MB", "GB"];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return Math.round(bytes / Math.pow(k, i) * 100) / 100 + " " + sizes[i];
  }
  /**
   * Clear all objects
   */
  clear() {
    this.objects.clear();
    if (this.verbose) {
      console.log(`[MemoryStorage] Cleared all objects`);
    }
  }
}

class MemoryClient extends EventEmitter {
  constructor(config = {}) {
    super();
    this.id = config.id || idGenerator(77);
    this.verbose = config.verbose || false;
    this.parallelism = config.parallelism || 10;
    this.bucket = config.bucket || "s3db";
    this.keyPrefix = config.keyPrefix || "";
    this.region = config.region || "us-east-1";
    this.storage = new MemoryStorage({
      bucket: this.bucket,
      enforceLimits: config.enforceLimits || false,
      metadataLimit: config.metadataLimit || 2048,
      maxObjectSize: config.maxObjectSize || 5 * 1024 * 1024 * 1024,
      persistPath: config.persistPath,
      autoPersist: config.autoPersist || false,
      verbose: this.verbose
    });
    this.config = {
      bucket: this.bucket,
      keyPrefix: this.keyPrefix,
      region: this.region,
      endpoint: "memory://localhost",
      forcePathStyle: true
    };
    if (this.verbose) {
      console.log(`[MemoryClient] Initialized (id: ${this.id}, bucket: ${this.bucket})`);
    }
  }
  /**
   * Simulate sendCommand from AWS SDK
   * Used by Database/Resource to send AWS SDK commands
   */
  async sendCommand(command) {
    const commandName = command.constructor.name;
    const input = command.input || {};
    this.emit("cl:request", commandName, input);
    this.emit("command.request", commandName, input);
    let response;
    try {
      switch (commandName) {
        case "PutObjectCommand":
          response = await this._handlePutObject(input);
          break;
        case "GetObjectCommand":
          response = await this._handleGetObject(input);
          break;
        case "HeadObjectCommand":
          response = await this._handleHeadObject(input);
          break;
        case "CopyObjectCommand":
          response = await this._handleCopyObject(input);
          break;
        case "DeleteObjectCommand":
          response = await this._handleDeleteObject(input);
          break;
        case "DeleteObjectsCommand":
          response = await this._handleDeleteObjects(input);
          break;
        case "ListObjectsV2Command":
          response = await this._handleListObjects(input);
          break;
        default:
          throw new Error(`Unsupported command: ${commandName}`);
      }
      this.emit("cl:response", commandName, response, input);
      this.emit("command.response", commandName, response, input);
      return response;
    } catch (error) {
      const mappedError = mapAwsError(error, {
        bucket: this.bucket,
        key: input.Key,
        commandName,
        commandInput: input
      });
      throw mappedError;
    }
  }
  /**
   * PutObjectCommand handler
   */
  async _handlePutObject(input) {
    const key = input.Key;
    const metadata = input.Metadata || {};
    const contentType = input.ContentType;
    const body = input.Body;
    const contentEncoding = input.ContentEncoding;
    const contentLength = input.ContentLength;
    const ifMatch = input.IfMatch;
    return await this.storage.put(key, {
      body,
      metadata,
      contentType,
      contentEncoding,
      contentLength,
      ifMatch
    });
  }
  /**
   * GetObjectCommand handler
   */
  async _handleGetObject(input) {
    const key = input.Key;
    return await this.storage.get(key);
  }
  /**
   * HeadObjectCommand handler
   */
  async _handleHeadObject(input) {
    const key = input.Key;
    return await this.storage.head(key);
  }
  /**
   * CopyObjectCommand handler
   */
  async _handleCopyObject(input) {
    const copySource = input.CopySource;
    const parts = copySource.split("/");
    const sourceKey = parts.slice(1).join("/");
    const destinationKey = input.Key;
    const metadata = input.Metadata;
    const metadataDirective = input.MetadataDirective;
    const contentType = input.ContentType;
    return await this.storage.copy(sourceKey, destinationKey, {
      metadata,
      metadataDirective,
      contentType
    });
  }
  /**
   * DeleteObjectCommand handler
   */
  async _handleDeleteObject(input) {
    const key = input.Key;
    return await this.storage.delete(key);
  }
  /**
   * DeleteObjectsCommand handler
   */
  async _handleDeleteObjects(input) {
    const objects = input.Delete?.Objects || [];
    const keys = objects.map((obj) => obj.Key);
    return await this.storage.deleteMultiple(keys);
  }
  /**
   * ListObjectsV2Command handler
   */
  async _handleListObjects(input) {
    const fullPrefix = this.keyPrefix && input.Prefix ? path$1.join(this.keyPrefix, input.Prefix) : this.keyPrefix || input.Prefix || "";
    return await this.storage.list({
      prefix: fullPrefix,
      delimiter: input.Delimiter,
      maxKeys: input.MaxKeys,
      continuationToken: input.ContinuationToken
    });
  }
  /**
   * Put an object (Client interface method)
   */
  async putObject({ key, metadata, contentType, body, contentEncoding, contentLength, ifMatch }) {
    const fullKey = this.keyPrefix ? path$1.join(this.keyPrefix, key) : key;
    const stringMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        stringMetadata[validKey] = encoded;
      }
    }
    const response = await this.storage.put(fullKey, {
      body,
      metadata: stringMetadata,
      contentType,
      contentEncoding,
      contentLength,
      ifMatch
    });
    this.emit("cl:PutObject", null, { key, metadata, contentType, body, contentEncoding, contentLength });
    return response;
  }
  /**
   * Get an object (Client interface method)
   */
  async getObject(key) {
    const fullKey = this.keyPrefix ? path$1.join(this.keyPrefix, key) : key;
    const response = await this.storage.get(fullKey);
    const decodedMetadata = {};
    if (response.Metadata) {
      for (const [k, v] of Object.entries(response.Metadata)) {
        decodedMetadata[k] = metadataDecode(v);
      }
    }
    this.emit("cl:GetObject", null, { key });
    return {
      ...response,
      Metadata: decodedMetadata
    };
  }
  /**
   * Head object (get metadata only)
   */
  async headObject(key) {
    const fullKey = this.keyPrefix ? path$1.join(this.keyPrefix, key) : key;
    const response = await this.storage.head(fullKey);
    const decodedMetadata = {};
    if (response.Metadata) {
      for (const [k, v] of Object.entries(response.Metadata)) {
        decodedMetadata[k] = metadataDecode(v);
      }
    }
    this.emit("cl:HeadObject", null, { key });
    return {
      ...response,
      Metadata: decodedMetadata
    };
  }
  /**
   * Copy an object
   */
  async copyObject({ from, to, metadata, metadataDirective, contentType }) {
    const fullFrom = this.keyPrefix ? path$1.join(this.keyPrefix, from) : from;
    const fullTo = this.keyPrefix ? path$1.join(this.keyPrefix, to) : to;
    const encodedMetadata = {};
    if (metadata) {
      for (const [k, v] of Object.entries(metadata)) {
        const validKey = String(k).replace(/[^a-zA-Z0-9\-_]/g, "_");
        const { encoded } = metadataEncode(v);
        encodedMetadata[validKey] = encoded;
      }
    }
    const response = await this.storage.copy(fullFrom, fullTo, {
      metadata: encodedMetadata,
      metadataDirective,
      contentType
    });
    this.emit("cl:CopyObject", null, { from, to, metadata, metadataDirective });
    return response;
  }
  /**
   * Check if object exists
   */
  async exists(key) {
    const fullKey = this.keyPrefix ? path$1.join(this.keyPrefix, key) : key;
    return this.storage.exists(fullKey);
  }
  /**
   * Delete an object
   */
  async deleteObject(key) {
    const fullKey = this.keyPrefix ? path$1.join(this.keyPrefix, key) : key;
    const response = await this.storage.delete(fullKey);
    this.emit("cl:DeleteObject", null, { key });
    return response;
  }
  /**
   * Delete multiple objects (batch)
   */
  async deleteObjects(keys) {
    const fullKeys = keys.map(
      (key) => this.keyPrefix ? path$1.join(this.keyPrefix, key) : key
    );
    const batches = chunk(fullKeys, this.parallelism);
    const allResults = { Deleted: [], Errors: [] };
    const { results } = await PromisePool.withConcurrency(this.parallelism).for(batches).process(async (batch) => {
      return await this.storage.deleteMultiple(batch);
    });
    for (const result of results) {
      allResults.Deleted.push(...result.Deleted);
      allResults.Errors.push(...result.Errors);
    }
    this.emit("deleteObjects", null, { keys, count: allResults.Deleted.length });
    return allResults;
  }
  /**
   * List objects with pagination support
   */
  async listObjects({ prefix = "", delimiter = null, maxKeys = 1e3, continuationToken = null }) {
    const fullPrefix = this.keyPrefix ? path$1.join(this.keyPrefix, prefix) : prefix;
    const response = await this.storage.list({
      prefix: fullPrefix,
      delimiter,
      maxKeys,
      continuationToken
    });
    this.emit("cl:ListObjects", null, { prefix, count: response.Contents.length });
    return response;
  }
  /**
   * Get a page of keys with offset/limit pagination
   */
  async getKeysPage(params = {}) {
    const { prefix = "", offset = 0, amount = 100 } = params;
    let keys = [];
    let truncated = true;
    let continuationToken;
    if (offset > 0) {
      const fullPrefix = this.keyPrefix ? path$1.join(this.keyPrefix, prefix) : prefix;
      const response = await this.storage.list({
        prefix: fullPrefix,
        maxKeys: offset + amount
      });
      keys = response.Contents.map((x) => x.Key).slice(offset, offset + amount);
    } else {
      while (truncated) {
        const options = {
          prefix,
          continuationToken,
          maxKeys: amount - keys.length
        };
        const res = await this.listObjects(options);
        if (res.Contents) {
          keys = keys.concat(res.Contents.map((x) => x.Key));
        }
        truncated = res.IsTruncated || false;
        continuationToken = res.NextContinuationToken;
        if (keys.length >= amount) {
          keys = keys.slice(0, amount);
          break;
        }
      }
    }
    if (this.keyPrefix) {
      keys = keys.map((x) => x.replace(this.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace("/", "") : x);
    }
    this.emit("cl:GetKeysPage", keys, params);
    return keys;
  }
  /**
   * Get all keys with a given prefix
   */
  async getAllKeys({ prefix = "" }) {
    const fullPrefix = this.keyPrefix ? path$1.join(this.keyPrefix, prefix) : prefix;
    const response = await this.storage.list({
      prefix: fullPrefix,
      maxKeys: 1e5
      // Large number to get all
    });
    let keys = response.Contents.map((x) => x.Key);
    if (this.keyPrefix) {
      keys = keys.map((x) => x.replace(this.keyPrefix, "")).map((x) => x.startsWith("/") ? x.replace("/", "") : x);
    }
    this.emit("cl:GetAllKeys", keys, { prefix });
    return keys;
  }
  /**
   * Count total objects under a prefix
   */
  async count({ prefix = "" } = {}) {
    const keys = await this.getAllKeys({ prefix });
    const count = keys.length;
    this.emit("cl:Count", count, { prefix });
    return count;
  }
  /**
   * Delete all objects under a prefix
   */
  async deleteAll({ prefix = "" } = {}) {
    const keys = await this.getAllKeys({ prefix });
    let totalDeleted = 0;
    if (keys.length > 0) {
      const result = await this.deleteObjects(keys);
      totalDeleted = result.Deleted.length;
      this.emit("deleteAll", {
        prefix,
        batch: totalDeleted,
        total: totalDeleted
      });
    }
    this.emit("deleteAllComplete", {
      prefix,
      totalDeleted
    });
    return totalDeleted;
  }
  /**
   * Get continuation token after skipping offset items
   */
  async getContinuationTokenAfterOffset({ prefix = "", offset = 1e3 } = {}) {
    if (offset === 0) return null;
    const keys = await this.getAllKeys({ prefix });
    if (offset >= keys.length) {
      this.emit("cl:GetContinuationTokenAfterOffset", null, { prefix, offset });
      return null;
    }
    const token = keys[offset];
    this.emit("cl:GetContinuationTokenAfterOffset", token, { prefix, offset });
    return token;
  }
  /**
   * Move an object from one key to another
   */
  async moveObject({ from, to }) {
    await this.copyObject({ from, to, metadataDirective: "COPY" });
    await this.deleteObject(from);
  }
  /**
   * Move all objects from one prefix to another
   */
  async moveAllObjects({ prefixFrom, prefixTo }) {
    const keys = await this.getAllKeys({ prefix: prefixFrom });
    const results = [];
    const errors = [];
    for (const key of keys) {
      try {
        const to = key.replace(prefixFrom, prefixTo);
        await this.moveObject({ from: key, to });
        results.push(to);
      } catch (error) {
        errors.push({
          message: error.message,
          raw: error,
          key
        });
      }
    }
    this.emit("moveAllObjects", { results, errors });
    if (errors.length > 0) {
      const error = new Error("Some objects could not be moved");
      error.context = {
        bucket: this.bucket,
        operation: "moveAllObjects",
        prefixFrom,
        prefixTo,
        totalKeys: keys.length,
        failedCount: errors.length,
        successCount: results.length,
        errors
      };
      throw error;
    }
    return results;
  }
  /**
   * Create a snapshot of current storage state
   */
  snapshot() {
    return this.storage.snapshot();
  }
  /**
   * Restore from a snapshot
   */
  restore(snapshot) {
    return this.storage.restore(snapshot);
  }
  /**
   * Save current state to disk (persistence)
   */
  async saveToDisk(path2) {
    return await this.storage.saveToDisk(path2);
  }
  /**
   * Load state from disk
   */
  async loadFromDisk(path2) {
    return await this.storage.loadFromDisk(path2);
  }
  /**
   * Export to BackupPlugin-compatible format (s3db.json + JSONL files)
   * Compatible with BackupPlugin for easy migration
   *
   * @param {string} outputDir - Output directory path
   * @param {Object} options - Export options
   * @param {Array<string>} options.resources - Resource names to export (default: all)
   * @param {boolean} options.compress - Use gzip compression (default: true)
   * @param {Object} options.database - Database instance for schema metadata
   * @returns {Promise<Object>} Export manifest with file paths and stats
   */
  async exportBackup(outputDir, options = {}) {
    const { mkdir, writeFile } = await import('fs/promises');
    const zlib = await import('zlib');
    const { promisify } = await import('util');
    const gzip = promisify(zlib.gzip);
    await mkdir(outputDir, { recursive: true });
    const compress = options.compress !== false;
    const database = options.database;
    const resourceFilter = options.resources;
    const allKeys = await this.getAllKeys({});
    const resourceMap = /* @__PURE__ */ new Map();
    for (const key of allKeys) {
      const match = key.match(/^resource=([^/]+)\//);
      if (match) {
        const resourceName = match[1];
        if (!resourceFilter || resourceFilter.includes(resourceName)) {
          if (!resourceMap.has(resourceName)) {
            resourceMap.set(resourceName, []);
          }
          resourceMap.get(resourceName).push(key);
        }
      }
    }
    const exportedFiles = {};
    const resourceStats = {};
    for (const [resourceName, keys] of resourceMap.entries()) {
      const records = [];
      const resource = database && database.resources && database.resources[resourceName];
      for (const key of keys) {
        const idMatch = key.match(/\/id=([^/]+)/);
        const recordId = idMatch ? idMatch[1] : null;
        let record;
        if (resource && recordId) {
          try {
            record = await resource.get(recordId);
          } catch (err) {
            console.warn(`Failed to get record ${recordId} from resource ${resourceName}, using fallback`);
            record = null;
          }
        }
        if (!record) {
          const obj = await this.getObject(key);
          record = { ...obj.Metadata };
          if (recordId && !record.id) {
            record.id = recordId;
          }
          if (obj.Body) {
            const chunks = [];
            for await (const chunk2 of obj.Body) {
              chunks.push(chunk2);
            }
            const bodyBuffer = Buffer.concat(chunks);
            const bodyStr = bodyBuffer.toString("utf-8");
            if (bodyStr.startsWith("{") || bodyStr.startsWith("[")) {
              try {
                const bodyData = JSON.parse(bodyStr);
                Object.assign(record, bodyData);
              } catch {
                record._body = bodyStr;
              }
            } else if (bodyStr) {
              record._body = bodyStr;
            }
          }
        }
        records.push(record);
      }
      const jsonl = records.map((r) => JSON.stringify(r)).join("\n");
      const filename = compress ? `${resourceName}.jsonl.gz` : `${resourceName}.jsonl`;
      const filePath = `${outputDir}/${filename}`;
      if (compress) {
        const compressed = await gzip(jsonl);
        await writeFile(filePath, compressed);
      } else {
        await writeFile(filePath, jsonl, "utf-8");
      }
      exportedFiles[resourceName] = filePath;
      resourceStats[resourceName] = {
        recordCount: records.length,
        fileSize: compress ? (await gzip(jsonl)).length : Buffer.byteLength(jsonl)
      };
    }
    const s3dbMetadata = {
      version: "1.0",
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      bucket: this.bucket,
      keyPrefix: this.keyPrefix || "",
      compressed: compress,
      resources: {},
      totalRecords: 0,
      totalSize: 0
    };
    if (database && database.resources) {
      for (const [resourceName, resource] of Object.entries(database.resources)) {
        if (resourceMap.has(resourceName)) {
          s3dbMetadata.resources[resourceName] = {
            schema: resource.schema ? {
              attributes: resource.schema.attributes,
              partitions: resource.schema.partitions,
              behavior: resource.schema.behavior,
              timestamps: resource.schema.timestamps
            } : null,
            stats: resourceStats[resourceName]
          };
        }
      }
    } else {
      for (const [resourceName, stats] of Object.entries(resourceStats)) {
        s3dbMetadata.resources[resourceName] = { stats };
      }
    }
    for (const stats of Object.values(resourceStats)) {
      s3dbMetadata.totalRecords += stats.recordCount;
      s3dbMetadata.totalSize += stats.fileSize;
    }
    const s3dbPath = `${outputDir}/s3db.json`;
    await writeFile(s3dbPath, JSON.stringify(s3dbMetadata, null, 2), "utf-8");
    return {
      manifest: s3dbPath,
      files: exportedFiles,
      stats: s3dbMetadata,
      resourceCount: resourceMap.size,
      totalRecords: s3dbMetadata.totalRecords,
      totalSize: s3dbMetadata.totalSize
    };
  }
  /**
   * Import from BackupPlugin-compatible format
   * Loads data from s3db.json + JSONL files created by BackupPlugin or exportBackup()
   *
   * @param {string} backupDir - Backup directory path containing s3db.json
   * @param {Object} options - Import options
   * @param {Array<string>} options.resources - Resource names to import (default: all)
   * @param {boolean} options.clear - Clear existing data first (default: false)
   * @param {Object} options.database - Database instance to recreate schemas
   * @returns {Promise<Object>} Import stats
   */
  async importBackup(backupDir, options = {}) {
    const { readFile, readdir } = await import('fs/promises');
    const zlib = await import('zlib');
    const { promisify } = await import('util');
    const gunzip = promisify(zlib.gunzip);
    if (options.clear) {
      this.clear();
    }
    const s3dbPath = `${backupDir}/s3db.json`;
    const s3dbContent = await readFile(s3dbPath, "utf-8");
    const metadata = JSON.parse(s3dbContent);
    const database = options.database;
    const resourceFilter = options.resources;
    const importStats = {
      resourcesImported: 0,
      recordsImported: 0,
      errors: []
    };
    if (database && metadata.resources) {
      for (const [resourceName, resourceMeta] of Object.entries(metadata.resources)) {
        if (resourceFilter && !resourceFilter.includes(resourceName)) continue;
        if (resourceMeta.schema) {
          try {
            await database.createResource({
              name: resourceName,
              ...resourceMeta.schema
            });
          } catch (error) {
          }
        }
      }
    }
    const files = await readdir(backupDir);
    for (const file of files) {
      if (!file.endsWith(".jsonl") && !file.endsWith(".jsonl.gz")) continue;
      const resourceName = file.replace(/\.jsonl(\.gz)?$/, "");
      if (resourceFilter && !resourceFilter.includes(resourceName)) continue;
      const filePath = `${backupDir}/${file}`;
      let content = await readFile(filePath);
      if (file.endsWith(".gz")) {
        content = await gunzip(content);
      }
      const jsonl = content.toString("utf-8");
      const lines = jsonl.split("\n").filter((line) => line.trim());
      for (const line of lines) {
        try {
          const record = JSON.parse(line);
          const id = record.id || record._id || `imported_${Date.now()}_${Math.random()}`;
          const { _body, id: _, _id: __, ...metadata2 } = record;
          await this.putObject({
            key: `resource=${resourceName}/id=${id}`,
            metadata: metadata2,
            body: _body ? Buffer.from(_body) : void 0
          });
          importStats.recordsImported++;
        } catch (error) {
          importStats.errors.push({
            resource: resourceName,
            error: error.message,
            line
          });
        }
      }
      importStats.resourcesImported++;
    }
    return importStats;
  }
  /**
   * Get storage statistics
   */
  getStats() {
    return this.storage.getStats();
  }
  /**
   * Clear all objects
   */
  clear() {
    this.storage.clear();
  }
}

function mapFieldTypeToTypeScript(fieldType) {
  const baseType = fieldType.split("|")[0].trim();
  const typeMap = {
    "string": "string",
    "number": "number",
    "integer": "number",
    "boolean": "boolean",
    "array": "any[]",
    "object": "Record<string, any>",
    "json": "Record<string, any>",
    "secret": "string",
    "email": "string",
    "url": "string",
    "date": "string",
    // ISO date string
    "datetime": "string",
    // ISO datetime string
    "ip4": "string",
    "ip6": "string"
  };
  if (baseType.startsWith("embedding:")) {
    const dimensions = parseInt(baseType.split(":")[1]);
    return `number[] /* ${dimensions} dimensions */`;
  }
  return typeMap[baseType] || "any";
}
function isFieldRequired(fieldDef) {
  if (typeof fieldDef === "string") {
    return fieldDef.includes("|required");
  }
  if (typeof fieldDef === "object" && fieldDef.required) {
    return true;
  }
  return false;
}
function generateResourceInterface(resourceName, attributes, timestamps = false) {
  const interfaceName = toPascalCase(resourceName);
  const lines = [];
  lines.push(`export interface ${interfaceName} {`);
  lines.push(`  /** Resource ID (auto-generated) */`);
  lines.push(`  id: string;`);
  lines.push("");
  for (const [fieldName, fieldDef] of Object.entries(attributes)) {
    const required = isFieldRequired(fieldDef);
    const optional = required ? "" : "?";
    let tsType;
    if (typeof fieldDef === "string") {
      tsType = mapFieldTypeToTypeScript(fieldDef);
    } else if (typeof fieldDef === "object" && fieldDef.type) {
      tsType = mapFieldTypeToTypeScript(fieldDef.type);
      if (fieldDef.type === "object" && fieldDef.props) {
        tsType = "{\n";
        for (const [propName, propDef] of Object.entries(fieldDef.props)) {
          const propType = typeof propDef === "string" ? mapFieldTypeToTypeScript(propDef) : mapFieldTypeToTypeScript(propDef.type);
          const propRequired = isFieldRequired(propDef);
          tsType += `    ${propName}${propRequired ? "" : "?"}: ${propType};
`;
        }
        tsType += "  }";
      }
      if (fieldDef.type === "array" && fieldDef.items) {
        const itemType = mapFieldTypeToTypeScript(fieldDef.items);
        tsType = `Array<${itemType}>`;
      }
    } else {
      tsType = "any";
    }
    if (fieldDef.description) {
      lines.push(`  /** ${fieldDef.description} */`);
    }
    lines.push(`  ${fieldName}${optional}: ${tsType};`);
  }
  if (timestamps) {
    lines.push("");
    lines.push(`  /** Creation timestamp (ISO 8601) */`);
    lines.push(`  createdAt: string;`);
    lines.push(`  /** Last update timestamp (ISO 8601) */`);
    lines.push(`  updatedAt: string;`);
  }
  lines.push("}");
  lines.push("");
  return lines.join("\n");
}
function toPascalCase(str) {
  return str.split(/[_-]/).map((word) => word.charAt(0).toUpperCase() + word.slice(1)).join("");
}
async function generateTypes(database, options = {}) {
  const {
    outputPath = "./types/database.d.ts",
    moduleName = "s3db.js",
    includeResource = true
  } = options;
  const lines = [];
  lines.push("/**");
  lines.push(" * Auto-generated TypeScript definitions for s3db.js resources");
  lines.push(" * Generated at: " + (/* @__PURE__ */ new Date()).toISOString());
  lines.push(" * DO NOT EDIT - This file is auto-generated");
  lines.push(" */");
  lines.push("");
  if (includeResource) {
    lines.push(`import { Resource, Database } from '${moduleName}';`);
    lines.push("");
  }
  const resourceInterfaces = [];
  for (const [name, resource] of Object.entries(database.resources)) {
    const allAttributes = resource.config?.attributes || resource.attributes || {};
    const timestamps = resource.config?.timestamps || false;
    const pluginAttrNames = resource.schema?._pluginAttributes ? Object.values(resource.schema._pluginAttributes).flat() : [];
    const userAttributes = Object.fromEntries(
      Object.entries(allAttributes).filter(([name2]) => !pluginAttrNames.includes(name2))
    );
    const interfaceDef = generateResourceInterface(name, userAttributes, timestamps);
    lines.push(interfaceDef);
    resourceInterfaces.push({
      name,
      interfaceName: toPascalCase(name),
      resource
    });
  }
  lines.push("/**");
  lines.push(" * Typed resource map for property access");
  lines.push(" * @example");
  lines.push(" * const users = db.resources.users; // Type-safe!");
  lines.push(' * const user = await users.get("id"); // Autocomplete works!');
  lines.push(" */");
  lines.push("export interface ResourceMap {");
  for (const { name, interfaceName } of resourceInterfaces) {
    lines.push(`  /** ${interfaceName} resource */`);
    if (includeResource) {
      lines.push(`  ${name}: Resource<${interfaceName}>;`);
    } else {
      lines.push(`  ${name}: any;`);
    }
  }
  lines.push("}");
  lines.push("");
  if (includeResource) {
    lines.push("/**");
    lines.push(" * Extended Database class with typed resources");
    lines.push(" */");
    lines.push("declare module 's3db.js' {");
    lines.push("  interface Database {");
    lines.push("    resources: ResourceMap;");
    lines.push("  }");
    lines.push("");
    lines.push("  interface Resource<T = any> {");
    lines.push("    get(id: string): Promise<T>;");
    lines.push("    getOrNull(id: string): Promise<T | null>;");
    lines.push("    getOrThrow(id: string): Promise<T>;");
    lines.push("    insert(data: Partial<T>): Promise<T>;");
    lines.push("    update(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    patch(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    replace(id: string, data: Partial<T>): Promise<T>;");
    lines.push("    delete(id: string): Promise<void>;");
    lines.push("    list(options?: any): Promise<T[]>;");
    lines.push("    query(filters: Partial<T>, options?: any): Promise<T[]>;");
    lines.push("    validate(data: Partial<T>, options?: any): Promise<{ valid: boolean; errors: any[]; data: T | null }>;");
    lines.push("  }");
    lines.push("}");
  }
  const content = lines.join("\n");
  if (outputPath) {
    await mkdir(dirname(outputPath), { recursive: true });
    await writeFile(outputPath, content, "utf-8");
  }
  return content;
}
async function printTypes(database, options = {}) {
  const types = await generateTypes(database, { ...options, outputPath: null });
  console.log(types);
  return types;
}

class Factory {
  /**
   * Global sequence counter
   * @private
   */
  static _sequences = /* @__PURE__ */ new Map();
  /**
   * Registered factories
   * @private
   */
  static _factories = /* @__PURE__ */ new Map();
  /**
   * Database instance (set globally)
   * @private
   */
  static _database = null;
  /**
   * Create a new factory definition
   * @param {string} resourceName - Resource name
   * @param {Object|Function} definition - Field definitions or function
   * @param {Object} options - Factory options
   * @returns {Factory} Factory instance
   */
  static define(resourceName, definition, options = {}) {
    const factory = new Factory(resourceName, definition, options);
    Factory._factories.set(resourceName, factory);
    return factory;
  }
  /**
   * Set global database instance
   * @param {Database} database - s3db.js Database instance
   */
  static setDatabase(database) {
    Factory._database = database;
  }
  /**
   * Get factory by resource name
   * @param {string} resourceName - Resource name
   * @returns {Factory} Factory instance
   */
  static get(resourceName) {
    return Factory._factories.get(resourceName);
  }
  /**
   * Reset all sequences
   */
  static resetSequences() {
    Factory._sequences.clear();
  }
  /**
   * Reset all factories
   */
  static reset() {
    Factory._sequences.clear();
    Factory._factories.clear();
    Factory._database = null;
  }
  /**
   * Constructor
   * @param {string} resourceName - Resource name
   * @param {Object|Function} definition - Field definitions
   * @param {Object} options - Factory options
   */
  constructor(resourceName, definition, options = {}) {
    this.resourceName = resourceName;
    this.definition = definition;
    this.options = options;
    this.traits = /* @__PURE__ */ new Map();
    this.afterCreateCallbacks = [];
    this.beforeCreateCallbacks = [];
  }
  /**
   * Get next sequence number
   * @param {string} name - Sequence name (default: factory name)
   * @returns {number} Next sequence number
   */
  sequence(name = this.resourceName) {
    const current = Factory._sequences.get(name) || 0;
    const next = current + 1;
    Factory._sequences.set(name, next);
    return next;
  }
  /**
   * Define a trait (state variation)
   * @param {string} name - Trait name
   * @param {Object|Function} attributes - Trait attributes
   * @returns {Factory} This factory (for chaining)
   */
  trait(name, attributes) {
    this.traits.set(name, attributes);
    return this;
  }
  /**
   * Register after create callback
   * @param {Function} callback - Callback function
   * @returns {Factory} This factory (for chaining)
   */
  afterCreate(callback) {
    this.afterCreateCallbacks.push(callback);
    return this;
  }
  /**
   * Register before create callback
   * @param {Function} callback - Callback function
   * @returns {Factory} This factory (for chaining)
   */
  beforeCreate(callback) {
    this.beforeCreateCallbacks.push(callback);
    return this;
  }
  /**
   * Build attributes without creating in database
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object>} Built attributes
   */
  async build(overrides = {}, options = {}) {
    const { traits = [] } = options;
    const seq = this.sequence();
    let attributes = typeof this.definition === "function" ? await this.definition({ seq, factory: this }) : { ...this.definition };
    for (const traitName of traits) {
      const trait = this.traits.get(traitName);
      if (!trait) {
        throw new Error(`Trait '${traitName}' not found in factory '${this.resourceName}'`);
      }
      const traitAttrs = typeof trait === "function" ? await trait({ seq, factory: this }) : trait;
      attributes = { ...attributes, ...traitAttrs };
    }
    attributes = { ...attributes, ...overrides };
    for (const [key, value] of Object.entries(attributes)) {
      if (typeof value === "function") {
        attributes[key] = await value({ seq, factory: this });
      }
    }
    return attributes;
  }
  /**
   * Create resource in database
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object>} Created resource
   */
  async create(overrides = {}, options = {}) {
    const { database = Factory._database } = options;
    if (!database) {
      throw new Error("Database not set. Use Factory.setDatabase(db) or pass database option");
    }
    let attributes = await this.build(overrides, options);
    for (const callback of this.beforeCreateCallbacks) {
      attributes = await callback(attributes) || attributes;
    }
    const resource = database.resources[this.resourceName];
    if (!resource) {
      throw new Error(`Resource '${this.resourceName}' not found in database`);
    }
    let created = await resource.insert(attributes);
    for (const callback of this.afterCreateCallbacks) {
      created = await callback(created, { database }) || created;
    }
    return created;
  }
  /**
   * Create multiple resources
   * @param {number} count - Number of resources to create
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object[]>} Created resources
   */
  async createMany(count, overrides = {}, options = {}) {
    const resources = [];
    for (let i = 0; i < count; i++) {
      const resource = await this.create(overrides, options);
      resources.push(resource);
    }
    return resources;
  }
  /**
   * Build multiple resources without creating
   * @param {number} count - Number of resources to build
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object[]>} Built resources
   */
  async buildMany(count, overrides = {}, options = {}) {
    const resources = [];
    for (let i = 0; i < count; i++) {
      const resource = await this.build(overrides, options);
      resources.push(resource);
    }
    return resources;
  }
  /**
   * Create with specific traits
   * @param {string|string[]} traits - Trait name(s)
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Create options
   * @returns {Promise<Object>} Created resource
   */
  async createWithTraits(traits, overrides = {}, options = {}) {
    const traitArray = Array.isArray(traits) ? traits : [traits];
    return this.create(overrides, { ...options, traits: traitArray });
  }
  /**
   * Build with specific traits
   * @param {string|string[]} traits - Trait name(s)
   * @param {Object} overrides - Override attributes
   * @param {Object} options - Build options
   * @returns {Promise<Object>} Built resource
   */
  async buildWithTraits(traits, overrides = {}, options = {}) {
    const traitArray = Array.isArray(traits) ? traits : [traits];
    return this.build(overrides, { ...options, traits: traitArray });
  }
}

class Seeder {
  /**
   * Constructor
   * @param {Database} database - s3db.js Database instance
   * @param {Object} options - Seeder options
   */
  constructor(database, options = {}) {
    this.database = database;
    this.options = options;
    this.verbose = options.verbose !== false;
  }
  /**
   * Log message (if verbose)
   * @param {string} message - Message to log
   * @private
   */
  log(message) {
    if (this.verbose) {
      console.log(`[Seeder] ${message}`);
    }
  }
  /**
   * Seed resources using factories
   * @param {Object} specs - Seed specifications { resourceName: count }
   * @returns {Promise<Object>} Created resources by resource name
   *
   * @example
   * const created = await seeder.seed({
   *   users: 10,
   *   posts: 50
   * });
   */
  async seed(specs) {
    const created = {};
    for (const [resourceName, count] of Object.entries(specs)) {
      this.log(`Seeding ${count} ${resourceName}...`);
      const factory = Factory.get(resourceName);
      if (!factory) {
        throw new Error(`Factory for '${resourceName}' not found. Define it with Factory.define()`);
      }
      created[resourceName] = await factory.createMany(count, {}, { database: this.database });
      this.log(`\u2705 Created ${count} ${resourceName}`);
    }
    return created;
  }
  /**
   * Seed with custom callback
   * @param {Function} callback - Seeding callback
   * @returns {Promise<any>} Result of callback
   *
   * @example
   * await seeder.call(async (db) => {
   *   const user = await UserFactory.create();
   *   const posts = await PostFactory.createMany(5, { userId: user.id });
   *   return { user, posts };
   * });
   */
  async call(callback) {
    this.log("Running custom seeder...");
    const result = await callback(this.database);
    this.log("\u2705 Custom seeder completed");
    return result;
  }
  /**
   * Truncate resources (delete all data)
   * @param {string[]} resourceNames - Resource names to truncate
   * @returns {Promise<void>}
   *
   * @example
   * await seeder.truncate(['users', 'posts']);
   */
  async truncate(resourceNames) {
    for (const resourceName of resourceNames) {
      this.log(`Truncating ${resourceName}...`);
      const resource = this.database.resources[resourceName];
      if (!resource) {
        this.log(`\u26A0\uFE0F  Resource '${resourceName}' not found, skipping`);
        continue;
      }
      const ids = await resource.listIds();
      if (ids.length > 0) {
        await resource.deleteMany(ids);
        this.log(`\u2705 Deleted ${ids.length} ${resourceName}`);
      } else {
        this.log(`\u2705 ${resourceName} already empty`);
      }
    }
  }
  /**
   * Truncate all resources
   * @returns {Promise<void>}
   */
  async truncateAll() {
    const resourceNames = Object.keys(this.database.resources);
    await this.truncate(resourceNames);
  }
  /**
   * Run multiple seeders in order
   * @param {Function[]} seeders - Array of seeder functions
   * @returns {Promise<Object[]>} Results of each seeder
   *
   * @example
   * await seeder.run([
   *   async (db) => await UserFactory.createMany(10),
   *   async (db) => await PostFactory.createMany(50)
   * ]);
   */
  async run(seeders) {
    const results = [];
    for (const seederFn of seeders) {
      this.log(`Running seeder ${seederFn.name || "anonymous"}...`);
      const result = await seederFn(this.database);
      results.push(result);
      this.log(`\u2705 Completed ${seederFn.name || "anonymous"}`);
    }
    return results;
  }
  /**
   * Seed and return specific resources
   * @param {Object} specs - Seed specifications
   * @returns {Promise<Object>} Created resources
   *
   * @example
   * const { users, posts } = await seeder.seedAndReturn({
   *   users: 5,
   *   posts: 10
   * });
   */
  async seedAndReturn(specs) {
    return await this.seed(specs);
  }
  /**
   * Reset database (truncate all and reset sequences)
   * @returns {Promise<void>}
   */
  async reset() {
    this.log("Resetting database...");
    await this.truncateAll();
    Factory.resetSequences();
    this.log("\u2705 Database reset complete");
  }
}

function generateToken(bytes = 32, encoding = "hex") {
  const buffer = randomBytes(bytes);
  switch (encoding) {
    case "hex":
      return buffer.toString("hex");
    case "base64":
      return buffer.toString("base64");
    case "base64url":
      return buffer.toString("base64url");
    default:
      throw new Error(`Invalid encoding: ${encoding}. Use 'hex', 'base64', or 'base64url'.`);
  }
}
function generatePasswordResetToken() {
  return generateToken(32, "hex");
}
function generateSessionId() {
  return idGenerator();
}
function calculateExpiration(duration) {
  let ms;
  if (typeof duration === "number") {
    ms = duration;
  } else if (typeof duration === "string") {
    const match = duration.match(/^(\d+)([smhd])$/);
    if (!match) {
      throw new Error(`Invalid duration format: ${duration}. Use '15m', '1h', '7d', etc.`);
    }
    const value = parseInt(match[1], 10);
    const unit = match[2];
    switch (unit) {
      case "s":
        ms = value * 1e3;
        break;
      // seconds
      case "m":
        ms = value * 60 * 1e3;
        break;
      // minutes
      case "h":
        ms = value * 60 * 60 * 1e3;
        break;
      // hours
      case "d":
        ms = value * 24 * 60 * 60 * 1e3;
        break;
      // days
      default:
        throw new Error(`Invalid duration unit: ${unit}`);
    }
  } else {
    throw new Error("Duration must be a string or number");
  }
  return Date.now() + ms;
}
function isExpired(expiresAt) {
  if (!expiresAt) {
    return true;
  }
  const timestamp = typeof expiresAt === "string" ? new Date(expiresAt).getTime() : expiresAt;
  return Date.now() > timestamp;
}

const DEFAULT_CONFIG = {
  sessionExpiry: "24h",
  // Default: 24 hours
  cookieName: "s3db_session",
  // Cookie name
  cookiePath: "/",
  // Cookie path
  cookieHttpOnly: true,
  // HTTP-only cookie (no JS access)
  cookieSecure: false,
  // Secure cookie (HTTPS only) - set to true in production
  cookieSameSite: "Lax",
  // SameSite attribute ('Strict', 'Lax', 'None')
  cleanupInterval: 36e5,
  // Cleanup interval: 1 hour (in ms)
  enableCleanup: true
  // Enable automatic cleanup
};
class SessionManager {
  /**
   * Create Session Manager
   * @param {Object} options - Configuration options
   * @param {Object} options.sessionResource - S3DB sessions resource
   * @param {Object} [options.config] - Session configuration
   */
  constructor(options = {}) {
    this.sessionResource = options.sessionResource;
    this.config = { ...DEFAULT_CONFIG, ...options.config };
    this.cleanupTimer = null;
    if (!this.sessionResource) {
      throw new Error("SessionManager requires a sessionResource");
    }
    if (this.config.enableCleanup) {
      this._startCleanup();
    }
  }
  /**
   * Create a new session
   * @param {Object} data - Session data
   * @param {string} data.userId - User ID
   * @param {Object} [data.metadata] - Additional session metadata
   * @param {string} [data.ipAddress] - Client IP address
   * @param {string} [data.userAgent] - Client user agent
   * @param {string} [duration] - Session duration (overrides default)
   * @returns {Promise<{sessionId: string, expiresAt: number, session: Object}>}
   */
  async createSession(data) {
    const { userId, metadata = {}, ipAddress, userAgent, duration } = data;
    if (!userId) {
      throw new Error("userId is required to create a session");
    }
    generateSessionId();
    const expiresAt = calculateExpiration(duration || this.config.sessionExpiry);
    const sessionData = {
      userId,
      expiresAt: new Date(expiresAt).toISOString(),
      ipAddress: ipAddress || null,
      userAgent: userAgent || null,
      metadata,
      createdAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    const [ok, err, session] = await tryFn(
      () => this.sessionResource.insert(sessionData)
    );
    if (!ok) {
      throw new Error(`Failed to create session: ${err.message}`);
    }
    return {
      sessionId: session.id,
      // S3DB auto-generated ID
      expiresAt,
      session
    };
  }
  /**
   * Validate a session
   * @param {string} sessionId - Session ID to validate
   * @returns {Promise<{valid: boolean, session: Object|null, reason: string|null}>}
   */
  async validateSession(sessionId) {
    if (!sessionId) {
      return { valid: false, session: null, reason: "No session ID provided" };
    }
    const [ok, err, session] = await tryFn(
      () => this.sessionResource.get(sessionId)
    );
    if (!ok || !session) {
      return { valid: false, session: null, reason: "Session not found" };
    }
    if (isExpired(session.expiresAt)) {
      await this.destroySession(sessionId);
      return { valid: false, session: null, reason: "Session expired" };
    }
    return { valid: true, session, reason: null };
  }
  /**
   * Get session data without validation
   * @param {string} sessionId - Session ID
   * @returns {Promise<Object|null>} Session object or null
   */
  async getSession(sessionId) {
    if (!sessionId) {
      return null;
    }
    const [ok, , session] = await tryFn(
      () => this.sessionResource.get(sessionId)
    );
    return ok ? session : null;
  }
  /**
   * Update session metadata
   * @param {string} sessionId - Session ID
   * @param {Object} metadata - New metadata to merge
   * @returns {Promise<Object>} Updated session
   */
  async updateSession(sessionId, metadata) {
    if (!sessionId) {
      throw new Error("sessionId is required");
    }
    const session = await this.getSession(sessionId);
    if (!session) {
      throw new Error("Session not found");
    }
    const updatedMetadata = { ...session.metadata, ...metadata };
    const [ok, err, updated] = await tryFn(
      () => this.sessionResource.update(sessionId, {
        metadata: updatedMetadata
      })
    );
    if (!ok) {
      throw new Error(`Failed to update session: ${err.message}`);
    }
    return updated;
  }
  /**
   * Destroy a session (logout)
   * @param {string} sessionId - Session ID to destroy
   * @returns {Promise<boolean>} True if session was destroyed
   */
  async destroySession(sessionId) {
    if (!sessionId) {
      return false;
    }
    const [ok] = await tryFn(
      () => this.sessionResource.delete(sessionId)
    );
    return ok;
  }
  /**
   * Destroy all sessions for a user (logout all devices)
   * @param {string} userId - User ID
   * @returns {Promise<number>} Number of sessions destroyed
   */
  async destroyUserSessions(userId) {
    if (!userId) {
      return 0;
    }
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.query({ userId })
    );
    if (!ok || !sessions || sessions.length === 0) {
      return 0;
    }
    let count = 0;
    for (const session of sessions) {
      const destroyed = await this.destroySession(session.id);
      if (destroyed) count++;
    }
    return count;
  }
  /**
   * Get all active sessions for a user
   * @param {string} userId - User ID
   * @returns {Promise<Array>} Array of active sessions
   */
  async getUserSessions(userId) {
    if (!userId) {
      return [];
    }
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.query({ userId })
    );
    if (!ok || !sessions) {
      return [];
    }
    const activeSessions = [];
    for (const session of sessions) {
      if (!isExpired(session.expiresAt)) {
        activeSessions.push(session);
      } else {
        await this.destroySession(session.id);
      }
    }
    return activeSessions;
  }
  /**
   * Set session cookie in HTTP response
   * @param {Object} res - HTTP response object (Express/Hono style)
   * @param {string} sessionId - Session ID
   * @param {number} expiresAt - Expiration timestamp (Unix ms)
   */
  setSessionCookie(res, sessionId, expiresAt) {
    const expires = new Date(expiresAt);
    const cookieOptions = [
      `${this.config.cookieName}=${sessionId}`,
      `Path=${this.config.cookiePath}`,
      `Expires=${expires.toUTCString()}`,
      `Max-Age=${Math.floor((expiresAt - Date.now()) / 1e3)}`
    ];
    if (this.config.cookieHttpOnly) {
      cookieOptions.push("HttpOnly");
    }
    if (this.config.cookieSecure) {
      cookieOptions.push("Secure");
    }
    if (this.config.cookieSameSite) {
      cookieOptions.push(`SameSite=${this.config.cookieSameSite}`);
    }
    const cookieValue = cookieOptions.join("; ");
    if (typeof res.setHeader === "function") {
      res.setHeader("Set-Cookie", cookieValue);
    } else if (typeof res.header === "function") {
      res.header("Set-Cookie", cookieValue);
    } else {
      throw new Error("Unsupported response object");
    }
  }
  /**
   * Clear session cookie in HTTP response
   * @param {Object} res - HTTP response object
   */
  clearSessionCookie(res) {
    const cookieOptions = [
      `${this.config.cookieName}=`,
      `Path=${this.config.cookiePath}`,
      "Expires=Thu, 01 Jan 1970 00:00:00 GMT",
      "Max-Age=0"
    ];
    if (this.config.cookieHttpOnly) {
      cookieOptions.push("HttpOnly");
    }
    if (this.config.cookieSecure) {
      cookieOptions.push("Secure");
    }
    if (this.config.cookieSameSite) {
      cookieOptions.push(`SameSite=${this.config.cookieSameSite}`);
    }
    const cookieValue = cookieOptions.join("; ");
    if (typeof res.setHeader === "function") {
      res.setHeader("Set-Cookie", cookieValue);
    } else if (typeof res.header === "function") {
      res.header("Set-Cookie", cookieValue);
    }
  }
  /**
   * Get session ID from HTTP request cookies
   * @param {Object} req - HTTP request object
   * @returns {string|null} Session ID or null
   */
  getSessionIdFromRequest(req) {
    const cookieHeader = req.headers?.cookie || req.header?.("cookie");
    if (!cookieHeader) {
      return null;
    }
    const cookies = cookieHeader.split(";").reduce((acc, cookie) => {
      const [key, value] = cookie.trim().split("=");
      acc[key] = value;
      return acc;
    }, {});
    return cookies[this.config.cookieName] || null;
  }
  /**
   * Cleanup expired sessions
   * @returns {Promise<number>} Number of sessions cleaned up
   */
  async cleanupExpiredSessions() {
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.list({ limit: 1e3 })
    );
    if (!ok || !sessions) {
      return 0;
    }
    let count = 0;
    for (const session of sessions) {
      if (isExpired(session.expiresAt)) {
        const destroyed = await this.destroySession(session.id);
        if (destroyed) count++;
      }
    }
    return count;
  }
  /**
   * Start automatic cleanup of expired sessions
   * @private
   */
  _startCleanup() {
    if (this.cleanupTimer) {
      return;
    }
    this.cleanupTimer = setInterval(async () => {
      try {
        const count = await this.cleanupExpiredSessions();
        if (count > 0) {
          console.log(`[SessionManager] Cleaned up ${count} expired sessions`);
        }
      } catch (error) {
        console.error("[SessionManager] Cleanup error:", error.message);
      }
    }, this.config.cleanupInterval);
  }
  /**
   * Stop automatic cleanup
   */
  stopCleanup() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }
  }
  /**
   * Get session statistics
   * @returns {Promise<Object>} Session statistics
   */
  async getStatistics() {
    const [ok, , sessions] = await tryFn(
      () => this.sessionResource.list({ limit: 1e4 })
    );
    if (!ok || !sessions) {
      return {
        total: 0,
        active: 0,
        expired: 0,
        users: 0
      };
    }
    let active = 0;
    let expired = 0;
    const uniqueUsers = /* @__PURE__ */ new Set();
    for (const session of sessions) {
      if (isExpired(session.expiresAt)) {
        expired++;
      } else {
        active++;
        uniqueUsers.add(session.userId);
      }
    }
    return {
      total: sessions.length,
      active,
      expired,
      users: uniqueUsers.size
    };
  }
}

var sessionManager = /*#__PURE__*/Object.freeze({
  __proto__: null,
  SessionManager: SessionManager
});

class EmailService {
  /**
   * Create Email Service instance
   * @param {Object} options - Email service configuration
   */
  constructor(options = {}) {
    this.config = {
      enabled: options.enabled !== false,
      from: options.from || "noreply@s3db.identity",
      replyTo: options.replyTo || null,
      // SMTP configuration
      smtp: {
        host: options.smtp?.host || "localhost",
        port: options.smtp?.port || 587,
        secure: options.smtp?.secure || false,
        // true for 465, false for other ports
        auth: {
          user: options.smtp?.auth?.user || "",
          pass: options.smtp?.auth?.pass || ""
        },
        // Optional TLS options
        tls: {
          rejectUnauthorized: options.smtp?.tls?.rejectUnauthorized !== false
        }
      },
      // Template configuration
      templates: {
        baseUrl: options.templates?.baseUrl || "http://localhost:4000",
        brandName: options.templates?.brandName || "S3DB Identity",
        brandLogo: options.templates?.brandLogo || null,
        brandColor: options.templates?.brandColor || "#007bff",
        supportEmail: options.templates?.supportEmail || null,
        customFooter: options.templates?.customFooter || null
      },
      verbose: options.verbose || false
    };
    this.transporter = null;
    this.initialized = false;
  }
  /**
   * Initialize email service (lazy initialization)
   * @private
   */
  async _initialize() {
    if (this.initialized || !this.config.enabled) {
      return;
    }
    try {
      const nodemailer = await Promise.resolve().then(function () { return nodemailer$1; });
      this.transporter = nodemailer.default.createTransport({
        host: this.config.smtp.host,
        port: this.config.smtp.port,
        secure: this.config.smtp.secure,
        auth: this.config.smtp.auth,
        tls: this.config.smtp.tls
      });
      if (this.config.verbose) {
        await this.transporter.verify();
        console.log("[EmailService] SMTP connection verified");
      }
      this.initialized = true;
    } catch (error) {
      console.error("[EmailService] Failed to initialize:", error);
      throw new Error(`Failed to initialize email service: ${error.message}`);
    }
  }
  /**
   * Send an email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email address
   * @param {string} options.subject - Email subject
   * @param {string} options.html - HTML email body
   * @param {string} [options.text] - Plain text email body (fallback)
   * @param {string} [options.from] - Override sender address
   * @param {string} [options.replyTo] - Reply-to address
   * @returns {Promise<Object>} Send result
   */
  async sendEmail(options) {
    if (!this.config.enabled) {
      if (this.config.verbose) {
        console.log("[EmailService] Email service disabled, skipping send");
      }
      return { success: false, reason: "disabled" };
    }
    if (!this.initialized) {
      await this._initialize();
    }
    const { to, subject, html, text, from, replyTo } = options;
    if (!to || !subject || !html) {
      throw new Error("Email requires to, subject, and html fields");
    }
    try {
      const info = await this.transporter.sendMail({
        from: from || this.config.from,
        to,
        subject,
        text: text || this._htmlToText(html),
        html,
        replyTo: replyTo || this.config.replyTo
      });
      if (this.config.verbose) {
        console.log("[EmailService] Email sent successfully:", info.messageId);
      }
      return {
        success: true,
        messageId: info.messageId,
        accepted: info.accepted,
        rejected: info.rejected
      };
    } catch (error) {
      console.error("[EmailService] Failed to send email:", error);
      return {
        success: false,
        error: error.message
      };
    }
  }
  /**
   * Convert HTML to plain text (simple implementation)
   * @param {string} html - HTML content
   * @returns {string} Plain text
   * @private
   */
  _htmlToText(html) {
    return html.replace(/<br\s*\/?>/gi, "\n").replace(/<\/p>/gi, "\n\n").replace(/<[^>]+>/g, "").replace(/&nbsp;/g, " ").replace(/&amp;/g, "&").replace(/&lt;/g, "<").replace(/&gt;/g, ">").replace(/&quot;/g, '"').trim();
  }
  /**
   * Base email template wrapper
   * @param {Object} options - Template options
   * @param {string} options.title - Email title
   * @param {string} options.preheader - Email preheader (preview text)
   * @param {string} options.content - Email content (HTML)
   * @returns {string} HTML email
   * @private
   */
  _baseTemplate({ title, preheader, content }) {
    const { brandName, brandLogo, brandColor, supportEmail, customFooter } = this.config.templates;
    return `<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${title}</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      line-height: 1.6;
      color: #333;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
    }
    .email-wrapper {
      max-width: 600px;
      margin: 0 auto;
      background-color: #ffffff;
    }
    .email-header {
      background-color: ${brandColor};
      padding: 30px 20px;
      text-align: center;
    }
    .email-header h1 {
      color: #ffffff;
      margin: 0;
      font-size: 24px;
    }
    .email-body {
      padding: 40px 20px;
    }
    .email-footer {
      background-color: #f8f9fa;
      padding: 20px;
      text-align: center;
      font-size: 12px;
      color: #6c757d;
      border-top: 1px solid #dee2e6;
    }
    .button {
      display: inline-block;
      padding: 12px 30px;
      background-color: ${brandColor};
      color: #ffffff !important;
      text-decoration: none;
      border-radius: 4px;
      font-weight: 500;
      margin: 20px 0;
    }
    .button:hover {
      background-color: ${brandColor}dd;
    }
    .info-box {
      background-color: #f8f9fa;
      border-left: 4px solid ${brandColor};
      padding: 15px;
      margin: 20px 0;
    }
    .preheader {
      display: none;
      font-size: 1px;
      color: #ffffff;
      line-height: 1px;
      max-height: 0;
      max-width: 0;
      opacity: 0;
      overflow: hidden;
    }
  </style>
</head>
<body>
  <span class="preheader">${preheader || ""}</span>
  <div class="email-wrapper">
    <div class="email-header">
      ${brandLogo ? `<img src="${brandLogo}" alt="${brandName}" height="40" style="margin-bottom: 10px;">` : ""}
      <h1>${brandName}</h1>
    </div>
    <div class="email-body">
      ${content}
    </div>
    <div class="email-footer">
      ${customFooter || `
        <p>This email was sent from ${brandName}</p>
        ${supportEmail ? `<p>Need help? Contact us at <a href="mailto:${supportEmail}">${supportEmail}</a></p>` : ""}
        <p>&copy; ${(/* @__PURE__ */ new Date()).getFullYear()} ${brandName}. All rights reserved.</p>
      `}
    </div>
  </div>
</body>
</html>`;
  }
  /**
   * Send password reset email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @param {string} options.resetToken - Password reset token
   * @param {number} [options.expiresIn] - Token expiration in minutes (default: 60)
   * @returns {Promise<Object>} Send result
   */
  async sendPasswordResetEmail({ to, name, resetToken, expiresIn = 60 }) {
    const { baseUrl } = this.config.templates;
    const resetUrl = `${baseUrl}/reset-password?token=${resetToken}`;
    const content = `
      <h2>Password Reset Request</h2>
      <p>Hi ${name},</p>
      <p>We received a request to reset your password. If you didn't make this request, you can safely ignore this email.</p>
      <p>To reset your password, click the button below:</p>
      <p style="text-align: center;">
        <a href="${resetUrl}" class="button">Reset Password</a>
      </p>
      <div class="info-box">
        <p><strong>\u23F0 This link will expire in ${expiresIn} minutes.</strong></p>
        <p>If the button doesn't work, copy and paste this link into your browser:</p>
        <p style="word-break: break-all;"><a href="${resetUrl}">${resetUrl}</a></p>
      </div>
      <p>If you didn't request a password reset, please ignore this email or contact support if you have concerns.</p>
      <p>Best regards,<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Reset Your Password",
      preheader: "Click here to reset your password",
      content
    });
    return this.sendEmail({
      to,
      subject: "Reset Your Password",
      html
    });
  }
  /**
   * Send email verification email
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @param {string} options.verificationToken - Email verification token
   * @param {number} [options.expiresIn] - Token expiration in hours (default: 24)
   * @returns {Promise<Object>} Send result
   */
  async sendEmailVerificationEmail({ to, name, verificationToken, expiresIn = 24 }) {
    const { baseUrl } = this.config.templates;
    const verifyUrl = `${baseUrl}/verify-email?token=${verificationToken}`;
    const content = `
      <h2>Verify Your Email Address</h2>
      <p>Hi ${name},</p>
      <p>Thank you for creating an account with ${this.config.templates.brandName}! To complete your registration, please verify your email address.</p>
      <p style="text-align: center;">
        <a href="${verifyUrl}" class="button">Verify Email Address</a>
      </p>
      <div class="info-box">
        <p><strong>\u23F0 This link will expire in ${expiresIn} hours.</strong></p>
        <p>If the button doesn't work, copy and paste this link into your browser:</p>
        <p style="word-break: break-all;"><a href="${verifyUrl}">${verifyUrl}</a></p>
      </div>
      <p>If you didn't create an account with us, you can safely ignore this email.</p>
      <p>Welcome aboard!<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Verify Your Email",
      preheader: "Verify your email address to get started",
      content
    });
    return this.sendEmail({
      to,
      subject: "Verify Your Email Address",
      html
    });
  }
  /**
   * Send welcome email after successful registration
   * @param {Object} options - Email options
   * @param {string} options.to - Recipient email
   * @param {string} options.name - Recipient name
   * @returns {Promise<Object>} Send result
   */
  async sendWelcomeEmail({ to, name }) {
    const { baseUrl } = this.config.templates;
    const content = `
      <h2>Welcome to ${this.config.templates.brandName}!</h2>
      <p>Hi ${name},</p>
      <p>Your account is now active and you're ready to get started.</p>
      <p style="text-align: center;">
        <a href="${baseUrl}/profile" class="button">Go to Your Profile</a>
      </p>
      <p>If you have any questions or need help, don't hesitate to reach out to our support team.</p>
      <p>Best regards,<br>The ${this.config.templates.brandName} Team</p>
    `;
    const html = this._baseTemplate({
      title: "Welcome!",
      preheader: "Your account is ready",
      content
    });
    return this.sendEmail({
      to,
      subject: `Welcome to ${this.config.templates.brandName}!`,
      html
    });
  }
  /**
   * Test email service connection
   * @returns {Promise<boolean>} True if connection is valid
   */
  async testConnection() {
    if (!this.config.enabled) {
      return false;
    }
    try {
      await this._initialize();
      await this.transporter.verify();
      return true;
    } catch (error) {
      console.error("[EmailService] Connection test failed:", error);
      return false;
    }
  }
  /**
   * Close transporter connection
   */
  async close() {
    if (this.transporter) {
      this.transporter.close();
      this.transporter = null;
      this.initialized = false;
    }
  }
}

var emailService = /*#__PURE__*/Object.freeze({
  __proto__: null,
  EmailService: EmailService
});

function createCorsMiddleware(config = {}) {
  const {
    origin = "*",
    methods = ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
    allowedHeaders = ["Content-Type", "Authorization", "X-API-Key"],
    exposedHeaders = ["X-Total-Count", "X-Page-Count"],
    credentials = true,
    maxAge = 86400
  } = config;
  return async (c, next) => {
    c.header("Access-Control-Allow-Origin", origin);
    c.header("Access-Control-Allow-Methods", methods.join(", "));
    c.header("Access-Control-Allow-Headers", allowedHeaders.join(", "));
    c.header("Access-Control-Expose-Headers", exposedHeaders.join(", "));
    if (credentials) {
      c.header("Access-Control-Allow-Credentials", "true");
    }
    c.header("Access-Control-Max-Age", maxAge.toString());
    if (c.req.method === "OPTIONS") {
      return c.body(null, 204);
    }
    await next();
  };
}

function createLoggingMiddleware(config = {}) {
  const {
    format = ":method :path :status :response-time ms",
    verbose = false
  } = config;
  return async (c, next) => {
    const start = Date.now();
    const method = c.req.method;
    const path = c.req.path;
    const requestId = c.get("requestId");
    await next();
    const duration = Date.now() - start;
    const status = c.res.status;
    const user = c.get("user")?.username || c.get("user")?.email || "anonymous";
    let logMessage = format.replace(":method", method).replace(":path", path).replace(":status", status).replace(":response-time", duration).replace(":user", user).replace(":requestId", requestId);
    console.log(`[HTTP] ${logMessage}`);
  };
}

promisify(gzip);
promisify(brotliCompress);

function createSecurityMiddleware(config = {}) {
  const {
    contentSecurityPolicy = {
      enabled: true,
      directives: {
        "default-src": ["'self'"],
        "script-src": ["'self'", "'unsafe-inline'"],
        "style-src": ["'self'", "'unsafe-inline'"],
        "img-src": ["'self'", "data:", "https:"]
      },
      reportOnly: false,
      reportUri: null
    },
    frameguard = { action: "deny" },
    noSniff = true,
    hsts = {
      maxAge: 15552e3,
      // 180 days
      includeSubDomains: true,
      preload: false
    },
    referrerPolicy = { policy: "no-referrer" },
    dnsPrefetchControl = { allow: false },
    ieNoOpen = true,
    permittedCrossDomainPolicies = { policy: "none" },
    xssFilter = { mode: "block" },
    permissionsPolicy = {
      features: {
        geolocation: [],
        microphone: [],
        camera: [],
        payment: [],
        usb: []
      }
    }
  } = config;
  return async (c, next) => {
    if (noSniff) {
      c.header("X-Content-Type-Options", "nosniff");
    }
    if (frameguard) {
      const action = frameguard.action.toUpperCase();
      if (action === "DENY") {
        c.header("X-Frame-Options", "DENY");
      } else if (action === "SAMEORIGIN") {
        c.header("X-Frame-Options", "SAMEORIGIN");
      }
    }
    if (hsts) {
      const parts = [`max-age=${hsts.maxAge}`];
      if (hsts.includeSubDomains) {
        parts.push("includeSubDomains");
      }
      if (hsts.preload) {
        parts.push("preload");
      }
      c.header("Strict-Transport-Security", parts.join("; "));
    }
    if (referrerPolicy) {
      c.header("Referrer-Policy", referrerPolicy.policy);
    }
    if (dnsPrefetchControl) {
      const value = dnsPrefetchControl.allow ? "on" : "off";
      c.header("X-DNS-Prefetch-Control", value);
    }
    if (ieNoOpen) {
      c.header("X-Download-Options", "noopen");
    }
    if (permittedCrossDomainPolicies) {
      c.header("X-Permitted-Cross-Domain-Policies", permittedCrossDomainPolicies.policy);
    }
    if (xssFilter) {
      const mode = xssFilter.mode;
      c.header("X-XSS-Protection", mode === "block" ? "1; mode=block" : "0");
    }
    if (permissionsPolicy && permissionsPolicy.features) {
      const features = permissionsPolicy.features;
      const policies = [];
      for (const [feature, allowList] of Object.entries(features)) {
        if (Array.isArray(allowList)) {
          const value = allowList.length === 0 ? `${feature}=()` : `${feature}=(${allowList.join(" ")})`;
          policies.push(value);
        }
      }
      if (policies.length > 0) {
        c.header("Permissions-Policy", policies.join(", "));
      }
    }
    if (contentSecurityPolicy && contentSecurityPolicy.enabled !== false && contentSecurityPolicy.directives) {
      const cspParts = [];
      for (const [directive, values] of Object.entries(contentSecurityPolicy.directives)) {
        if (Array.isArray(values) && values.length > 0) {
          cspParts.push(`${directive} ${values.join(" ")}`);
        } else if (typeof values === "string") {
          cspParts.push(`${directive} ${values}`);
        }
      }
      if (contentSecurityPolicy.reportUri) {
        cspParts.push(`report-uri ${contentSecurityPolicy.reportUri}`);
      }
      if (cspParts.length > 0) {
        const cspValue = cspParts.join("; ");
        const headerName = contentSecurityPolicy.reportOnly ? "Content-Security-Policy-Report-Only" : "Content-Security-Policy";
        c.header(headerName, cspValue);
      }
    }
    await next();
  };
}

function createExpressStyleResponse(c) {
  let statusCode = 200;
  return {
    status(code) {
      statusCode = code;
      return this;
    },
    json(data) {
      return c.json(data, statusCode);
    }
  };
}
class IdentityServer {
  /**
   * Create Identity server
   * @param {Object} options - Server options
   */
  constructor(options = {}) {
    this.options = {
      port: options.port || 4e3,
      host: options.host || "0.0.0.0",
      verbose: options.verbose || false,
      issuer: options.issuer,
      oauth2Server: options.oauth2Server,
      sessionManager: options.sessionManager || null,
      usersResource: options.usersResource || null,
      identityPlugin: options.identityPlugin || null,
      cors: options.cors || {},
      security: options.security || {},
      logging: options.logging || {}
    };
    this.app = null;
    this.server = null;
    this.isRunning = false;
    this.initialized = false;
  }
  /**
   * Setup all routes
   * @private
   */
  _setupRoutes() {
    this.app.use("*", async (c, next) => {
      c.set("requestId", idGenerator());
      c.set("verbose", this.options.verbose);
      await next();
    });
    if (this.options.cors.enabled) {
      const corsMiddleware = createCorsMiddleware(this.options.cors);
      this.app.use("*", corsMiddleware);
    }
    if (this.options.security.enabled) {
      const securityMiddleware = createSecurityMiddleware(this.options.security);
      this.app.use("*", securityMiddleware);
    }
    if (this.options.logging.enabled) {
      const loggingMiddleware = createLoggingMiddleware(this.options.logging);
      this.app.use("*", loggingMiddleware);
    }
    this.app.get("/health", (c) => {
      const response = success({
        status: "ok",
        service: "identity-provider",
        uptime: process.uptime(),
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/live", (c) => {
      const response = success({
        status: "alive",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/health/ready", (c) => {
      const isReady = this.options.oauth2Server !== null;
      if (!isReady) {
        const response2 = error("Service not ready", {
          status: 503,
          code: "NOT_READY"
        });
        return c.json(response2, 503);
      }
      const response = success({
        status: "ready",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
      return c.json(response);
    });
    this.app.get("/", (c) => {
      return c.redirect("/.well-known/openid-configuration", 302);
    });
    this._setupOAuth2Routes();
    this._setupUIRoutes();
    this.app.onError((err, c) => {
      return errorHandler(err, c);
    });
    this.app.notFound((c) => {
      const response = error("Route not found", {
        status: 404,
        code: "NOT_FOUND",
        details: {
          path: c.req.path,
          method: c.req.method
        }
      });
      return c.json(response, 404);
    });
  }
  /**
   * Setup OAuth2/OIDC routes
   * @private
   */
  _setupOAuth2Routes() {
    const { oauth2Server } = this.options;
    if (!oauth2Server) {
      console.error("[Identity Server] OAuth2 Server not provided");
      return;
    }
    this.app.get("/.well-known/openid-configuration", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.discoveryHandler(c.req, res);
    });
    this.app.get("/.well-known/jwks.json", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.jwksHandler(c.req, res);
    });
    this.app.post("/oauth/token", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.tokenHandler(c.req, res);
    });
    this.app.get("/oauth/userinfo", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.userinfoHandler(c.req, res);
    });
    this.app.post("/oauth/introspect", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.introspectHandler(c.req, res);
    });
    this.app.get("/oauth/authorize", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.authorizeHandler(c.req, res);
    });
    this.app.post("/oauth/authorize", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.authorizePostHandler(c.req, res);
    });
    this.app.post("/oauth/register", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.registerClientHandler(c.req, res);
    });
    this.app.post("/oauth/revoke", async (c) => {
      const res = createExpressStyleResponse(c);
      return await oauth2Server.revokeHandler(c.req, res);
    });
    if (this.options.verbose) {
      console.log("[Identity Server] Mounted OAuth2/OIDC routes:");
      console.log("[Identity Server]   GET  /.well-known/openid-configuration (OIDC Discovery)");
      console.log("[Identity Server]   GET  /.well-known/jwks.json (JWKS)");
      console.log("[Identity Server]   GET  /oauth/authorize (Authorization UI)");
      console.log("[Identity Server]   POST /oauth/authorize (Process Login)");
      console.log("[Identity Server]   POST /oauth/token (Token)");
      console.log("[Identity Server]   GET  /oauth/userinfo (UserInfo)");
      console.log("[Identity Server]   POST /oauth/introspect (Introspection)");
      console.log("[Identity Server]   POST /oauth/register (Client Registration)");
      console.log("[Identity Server]   POST /oauth/revoke (Token Revocation)");
    }
  }
  /**
   * Setup UI routes (login, register, profile, etc.)
   * @private
   */
  async _setupUIRoutes() {
    const { sessionManager, identityPlugin } = this.options;
    if (!sessionManager || !identityPlugin) {
      if (this.options.verbose) {
        console.log("[Identity Server] SessionManager or IdentityPlugin not provided, skipping UI routes");
      }
      return;
    }
    try {
      const { registerUIRoutes } = await Promise.resolve().then(function () { return routes; });
      registerUIRoutes(this.app, identityPlugin);
      if (this.options.verbose) {
        console.log("[Identity Server] Mounted UI routes:");
        console.log("[Identity Server]   GET  /login (Login Form)");
        console.log("[Identity Server]   POST /login (Process Login)");
        console.log("[Identity Server]   GET  /register (Registration Form)");
        console.log("[Identity Server]   POST /register (Process Registration)");
        console.log("[Identity Server]   GET  /logout (Logout)");
        console.log("[Identity Server]   POST /logout (Logout)");
        console.log("[Identity Server]   GET  /forgot-password (Forgot Password Form)");
        console.log("[Identity Server]   POST /forgot-password (Process Forgot Password)");
        console.log("[Identity Server]   GET  /reset-password (Reset Password Form)");
        console.log("[Identity Server]   POST /reset-password (Process Password Reset)");
        console.log("[Identity Server]   GET  /profile (User Profile - Protected)");
        console.log("[Identity Server]   POST /profile/update (Update Profile)");
        console.log("[Identity Server]   POST /profile/change-password (Change Password)");
        console.log("[Identity Server]   POST /profile/logout-session (Logout Specific Session)");
        console.log("[Identity Server]   POST /profile/logout-all-sessions (Logout All Other Sessions)");
        console.log("[Identity Server]   GET  /admin (Admin Dashboard - Protected)");
        console.log("[Identity Server]   GET  /admin/clients (List OAuth2 Clients)");
        console.log("[Identity Server]   GET  /admin/clients/new (New Client Form)");
        console.log("[Identity Server]   POST /admin/clients/create (Create Client)");
        console.log("[Identity Server]   GET  /admin/clients/:id/edit (Edit Client Form)");
        console.log("[Identity Server]   POST /admin/clients/:id/update (Update Client)");
        console.log("[Identity Server]   POST /admin/clients/:id/delete (Delete Client)");
        console.log("[Identity Server]   POST /admin/clients/:id/rotate-secret (Rotate Client Secret)");
        console.log("[Identity Server]   POST /admin/clients/:id/toggle-active (Toggle Client Active)");
        console.log("[Identity Server]   GET  /admin/users (List Users - Protected)");
        console.log("[Identity Server]   GET  /admin/users/:id/edit (Edit User Form)");
        console.log("[Identity Server]   POST /admin/users/:id/update (Update User)");
        console.log("[Identity Server]   POST /admin/users/:id/delete (Delete User)");
        console.log("[Identity Server]   POST /admin/users/:id/change-status (Change User Status)");
        console.log("[Identity Server]   POST /admin/users/:id/verify-email (Mark Email Verified)");
        console.log("[Identity Server]   POST /admin/users/:id/reset-password (Send Password Reset)");
        console.log("[Identity Server]   POST /admin/users/:id/toggle-admin (Toggle Admin Role)");
        console.log("[Identity Server]   GET  /oauth/authorize (OAuth2 Consent Screen - Overrides OAuth2Server)");
        console.log("[Identity Server]   POST /oauth/consent (Process OAuth2 Consent Decision)");
        console.log("[Identity Server]   GET  /verify-email (Verify Email with Token)");
        console.log("[Identity Server]   POST /verify-email/resend (Resend Verification Email)");
      }
    } catch (error) {
      console.error("[Identity Server] Failed to setup UI routes:", error);
    }
  }
  /**
   * Start the server
   * @returns {Promise<void>}
   */
  async start() {
    if (this.isRunning) {
      console.warn("[Identity Server] Server is already running");
      return;
    }
    if (!this.initialized) {
      const { Hono } = await import('hono');
      const { serve } = await import('@hono/node-server');
      this.Hono = Hono;
      this.serve = serve;
      this.app = new Hono();
      this._setupRoutes();
      this.initialized = true;
    }
    const { port, host } = this.options;
    return new Promise((resolve, reject) => {
      try {
        this.server = this.serve({
          fetch: this.app.fetch,
          port,
          hostname: host
        }, (info) => {
          this.isRunning = true;
          console.log(`[Identity Server] Server listening on http://${info.address}:${info.port}`);
          console.log(`[Identity Server] Issuer: ${this.options.issuer}`);
          console.log(`[Identity Server] Discovery: ${this.options.issuer}/.well-known/openid-configuration`);
          resolve();
        });
      } catch (err) {
        reject(err);
      }
    });
  }
  /**
   * Stop the server
   * @returns {Promise<void>}
   */
  async stop() {
    if (!this.isRunning) {
      console.warn("[Identity Server] Server is not running");
      return;
    }
    if (this.server && typeof this.server.close === "function") {
      await new Promise((resolve) => {
        this.server.close(() => {
          this.isRunning = false;
          console.log("[Identity Server] Server stopped");
          resolve();
        });
      });
    } else {
      this.isRunning = false;
      console.log("[Identity Server] Server stopped");
    }
  }
  /**
   * Get server info
   * @returns {Object} Server information
   */
  getInfo() {
    return {
      isRunning: this.isRunning,
      port: this.options.port,
      host: this.options.host,
      issuer: this.options.issuer
    };
  }
  /**
   * Get Hono app instance
   * @returns {Hono} Hono app
   */
  getApp() {
    return this.app;
  }
}

var server = /*#__PURE__*/Object.freeze({
  __proto__: null,
  IdentityServer: IdentityServer
});

function sanitizeLabel(value) {
  if (typeof value !== "string") {
    value = String(value);
  }
  return value.replace(/\\/g, "\\\\").replace(/"/g, '\\"').replace(/\n/g, "\\n");
}
function sanitizeMetricName(name) {
  let sanitized = name.replace(/[^a-zA-Z0-9_]/g, "_");
  if (/^\d/.test(sanitized)) {
    sanitized = "_" + sanitized;
  }
  return sanitized;
}
function formatLabels(labels) {
  if (!labels || Object.keys(labels).length === 0) {
    return "";
  }
  const labelPairs = Object.entries(labels).map(([key, value]) => `${key}="${sanitizeLabel(value)}"`).join(",");
  return `{${labelPairs}}`;
}
function formatMetric(name, type, help, values) {
  const lines = [];
  lines.push(`# HELP ${name} ${help}`);
  lines.push(`# TYPE ${name} ${type}`);
  for (const { labels, value } of values) {
    const labelsStr = formatLabels(labels);
    lines.push(`${name}${labelsStr} ${value}`);
  }
  return lines.join("\n");
}
function formatPrometheusMetrics(metricsPlugin) {
  const lines = [];
  const metrics = metricsPlugin.metrics;
  const operationsTotalValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.count > 0) {
      operationsTotalValues.push({
        labels: { operation, resource: "_global" },
        value: data.count
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.count > 0) {
        operationsTotalValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: data.count
        });
      }
    }
  }
  if (operationsTotalValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operations_total",
      "counter",
      "Total number of operations by type and resource",
      operationsTotalValues
    ));
    lines.push("");
  }
  const durationValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.count > 0) {
      const avgSeconds = data.totalTime / data.count / 1e3;
      durationValues.push({
        labels: { operation, resource: "_global" },
        value: avgSeconds.toFixed(6)
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.count > 0) {
        const avgSeconds = data.totalTime / data.count / 1e3;
        durationValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: avgSeconds.toFixed(6)
        });
      }
    }
  }
  if (durationValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operation_duration_seconds",
      "gauge",
      "Average operation duration in seconds",
      durationValues
    ));
    lines.push("");
  }
  const errorsValues = [];
  for (const [operation, data] of Object.entries(metrics.operations)) {
    if (data.errors > 0) {
      errorsValues.push({
        labels: { operation, resource: "_global" },
        value: data.errors
      });
    }
  }
  for (const [resourceName, operations] of Object.entries(metrics.resources)) {
    for (const [operation, data] of Object.entries(operations)) {
      if (data.errors > 0) {
        errorsValues.push({
          labels: { operation, resource: sanitizeMetricName(resourceName) },
          value: data.errors
        });
      }
    }
  }
  if (errorsValues.length > 0) {
    lines.push(formatMetric(
      "s3db_operation_errors_total",
      "counter",
      "Total number of operation errors",
      errorsValues
    ));
    lines.push("");
  }
  const startTime = new Date(metrics.startTime);
  const uptimeSeconds = (Date.now() - startTime.getTime()) / 1e3;
  lines.push(formatMetric(
    "s3db_uptime_seconds",
    "gauge",
    "Process uptime in seconds",
    [{ labels: {}, value: uptimeSeconds.toFixed(2) }]
  ));
  lines.push("");
  const resourcesCount = Object.keys(metrics.resources).length;
  lines.push(formatMetric(
    "s3db_resources_total",
    "gauge",
    "Total number of tracked resources",
    [{ labels: {}, value: resourcesCount }]
  ));
  lines.push("");
  const nodeVersion = process.version || "unknown";
  const s3dbVersion = "1.0.0";
  lines.push(formatMetric(
    "s3db_info",
    "gauge",
    "Build and runtime information",
    [{
      labels: {
        version: s3dbVersion,
        node_version: nodeVersion
      },
      value: 1
    }]
  ));
  return lines.join("\n") + "\n";
}

var prometheusFormatter = /*#__PURE__*/Object.freeze({
  __proto__: null,
  formatPrometheusMetrics: formatPrometheusMetrics
});

function silhouetteScore(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const k = centroids.length;
  const n = vectors.length;
  const clusters = Array(k).fill(null).map(() => []);
  vectors.forEach((vector, i) => {
    clusters[assignments[i]].push(i);
  });
  let totalScore = 0;
  let validPoints = 0;
  if (clusters.every((c) => c.length <= 1)) {
    return 0;
  }
  for (let i = 0; i < n; i++) {
    const clusterIdx = assignments[i];
    const cluster = clusters[clusterIdx];
    if (cluster.length === 1) continue;
    let a = 0;
    for (const j of cluster) {
      if (i !== j) {
        a += distanceFn(vectors[i], vectors[j]);
      }
    }
    a /= cluster.length - 1;
    let b = Infinity;
    for (let otherCluster = 0; otherCluster < k; otherCluster++) {
      if (otherCluster === clusterIdx) continue;
      const otherPoints = clusters[otherCluster];
      if (otherPoints.length === 0) continue;
      let avgDist = 0;
      for (const j of otherPoints) {
        avgDist += distanceFn(vectors[i], vectors[j]);
      }
      avgDist /= otherPoints.length;
      b = Math.min(b, avgDist);
    }
    if (b === Infinity) continue;
    const maxAB = Math.max(a, b);
    const s = maxAB === 0 ? 0 : (b - a) / maxAB;
    totalScore += s;
    validPoints++;
  }
  return validPoints > 0 ? totalScore / validPoints : 0;
}
function daviesBouldinIndex(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const k = centroids.length;
  const scatters = new Array(k).fill(0);
  const clusterCounts = new Array(k).fill(0);
  vectors.forEach((vector, i) => {
    const cluster = assignments[i];
    scatters[cluster] += distanceFn(vector, centroids[cluster]);
    clusterCounts[cluster]++;
  });
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] > 0) {
      scatters[i] /= clusterCounts[i];
    }
  }
  let dbIndex = 0;
  let validClusters = 0;
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] === 0) continue;
    let maxRatio = 0;
    for (let j = 0; j < k; j++) {
      if (i === j || clusterCounts[j] === 0) continue;
      const centroidDist = distanceFn(centroids[i], centroids[j]);
      if (centroidDist === 0) continue;
      const ratio = (scatters[i] + scatters[j]) / centroidDist;
      maxRatio = Math.max(maxRatio, ratio);
    }
    dbIndex += maxRatio;
    validClusters++;
  }
  return validClusters > 0 ? dbIndex / validClusters : 0;
}
function calinskiHarabaszIndex(vectors, assignments, centroids, distanceFn = euclideanDistance) {
  const n = vectors.length;
  const k = centroids.length;
  if (k === 1 || k === n) return 0;
  const dimensions = vectors[0].length;
  const overallCentroid = new Array(dimensions).fill(0);
  vectors.forEach((vector) => {
    vector.forEach((val, dim) => {
      overallCentroid[dim] += val;
    });
  });
  overallCentroid.forEach((val, dim, arr) => {
    arr[dim] = val / n;
  });
  const clusterCounts = new Array(k).fill(0);
  vectors.forEach((vector, i) => {
    clusterCounts[assignments[i]]++;
  });
  let bgss = 0;
  for (let i = 0; i < k; i++) {
    if (clusterCounts[i] === 0) continue;
    const dist = distanceFn(centroids[i], overallCentroid);
    bgss += clusterCounts[i] * dist * dist;
  }
  let wcss = 0;
  vectors.forEach((vector, i) => {
    const cluster = assignments[i];
    const dist = distanceFn(vector, centroids[cluster]);
    wcss += dist * dist;
  });
  if (wcss === 0) return 0;
  return bgss / (k - 1) / (wcss / (n - k));
}
async function gapStatistic(vectors, assignments, centroids, distanceFn = euclideanDistance, nReferences = 10) {
  const n = vectors.length;
  const k = centroids.length;
  const dimensions = vectors[0].length;
  let wk = 0;
  vectors.forEach((vector, i) => {
    const dist = distanceFn(vector, centroids[assignments[i]]);
    wk += dist * dist;
  });
  wk = Math.log(wk + 1e-10);
  const referenceWks = [];
  const mins = new Array(dimensions).fill(Infinity);
  const maxs = new Array(dimensions).fill(-Infinity);
  vectors.forEach((vector) => {
    vector.forEach((val, dim) => {
      mins[dim] = Math.min(mins[dim], val);
      maxs[dim] = Math.max(maxs[dim], val);
    });
  });
  for (let ref = 0; ref < nReferences; ref++) {
    const refVectors = [];
    for (let i = 0; i < n; i++) {
      const refVector = new Array(dimensions);
      for (let dim = 0; dim < dimensions; dim++) {
        refVector[dim] = mins[dim] + Math.random() * (maxs[dim] - mins[dim]);
      }
      refVectors.push(refVector);
    }
    const refResult = kmeans(refVectors, k, { maxIterations: 50, distanceFn });
    let refWk = 0;
    refVectors.forEach((vector, i) => {
      const dist = distanceFn(vector, refResult.centroids[refResult.assignments[i]]);
      refWk += dist * dist;
    });
    referenceWks.push(Math.log(refWk + 1e-10));
  }
  const expectedWk = referenceWks.reduce((a, b) => a + b, 0) / nReferences;
  const gap = expectedWk - wk;
  const sdk = Math.sqrt(
    referenceWks.reduce((sum, wk2) => sum + Math.pow(wk2 - expectedWk, 2), 0) / nReferences
  );
  const sk = sdk * Math.sqrt(1 + 1 / nReferences);
  return { gap, sk, expectedWk, actualWk: wk };
}
function clusteringStability(vectors, k, options = {}) {
  const {
    nRuns = 10,
    distanceFn = euclideanDistance,
    ...kmeansOptions
  } = options;
  const inertias = [];
  const allAssignments = [];
  for (let run = 0; run < nRuns; run++) {
    const result = kmeans(vectors, k, {
      ...kmeansOptions,
      distanceFn,
      seed: run
      // Different seed for each run
    });
    inertias.push(result.inertia);
    allAssignments.push(result.assignments);
  }
  const assignmentSimilarities = [];
  for (let i = 0; i < nRuns - 1; i++) {
    for (let j = i + 1; j < nRuns; j++) {
      const similarity = calculateAssignmentSimilarity(allAssignments[i], allAssignments[j]);
      assignmentSimilarities.push(similarity);
    }
  }
  const avgInertia = inertias.reduce((a, b) => a + b, 0) / nRuns;
  const stdInertia = Math.sqrt(
    inertias.reduce((sum, val) => sum + Math.pow(val - avgInertia, 2), 0) / nRuns
  );
  const avgSimilarity = assignmentSimilarities.length > 0 ? assignmentSimilarities.reduce((a, b) => a + b, 0) / assignmentSimilarities.length : 1;
  return {
    avgInertia,
    stdInertia,
    cvInertia: avgInertia !== 0 ? stdInertia / avgInertia : 0,
    // Coefficient of variation
    avgSimilarity,
    stability: avgSimilarity
    // Higher is more stable
  };
}
function calculateAssignmentSimilarity(assignments1, assignments2) {
  const n = assignments1.length;
  let matches = 0;
  for (let i = 0; i < n; i++) {
    for (let j = i + 1; j < n; j++) {
      const sameCluster1 = assignments1[i] === assignments1[j];
      const sameCluster2 = assignments2[i] === assignments2[j];
      if (sameCluster1 === sameCluster2) {
        matches++;
      }
    }
  }
  const totalPairs = n * (n - 1) / 2;
  return totalPairs > 0 ? matches / totalPairs : 1;
}

var metrics = /*#__PURE__*/Object.freeze({
  __proto__: null,
  calinskiHarabaszIndex: calinskiHarabaszIndex,
  clusteringStability: clusteringStability,
  daviesBouldinIndex: daviesBouldinIndex,
  gapStatistic: gapStatistic,
  silhouetteScore: silhouetteScore
});

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var nodemailer$2 = {};

var shared = {exports: {}};

var fetch$1 = {exports: {}};

var cookies;
var hasRequiredCookies;

function requireCookies () {
	if (hasRequiredCookies) return cookies;
	hasRequiredCookies = 1;

	// module to handle cookies

	const urllib = require$$0$1;

	const SESSION_TIMEOUT = 1800; // 30 min

	/**
	 * Creates a biskviit cookie jar for managing cookie values in memory
	 *
	 * @constructor
	 * @param {Object} [options] Optional options object
	 */
	class Cookies {
	    constructor(options) {
	        this.options = options || {};
	        this.cookies = [];
	    }

	    /**
	     * Stores a cookie string to the cookie storage
	     *
	     * @param {String} cookieStr Value from the 'Set-Cookie:' header
	     * @param {String} url Current URL
	     */
	    set(cookieStr, url) {
	        let urlparts = urllib.parse(url || '');
	        let cookie = this.parse(cookieStr);
	        let domain;

	        if (cookie.domain) {
	            domain = cookie.domain.replace(/^\./, '');

	            // do not allow cross origin cookies
	            if (
	                // can't be valid if the requested domain is shorter than current hostname
	                urlparts.hostname.length < domain.length ||
	                // prefix domains with dot to be sure that partial matches are not used
	                ('.' + urlparts.hostname).substr(-domain.length + 1) !== '.' + domain
	            ) {
	                cookie.domain = urlparts.hostname;
	            }
	        } else {
	            cookie.domain = urlparts.hostname;
	        }

	        if (!cookie.path) {
	            cookie.path = this.getPath(urlparts.pathname);
	        }

	        // if no expire date, then use sessionTimeout value
	        if (!cookie.expires) {
	            cookie.expires = new Date(Date.now() + (Number(this.options.sessionTimeout || SESSION_TIMEOUT) || SESSION_TIMEOUT) * 1000);
	        }

	        return this.add(cookie);
	    }

	    /**
	     * Returns cookie string for the 'Cookie:' header.
	     *
	     * @param {String} url URL to check for
	     * @returns {String} Cookie header or empty string if no matches were found
	     */
	    get(url) {
	        return this.list(url)
	            .map(cookie => cookie.name + '=' + cookie.value)
	            .join('; ');
	    }

	    /**
	     * Lists all valied cookie objects for the specified URL
	     *
	     * @param {String} url URL to check for
	     * @returns {Array} An array of cookie objects
	     */
	    list(url) {
	        let result = [];
	        let i;
	        let cookie;

	        for (i = this.cookies.length - 1; i >= 0; i--) {
	            cookie = this.cookies[i];

	            if (this.isExpired(cookie)) {
	                this.cookies.splice(i, i);
	                continue;
	            }

	            if (this.match(cookie, url)) {
	                result.unshift(cookie);
	            }
	        }

	        return result;
	    }

	    /**
	     * Parses cookie string from the 'Set-Cookie:' header
	     *
	     * @param {String} cookieStr String from the 'Set-Cookie:' header
	     * @returns {Object} Cookie object
	     */
	    parse(cookieStr) {
	        let cookie = {};

	        (cookieStr || '')
	            .toString()
	            .split(';')
	            .forEach(cookiePart => {
	                let valueParts = cookiePart.split('=');
	                let key = valueParts.shift().trim().toLowerCase();
	                let value = valueParts.join('=').trim();
	                let domain;

	                if (!key) {
	                    // skip empty parts
	                    return;
	                }

	                switch (key) {
	                    case 'expires':
	                        value = new Date(value);
	                        // ignore date if can not parse it
	                        if (value.toString() !== 'Invalid Date') {
	                            cookie.expires = value;
	                        }
	                        break;

	                    case 'path':
	                        cookie.path = value;
	                        break;

	                    case 'domain':
	                        domain = value.toLowerCase();
	                        if (domain.length && domain.charAt(0) !== '.') {
	                            domain = '.' + domain; // ensure preceeding dot for user set domains
	                        }
	                        cookie.domain = domain;
	                        break;

	                    case 'max-age':
	                        cookie.expires = new Date(Date.now() + (Number(value) || 0) * 1000);
	                        break;

	                    case 'secure':
	                        cookie.secure = true;
	                        break;

	                    case 'httponly':
	                        cookie.httponly = true;
	                        break;

	                    default:
	                        if (!cookie.name) {
	                            cookie.name = key;
	                            cookie.value = value;
	                        }
	                }
	            });

	        return cookie;
	    }

	    /**
	     * Checks if a cookie object is valid for a specified URL
	     *
	     * @param {Object} cookie Cookie object
	     * @param {String} url URL to check for
	     * @returns {Boolean} true if cookie is valid for specifiec URL
	     */
	    match(cookie, url) {
	        let urlparts = urllib.parse(url || '');

	        // check if hostname matches
	        // .foo.com also matches subdomains, foo.com does not
	        if (
	            urlparts.hostname !== cookie.domain &&
	            (cookie.domain.charAt(0) !== '.' || ('.' + urlparts.hostname).substr(-cookie.domain.length) !== cookie.domain)
	        ) {
	            return false;
	        }

	        // check if path matches
	        let path = this.getPath(urlparts.pathname);
	        if (path.substr(0, cookie.path.length) !== cookie.path) {
	            return false;
	        }

	        // check secure argument
	        if (cookie.secure && urlparts.protocol !== 'https:') {
	            return false;
	        }

	        return true;
	    }

	    /**
	     * Adds (or updates/removes if needed) a cookie object to the cookie storage
	     *
	     * @param {Object} cookie Cookie value to be stored
	     */
	    add(cookie) {
	        let i;
	        let len;

	        // nothing to do here
	        if (!cookie || !cookie.name) {
	            return false;
	        }

	        // overwrite if has same params
	        for (i = 0, len = this.cookies.length; i < len; i++) {
	            if (this.compare(this.cookies[i], cookie)) {
	                // check if the cookie needs to be removed instead
	                if (this.isExpired(cookie)) {
	                    this.cookies.splice(i, 1); // remove expired/unset cookie
	                    return false;
	                }

	                this.cookies[i] = cookie;
	                return true;
	            }
	        }

	        // add as new if not already expired
	        if (!this.isExpired(cookie)) {
	            this.cookies.push(cookie);
	        }

	        return true;
	    }

	    /**
	     * Checks if two cookie objects are the same
	     *
	     * @param {Object} a Cookie to check against
	     * @param {Object} b Cookie to check against
	     * @returns {Boolean} True, if the cookies are the same
	     */
	    compare(a, b) {
	        return a.name === b.name && a.path === b.path && a.domain === b.domain && a.secure === b.secure && a.httponly === a.httponly;
	    }

	    /**
	     * Checks if a cookie is expired
	     *
	     * @param {Object} cookie Cookie object to check against
	     * @returns {Boolean} True, if the cookie is expired
	     */
	    isExpired(cookie) {
	        return (cookie.expires && cookie.expires < new Date()) || !cookie.value;
	    }

	    /**
	     * Returns normalized cookie path for an URL path argument
	     *
	     * @param {String} pathname
	     * @returns {String} Normalized path
	     */
	    getPath(pathname) {
	        let path = (pathname || '/').split('/');
	        path.pop(); // remove filename part
	        path = path.join('/').trim();

	        // ensure path prefix /
	        if (path.charAt(0) !== '/') {
	            path = '/' + path;
	        }

	        // ensure path suffix /
	        if (path.substr(-1) !== '/') {
	            path += '/';
	        }

	        return path;
	    }
	}

	cookies = Cookies;
	return cookies;
}

var name = "nodemailer";
var version = "7.0.10";
var homepage = "https://nodemailer.com/";
var require$$9 = {
	name: name,
	version: version,
	homepage: homepage};

var hasRequiredFetch;

function requireFetch () {
	if (hasRequiredFetch) return fetch$1.exports;
	hasRequiredFetch = 1;

	const http = require$$0$3;
	const https = require$$1;
	const urllib = require$$0$1;
	const zlib = require$$3;
	const PassThrough = require$$0$2.PassThrough;
	const Cookies = requireCookies();
	const packageData = require$$9;
	const net = require$$7;

	const MAX_REDIRECTS = 5;

	fetch$1.exports = function (url, options) {
	    return nmfetch(url, options);
	};

	fetch$1.exports.Cookies = Cookies;

	function nmfetch(url, options) {
	    options = options || {};

	    options.fetchRes = options.fetchRes || new PassThrough();
	    options.cookies = options.cookies || new Cookies();
	    options.redirects = options.redirects || 0;
	    options.maxRedirects = isNaN(options.maxRedirects) ? MAX_REDIRECTS : options.maxRedirects;

	    if (options.cookie) {
	        [].concat(options.cookie || []).forEach(cookie => {
	            options.cookies.set(cookie, url);
	        });
	        options.cookie = false;
	    }

	    let fetchRes = options.fetchRes;
	    let parsed = urllib.parse(url);
	    let method = (options.method || '').toString().trim().toUpperCase() || 'GET';
	    let finished = false;
	    let cookies;
	    let body;

	    let handler = parsed.protocol === 'https:' ? https : http;

	    let headers = {
	        'accept-encoding': 'gzip,deflate',
	        'user-agent': 'nodemailer/' + packageData.version
	    };

	    Object.keys(options.headers || {}).forEach(key => {
	        headers[key.toLowerCase().trim()] = options.headers[key];
	    });

	    if (options.userAgent) {
	        headers['user-agent'] = options.userAgent;
	    }

	    if (parsed.auth) {
	        headers.Authorization = 'Basic ' + Buffer.from(parsed.auth).toString('base64');
	    }

	    if ((cookies = options.cookies.get(url))) {
	        headers.cookie = cookies;
	    }

	    if (options.body) {
	        if (options.contentType !== false) {
	            headers['Content-Type'] = options.contentType || 'application/x-www-form-urlencoded';
	        }

	        if (typeof options.body.pipe === 'function') {
	            // it's a stream
	            headers['Transfer-Encoding'] = 'chunked';
	            body = options.body;
	            body.on('error', err => {
	                if (finished) {
	                    return;
	                }
	                finished = true;
	                err.type = 'FETCH';
	                err.sourceUrl = url;
	                fetchRes.emit('error', err);
	            });
	        } else {
	            if (options.body instanceof Buffer) {
	                body = options.body;
	            } else if (typeof options.body === 'object') {
	                try {
	                    // encodeURIComponent can fail on invalid input (partial emoji etc.)
	                    body = Buffer.from(
	                        Object.keys(options.body)
	                            .map(key => {
	                                let value = options.body[key].toString().trim();
	                                return encodeURIComponent(key) + '=' + encodeURIComponent(value);
	                            })
	                            .join('&')
	                    );
	                } catch (E) {
	                    if (finished) {
	                        return;
	                    }
	                    finished = true;
	                    E.type = 'FETCH';
	                    E.sourceUrl = url;
	                    fetchRes.emit('error', E);
	                    return;
	                }
	            } else {
	                body = Buffer.from(options.body.toString().trim());
	            }

	            headers['Content-Type'] = options.contentType || 'application/x-www-form-urlencoded';
	            headers['Content-Length'] = body.length;
	        }
	        // if method is not provided, use POST instead of GET
	        method = (options.method || '').toString().trim().toUpperCase() || 'POST';
	    }

	    let req;
	    let reqOptions = {
	        method,
	        host: parsed.hostname,
	        path: parsed.path,
	        port: parsed.port ? parsed.port : parsed.protocol === 'https:' ? 443 : 80,
	        headers,
	        rejectUnauthorized: false,
	        agent: false
	    };

	    if (options.tls) {
	        Object.keys(options.tls).forEach(key => {
	            reqOptions[key] = options.tls[key];
	        });
	    }

	    if (
	        parsed.protocol === 'https:' &&
	        parsed.hostname &&
	        parsed.hostname !== reqOptions.host &&
	        !net.isIP(parsed.hostname) &&
	        !reqOptions.servername
	    ) {
	        reqOptions.servername = parsed.hostname;
	    }

	    try {
	        req = handler.request(reqOptions);
	    } catch (E) {
	        finished = true;
	        setImmediate(() => {
	            E.type = 'FETCH';
	            E.sourceUrl = url;
	            fetchRes.emit('error', E);
	        });
	        return fetchRes;
	    }

	    if (options.timeout) {
	        req.setTimeout(options.timeout, () => {
	            if (finished) {
	                return;
	            }
	            finished = true;
	            req.abort();
	            let err = new Error('Request Timeout');
	            err.type = 'FETCH';
	            err.sourceUrl = url;
	            fetchRes.emit('error', err);
	        });
	    }

	    req.on('error', err => {
	        if (finished) {
	            return;
	        }
	        finished = true;
	        err.type = 'FETCH';
	        err.sourceUrl = url;
	        fetchRes.emit('error', err);
	    });

	    req.on('response', res => {
	        let inflate;

	        if (finished) {
	            return;
	        }

	        switch (res.headers['content-encoding']) {
	            case 'gzip':
	            case 'deflate':
	                inflate = zlib.createUnzip();
	                break;
	        }

	        if (res.headers['set-cookie']) {
	            [].concat(res.headers['set-cookie'] || []).forEach(cookie => {
	                options.cookies.set(cookie, url);
	            });
	        }

	        if ([301, 302, 303, 307, 308].includes(res.statusCode) && res.headers.location) {
	            // redirect
	            options.redirects++;
	            if (options.redirects > options.maxRedirects) {
	                finished = true;
	                let err = new Error('Maximum redirect count exceeded');
	                err.type = 'FETCH';
	                err.sourceUrl = url;
	                fetchRes.emit('error', err);
	                req.abort();
	                return;
	            }
	            // redirect does not include POST body
	            options.method = 'GET';
	            options.body = false;
	            return nmfetch(urllib.resolve(url, res.headers.location), options);
	        }

	        fetchRes.statusCode = res.statusCode;
	        fetchRes.headers = res.headers;

	        if (res.statusCode >= 300 && !options.allowErrorResponse) {
	            finished = true;
	            let err = new Error('Invalid status code ' + res.statusCode);
	            err.type = 'FETCH';
	            err.sourceUrl = url;
	            fetchRes.emit('error', err);
	            req.abort();
	            return;
	        }

	        res.on('error', err => {
	            if (finished) {
	                return;
	            }
	            finished = true;
	            err.type = 'FETCH';
	            err.sourceUrl = url;
	            fetchRes.emit('error', err);
	            req.abort();
	        });

	        if (inflate) {
	            res.pipe(inflate).pipe(fetchRes);
	            inflate.on('error', err => {
	                if (finished) {
	                    return;
	                }
	                finished = true;
	                err.type = 'FETCH';
	                err.sourceUrl = url;
	                fetchRes.emit('error', err);
	                req.abort();
	            });
	        } else {
	            res.pipe(fetchRes);
	        }
	    });

	    setImmediate(() => {
	        if (body) {
	            try {
	                if (typeof body.pipe === 'function') {
	                    return body.pipe(req);
	                } else {
	                    req.write(body);
	                }
	            } catch (err) {
	                finished = true;
	                err.type = 'FETCH';
	                err.sourceUrl = url;
	                fetchRes.emit('error', err);
	                return;
	            }
	        }
	        req.end();
	    });

	    return fetchRes;
	}
	return fetch$1.exports;
}

/* eslint no-console: 0 */

var hasRequiredShared;

function requireShared () {
	if (hasRequiredShared) return shared.exports;
	hasRequiredShared = 1;
	(function (module) {

		const urllib = require$$0$1;
		const util = require$$1$1;
		const fs = fs$1;
		const nmfetch = requireFetch();
		const dns = require$$4;
		const net = require$$7;
		const os$1 = os;

		const DNS_TTL = 5 * 60 * 1000;
		const CACHE_CLEANUP_INTERVAL = 30 * 1000; // Minimum 30 seconds between cleanups
		const MAX_CACHE_SIZE = 1000; // Maximum number of entries in cache

		let lastCacheCleanup = 0;
		module.exports._lastCacheCleanup = () => lastCacheCleanup;
		module.exports._resetCacheCleanup = () => {
		    lastCacheCleanup = 0;
		};

		let networkInterfaces;
		try {
		    networkInterfaces = os$1.networkInterfaces();
		} catch (_err) {
		    // fails on some systems
		}

		module.exports.networkInterfaces = networkInterfaces;

		const isFamilySupported = (family, allowInternal) => {
		    let networkInterfaces = module.exports.networkInterfaces;
		    if (!networkInterfaces) {
		        // hope for the best
		        return true;
		    }

		    const familySupported =
		        // crux that replaces Object.values(networkInterfaces) as Object.values is not supported in nodejs v6
		        Object.keys(networkInterfaces)
		            .map(key => networkInterfaces[key])
		            // crux that replaces .flat() as it is not supported in older Node versions (v10 and older)
		            .reduce((acc, val) => acc.concat(val), [])
		            .filter(i => !i.internal || allowInternal)
		            .filter(i => i.family === 'IPv' + family || i.family === family).length > 0;

		    return familySupported;
		};

		const resolver = (family, hostname, options, callback) => {
		    options = options || {};
		    const familySupported = isFamilySupported(family, options.allowInternalNetworkInterfaces);

		    if (!familySupported) {
		        return callback(null, []);
		    }

		    const resolver = dns.Resolver ? new dns.Resolver(options) : dns;
		    resolver['resolve' + family](hostname, (err, addresses) => {
		        if (err) {
		            switch (err.code) {
		                case dns.NODATA:
		                case dns.NOTFOUND:
		                case dns.NOTIMP:
		                case dns.SERVFAIL:
		                case dns.CONNREFUSED:
		                case dns.REFUSED:
		                case 'EAI_AGAIN':
		                    return callback(null, []);
		            }
		            return callback(err);
		        }
		        return callback(null, Array.isArray(addresses) ? addresses : [].concat(addresses || []));
		    });
		};

		const dnsCache = (module.exports.dnsCache = new Map());

		const formatDNSValue = (value, extra) => {
		    if (!value) {
		        return Object.assign({}, extra || {});
		    }

		    return Object.assign(
		        {
		            servername: value.servername,
		            host:
		                !value.addresses || !value.addresses.length
		                    ? null
		                    : value.addresses.length === 1
		                      ? value.addresses[0]
		                      : value.addresses[Math.floor(Math.random() * value.addresses.length)]
		        },
		        extra || {}
		    );
		};

		module.exports.resolveHostname = (options, callback) => {
		    options = options || {};

		    if (!options.host && options.servername) {
		        options.host = options.servername;
		    }

		    if (!options.host || net.isIP(options.host)) {
		        // nothing to do here
		        let value = {
		            addresses: [options.host],
		            servername: options.servername || false
		        };
		        return callback(
		            null,
		            formatDNSValue(value, {
		                cached: false
		            })
		        );
		    }

		    let cached;
		    if (dnsCache.has(options.host)) {
		        cached = dnsCache.get(options.host);

		        // Lazy cleanup with time throttling
		        const now = Date.now();
		        if (now - lastCacheCleanup > CACHE_CLEANUP_INTERVAL) {
		            lastCacheCleanup = now;

		            // Clean up expired entries
		            for (const [host, entry] of dnsCache.entries()) {
		                if (entry.expires && entry.expires < now) {
		                    dnsCache.delete(host);
		                }
		            }

		            // If cache is still too large, remove oldest entries
		            if (dnsCache.size > MAX_CACHE_SIZE) {
		                const toDelete = Math.floor(MAX_CACHE_SIZE * 0.1); // Remove 10% of entries
		                const keys = Array.from(dnsCache.keys()).slice(0, toDelete);
		                keys.forEach(key => dnsCache.delete(key));
		            }
		        }

		        if (!cached.expires || cached.expires >= now) {
		            return callback(
		                null,
		                formatDNSValue(cached.value, {
		                    cached: true
		                })
		            );
		        }
		    }

		    resolver(4, options.host, options, (err, addresses) => {
		        if (err) {
		            if (cached) {
		                dnsCache.set(options.host, {
		                    value: cached.value,
		                    expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                });

		                return callback(
		                    null,
		                    formatDNSValue(cached.value, {
		                        cached: true,
		                        error: err
		                    })
		                );
		            }
		            return callback(err);
		        }

		        if (addresses && addresses.length) {
		            let value = {
		                addresses,
		                servername: options.servername || options.host
		            };

		            dnsCache.set(options.host, {
		                value,
		                expires: Date.now() + (options.dnsTtl || DNS_TTL)
		            });

		            return callback(
		                null,
		                formatDNSValue(value, {
		                    cached: false
		                })
		            );
		        }

		        resolver(6, options.host, options, (err, addresses) => {
		            if (err) {
		                if (cached) {
		                    dnsCache.set(options.host, {
		                        value: cached.value,
		                        expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                    });

		                    return callback(
		                        null,
		                        formatDNSValue(cached.value, {
		                            cached: true,
		                            error: err
		                        })
		                    );
		                }
		                return callback(err);
		            }

		            if (addresses && addresses.length) {
		                let value = {
		                    addresses,
		                    servername: options.servername || options.host
		                };

		                dnsCache.set(options.host, {
		                    value,
		                    expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                });

		                return callback(
		                    null,
		                    formatDNSValue(value, {
		                        cached: false
		                    })
		                );
		            }

		            try {
		                dns.lookup(options.host, { all: true }, (err, addresses) => {
		                    if (err) {
		                        if (cached) {
		                            dnsCache.set(options.host, {
		                                value: cached.value,
		                                expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                            });

		                            return callback(
		                                null,
		                                formatDNSValue(cached.value, {
		                                    cached: true,
		                                    error: err
		                                })
		                            );
		                        }
		                        return callback(err);
		                    }

		                    let address = addresses
		                        ? addresses
		                              .filter(addr => isFamilySupported(addr.family))
		                              .map(addr => addr.address)
		                              .shift()
		                        : false;

		                    if (addresses && addresses.length && !address) {
		                        // there are addresses but none can be used
		                        console.warn(`Failed to resolve IPv${addresses[0].family} addresses with current network`);
		                    }

		                    if (!address && cached) {
		                        // nothing was found, fallback to cached value
		                        return callback(
		                            null,
		                            formatDNSValue(cached.value, {
		                                cached: true
		                            })
		                        );
		                    }

		                    let value = {
		                        addresses: address ? [address] : [options.host],
		                        servername: options.servername || options.host
		                    };

		                    dnsCache.set(options.host, {
		                        value,
		                        expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                    });

		                    return callback(
		                        null,
		                        formatDNSValue(value, {
		                            cached: false
		                        })
		                    );
		                });
		            } catch (_err) {
		                if (cached) {
		                    dnsCache.set(options.host, {
		                        value: cached.value,
		                        expires: Date.now() + (options.dnsTtl || DNS_TTL)
		                    });

		                    return callback(
		                        null,
		                        formatDNSValue(cached.value, {
		                            cached: true,
		                            error: err
		                        })
		                    );
		                }
		                return callback(err);
		            }
		        });
		    });
		};
		/**
		 * Parses connection url to a structured configuration object
		 *
		 * @param {String} str Connection url
		 * @return {Object} Configuration object
		 */
		module.exports.parseConnectionUrl = str => {
		    str = str || '';
		    let options = {};

		    [urllib.parse(str, true)].forEach(url => {
		        let auth;

		        switch (url.protocol) {
		            case 'smtp:':
		                options.secure = false;
		                break;
		            case 'smtps:':
		                options.secure = true;
		                break;
		            case 'direct:':
		                options.direct = true;
		                break;
		        }

		        if (!isNaN(url.port) && Number(url.port)) {
		            options.port = Number(url.port);
		        }

		        if (url.hostname) {
		            options.host = url.hostname;
		        }

		        if (url.auth) {
		            auth = url.auth.split(':');

		            if (!options.auth) {
		                options.auth = {};
		            }

		            options.auth.user = auth.shift();
		            options.auth.pass = auth.join(':');
		        }

		        Object.keys(url.query || {}).forEach(key => {
		            let obj = options;
		            let lKey = key;
		            let value = url.query[key];

		            if (!isNaN(value)) {
		                value = Number(value);
		            }

		            switch (value) {
		                case 'true':
		                    value = true;
		                    break;
		                case 'false':
		                    value = false;
		                    break;
		            }

		            // tls is nested object
		            if (key.indexOf('tls.') === 0) {
		                lKey = key.substr(4);
		                if (!options.tls) {
		                    options.tls = {};
		                }
		                obj = options.tls;
		            } else if (key.indexOf('.') >= 0) {
		                // ignore nested properties besides tls
		                return;
		            }

		            if (!(lKey in obj)) {
		                obj[lKey] = value;
		            }
		        });
		    });

		    return options;
		};

		module.exports._logFunc = (logger, level, defaults, data, message, ...args) => {
		    let entry = {};

		    Object.keys(defaults || {}).forEach(key => {
		        if (key !== 'level') {
		            entry[key] = defaults[key];
		        }
		    });

		    Object.keys(data || {}).forEach(key => {
		        if (key !== 'level') {
		            entry[key] = data[key];
		        }
		    });

		    logger[level](entry, message, ...args);
		};

		/**
		 * Returns a bunyan-compatible logger interface. Uses either provided logger or
		 * creates a default console logger
		 *
		 * @param {Object} [options] Options object that might include 'logger' value
		 * @return {Object} bunyan compatible logger
		 */
		module.exports.getLogger = (options, defaults) => {
		    options = options || {};

		    let response = {};
		    let levels = ['trace', 'debug', 'info', 'warn', 'error', 'fatal'];

		    if (!options.logger) {
		        // use vanity logger
		        levels.forEach(level => {
		            response[level] = () => false;
		        });
		        return response;
		    }

		    let logger = options.logger;

		    if (options.logger === true) {
		        // create console logger
		        logger = createDefaultLogger(levels);
		    }

		    levels.forEach(level => {
		        response[level] = (data, message, ...args) => {
		            module.exports._logFunc(logger, level, defaults, data, message, ...args);
		        };
		    });

		    return response;
		};

		/**
		 * Wrapper for creating a callback that either resolves or rejects a promise
		 * based on input
		 *
		 * @param {Function} resolve Function to run if callback is called
		 * @param {Function} reject Function to run if callback ends with an error
		 */
		module.exports.callbackPromise = (resolve, reject) =>
		    function () {
		        let args = Array.from(arguments);
		        let err = args.shift();
		        if (err) {
		            reject(err);
		        } else {
		            resolve(...args);
		        }
		    };

		module.exports.parseDataURI = uri => {
		    if (typeof uri !== 'string') {
		        return null;
		    }

		    // Early return for non-data URIs to avoid unnecessary processing
		    if (!uri.startsWith('data:')) {
		        return null;
		    }

		    // Find the first comma safely - this prevents ReDoS
		    const commaPos = uri.indexOf(',');
		    if (commaPos === -1) {
		        return null;
		    }

		    const data = uri.substring(commaPos + 1);
		    const metaStr = uri.substring('data:'.length, commaPos);

		    let encoding;
		    const metaEntries = metaStr.split(';');

		    if (metaEntries.length > 0) {
		        const lastEntry = metaEntries[metaEntries.length - 1].toLowerCase().trim();
		        // Only recognize valid encoding types to prevent manipulation
		        if (['base64', 'utf8', 'utf-8'].includes(lastEntry) && lastEntry.indexOf('=') === -1) {
		            encoding = lastEntry;
		            metaEntries.pop();
		        }
		    }

		    const contentType = metaEntries.length > 0 ? metaEntries.shift() : 'application/octet-stream';
		    const params = {};

		    for (let i = 0; i < metaEntries.length; i++) {
		        const entry = metaEntries[i];
		        const sepPos = entry.indexOf('=');
		        if (sepPos > 0) {
		            // Ensure there's a key before the '='
		            const key = entry.substring(0, sepPos).trim();
		            const value = entry.substring(sepPos + 1).trim();
		            if (key) {
		                params[key] = value;
		            }
		        }
		    }

		    // Decode data based on encoding with proper error handling
		    let bufferData;
		    try {
		        if (encoding === 'base64') {
		            bufferData = Buffer.from(data, 'base64');
		        } else {
		            try {
		                bufferData = Buffer.from(decodeURIComponent(data));
		            } catch (_decodeError) {
		                bufferData = Buffer.from(data);
		            }
		        }
		    } catch (_bufferError) {
		        bufferData = Buffer.alloc(0);
		    }

		    return {
		        data: bufferData,
		        encoding: encoding || null,
		        contentType: contentType || 'application/octet-stream',
		        params
		    };
		};

		/**
		 * Resolves a String or a Buffer value for content value. Useful if the value
		 * is a Stream or a file or an URL. If the value is a Stream, overwrites
		 * the stream object with the resolved value (you can't stream a value twice).
		 *
		 * This is useful when you want to create a plugin that needs a content value,
		 * for example the `html` or `text` value as a String or a Buffer but not as
		 * a file path or an URL.
		 *
		 * @param {Object} data An object or an Array you want to resolve an element for
		 * @param {String|Number} key Property name or an Array index
		 * @param {Function} callback Callback function with (err, value)
		 */
		module.exports.resolveContent = (data, key, callback) => {
		    let promise;

		    if (!callback) {
		        promise = new Promise((resolve, reject) => {
		            callback = module.exports.callbackPromise(resolve, reject);
		        });
		    }

		    let content = (data && data[key] && data[key].content) || data[key];
		    let contentStream;
		    let encoding = ((typeof data[key] === 'object' && data[key].encoding) || 'utf8')
		        .toString()
		        .toLowerCase()
		        .replace(/[-_\s]/g, '');

		    if (!content) {
		        return callback(null, content);
		    }

		    if (typeof content === 'object') {
		        if (typeof content.pipe === 'function') {
		            return resolveStream(content, (err, value) => {
		                if (err) {
		                    return callback(err);
		                }
		                // we can't stream twice the same content, so we need
		                // to replace the stream object with the streaming result
		                if (data[key].content) {
		                    data[key].content = value;
		                } else {
		                    data[key] = value;
		                }
		                callback(null, value);
		            });
		        } else if (/^https?:\/\//i.test(content.path || content.href)) {
		            contentStream = nmfetch(content.path || content.href);
		            return resolveStream(contentStream, callback);
		        } else if (/^data:/i.test(content.path || content.href)) {
		            let parsedDataUri = module.exports.parseDataURI(content.path || content.href);

		            if (!parsedDataUri || !parsedDataUri.data) {
		                return callback(null, Buffer.from(0));
		            }
		            return callback(null, parsedDataUri.data);
		        } else if (content.path) {
		            return resolveStream(fs.createReadStream(content.path), callback);
		        }
		    }

		    if (typeof data[key].content === 'string' && !['utf8', 'usascii', 'ascii'].includes(encoding)) {
		        content = Buffer.from(data[key].content, encoding);
		    }

		    // default action, return as is
		    setImmediate(() => callback(null, content));

		    return promise;
		};

		/**
		 * Copies properties from source objects to target objects
		 */
		module.exports.assign = function (/* target, ... sources */) {
		    let args = Array.from(arguments);
		    let target = args.shift() || {};

		    args.forEach(source => {
		        Object.keys(source || {}).forEach(key => {
		            if (['tls', 'auth'].includes(key) && source[key] && typeof source[key] === 'object') {
		                // tls and auth are special keys that need to be enumerated separately
		                // other objects are passed as is
		                if (!target[key]) {
		                    // ensure that target has this key
		                    target[key] = {};
		                }
		                Object.keys(source[key]).forEach(subKey => {
		                    target[key][subKey] = source[key][subKey];
		                });
		            } else {
		                target[key] = source[key];
		            }
		        });
		    });
		    return target;
		};

		module.exports.encodeXText = str => {
		    // ! 0x21
		    // + 0x2B
		    // = 0x3D
		    // ~ 0x7E
		    if (!/[^\x21-\x2A\x2C-\x3C\x3E-\x7E]/.test(str)) {
		        return str;
		    }
		    let buf = Buffer.from(str);
		    let result = '';
		    for (let i = 0, len = buf.length; i < len; i++) {
		        let c = buf[i];
		        if (c < 0x21 || c > 0x7e || c === 0x2b || c === 0x3d) {
		            result += '+' + (c < 0x10 ? '0' : '') + c.toString(16).toUpperCase();
		        } else {
		            result += String.fromCharCode(c);
		        }
		    }
		    return result;
		};

		/**
		 * Streams a stream value into a Buffer
		 *
		 * @param {Object} stream Readable stream
		 * @param {Function} callback Callback function with (err, value)
		 */
		function resolveStream(stream, callback) {
		    let responded = false;
		    let chunks = [];
		    let chunklen = 0;

		    stream.on('error', err => {
		        if (responded) {
		            return;
		        }

		        responded = true;
		        callback(err);
		    });

		    stream.on('readable', () => {
		        let chunk;
		        while ((chunk = stream.read()) !== null) {
		            chunks.push(chunk);
		            chunklen += chunk.length;
		        }
		    });

		    stream.on('end', () => {
		        if (responded) {
		            return;
		        }
		        responded = true;

		        let value;

		        try {
		            value = Buffer.concat(chunks, chunklen);
		        } catch (E) {
		            return callback(E);
		        }
		        callback(null, value);
		    });
		}

		/**
		 * Generates a bunyan-like logger that prints to console
		 *
		 * @returns {Object} Bunyan logger instance
		 */
		function createDefaultLogger(levels) {
		    let levelMaxLen = 0;
		    let levelNames = new Map();
		    levels.forEach(level => {
		        if (level.length > levelMaxLen) {
		            levelMaxLen = level.length;
		        }
		    });

		    levels.forEach(level => {
		        let levelName = level.toUpperCase();
		        if (levelName.length < levelMaxLen) {
		            levelName += ' '.repeat(levelMaxLen - levelName.length);
		        }
		        levelNames.set(level, levelName);
		    });

		    let print = (level, entry, message, ...args) => {
		        let prefix = '';
		        if (entry) {
		            if (entry.tnx === 'server') {
		                prefix = 'S: ';
		            } else if (entry.tnx === 'client') {
		                prefix = 'C: ';
		            }

		            if (entry.sid) {
		                prefix = '[' + entry.sid + '] ' + prefix;
		            }

		            if (entry.cid) {
		                prefix = '[#' + entry.cid + '] ' + prefix;
		            }
		        }

		        message = util.format(message, ...args);
		        message.split(/\r?\n/).forEach(line => {
		            console.log('[%s] %s %s', new Date().toISOString().substr(0, 19).replace(/T/, ' '), levelNames.get(level), prefix + line);
		        });
		    };

		    let logger = {};
		    levels.forEach(level => {
		        logger[level] = print.bind(null, level);
		    });

		    return logger;
		} 
	} (shared));
	return shared.exports;
}

/* eslint quote-props: 0 */

var mimeTypes_1;
var hasRequiredMimeTypes;

function requireMimeTypes () {
	if (hasRequiredMimeTypes) return mimeTypes_1;
	hasRequiredMimeTypes = 1;

	const path = path$1;

	const defaultMimeType = 'application/octet-stream';
	const defaultExtension = 'bin';

	const mimeTypes = new Map([
	    ['application/acad', 'dwg'],
	    ['application/applixware', 'aw'],
	    ['application/arj', 'arj'],
	    ['application/atom+xml', 'xml'],
	    ['application/atomcat+xml', 'atomcat'],
	    ['application/atomsvc+xml', 'atomsvc'],
	    ['application/base64', ['mm', 'mme']],
	    ['application/binhex', 'hqx'],
	    ['application/binhex4', 'hqx'],
	    ['application/book', ['book', 'boo']],
	    ['application/ccxml+xml,', 'ccxml'],
	    ['application/cdf', 'cdf'],
	    ['application/cdmi-capability', 'cdmia'],
	    ['application/cdmi-container', 'cdmic'],
	    ['application/cdmi-domain', 'cdmid'],
	    ['application/cdmi-object', 'cdmio'],
	    ['application/cdmi-queue', 'cdmiq'],
	    ['application/clariscad', 'ccad'],
	    ['application/commonground', 'dp'],
	    ['application/cu-seeme', 'cu'],
	    ['application/davmount+xml', 'davmount'],
	    ['application/drafting', 'drw'],
	    ['application/dsptype', 'tsp'],
	    ['application/dssc+der', 'dssc'],
	    ['application/dssc+xml', 'xdssc'],
	    ['application/dxf', 'dxf'],
	    ['application/ecmascript', ['js', 'es']],
	    ['application/emma+xml', 'emma'],
	    ['application/envoy', 'evy'],
	    ['application/epub+zip', 'epub'],
	    ['application/excel', ['xls', 'xl', 'xla', 'xlb', 'xlc', 'xld', 'xlk', 'xll', 'xlm', 'xlt', 'xlv', 'xlw']],
	    ['application/exi', 'exi'],
	    ['application/font-tdpfr', 'pfr'],
	    ['application/fractals', 'fif'],
	    ['application/freeloader', 'frl'],
	    ['application/futuresplash', 'spl'],
	    ['application/geo+json', 'geojson'],
	    ['application/gnutar', 'tgz'],
	    ['application/groupwise', 'vew'],
	    ['application/hlp', 'hlp'],
	    ['application/hta', 'hta'],
	    ['application/hyperstudio', 'stk'],
	    ['application/i-deas', 'unv'],
	    ['application/iges', ['iges', 'igs']],
	    ['application/inf', 'inf'],
	    ['application/internet-property-stream', 'acx'],
	    ['application/ipfix', 'ipfix'],
	    ['application/java', 'class'],
	    ['application/java-archive', 'jar'],
	    ['application/java-byte-code', 'class'],
	    ['application/java-serialized-object', 'ser'],
	    ['application/java-vm', 'class'],
	    ['application/javascript', 'js'],
	    ['application/json', 'json'],
	    ['application/lha', 'lha'],
	    ['application/lzx', 'lzx'],
	    ['application/mac-binary', 'bin'],
	    ['application/mac-binhex', 'hqx'],
	    ['application/mac-binhex40', 'hqx'],
	    ['application/mac-compactpro', 'cpt'],
	    ['application/macbinary', 'bin'],
	    ['application/mads+xml', 'mads'],
	    ['application/marc', 'mrc'],
	    ['application/marcxml+xml', 'mrcx'],
	    ['application/mathematica', 'ma'],
	    ['application/mathml+xml', 'mathml'],
	    ['application/mbedlet', 'mbd'],
	    ['application/mbox', 'mbox'],
	    ['application/mcad', 'mcd'],
	    ['application/mediaservercontrol+xml', 'mscml'],
	    ['application/metalink4+xml', 'meta4'],
	    ['application/mets+xml', 'mets'],
	    ['application/mime', 'aps'],
	    ['application/mods+xml', 'mods'],
	    ['application/mp21', 'm21'],
	    ['application/mp4', 'mp4'],
	    ['application/mspowerpoint', ['ppt', 'pot', 'pps', 'ppz']],
	    ['application/msword', ['doc', 'dot', 'w6w', 'wiz', 'word']],
	    ['application/mswrite', 'wri'],
	    ['application/mxf', 'mxf'],
	    ['application/netmc', 'mcp'],
	    ['application/octet-stream', ['*']],
	    ['application/oda', 'oda'],
	    ['application/oebps-package+xml', 'opf'],
	    ['application/ogg', 'ogx'],
	    ['application/olescript', 'axs'],
	    ['application/onenote', 'onetoc'],
	    ['application/patch-ops-error+xml', 'xer'],
	    ['application/pdf', 'pdf'],
	    ['application/pgp-encrypted', 'asc'],
	    ['application/pgp-signature', 'pgp'],
	    ['application/pics-rules', 'prf'],
	    ['application/pkcs-12', 'p12'],
	    ['application/pkcs-crl', 'crl'],
	    ['application/pkcs10', 'p10'],
	    ['application/pkcs7-mime', ['p7c', 'p7m']],
	    ['application/pkcs7-signature', 'p7s'],
	    ['application/pkcs8', 'p8'],
	    ['application/pkix-attr-cert', 'ac'],
	    ['application/pkix-cert', ['cer', 'crt']],
	    ['application/pkix-crl', 'crl'],
	    ['application/pkix-pkipath', 'pkipath'],
	    ['application/pkixcmp', 'pki'],
	    ['application/plain', 'text'],
	    ['application/pls+xml', 'pls'],
	    ['application/postscript', ['ps', 'ai', 'eps']],
	    ['application/powerpoint', 'ppt'],
	    ['application/pro_eng', ['part', 'prt']],
	    ['application/prs.cww', 'cww'],
	    ['application/pskc+xml', 'pskcxml'],
	    ['application/rdf+xml', 'rdf'],
	    ['application/reginfo+xml', 'rif'],
	    ['application/relax-ng-compact-syntax', 'rnc'],
	    ['application/resource-lists+xml', 'rl'],
	    ['application/resource-lists-diff+xml', 'rld'],
	    ['application/ringing-tones', 'rng'],
	    ['application/rls-services+xml', 'rs'],
	    ['application/rsd+xml', 'rsd'],
	    ['application/rss+xml', 'xml'],
	    ['application/rtf', ['rtf', 'rtx']],
	    ['application/sbml+xml', 'sbml'],
	    ['application/scvp-cv-request', 'scq'],
	    ['application/scvp-cv-response', 'scs'],
	    ['application/scvp-vp-request', 'spq'],
	    ['application/scvp-vp-response', 'spp'],
	    ['application/sdp', 'sdp'],
	    ['application/sea', 'sea'],
	    ['application/set', 'set'],
	    ['application/set-payment-initiation', 'setpay'],
	    ['application/set-registration-initiation', 'setreg'],
	    ['application/shf+xml', 'shf'],
	    ['application/sla', 'stl'],
	    ['application/smil', ['smi', 'smil']],
	    ['application/smil+xml', 'smi'],
	    ['application/solids', 'sol'],
	    ['application/sounder', 'sdr'],
	    ['application/sparql-query', 'rq'],
	    ['application/sparql-results+xml', 'srx'],
	    ['application/srgs', 'gram'],
	    ['application/srgs+xml', 'grxml'],
	    ['application/sru+xml', 'sru'],
	    ['application/ssml+xml', 'ssml'],
	    ['application/step', ['step', 'stp']],
	    ['application/streamingmedia', 'ssm'],
	    ['application/tei+xml', 'tei'],
	    ['application/thraud+xml', 'tfi'],
	    ['application/timestamped-data', 'tsd'],
	    ['application/toolbook', 'tbk'],
	    ['application/vda', 'vda'],
	    ['application/vnd.3gpp.pic-bw-large', 'plb'],
	    ['application/vnd.3gpp.pic-bw-small', 'psb'],
	    ['application/vnd.3gpp.pic-bw-var', 'pvb'],
	    ['application/vnd.3gpp2.tcap', 'tcap'],
	    ['application/vnd.3m.post-it-notes', 'pwn'],
	    ['application/vnd.accpac.simply.aso', 'aso'],
	    ['application/vnd.accpac.simply.imp', 'imp'],
	    ['application/vnd.acucobol', 'acu'],
	    ['application/vnd.acucorp', 'atc'],
	    ['application/vnd.adobe.air-application-installer-package+zip', 'air'],
	    ['application/vnd.adobe.fxp', 'fxp'],
	    ['application/vnd.adobe.xdp+xml', 'xdp'],
	    ['application/vnd.adobe.xfdf', 'xfdf'],
	    ['application/vnd.ahead.space', 'ahead'],
	    ['application/vnd.airzip.filesecure.azf', 'azf'],
	    ['application/vnd.airzip.filesecure.azs', 'azs'],
	    ['application/vnd.amazon.ebook', 'azw'],
	    ['application/vnd.americandynamics.acc', 'acc'],
	    ['application/vnd.amiga.ami', 'ami'],
	    ['application/vnd.android.package-archive', 'apk'],
	    ['application/vnd.anser-web-certificate-issue-initiation', 'cii'],
	    ['application/vnd.anser-web-funds-transfer-initiation', 'fti'],
	    ['application/vnd.antix.game-component', 'atx'],
	    ['application/vnd.apple.installer+xml', 'mpkg'],
	    ['application/vnd.apple.mpegurl', 'm3u8'],
	    ['application/vnd.aristanetworks.swi', 'swi'],
	    ['application/vnd.audiograph', 'aep'],
	    ['application/vnd.blueice.multipass', 'mpm'],
	    ['application/vnd.bmi', 'bmi'],
	    ['application/vnd.businessobjects', 'rep'],
	    ['application/vnd.chemdraw+xml', 'cdxml'],
	    ['application/vnd.chipnuts.karaoke-mmd', 'mmd'],
	    ['application/vnd.cinderella', 'cdy'],
	    ['application/vnd.claymore', 'cla'],
	    ['application/vnd.cloanto.rp9', 'rp9'],
	    ['application/vnd.clonk.c4group', 'c4g'],
	    ['application/vnd.cluetrust.cartomobile-config', 'c11amc'],
	    ['application/vnd.cluetrust.cartomobile-config-pkg', 'c11amz'],
	    ['application/vnd.commonspace', 'csp'],
	    ['application/vnd.contact.cmsg', 'cdbcmsg'],
	    ['application/vnd.cosmocaller', 'cmc'],
	    ['application/vnd.crick.clicker', 'clkx'],
	    ['application/vnd.crick.clicker.keyboard', 'clkk'],
	    ['application/vnd.crick.clicker.palette', 'clkp'],
	    ['application/vnd.crick.clicker.template', 'clkt'],
	    ['application/vnd.crick.clicker.wordbank', 'clkw'],
	    ['application/vnd.criticaltools.wbs+xml', 'wbs'],
	    ['application/vnd.ctc-posml', 'pml'],
	    ['application/vnd.cups-ppd', 'ppd'],
	    ['application/vnd.curl.car', 'car'],
	    ['application/vnd.curl.pcurl', 'pcurl'],
	    ['application/vnd.data-vision.rdz', 'rdz'],
	    ['application/vnd.denovo.fcselayout-link', 'fe_launch'],
	    ['application/vnd.dna', 'dna'],
	    ['application/vnd.dolby.mlp', 'mlp'],
	    ['application/vnd.dpgraph', 'dpg'],
	    ['application/vnd.dreamfactory', 'dfac'],
	    ['application/vnd.dvb.ait', 'ait'],
	    ['application/vnd.dvb.service', 'svc'],
	    ['application/vnd.dynageo', 'geo'],
	    ['application/vnd.ecowin.chart', 'mag'],
	    ['application/vnd.enliven', 'nml'],
	    ['application/vnd.epson.esf', 'esf'],
	    ['application/vnd.epson.msf', 'msf'],
	    ['application/vnd.epson.quickanime', 'qam'],
	    ['application/vnd.epson.salt', 'slt'],
	    ['application/vnd.epson.ssf', 'ssf'],
	    ['application/vnd.eszigno3+xml', 'es3'],
	    ['application/vnd.ezpix-album', 'ez2'],
	    ['application/vnd.ezpix-package', 'ez3'],
	    ['application/vnd.fdf', 'fdf'],
	    ['application/vnd.fdsn.seed', 'seed'],
	    ['application/vnd.flographit', 'gph'],
	    ['application/vnd.fluxtime.clip', 'ftc'],
	    ['application/vnd.framemaker', 'fm'],
	    ['application/vnd.frogans.fnc', 'fnc'],
	    ['application/vnd.frogans.ltf', 'ltf'],
	    ['application/vnd.fsc.weblaunch', 'fsc'],
	    ['application/vnd.fujitsu.oasys', 'oas'],
	    ['application/vnd.fujitsu.oasys2', 'oa2'],
	    ['application/vnd.fujitsu.oasys3', 'oa3'],
	    ['application/vnd.fujitsu.oasysgp', 'fg5'],
	    ['application/vnd.fujitsu.oasysprs', 'bh2'],
	    ['application/vnd.fujixerox.ddd', 'ddd'],
	    ['application/vnd.fujixerox.docuworks', 'xdw'],
	    ['application/vnd.fujixerox.docuworks.binder', 'xbd'],
	    ['application/vnd.fuzzysheet', 'fzs'],
	    ['application/vnd.genomatix.tuxedo', 'txd'],
	    ['application/vnd.geogebra.file', 'ggb'],
	    ['application/vnd.geogebra.tool', 'ggt'],
	    ['application/vnd.geometry-explorer', 'gex'],
	    ['application/vnd.geonext', 'gxt'],
	    ['application/vnd.geoplan', 'g2w'],
	    ['application/vnd.geospace', 'g3w'],
	    ['application/vnd.gmx', 'gmx'],
	    ['application/vnd.google-earth.kml+xml', 'kml'],
	    ['application/vnd.google-earth.kmz', 'kmz'],
	    ['application/vnd.grafeq', 'gqf'],
	    ['application/vnd.groove-account', 'gac'],
	    ['application/vnd.groove-help', 'ghf'],
	    ['application/vnd.groove-identity-message', 'gim'],
	    ['application/vnd.groove-injector', 'grv'],
	    ['application/vnd.groove-tool-message', 'gtm'],
	    ['application/vnd.groove-tool-template', 'tpl'],
	    ['application/vnd.groove-vcard', 'vcg'],
	    ['application/vnd.hal+xml', 'hal'],
	    ['application/vnd.handheld-entertainment+xml', 'zmm'],
	    ['application/vnd.hbci', 'hbci'],
	    ['application/vnd.hhe.lesson-player', 'les'],
	    ['application/vnd.hp-hpgl', ['hgl', 'hpg', 'hpgl']],
	    ['application/vnd.hp-hpid', 'hpid'],
	    ['application/vnd.hp-hps', 'hps'],
	    ['application/vnd.hp-jlyt', 'jlt'],
	    ['application/vnd.hp-pcl', 'pcl'],
	    ['application/vnd.hp-pclxl', 'pclxl'],
	    ['application/vnd.hydrostatix.sof-data', 'sfd-hdstx'],
	    ['application/vnd.hzn-3d-crossword', 'x3d'],
	    ['application/vnd.ibm.minipay', 'mpy'],
	    ['application/vnd.ibm.modcap', 'afp'],
	    ['application/vnd.ibm.rights-management', 'irm'],
	    ['application/vnd.ibm.secure-container', 'sc'],
	    ['application/vnd.iccprofile', 'icc'],
	    ['application/vnd.igloader', 'igl'],
	    ['application/vnd.immervision-ivp', 'ivp'],
	    ['application/vnd.immervision-ivu', 'ivu'],
	    ['application/vnd.insors.igm', 'igm'],
	    ['application/vnd.intercon.formnet', 'xpw'],
	    ['application/vnd.intergeo', 'i2g'],
	    ['application/vnd.intu.qbo', 'qbo'],
	    ['application/vnd.intu.qfx', 'qfx'],
	    ['application/vnd.ipunplugged.rcprofile', 'rcprofile'],
	    ['application/vnd.irepository.package+xml', 'irp'],
	    ['application/vnd.is-xpr', 'xpr'],
	    ['application/vnd.isac.fcs', 'fcs'],
	    ['application/vnd.jam', 'jam'],
	    ['application/vnd.jcp.javame.midlet-rms', 'rms'],
	    ['application/vnd.jisp', 'jisp'],
	    ['application/vnd.joost.joda-archive', 'joda'],
	    ['application/vnd.kahootz', 'ktz'],
	    ['application/vnd.kde.karbon', 'karbon'],
	    ['application/vnd.kde.kchart', 'chrt'],
	    ['application/vnd.kde.kformula', 'kfo'],
	    ['application/vnd.kde.kivio', 'flw'],
	    ['application/vnd.kde.kontour', 'kon'],
	    ['application/vnd.kde.kpresenter', 'kpr'],
	    ['application/vnd.kde.kspread', 'ksp'],
	    ['application/vnd.kde.kword', 'kwd'],
	    ['application/vnd.kenameaapp', 'htke'],
	    ['application/vnd.kidspiration', 'kia'],
	    ['application/vnd.kinar', 'kne'],
	    ['application/vnd.koan', 'skp'],
	    ['application/vnd.kodak-descriptor', 'sse'],
	    ['application/vnd.las.las+xml', 'lasxml'],
	    ['application/vnd.llamagraphics.life-balance.desktop', 'lbd'],
	    ['application/vnd.llamagraphics.life-balance.exchange+xml', 'lbe'],
	    ['application/vnd.lotus-1-2-3', '123'],
	    ['application/vnd.lotus-approach', 'apr'],
	    ['application/vnd.lotus-freelance', 'pre'],
	    ['application/vnd.lotus-notes', 'nsf'],
	    ['application/vnd.lotus-organizer', 'org'],
	    ['application/vnd.lotus-screencam', 'scm'],
	    ['application/vnd.lotus-wordpro', 'lwp'],
	    ['application/vnd.macports.portpkg', 'portpkg'],
	    ['application/vnd.mcd', 'mcd'],
	    ['application/vnd.medcalcdata', 'mc1'],
	    ['application/vnd.mediastation.cdkey', 'cdkey'],
	    ['application/vnd.mfer', 'mwf'],
	    ['application/vnd.mfmp', 'mfm'],
	    ['application/vnd.micrografx.flo', 'flo'],
	    ['application/vnd.micrografx.igx', 'igx'],
	    ['application/vnd.mif', 'mif'],
	    ['application/vnd.mobius.daf', 'daf'],
	    ['application/vnd.mobius.dis', 'dis'],
	    ['application/vnd.mobius.mbk', 'mbk'],
	    ['application/vnd.mobius.mqy', 'mqy'],
	    ['application/vnd.mobius.msl', 'msl'],
	    ['application/vnd.mobius.plc', 'plc'],
	    ['application/vnd.mobius.txf', 'txf'],
	    ['application/vnd.mophun.application', 'mpn'],
	    ['application/vnd.mophun.certificate', 'mpc'],
	    ['application/vnd.mozilla.xul+xml', 'xul'],
	    ['application/vnd.ms-artgalry', 'cil'],
	    ['application/vnd.ms-cab-compressed', 'cab'],
	    ['application/vnd.ms-excel', ['xls', 'xla', 'xlc', 'xlm', 'xlt', 'xlw', 'xlb', 'xll']],
	    ['application/vnd.ms-excel.addin.macroenabled.12', 'xlam'],
	    ['application/vnd.ms-excel.sheet.binary.macroenabled.12', 'xlsb'],
	    ['application/vnd.ms-excel.sheet.macroenabled.12', 'xlsm'],
	    ['application/vnd.ms-excel.template.macroenabled.12', 'xltm'],
	    ['application/vnd.ms-fontobject', 'eot'],
	    ['application/vnd.ms-htmlhelp', 'chm'],
	    ['application/vnd.ms-ims', 'ims'],
	    ['application/vnd.ms-lrm', 'lrm'],
	    ['application/vnd.ms-officetheme', 'thmx'],
	    ['application/vnd.ms-outlook', 'msg'],
	    ['application/vnd.ms-pki.certstore', 'sst'],
	    ['application/vnd.ms-pki.pko', 'pko'],
	    ['application/vnd.ms-pki.seccat', 'cat'],
	    ['application/vnd.ms-pki.stl', 'stl'],
	    ['application/vnd.ms-pkicertstore', 'sst'],
	    ['application/vnd.ms-pkiseccat', 'cat'],
	    ['application/vnd.ms-pkistl', 'stl'],
	    ['application/vnd.ms-powerpoint', ['ppt', 'pot', 'pps', 'ppa', 'pwz']],
	    ['application/vnd.ms-powerpoint.addin.macroenabled.12', 'ppam'],
	    ['application/vnd.ms-powerpoint.presentation.macroenabled.12', 'pptm'],
	    ['application/vnd.ms-powerpoint.slide.macroenabled.12', 'sldm'],
	    ['application/vnd.ms-powerpoint.slideshow.macroenabled.12', 'ppsm'],
	    ['application/vnd.ms-powerpoint.template.macroenabled.12', 'potm'],
	    ['application/vnd.ms-project', 'mpp'],
	    ['application/vnd.ms-word.document.macroenabled.12', 'docm'],
	    ['application/vnd.ms-word.template.macroenabled.12', 'dotm'],
	    ['application/vnd.ms-works', ['wks', 'wcm', 'wdb', 'wps']],
	    ['application/vnd.ms-wpl', 'wpl'],
	    ['application/vnd.ms-xpsdocument', 'xps'],
	    ['application/vnd.mseq', 'mseq'],
	    ['application/vnd.musician', 'mus'],
	    ['application/vnd.muvee.style', 'msty'],
	    ['application/vnd.neurolanguage.nlu', 'nlu'],
	    ['application/vnd.noblenet-directory', 'nnd'],
	    ['application/vnd.noblenet-sealer', 'nns'],
	    ['application/vnd.noblenet-web', 'nnw'],
	    ['application/vnd.nokia.configuration-message', 'ncm'],
	    ['application/vnd.nokia.n-gage.data', 'ngdat'],
	    ['application/vnd.nokia.n-gage.symbian.install', 'n-gage'],
	    ['application/vnd.nokia.radio-preset', 'rpst'],
	    ['application/vnd.nokia.radio-presets', 'rpss'],
	    ['application/vnd.nokia.ringing-tone', 'rng'],
	    ['application/vnd.novadigm.edm', 'edm'],
	    ['application/vnd.novadigm.edx', 'edx'],
	    ['application/vnd.novadigm.ext', 'ext'],
	    ['application/vnd.oasis.opendocument.chart', 'odc'],
	    ['application/vnd.oasis.opendocument.chart-template', 'otc'],
	    ['application/vnd.oasis.opendocument.database', 'odb'],
	    ['application/vnd.oasis.opendocument.formula', 'odf'],
	    ['application/vnd.oasis.opendocument.formula-template', 'odft'],
	    ['application/vnd.oasis.opendocument.graphics', 'odg'],
	    ['application/vnd.oasis.opendocument.graphics-template', 'otg'],
	    ['application/vnd.oasis.opendocument.image', 'odi'],
	    ['application/vnd.oasis.opendocument.image-template', 'oti'],
	    ['application/vnd.oasis.opendocument.presentation', 'odp'],
	    ['application/vnd.oasis.opendocument.presentation-template', 'otp'],
	    ['application/vnd.oasis.opendocument.spreadsheet', 'ods'],
	    ['application/vnd.oasis.opendocument.spreadsheet-template', 'ots'],
	    ['application/vnd.oasis.opendocument.text', 'odt'],
	    ['application/vnd.oasis.opendocument.text-master', 'odm'],
	    ['application/vnd.oasis.opendocument.text-template', 'ott'],
	    ['application/vnd.oasis.opendocument.text-web', 'oth'],
	    ['application/vnd.olpc-sugar', 'xo'],
	    ['application/vnd.oma.dd2+xml', 'dd2'],
	    ['application/vnd.openofficeorg.extension', 'oxt'],
	    ['application/vnd.openxmlformats-officedocument.presentationml.presentation', 'pptx'],
	    ['application/vnd.openxmlformats-officedocument.presentationml.slide', 'sldx'],
	    ['application/vnd.openxmlformats-officedocument.presentationml.slideshow', 'ppsx'],
	    ['application/vnd.openxmlformats-officedocument.presentationml.template', 'potx'],
	    ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'xlsx'],
	    ['application/vnd.openxmlformats-officedocument.spreadsheetml.template', 'xltx'],
	    ['application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'docx'],
	    ['application/vnd.openxmlformats-officedocument.wordprocessingml.template', 'dotx'],
	    ['application/vnd.osgeo.mapguide.package', 'mgp'],
	    ['application/vnd.osgi.dp', 'dp'],
	    ['application/vnd.palm', 'pdb'],
	    ['application/vnd.pawaafile', 'paw'],
	    ['application/vnd.pg.format', 'str'],
	    ['application/vnd.pg.osasli', 'ei6'],
	    ['application/vnd.picsel', 'efif'],
	    ['application/vnd.pmi.widget', 'wg'],
	    ['application/vnd.pocketlearn', 'plf'],
	    ['application/vnd.powerbuilder6', 'pbd'],
	    ['application/vnd.previewsystems.box', 'box'],
	    ['application/vnd.proteus.magazine', 'mgz'],
	    ['application/vnd.publishare-delta-tree', 'qps'],
	    ['application/vnd.pvi.ptid1', 'ptid'],
	    ['application/vnd.quark.quarkxpress', 'qxd'],
	    ['application/vnd.realvnc.bed', 'bed'],
	    ['application/vnd.recordare.musicxml', 'mxl'],
	    ['application/vnd.recordare.musicxml+xml', 'musicxml'],
	    ['application/vnd.rig.cryptonote', 'cryptonote'],
	    ['application/vnd.rim.cod', 'cod'],
	    ['application/vnd.rn-realmedia', 'rm'],
	    ['application/vnd.rn-realplayer', 'rnx'],
	    ['application/vnd.route66.link66+xml', 'link66'],
	    ['application/vnd.sailingtracker.track', 'st'],
	    ['application/vnd.seemail', 'see'],
	    ['application/vnd.sema', 'sema'],
	    ['application/vnd.semd', 'semd'],
	    ['application/vnd.semf', 'semf'],
	    ['application/vnd.shana.informed.formdata', 'ifm'],
	    ['application/vnd.shana.informed.formtemplate', 'itp'],
	    ['application/vnd.shana.informed.interchange', 'iif'],
	    ['application/vnd.shana.informed.package', 'ipk'],
	    ['application/vnd.simtech-mindmapper', 'twd'],
	    ['application/vnd.smaf', 'mmf'],
	    ['application/vnd.smart.teacher', 'teacher'],
	    ['application/vnd.solent.sdkm+xml', 'sdkm'],
	    ['application/vnd.spotfire.dxp', 'dxp'],
	    ['application/vnd.spotfire.sfs', 'sfs'],
	    ['application/vnd.stardivision.calc', 'sdc'],
	    ['application/vnd.stardivision.draw', 'sda'],
	    ['application/vnd.stardivision.impress', 'sdd'],
	    ['application/vnd.stardivision.math', 'smf'],
	    ['application/vnd.stardivision.writer', 'sdw'],
	    ['application/vnd.stardivision.writer-global', 'sgl'],
	    ['application/vnd.stepmania.stepchart', 'sm'],
	    ['application/vnd.sun.xml.calc', 'sxc'],
	    ['application/vnd.sun.xml.calc.template', 'stc'],
	    ['application/vnd.sun.xml.draw', 'sxd'],
	    ['application/vnd.sun.xml.draw.template', 'std'],
	    ['application/vnd.sun.xml.impress', 'sxi'],
	    ['application/vnd.sun.xml.impress.template', 'sti'],
	    ['application/vnd.sun.xml.math', 'sxm'],
	    ['application/vnd.sun.xml.writer', 'sxw'],
	    ['application/vnd.sun.xml.writer.global', 'sxg'],
	    ['application/vnd.sun.xml.writer.template', 'stw'],
	    ['application/vnd.sus-calendar', 'sus'],
	    ['application/vnd.svd', 'svd'],
	    ['application/vnd.symbian.install', 'sis'],
	    ['application/vnd.syncml+xml', 'xsm'],
	    ['application/vnd.syncml.dm+wbxml', 'bdm'],
	    ['application/vnd.syncml.dm+xml', 'xdm'],
	    ['application/vnd.tao.intent-module-archive', 'tao'],
	    ['application/vnd.tmobile-livetv', 'tmo'],
	    ['application/vnd.trid.tpt', 'tpt'],
	    ['application/vnd.triscape.mxs', 'mxs'],
	    ['application/vnd.trueapp', 'tra'],
	    ['application/vnd.ufdl', 'ufd'],
	    ['application/vnd.uiq.theme', 'utz'],
	    ['application/vnd.umajin', 'umj'],
	    ['application/vnd.unity', 'unityweb'],
	    ['application/vnd.uoml+xml', 'uoml'],
	    ['application/vnd.vcx', 'vcx'],
	    ['application/vnd.visio', 'vsd'],
	    ['application/vnd.visionary', 'vis'],
	    ['application/vnd.vsf', 'vsf'],
	    ['application/vnd.wap.wbxml', 'wbxml'],
	    ['application/vnd.wap.wmlc', 'wmlc'],
	    ['application/vnd.wap.wmlscriptc', 'wmlsc'],
	    ['application/vnd.webturbo', 'wtb'],
	    ['application/vnd.wolfram.player', 'nbp'],
	    ['application/vnd.wordperfect', 'wpd'],
	    ['application/vnd.wqd', 'wqd'],
	    ['application/vnd.wt.stf', 'stf'],
	    ['application/vnd.xara', ['web', 'xar']],
	    ['application/vnd.xfdl', 'xfdl'],
	    ['application/vnd.yamaha.hv-dic', 'hvd'],
	    ['application/vnd.yamaha.hv-script', 'hvs'],
	    ['application/vnd.yamaha.hv-voice', 'hvp'],
	    ['application/vnd.yamaha.openscoreformat', 'osf'],
	    ['application/vnd.yamaha.openscoreformat.osfpvg+xml', 'osfpvg'],
	    ['application/vnd.yamaha.smaf-audio', 'saf'],
	    ['application/vnd.yamaha.smaf-phrase', 'spf'],
	    ['application/vnd.yellowriver-custom-menu', 'cmp'],
	    ['application/vnd.zul', 'zir'],
	    ['application/vnd.zzazz.deck+xml', 'zaz'],
	    ['application/vocaltec-media-desc', 'vmd'],
	    ['application/vocaltec-media-file', 'vmf'],
	    ['application/voicexml+xml', 'vxml'],
	    ['application/widget', 'wgt'],
	    ['application/winhlp', 'hlp'],
	    ['application/wordperfect', ['wp', 'wp5', 'wp6', 'wpd']],
	    ['application/wordperfect6.0', ['w60', 'wp5']],
	    ['application/wordperfect6.1', 'w61'],
	    ['application/wsdl+xml', 'wsdl'],
	    ['application/wspolicy+xml', 'wspolicy'],
	    ['application/x-123', 'wk1'],
	    ['application/x-7z-compressed', '7z'],
	    ['application/x-abiword', 'abw'],
	    ['application/x-ace-compressed', 'ace'],
	    ['application/x-aim', 'aim'],
	    ['application/x-authorware-bin', 'aab'],
	    ['application/x-authorware-map', 'aam'],
	    ['application/x-authorware-seg', 'aas'],
	    ['application/x-bcpio', 'bcpio'],
	    ['application/x-binary', 'bin'],
	    ['application/x-binhex40', 'hqx'],
	    ['application/x-bittorrent', 'torrent'],
	    ['application/x-bsh', ['bsh', 'sh', 'shar']],
	    ['application/x-bytecode.elisp', 'elc'],
	    ['application/x-bytecode.python', 'pyc'],
	    ['application/x-bzip', 'bz'],
	    ['application/x-bzip2', ['boz', 'bz2']],
	    ['application/x-cdf', 'cdf'],
	    ['application/x-cdlink', 'vcd'],
	    ['application/x-chat', ['cha', 'chat']],
	    ['application/x-chess-pgn', 'pgn'],
	    ['application/x-cmu-raster', 'ras'],
	    ['application/x-cocoa', 'cco'],
	    ['application/x-compactpro', 'cpt'],
	    ['application/x-compress', 'z'],
	    ['application/x-compressed', ['tgz', 'gz', 'z', 'zip']],
	    ['application/x-conference', 'nsc'],
	    ['application/x-cpio', 'cpio'],
	    ['application/x-cpt', 'cpt'],
	    ['application/x-csh', 'csh'],
	    ['application/x-debian-package', 'deb'],
	    ['application/x-deepv', 'deepv'],
	    ['application/x-director', ['dir', 'dcr', 'dxr']],
	    ['application/x-doom', 'wad'],
	    ['application/x-dtbncx+xml', 'ncx'],
	    ['application/x-dtbook+xml', 'dtb'],
	    ['application/x-dtbresource+xml', 'res'],
	    ['application/x-dvi', 'dvi'],
	    ['application/x-elc', 'elc'],
	    ['application/x-envoy', ['env', 'evy']],
	    ['application/x-esrehber', 'es'],
	    ['application/x-excel', ['xls', 'xla', 'xlb', 'xlc', 'xld', 'xlk', 'xll', 'xlm', 'xlt', 'xlv', 'xlw']],
	    ['application/x-font-bdf', 'bdf'],
	    ['application/x-font-ghostscript', 'gsf'],
	    ['application/x-font-linux-psf', 'psf'],
	    ['application/x-font-otf', 'otf'],
	    ['application/x-font-pcf', 'pcf'],
	    ['application/x-font-snf', 'snf'],
	    ['application/x-font-ttf', 'ttf'],
	    ['application/x-font-type1', 'pfa'],
	    ['application/x-font-woff', 'woff'],
	    ['application/x-frame', 'mif'],
	    ['application/x-freelance', 'pre'],
	    ['application/x-futuresplash', 'spl'],
	    ['application/x-gnumeric', 'gnumeric'],
	    ['application/x-gsp', 'gsp'],
	    ['application/x-gss', 'gss'],
	    ['application/x-gtar', 'gtar'],
	    ['application/x-gzip', ['gz', 'gzip']],
	    ['application/x-hdf', 'hdf'],
	    ['application/x-helpfile', ['help', 'hlp']],
	    ['application/x-httpd-imap', 'imap'],
	    ['application/x-ima', 'ima'],
	    ['application/x-internet-signup', ['ins', 'isp']],
	    ['application/x-internett-signup', 'ins'],
	    ['application/x-inventor', 'iv'],
	    ['application/x-ip2', 'ip'],
	    ['application/x-iphone', 'iii'],
	    ['application/x-java-class', 'class'],
	    ['application/x-java-commerce', 'jcm'],
	    ['application/x-java-jnlp-file', 'jnlp'],
	    ['application/x-javascript', 'js'],
	    ['application/x-koan', ['skd', 'skm', 'skp', 'skt']],
	    ['application/x-ksh', 'ksh'],
	    ['application/x-latex', ['latex', 'ltx']],
	    ['application/x-lha', 'lha'],
	    ['application/x-lisp', 'lsp'],
	    ['application/x-livescreen', 'ivy'],
	    ['application/x-lotus', 'wq1'],
	    ['application/x-lotusscreencam', 'scm'],
	    ['application/x-lzh', 'lzh'],
	    ['application/x-lzx', 'lzx'],
	    ['application/x-mac-binhex40', 'hqx'],
	    ['application/x-macbinary', 'bin'],
	    ['application/x-magic-cap-package-1.0', 'mc$'],
	    ['application/x-mathcad', 'mcd'],
	    ['application/x-meme', 'mm'],
	    ['application/x-midi', ['mid', 'midi']],
	    ['application/x-mif', 'mif'],
	    ['application/x-mix-transfer', 'nix'],
	    ['application/x-mobipocket-ebook', 'prc'],
	    ['application/x-mplayer2', 'asx'],
	    ['application/x-ms-application', 'application'],
	    ['application/x-ms-wmd', 'wmd'],
	    ['application/x-ms-wmz', 'wmz'],
	    ['application/x-ms-xbap', 'xbap'],
	    ['application/x-msaccess', 'mdb'],
	    ['application/x-msbinder', 'obd'],
	    ['application/x-mscardfile', 'crd'],
	    ['application/x-msclip', 'clp'],
	    ['application/x-msdownload', ['exe', 'dll']],
	    ['application/x-msexcel', ['xls', 'xla', 'xlw']],
	    ['application/x-msmediaview', ['mvb', 'm13', 'm14']],
	    ['application/x-msmetafile', 'wmf'],
	    ['application/x-msmoney', 'mny'],
	    ['application/x-mspowerpoint', 'ppt'],
	    ['application/x-mspublisher', 'pub'],
	    ['application/x-msschedule', 'scd'],
	    ['application/x-msterminal', 'trm'],
	    ['application/x-mswrite', 'wri'],
	    ['application/x-navi-animation', 'ani'],
	    ['application/x-navidoc', 'nvd'],
	    ['application/x-navimap', 'map'],
	    ['application/x-navistyle', 'stl'],
	    ['application/x-netcdf', ['cdf', 'nc']],
	    ['application/x-newton-compatible-pkg', 'pkg'],
	    ['application/x-nokia-9000-communicator-add-on-software', 'aos'],
	    ['application/x-omc', 'omc'],
	    ['application/x-omcdatamaker', 'omcd'],
	    ['application/x-omcregerator', 'omcr'],
	    ['application/x-pagemaker', ['pm4', 'pm5']],
	    ['application/x-pcl', 'pcl'],
	    ['application/x-perfmon', ['pma', 'pmc', 'pml', 'pmr', 'pmw']],
	    ['application/x-pixclscript', 'plx'],
	    ['application/x-pkcs10', 'p10'],
	    ['application/x-pkcs12', ['p12', 'pfx']],
	    ['application/x-pkcs7-certificates', ['p7b', 'spc']],
	    ['application/x-pkcs7-certreqresp', 'p7r'],
	    ['application/x-pkcs7-mime', ['p7m', 'p7c']],
	    ['application/x-pkcs7-signature', ['p7s', 'p7a']],
	    ['application/x-pointplus', 'css'],
	    ['application/x-portable-anymap', 'pnm'],
	    ['application/x-project', ['mpc', 'mpt', 'mpv', 'mpx']],
	    ['application/x-qpro', 'wb1'],
	    ['application/x-rar-compressed', 'rar'],
	    ['application/x-rtf', 'rtf'],
	    ['application/x-sdp', 'sdp'],
	    ['application/x-sea', 'sea'],
	    ['application/x-seelogo', 'sl'],
	    ['application/x-sh', 'sh'],
	    ['application/x-shar', ['shar', 'sh']],
	    ['application/x-shockwave-flash', 'swf'],
	    ['application/x-silverlight-app', 'xap'],
	    ['application/x-sit', 'sit'],
	    ['application/x-sprite', ['spr', 'sprite']],
	    ['application/x-stuffit', 'sit'],
	    ['application/x-stuffitx', 'sitx'],
	    ['application/x-sv4cpio', 'sv4cpio'],
	    ['application/x-sv4crc', 'sv4crc'],
	    ['application/x-tar', 'tar'],
	    ['application/x-tbook', ['sbk', 'tbk']],
	    ['application/x-tcl', 'tcl'],
	    ['application/x-tex', 'tex'],
	    ['application/x-tex-tfm', 'tfm'],
	    ['application/x-texinfo', ['texi', 'texinfo']],
	    ['application/x-troff', ['roff', 't', 'tr']],
	    ['application/x-troff-man', 'man'],
	    ['application/x-troff-me', 'me'],
	    ['application/x-troff-ms', 'ms'],
	    ['application/x-troff-msvideo', 'avi'],
	    ['application/x-ustar', 'ustar'],
	    ['application/x-visio', ['vsd', 'vst', 'vsw']],
	    ['application/x-vnd.audioexplosion.mzz', 'mzz'],
	    ['application/x-vnd.ls-xpix', 'xpix'],
	    ['application/x-vrml', 'vrml'],
	    ['application/x-wais-source', ['src', 'wsrc']],
	    ['application/x-winhelp', 'hlp'],
	    ['application/x-wintalk', 'wtk'],
	    ['application/x-world', ['wrl', 'svr']],
	    ['application/x-wpwin', 'wpd'],
	    ['application/x-wri', 'wri'],
	    ['application/x-x509-ca-cert', ['cer', 'crt', 'der']],
	    ['application/x-x509-user-cert', 'crt'],
	    ['application/x-xfig', 'fig'],
	    ['application/x-xpinstall', 'xpi'],
	    ['application/x-zip-compressed', 'zip'],
	    ['application/xcap-diff+xml', 'xdf'],
	    ['application/xenc+xml', 'xenc'],
	    ['application/xhtml+xml', 'xhtml'],
	    ['application/xml', 'xml'],
	    ['application/xml-dtd', 'dtd'],
	    ['application/xop+xml', 'xop'],
	    ['application/xslt+xml', 'xslt'],
	    ['application/xspf+xml', 'xspf'],
	    ['application/xv+xml', 'mxml'],
	    ['application/yang', 'yang'],
	    ['application/yin+xml', 'yin'],
	    ['application/ynd.ms-pkipko', 'pko'],
	    ['application/zip', 'zip'],
	    ['audio/adpcm', 'adp'],
	    ['audio/aiff', ['aiff', 'aif', 'aifc']],
	    ['audio/basic', ['snd', 'au']],
	    ['audio/it', 'it'],
	    ['audio/make', ['funk', 'my', 'pfunk']],
	    ['audio/make.my.funk', 'pfunk'],
	    ['audio/mid', ['mid', 'rmi']],
	    ['audio/midi', ['midi', 'kar', 'mid']],
	    ['audio/mod', 'mod'],
	    ['audio/mp4', 'mp4a'],
	    ['audio/mpeg', ['mpga', 'mp3', 'm2a', 'mp2', 'mpa', 'mpg']],
	    ['audio/mpeg3', 'mp3'],
	    ['audio/nspaudio', ['la', 'lma']],
	    ['audio/ogg', 'oga'],
	    ['audio/s3m', 's3m'],
	    ['audio/tsp-audio', 'tsi'],
	    ['audio/tsplayer', 'tsp'],
	    ['audio/vnd.dece.audio', 'uva'],
	    ['audio/vnd.digital-winds', 'eol'],
	    ['audio/vnd.dra', 'dra'],
	    ['audio/vnd.dts', 'dts'],
	    ['audio/vnd.dts.hd', 'dtshd'],
	    ['audio/vnd.lucent.voice', 'lvp'],
	    ['audio/vnd.ms-playready.media.pya', 'pya'],
	    ['audio/vnd.nuera.ecelp4800', 'ecelp4800'],
	    ['audio/vnd.nuera.ecelp7470', 'ecelp7470'],
	    ['audio/vnd.nuera.ecelp9600', 'ecelp9600'],
	    ['audio/vnd.qcelp', 'qcp'],
	    ['audio/vnd.rip', 'rip'],
	    ['audio/voc', 'voc'],
	    ['audio/voxware', 'vox'],
	    ['audio/wav', 'wav'],
	    ['audio/webm', 'weba'],
	    ['audio/x-aac', 'aac'],
	    ['audio/x-adpcm', 'snd'],
	    ['audio/x-aiff', ['aiff', 'aif', 'aifc']],
	    ['audio/x-au', 'au'],
	    ['audio/x-gsm', ['gsd', 'gsm']],
	    ['audio/x-jam', 'jam'],
	    ['audio/x-liveaudio', 'lam'],
	    ['audio/x-mid', ['mid', 'midi']],
	    ['audio/x-midi', ['midi', 'mid']],
	    ['audio/x-mod', 'mod'],
	    ['audio/x-mpeg', 'mp2'],
	    ['audio/x-mpeg-3', 'mp3'],
	    ['audio/x-mpegurl', 'm3u'],
	    ['audio/x-mpequrl', 'm3u'],
	    ['audio/x-ms-wax', 'wax'],
	    ['audio/x-ms-wma', 'wma'],
	    ['audio/x-nspaudio', ['la', 'lma']],
	    ['audio/x-pn-realaudio', ['ra', 'ram', 'rm', 'rmm', 'rmp']],
	    ['audio/x-pn-realaudio-plugin', ['ra', 'rmp', 'rpm']],
	    ['audio/x-psid', 'sid'],
	    ['audio/x-realaudio', 'ra'],
	    ['audio/x-twinvq', 'vqf'],
	    ['audio/x-twinvq-plugin', ['vqe', 'vql']],
	    ['audio/x-vnd.audioexplosion.mjuicemediafile', 'mjf'],
	    ['audio/x-voc', 'voc'],
	    ['audio/x-wav', 'wav'],
	    ['audio/xm', 'xm'],
	    ['chemical/x-cdx', 'cdx'],
	    ['chemical/x-cif', 'cif'],
	    ['chemical/x-cmdf', 'cmdf'],
	    ['chemical/x-cml', 'cml'],
	    ['chemical/x-csml', 'csml'],
	    ['chemical/x-pdb', ['pdb', 'xyz']],
	    ['chemical/x-xyz', 'xyz'],
	    ['drawing/x-dwf', 'dwf'],
	    ['i-world/i-vrml', 'ivr'],
	    ['image/bmp', ['bmp', 'bm']],
	    ['image/cgm', 'cgm'],
	    ['image/cis-cod', 'cod'],
	    ['image/cmu-raster', ['ras', 'rast']],
	    ['image/fif', 'fif'],
	    ['image/florian', ['flo', 'turbot']],
	    ['image/g3fax', 'g3'],
	    ['image/gif', 'gif'],
	    ['image/ief', ['ief', 'iefs']],
	    ['image/jpeg', ['jpeg', 'jpe', 'jpg', 'jfif', 'jfif-tbnl']],
	    ['image/jutvision', 'jut'],
	    ['image/ktx', 'ktx'],
	    ['image/naplps', ['nap', 'naplps']],
	    ['image/pict', ['pic', 'pict']],
	    ['image/pipeg', 'jfif'],
	    ['image/pjpeg', ['jfif', 'jpe', 'jpeg', 'jpg']],
	    ['image/png', ['png', 'x-png']],
	    ['image/prs.btif', 'btif'],
	    ['image/svg+xml', 'svg'],
	    ['image/tiff', ['tif', 'tiff']],
	    ['image/vasa', 'mcf'],
	    ['image/vnd.adobe.photoshop', 'psd'],
	    ['image/vnd.dece.graphic', 'uvi'],
	    ['image/vnd.djvu', 'djvu'],
	    ['image/vnd.dvb.subtitle', 'sub'],
	    ['image/vnd.dwg', ['dwg', 'dxf', 'svf']],
	    ['image/vnd.dxf', 'dxf'],
	    ['image/vnd.fastbidsheet', 'fbs'],
	    ['image/vnd.fpx', 'fpx'],
	    ['image/vnd.fst', 'fst'],
	    ['image/vnd.fujixerox.edmics-mmr', 'mmr'],
	    ['image/vnd.fujixerox.edmics-rlc', 'rlc'],
	    ['image/vnd.ms-modi', 'mdi'],
	    ['image/vnd.net-fpx', ['fpx', 'npx']],
	    ['image/vnd.rn-realflash', 'rf'],
	    ['image/vnd.rn-realpix', 'rp'],
	    ['image/vnd.wap.wbmp', 'wbmp'],
	    ['image/vnd.xiff', 'xif'],
	    ['image/webp', 'webp'],
	    ['image/x-cmu-raster', 'ras'],
	    ['image/x-cmx', 'cmx'],
	    ['image/x-dwg', ['dwg', 'dxf', 'svf']],
	    ['image/x-freehand', 'fh'],
	    ['image/x-icon', 'ico'],
	    ['image/x-jg', 'art'],
	    ['image/x-jps', 'jps'],
	    ['image/x-niff', ['niff', 'nif']],
	    ['image/x-pcx', 'pcx'],
	    ['image/x-pict', ['pct', 'pic']],
	    ['image/x-portable-anymap', 'pnm'],
	    ['image/x-portable-bitmap', 'pbm'],
	    ['image/x-portable-graymap', 'pgm'],
	    ['image/x-portable-greymap', 'pgm'],
	    ['image/x-portable-pixmap', 'ppm'],
	    ['image/x-quicktime', ['qif', 'qti', 'qtif']],
	    ['image/x-rgb', 'rgb'],
	    ['image/x-tiff', ['tif', 'tiff']],
	    ['image/x-windows-bmp', 'bmp'],
	    ['image/x-xbitmap', 'xbm'],
	    ['image/x-xbm', 'xbm'],
	    ['image/x-xpixmap', ['xpm', 'pm']],
	    ['image/x-xwd', 'xwd'],
	    ['image/x-xwindowdump', 'xwd'],
	    ['image/xbm', 'xbm'],
	    ['image/xpm', 'xpm'],
	    ['message/rfc822', ['eml', 'mht', 'mhtml', 'nws', 'mime']],
	    ['model/iges', ['iges', 'igs']],
	    ['model/mesh', 'msh'],
	    ['model/vnd.collada+xml', 'dae'],
	    ['model/vnd.dwf', 'dwf'],
	    ['model/vnd.gdl', 'gdl'],
	    ['model/vnd.gtw', 'gtw'],
	    ['model/vnd.mts', 'mts'],
	    ['model/vnd.vtu', 'vtu'],
	    ['model/vrml', ['vrml', 'wrl', 'wrz']],
	    ['model/x-pov', 'pov'],
	    ['multipart/x-gzip', 'gzip'],
	    ['multipart/x-ustar', 'ustar'],
	    ['multipart/x-zip', 'zip'],
	    ['music/crescendo', ['mid', 'midi']],
	    ['music/x-karaoke', 'kar'],
	    ['paleovu/x-pv', 'pvu'],
	    ['text/asp', 'asp'],
	    ['text/calendar', 'ics'],
	    ['text/css', 'css'],
	    ['text/csv', 'csv'],
	    ['text/ecmascript', 'js'],
	    ['text/h323', '323'],
	    ['text/html', ['html', 'htm', 'stm', 'acgi', 'htmls', 'htx', 'shtml']],
	    ['text/iuls', 'uls'],
	    ['text/javascript', 'js'],
	    ['text/mcf', 'mcf'],
	    ['text/n3', 'n3'],
	    ['text/pascal', 'pas'],
	    [
	        'text/plain',
	        [
	            'txt',
	            'bas',
	            'c',
	            'h',
	            'c++',
	            'cc',
	            'com',
	            'conf',
	            'cxx',
	            'def',
	            'f',
	            'f90',
	            'for',
	            'g',
	            'hh',
	            'idc',
	            'jav',
	            'java',
	            'list',
	            'log',
	            'lst',
	            'm',
	            'mar',
	            'pl',
	            'sdml',
	            'text'
	        ]
	    ],
	    ['text/plain-bas', 'par'],
	    ['text/prs.lines.tag', 'dsc'],
	    ['text/richtext', ['rtx', 'rt', 'rtf']],
	    ['text/scriplet', 'wsc'],
	    ['text/scriptlet', 'sct'],
	    ['text/sgml', ['sgm', 'sgml']],
	    ['text/tab-separated-values', 'tsv'],
	    ['text/troff', 't'],
	    ['text/turtle', 'ttl'],
	    ['text/uri-list', ['uni', 'unis', 'uri', 'uris']],
	    ['text/vnd.abc', 'abc'],
	    ['text/vnd.curl', 'curl'],
	    ['text/vnd.curl.dcurl', 'dcurl'],
	    ['text/vnd.curl.mcurl', 'mcurl'],
	    ['text/vnd.curl.scurl', 'scurl'],
	    ['text/vnd.fly', 'fly'],
	    ['text/vnd.fmi.flexstor', 'flx'],
	    ['text/vnd.graphviz', 'gv'],
	    ['text/vnd.in3d.3dml', '3dml'],
	    ['text/vnd.in3d.spot', 'spot'],
	    ['text/vnd.rn-realtext', 'rt'],
	    ['text/vnd.sun.j2me.app-descriptor', 'jad'],
	    ['text/vnd.wap.wml', 'wml'],
	    ['text/vnd.wap.wmlscript', 'wmls'],
	    ['text/webviewhtml', 'htt'],
	    ['text/x-asm', ['asm', 's']],
	    ['text/x-audiosoft-intra', 'aip'],
	    ['text/x-c', ['c', 'cc', 'cpp']],
	    ['text/x-component', 'htc'],
	    ['text/x-fortran', ['for', 'f', 'f77', 'f90']],
	    ['text/x-h', ['h', 'hh']],
	    ['text/x-java-source', ['java', 'jav']],
	    ['text/x-java-source,java', 'java'],
	    ['text/x-la-asf', 'lsx'],
	    ['text/x-m', 'm'],
	    ['text/x-pascal', 'p'],
	    ['text/x-script', 'hlb'],
	    ['text/x-script.csh', 'csh'],
	    ['text/x-script.elisp', 'el'],
	    ['text/x-script.guile', 'scm'],
	    ['text/x-script.ksh', 'ksh'],
	    ['text/x-script.lisp', 'lsp'],
	    ['text/x-script.perl', 'pl'],
	    ['text/x-script.perl-module', 'pm'],
	    ['text/x-script.phyton', 'py'],
	    ['text/x-script.rexx', 'rexx'],
	    ['text/x-script.scheme', 'scm'],
	    ['text/x-script.sh', 'sh'],
	    ['text/x-script.tcl', 'tcl'],
	    ['text/x-script.tcsh', 'tcsh'],
	    ['text/x-script.zsh', 'zsh'],
	    ['text/x-server-parsed-html', ['shtml', 'ssi']],
	    ['text/x-setext', 'etx'],
	    ['text/x-sgml', ['sgm', 'sgml']],
	    ['text/x-speech', ['spc', 'talk']],
	    ['text/x-uil', 'uil'],
	    ['text/x-uuencode', ['uu', 'uue']],
	    ['text/x-vcalendar', 'vcs'],
	    ['text/x-vcard', 'vcf'],
	    ['text/xml', 'xml'],
	    ['video/3gpp', '3gp'],
	    ['video/3gpp2', '3g2'],
	    ['video/animaflex', 'afl'],
	    ['video/avi', 'avi'],
	    ['video/avs-video', 'avs'],
	    ['video/dl', 'dl'],
	    ['video/fli', 'fli'],
	    ['video/gl', 'gl'],
	    ['video/h261', 'h261'],
	    ['video/h263', 'h263'],
	    ['video/h264', 'h264'],
	    ['video/jpeg', 'jpgv'],
	    ['video/jpm', 'jpm'],
	    ['video/mj2', 'mj2'],
	    ['video/mp4', 'mp4'],
	    ['video/mpeg', ['mpeg', 'mp2', 'mpa', 'mpe', 'mpg', 'mpv2', 'm1v', 'm2v', 'mp3']],
	    ['video/msvideo', 'avi'],
	    ['video/ogg', 'ogv'],
	    ['video/quicktime', ['mov', 'qt', 'moov']],
	    ['video/vdo', 'vdo'],
	    ['video/vivo', ['viv', 'vivo']],
	    ['video/vnd.dece.hd', 'uvh'],
	    ['video/vnd.dece.mobile', 'uvm'],
	    ['video/vnd.dece.pd', 'uvp'],
	    ['video/vnd.dece.sd', 'uvs'],
	    ['video/vnd.dece.video', 'uvv'],
	    ['video/vnd.fvt', 'fvt'],
	    ['video/vnd.mpegurl', 'mxu'],
	    ['video/vnd.ms-playready.media.pyv', 'pyv'],
	    ['video/vnd.rn-realvideo', 'rv'],
	    ['video/vnd.uvvu.mp4', 'uvu'],
	    ['video/vnd.vivo', ['viv', 'vivo']],
	    ['video/vosaic', 'vos'],
	    ['video/webm', 'webm'],
	    ['video/x-amt-demorun', 'xdr'],
	    ['video/x-amt-showrun', 'xsr'],
	    ['video/x-atomic3d-feature', 'fmf'],
	    ['video/x-dl', 'dl'],
	    ['video/x-dv', ['dif', 'dv']],
	    ['video/x-f4v', 'f4v'],
	    ['video/x-fli', 'fli'],
	    ['video/x-flv', 'flv'],
	    ['video/x-gl', 'gl'],
	    ['video/x-isvideo', 'isu'],
	    ['video/x-la-asf', ['lsf', 'lsx']],
	    ['video/x-m4v', 'm4v'],
	    ['video/x-motion-jpeg', 'mjpg'],
	    ['video/x-mpeg', ['mp3', 'mp2']],
	    ['video/x-mpeq2a', 'mp2'],
	    ['video/x-ms-asf', ['asf', 'asr', 'asx']],
	    ['video/x-ms-asf-plugin', 'asx'],
	    ['video/x-ms-wm', 'wm'],
	    ['video/x-ms-wmv', 'wmv'],
	    ['video/x-ms-wmx', 'wmx'],
	    ['video/x-ms-wvx', 'wvx'],
	    ['video/x-msvideo', 'avi'],
	    ['video/x-qtc', 'qtc'],
	    ['video/x-scm', 'scm'],
	    ['video/x-sgi-movie', ['movie', 'mv']],
	    ['windows/metafile', 'wmf'],
	    ['www/mime', 'mime'],
	    ['x-conference/x-cooltalk', 'ice'],
	    ['x-music/x-midi', ['mid', 'midi']],
	    ['x-world/x-3dmf', ['3dm', '3dmf', 'qd3', 'qd3d']],
	    ['x-world/x-svr', 'svr'],
	    ['x-world/x-vrml', ['flr', 'vrml', 'wrl', 'wrz', 'xaf', 'xof']],
	    ['x-world/x-vrt', 'vrt'],
	    ['xgl/drawing', 'xgz'],
	    ['xgl/movie', 'xmz']
	]);
	const extensions = new Map([
	    ['123', 'application/vnd.lotus-1-2-3'],
	    ['323', 'text/h323'],
	    ['*', 'application/octet-stream'],
	    ['3dm', 'x-world/x-3dmf'],
	    ['3dmf', 'x-world/x-3dmf'],
	    ['3dml', 'text/vnd.in3d.3dml'],
	    ['3g2', 'video/3gpp2'],
	    ['3gp', 'video/3gpp'],
	    ['7z', 'application/x-7z-compressed'],
	    ['a', 'application/octet-stream'],
	    ['aab', 'application/x-authorware-bin'],
	    ['aac', 'audio/x-aac'],
	    ['aam', 'application/x-authorware-map'],
	    ['aas', 'application/x-authorware-seg'],
	    ['abc', 'text/vnd.abc'],
	    ['abw', 'application/x-abiword'],
	    ['ac', 'application/pkix-attr-cert'],
	    ['acc', 'application/vnd.americandynamics.acc'],
	    ['ace', 'application/x-ace-compressed'],
	    ['acgi', 'text/html'],
	    ['acu', 'application/vnd.acucobol'],
	    ['acx', 'application/internet-property-stream'],
	    ['adp', 'audio/adpcm'],
	    ['aep', 'application/vnd.audiograph'],
	    ['afl', 'video/animaflex'],
	    ['afp', 'application/vnd.ibm.modcap'],
	    ['ahead', 'application/vnd.ahead.space'],
	    ['ai', 'application/postscript'],
	    ['aif', ['audio/aiff', 'audio/x-aiff']],
	    ['aifc', ['audio/aiff', 'audio/x-aiff']],
	    ['aiff', ['audio/aiff', 'audio/x-aiff']],
	    ['aim', 'application/x-aim'],
	    ['aip', 'text/x-audiosoft-intra'],
	    ['air', 'application/vnd.adobe.air-application-installer-package+zip'],
	    ['ait', 'application/vnd.dvb.ait'],
	    ['ami', 'application/vnd.amiga.ami'],
	    ['ani', 'application/x-navi-animation'],
	    ['aos', 'application/x-nokia-9000-communicator-add-on-software'],
	    ['apk', 'application/vnd.android.package-archive'],
	    ['application', 'application/x-ms-application'],
	    ['apr', 'application/vnd.lotus-approach'],
	    ['aps', 'application/mime'],
	    ['arc', 'application/octet-stream'],
	    ['arj', ['application/arj', 'application/octet-stream']],
	    ['art', 'image/x-jg'],
	    ['asf', 'video/x-ms-asf'],
	    ['asm', 'text/x-asm'],
	    ['aso', 'application/vnd.accpac.simply.aso'],
	    ['asp', 'text/asp'],
	    ['asr', 'video/x-ms-asf'],
	    ['asx', ['video/x-ms-asf', 'application/x-mplayer2', 'video/x-ms-asf-plugin']],
	    ['atc', 'application/vnd.acucorp'],
	    ['atomcat', 'application/atomcat+xml'],
	    ['atomsvc', 'application/atomsvc+xml'],
	    ['atx', 'application/vnd.antix.game-component'],
	    ['au', ['audio/basic', 'audio/x-au']],
	    ['avi', ['video/avi', 'video/msvideo', 'application/x-troff-msvideo', 'video/x-msvideo']],
	    ['avs', 'video/avs-video'],
	    ['aw', 'application/applixware'],
	    ['axs', 'application/olescript'],
	    ['azf', 'application/vnd.airzip.filesecure.azf'],
	    ['azs', 'application/vnd.airzip.filesecure.azs'],
	    ['azw', 'application/vnd.amazon.ebook'],
	    ['bas', 'text/plain'],
	    ['bcpio', 'application/x-bcpio'],
	    ['bdf', 'application/x-font-bdf'],
	    ['bdm', 'application/vnd.syncml.dm+wbxml'],
	    ['bed', 'application/vnd.realvnc.bed'],
	    ['bh2', 'application/vnd.fujitsu.oasysprs'],
	    [
	        'bin',
	        ['application/octet-stream', 'application/mac-binary', 'application/macbinary', 'application/x-macbinary', 'application/x-binary']
	    ],
	    ['bm', 'image/bmp'],
	    ['bmi', 'application/vnd.bmi'],
	    ['bmp', ['image/bmp', 'image/x-windows-bmp']],
	    ['boo', 'application/book'],
	    ['book', 'application/book'],
	    ['box', 'application/vnd.previewsystems.box'],
	    ['boz', 'application/x-bzip2'],
	    ['bsh', 'application/x-bsh'],
	    ['btif', 'image/prs.btif'],
	    ['bz', 'application/x-bzip'],
	    ['bz2', 'application/x-bzip2'],
	    ['c', ['text/plain', 'text/x-c']],
	    ['c++', 'text/plain'],
	    ['c11amc', 'application/vnd.cluetrust.cartomobile-config'],
	    ['c11amz', 'application/vnd.cluetrust.cartomobile-config-pkg'],
	    ['c4g', 'application/vnd.clonk.c4group'],
	    ['cab', 'application/vnd.ms-cab-compressed'],
	    ['car', 'application/vnd.curl.car'],
	    ['cat', ['application/vnd.ms-pkiseccat', 'application/vnd.ms-pki.seccat']],
	    ['cc', ['text/plain', 'text/x-c']],
	    ['ccad', 'application/clariscad'],
	    ['cco', 'application/x-cocoa'],
	    ['ccxml', 'application/ccxml+xml,'],
	    ['cdbcmsg', 'application/vnd.contact.cmsg'],
	    ['cdf', ['application/cdf', 'application/x-cdf', 'application/x-netcdf']],
	    ['cdkey', 'application/vnd.mediastation.cdkey'],
	    ['cdmia', 'application/cdmi-capability'],
	    ['cdmic', 'application/cdmi-container'],
	    ['cdmid', 'application/cdmi-domain'],
	    ['cdmio', 'application/cdmi-object'],
	    ['cdmiq', 'application/cdmi-queue'],
	    ['cdx', 'chemical/x-cdx'],
	    ['cdxml', 'application/vnd.chemdraw+xml'],
	    ['cdy', 'application/vnd.cinderella'],
	    ['cer', ['application/pkix-cert', 'application/x-x509-ca-cert']],
	    ['cgm', 'image/cgm'],
	    ['cha', 'application/x-chat'],
	    ['chat', 'application/x-chat'],
	    ['chm', 'application/vnd.ms-htmlhelp'],
	    ['chrt', 'application/vnd.kde.kchart'],
	    ['cif', 'chemical/x-cif'],
	    ['cii', 'application/vnd.anser-web-certificate-issue-initiation'],
	    ['cil', 'application/vnd.ms-artgalry'],
	    ['cla', 'application/vnd.claymore'],
	    [
	        'class',
	        ['application/octet-stream', 'application/java', 'application/java-byte-code', 'application/java-vm', 'application/x-java-class']
	    ],
	    ['clkk', 'application/vnd.crick.clicker.keyboard'],
	    ['clkp', 'application/vnd.crick.clicker.palette'],
	    ['clkt', 'application/vnd.crick.clicker.template'],
	    ['clkw', 'application/vnd.crick.clicker.wordbank'],
	    ['clkx', 'application/vnd.crick.clicker'],
	    ['clp', 'application/x-msclip'],
	    ['cmc', 'application/vnd.cosmocaller'],
	    ['cmdf', 'chemical/x-cmdf'],
	    ['cml', 'chemical/x-cml'],
	    ['cmp', 'application/vnd.yellowriver-custom-menu'],
	    ['cmx', 'image/x-cmx'],
	    ['cod', ['image/cis-cod', 'application/vnd.rim.cod']],
	    ['com', ['application/octet-stream', 'text/plain']],
	    ['conf', 'text/plain'],
	    ['cpio', 'application/x-cpio'],
	    ['cpp', 'text/x-c'],
	    ['cpt', ['application/mac-compactpro', 'application/x-compactpro', 'application/x-cpt']],
	    ['crd', 'application/x-mscardfile'],
	    ['crl', ['application/pkix-crl', 'application/pkcs-crl']],
	    ['crt', ['application/pkix-cert', 'application/x-x509-user-cert', 'application/x-x509-ca-cert']],
	    ['cryptonote', 'application/vnd.rig.cryptonote'],
	    ['csh', ['text/x-script.csh', 'application/x-csh']],
	    ['csml', 'chemical/x-csml'],
	    ['csp', 'application/vnd.commonspace'],
	    ['css', ['text/css', 'application/x-pointplus']],
	    ['csv', 'text/csv'],
	    ['cu', 'application/cu-seeme'],
	    ['curl', 'text/vnd.curl'],
	    ['cww', 'application/prs.cww'],
	    ['cxx', 'text/plain'],
	    ['dae', 'model/vnd.collada+xml'],
	    ['daf', 'application/vnd.mobius.daf'],
	    ['davmount', 'application/davmount+xml'],
	    ['dcr', 'application/x-director'],
	    ['dcurl', 'text/vnd.curl.dcurl'],
	    ['dd2', 'application/vnd.oma.dd2+xml'],
	    ['ddd', 'application/vnd.fujixerox.ddd'],
	    ['deb', 'application/x-debian-package'],
	    ['deepv', 'application/x-deepv'],
	    ['def', 'text/plain'],
	    ['der', 'application/x-x509-ca-cert'],
	    ['dfac', 'application/vnd.dreamfactory'],
	    ['dif', 'video/x-dv'],
	    ['dir', 'application/x-director'],
	    ['dis', 'application/vnd.mobius.dis'],
	    ['djvu', 'image/vnd.djvu'],
	    ['dl', ['video/dl', 'video/x-dl']],
	    ['dll', 'application/x-msdownload'],
	    ['dms', 'application/octet-stream'],
	    ['dna', 'application/vnd.dna'],
	    ['doc', 'application/msword'],
	    ['docm', 'application/vnd.ms-word.document.macroenabled.12'],
	    ['docx', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
	    ['dot', 'application/msword'],
	    ['dotm', 'application/vnd.ms-word.template.macroenabled.12'],
	    ['dotx', 'application/vnd.openxmlformats-officedocument.wordprocessingml.template'],
	    ['dp', ['application/commonground', 'application/vnd.osgi.dp']],
	    ['dpg', 'application/vnd.dpgraph'],
	    ['dra', 'audio/vnd.dra'],
	    ['drw', 'application/drafting'],
	    ['dsc', 'text/prs.lines.tag'],
	    ['dssc', 'application/dssc+der'],
	    ['dtb', 'application/x-dtbook+xml'],
	    ['dtd', 'application/xml-dtd'],
	    ['dts', 'audio/vnd.dts'],
	    ['dtshd', 'audio/vnd.dts.hd'],
	    ['dump', 'application/octet-stream'],
	    ['dv', 'video/x-dv'],
	    ['dvi', 'application/x-dvi'],
	    ['dwf', ['model/vnd.dwf', 'drawing/x-dwf']],
	    ['dwg', ['application/acad', 'image/vnd.dwg', 'image/x-dwg']],
	    ['dxf', ['application/dxf', 'image/vnd.dwg', 'image/vnd.dxf', 'image/x-dwg']],
	    ['dxp', 'application/vnd.spotfire.dxp'],
	    ['dxr', 'application/x-director'],
	    ['ecelp4800', 'audio/vnd.nuera.ecelp4800'],
	    ['ecelp7470', 'audio/vnd.nuera.ecelp7470'],
	    ['ecelp9600', 'audio/vnd.nuera.ecelp9600'],
	    ['edm', 'application/vnd.novadigm.edm'],
	    ['edx', 'application/vnd.novadigm.edx'],
	    ['efif', 'application/vnd.picsel'],
	    ['ei6', 'application/vnd.pg.osasli'],
	    ['el', 'text/x-script.elisp'],
	    ['elc', ['application/x-elc', 'application/x-bytecode.elisp']],
	    ['eml', 'message/rfc822'],
	    ['emma', 'application/emma+xml'],
	    ['env', 'application/x-envoy'],
	    ['eol', 'audio/vnd.digital-winds'],
	    ['eot', 'application/vnd.ms-fontobject'],
	    ['eps', 'application/postscript'],
	    ['epub', 'application/epub+zip'],
	    ['es', ['application/ecmascript', 'application/x-esrehber']],
	    ['es3', 'application/vnd.eszigno3+xml'],
	    ['esf', 'application/vnd.epson.esf'],
	    ['etx', 'text/x-setext'],
	    ['evy', ['application/envoy', 'application/x-envoy']],
	    ['exe', ['application/octet-stream', 'application/x-msdownload']],
	    ['exi', 'application/exi'],
	    ['ext', 'application/vnd.novadigm.ext'],
	    ['ez2', 'application/vnd.ezpix-album'],
	    ['ez3', 'application/vnd.ezpix-package'],
	    ['f', ['text/plain', 'text/x-fortran']],
	    ['f4v', 'video/x-f4v'],
	    ['f77', 'text/x-fortran'],
	    ['f90', ['text/plain', 'text/x-fortran']],
	    ['fbs', 'image/vnd.fastbidsheet'],
	    ['fcs', 'application/vnd.isac.fcs'],
	    ['fdf', 'application/vnd.fdf'],
	    ['fe_launch', 'application/vnd.denovo.fcselayout-link'],
	    ['fg5', 'application/vnd.fujitsu.oasysgp'],
	    ['fh', 'image/x-freehand'],
	    ['fif', ['application/fractals', 'image/fif']],
	    ['fig', 'application/x-xfig'],
	    ['fli', ['video/fli', 'video/x-fli']],
	    ['flo', ['image/florian', 'application/vnd.micrografx.flo']],
	    ['flr', 'x-world/x-vrml'],
	    ['flv', 'video/x-flv'],
	    ['flw', 'application/vnd.kde.kivio'],
	    ['flx', 'text/vnd.fmi.flexstor'],
	    ['fly', 'text/vnd.fly'],
	    ['fm', 'application/vnd.framemaker'],
	    ['fmf', 'video/x-atomic3d-feature'],
	    ['fnc', 'application/vnd.frogans.fnc'],
	    ['for', ['text/plain', 'text/x-fortran']],
	    ['fpx', ['image/vnd.fpx', 'image/vnd.net-fpx']],
	    ['frl', 'application/freeloader'],
	    ['fsc', 'application/vnd.fsc.weblaunch'],
	    ['fst', 'image/vnd.fst'],
	    ['ftc', 'application/vnd.fluxtime.clip'],
	    ['fti', 'application/vnd.anser-web-funds-transfer-initiation'],
	    ['funk', 'audio/make'],
	    ['fvt', 'video/vnd.fvt'],
	    ['fxp', 'application/vnd.adobe.fxp'],
	    ['fzs', 'application/vnd.fuzzysheet'],
	    ['g', 'text/plain'],
	    ['g2w', 'application/vnd.geoplan'],
	    ['g3', 'image/g3fax'],
	    ['g3w', 'application/vnd.geospace'],
	    ['gac', 'application/vnd.groove-account'],
	    ['gdl', 'model/vnd.gdl'],
	    ['geo', 'application/vnd.dynageo'],
	    ['geojson', 'application/geo+json'],
	    ['gex', 'application/vnd.geometry-explorer'],
	    ['ggb', 'application/vnd.geogebra.file'],
	    ['ggt', 'application/vnd.geogebra.tool'],
	    ['ghf', 'application/vnd.groove-help'],
	    ['gif', 'image/gif'],
	    ['gim', 'application/vnd.groove-identity-message'],
	    ['gl', ['video/gl', 'video/x-gl']],
	    ['gmx', 'application/vnd.gmx'],
	    ['gnumeric', 'application/x-gnumeric'],
	    ['gph', 'application/vnd.flographit'],
	    ['gqf', 'application/vnd.grafeq'],
	    ['gram', 'application/srgs'],
	    ['grv', 'application/vnd.groove-injector'],
	    ['grxml', 'application/srgs+xml'],
	    ['gsd', 'audio/x-gsm'],
	    ['gsf', 'application/x-font-ghostscript'],
	    ['gsm', 'audio/x-gsm'],
	    ['gsp', 'application/x-gsp'],
	    ['gss', 'application/x-gss'],
	    ['gtar', 'application/x-gtar'],
	    ['gtm', 'application/vnd.groove-tool-message'],
	    ['gtw', 'model/vnd.gtw'],
	    ['gv', 'text/vnd.graphviz'],
	    ['gxt', 'application/vnd.geonext'],
	    ['gz', ['application/x-gzip', 'application/x-compressed']],
	    ['gzip', ['multipart/x-gzip', 'application/x-gzip']],
	    ['h', ['text/plain', 'text/x-h']],
	    ['h261', 'video/h261'],
	    ['h263', 'video/h263'],
	    ['h264', 'video/h264'],
	    ['hal', 'application/vnd.hal+xml'],
	    ['hbci', 'application/vnd.hbci'],
	    ['hdf', 'application/x-hdf'],
	    ['help', 'application/x-helpfile'],
	    ['hgl', 'application/vnd.hp-hpgl'],
	    ['hh', ['text/plain', 'text/x-h']],
	    ['hlb', 'text/x-script'],
	    ['hlp', ['application/winhlp', 'application/hlp', 'application/x-helpfile', 'application/x-winhelp']],
	    ['hpg', 'application/vnd.hp-hpgl'],
	    ['hpgl', 'application/vnd.hp-hpgl'],
	    ['hpid', 'application/vnd.hp-hpid'],
	    ['hps', 'application/vnd.hp-hps'],
	    [
	        'hqx',
	        [
	            'application/mac-binhex40',
	            'application/binhex',
	            'application/binhex4',
	            'application/mac-binhex',
	            'application/x-binhex40',
	            'application/x-mac-binhex40'
	        ]
	    ],
	    ['hta', 'application/hta'],
	    ['htc', 'text/x-component'],
	    ['htke', 'application/vnd.kenameaapp'],
	    ['htm', 'text/html'],
	    ['html', 'text/html'],
	    ['htmls', 'text/html'],
	    ['htt', 'text/webviewhtml'],
	    ['htx', 'text/html'],
	    ['hvd', 'application/vnd.yamaha.hv-dic'],
	    ['hvp', 'application/vnd.yamaha.hv-voice'],
	    ['hvs', 'application/vnd.yamaha.hv-script'],
	    ['i2g', 'application/vnd.intergeo'],
	    ['icc', 'application/vnd.iccprofile'],
	    ['ice', 'x-conference/x-cooltalk'],
	    ['ico', 'image/x-icon'],
	    ['ics', 'text/calendar'],
	    ['idc', 'text/plain'],
	    ['ief', 'image/ief'],
	    ['iefs', 'image/ief'],
	    ['ifm', 'application/vnd.shana.informed.formdata'],
	    ['iges', ['application/iges', 'model/iges']],
	    ['igl', 'application/vnd.igloader'],
	    ['igm', 'application/vnd.insors.igm'],
	    ['igs', ['application/iges', 'model/iges']],
	    ['igx', 'application/vnd.micrografx.igx'],
	    ['iif', 'application/vnd.shana.informed.interchange'],
	    ['iii', 'application/x-iphone'],
	    ['ima', 'application/x-ima'],
	    ['imap', 'application/x-httpd-imap'],
	    ['imp', 'application/vnd.accpac.simply.imp'],
	    ['ims', 'application/vnd.ms-ims'],
	    ['inf', 'application/inf'],
	    ['ins', ['application/x-internet-signup', 'application/x-internett-signup']],
	    ['ip', 'application/x-ip2'],
	    ['ipfix', 'application/ipfix'],
	    ['ipk', 'application/vnd.shana.informed.package'],
	    ['irm', 'application/vnd.ibm.rights-management'],
	    ['irp', 'application/vnd.irepository.package+xml'],
	    ['isp', 'application/x-internet-signup'],
	    ['isu', 'video/x-isvideo'],
	    ['it', 'audio/it'],
	    ['itp', 'application/vnd.shana.informed.formtemplate'],
	    ['iv', 'application/x-inventor'],
	    ['ivp', 'application/vnd.immervision-ivp'],
	    ['ivr', 'i-world/i-vrml'],
	    ['ivu', 'application/vnd.immervision-ivu'],
	    ['ivy', 'application/x-livescreen'],
	    ['jad', 'text/vnd.sun.j2me.app-descriptor'],
	    ['jam', ['application/vnd.jam', 'audio/x-jam']],
	    ['jar', 'application/java-archive'],
	    ['jav', ['text/plain', 'text/x-java-source']],
	    ['java', ['text/plain', 'text/x-java-source,java', 'text/x-java-source']],
	    ['jcm', 'application/x-java-commerce'],
	    ['jfif', ['image/pipeg', 'image/jpeg', 'image/pjpeg']],
	    ['jfif-tbnl', 'image/jpeg'],
	    ['jisp', 'application/vnd.jisp'],
	    ['jlt', 'application/vnd.hp-jlyt'],
	    ['jnlp', 'application/x-java-jnlp-file'],
	    ['joda', 'application/vnd.joost.joda-archive'],
	    ['jpe', ['image/jpeg', 'image/pjpeg']],
	    ['jpeg', ['image/jpeg', 'image/pjpeg']],
	    ['jpg', ['image/jpeg', 'image/pjpeg']],
	    ['jpgv', 'video/jpeg'],
	    ['jpm', 'video/jpm'],
	    ['jps', 'image/x-jps'],
	    ['js', ['application/javascript', 'application/ecmascript', 'text/javascript', 'text/ecmascript', 'application/x-javascript']],
	    ['json', 'application/json'],
	    ['jut', 'image/jutvision'],
	    ['kar', ['audio/midi', 'music/x-karaoke']],
	    ['karbon', 'application/vnd.kde.karbon'],
	    ['kfo', 'application/vnd.kde.kformula'],
	    ['kia', 'application/vnd.kidspiration'],
	    ['kml', 'application/vnd.google-earth.kml+xml'],
	    ['kmz', 'application/vnd.google-earth.kmz'],
	    ['kne', 'application/vnd.kinar'],
	    ['kon', 'application/vnd.kde.kontour'],
	    ['kpr', 'application/vnd.kde.kpresenter'],
	    ['ksh', ['application/x-ksh', 'text/x-script.ksh']],
	    ['ksp', 'application/vnd.kde.kspread'],
	    ['ktx', 'image/ktx'],
	    ['ktz', 'application/vnd.kahootz'],
	    ['kwd', 'application/vnd.kde.kword'],
	    ['la', ['audio/nspaudio', 'audio/x-nspaudio']],
	    ['lam', 'audio/x-liveaudio'],
	    ['lasxml', 'application/vnd.las.las+xml'],
	    ['latex', 'application/x-latex'],
	    ['lbd', 'application/vnd.llamagraphics.life-balance.desktop'],
	    ['lbe', 'application/vnd.llamagraphics.life-balance.exchange+xml'],
	    ['les', 'application/vnd.hhe.lesson-player'],
	    ['lha', ['application/octet-stream', 'application/lha', 'application/x-lha']],
	    ['lhx', 'application/octet-stream'],
	    ['link66', 'application/vnd.route66.link66+xml'],
	    ['list', 'text/plain'],
	    ['lma', ['audio/nspaudio', 'audio/x-nspaudio']],
	    ['log', 'text/plain'],
	    ['lrm', 'application/vnd.ms-lrm'],
	    ['lsf', 'video/x-la-asf'],
	    ['lsp', ['application/x-lisp', 'text/x-script.lisp']],
	    ['lst', 'text/plain'],
	    ['lsx', ['video/x-la-asf', 'text/x-la-asf']],
	    ['ltf', 'application/vnd.frogans.ltf'],
	    ['ltx', 'application/x-latex'],
	    ['lvp', 'audio/vnd.lucent.voice'],
	    ['lwp', 'application/vnd.lotus-wordpro'],
	    ['lzh', ['application/octet-stream', 'application/x-lzh']],
	    ['lzx', ['application/lzx', 'application/octet-stream', 'application/x-lzx']],
	    ['m', ['text/plain', 'text/x-m']],
	    ['m13', 'application/x-msmediaview'],
	    ['m14', 'application/x-msmediaview'],
	    ['m1v', 'video/mpeg'],
	    ['m21', 'application/mp21'],
	    ['m2a', 'audio/mpeg'],
	    ['m2v', 'video/mpeg'],
	    ['m3u', ['audio/x-mpegurl', 'audio/x-mpequrl']],
	    ['m3u8', 'application/vnd.apple.mpegurl'],
	    ['m4v', 'video/x-m4v'],
	    ['ma', 'application/mathematica'],
	    ['mads', 'application/mads+xml'],
	    ['mag', 'application/vnd.ecowin.chart'],
	    ['man', 'application/x-troff-man'],
	    ['map', 'application/x-navimap'],
	    ['mar', 'text/plain'],
	    ['mathml', 'application/mathml+xml'],
	    ['mbd', 'application/mbedlet'],
	    ['mbk', 'application/vnd.mobius.mbk'],
	    ['mbox', 'application/mbox'],
	    ['mc$', 'application/x-magic-cap-package-1.0'],
	    ['mc1', 'application/vnd.medcalcdata'],
	    ['mcd', ['application/mcad', 'application/vnd.mcd', 'application/x-mathcad']],
	    ['mcf', ['image/vasa', 'text/mcf']],
	    ['mcp', 'application/netmc'],
	    ['mcurl', 'text/vnd.curl.mcurl'],
	    ['mdb', 'application/x-msaccess'],
	    ['mdi', 'image/vnd.ms-modi'],
	    ['me', 'application/x-troff-me'],
	    ['meta4', 'application/metalink4+xml'],
	    ['mets', 'application/mets+xml'],
	    ['mfm', 'application/vnd.mfmp'],
	    ['mgp', 'application/vnd.osgeo.mapguide.package'],
	    ['mgz', 'application/vnd.proteus.magazine'],
	    ['mht', 'message/rfc822'],
	    ['mhtml', 'message/rfc822'],
	    ['mid', ['audio/mid', 'audio/midi', 'music/crescendo', 'x-music/x-midi', 'audio/x-midi', 'application/x-midi', 'audio/x-mid']],
	    ['midi', ['audio/midi', 'music/crescendo', 'x-music/x-midi', 'audio/x-midi', 'application/x-midi', 'audio/x-mid']],
	    ['mif', ['application/vnd.mif', 'application/x-mif', 'application/x-frame']],
	    ['mime', ['message/rfc822', 'www/mime']],
	    ['mj2', 'video/mj2'],
	    ['mjf', 'audio/x-vnd.audioexplosion.mjuicemediafile'],
	    ['mjpg', 'video/x-motion-jpeg'],
	    ['mlp', 'application/vnd.dolby.mlp'],
	    ['mm', ['application/base64', 'application/x-meme']],
	    ['mmd', 'application/vnd.chipnuts.karaoke-mmd'],
	    ['mme', 'application/base64'],
	    ['mmf', 'application/vnd.smaf'],
	    ['mmr', 'image/vnd.fujixerox.edmics-mmr'],
	    ['mny', 'application/x-msmoney'],
	    ['mod', ['audio/mod', 'audio/x-mod']],
	    ['mods', 'application/mods+xml'],
	    ['moov', 'video/quicktime'],
	    ['mov', 'video/quicktime'],
	    ['movie', 'video/x-sgi-movie'],
	    ['mp2', ['video/mpeg', 'audio/mpeg', 'video/x-mpeg', 'audio/x-mpeg', 'video/x-mpeq2a']],
	    ['mp3', ['audio/mpeg', 'audio/mpeg3', 'video/mpeg', 'audio/x-mpeg-3', 'video/x-mpeg']],
	    ['mp4', ['video/mp4', 'application/mp4']],
	    ['mp4a', 'audio/mp4'],
	    ['mpa', ['video/mpeg', 'audio/mpeg']],
	    ['mpc', ['application/vnd.mophun.certificate', 'application/x-project']],
	    ['mpe', 'video/mpeg'],
	    ['mpeg', 'video/mpeg'],
	    ['mpg', ['video/mpeg', 'audio/mpeg']],
	    ['mpga', 'audio/mpeg'],
	    ['mpkg', 'application/vnd.apple.installer+xml'],
	    ['mpm', 'application/vnd.blueice.multipass'],
	    ['mpn', 'application/vnd.mophun.application'],
	    ['mpp', 'application/vnd.ms-project'],
	    ['mpt', 'application/x-project'],
	    ['mpv', 'application/x-project'],
	    ['mpv2', 'video/mpeg'],
	    ['mpx', 'application/x-project'],
	    ['mpy', 'application/vnd.ibm.minipay'],
	    ['mqy', 'application/vnd.mobius.mqy'],
	    ['mrc', 'application/marc'],
	    ['mrcx', 'application/marcxml+xml'],
	    ['ms', 'application/x-troff-ms'],
	    ['mscml', 'application/mediaservercontrol+xml'],
	    ['mseq', 'application/vnd.mseq'],
	    ['msf', 'application/vnd.epson.msf'],
	    ['msg', 'application/vnd.ms-outlook'],
	    ['msh', 'model/mesh'],
	    ['msl', 'application/vnd.mobius.msl'],
	    ['msty', 'application/vnd.muvee.style'],
	    ['mts', 'model/vnd.mts'],
	    ['mus', 'application/vnd.musician'],
	    ['musicxml', 'application/vnd.recordare.musicxml+xml'],
	    ['mv', 'video/x-sgi-movie'],
	    ['mvb', 'application/x-msmediaview'],
	    ['mwf', 'application/vnd.mfer'],
	    ['mxf', 'application/mxf'],
	    ['mxl', 'application/vnd.recordare.musicxml'],
	    ['mxml', 'application/xv+xml'],
	    ['mxs', 'application/vnd.triscape.mxs'],
	    ['mxu', 'video/vnd.mpegurl'],
	    ['my', 'audio/make'],
	    ['mzz', 'application/x-vnd.audioexplosion.mzz'],
	    ['n-gage', 'application/vnd.nokia.n-gage.symbian.install'],
	    ['n3', 'text/n3'],
	    ['nap', 'image/naplps'],
	    ['naplps', 'image/naplps'],
	    ['nbp', 'application/vnd.wolfram.player'],
	    ['nc', 'application/x-netcdf'],
	    ['ncm', 'application/vnd.nokia.configuration-message'],
	    ['ncx', 'application/x-dtbncx+xml'],
	    ['ngdat', 'application/vnd.nokia.n-gage.data'],
	    ['nif', 'image/x-niff'],
	    ['niff', 'image/x-niff'],
	    ['nix', 'application/x-mix-transfer'],
	    ['nlu', 'application/vnd.neurolanguage.nlu'],
	    ['nml', 'application/vnd.enliven'],
	    ['nnd', 'application/vnd.noblenet-directory'],
	    ['nns', 'application/vnd.noblenet-sealer'],
	    ['nnw', 'application/vnd.noblenet-web'],
	    ['npx', 'image/vnd.net-fpx'],
	    ['nsc', 'application/x-conference'],
	    ['nsf', 'application/vnd.lotus-notes'],
	    ['nvd', 'application/x-navidoc'],
	    ['nws', 'message/rfc822'],
	    ['o', 'application/octet-stream'],
	    ['oa2', 'application/vnd.fujitsu.oasys2'],
	    ['oa3', 'application/vnd.fujitsu.oasys3'],
	    ['oas', 'application/vnd.fujitsu.oasys'],
	    ['obd', 'application/x-msbinder'],
	    ['oda', 'application/oda'],
	    ['odb', 'application/vnd.oasis.opendocument.database'],
	    ['odc', 'application/vnd.oasis.opendocument.chart'],
	    ['odf', 'application/vnd.oasis.opendocument.formula'],
	    ['odft', 'application/vnd.oasis.opendocument.formula-template'],
	    ['odg', 'application/vnd.oasis.opendocument.graphics'],
	    ['odi', 'application/vnd.oasis.opendocument.image'],
	    ['odm', 'application/vnd.oasis.opendocument.text-master'],
	    ['odp', 'application/vnd.oasis.opendocument.presentation'],
	    ['ods', 'application/vnd.oasis.opendocument.spreadsheet'],
	    ['odt', 'application/vnd.oasis.opendocument.text'],
	    ['oga', 'audio/ogg'],
	    ['ogv', 'video/ogg'],
	    ['ogx', 'application/ogg'],
	    ['omc', 'application/x-omc'],
	    ['omcd', 'application/x-omcdatamaker'],
	    ['omcr', 'application/x-omcregerator'],
	    ['onetoc', 'application/onenote'],
	    ['opf', 'application/oebps-package+xml'],
	    ['org', 'application/vnd.lotus-organizer'],
	    ['osf', 'application/vnd.yamaha.openscoreformat'],
	    ['osfpvg', 'application/vnd.yamaha.openscoreformat.osfpvg+xml'],
	    ['otc', 'application/vnd.oasis.opendocument.chart-template'],
	    ['otf', 'application/x-font-otf'],
	    ['otg', 'application/vnd.oasis.opendocument.graphics-template'],
	    ['oth', 'application/vnd.oasis.opendocument.text-web'],
	    ['oti', 'application/vnd.oasis.opendocument.image-template'],
	    ['otp', 'application/vnd.oasis.opendocument.presentation-template'],
	    ['ots', 'application/vnd.oasis.opendocument.spreadsheet-template'],
	    ['ott', 'application/vnd.oasis.opendocument.text-template'],
	    ['oxt', 'application/vnd.openofficeorg.extension'],
	    ['p', 'text/x-pascal'],
	    ['p10', ['application/pkcs10', 'application/x-pkcs10']],
	    ['p12', ['application/pkcs-12', 'application/x-pkcs12']],
	    ['p7a', 'application/x-pkcs7-signature'],
	    ['p7b', 'application/x-pkcs7-certificates'],
	    ['p7c', ['application/pkcs7-mime', 'application/x-pkcs7-mime']],
	    ['p7m', ['application/pkcs7-mime', 'application/x-pkcs7-mime']],
	    ['p7r', 'application/x-pkcs7-certreqresp'],
	    ['p7s', ['application/pkcs7-signature', 'application/x-pkcs7-signature']],
	    ['p8', 'application/pkcs8'],
	    ['par', 'text/plain-bas'],
	    ['part', 'application/pro_eng'],
	    ['pas', 'text/pascal'],
	    ['paw', 'application/vnd.pawaafile'],
	    ['pbd', 'application/vnd.powerbuilder6'],
	    ['pbm', 'image/x-portable-bitmap'],
	    ['pcf', 'application/x-font-pcf'],
	    ['pcl', ['application/vnd.hp-pcl', 'application/x-pcl']],
	    ['pclxl', 'application/vnd.hp-pclxl'],
	    ['pct', 'image/x-pict'],
	    ['pcurl', 'application/vnd.curl.pcurl'],
	    ['pcx', 'image/x-pcx'],
	    ['pdb', ['application/vnd.palm', 'chemical/x-pdb']],
	    ['pdf', 'application/pdf'],
	    ['pfa', 'application/x-font-type1'],
	    ['pfr', 'application/font-tdpfr'],
	    ['pfunk', ['audio/make', 'audio/make.my.funk']],
	    ['pfx', 'application/x-pkcs12'],
	    ['pgm', ['image/x-portable-graymap', 'image/x-portable-greymap']],
	    ['pgn', 'application/x-chess-pgn'],
	    ['pgp', 'application/pgp-signature'],
	    ['pic', ['image/pict', 'image/x-pict']],
	    ['pict', 'image/pict'],
	    ['pkg', 'application/x-newton-compatible-pkg'],
	    ['pki', 'application/pkixcmp'],
	    ['pkipath', 'application/pkix-pkipath'],
	    ['pko', ['application/ynd.ms-pkipko', 'application/vnd.ms-pki.pko']],
	    ['pl', ['text/plain', 'text/x-script.perl']],
	    ['plb', 'application/vnd.3gpp.pic-bw-large'],
	    ['plc', 'application/vnd.mobius.plc'],
	    ['plf', 'application/vnd.pocketlearn'],
	    ['pls', 'application/pls+xml'],
	    ['plx', 'application/x-pixclscript'],
	    ['pm', ['text/x-script.perl-module', 'image/x-xpixmap']],
	    ['pm4', 'application/x-pagemaker'],
	    ['pm5', 'application/x-pagemaker'],
	    ['pma', 'application/x-perfmon'],
	    ['pmc', 'application/x-perfmon'],
	    ['pml', ['application/vnd.ctc-posml', 'application/x-perfmon']],
	    ['pmr', 'application/x-perfmon'],
	    ['pmw', 'application/x-perfmon'],
	    ['png', 'image/png'],
	    ['pnm', ['application/x-portable-anymap', 'image/x-portable-anymap']],
	    ['portpkg', 'application/vnd.macports.portpkg'],
	    ['pot', ['application/vnd.ms-powerpoint', 'application/mspowerpoint']],
	    ['potm', 'application/vnd.ms-powerpoint.template.macroenabled.12'],
	    ['potx', 'application/vnd.openxmlformats-officedocument.presentationml.template'],
	    ['pov', 'model/x-pov'],
	    ['ppa', 'application/vnd.ms-powerpoint'],
	    ['ppam', 'application/vnd.ms-powerpoint.addin.macroenabled.12'],
	    ['ppd', 'application/vnd.cups-ppd'],
	    ['ppm', 'image/x-portable-pixmap'],
	    ['pps', ['application/vnd.ms-powerpoint', 'application/mspowerpoint']],
	    ['ppsm', 'application/vnd.ms-powerpoint.slideshow.macroenabled.12'],
	    ['ppsx', 'application/vnd.openxmlformats-officedocument.presentationml.slideshow'],
	    ['ppt', ['application/vnd.ms-powerpoint', 'application/mspowerpoint', 'application/powerpoint', 'application/x-mspowerpoint']],
	    ['pptm', 'application/vnd.ms-powerpoint.presentation.macroenabled.12'],
	    ['pptx', 'application/vnd.openxmlformats-officedocument.presentationml.presentation'],
	    ['ppz', 'application/mspowerpoint'],
	    ['prc', 'application/x-mobipocket-ebook'],
	    ['pre', ['application/vnd.lotus-freelance', 'application/x-freelance']],
	    ['prf', 'application/pics-rules'],
	    ['prt', 'application/pro_eng'],
	    ['ps', 'application/postscript'],
	    ['psb', 'application/vnd.3gpp.pic-bw-small'],
	    ['psd', ['application/octet-stream', 'image/vnd.adobe.photoshop']],
	    ['psf', 'application/x-font-linux-psf'],
	    ['pskcxml', 'application/pskc+xml'],
	    ['ptid', 'application/vnd.pvi.ptid1'],
	    ['pub', 'application/x-mspublisher'],
	    ['pvb', 'application/vnd.3gpp.pic-bw-var'],
	    ['pvu', 'paleovu/x-pv'],
	    ['pwn', 'application/vnd.3m.post-it-notes'],
	    ['pwz', 'application/vnd.ms-powerpoint'],
	    ['py', 'text/x-script.phyton'],
	    ['pya', 'audio/vnd.ms-playready.media.pya'],
	    ['pyc', 'application/x-bytecode.python'],
	    ['pyv', 'video/vnd.ms-playready.media.pyv'],
	    ['qam', 'application/vnd.epson.quickanime'],
	    ['qbo', 'application/vnd.intu.qbo'],
	    ['qcp', 'audio/vnd.qcelp'],
	    ['qd3', 'x-world/x-3dmf'],
	    ['qd3d', 'x-world/x-3dmf'],
	    ['qfx', 'application/vnd.intu.qfx'],
	    ['qif', 'image/x-quicktime'],
	    ['qps', 'application/vnd.publishare-delta-tree'],
	    ['qt', 'video/quicktime'],
	    ['qtc', 'video/x-qtc'],
	    ['qti', 'image/x-quicktime'],
	    ['qtif', 'image/x-quicktime'],
	    ['qxd', 'application/vnd.quark.quarkxpress'],
	    ['ra', ['audio/x-realaudio', 'audio/x-pn-realaudio', 'audio/x-pn-realaudio-plugin']],
	    ['ram', 'audio/x-pn-realaudio'],
	    ['rar', 'application/x-rar-compressed'],
	    ['ras', ['image/cmu-raster', 'application/x-cmu-raster', 'image/x-cmu-raster']],
	    ['rast', 'image/cmu-raster'],
	    ['rcprofile', 'application/vnd.ipunplugged.rcprofile'],
	    ['rdf', 'application/rdf+xml'],
	    ['rdz', 'application/vnd.data-vision.rdz'],
	    ['rep', 'application/vnd.businessobjects'],
	    ['res', 'application/x-dtbresource+xml'],
	    ['rexx', 'text/x-script.rexx'],
	    ['rf', 'image/vnd.rn-realflash'],
	    ['rgb', 'image/x-rgb'],
	    ['rif', 'application/reginfo+xml'],
	    ['rip', 'audio/vnd.rip'],
	    ['rl', 'application/resource-lists+xml'],
	    ['rlc', 'image/vnd.fujixerox.edmics-rlc'],
	    ['rld', 'application/resource-lists-diff+xml'],
	    ['rm', ['application/vnd.rn-realmedia', 'audio/x-pn-realaudio']],
	    ['rmi', 'audio/mid'],
	    ['rmm', 'audio/x-pn-realaudio'],
	    ['rmp', ['audio/x-pn-realaudio-plugin', 'audio/x-pn-realaudio']],
	    ['rms', 'application/vnd.jcp.javame.midlet-rms'],
	    ['rnc', 'application/relax-ng-compact-syntax'],
	    ['rng', ['application/ringing-tones', 'application/vnd.nokia.ringing-tone']],
	    ['rnx', 'application/vnd.rn-realplayer'],
	    ['roff', 'application/x-troff'],
	    ['rp', 'image/vnd.rn-realpix'],
	    ['rp9', 'application/vnd.cloanto.rp9'],
	    ['rpm', 'audio/x-pn-realaudio-plugin'],
	    ['rpss', 'application/vnd.nokia.radio-presets'],
	    ['rpst', 'application/vnd.nokia.radio-preset'],
	    ['rq', 'application/sparql-query'],
	    ['rs', 'application/rls-services+xml'],
	    ['rsd', 'application/rsd+xml'],
	    ['rt', ['text/richtext', 'text/vnd.rn-realtext']],
	    ['rtf', ['application/rtf', 'text/richtext', 'application/x-rtf']],
	    ['rtx', ['text/richtext', 'application/rtf']],
	    ['rv', 'video/vnd.rn-realvideo'],
	    ['s', 'text/x-asm'],
	    ['s3m', 'audio/s3m'],
	    ['saf', 'application/vnd.yamaha.smaf-audio'],
	    ['saveme', 'application/octet-stream'],
	    ['sbk', 'application/x-tbook'],
	    ['sbml', 'application/sbml+xml'],
	    ['sc', 'application/vnd.ibm.secure-container'],
	    ['scd', 'application/x-msschedule'],
	    [
	        'scm',
	        ['application/vnd.lotus-screencam', 'video/x-scm', 'text/x-script.guile', 'application/x-lotusscreencam', 'text/x-script.scheme']
	    ],
	    ['scq', 'application/scvp-cv-request'],
	    ['scs', 'application/scvp-cv-response'],
	    ['sct', 'text/scriptlet'],
	    ['scurl', 'text/vnd.curl.scurl'],
	    ['sda', 'application/vnd.stardivision.draw'],
	    ['sdc', 'application/vnd.stardivision.calc'],
	    ['sdd', 'application/vnd.stardivision.impress'],
	    ['sdkm', 'application/vnd.solent.sdkm+xml'],
	    ['sdml', 'text/plain'],
	    ['sdp', ['application/sdp', 'application/x-sdp']],
	    ['sdr', 'application/sounder'],
	    ['sdw', 'application/vnd.stardivision.writer'],
	    ['sea', ['application/sea', 'application/x-sea']],
	    ['see', 'application/vnd.seemail'],
	    ['seed', 'application/vnd.fdsn.seed'],
	    ['sema', 'application/vnd.sema'],
	    ['semd', 'application/vnd.semd'],
	    ['semf', 'application/vnd.semf'],
	    ['ser', 'application/java-serialized-object'],
	    ['set', 'application/set'],
	    ['setpay', 'application/set-payment-initiation'],
	    ['setreg', 'application/set-registration-initiation'],
	    ['sfd-hdstx', 'application/vnd.hydrostatix.sof-data'],
	    ['sfs', 'application/vnd.spotfire.sfs'],
	    ['sgl', 'application/vnd.stardivision.writer-global'],
	    ['sgm', ['text/sgml', 'text/x-sgml']],
	    ['sgml', ['text/sgml', 'text/x-sgml']],
	    ['sh', ['application/x-shar', 'application/x-bsh', 'application/x-sh', 'text/x-script.sh']],
	    ['shar', ['application/x-bsh', 'application/x-shar']],
	    ['shf', 'application/shf+xml'],
	    ['shtml', ['text/html', 'text/x-server-parsed-html']],
	    ['sid', 'audio/x-psid'],
	    ['sis', 'application/vnd.symbian.install'],
	    ['sit', ['application/x-stuffit', 'application/x-sit']],
	    ['sitx', 'application/x-stuffitx'],
	    ['skd', 'application/x-koan'],
	    ['skm', 'application/x-koan'],
	    ['skp', ['application/vnd.koan', 'application/x-koan']],
	    ['skt', 'application/x-koan'],
	    ['sl', 'application/x-seelogo'],
	    ['sldm', 'application/vnd.ms-powerpoint.slide.macroenabled.12'],
	    ['sldx', 'application/vnd.openxmlformats-officedocument.presentationml.slide'],
	    ['slt', 'application/vnd.epson.salt'],
	    ['sm', 'application/vnd.stepmania.stepchart'],
	    ['smf', 'application/vnd.stardivision.math'],
	    ['smi', ['application/smil', 'application/smil+xml']],
	    ['smil', 'application/smil'],
	    ['snd', ['audio/basic', 'audio/x-adpcm']],
	    ['snf', 'application/x-font-snf'],
	    ['sol', 'application/solids'],
	    ['spc', ['text/x-speech', 'application/x-pkcs7-certificates']],
	    ['spf', 'application/vnd.yamaha.smaf-phrase'],
	    ['spl', ['application/futuresplash', 'application/x-futuresplash']],
	    ['spot', 'text/vnd.in3d.spot'],
	    ['spp', 'application/scvp-vp-response'],
	    ['spq', 'application/scvp-vp-request'],
	    ['spr', 'application/x-sprite'],
	    ['sprite', 'application/x-sprite'],
	    ['src', 'application/x-wais-source'],
	    ['sru', 'application/sru+xml'],
	    ['srx', 'application/sparql-results+xml'],
	    ['sse', 'application/vnd.kodak-descriptor'],
	    ['ssf', 'application/vnd.epson.ssf'],
	    ['ssi', 'text/x-server-parsed-html'],
	    ['ssm', 'application/streamingmedia'],
	    ['ssml', 'application/ssml+xml'],
	    ['sst', ['application/vnd.ms-pkicertstore', 'application/vnd.ms-pki.certstore']],
	    ['st', 'application/vnd.sailingtracker.track'],
	    ['stc', 'application/vnd.sun.xml.calc.template'],
	    ['std', 'application/vnd.sun.xml.draw.template'],
	    ['step', 'application/step'],
	    ['stf', 'application/vnd.wt.stf'],
	    ['sti', 'application/vnd.sun.xml.impress.template'],
	    ['stk', 'application/hyperstudio'],
	    ['stl', ['application/vnd.ms-pkistl', 'application/sla', 'application/vnd.ms-pki.stl', 'application/x-navistyle']],
	    ['stm', 'text/html'],
	    ['stp', 'application/step'],
	    ['str', 'application/vnd.pg.format'],
	    ['stw', 'application/vnd.sun.xml.writer.template'],
	    ['sub', 'image/vnd.dvb.subtitle'],
	    ['sus', 'application/vnd.sus-calendar'],
	    ['sv4cpio', 'application/x-sv4cpio'],
	    ['sv4crc', 'application/x-sv4crc'],
	    ['svc', 'application/vnd.dvb.service'],
	    ['svd', 'application/vnd.svd'],
	    ['svf', ['image/vnd.dwg', 'image/x-dwg']],
	    ['svg', 'image/svg+xml'],
	    ['svr', ['x-world/x-svr', 'application/x-world']],
	    ['swf', 'application/x-shockwave-flash'],
	    ['swi', 'application/vnd.aristanetworks.swi'],
	    ['sxc', 'application/vnd.sun.xml.calc'],
	    ['sxd', 'application/vnd.sun.xml.draw'],
	    ['sxg', 'application/vnd.sun.xml.writer.global'],
	    ['sxi', 'application/vnd.sun.xml.impress'],
	    ['sxm', 'application/vnd.sun.xml.math'],
	    ['sxw', 'application/vnd.sun.xml.writer'],
	    ['t', ['text/troff', 'application/x-troff']],
	    ['talk', 'text/x-speech'],
	    ['tao', 'application/vnd.tao.intent-module-archive'],
	    ['tar', 'application/x-tar'],
	    ['tbk', ['application/toolbook', 'application/x-tbook']],
	    ['tcap', 'application/vnd.3gpp2.tcap'],
	    ['tcl', ['text/x-script.tcl', 'application/x-tcl']],
	    ['tcsh', 'text/x-script.tcsh'],
	    ['teacher', 'application/vnd.smart.teacher'],
	    ['tei', 'application/tei+xml'],
	    ['tex', 'application/x-tex'],
	    ['texi', 'application/x-texinfo'],
	    ['texinfo', 'application/x-texinfo'],
	    ['text', ['application/plain', 'text/plain']],
	    ['tfi', 'application/thraud+xml'],
	    ['tfm', 'application/x-tex-tfm'],
	    ['tgz', ['application/gnutar', 'application/x-compressed']],
	    ['thmx', 'application/vnd.ms-officetheme'],
	    ['tif', ['image/tiff', 'image/x-tiff']],
	    ['tiff', ['image/tiff', 'image/x-tiff']],
	    ['tmo', 'application/vnd.tmobile-livetv'],
	    ['torrent', 'application/x-bittorrent'],
	    ['tpl', 'application/vnd.groove-tool-template'],
	    ['tpt', 'application/vnd.trid.tpt'],
	    ['tr', 'application/x-troff'],
	    ['tra', 'application/vnd.trueapp'],
	    ['trm', 'application/x-msterminal'],
	    ['tsd', 'application/timestamped-data'],
	    ['tsi', 'audio/tsp-audio'],
	    ['tsp', ['application/dsptype', 'audio/tsplayer']],
	    ['tsv', 'text/tab-separated-values'],
	    ['ttf', 'application/x-font-ttf'],
	    ['ttl', 'text/turtle'],
	    ['turbot', 'image/florian'],
	    ['twd', 'application/vnd.simtech-mindmapper'],
	    ['txd', 'application/vnd.genomatix.tuxedo'],
	    ['txf', 'application/vnd.mobius.txf'],
	    ['txt', 'text/plain'],
	    ['ufd', 'application/vnd.ufdl'],
	    ['uil', 'text/x-uil'],
	    ['uls', 'text/iuls'],
	    ['umj', 'application/vnd.umajin'],
	    ['uni', 'text/uri-list'],
	    ['unis', 'text/uri-list'],
	    ['unityweb', 'application/vnd.unity'],
	    ['unv', 'application/i-deas'],
	    ['uoml', 'application/vnd.uoml+xml'],
	    ['uri', 'text/uri-list'],
	    ['uris', 'text/uri-list'],
	    ['ustar', ['application/x-ustar', 'multipart/x-ustar']],
	    ['utz', 'application/vnd.uiq.theme'],
	    ['uu', ['application/octet-stream', 'text/x-uuencode']],
	    ['uue', 'text/x-uuencode'],
	    ['uva', 'audio/vnd.dece.audio'],
	    ['uvh', 'video/vnd.dece.hd'],
	    ['uvi', 'image/vnd.dece.graphic'],
	    ['uvm', 'video/vnd.dece.mobile'],
	    ['uvp', 'video/vnd.dece.pd'],
	    ['uvs', 'video/vnd.dece.sd'],
	    ['uvu', 'video/vnd.uvvu.mp4'],
	    ['uvv', 'video/vnd.dece.video'],
	    ['vcd', 'application/x-cdlink'],
	    ['vcf', 'text/x-vcard'],
	    ['vcg', 'application/vnd.groove-vcard'],
	    ['vcs', 'text/x-vcalendar'],
	    ['vcx', 'application/vnd.vcx'],
	    ['vda', 'application/vda'],
	    ['vdo', 'video/vdo'],
	    ['vew', 'application/groupwise'],
	    ['vis', 'application/vnd.visionary'],
	    ['viv', ['video/vivo', 'video/vnd.vivo']],
	    ['vivo', ['video/vivo', 'video/vnd.vivo']],
	    ['vmd', 'application/vocaltec-media-desc'],
	    ['vmf', 'application/vocaltec-media-file'],
	    ['voc', ['audio/voc', 'audio/x-voc']],
	    ['vos', 'video/vosaic'],
	    ['vox', 'audio/voxware'],
	    ['vqe', 'audio/x-twinvq-plugin'],
	    ['vqf', 'audio/x-twinvq'],
	    ['vql', 'audio/x-twinvq-plugin'],
	    ['vrml', ['model/vrml', 'x-world/x-vrml', 'application/x-vrml']],
	    ['vrt', 'x-world/x-vrt'],
	    ['vsd', ['application/vnd.visio', 'application/x-visio']],
	    ['vsf', 'application/vnd.vsf'],
	    ['vst', 'application/x-visio'],
	    ['vsw', 'application/x-visio'],
	    ['vtu', 'model/vnd.vtu'],
	    ['vxml', 'application/voicexml+xml'],
	    ['w60', 'application/wordperfect6.0'],
	    ['w61', 'application/wordperfect6.1'],
	    ['w6w', 'application/msword'],
	    ['wad', 'application/x-doom'],
	    ['wav', ['audio/wav', 'audio/x-wav']],
	    ['wax', 'audio/x-ms-wax'],
	    ['wb1', 'application/x-qpro'],
	    ['wbmp', 'image/vnd.wap.wbmp'],
	    ['wbs', 'application/vnd.criticaltools.wbs+xml'],
	    ['wbxml', 'application/vnd.wap.wbxml'],
	    ['wcm', 'application/vnd.ms-works'],
	    ['wdb', 'application/vnd.ms-works'],
	    ['web', 'application/vnd.xara'],
	    ['weba', 'audio/webm'],
	    ['webm', 'video/webm'],
	    ['webp', 'image/webp'],
	    ['wg', 'application/vnd.pmi.widget'],
	    ['wgt', 'application/widget'],
	    ['wiz', 'application/msword'],
	    ['wk1', 'application/x-123'],
	    ['wks', 'application/vnd.ms-works'],
	    ['wm', 'video/x-ms-wm'],
	    ['wma', 'audio/x-ms-wma'],
	    ['wmd', 'application/x-ms-wmd'],
	    ['wmf', ['windows/metafile', 'application/x-msmetafile']],
	    ['wml', 'text/vnd.wap.wml'],
	    ['wmlc', 'application/vnd.wap.wmlc'],
	    ['wmls', 'text/vnd.wap.wmlscript'],
	    ['wmlsc', 'application/vnd.wap.wmlscriptc'],
	    ['wmv', 'video/x-ms-wmv'],
	    ['wmx', 'video/x-ms-wmx'],
	    ['wmz', 'application/x-ms-wmz'],
	    ['woff', 'application/x-font-woff'],
	    ['word', 'application/msword'],
	    ['wp', 'application/wordperfect'],
	    ['wp5', ['application/wordperfect', 'application/wordperfect6.0']],
	    ['wp6', 'application/wordperfect'],
	    ['wpd', ['application/wordperfect', 'application/vnd.wordperfect', 'application/x-wpwin']],
	    ['wpl', 'application/vnd.ms-wpl'],
	    ['wps', 'application/vnd.ms-works'],
	    ['wq1', 'application/x-lotus'],
	    ['wqd', 'application/vnd.wqd'],
	    ['wri', ['application/mswrite', 'application/x-wri', 'application/x-mswrite']],
	    ['wrl', ['model/vrml', 'x-world/x-vrml', 'application/x-world']],
	    ['wrz', ['model/vrml', 'x-world/x-vrml']],
	    ['wsc', 'text/scriplet'],
	    ['wsdl', 'application/wsdl+xml'],
	    ['wspolicy', 'application/wspolicy+xml'],
	    ['wsrc', 'application/x-wais-source'],
	    ['wtb', 'application/vnd.webturbo'],
	    ['wtk', 'application/x-wintalk'],
	    ['wvx', 'video/x-ms-wvx'],
	    ['x-png', 'image/png'],
	    ['x3d', 'application/vnd.hzn-3d-crossword'],
	    ['xaf', 'x-world/x-vrml'],
	    ['xap', 'application/x-silverlight-app'],
	    ['xar', 'application/vnd.xara'],
	    ['xbap', 'application/x-ms-xbap'],
	    ['xbd', 'application/vnd.fujixerox.docuworks.binder'],
	    ['xbm', ['image/xbm', 'image/x-xbm', 'image/x-xbitmap']],
	    ['xdf', 'application/xcap-diff+xml'],
	    ['xdm', 'application/vnd.syncml.dm+xml'],
	    ['xdp', 'application/vnd.adobe.xdp+xml'],
	    ['xdr', 'video/x-amt-demorun'],
	    ['xdssc', 'application/dssc+xml'],
	    ['xdw', 'application/vnd.fujixerox.docuworks'],
	    ['xenc', 'application/xenc+xml'],
	    ['xer', 'application/patch-ops-error+xml'],
	    ['xfdf', 'application/vnd.adobe.xfdf'],
	    ['xfdl', 'application/vnd.xfdl'],
	    ['xgz', 'xgl/drawing'],
	    ['xhtml', 'application/xhtml+xml'],
	    ['xif', 'image/vnd.xiff'],
	    ['xl', 'application/excel'],
	    ['xla', ['application/vnd.ms-excel', 'application/excel', 'application/x-msexcel', 'application/x-excel']],
	    ['xlam', 'application/vnd.ms-excel.addin.macroenabled.12'],
	    ['xlb', ['application/excel', 'application/vnd.ms-excel', 'application/x-excel']],
	    ['xlc', ['application/vnd.ms-excel', 'application/excel', 'application/x-excel']],
	    ['xld', ['application/excel', 'application/x-excel']],
	    ['xlk', ['application/excel', 'application/x-excel']],
	    ['xll', ['application/excel', 'application/vnd.ms-excel', 'application/x-excel']],
	    ['xlm', ['application/vnd.ms-excel', 'application/excel', 'application/x-excel']],
	    ['xls', ['application/vnd.ms-excel', 'application/excel', 'application/x-msexcel', 'application/x-excel']],
	    ['xlsb', 'application/vnd.ms-excel.sheet.binary.macroenabled.12'],
	    ['xlsm', 'application/vnd.ms-excel.sheet.macroenabled.12'],
	    ['xlsx', 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'],
	    ['xlt', ['application/vnd.ms-excel', 'application/excel', 'application/x-excel']],
	    ['xltm', 'application/vnd.ms-excel.template.macroenabled.12'],
	    ['xltx', 'application/vnd.openxmlformats-officedocument.spreadsheetml.template'],
	    ['xlv', ['application/excel', 'application/x-excel']],
	    ['xlw', ['application/vnd.ms-excel', 'application/excel', 'application/x-msexcel', 'application/x-excel']],
	    ['xm', 'audio/xm'],
	    ['xml', ['application/xml', 'text/xml', 'application/atom+xml', 'application/rss+xml']],
	    ['xmz', 'xgl/movie'],
	    ['xo', 'application/vnd.olpc-sugar'],
	    ['xof', 'x-world/x-vrml'],
	    ['xop', 'application/xop+xml'],
	    ['xpi', 'application/x-xpinstall'],
	    ['xpix', 'application/x-vnd.ls-xpix'],
	    ['xpm', ['image/xpm', 'image/x-xpixmap']],
	    ['xpr', 'application/vnd.is-xpr'],
	    ['xps', 'application/vnd.ms-xpsdocument'],
	    ['xpw', 'application/vnd.intercon.formnet'],
	    ['xslt', 'application/xslt+xml'],
	    ['xsm', 'application/vnd.syncml+xml'],
	    ['xspf', 'application/xspf+xml'],
	    ['xsr', 'video/x-amt-showrun'],
	    ['xul', 'application/vnd.mozilla.xul+xml'],
	    ['xwd', ['image/x-xwd', 'image/x-xwindowdump']],
	    ['xyz', ['chemical/x-xyz', 'chemical/x-pdb']],
	    ['yang', 'application/yang'],
	    ['yin', 'application/yin+xml'],
	    ['z', ['application/x-compressed', 'application/x-compress']],
	    ['zaz', 'application/vnd.zzazz.deck+xml'],
	    ['zip', ['application/zip', 'multipart/x-zip', 'application/x-zip-compressed', 'application/x-compressed']],
	    ['zir', 'application/vnd.zul'],
	    ['zmm', 'application/vnd.handheld-entertainment+xml'],
	    ['zoo', 'application/octet-stream'],
	    ['zsh', 'text/x-script.zsh']
	]);

	mimeTypes_1 = {
	    detectMimeType(filename) {
	        if (!filename) {
	            return defaultMimeType;
	        }

	        let parsed = path.parse(filename);
	        let extension = (parsed.ext.substr(1) || parsed.name || '').split('?').shift().trim().toLowerCase();
	        let value = defaultMimeType;

	        if (extensions.has(extension)) {
	            value = extensions.get(extension);
	        }

	        if (Array.isArray(value)) {
	            return value[0];
	        }
	        return value;
	    },

	    detectExtension(mimeType) {
	        if (!mimeType) {
	            return defaultExtension;
	        }
	        let parts = (mimeType || '').toLowerCase().trim().split('/');
	        let rootType = parts.shift().trim();
	        let subType = parts.join('/').trim();

	        if (mimeTypes.has(rootType + '/' + subType)) {
	            let value = mimeTypes.get(rootType + '/' + subType);
	            if (Array.isArray(value)) {
	                return value[0];
	            }
	            return value;
	        }

	        switch (rootType) {
	            case 'text':
	                return 'txt';
	            default:
	                return 'bin';
	        }
	    }
	};
	return mimeTypes_1;
}

/*

Copied from https://github.com/mathiasbynens/punycode.js/blob/ef3505c8abb5143a00d53ce59077c9f7f4b2ac47/punycode.js

Copyright Mathias Bynens <https://mathiasbynens.be/>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

*/

var punycode_1;
var hasRequiredPunycode;

function requirePunycode () {
	if (hasRequiredPunycode) return punycode_1;
	hasRequiredPunycode = 1;

	/** Highest positive signed 32-bit float value */
	const maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1

	/** Bootstring parameters */
	const base = 36;
	const tMin = 1;
	const tMax = 26;
	const skew = 38;
	const damp = 700;
	const initialBias = 72;
	const initialN = 128; // 0x80
	const delimiter = '-'; // '\x2D'

	/** Regular expressions */
	const regexPunycode = /^xn--/;
	const regexNonASCII = /[^\0-\x7F]/; // Note: U+007F DEL is excluded too.
	const regexSeparators = /[\x2E\u3002\uFF0E\uFF61]/g; // RFC 3490 separators

	/** Error messages */
	const errors = {
	    overflow: 'Overflow: input needs wider integers to process',
	    'not-basic': 'Illegal input >= 0x80 (not a basic code point)',
	    'invalid-input': 'Invalid input'
	};

	/** Convenience shortcuts */
	const baseMinusTMin = base - tMin;
	const floor = Math.floor;
	const stringFromCharCode = String.fromCharCode;

	/*--------------------------------------------------------------------------*/

	/**
	 * A generic error utility function.
	 * @private
	 * @param {String} type The error type.
	 * @returns {Error} Throws a `RangeError` with the applicable error message.
	 */
	function error(type) {
	    throw new RangeError(errors[type]);
	}

	/**
	 * A generic `Array#map` utility function.
	 * @private
	 * @param {Array} array The array to iterate over.
	 * @param {Function} callback The function that gets called for every array
	 * item.
	 * @returns {Array} A new array of values returned by the callback function.
	 */
	function map(array, callback) {
	    const result = [];
	    let length = array.length;
	    while (length--) {
	        result[length] = callback(array[length]);
	    }
	    return result;
	}

	/**
	 * A simple `Array#map`-like wrapper to work with domain name strings or email
	 * addresses.
	 * @private
	 * @param {String} domain The domain name or email address.
	 * @param {Function} callback The function that gets called for every
	 * character.
	 * @returns {String} A new string of characters returned by the callback
	 * function.
	 */
	function mapDomain(domain, callback) {
	    const parts = domain.split('@');
	    let result = '';
	    if (parts.length > 1) {
	        // In email addresses, only the domain name should be punycoded. Leave
	        // the local part (i.e. everything up to `@`) intact.
	        result = parts[0] + '@';
	        domain = parts[1];
	    }
	    // Avoid `split(regex)` for IE8 compatibility. See #17.
	    domain = domain.replace(regexSeparators, '\x2E');
	    const labels = domain.split('.');
	    const encoded = map(labels, callback).join('.');
	    return result + encoded;
	}

	/**
	 * Creates an array containing the numeric code points of each Unicode
	 * character in the string. While JavaScript uses UCS-2 internally,
	 * this function will convert a pair of surrogate halves (each of which
	 * UCS-2 exposes as separate characters) into a single code point,
	 * matching UTF-16.
	 * @see `punycode.ucs2.encode`
	 * @see <https://mathiasbynens.be/notes/javascript-encoding>
	 * @memberOf punycode.ucs2
	 * @name decode
	 * @param {String} string The Unicode input string (UCS-2).
	 * @returns {Array} The new array of code points.
	 */
	function ucs2decode(string) {
	    const output = [];
	    let counter = 0;
	    const length = string.length;
	    while (counter < length) {
	        const value = string.charCodeAt(counter++);
	        if (value >= 0xd800 && value <= 0xdbff && counter < length) {
	            // It's a high surrogate, and there is a next character.
	            const extra = string.charCodeAt(counter++);
	            if ((extra & 0xfc00) == 0xdc00) {
	                // Low surrogate.
	                output.push(((value & 0x3ff) << 10) + (extra & 0x3ff) + 0x10000);
	            } else {
	                // It's an unmatched surrogate; only append this code unit, in case the
	                // next code unit is the high surrogate of a surrogate pair.
	                output.push(value);
	                counter--;
	            }
	        } else {
	            output.push(value);
	        }
	    }
	    return output;
	}

	/**
	 * Creates a string based on an array of numeric code points.
	 * @see `punycode.ucs2.decode`
	 * @memberOf punycode.ucs2
	 * @name encode
	 * @param {Array} codePoints The array of numeric code points.
	 * @returns {String} The new Unicode string (UCS-2).
	 */
	const ucs2encode = codePoints => String.fromCodePoint(...codePoints);

	/**
	 * Converts a basic code point into a digit/integer.
	 * @see `digitToBasic()`
	 * @private
	 * @param {Number} codePoint The basic numeric code point value.
	 * @returns {Number} The numeric value of a basic code point (for use in
	 * representing integers) in the range `0` to `base - 1`, or `base` if
	 * the code point does not represent a value.
	 */
	const basicToDigit = function (codePoint) {
	    if (codePoint >= 0x30 && codePoint < 0x3a) {
	        return 26 + (codePoint - 0x30);
	    }
	    if (codePoint >= 0x41 && codePoint < 0x5b) {
	        return codePoint - 0x41;
	    }
	    if (codePoint >= 0x61 && codePoint < 0x7b) {
	        return codePoint - 0x61;
	    }
	    return base;
	};

	/**
	 * Converts a digit/integer into a basic code point.
	 * @see `basicToDigit()`
	 * @private
	 * @param {Number} digit The numeric value of a basic code point.
	 * @returns {Number} The basic code point whose value (when used for
	 * representing integers) is `digit`, which needs to be in the range
	 * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is
	 * used; else, the lowercase form is used. The behavior is undefined
	 * if `flag` is non-zero and `digit` has no uppercase form.
	 */
	const digitToBasic = function (digit, flag) {
	    //  0..25 map to ASCII a..z or A..Z
	    // 26..35 map to ASCII 0..9
	    return digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);
	};

	/**
	 * Bias adaptation function as per section 3.4 of RFC 3492.
	 * https://tools.ietf.org/html/rfc3492#section-3.4
	 * @private
	 */
	const adapt = function (delta, numPoints, firstTime) {
	    let k = 0;
	    delta = firstTime ? floor(delta / damp) : delta >> 1;
	    delta += floor(delta / numPoints);
	    for (; /* no initialization */ delta > (baseMinusTMin * tMax) >> 1; k += base) {
	        delta = floor(delta / baseMinusTMin);
	    }
	    return floor(k + ((baseMinusTMin + 1) * delta) / (delta + skew));
	};

	/**
	 * Converts a Punycode string of ASCII-only symbols to a string of Unicode
	 * symbols.
	 * @memberOf punycode
	 * @param {String} input The Punycode string of ASCII-only symbols.
	 * @returns {String} The resulting string of Unicode symbols.
	 */
	const decode = function (input) {
	    // Don't use UCS-2.
	    const output = [];
	    const inputLength = input.length;
	    let i = 0;
	    let n = initialN;
	    let bias = initialBias;

	    // Handle the basic code points: let `basic` be the number of input code
	    // points before the last delimiter, or `0` if there is none, then copy
	    // the first basic code points to the output.

	    let basic = input.lastIndexOf(delimiter);
	    if (basic < 0) {
	        basic = 0;
	    }

	    for (let j = 0; j < basic; ++j) {
	        // if it's not a basic code point
	        if (input.charCodeAt(j) >= 0x80) {
	            error('not-basic');
	        }
	        output.push(input.charCodeAt(j));
	    }

	    // Main decoding loop: start just after the last delimiter if any basic code
	    // points were copied; start at the beginning otherwise.

	    for (let index = basic > 0 ? basic + 1 : 0; index < inputLength /* no final expression */; ) {
	        // `index` is the index of the next character to be consumed.
	        // Decode a generalized variable-length integer into `delta`,
	        // which gets added to `i`. The overflow checking is easier
	        // if we increase `i` as we go, then subtract off its starting
	        // value at the end to obtain `delta`.
	        const oldi = i;
	        for (let w = 1, k = base /* no condition */; ; k += base) {
	            if (index >= inputLength) {
	                error('invalid-input');
	            }

	            const digit = basicToDigit(input.charCodeAt(index++));

	            if (digit >= base) {
	                error('invalid-input');
	            }
	            if (digit > floor((maxInt - i) / w)) {
	                error('overflow');
	            }

	            i += digit * w;
	            const t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;

	            if (digit < t) {
	                break;
	            }

	            const baseMinusT = base - t;
	            if (w > floor(maxInt / baseMinusT)) {
	                error('overflow');
	            }

	            w *= baseMinusT;
	        }

	        const out = output.length + 1;
	        bias = adapt(i - oldi, out, oldi == 0);

	        // `i` was supposed to wrap around from `out` to `0`,
	        // incrementing `n` each time, so we'll fix that now:
	        if (floor(i / out) > maxInt - n) {
	            error('overflow');
	        }

	        n += floor(i / out);
	        i %= out;

	        // Insert `n` at position `i` of the output.
	        output.splice(i++, 0, n);
	    }

	    return String.fromCodePoint(...output);
	};

	/**
	 * Converts a string of Unicode symbols (e.g. a domain name label) to a
	 * Punycode string of ASCII-only symbols.
	 * @memberOf punycode
	 * @param {String} input The string of Unicode symbols.
	 * @returns {String} The resulting Punycode string of ASCII-only symbols.
	 */
	const encode = function (input) {
	    const output = [];

	    // Convert the input in UCS-2 to an array of Unicode code points.
	    input = ucs2decode(input);

	    // Cache the length.
	    const inputLength = input.length;

	    // Initialize the state.
	    let n = initialN;
	    let delta = 0;
	    let bias = initialBias;

	    // Handle the basic code points.
	    for (const currentValue of input) {
	        if (currentValue < 0x80) {
	            output.push(stringFromCharCode(currentValue));
	        }
	    }

	    const basicLength = output.length;
	    let handledCPCount = basicLength;

	    // `handledCPCount` is the number of code points that have been handled;
	    // `basicLength` is the number of basic code points.

	    // Finish the basic string with a delimiter unless it's empty.
	    if (basicLength) {
	        output.push(delimiter);
	    }

	    // Main encoding loop:
	    while (handledCPCount < inputLength) {
	        // All non-basic code points < n have been handled already. Find the next
	        // larger one:
	        let m = maxInt;
	        for (const currentValue of input) {
	            if (currentValue >= n && currentValue < m) {
	                m = currentValue;
	            }
	        }

	        // Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,
	        // but guard against overflow.
	        const handledCPCountPlusOne = handledCPCount + 1;
	        if (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {
	            error('overflow');
	        }

	        delta += (m - n) * handledCPCountPlusOne;
	        n = m;

	        for (const currentValue of input) {
	            if (currentValue < n && ++delta > maxInt) {
	                error('overflow');
	            }
	            if (currentValue === n) {
	                // Represent delta as a generalized variable-length integer.
	                let q = delta;
	                for (let k = base /* no condition */; ; k += base) {
	                    const t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;
	                    if (q < t) {
	                        break;
	                    }
	                    const qMinusT = q - t;
	                    const baseMinusT = base - t;
	                    output.push(stringFromCharCode(digitToBasic(t + (qMinusT % baseMinusT), 0)));
	                    q = floor(qMinusT / baseMinusT);
	                }

	                output.push(stringFromCharCode(digitToBasic(q, 0)));
	                bias = adapt(delta, handledCPCountPlusOne, handledCPCount === basicLength);
	                delta = 0;
	                ++handledCPCount;
	            }
	        }

	        ++delta;
	        ++n;
	    }
	    return output.join('');
	};

	/**
	 * Converts a Punycode string representing a domain name or an email address
	 * to Unicode. Only the Punycoded parts of the input will be converted, i.e.
	 * it doesn't matter if you call it on a string that has already been
	 * converted to Unicode.
	 * @memberOf punycode
	 * @param {String} input The Punycoded domain name or email address to
	 * convert to Unicode.
	 * @returns {String} The Unicode representation of the given Punycode
	 * string.
	 */
	const toUnicode = function (input) {
	    return mapDomain(input, function (string) {
	        return regexPunycode.test(string) ? decode(string.slice(4).toLowerCase()) : string;
	    });
	};

	/**
	 * Converts a Unicode string representing a domain name or an email address to
	 * Punycode. Only the non-ASCII parts of the domain name will be converted,
	 * i.e. it doesn't matter if you call it with a domain that's already in
	 * ASCII.
	 * @memberOf punycode
	 * @param {String} input The domain name or email address to convert, as a
	 * Unicode string.
	 * @returns {String} The Punycode representation of the given domain name or
	 * email address.
	 */
	const toASCII = function (input) {
	    return mapDomain(input, function (string) {
	        return regexNonASCII.test(string) ? 'xn--' + encode(string) : string;
	    });
	};

	/*--------------------------------------------------------------------------*/

	/** Define the public API */
	const punycode = {
	    /**
	     * A string representing the current Punycode.js version number.
	     * @memberOf punycode
	     * @type String
	     */
	    version: '2.3.1',
	    /**
	     * An object of methods to convert from JavaScript's internal character
	     * representation (UCS-2) to Unicode code points, and back.
	     * @see <https://mathiasbynens.be/notes/javascript-encoding>
	     * @memberOf punycode
	     * @type Object
	     */
	    ucs2: {
	        decode: ucs2decode,
	        encode: ucs2encode
	    },
	    decode: decode,
	    encode: encode,
	    toASCII: toASCII,
	    toUnicode: toUnicode
	};

	punycode_1 = punycode;
	return punycode_1;
}

var base64;
var hasRequiredBase64;

function requireBase64 () {
	if (hasRequiredBase64) return base64;
	hasRequiredBase64 = 1;

	const Transform = require$$0$2.Transform;

	/**
	 * Encodes a Buffer into a base64 encoded string
	 *
	 * @param {Buffer} buffer Buffer to convert
	 * @returns {String} base64 encoded string
	 */
	function encode(buffer) {
	    if (typeof buffer === 'string') {
	        buffer = Buffer.from(buffer, 'utf-8');
	    }

	    return buffer.toString('base64');
	}

	/**
	 * Adds soft line breaks to a base64 string
	 *
	 * @param {String} str base64 encoded string that might need line wrapping
	 * @param {Number} [lineLength=76] Maximum allowed length for a line
	 * @returns {String} Soft-wrapped base64 encoded string
	 */
	function wrap(str, lineLength) {
	    str = (str || '').toString();
	    lineLength = lineLength || 76;

	    if (str.length <= lineLength) {
	        return str;
	    }

	    let result = [];
	    let pos = 0;
	    let chunkLength = lineLength * 1024;
	    while (pos < str.length) {
	        let wrappedLines = str.substr(pos, chunkLength).replace(new RegExp('.{' + lineLength + '}', 'g'), '$&\r\n');
	        result.push(wrappedLines);
	        pos += chunkLength;
	    }

	    return result.join('');
	}

	/**
	 * Creates a transform stream for encoding data to base64 encoding
	 *
	 * @constructor
	 * @param {Object} options Stream options
	 * @param {Number} [options.lineLength=76] Maximum length for lines, set to false to disable wrapping
	 */
	class Encoder extends Transform {
	    constructor(options) {
	        super();
	        this.options = options || {};

	        if (this.options.lineLength !== false) {
	            this.options.lineLength = this.options.lineLength || 76;
	        }

	        this._curLine = '';
	        this._remainingBytes = false;

	        this.inputBytes = 0;
	        this.outputBytes = 0;
	    }

	    _transform(chunk, encoding, done) {
	        if (encoding !== 'buffer') {
	            chunk = Buffer.from(chunk, encoding);
	        }

	        if (!chunk || !chunk.length) {
	            return setImmediate(done);
	        }

	        this.inputBytes += chunk.length;

	        if (this._remainingBytes && this._remainingBytes.length) {
	            chunk = Buffer.concat([this._remainingBytes, chunk], this._remainingBytes.length + chunk.length);
	            this._remainingBytes = false;
	        }

	        if (chunk.length % 3) {
	            this._remainingBytes = chunk.slice(chunk.length - (chunk.length % 3));
	            chunk = chunk.slice(0, chunk.length - (chunk.length % 3));
	        } else {
	            this._remainingBytes = false;
	        }

	        let b64 = this._curLine + encode(chunk);

	        if (this.options.lineLength) {
	            b64 = wrap(b64, this.options.lineLength);

	            let lastLF = b64.lastIndexOf('\n');
	            if (lastLF < 0) {
	                this._curLine = b64;
	                b64 = '';
	            } else {
	                this._curLine = b64.substring(lastLF + 1);
	                b64 = b64.substring(0, lastLF + 1);

	                if (b64 && !b64.endsWith('\r\n')) {
	                    b64 += '\r\n';
	                }
	            }
	        } else {
	            this._curLine = '';
	        }

	        if (b64) {
	            this.outputBytes += b64.length;
	            this.push(Buffer.from(b64, 'ascii'));
	        }

	        setImmediate(done);
	    }

	    _flush(done) {
	        if (this._remainingBytes && this._remainingBytes.length) {
	            this._curLine += encode(this._remainingBytes);
	        }

	        if (this._curLine) {
	            this.outputBytes += this._curLine.length;
	            this.push(Buffer.from(this._curLine, 'ascii'));
	            this._curLine = '';
	        }
	        done();
	    }
	}

	base64 = {
	    encode,
	    wrap,
	    Encoder
	};
	return base64;
}

var qp;
var hasRequiredQp;

function requireQp () {
	if (hasRequiredQp) return qp;
	hasRequiredQp = 1;

	const Transform = require$$0$2.Transform;

	/**
	 * Encodes a Buffer into a Quoted-Printable encoded string
	 *
	 * @param {Buffer} buffer Buffer to convert
	 * @returns {String} Quoted-Printable encoded string
	 */
	function encode(buffer) {
	    if (typeof buffer === 'string') {
	        buffer = Buffer.from(buffer, 'utf-8');
	    }

	    // usable characters that do not need encoding
	    let ranges = [
	        // https://tools.ietf.org/html/rfc2045#section-6.7
	        [0x09], // <TAB>
	        [0x0a], // <LF>
	        [0x0d], // <CR>
	        [0x20, 0x3c], // <SP>!"#$%&'()*+,-./0123456789:;
	        [0x3e, 0x7e] // >?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}
	    ];
	    let result = '';
	    let ord;

	    for (let i = 0, len = buffer.length; i < len; i++) {
	        ord = buffer[i];
	        // if the char is in allowed range, then keep as is, unless it is a WS in the end of a line
	        if (
	            checkRanges(ord, ranges) &&
	            !((ord === 0x20 || ord === 0x09) && (i === len - 1 || buffer[i + 1] === 0x0a || buffer[i + 1] === 0x0d))
	        ) {
	            result += String.fromCharCode(ord);
	            continue;
	        }
	        result += '=' + (ord < 0x10 ? '0' : '') + ord.toString(16).toUpperCase();
	    }

	    return result;
	}

	/**
	 * Adds soft line breaks to a Quoted-Printable string
	 *
	 * @param {String} str Quoted-Printable encoded string that might need line wrapping
	 * @param {Number} [lineLength=76] Maximum allowed length for a line
	 * @returns {String} Soft-wrapped Quoted-Printable encoded string
	 */
	function wrap(str, lineLength) {
	    str = (str || '').toString();
	    lineLength = lineLength || 76;

	    if (str.length <= lineLength) {
	        return str;
	    }

	    let pos = 0;
	    let len = str.length;
	    let match, code, line;
	    let lineMargin = Math.floor(lineLength / 3);
	    let result = '';

	    // insert soft linebreaks where needed
	    while (pos < len) {
	        line = str.substr(pos, lineLength);
	        if ((match = line.match(/\r\n/))) {
	            line = line.substr(0, match.index + match[0].length);
	            result += line;
	            pos += line.length;
	            continue;
	        }

	        if (line.substr(-1) === '\n') {
	            // nothing to change here
	            result += line;
	            pos += line.length;
	            continue;
	        } else if ((match = line.substr(-lineMargin).match(/\n.*?$/))) {
	            // truncate to nearest line break
	            line = line.substr(0, line.length - (match[0].length - 1));
	            result += line;
	            pos += line.length;
	            continue;
	        } else if (line.length > lineLength - lineMargin && (match = line.substr(-lineMargin).match(/[ \t.,!?][^ \t.,!?]*$/))) {
	            // truncate to nearest space
	            line = line.substr(0, line.length - (match[0].length - 1));
	        } else if (line.match(/[=][\da-f]{0,2}$/i)) {
	            // push incomplete encoding sequences to the next line
	            if ((match = line.match(/[=][\da-f]{0,1}$/i))) {
	                line = line.substr(0, line.length - match[0].length);
	            }

	            // ensure that utf-8 sequences are not split
	            while (
	                line.length > 3 &&
	                line.length < len - pos &&
	                !line.match(/^(?:=[\da-f]{2}){1,4}$/i) &&
	                (match = line.match(/[=][\da-f]{2}$/gi))
	            ) {
	                code = parseInt(match[0].substr(1, 2), 16);
	                if (code < 128) {
	                    break;
	                }

	                line = line.substr(0, line.length - 3);

	                if (code >= 0xc0) {
	                    break;
	                }
	            }
	        }

	        if (pos + line.length < len && line.substr(-1) !== '\n') {
	            if (line.length === lineLength && line.match(/[=][\da-f]{2}$/i)) {
	                line = line.substr(0, line.length - 3);
	            } else if (line.length === lineLength) {
	                line = line.substr(0, line.length - 1);
	            }
	            pos += line.length;
	            line += '=\r\n';
	        } else {
	            pos += line.length;
	        }

	        result += line;
	    }

	    return result;
	}

	/**
	 * Helper function to check if a number is inside provided ranges
	 *
	 * @param {Number} nr Number to check for
	 * @param {Array} ranges An Array of allowed values
	 * @returns {Boolean} True if the value was found inside allowed ranges, false otherwise
	 */
	function checkRanges(nr, ranges) {
	    for (let i = ranges.length - 1; i >= 0; i--) {
	        if (!ranges[i].length) {
	            continue;
	        }
	        if (ranges[i].length === 1 && nr === ranges[i][0]) {
	            return true;
	        }
	        if (ranges[i].length === 2 && nr >= ranges[i][0] && nr <= ranges[i][1]) {
	            return true;
	        }
	    }
	    return false;
	}

	/**
	 * Creates a transform stream for encoding data to Quoted-Printable encoding
	 *
	 * @constructor
	 * @param {Object} options Stream options
	 * @param {Number} [options.lineLength=76] Maximum length for lines, set to false to disable wrapping
	 */
	class Encoder extends Transform {
	    constructor(options) {
	        super();

	        // init Transform
	        this.options = options || {};

	        if (this.options.lineLength !== false) {
	            this.options.lineLength = this.options.lineLength || 76;
	        }

	        this._curLine = '';

	        this.inputBytes = 0;
	        this.outputBytes = 0;
	    }

	    _transform(chunk, encoding, done) {
	        let qp;

	        if (encoding !== 'buffer') {
	            chunk = Buffer.from(chunk, encoding);
	        }

	        if (!chunk || !chunk.length) {
	            return done();
	        }

	        this.inputBytes += chunk.length;

	        if (this.options.lineLength) {
	            qp = this._curLine + encode(chunk);
	            qp = wrap(qp, this.options.lineLength);
	            qp = qp.replace(/(^|\n)([^\n]*)$/, (match, lineBreak, lastLine) => {
	                this._curLine = lastLine;
	                return lineBreak;
	            });

	            if (qp) {
	                this.outputBytes += qp.length;
	                this.push(qp);
	            }
	        } else {
	            qp = encode(chunk);
	            this.outputBytes += qp.length;
	            this.push(qp, 'ascii');
	        }

	        done();
	    }

	    _flush(done) {
	        if (this._curLine) {
	            this.outputBytes += this._curLine.length;
	            this.push(this._curLine, 'ascii');
	        }
	        done();
	    }
	}

	// expose to the world
	qp = {
	    encode,
	    wrap,
	    Encoder
	};
	return qp;
}

/* eslint no-control-regex:0 */

var mimeFuncs;
var hasRequiredMimeFuncs;

function requireMimeFuncs () {
	if (hasRequiredMimeFuncs) return mimeFuncs;
	hasRequiredMimeFuncs = 1;

	const base64 = requireBase64();
	const qp = requireQp();
	const mimeTypes = requireMimeTypes();

	mimeFuncs = {
	    /**
	     * Checks if a value is plaintext string (uses only printable 7bit chars)
	     *
	     * @param {String} value String to be tested
	     * @returns {Boolean} true if it is a plaintext string
	     */
	    isPlainText(value, isParam) {
	        const re = isParam ? /[\x00-\x08\x0b\x0c\x0e-\x1f"\u0080-\uFFFF]/ : /[\x00-\x08\x0b\x0c\x0e-\x1f\u0080-\uFFFF]/;
	        if (typeof value !== 'string' || re.test(value)) {
	            return false;
	        } else {
	            return true;
	        }
	    },

	    /**
	     * Checks if a multi line string containes lines longer than the selected value.
	     *
	     * Useful when detecting if a mail message needs any processing at all –
	     * if only plaintext characters are used and lines are short, then there is
	     * no need to encode the values in any way. If the value is plaintext but has
	     * longer lines then allowed, then use format=flowed
	     *
	     * @param {Number} lineLength Max line length to check for
	     * @returns {Boolean} Returns true if there is at least one line longer than lineLength chars
	     */
	    hasLongerLines(str, lineLength) {
	        if (str.length > 128 * 1024) {
	            // do not test strings longer than 128kB
	            return true;
	        }
	        return new RegExp('^.{' + (lineLength + 1) + ',}', 'm').test(str);
	    },

	    /**
	     * Encodes a string or an Buffer to an UTF-8 MIME Word (rfc2047)
	     *
	     * @param {String|Buffer} data String to be encoded
	     * @param {String} mimeWordEncoding='Q' Encoding for the mime word, either Q or B
	     * @param {Number} [maxLength=0] If set, split mime words into several chunks if needed
	     * @return {String} Single or several mime words joined together
	     */
	    encodeWord(data, mimeWordEncoding, maxLength) {
	        mimeWordEncoding = (mimeWordEncoding || 'Q').toString().toUpperCase().trim().charAt(0);
	        maxLength = maxLength || 0;

	        let encodedStr;
	        let toCharset = 'UTF-8';

	        if (maxLength && maxLength > 7 + toCharset.length) {
	            maxLength -= 7 + toCharset.length;
	        }

	        if (mimeWordEncoding === 'Q') {
	            // https://tools.ietf.org/html/rfc2047#section-5 rule (3)
	            encodedStr = qp.encode(data).replace(/[^a-z0-9!*+\-/=]/gi, chr => {
	                let ord = chr.charCodeAt(0).toString(16).toUpperCase();
	                if (chr === ' ') {
	                    return '_';
	                } else {
	                    return '=' + (ord.length === 1 ? '0' + ord : ord);
	                }
	            });
	        } else if (mimeWordEncoding === 'B') {
	            encodedStr = typeof data === 'string' ? data : base64.encode(data);
	            maxLength = maxLength ? Math.max(3, ((maxLength - (maxLength % 4)) / 4) * 3) : 0;
	        }

	        if (maxLength && (mimeWordEncoding !== 'B' ? encodedStr : base64.encode(data)).length > maxLength) {
	            if (mimeWordEncoding === 'Q') {
	                encodedStr = this.splitMimeEncodedString(encodedStr, maxLength).join('?= =?' + toCharset + '?' + mimeWordEncoding + '?');
	            } else {
	                // RFC2047 6.3 (2) states that encoded-word must include an integral number of characters, so no chopping unicode sequences
	                let parts = [];
	                let lpart = '';
	                for (let i = 0, len = encodedStr.length; i < len; i++) {
	                    let chr = encodedStr.charAt(i);

	                    if (/[\ud83c\ud83d\ud83e]/.test(chr) && i < len - 1) {
	                        // composite emoji byte, so add the next byte as well
	                        chr += encodedStr.charAt(++i);
	                    }

	                    // check if we can add this character to the existing string
	                    // without breaking byte length limit
	                    if (Buffer.byteLength(lpart + chr) <= maxLength || i === 0) {
	                        lpart += chr;
	                    } else {
	                        // we hit the length limit, so push the existing string and start over
	                        parts.push(base64.encode(lpart));
	                        lpart = chr;
	                    }
	                }
	                if (lpart) {
	                    parts.push(base64.encode(lpart));
	                }

	                if (parts.length > 1) {
	                    encodedStr = parts.join('?= =?' + toCharset + '?' + mimeWordEncoding + '?');
	                } else {
	                    encodedStr = parts.join('');
	                }
	            }
	        } else if (mimeWordEncoding === 'B') {
	            encodedStr = base64.encode(data);
	        }

	        return '=?' + toCharset + '?' + mimeWordEncoding + '?' + encodedStr + (encodedStr.substr(-2) === '?=' ? '' : '?=');
	    },

	    /**
	     * Finds word sequences with non ascii text and converts these to mime words
	     *
	     * @param {String} value String to be encoded
	     * @param {String} mimeWordEncoding='Q' Encoding for the mime word, either Q or B
	     * @param {Number} [maxLength=0] If set, split mime words into several chunks if needed
	     * @param {Boolean} [encodeAll=false] If true and the value needs encoding then encodes entire string, not just the smallest match
	     * @return {String} String with possible mime words
	     */
	    encodeWords(value, mimeWordEncoding, maxLength, encodeAll) {
	        maxLength = maxLength || 0;

	        let encodedValue;

	        // find first word with a non-printable ascii or special symbol in it
	        let firstMatch = value.match(/(?:^|\s)([^\s]*["\u0080-\uFFFF])/);
	        if (!firstMatch) {
	            return value;
	        }

	        if (encodeAll) {
	            // if it is requested to encode everything or the string contains something that resebles encoded word, then encode everything

	            return this.encodeWord(value, mimeWordEncoding, maxLength);
	        }

	        // find the last word with a non-printable ascii in it
	        let lastMatch = value.match(/(["\u0080-\uFFFF][^\s]*)[^"\u0080-\uFFFF]*$/);
	        if (!lastMatch) {
	            // should not happen
	            return value;
	        }

	        let startIndex =
	            firstMatch.index +
	            (
	                firstMatch[0].match(/[^\s]/) || {
	                    index: 0
	                }
	            ).index;
	        let endIndex = lastMatch.index + (lastMatch[1] || '').length;

	        encodedValue =
	            (startIndex ? value.substr(0, startIndex) : '') +
	            this.encodeWord(value.substring(startIndex, endIndex), mimeWordEncoding || 'Q', maxLength) +
	            (endIndex < value.length ? value.substr(endIndex) : '');

	        return encodedValue;
	    },

	    /**
	     * Joins parsed header value together as 'value; param1=value1; param2=value2'
	     * PS: We are following RFC 822 for the list of special characters that we need to keep in quotes.
	     *      Refer: https://www.w3.org/Protocols/rfc1341/4_Content-Type.html
	     * @param {Object} structured Parsed header value
	     * @return {String} joined header value
	     */
	    buildHeaderValue(structured) {
	        let paramsArray = [];

	        Object.keys(structured.params || {}).forEach(param => {
	            // filename might include unicode characters so it is a special case
	            // other values probably do not
	            let value = structured.params[param];
	            if (!this.isPlainText(value, true) || value.length >= 75) {
	                this.buildHeaderParam(param, value, 50).forEach(encodedParam => {
	                    if (!/[\s"\\;:/=(),<>@[\]?]|^[-']|'$/.test(encodedParam.value) || encodedParam.key.substr(-1) === '*') {
	                        paramsArray.push(encodedParam.key + '=' + encodedParam.value);
	                    } else {
	                        paramsArray.push(encodedParam.key + '=' + JSON.stringify(encodedParam.value));
	                    }
	                });
	            } else if (/[\s'"\\;:/=(),<>@[\]?]|^-/.test(value)) {
	                paramsArray.push(param + '=' + JSON.stringify(value));
	            } else {
	                paramsArray.push(param + '=' + value);
	            }
	        });

	        return structured.value + (paramsArray.length ? '; ' + paramsArray.join('; ') : '');
	    },

	    /**
	     * Encodes a string or an Buffer to an UTF-8 Parameter Value Continuation encoding (rfc2231)
	     * Useful for splitting long parameter values.
	     *
	     * For example
	     *      title="unicode string"
	     * becomes
	     *     title*0*=utf-8''unicode
	     *     title*1*=%20string
	     *
	     * @param {String|Buffer} data String to be encoded
	     * @param {Number} [maxLength=50] Max length for generated chunks
	     * @param {String} [fromCharset='UTF-8'] Source sharacter set
	     * @return {Array} A list of encoded keys and headers
	     */
	    buildHeaderParam(key, data, maxLength) {
	        let list = [];
	        let encodedStr = typeof data === 'string' ? data : (data || '').toString();
	        let encodedStrArr;
	        let chr, ord;
	        let line;
	        let startPos = 0;
	        let i, len;

	        maxLength = maxLength || 50;

	        // process ascii only text
	        if (this.isPlainText(data, true)) {
	            // check if conversion is even needed
	            if (encodedStr.length <= maxLength) {
	                return [
	                    {
	                        key,
	                        value: encodedStr
	                    }
	                ];
	            }

	            encodedStr = encodedStr.replace(new RegExp('.{' + maxLength + '}', 'g'), str => {
	                list.push({
	                    line: str
	                });
	                return '';
	            });

	            if (encodedStr) {
	                list.push({
	                    line: encodedStr
	                });
	            }
	        } else {
	            if (/[\uD800-\uDBFF]/.test(encodedStr)) {
	                // string containts surrogate pairs, so normalize it to an array of bytes
	                encodedStrArr = [];
	                for (i = 0, len = encodedStr.length; i < len; i++) {
	                    chr = encodedStr.charAt(i);
	                    ord = chr.charCodeAt(0);
	                    if (ord >= 0xd800 && ord <= 0xdbff && i < len - 1) {
	                        chr += encodedStr.charAt(i + 1);
	                        encodedStrArr.push(chr);
	                        i++;
	                    } else {
	                        encodedStrArr.push(chr);
	                    }
	                }
	                encodedStr = encodedStrArr;
	            }

	            // first line includes the charset and language info and needs to be encoded
	            // even if it does not contain any unicode characters
	            line = "utf-8''";
	            let encoded = true;
	            startPos = 0;

	            // process text with unicode or special chars
	            for (i = 0, len = encodedStr.length; i < len; i++) {
	                chr = encodedStr[i];

	                if (encoded) {
	                    chr = this.safeEncodeURIComponent(chr);
	                } else {
	                    // try to urlencode current char
	                    chr = chr === ' ' ? chr : this.safeEncodeURIComponent(chr);
	                    // By default it is not required to encode a line, the need
	                    // only appears when the string contains unicode or special chars
	                    // in this case we start processing the line over and encode all chars
	                    if (chr !== encodedStr[i]) {
	                        // Check if it is even possible to add the encoded char to the line
	                        // If not, there is no reason to use this line, just push it to the list
	                        // and start a new line with the char that needs encoding
	                        if ((this.safeEncodeURIComponent(line) + chr).length >= maxLength) {
	                            list.push({
	                                line,
	                                encoded
	                            });
	                            line = '';
	                            startPos = i - 1;
	                        } else {
	                            encoded = true;
	                            i = startPos;
	                            line = '';
	                            continue;
	                        }
	                    }
	                }

	                // if the line is already too long, push it to the list and start a new one
	                if ((line + chr).length >= maxLength) {
	                    list.push({
	                        line,
	                        encoded
	                    });
	                    line = chr = encodedStr[i] === ' ' ? ' ' : this.safeEncodeURIComponent(encodedStr[i]);
	                    if (chr === encodedStr[i]) {
	                        encoded = false;
	                        startPos = i - 1;
	                    } else {
	                        encoded = true;
	                    }
	                } else {
	                    line += chr;
	                }
	            }

	            if (line) {
	                list.push({
	                    line,
	                    encoded
	                });
	            }
	        }

	        return list.map((item, i) => ({
	            // encoded lines: {name}*{part}*
	            // unencoded lines: {name}*{part}
	            // if any line needs to be encoded then the first line (part==0) is always encoded
	            key: key + '*' + i + (item.encoded ? '*' : ''),
	            value: item.line
	        }));
	    },

	    /**
	     * Parses a header value with key=value arguments into a structured
	     * object.
	     *
	     *   parseHeaderValue('content-type: text/plain; CHARSET='UTF-8'') ->
	     *   {
	     *     'value': 'text/plain',
	     *     'params': {
	     *       'charset': 'UTF-8'
	     *     }
	     *   }
	     *
	     * @param {String} str Header value
	     * @return {Object} Header value as a parsed structure
	     */
	    parseHeaderValue(str) {
	        let response = {
	            value: false,
	            params: {}
	        };
	        let key = false;
	        let value = '';
	        let type = 'value';
	        let quote = false;
	        let escaped = false;
	        let chr;

	        for (let i = 0, len = str.length; i < len; i++) {
	            chr = str.charAt(i);
	            if (type === 'key') {
	                if (chr === '=') {
	                    key = value.trim().toLowerCase();
	                    type = 'value';
	                    value = '';
	                    continue;
	                }
	                value += chr;
	            } else {
	                if (escaped) {
	                    value += chr;
	                } else if (chr === '\\') {
	                    escaped = true;
	                    continue;
	                } else if (quote && chr === quote) {
	                    quote = false;
	                } else if (!quote && chr === '"') {
	                    quote = chr;
	                } else if (!quote && chr === ';') {
	                    if (key === false) {
	                        response.value = value.trim();
	                    } else {
	                        response.params[key] = value.trim();
	                    }
	                    type = 'key';
	                    value = '';
	                } else {
	                    value += chr;
	                }
	                escaped = false;
	            }
	        }

	        if (type === 'value') {
	            if (key === false) {
	                response.value = value.trim();
	            } else {
	                response.params[key] = value.trim();
	            }
	        } else if (value.trim()) {
	            response.params[value.trim().toLowerCase()] = '';
	        }

	        // handle parameter value continuations
	        // https://tools.ietf.org/html/rfc2231#section-3

	        // preprocess values
	        Object.keys(response.params).forEach(key => {
	            let actualKey, nr, match, value;
	            if ((match = key.match(/(\*(\d+)|\*(\d+)\*|\*)$/))) {
	                actualKey = key.substr(0, match.index);
	                nr = Number(match[2] || match[3]) || 0;

	                if (!response.params[actualKey] || typeof response.params[actualKey] !== 'object') {
	                    response.params[actualKey] = {
	                        charset: false,
	                        values: []
	                    };
	                }

	                value = response.params[key];

	                if (nr === 0 && match[0].substr(-1) === '*' && (match = value.match(/^([^']*)'[^']*'(.*)$/))) {
	                    response.params[actualKey].charset = match[1] || 'iso-8859-1';
	                    value = match[2];
	                }

	                response.params[actualKey].values[nr] = value;

	                // remove the old reference
	                delete response.params[key];
	            }
	        });

	        // concatenate split rfc2231 strings and convert encoded strings to mime encoded words
	        Object.keys(response.params).forEach(key => {
	            let value;
	            if (response.params[key] && Array.isArray(response.params[key].values)) {
	                value = response.params[key].values.map(val => val || '').join('');

	                if (response.params[key].charset) {
	                    // convert "%AB" to "=?charset?Q?=AB?="
	                    response.params[key] =
	                        '=?' +
	                        response.params[key].charset +
	                        '?Q?' +
	                        value
	                            // fix invalidly encoded chars
	                            .replace(/[=?_\s]/g, s => {
	                                let c = s.charCodeAt(0).toString(16);
	                                if (s === ' ') {
	                                    return '_';
	                                } else {
	                                    return '%' + (c.length < 2 ? '0' : '') + c;
	                                }
	                            })
	                            // change from urlencoding to percent encoding
	                            .replace(/%/g, '=') +
	                        '?=';
	                } else {
	                    response.params[key] = value;
	                }
	            }
	        });

	        return response;
	    },

	    /**
	     * Returns file extension for a content type string. If no suitable extensions
	     * are found, 'bin' is used as the default extension
	     *
	     * @param {String} mimeType Content type to be checked for
	     * @return {String} File extension
	     */
	    detectExtension: mimeType => mimeTypes.detectExtension(mimeType),

	    /**
	     * Returns content type for a file extension. If no suitable content types
	     * are found, 'application/octet-stream' is used as the default content type
	     *
	     * @param {String} extension Extension to be checked for
	     * @return {String} File extension
	     */
	    detectMimeType: extension => mimeTypes.detectMimeType(extension),

	    /**
	     * Folds long lines, useful for folding header lines (afterSpace=false) and
	     * flowed text (afterSpace=true)
	     *
	     * @param {String} str String to be folded
	     * @param {Number} [lineLength=76] Maximum length of a line
	     * @param {Boolean} afterSpace If true, leave a space in th end of a line
	     * @return {String} String with folded lines
	     */
	    foldLines(str, lineLength, afterSpace) {
	        str = (str || '').toString();
	        lineLength = lineLength || 76;

	        let pos = 0,
	            len = str.length,
	            result = '',
	            line,
	            match;

	        while (pos < len) {
	            line = str.substr(pos, lineLength);
	            if (line.length < lineLength) {
	                result += line;
	                break;
	            }
	            if ((match = line.match(/^[^\n\r]*(\r?\n|\r)/))) {
	                line = match[0];
	                result += line;
	                pos += line.length;
	                continue;
	            } else if ((match = line.match(/(\s+)[^\s]*$/)) && match[0].length - (afterSpace ? (match[1] || '').length : 0) < line.length) {
	                line = line.substr(0, line.length - (match[0].length - (afterSpace ? (match[1] || '').length : 0)));
	            } else if ((match = str.substr(pos + line.length).match(/^[^\s]+(\s*)/))) {
	                line = line + match[0].substr(0, match[0].length - (!afterSpace ? (match[1] || '').length : 0));
	            }

	            result += line;
	            pos += line.length;
	            if (pos < len) {
	                result += '\r\n';
	            }
	        }

	        return result;
	    },

	    /**
	     * Splits a mime encoded string. Needed for dividing mime words into smaller chunks
	     *
	     * @param {String} str Mime encoded string to be split up
	     * @param {Number} maxlen Maximum length of characters for one part (minimum 12)
	     * @return {Array} Split string
	     */
	    splitMimeEncodedString: (str, maxlen) => {
	        let curLine,
	            match,
	            chr,
	            done,
	            lines = [];

	        // require at least 12 symbols to fit possible 4 octet UTF-8 sequences
	        maxlen = Math.max(maxlen || 0, 12);

	        while (str.length) {
	            curLine = str.substr(0, maxlen);

	            // move incomplete escaped char back to main
	            if ((match = curLine.match(/[=][0-9A-F]?$/i))) {
	                curLine = curLine.substr(0, match.index);
	            }

	            done = false;
	            while (!done) {
	                done = true;
	                // check if not middle of a unicode char sequence
	                if ((match = str.substr(curLine.length).match(/^[=]([0-9A-F]{2})/i))) {
	                    chr = parseInt(match[1], 16);
	                    // invalid sequence, move one char back anc recheck
	                    if (chr < 0xc2 && chr > 0x7f) {
	                        curLine = curLine.substr(0, curLine.length - 3);
	                        done = false;
	                    }
	                }
	            }

	            if (curLine.length) {
	                lines.push(curLine);
	            }
	            str = str.substr(curLine.length);
	        }

	        return lines;
	    },

	    encodeURICharComponent: chr => {
	        let res = '';
	        let ord = chr.charCodeAt(0).toString(16).toUpperCase();

	        if (ord.length % 2) {
	            ord = '0' + ord;
	        }

	        if (ord.length > 2) {
	            for (let i = 0, len = ord.length / 2; i < len; i++) {
	                res += '%' + ord.substr(i, 2);
	            }
	        } else {
	            res += '%' + ord;
	        }

	        return res;
	    },

	    safeEncodeURIComponent(str) {
	        str = (str || '').toString();

	        try {
	            // might throw if we try to encode invalid sequences, eg. partial emoji
	            str = encodeURIComponent(str);
	        } catch (_E) {
	            // should never run
	            return str.replace(/[^\x00-\x1F *'()<>@,;:\\"[\]?=\u007F-\uFFFF]+/g, '');
	        }

	        // ensure chars that are not handled by encodeURICompent are converted as well
	        return str.replace(/[\x00-\x1F *'()<>@,;:\\"[\]?=\u007F-\uFFFF]/g, chr => this.encodeURICharComponent(chr));
	    }
	};
	return mimeFuncs;
}

var addressparser_1;
var hasRequiredAddressparser;

function requireAddressparser () {
	if (hasRequiredAddressparser) return addressparser_1;
	hasRequiredAddressparser = 1;

	/**
	 * Converts tokens for a single address into an address object
	 *
	 * @param {Array} tokens Tokens object
	 * @return {Object} Address object
	 */
	function _handleAddress(tokens) {
	    let isGroup = false;
	    let state = 'text';
	    let address;
	    let addresses = [];
	    let data = {
	        address: [],
	        comment: [],
	        group: [],
	        text: [],
	        textWasQuoted: [] // Track which text tokens came from inside quotes
	    };
	    let i;
	    let len;
	    let insideQuotes = false; // Track if we're currently inside a quoted string

	    // Filter out <addresses>, (comments) and regular text
	    for (i = 0, len = tokens.length; i < len; i++) {
	        let token = tokens[i];
	        let prevToken = i ? tokens[i - 1] : null;
	        if (token.type === 'operator') {
	            switch (token.value) {
	                case '<':
	                    state = 'address';
	                    insideQuotes = false;
	                    break;
	                case '(':
	                    state = 'comment';
	                    insideQuotes = false;
	                    break;
	                case ':':
	                    state = 'group';
	                    isGroup = true;
	                    insideQuotes = false;
	                    break;
	                case '"':
	                    // Track quote state for text tokens
	                    insideQuotes = !insideQuotes;
	                    state = 'text';
	                    break;
	                default:
	                    state = 'text';
	                    insideQuotes = false;
	                    break;
	            }
	        } else if (token.value) {
	            if (state === 'address') {
	                // handle use case where unquoted name includes a "<"
	                // Apple Mail truncates everything between an unexpected < and an address
	                // and so will we
	                token.value = token.value.replace(/^[^<]*<\s*/, '');
	            }

	            if (prevToken && prevToken.noBreak && data[state].length) {
	                // join values
	                data[state][data[state].length - 1] += token.value;
	                if (state === 'text' && insideQuotes) {
	                    data.textWasQuoted[data.textWasQuoted.length - 1] = true;
	                }
	            } else {
	                data[state].push(token.value);
	                if (state === 'text') {
	                    data.textWasQuoted.push(insideQuotes);
	                }
	            }
	        }
	    }

	    // If there is no text but a comment, replace the two
	    if (!data.text.length && data.comment.length) {
	        data.text = data.comment;
	        data.comment = [];
	    }

	    if (isGroup) {
	        // http://tools.ietf.org/html/rfc2822#appendix-A.1.3
	        data.text = data.text.join(' ');

	        // Parse group members, but flatten any nested groups (RFC 5322 doesn't allow nesting)
	        let groupMembers = [];
	        if (data.group.length) {
	            let parsedGroup = addressparser(data.group.join(','));
	            // Flatten: if any member is itself a group, extract its members into the sequence
	            parsedGroup.forEach(member => {
	                if (member.group) {
	                    // Nested group detected - flatten it by adding its members directly
	                    groupMembers = groupMembers.concat(member.group);
	                } else {
	                    groupMembers.push(member);
	                }
	            });
	        }

	        addresses.push({
	            name: data.text || (address && address.name),
	            group: groupMembers
	        });
	    } else {
	        // If no address was found, try to detect one from regular text
	        if (!data.address.length && data.text.length) {
	            for (i = data.text.length - 1; i >= 0; i--) {
	                // Security fix: Do not extract email addresses from quoted strings
	                // RFC 5321 allows @ inside quoted local-parts like "user@domain"@example.com
	                // Extracting emails from quoted text leads to misrouting vulnerabilities
	                if (!data.textWasQuoted[i] && data.text[i].match(/^[^@\s]+@[^@\s]+$/)) {
	                    data.address = data.text.splice(i, 1);
	                    data.textWasQuoted.splice(i, 1);
	                    break;
	                }
	            }

	            let _regexHandler = function (address) {
	                if (!data.address.length) {
	                    data.address = [address.trim()];
	                    return ' ';
	                } else {
	                    return address;
	                }
	            };

	            // still no address
	            if (!data.address.length) {
	                for (i = data.text.length - 1; i >= 0; i--) {
	                    // Security fix: Do not extract email addresses from quoted strings
	                    if (!data.textWasQuoted[i]) {
	                        // fixed the regex to parse email address correctly when email address has more than one @
	                        data.text[i] = data.text[i].replace(/\s*\b[^@\s]+@[^\s]+\b\s*/, _regexHandler).trim();
	                        if (data.address.length) {
	                            break;
	                        }
	                    }
	                }
	            }
	        }

	        // If there's still is no text but a comment exixts, replace the two
	        if (!data.text.length && data.comment.length) {
	            data.text = data.comment;
	            data.comment = [];
	        }

	        // Keep only the first address occurence, push others to regular text
	        if (data.address.length > 1) {
	            data.text = data.text.concat(data.address.splice(1));
	        }

	        // Join values with spaces
	        data.text = data.text.join(' ');
	        data.address = data.address.join(' ');

	        if (!data.address && isGroup) {
	            return [];
	        } else {
	            address = {
	                address: data.address || data.text || '',
	                name: data.text || data.address || ''
	            };

	            if (address.address === address.name) {
	                if ((address.address || '').match(/@/)) {
	                    address.name = '';
	                } else {
	                    address.address = '';
	                }
	            }

	            addresses.push(address);
	        }
	    }

	    return addresses;
	}

	/**
	 * Creates a Tokenizer object for tokenizing address field strings
	 *
	 * @constructor
	 * @param {String} str Address field string
	 */
	class Tokenizer {
	    constructor(str) {
	        this.str = (str || '').toString();
	        this.operatorCurrent = '';
	        this.operatorExpecting = '';
	        this.node = null;
	        this.escaped = false;

	        this.list = [];
	        /**
	         * Operator tokens and which tokens are expected to end the sequence
	         */
	        this.operators = {
	            '"': '"',
	            '(': ')',
	            '<': '>',
	            ',': '',
	            ':': ';',
	            // Semicolons are not a legal delimiter per the RFC2822 grammar other
	            // than for terminating a group, but they are also not valid for any
	            // other use in this context.  Given that some mail clients have
	            // historically allowed the semicolon as a delimiter equivalent to the
	            // comma in their UI, it makes sense to treat them the same as a comma
	            // when used outside of a group.
	            ';': ''
	        };
	    }

	    /**
	     * Tokenizes the original input string
	     *
	     * @return {Array} An array of operator|text tokens
	     */
	    tokenize() {
	        let list = [];

	        for (let i = 0, len = this.str.length; i < len; i++) {
	            let chr = this.str.charAt(i);
	            let nextChr = i < len - 1 ? this.str.charAt(i + 1) : null;
	            this.checkChar(chr, nextChr);
	        }

	        this.list.forEach(node => {
	            node.value = (node.value || '').toString().trim();
	            if (node.value) {
	                list.push(node);
	            }
	        });

	        return list;
	    }

	    /**
	     * Checks if a character is an operator or text and acts accordingly
	     *
	     * @param {String} chr Character from the address field
	     */
	    checkChar(chr, nextChr) {
	        if (this.escaped) ; else if (chr === this.operatorExpecting) {
	            this.node = {
	                type: 'operator',
	                value: chr
	            };

	            if (nextChr && ![' ', '\t', '\r', '\n', ',', ';'].includes(nextChr)) {
	                this.node.noBreak = true;
	            }

	            this.list.push(this.node);
	            this.node = null;
	            this.operatorExpecting = '';
	            this.escaped = false;

	            return;
	        } else if (!this.operatorExpecting && chr in this.operators) {
	            this.node = {
	                type: 'operator',
	                value: chr
	            };
	            this.list.push(this.node);
	            this.node = null;
	            this.operatorExpecting = this.operators[chr];
	            this.escaped = false;
	            return;
	        } else if (['"', "'"].includes(this.operatorExpecting) && chr === '\\') {
	            this.escaped = true;
	            return;
	        }

	        if (!this.node) {
	            this.node = {
	                type: 'text',
	                value: ''
	            };
	            this.list.push(this.node);
	        }

	        if (chr === '\n') {
	            // Convert newlines to spaces. Carriage return is ignored as \r and \n usually
	            // go together anyway and there already is a WS for \n. Lone \r means something is fishy.
	            chr = ' ';
	        }

	        if (chr.charCodeAt(0) >= 0x21 || [' ', '\t'].includes(chr)) {
	            // skip command bytes
	            this.node.value += chr;
	        }

	        this.escaped = false;
	    }
	}

	/**
	 * Parses structured e-mail addresses from an address field
	 *
	 * Example:
	 *
	 *    'Name <address@domain>'
	 *
	 * will be converted to
	 *
	 *     [{name: 'Name', address: 'address@domain'}]
	 *
	 * @param {String} str Address field
	 * @return {Array} An array of address objects
	 */
	function addressparser(str, options) {
	    options = options || {};

	    let tokenizer = new Tokenizer(str);
	    let tokens = tokenizer.tokenize();

	    let addresses = [];
	    let address = [];
	    let parsedAddresses = [];

	    tokens.forEach(token => {
	        if (token.type === 'operator' && (token.value === ',' || token.value === ';')) {
	            if (address.length) {
	                addresses.push(address);
	            }
	            address = [];
	        } else {
	            address.push(token);
	        }
	    });

	    if (address.length) {
	        addresses.push(address);
	    }

	    addresses.forEach(address => {
	        address = _handleAddress(address);
	        if (address.length) {
	            parsedAddresses = parsedAddresses.concat(address);
	        }
	    });

	    if (options.flatten) {
	        let addresses = [];
	        let walkAddressList = list => {
	            list.forEach(address => {
	                if (address.group) {
	                    return walkAddressList(address.group);
	                } else {
	                    addresses.push(address);
	                }
	            });
	        };
	        walkAddressList(parsedAddresses);
	        return addresses;
	    }

	    return parsedAddresses;
	}

	// expose to the world
	addressparser_1 = addressparser;
	return addressparser_1;
}

var lastNewline;
var hasRequiredLastNewline;

function requireLastNewline () {
	if (hasRequiredLastNewline) return lastNewline;
	hasRequiredLastNewline = 1;

	const Transform = require$$0$2.Transform;

	class LastNewline extends Transform {
	    constructor() {
	        super();
	        this.lastByte = false;
	    }

	    _transform(chunk, encoding, done) {
	        if (chunk.length) {
	            this.lastByte = chunk[chunk.length - 1];
	        }

	        this.push(chunk);
	        done();
	    }

	    _flush(done) {
	        if (this.lastByte === 0x0a) {
	            return done();
	        }
	        if (this.lastByte === 0x0d) {
	            this.push(Buffer.from('\n'));
	            return done();
	        }
	        this.push(Buffer.from('\r\n'));
	        return done();
	    }
	}

	lastNewline = LastNewline;
	return lastNewline;
}

var leWindows;
var hasRequiredLeWindows;

function requireLeWindows () {
	if (hasRequiredLeWindows) return leWindows;
	hasRequiredLeWindows = 1;

	const stream = require$$0$2;
	const Transform = stream.Transform;

	/**
	 * Ensures that only <CR><LF> sequences are used for linebreaks
	 *
	 * @param {Object} options Stream options
	 */
	class LeWindows extends Transform {
	    constructor(options) {
	        super(options);
	        // init Transform
	        this.options = options || {};
	        this.lastByte = false;
	    }

	    /**
	     * Escapes dots
	     */
	    _transform(chunk, encoding, done) {
	        let buf;
	        let lastPos = 0;

	        for (let i = 0, len = chunk.length; i < len; i++) {
	            if (chunk[i] === 0x0a) {
	                // \n
	                if ((i && chunk[i - 1] !== 0x0d) || (!i && this.lastByte !== 0x0d)) {
	                    if (i > lastPos) {
	                        buf = chunk.slice(lastPos, i);
	                        this.push(buf);
	                    }
	                    this.push(Buffer.from('\r\n'));
	                    lastPos = i + 1;
	                }
	            }
	        }

	        if (lastPos && lastPos < chunk.length) {
	            buf = chunk.slice(lastPos);
	            this.push(buf);
	        } else if (!lastPos) {
	            this.push(chunk);
	        }

	        this.lastByte = chunk[chunk.length - 1];
	        done();
	    }
	}

	leWindows = LeWindows;
	return leWindows;
}

var leUnix;
var hasRequiredLeUnix;

function requireLeUnix () {
	if (hasRequiredLeUnix) return leUnix;
	hasRequiredLeUnix = 1;

	const stream = require$$0$2;
	const Transform = stream.Transform;

	/**
	 * Ensures that only <LF> is used for linebreaks
	 *
	 * @param {Object} options Stream options
	 */
	class LeWindows extends Transform {
	    constructor(options) {
	        super(options);
	        // init Transform
	        this.options = options || {};
	    }

	    /**
	     * Escapes dots
	     */
	    _transform(chunk, encoding, done) {
	        let buf;
	        let lastPos = 0;

	        for (let i = 0, len = chunk.length; i < len; i++) {
	            if (chunk[i] === 0x0d) {
	                // \n
	                buf = chunk.slice(lastPos, i);
	                lastPos = i + 1;
	                this.push(buf);
	            }
	        }
	        if (lastPos && lastPos < chunk.length) {
	            buf = chunk.slice(lastPos);
	            this.push(buf);
	        } else if (!lastPos) {
	            this.push(chunk);
	        }
	        done();
	    }
	}

	leUnix = LeWindows;
	return leUnix;
}

/* eslint no-undefined: 0, prefer-spread: 0, no-control-regex: 0 */

var mimeNode;
var hasRequiredMimeNode;

function requireMimeNode () {
	if (hasRequiredMimeNode) return mimeNode;
	hasRequiredMimeNode = 1;

	const crypto = crypto$1;
	const fs = fs$1;
	const punycode = requirePunycode();
	const PassThrough = require$$0$2.PassThrough;
	const shared = requireShared();

	const mimeFuncs = requireMimeFuncs();
	const qp = requireQp();
	const base64 = requireBase64();
	const addressparser = requireAddressparser();
	const nmfetch = requireFetch();
	const LastNewline = requireLastNewline();

	const LeWindows = requireLeWindows();
	const LeUnix = requireLeUnix();

	/**
	 * Creates a new mime tree node. Assumes 'multipart/*' as the content type
	 * if it is a branch, anything else counts as leaf. If rootNode is missing from
	 * the options, assumes this is the root.
	 *
	 * @param {String} contentType Define the content type for the node. Can be left blank for attachments (derived from filename)
	 * @param {Object} [options] optional options
	 * @param {Object} [options.rootNode] root node for this tree
	 * @param {Object} [options.parentNode] immediate parent for this node
	 * @param {Object} [options.filename] filename for an attachment node
	 * @param {String} [options.baseBoundary] shared part of the unique multipart boundary
	 * @param {Boolean} [options.keepBcc] If true, do not exclude Bcc from the generated headers
	 * @param {Function} [options.normalizeHeaderKey] method to normalize header keys for custom caseing
	 * @param {String} [options.textEncoding] either 'Q' (the default) or 'B'
	 */
	class MimeNode {
	    constructor(contentType, options) {
	        this.nodeCounter = 0;

	        options = options || {};

	        /**
	         * shared part of the unique multipart boundary
	         */
	        this.baseBoundary = options.baseBoundary || crypto.randomBytes(8).toString('hex');
	        this.boundaryPrefix = options.boundaryPrefix || '--_NmP';

	        this.disableFileAccess = !!options.disableFileAccess;
	        this.disableUrlAccess = !!options.disableUrlAccess;

	        this.normalizeHeaderKey = options.normalizeHeaderKey;

	        /**
	         * If date headers is missing and current node is the root, this value is used instead
	         */
	        this.date = new Date();

	        /**
	         * Root node for current mime tree
	         */
	        this.rootNode = options.rootNode || this;

	        /**
	         * If true include Bcc in generated headers (if available)
	         */
	        this.keepBcc = !!options.keepBcc;

	        /**
	         * If filename is specified but contentType is not (probably an attachment)
	         * detect the content type from filename extension
	         */
	        if (options.filename) {
	            /**
	             * Filename for this node. Useful with attachments
	             */
	            this.filename = options.filename;
	            if (!contentType) {
	                contentType = mimeFuncs.detectMimeType(this.filename.split('.').pop());
	            }
	        }

	        /**
	         * Indicates which encoding should be used for header strings: "Q" or "B"
	         */
	        this.textEncoding = (options.textEncoding || '').toString().trim().charAt(0).toUpperCase();

	        /**
	         * Immediate parent for this node (or undefined if not set)
	         */
	        this.parentNode = options.parentNode;

	        /**
	         * Hostname for default message-id values
	         */
	        this.hostname = options.hostname;

	        /**
	         * If set to 'win' then uses \r\n, if 'linux' then \n. If not set (or `raw` is used) then newlines are kept as is.
	         */
	        this.newline = options.newline;

	        /**
	         * An array for possible child nodes
	         */
	        this.childNodes = [];

	        /**
	         * Used for generating unique boundaries (prepended to the shared base)
	         */
	        this._nodeId = ++this.rootNode.nodeCounter;

	        /**
	         * A list of header values for this node in the form of [{key:'', value:''}]
	         */
	        this._headers = [];

	        /**
	         * True if the content only uses ASCII printable characters
	         * @type {Boolean}
	         */
	        this._isPlainText = false;

	        /**
	         * True if the content is plain text but has longer lines than allowed
	         * @type {Boolean}
	         */
	        this._hasLongLines = false;

	        /**
	         * If set, use instead this value for envelopes instead of generating one
	         * @type {Boolean}
	         */
	        this._envelope = false;

	        /**
	         * If set then use this value as the stream content instead of building it
	         * @type {String|Buffer|Stream}
	         */
	        this._raw = false;

	        /**
	         * Additional transform streams that the message will be piped before
	         * exposing by createReadStream
	         * @type {Array}
	         */
	        this._transforms = [];

	        /**
	         * Additional process functions that the message will be piped through before
	         * exposing by createReadStream. These functions are run after transforms
	         * @type {Array}
	         */
	        this._processFuncs = [];

	        /**
	         * If content type is set (or derived from the filename) add it to headers
	         */
	        if (contentType) {
	            this.setHeader('Content-Type', contentType);
	        }
	    }

	    /////// PUBLIC METHODS

	    /**
	     * Creates and appends a child node.Arguments provided are passed to MimeNode constructor
	     *
	     * @param {String} [contentType] Optional content type
	     * @param {Object} [options] Optional options object
	     * @return {Object} Created node object
	     */
	    createChild(contentType, options) {
	        if (!options && typeof contentType === 'object') {
	            options = contentType;
	            contentType = undefined;
	        }
	        let node = new MimeNode(contentType, options);
	        this.appendChild(node);
	        return node;
	    }

	    /**
	     * Appends an existing node to the mime tree. Removes the node from an existing
	     * tree if needed
	     *
	     * @param {Object} childNode node to be appended
	     * @return {Object} Appended node object
	     */
	    appendChild(childNode) {
	        if (childNode.rootNode !== this.rootNode) {
	            childNode.rootNode = this.rootNode;
	            childNode._nodeId = ++this.rootNode.nodeCounter;
	        }

	        childNode.parentNode = this;

	        this.childNodes.push(childNode);
	        return childNode;
	    }

	    /**
	     * Replaces current node with another node
	     *
	     * @param {Object} node Replacement node
	     * @return {Object} Replacement node
	     */
	    replace(node) {
	        if (node === this) {
	            return this;
	        }

	        this.parentNode.childNodes.forEach((childNode, i) => {
	            if (childNode === this) {
	                node.rootNode = this.rootNode;
	                node.parentNode = this.parentNode;
	                node._nodeId = this._nodeId;

	                this.rootNode = this;
	                this.parentNode = undefined;

	                node.parentNode.childNodes[i] = node;
	            }
	        });

	        return node;
	    }

	    /**
	     * Removes current node from the mime tree
	     *
	     * @return {Object} removed node
	     */
	    remove() {
	        if (!this.parentNode) {
	            return this;
	        }

	        for (let i = this.parentNode.childNodes.length - 1; i >= 0; i--) {
	            if (this.parentNode.childNodes[i] === this) {
	                this.parentNode.childNodes.splice(i, 1);
	                this.parentNode = undefined;
	                this.rootNode = this;
	                return this;
	            }
	        }
	    }

	    /**
	     * Sets a header value. If the value for selected key exists, it is overwritten.
	     * You can set multiple values as well by using [{key:'', value:''}] or
	     * {key: 'value'} as the first argument.
	     *
	     * @param {String|Array|Object} key Header key or a list of key value pairs
	     * @param {String} value Header value
	     * @return {Object} current node
	     */
	    setHeader(key, value) {
	        let added = false,
	            headerValue;

	        // Allow setting multiple headers at once
	        if (!value && key && typeof key === 'object') {
	            // allow {key:'content-type', value: 'text/plain'}
	            if (key.key && 'value' in key) {
	                this.setHeader(key.key, key.value);
	            } else if (Array.isArray(key)) {
	                // allow [{key:'content-type', value: 'text/plain'}]
	                key.forEach(i => {
	                    this.setHeader(i.key, i.value);
	                });
	            } else {
	                // allow {'content-type': 'text/plain'}
	                Object.keys(key).forEach(i => {
	                    this.setHeader(i, key[i]);
	                });
	            }
	            return this;
	        }

	        key = this._normalizeHeaderKey(key);

	        headerValue = {
	            key,
	            value
	        };

	        // Check if the value exists and overwrite
	        for (let i = 0, len = this._headers.length; i < len; i++) {
	            if (this._headers[i].key === key) {
	                if (!added) {
	                    // replace the first match
	                    this._headers[i] = headerValue;
	                    added = true;
	                } else {
	                    // remove following matches
	                    this._headers.splice(i, 1);
	                    i--;
	                    len--;
	                }
	            }
	        }

	        // match not found, append the value
	        if (!added) {
	            this._headers.push(headerValue);
	        }

	        return this;
	    }

	    /**
	     * Adds a header value. If the value for selected key exists, the value is appended
	     * as a new field and old one is not touched.
	     * You can set multiple values as well by using [{key:'', value:''}] or
	     * {key: 'value'} as the first argument.
	     *
	     * @param {String|Array|Object} key Header key or a list of key value pairs
	     * @param {String} value Header value
	     * @return {Object} current node
	     */
	    addHeader(key, value) {
	        // Allow setting multiple headers at once
	        if (!value && key && typeof key === 'object') {
	            // allow {key:'content-type', value: 'text/plain'}
	            if (key.key && key.value) {
	                this.addHeader(key.key, key.value);
	            } else if (Array.isArray(key)) {
	                // allow [{key:'content-type', value: 'text/plain'}]
	                key.forEach(i => {
	                    this.addHeader(i.key, i.value);
	                });
	            } else {
	                // allow {'content-type': 'text/plain'}
	                Object.keys(key).forEach(i => {
	                    this.addHeader(i, key[i]);
	                });
	            }
	            return this;
	        } else if (Array.isArray(value)) {
	            value.forEach(val => {
	                this.addHeader(key, val);
	            });
	            return this;
	        }

	        this._headers.push({
	            key: this._normalizeHeaderKey(key),
	            value
	        });

	        return this;
	    }

	    /**
	     * Retrieves the first mathcing value of a selected key
	     *
	     * @param {String} key Key to search for
	     * @retun {String} Value for the key
	     */
	    getHeader(key) {
	        key = this._normalizeHeaderKey(key);
	        for (let i = 0, len = this._headers.length; i < len; i++) {
	            if (this._headers[i].key === key) {
	                return this._headers[i].value;
	            }
	        }
	    }

	    /**
	     * Sets body content for current node. If the value is a string, charset is added automatically
	     * to Content-Type (if it is text/*). If the value is a Buffer, you need to specify
	     * the charset yourself
	     *
	     * @param (String|Buffer) content Body content
	     * @return {Object} current node
	     */
	    setContent(content) {
	        this.content = content;
	        if (typeof this.content.pipe === 'function') {
	            // pre-stream handler. might be triggered if a stream is set as content
	            // and 'error' fires before anything is done with this stream
	            this._contentErrorHandler = err => {
	                this.content.removeListener('error', this._contentErrorHandler);
	                this.content = err;
	            };
	            this.content.once('error', this._contentErrorHandler);
	        } else if (typeof this.content === 'string') {
	            this._isPlainText = mimeFuncs.isPlainText(this.content);
	            if (this._isPlainText && mimeFuncs.hasLongerLines(this.content, 76)) {
	                // If there are lines longer than 76 symbols/bytes do not use 7bit
	                this._hasLongLines = true;
	            }
	        }
	        return this;
	    }

	    build(callback) {
	        let promise;

	        if (!callback) {
	            promise = new Promise((resolve, reject) => {
	                callback = shared.callbackPromise(resolve, reject);
	            });
	        }

	        let stream = this.createReadStream();
	        let buf = [];
	        let buflen = 0;
	        let returned = false;

	        stream.on('readable', () => {
	            let chunk;

	            while ((chunk = stream.read()) !== null) {
	                buf.push(chunk);
	                buflen += chunk.length;
	            }
	        });

	        stream.once('error', err => {
	            if (returned) {
	                return;
	            }
	            returned = true;

	            return callback(err);
	        });

	        stream.once('end', chunk => {
	            if (returned) {
	                return;
	            }
	            returned = true;

	            if (chunk && chunk.length) {
	                buf.push(chunk);
	                buflen += chunk.length;
	            }
	            return callback(null, Buffer.concat(buf, buflen));
	        });

	        return promise;
	    }

	    getTransferEncoding() {
	        let transferEncoding = false;
	        let contentType = (this.getHeader('Content-Type') || '').toString().toLowerCase().trim();

	        if (this.content) {
	            transferEncoding = (this.getHeader('Content-Transfer-Encoding') || '').toString().toLowerCase().trim();
	            if (!transferEncoding || !['base64', 'quoted-printable'].includes(transferEncoding)) {
	                if (/^text\//i.test(contentType)) {
	                    // If there are no special symbols, no need to modify the text
	                    if (this._isPlainText && !this._hasLongLines) {
	                        transferEncoding = '7bit';
	                    } else if (typeof this.content === 'string' || this.content instanceof Buffer) {
	                        // detect preferred encoding for string value
	                        transferEncoding = this._getTextEncoding(this.content) === 'Q' ? 'quoted-printable' : 'base64';
	                    } else {
	                        // we can not check content for a stream, so either use preferred encoding or fallback to QP
	                        transferEncoding = this.textEncoding === 'B' ? 'base64' : 'quoted-printable';
	                    }
	                } else if (!/^(multipart|message)\//i.test(contentType)) {
	                    transferEncoding = transferEncoding || 'base64';
	                }
	            }
	        }
	        return transferEncoding;
	    }

	    /**
	     * Builds the header block for the mime node. Append \r\n\r\n before writing the content
	     *
	     * @returns {String} Headers
	     */
	    buildHeaders() {
	        let transferEncoding = this.getTransferEncoding();
	        let headers = [];

	        if (transferEncoding) {
	            this.setHeader('Content-Transfer-Encoding', transferEncoding);
	        }

	        if (this.filename && !this.getHeader('Content-Disposition')) {
	            this.setHeader('Content-Disposition', 'attachment');
	        }

	        // Ensure mandatory header fields
	        if (this.rootNode === this) {
	            if (!this.getHeader('Date')) {
	                this.setHeader('Date', this.date.toUTCString().replace(/GMT/, '+0000'));
	            }

	            // ensure that Message-Id is present
	            this.messageId();

	            if (!this.getHeader('MIME-Version')) {
	                this.setHeader('MIME-Version', '1.0');
	            }

	            // Ensure that Content-Type is the last header for the root node
	            for (let i = this._headers.length - 2; i >= 0; i--) {
	                let header = this._headers[i];
	                if (header.key === 'Content-Type') {
	                    this._headers.splice(i, 1);
	                    this._headers.push(header);
	                }
	            }
	        }

	        this._headers.forEach(header => {
	            let key = header.key;
	            let value = header.value;
	            let structured;
	            let param;
	            let options = {};
	            let formattedHeaders = ['From', 'Sender', 'To', 'Cc', 'Bcc', 'Reply-To', 'Date', 'References'];

	            if (value && typeof value === 'object' && !formattedHeaders.includes(key)) {
	                Object.keys(value).forEach(key => {
	                    if (key !== 'value') {
	                        options[key] = value[key];
	                    }
	                });
	                value = (value.value || '').toString();
	                if (!value.trim()) {
	                    return;
	                }
	            }

	            if (options.prepared) {
	                // header value is
	                if (options.foldLines) {
	                    headers.push(mimeFuncs.foldLines(key + ': ' + value));
	                } else {
	                    headers.push(key + ': ' + value);
	                }
	                return;
	            }

	            switch (header.key) {
	                case 'Content-Disposition':
	                    structured = mimeFuncs.parseHeaderValue(value);
	                    if (this.filename) {
	                        structured.params.filename = this.filename;
	                    }
	                    value = mimeFuncs.buildHeaderValue(structured);
	                    break;

	                case 'Content-Type':
	                    structured = mimeFuncs.parseHeaderValue(value);

	                    this._handleContentType(structured);

	                    if (
	                        structured.value.match(/^text\/plain\b/) &&
	                        typeof this.content === 'string' &&
	                        /[\u0080-\uFFFF]/.test(this.content)
	                    ) {
	                        structured.params.charset = 'utf-8';
	                    }

	                    value = mimeFuncs.buildHeaderValue(structured);

	                    if (this.filename) {
	                        // add support for non-compliant clients like QQ webmail
	                        // we can't build the value with buildHeaderValue as the value is non standard and
	                        // would be converted to parameter continuation encoding that we do not want
	                        param = this._encodeWords(this.filename);

	                        if (param !== this.filename || /[\s'"\\;:/=(),<>@[\]?]|^-/.test(param)) {
	                            // include value in quotes if needed
	                            param = '"' + param + '"';
	                        }
	                        value += '; name=' + param;
	                    }
	                    break;

	                case 'Bcc':
	                    if (!this.keepBcc) {
	                        // skip BCC values
	                        return;
	                    }
	                    break;
	            }

	            value = this._encodeHeaderValue(key, value);

	            // skip empty lines
	            if (!(value || '').toString().trim()) {
	                return;
	            }

	            if (typeof this.normalizeHeaderKey === 'function') {
	                let normalized = this.normalizeHeaderKey(key, value);
	                if (normalized && typeof normalized === 'string' && normalized.length) {
	                    key = normalized;
	                }
	            }

	            headers.push(mimeFuncs.foldLines(key + ': ' + value, 76));
	        });

	        return headers.join('\r\n');
	    }

	    /**
	     * Streams the rfc2822 message from the current node. If this is a root node,
	     * mandatory header fields are set if missing (Date, Message-Id, MIME-Version)
	     *
	     * @return {String} Compiled message
	     */
	    createReadStream(options) {
	        options = options || {};

	        let stream = new PassThrough(options);
	        let outputStream = stream;
	        let transform;

	        this.stream(stream, options, err => {
	            if (err) {
	                outputStream.emit('error', err);
	                return;
	            }
	            stream.end();
	        });

	        for (let i = 0, len = this._transforms.length; i < len; i++) {
	            transform = typeof this._transforms[i] === 'function' ? this._transforms[i]() : this._transforms[i];
	            outputStream.once('error', err => {
	                transform.emit('error', err);
	            });
	            outputStream = outputStream.pipe(transform);
	        }

	        // ensure terminating newline after possible user transforms
	        transform = new LastNewline();
	        outputStream.once('error', err => {
	            transform.emit('error', err);
	        });
	        outputStream = outputStream.pipe(transform);

	        // dkim and stuff
	        for (let i = 0, len = this._processFuncs.length; i < len; i++) {
	            transform = this._processFuncs[i];
	            outputStream = transform(outputStream);
	        }

	        if (this.newline) {
	            const winbreak = ['win', 'windows', 'dos', '\r\n'].includes(this.newline.toString().toLowerCase());
	            const newlineTransform = winbreak ? new LeWindows() : new LeUnix();

	            const stream = outputStream.pipe(newlineTransform);
	            outputStream.on('error', err => stream.emit('error', err));
	            return stream;
	        }

	        return outputStream;
	    }

	    /**
	     * Appends a transform stream object to the transforms list. Final output
	     * is passed through this stream before exposing
	     *
	     * @param {Object} transform Read-Write stream
	     */
	    transform(transform) {
	        this._transforms.push(transform);
	    }

	    /**
	     * Appends a post process function. The functon is run after transforms and
	     * uses the following syntax
	     *
	     *   processFunc(input) -> outputStream
	     *
	     * @param {Object} processFunc Read-Write stream
	     */
	    processFunc(processFunc) {
	        this._processFuncs.push(processFunc);
	    }

	    stream(outputStream, options, done) {
	        let transferEncoding = this.getTransferEncoding();
	        let contentStream;
	        let localStream;

	        // protect actual callback against multiple triggering
	        let returned = false;
	        let callback = err => {
	            if (returned) {
	                return;
	            }
	            returned = true;
	            done(err);
	        };

	        // for multipart nodes, push child nodes
	        // for content nodes end the stream
	        let finalize = () => {
	            let childId = 0;
	            let processChildNode = () => {
	                if (childId >= this.childNodes.length) {
	                    outputStream.write('\r\n--' + this.boundary + '--\r\n');
	                    return callback();
	                }
	                let child = this.childNodes[childId++];
	                outputStream.write((childId > 1 ? '\r\n' : '') + '--' + this.boundary + '\r\n');
	                child.stream(outputStream, options, err => {
	                    if (err) {
	                        return callback(err);
	                    }
	                    setImmediate(processChildNode);
	                });
	            };

	            if (this.multipart) {
	                setImmediate(processChildNode);
	            } else {
	                return callback();
	            }
	        };

	        // pushes node content
	        let sendContent = () => {
	            if (this.content) {
	                if (Object.prototype.toString.call(this.content) === '[object Error]') {
	                    // content is already errored
	                    return callback(this.content);
	                }

	                if (typeof this.content.pipe === 'function') {
	                    this.content.removeListener('error', this._contentErrorHandler);
	                    this._contentErrorHandler = err => callback(err);
	                    this.content.once('error', this._contentErrorHandler);
	                }

	                let createStream = () => {
	                    if (['quoted-printable', 'base64'].includes(transferEncoding)) {
	                        contentStream = new (transferEncoding === 'base64' ? base64 : qp).Encoder(options);

	                        contentStream.pipe(outputStream, {
	                            end: false
	                        });
	                        contentStream.once('end', finalize);
	                        contentStream.once('error', err => callback(err));

	                        localStream = this._getStream(this.content);
	                        localStream.pipe(contentStream);
	                    } else {
	                        // anything that is not QP or Base54 passes as-is
	                        localStream = this._getStream(this.content);
	                        localStream.pipe(outputStream, {
	                            end: false
	                        });
	                        localStream.once('end', finalize);
	                    }

	                    localStream.once('error', err => callback(err));
	                };

	                if (this.content._resolve) {
	                    let chunks = [];
	                    let chunklen = 0;
	                    let returned = false;
	                    let sourceStream = this._getStream(this.content);
	                    sourceStream.on('error', err => {
	                        if (returned) {
	                            return;
	                        }
	                        returned = true;
	                        callback(err);
	                    });
	                    sourceStream.on('readable', () => {
	                        let chunk;
	                        while ((chunk = sourceStream.read()) !== null) {
	                            chunks.push(chunk);
	                            chunklen += chunk.length;
	                        }
	                    });
	                    sourceStream.on('end', () => {
	                        if (returned) {
	                            return;
	                        }
	                        returned = true;
	                        this.content._resolve = false;
	                        this.content._resolvedValue = Buffer.concat(chunks, chunklen);
	                        setImmediate(createStream);
	                    });
	                } else {
	                    setImmediate(createStream);
	                }
	                return;
	            } else {
	                return setImmediate(finalize);
	            }
	        };

	        if (this._raw) {
	            setImmediate(() => {
	                if (Object.prototype.toString.call(this._raw) === '[object Error]') {
	                    // content is already errored
	                    return callback(this._raw);
	                }

	                // remove default error handler (if set)
	                if (typeof this._raw.pipe === 'function') {
	                    this._raw.removeListener('error', this._contentErrorHandler);
	                }

	                let raw = this._getStream(this._raw);
	                raw.pipe(outputStream, {
	                    end: false
	                });
	                raw.on('error', err => outputStream.emit('error', err));
	                raw.on('end', finalize);
	            });
	        } else {
	            outputStream.write(this.buildHeaders() + '\r\n\r\n');
	            setImmediate(sendContent);
	        }
	    }

	    /**
	     * Sets envelope to be used instead of the generated one
	     *
	     * @return {Object} SMTP envelope in the form of {from: 'from@example.com', to: ['to@example.com']}
	     */
	    setEnvelope(envelope) {
	        let list;

	        this._envelope = {
	            from: false,
	            to: []
	        };

	        if (envelope.from) {
	            list = [];
	            this._convertAddresses(this._parseAddresses(envelope.from), list);
	            list = list.filter(address => address && address.address);
	            if (list.length && list[0]) {
	                this._envelope.from = list[0].address;
	            }
	        }
	        ['to', 'cc', 'bcc'].forEach(key => {
	            if (envelope[key]) {
	                this._convertAddresses(this._parseAddresses(envelope[key]), this._envelope.to);
	            }
	        });

	        this._envelope.to = this._envelope.to.map(to => to.address).filter(address => address);

	        let standardFields = ['to', 'cc', 'bcc', 'from'];
	        Object.keys(envelope).forEach(key => {
	            if (!standardFields.includes(key)) {
	                this._envelope[key] = envelope[key];
	            }
	        });

	        return this;
	    }

	    /**
	     * Generates and returns an object with parsed address fields
	     *
	     * @return {Object} Address object
	     */
	    getAddresses() {
	        let addresses = {};

	        this._headers.forEach(header => {
	            let key = header.key.toLowerCase();
	            if (['from', 'sender', 'reply-to', 'to', 'cc', 'bcc'].includes(key)) {
	                if (!Array.isArray(addresses[key])) {
	                    addresses[key] = [];
	                }

	                this._convertAddresses(this._parseAddresses(header.value), addresses[key]);
	            }
	        });

	        return addresses;
	    }

	    /**
	     * Generates and returns SMTP envelope with the sender address and a list of recipients addresses
	     *
	     * @return {Object} SMTP envelope in the form of {from: 'from@example.com', to: ['to@example.com']}
	     */
	    getEnvelope() {
	        if (this._envelope) {
	            return this._envelope;
	        }

	        let envelope = {
	            from: false,
	            to: []
	        };
	        this._headers.forEach(header => {
	            let list = [];
	            if (header.key === 'From' || (!envelope.from && ['Reply-To', 'Sender'].includes(header.key))) {
	                this._convertAddresses(this._parseAddresses(header.value), list);
	                if (list.length && list[0]) {
	                    envelope.from = list[0].address;
	                }
	            } else if (['To', 'Cc', 'Bcc'].includes(header.key)) {
	                this._convertAddresses(this._parseAddresses(header.value), envelope.to);
	            }
	        });

	        envelope.to = envelope.to.map(to => to.address);

	        return envelope;
	    }

	    /**
	     * Returns Message-Id value. If it does not exist, then creates one
	     *
	     * @return {String} Message-Id value
	     */
	    messageId() {
	        let messageId = this.getHeader('Message-ID');
	        // You really should define your own Message-Id field!
	        if (!messageId) {
	            messageId = this._generateMessageId();
	            this.setHeader('Message-ID', messageId);
	        }
	        return messageId;
	    }

	    /**
	     * Sets pregenerated content that will be used as the output of this node
	     *
	     * @param {String|Buffer|Stream} Raw MIME contents
	     */
	    setRaw(raw) {
	        this._raw = raw;

	        if (this._raw && typeof this._raw.pipe === 'function') {
	            // pre-stream handler. might be triggered if a stream is set as content
	            // and 'error' fires before anything is done with this stream
	            this._contentErrorHandler = err => {
	                this._raw.removeListener('error', this._contentErrorHandler);
	                this._raw = err;
	            };
	            this._raw.once('error', this._contentErrorHandler);
	        }

	        return this;
	    }

	    /////// PRIVATE METHODS

	    /**
	     * Detects and returns handle to a stream related with the content.
	     *
	     * @param {Mixed} content Node content
	     * @returns {Object} Stream object
	     */
	    _getStream(content) {
	        let contentStream;

	        if (content._resolvedValue) {
	            // pass string or buffer content as a stream
	            contentStream = new PassThrough();

	            setImmediate(() => {
	                try {
	                    contentStream.end(content._resolvedValue);
	                } catch (_err) {
	                    contentStream.emit('error', _err);
	                }
	            });

	            return contentStream;
	        } else if (typeof content.pipe === 'function') {
	            // assume as stream
	            return content;
	        } else if (content && typeof content.path === 'string' && !content.href) {
	            if (this.disableFileAccess) {
	                contentStream = new PassThrough();
	                setImmediate(() => contentStream.emit('error', new Error('File access rejected for ' + content.path)));
	                return contentStream;
	            }
	            // read file
	            return fs.createReadStream(content.path);
	        } else if (content && typeof content.href === 'string') {
	            if (this.disableUrlAccess) {
	                contentStream = new PassThrough();
	                setImmediate(() => contentStream.emit('error', new Error('Url access rejected for ' + content.href)));
	                return contentStream;
	            }
	            // fetch URL
	            return nmfetch(content.href, { headers: content.httpHeaders });
	        } else {
	            // pass string or buffer content as a stream
	            contentStream = new PassThrough();

	            setImmediate(() => {
	                try {
	                    contentStream.end(content || '');
	                } catch (_err) {
	                    contentStream.emit('error', _err);
	                }
	            });
	            return contentStream;
	        }
	    }

	    /**
	     * Parses addresses. Takes in a single address or an array or an
	     * array of address arrays (eg. To: [[first group], [second group],...])
	     *
	     * @param {Mixed} addresses Addresses to be parsed
	     * @return {Array} An array of address objects
	     */
	    _parseAddresses(addresses) {
	        return [].concat.apply(
	            [],
	            [].concat(addresses).map(address => {
	                if (address && address.address) {
	                    address.address = this._normalizeAddress(address.address);
	                    address.name = address.name || '';
	                    return [address];
	                }
	                return addressparser(address);
	            })
	        );
	    }

	    /**
	     * Normalizes a header key, uses Camel-Case form, except for uppercase MIME-
	     *
	     * @param {String} key Key to be normalized
	     * @return {String} key in Camel-Case form
	     */
	    _normalizeHeaderKey(key) {
	        key = (key || '')
	            .toString()
	            // no newlines in keys
	            .replace(/\r?\n|\r/g, ' ')
	            .trim()
	            .toLowerCase()
	            // use uppercase words, except MIME
	            .replace(/^X-SMTPAPI$|^(MIME|DKIM|ARC|BIMI)\b|^[a-z]|-(SPF|FBL|ID|MD5)$|-[a-z]/gi, c => c.toUpperCase())
	            // special case
	            .replace(/^Content-Features$/i, 'Content-features');

	        return key;
	    }

	    /**
	     * Checks if the content type is multipart and defines boundary if needed.
	     * Doesn't return anything, modifies object argument instead.
	     *
	     * @param {Object} structured Parsed header value for 'Content-Type' key
	     */
	    _handleContentType(structured) {
	        this.contentType = structured.value.trim().toLowerCase();

	        this.multipart = /^multipart\//i.test(this.contentType) ? this.contentType.substr(this.contentType.indexOf('/') + 1) : false;

	        if (this.multipart) {
	            this.boundary = structured.params.boundary = structured.params.boundary || this.boundary || this._generateBoundary();
	        } else {
	            this.boundary = false;
	        }
	    }

	    /**
	     * Generates a multipart boundary value
	     *
	     * @return {String} boundary value
	     */
	    _generateBoundary() {
	        return this.rootNode.boundaryPrefix + '-' + this.rootNode.baseBoundary + '-Part_' + this._nodeId;
	    }

	    /**
	     * Encodes a header value for use in the generated rfc2822 email.
	     *
	     * @param {String} key Header key
	     * @param {String} value Header value
	     */
	    _encodeHeaderValue(key, value) {
	        key = this._normalizeHeaderKey(key);

	        switch (key) {
	            // Structured headers
	            case 'From':
	            case 'Sender':
	            case 'To':
	            case 'Cc':
	            case 'Bcc':
	            case 'Reply-To':
	                return this._convertAddresses(this._parseAddresses(value));

	            // values enclosed in <>
	            case 'Message-ID':
	            case 'In-Reply-To':
	            case 'Content-Id':
	                value = (value || '').toString().replace(/\r?\n|\r/g, ' ');

	                if (value.charAt(0) !== '<') {
	                    value = '<' + value;
	                }

	                if (value.charAt(value.length - 1) !== '>') {
	                    value = value + '>';
	                }
	                return value;

	            // space separated list of values enclosed in <>
	            case 'References':
	                value = [].concat
	                    .apply(
	                        [],
	                        [].concat(value || '').map(elm => {
	                            elm = (elm || '')
	                                .toString()
	                                .replace(/\r?\n|\r/g, ' ')
	                                .trim();
	                            return elm.replace(/<[^>]*>/g, str => str.replace(/\s/g, '')).split(/\s+/);
	                        })
	                    )
	                    .map(elm => {
	                        if (elm.charAt(0) !== '<') {
	                            elm = '<' + elm;
	                        }
	                        if (elm.charAt(elm.length - 1) !== '>') {
	                            elm = elm + '>';
	                        }
	                        return elm;
	                    });

	                return value.join(' ').trim();

	            case 'Date':
	                if (Object.prototype.toString.call(value) === '[object Date]') {
	                    return value.toUTCString().replace(/GMT/, '+0000');
	                }

	                value = (value || '').toString().replace(/\r?\n|\r/g, ' ');
	                return this._encodeWords(value);

	            case 'Content-Type':
	            case 'Content-Disposition':
	                // if it includes a filename then it is already encoded
	                return (value || '').toString().replace(/\r?\n|\r/g, ' ');

	            default:
	                value = (value || '').toString().replace(/\r?\n|\r/g, ' ');
	                // encodeWords only encodes if needed, otherwise the original string is returned
	                return this._encodeWords(value);
	        }
	    }

	    /**
	     * Rebuilds address object using punycode and other adjustments
	     *
	     * @param {Array} addresses An array of address objects
	     * @param {Array} [uniqueList] An array to be populated with addresses
	     * @return {String} address string
	     */
	    _convertAddresses(addresses, uniqueList) {
	        let values = [];

	        uniqueList = uniqueList || [];

	        [].concat(addresses || []).forEach(address => {
	            if (address.address) {
	                address.address = this._normalizeAddress(address.address);

	                if (!address.name) {
	                    values.push(address.address.indexOf(' ') >= 0 ? `<${address.address}>` : `${address.address}`);
	                } else if (address.name) {
	                    values.push(`${this._encodeAddressName(address.name)} <${address.address}>`);
	                }

	                if (address.address) {
	                    if (!uniqueList.filter(a => a.address === address.address).length) {
	                        uniqueList.push(address);
	                    }
	                }
	            } else if (address.group) {
	                let groupListAddresses = (address.group.length ? this._convertAddresses(address.group, uniqueList) : '').trim();
	                values.push(`${this._encodeAddressName(address.name)}:${groupListAddresses};`);
	            }
	        });

	        return values.join(', ');
	    }

	    /**
	     * Normalizes an email address
	     *
	     * @param {Array} address An array of address objects
	     * @return {String} address string
	     */
	    _normalizeAddress(address) {
	        address = (address || '')
	            .toString()
	            .replace(/[\x00-\x1F<>]+/g, ' ') // remove unallowed characters
	            .trim();

	        let lastAt = address.lastIndexOf('@');
	        if (lastAt < 0) {
	            // Bare username
	            return address;
	        }

	        let user = address.substr(0, lastAt);
	        let domain = address.substr(lastAt + 1);

	        // Usernames are not touched and are kept as is even if these include unicode
	        // Domains are punycoded by default
	        // 'jõgeva.ee' will be converted to 'xn--jgeva-dua.ee'
	        // non-unicode domains are left as is

	        let encodedDomain;

	        try {
	            encodedDomain = punycode.toASCII(domain.toLowerCase());
	        } catch (_err) {
	            // keep as is?
	        }

	        if (user.indexOf(' ') >= 0) {
	            if (user.charAt(0) !== '"') {
	                user = '"' + user;
	            }
	            if (user.substr(-1) !== '"') {
	                user = user + '"';
	            }
	        }

	        return `${user}@${encodedDomain}`;
	    }

	    /**
	     * If needed, mime encodes the name part
	     *
	     * @param {String} name Name part of an address
	     * @returns {String} Mime word encoded string if needed
	     */
	    _encodeAddressName(name) {
	        if (!/^[\w ]*$/.test(name)) {
	            if (/^[\x20-\x7e]*$/.test(name)) {
	                return '"' + name.replace(/([\\"])/g, '\\$1') + '"';
	            } else {
	                return mimeFuncs.encodeWord(name, this._getTextEncoding(name), 52);
	            }
	        }
	        return name;
	    }

	    /**
	     * If needed, mime encodes the name part
	     *
	     * @param {String} name Name part of an address
	     * @returns {String} Mime word encoded string if needed
	     */
	    _encodeWords(value) {
	        // set encodeAll parameter to true even though it is against the recommendation of RFC2047,
	        // by default only words that include non-ascii should be converted into encoded words
	        // but some clients (eg. Zimbra) do not handle it properly and remove surrounding whitespace
	        return mimeFuncs.encodeWords(value, this._getTextEncoding(value), 52, true);
	    }

	    /**
	     * Detects best mime encoding for a text value
	     *
	     * @param {String} value Value to check for
	     * @return {String} either 'Q' or 'B'
	     */
	    _getTextEncoding(value) {
	        value = (value || '').toString();

	        let encoding = this.textEncoding;
	        let latinLen;
	        let nonLatinLen;

	        if (!encoding) {
	            // count latin alphabet symbols and 8-bit range symbols + control symbols
	            // if there are more latin characters, then use quoted-printable
	            // encoding, otherwise use base64
	            nonLatinLen = (value.match(/[\x00-\x08\x0B\x0C\x0E-\x1F\u0080-\uFFFF]/g) || []).length;
	            latinLen = (value.match(/[a-z]/gi) || []).length;
	            // if there are more latin symbols than binary/unicode, then prefer Q, otherwise B
	            encoding = nonLatinLen < latinLen ? 'Q' : 'B';
	        }
	        return encoding;
	    }

	    /**
	     * Generates a message id
	     *
	     * @return {String} Random Message-ID value
	     */
	    _generateMessageId() {
	        return (
	            '<' +
	            [2, 2, 2, 6].reduce(
	                // crux to generate UUID-like random strings
	                (prev, len) => prev + '-' + crypto.randomBytes(len).toString('hex'),
	                crypto.randomBytes(4).toString('hex')
	            ) +
	            '@' +
	            // try to use the domain of the FROM address or fallback to server hostname
	            (this.getEnvelope().from || this.hostname || 'localhost').split('@').pop() +
	            '>'
	        );
	    }
	}

	mimeNode = MimeNode;
	return mimeNode;
}

/* eslint no-undefined: 0 */

var mailComposer;
var hasRequiredMailComposer;

function requireMailComposer () {
	if (hasRequiredMailComposer) return mailComposer;
	hasRequiredMailComposer = 1;

	const MimeNode = requireMimeNode();
	const mimeFuncs = requireMimeFuncs();
	const parseDataURI = requireShared().parseDataURI;

	/**
	 * Creates the object for composing a MimeNode instance out from the mail options
	 *
	 * @constructor
	 * @param {Object} mail Mail options
	 */
	class MailComposer {
	    constructor(mail) {
	        this.mail = mail || {};
	        this.message = false;
	    }

	    /**
	     * Builds MimeNode instance
	     */
	    compile() {
	        this._alternatives = this.getAlternatives();
	        this._htmlNode = this._alternatives.filter(alternative => /^text\/html\b/i.test(alternative.contentType)).pop();
	        this._attachments = this.getAttachments(!!this._htmlNode);

	        this._useRelated = !!(this._htmlNode && this._attachments.related.length);
	        this._useAlternative = this._alternatives.length > 1;
	        this._useMixed = this._attachments.attached.length > 1 || (this._alternatives.length && this._attachments.attached.length === 1);

	        // Compose MIME tree
	        if (this.mail.raw) {
	            this.message = new MimeNode('message/rfc822', { newline: this.mail.newline }).setRaw(this.mail.raw);
	        } else if (this._useMixed) {
	            this.message = this._createMixed();
	        } else if (this._useAlternative) {
	            this.message = this._createAlternative();
	        } else if (this._useRelated) {
	            this.message = this._createRelated();
	        } else {
	            this.message = this._createContentNode(
	                false,
	                []
	                    .concat(this._alternatives || [])
	                    .concat(this._attachments.attached || [])
	                    .shift() || {
	                    contentType: 'text/plain',
	                    content: ''
	                }
	            );
	        }

	        // Add custom headers
	        if (this.mail.headers) {
	            this.message.addHeader(this.mail.headers);
	        }

	        // Add headers to the root node, always overrides custom headers
	        ['from', 'sender', 'to', 'cc', 'bcc', 'reply-to', 'in-reply-to', 'references', 'subject', 'message-id', 'date'].forEach(header => {
	            let key = header.replace(/-(\w)/g, (o, c) => c.toUpperCase());
	            if (this.mail[key]) {
	                this.message.setHeader(header, this.mail[key]);
	            }
	        });

	        // Sets custom envelope
	        if (this.mail.envelope) {
	            this.message.setEnvelope(this.mail.envelope);
	        }

	        // ensure Message-Id value
	        this.message.messageId();

	        return this.message;
	    }

	    /**
	     * List all attachments. Resulting attachment objects can be used as input for MimeNode nodes
	     *
	     * @param {Boolean} findRelated If true separate related attachments from attached ones
	     * @returns {Object} An object of arrays (`related` and `attached`)
	     */
	    getAttachments(findRelated) {
	        let icalEvent, eventObject;
	        let attachments = [].concat(this.mail.attachments || []).map((attachment, i) => {
	            let data;

	            if (/^data:/i.test(attachment.path || attachment.href)) {
	                attachment = this._processDataUrl(attachment);
	            }

	            let contentType =
	                attachment.contentType || mimeFuncs.detectMimeType(attachment.filename || attachment.path || attachment.href || 'bin');

	            let isImage = /^image\//i.test(contentType);
	            let isMessageNode = /^message\//i.test(contentType);

	            let contentDisposition =
	                attachment.contentDisposition || (isMessageNode || (isImage && attachment.cid) ? 'inline' : 'attachment');

	            let contentTransferEncoding;
	            if ('contentTransferEncoding' in attachment) {
	                // also contains `false`, to set
	                contentTransferEncoding = attachment.contentTransferEncoding;
	            } else if (isMessageNode) {
	                contentTransferEncoding = '7bit';
	            } else {
	                contentTransferEncoding = 'base64'; // the default
	            }

	            data = {
	                contentType,
	                contentDisposition,
	                contentTransferEncoding
	            };

	            if (attachment.filename) {
	                data.filename = attachment.filename;
	            } else if (!isMessageNode && attachment.filename !== false) {
	                data.filename = (attachment.path || attachment.href || '').split('/').pop().split('?').shift() || 'attachment-' + (i + 1);
	                if (data.filename.indexOf('.') < 0) {
	                    data.filename += '.' + mimeFuncs.detectExtension(data.contentType);
	                }
	            }

	            if (/^https?:\/\//i.test(attachment.path)) {
	                attachment.href = attachment.path;
	                attachment.path = undefined;
	            }

	            if (attachment.cid) {
	                data.cid = attachment.cid;
	            }

	            if (attachment.raw) {
	                data.raw = attachment.raw;
	            } else if (attachment.path) {
	                data.content = {
	                    path: attachment.path
	                };
	            } else if (attachment.href) {
	                data.content = {
	                    href: attachment.href,
	                    httpHeaders: attachment.httpHeaders
	                };
	            } else {
	                data.content = attachment.content || '';
	            }

	            if (attachment.encoding) {
	                data.encoding = attachment.encoding;
	            }

	            if (attachment.headers) {
	                data.headers = attachment.headers;
	            }

	            return data;
	        });

	        if (this.mail.icalEvent) {
	            if (
	                typeof this.mail.icalEvent === 'object' &&
	                (this.mail.icalEvent.content || this.mail.icalEvent.path || this.mail.icalEvent.href || this.mail.icalEvent.raw)
	            ) {
	                icalEvent = this.mail.icalEvent;
	            } else {
	                icalEvent = {
	                    content: this.mail.icalEvent
	                };
	            }

	            eventObject = {};
	            Object.keys(icalEvent).forEach(key => {
	                eventObject[key] = icalEvent[key];
	            });

	            eventObject.contentType = 'application/ics';
	            if (!eventObject.headers) {
	                eventObject.headers = {};
	            }
	            eventObject.filename = eventObject.filename || 'invite.ics';
	            eventObject.headers['Content-Disposition'] = 'attachment';
	            eventObject.headers['Content-Transfer-Encoding'] = 'base64';
	        }

	        if (!findRelated) {
	            return {
	                attached: attachments.concat(eventObject || []),
	                related: []
	            };
	        } else {
	            return {
	                attached: attachments.filter(attachment => !attachment.cid).concat(eventObject || []),
	                related: attachments.filter(attachment => !!attachment.cid)
	            };
	        }
	    }

	    /**
	     * List alternatives. Resulting objects can be used as input for MimeNode nodes
	     *
	     * @returns {Array} An array of alternative elements. Includes the `text` and `html` values as well
	     */
	    getAlternatives() {
	        let alternatives = [],
	            text,
	            html,
	            watchHtml,
	            amp,
	            icalEvent,
	            eventObject;

	        if (this.mail.text) {
	            if (
	                typeof this.mail.text === 'object' &&
	                (this.mail.text.content || this.mail.text.path || this.mail.text.href || this.mail.text.raw)
	            ) {
	                text = this.mail.text;
	            } else {
	                text = {
	                    content: this.mail.text
	                };
	            }
	            text.contentType = 'text/plain; charset=utf-8';
	        }

	        if (this.mail.watchHtml) {
	            if (
	                typeof this.mail.watchHtml === 'object' &&
	                (this.mail.watchHtml.content || this.mail.watchHtml.path || this.mail.watchHtml.href || this.mail.watchHtml.raw)
	            ) {
	                watchHtml = this.mail.watchHtml;
	            } else {
	                watchHtml = {
	                    content: this.mail.watchHtml
	                };
	            }
	            watchHtml.contentType = 'text/watch-html; charset=utf-8';
	        }

	        if (this.mail.amp) {
	            if (
	                typeof this.mail.amp === 'object' &&
	                (this.mail.amp.content || this.mail.amp.path || this.mail.amp.href || this.mail.amp.raw)
	            ) {
	                amp = this.mail.amp;
	            } else {
	                amp = {
	                    content: this.mail.amp
	                };
	            }
	            amp.contentType = 'text/x-amp-html; charset=utf-8';
	        }

	        // NB! when including attachments with a calendar alternative you might end up in a blank screen on some clients
	        if (this.mail.icalEvent) {
	            if (
	                typeof this.mail.icalEvent === 'object' &&
	                (this.mail.icalEvent.content || this.mail.icalEvent.path || this.mail.icalEvent.href || this.mail.icalEvent.raw)
	            ) {
	                icalEvent = this.mail.icalEvent;
	            } else {
	                icalEvent = {
	                    content: this.mail.icalEvent
	                };
	            }

	            eventObject = {};
	            Object.keys(icalEvent).forEach(key => {
	                eventObject[key] = icalEvent[key];
	            });

	            if (eventObject.content && typeof eventObject.content === 'object') {
	                // we are going to have the same attachment twice, so mark this to be
	                // resolved just once
	                eventObject.content._resolve = true;
	            }

	            eventObject.filename = false;
	            eventObject.contentType =
	                'text/calendar; charset=utf-8; method=' + (eventObject.method || 'PUBLISH').toString().trim().toUpperCase();
	            if (!eventObject.headers) {
	                eventObject.headers = {};
	            }
	        }

	        if (this.mail.html) {
	            if (
	                typeof this.mail.html === 'object' &&
	                (this.mail.html.content || this.mail.html.path || this.mail.html.href || this.mail.html.raw)
	            ) {
	                html = this.mail.html;
	            } else {
	                html = {
	                    content: this.mail.html
	                };
	            }
	            html.contentType = 'text/html; charset=utf-8';
	        }

	        []
	            .concat(text || [])
	            .concat(watchHtml || [])
	            .concat(amp || [])
	            .concat(html || [])
	            .concat(eventObject || [])
	            .concat(this.mail.alternatives || [])
	            .forEach(alternative => {
	                let data;

	                if (/^data:/i.test(alternative.path || alternative.href)) {
	                    alternative = this._processDataUrl(alternative);
	                }

	                data = {
	                    contentType:
	                        alternative.contentType ||
	                        mimeFuncs.detectMimeType(alternative.filename || alternative.path || alternative.href || 'txt'),
	                    contentTransferEncoding: alternative.contentTransferEncoding
	                };

	                if (alternative.filename) {
	                    data.filename = alternative.filename;
	                }

	                if (/^https?:\/\//i.test(alternative.path)) {
	                    alternative.href = alternative.path;
	                    alternative.path = undefined;
	                }

	                if (alternative.raw) {
	                    data.raw = alternative.raw;
	                } else if (alternative.path) {
	                    data.content = {
	                        path: alternative.path
	                    };
	                } else if (alternative.href) {
	                    data.content = {
	                        href: alternative.href
	                    };
	                } else {
	                    data.content = alternative.content || '';
	                }

	                if (alternative.encoding) {
	                    data.encoding = alternative.encoding;
	                }

	                if (alternative.headers) {
	                    data.headers = alternative.headers;
	                }

	                alternatives.push(data);
	            });

	        return alternatives;
	    }

	    /**
	     * Builds multipart/mixed node. It should always contain different type of elements on the same level
	     * eg. text + attachments
	     *
	     * @param {Object} parentNode Parent for this note. If it does not exist, a root node is created
	     * @returns {Object} MimeNode node element
	     */
	    _createMixed(parentNode) {
	        let node;

	        if (!parentNode) {
	            node = new MimeNode('multipart/mixed', {
	                baseBoundary: this.mail.baseBoundary,
	                textEncoding: this.mail.textEncoding,
	                boundaryPrefix: this.mail.boundaryPrefix,
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        } else {
	            node = parentNode.createChild('multipart/mixed', {
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        }

	        if (this._useAlternative) {
	            this._createAlternative(node);
	        } else if (this._useRelated) {
	            this._createRelated(node);
	        }

	        []
	            .concat((!this._useAlternative && this._alternatives) || [])
	            .concat(this._attachments.attached || [])
	            .forEach(element => {
	                // if the element is a html node from related subpart then ignore it
	                if (!this._useRelated || element !== this._htmlNode) {
	                    this._createContentNode(node, element);
	                }
	            });

	        return node;
	    }

	    /**
	     * Builds multipart/alternative node. It should always contain same type of elements on the same level
	     * eg. text + html view of the same data
	     *
	     * @param {Object} parentNode Parent for this note. If it does not exist, a root node is created
	     * @returns {Object} MimeNode node element
	     */
	    _createAlternative(parentNode) {
	        let node;

	        if (!parentNode) {
	            node = new MimeNode('multipart/alternative', {
	                baseBoundary: this.mail.baseBoundary,
	                textEncoding: this.mail.textEncoding,
	                boundaryPrefix: this.mail.boundaryPrefix,
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        } else {
	            node = parentNode.createChild('multipart/alternative', {
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        }

	        this._alternatives.forEach(alternative => {
	            if (this._useRelated && this._htmlNode === alternative) {
	                this._createRelated(node);
	            } else {
	                this._createContentNode(node, alternative);
	            }
	        });

	        return node;
	    }

	    /**
	     * Builds multipart/related node. It should always contain html node with related attachments
	     *
	     * @param {Object} parentNode Parent for this note. If it does not exist, a root node is created
	     * @returns {Object} MimeNode node element
	     */
	    _createRelated(parentNode) {
	        let node;

	        if (!parentNode) {
	            node = new MimeNode('multipart/related; type="text/html"', {
	                baseBoundary: this.mail.baseBoundary,
	                textEncoding: this.mail.textEncoding,
	                boundaryPrefix: this.mail.boundaryPrefix,
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        } else {
	            node = parentNode.createChild('multipart/related; type="text/html"', {
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        }

	        this._createContentNode(node, this._htmlNode);

	        this._attachments.related.forEach(alternative => this._createContentNode(node, alternative));

	        return node;
	    }

	    /**
	     * Creates a regular node with contents
	     *
	     * @param {Object} parentNode Parent for this note. If it does not exist, a root node is created
	     * @param {Object} element Node data
	     * @returns {Object} MimeNode node element
	     */
	    _createContentNode(parentNode, element) {
	        element = element || {};
	        element.content = element.content || '';

	        let node;
	        let encoding = (element.encoding || 'utf8')
	            .toString()
	            .toLowerCase()
	            .replace(/[-_\s]/g, '');

	        if (!parentNode) {
	            node = new MimeNode(element.contentType, {
	                filename: element.filename,
	                baseBoundary: this.mail.baseBoundary,
	                textEncoding: this.mail.textEncoding,
	                boundaryPrefix: this.mail.boundaryPrefix,
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        } else {
	            node = parentNode.createChild(element.contentType, {
	                filename: element.filename,
	                textEncoding: this.mail.textEncoding,
	                disableUrlAccess: this.mail.disableUrlAccess,
	                disableFileAccess: this.mail.disableFileAccess,
	                normalizeHeaderKey: this.mail.normalizeHeaderKey,
	                newline: this.mail.newline
	            });
	        }

	        // add custom headers
	        if (element.headers) {
	            node.addHeader(element.headers);
	        }

	        if (element.cid) {
	            node.setHeader('Content-Id', '<' + element.cid.replace(/[<>]/g, '') + '>');
	        }

	        if (element.contentTransferEncoding) {
	            node.setHeader('Content-Transfer-Encoding', element.contentTransferEncoding);
	        } else if (this.mail.encoding && /^text\//i.test(element.contentType)) {
	            node.setHeader('Content-Transfer-Encoding', this.mail.encoding);
	        }

	        if (!/^text\//i.test(element.contentType) || element.contentDisposition) {
	            node.setHeader(
	                'Content-Disposition',
	                element.contentDisposition || (element.cid && /^image\//i.test(element.contentType) ? 'inline' : 'attachment')
	            );
	        }

	        if (typeof element.content === 'string' && !['utf8', 'usascii', 'ascii'].includes(encoding)) {
	            element.content = Buffer.from(element.content, encoding);
	        }

	        // prefer pregenerated raw content
	        if (element.raw) {
	            node.setRaw(element.raw);
	        } else {
	            node.setContent(element.content);
	        }

	        return node;
	    }

	    /**
	     * Parses data uri and converts it to a Buffer
	     *
	     * @param {Object} element Content element
	     * @return {Object} Parsed element
	     */
	    _processDataUrl(element) {
	        const dataUrl = element.path || element.href;

	        // Early validation to prevent ReDoS
	        if (!dataUrl || typeof dataUrl !== 'string') {
	            return element;
	        }

	        if (!dataUrl.startsWith('data:')) {
	            return element;
	        }

	        if (dataUrl.length > 52428800) {
	            // 52428800 chars = 50MB limit for data URL string (~37.5MB decoded image)
	            // Extract content type before rejecting to preserve MIME type
	            let detectedType = 'application/octet-stream';
	            const commaPos = dataUrl.indexOf(',');

	            if (commaPos > 0 && commaPos < 200) {
	                // Parse header safely with size limit
	                const header = dataUrl.substring(5, commaPos); // skip 'data:'
	                const parts = header.split(';');
	                if (parts[0] && parts[0].includes('/')) {
	                    detectedType = parts[0].trim();
	                }
	            }

	            // Return empty content for excessively long data URLs
	            return Object.assign({}, element, {
	                path: false,
	                href: false,
	                content: Buffer.alloc(0),
	                contentType: element.contentType || detectedType
	            });
	        }

	        let parsedDataUri;
	        try {
	            parsedDataUri = parseDataURI(dataUrl);
	        } catch (_err) {
	            return element;
	        }

	        if (!parsedDataUri) {
	            return element;
	        }

	        element.content = parsedDataUri.data;
	        element.contentType = element.contentType || parsedDataUri.contentType;

	        if ('path' in element) {
	            element.path = false;
	        }

	        if ('href' in element) {
	            element.href = false;
	        }

	        return element;
	    }
	}

	mailComposer = MailComposer;
	return mailComposer;
}

var messageParser;
var hasRequiredMessageParser;

function requireMessageParser () {
	if (hasRequiredMessageParser) return messageParser;
	hasRequiredMessageParser = 1;

	const Transform = require$$0$2.Transform;

	/**
	 * MessageParser instance is a transform stream that separates message headers
	 * from the rest of the body. Headers are emitted with the 'headers' event. Message
	 * body is passed on as the resulting stream.
	 */
	class MessageParser extends Transform {
	    constructor(options) {
	        super(options);
	        this.lastBytes = Buffer.alloc(4);
	        this.headersParsed = false;
	        this.headerBytes = 0;
	        this.headerChunks = [];
	        this.rawHeaders = false;
	        this.bodySize = 0;
	    }

	    /**
	     * Keeps count of the last 4 bytes in order to detect line breaks on chunk boundaries
	     *
	     * @param {Buffer} data Next data chunk from the stream
	     */
	    updateLastBytes(data) {
	        let lblen = this.lastBytes.length;
	        let nblen = Math.min(data.length, lblen);

	        // shift existing bytes
	        for (let i = 0, len = lblen - nblen; i < len; i++) {
	            this.lastBytes[i] = this.lastBytes[i + nblen];
	        }

	        // add new bytes
	        for (let i = 1; i <= nblen; i++) {
	            this.lastBytes[lblen - i] = data[data.length - i];
	        }
	    }

	    /**
	     * Finds and removes message headers from the remaining body. We want to keep
	     * headers separated until final delivery to be able to modify these
	     *
	     * @param {Buffer} data Next chunk of data
	     * @return {Boolean} Returns true if headers are already found or false otherwise
	     */
	    checkHeaders(data) {
	        if (this.headersParsed) {
	            return true;
	        }

	        let lblen = this.lastBytes.length;
	        let headerPos = 0;
	        this.curLinePos = 0;
	        for (let i = 0, len = this.lastBytes.length + data.length; i < len; i++) {
	            let chr;
	            if (i < lblen) {
	                chr = this.lastBytes[i];
	            } else {
	                chr = data[i - lblen];
	            }
	            if (chr === 0x0a && i) {
	                let pr1 = i - 1 < lblen ? this.lastBytes[i - 1] : data[i - 1 - lblen];
	                let pr2 = i > 1 ? (i - 2 < lblen ? this.lastBytes[i - 2] : data[i - 2 - lblen]) : false;
	                if (pr1 === 0x0a) {
	                    this.headersParsed = true;
	                    headerPos = i - lblen + 1;
	                    this.headerBytes += headerPos;
	                    break;
	                } else if (pr1 === 0x0d && pr2 === 0x0a) {
	                    this.headersParsed = true;
	                    headerPos = i - lblen + 1;
	                    this.headerBytes += headerPos;
	                    break;
	                }
	            }
	        }

	        if (this.headersParsed) {
	            this.headerChunks.push(data.slice(0, headerPos));
	            this.rawHeaders = Buffer.concat(this.headerChunks, this.headerBytes);
	            this.headerChunks = null;
	            this.emit('headers', this.parseHeaders());
	            if (data.length - 1 > headerPos) {
	                let chunk = data.slice(headerPos);
	                this.bodySize += chunk.length;
	                // this would be the first chunk of data sent downstream
	                setImmediate(() => this.push(chunk));
	            }
	            return false;
	        } else {
	            this.headerBytes += data.length;
	            this.headerChunks.push(data);
	        }

	        // store last 4 bytes to catch header break
	        this.updateLastBytes(data);

	        return false;
	    }

	    _transform(chunk, encoding, callback) {
	        if (!chunk || !chunk.length) {
	            return callback();
	        }

	        if (typeof chunk === 'string') {
	            chunk = Buffer.from(chunk, encoding);
	        }

	        let headersFound;

	        try {
	            headersFound = this.checkHeaders(chunk);
	        } catch (E) {
	            return callback(E);
	        }

	        if (headersFound) {
	            this.bodySize += chunk.length;
	            this.push(chunk);
	        }

	        setImmediate(callback);
	    }

	    _flush(callback) {
	        if (this.headerChunks) {
	            let chunk = Buffer.concat(this.headerChunks, this.headerBytes);
	            this.bodySize += chunk.length;
	            this.push(chunk);
	            this.headerChunks = null;
	        }
	        callback();
	    }

	    parseHeaders() {
	        let lines = (this.rawHeaders || '').toString().split(/\r?\n/);
	        for (let i = lines.length - 1; i > 0; i--) {
	            if (/^\s/.test(lines[i])) {
	                lines[i - 1] += '\n' + lines[i];
	                lines.splice(i, 1);
	            }
	        }
	        return lines
	            .filter(line => line.trim())
	            .map(line => ({
	                key: line.substr(0, line.indexOf(':')).trim().toLowerCase(),
	                line
	            }));
	    }
	}

	messageParser = MessageParser;
	return messageParser;
}

var relaxedBody;
var hasRequiredRelaxedBody;

function requireRelaxedBody () {
	if (hasRequiredRelaxedBody) return relaxedBody;
	hasRequiredRelaxedBody = 1;

	// streams through a message body and calculates relaxed body hash

	const Transform = require$$0$2.Transform;
	const crypto = crypto$1;

	class RelaxedBody extends Transform {
	    constructor(options) {
	        super();
	        options = options || {};
	        this.chunkBuffer = [];
	        this.chunkBufferLen = 0;
	        this.bodyHash = crypto.createHash(options.hashAlgo || 'sha1');
	        this.remainder = '';
	        this.byteLength = 0;

	        this.debug = options.debug;
	        this._debugBody = options.debug ? [] : false;
	    }

	    updateHash(chunk) {
	        let bodyStr;

	        // find next remainder
	        let nextRemainder = '';

	        // This crux finds and removes the spaces from the last line and the newline characters after the last non-empty line
	        // If we get another chunk that does not match this description then we can restore the previously processed data
	        let state = 'file';
	        for (let i = chunk.length - 1; i >= 0; i--) {
	            let c = chunk[i];

	            if (state === 'file' && (c === 0x0a || c === 0x0d)) ; else if (state === 'file' && (c === 0x09 || c === 0x20)) {
	                // switch to line ending mode, this is the last non-empty line
	                state = 'line';
	            } else if (state === 'line' && (c === 0x09 || c === 0x20)) ; else if (state === 'file' || state === 'line') {
	                // non line/file ending character found, switch to body mode
	                state = 'body';
	                if (i === chunk.length - 1) {
	                    // final char is not part of line end or file end, so do nothing
	                    break;
	                }
	            }

	            if (i === 0) {
	                // reached to the beginning of the chunk, check if it is still about the ending
	                // and if the remainder also matches
	                if (
	                    (state === 'file' && (!this.remainder || /[\r\n]$/.test(this.remainder))) ||
	                    (state === 'line' && (!this.remainder || /[ \t]$/.test(this.remainder)))
	                ) {
	                    // keep everything
	                    this.remainder += chunk.toString('binary');
	                    return;
	                } else if (state === 'line' || state === 'file') {
	                    // process existing remainder as normal line but store the current chunk
	                    nextRemainder = chunk.toString('binary');
	                    chunk = false;
	                    break;
	                }
	            }

	            if (state !== 'body') {
	                continue;
	            }

	            // reached first non ending byte
	            nextRemainder = chunk.slice(i + 1).toString('binary');
	            chunk = chunk.slice(0, i + 1);
	            break;
	        }

	        let needsFixing = !!this.remainder;
	        if (chunk && !needsFixing) {
	            // check if we even need to change anything
	            for (let i = 0, len = chunk.length; i < len; i++) {
	                if (i && chunk[i] === 0x0a && chunk[i - 1] !== 0x0d) {
	                    // missing \r before \n
	                    needsFixing = true;
	                    break;
	                } else if (i && chunk[i] === 0x0d && chunk[i - 1] === 0x20) {
	                    // trailing WSP found
	                    needsFixing = true;
	                    break;
	                } else if (i && chunk[i] === 0x20 && chunk[i - 1] === 0x20) {
	                    // multiple spaces found, needs to be replaced with just one
	                    needsFixing = true;
	                    break;
	                } else if (chunk[i] === 0x09) {
	                    // TAB found, needs to be replaced with a space
	                    needsFixing = true;
	                    break;
	                }
	            }
	        }

	        if (needsFixing) {
	            bodyStr = this.remainder + (chunk ? chunk.toString('binary') : '');
	            this.remainder = nextRemainder;
	            bodyStr = bodyStr
	                .replace(/\r?\n/g, '\n') // use js line endings
	                .replace(/[ \t]*$/gm, '') // remove line endings, rtrim
	                .replace(/[ \t]+/gm, ' ') // single spaces
	                .replace(/\n/g, '\r\n'); // restore rfc822 line endings
	            chunk = Buffer.from(bodyStr, 'binary');
	        } else if (nextRemainder) {
	            this.remainder = nextRemainder;
	        }

	        if (this.debug) {
	            this._debugBody.push(chunk);
	        }
	        this.bodyHash.update(chunk);
	    }

	    _transform(chunk, encoding, callback) {
	        if (!chunk || !chunk.length) {
	            return callback();
	        }

	        if (typeof chunk === 'string') {
	            chunk = Buffer.from(chunk, encoding);
	        }

	        this.updateHash(chunk);

	        this.byteLength += chunk.length;
	        this.push(chunk);
	        callback();
	    }

	    _flush(callback) {
	        // generate final hash and emit it
	        if (/[\r\n]$/.test(this.remainder) && this.byteLength > 2) {
	            // add terminating line end
	            this.bodyHash.update(Buffer.from('\r\n'));
	        }
	        if (!this.byteLength) {
	            // emit empty line buffer to keep the stream flowing
	            this.push(Buffer.from('\r\n'));
	            // this.bodyHash.update(Buffer.from('\r\n'));
	        }

	        this.emit('hash', this.bodyHash.digest('base64'), this.debug ? Buffer.concat(this._debugBody) : false);
	        callback();
	    }
	}

	relaxedBody = RelaxedBody;
	return relaxedBody;
}

var sign = {exports: {}};

var hasRequiredSign;

function requireSign () {
	if (hasRequiredSign) return sign.exports;
	hasRequiredSign = 1;

	const punycode = requirePunycode();
	const mimeFuncs = requireMimeFuncs();
	const crypto = crypto$1;

	/**
	 * Returns DKIM signature header line
	 *
	 * @param {Object} headers Parsed headers object from MessageParser
	 * @param {String} bodyHash Base64 encoded hash of the message
	 * @param {Object} options DKIM options
	 * @param {String} options.domainName Domain name to be signed for
	 * @param {String} options.keySelector DKIM key selector to use
	 * @param {String} options.privateKey DKIM private key to use
	 * @return {String} Complete header line
	 */

	sign.exports = (headers, hashAlgo, bodyHash, options) => {
	    options = options || {};

	    // all listed fields from RFC4871 #5.5
	    let defaultFieldNames =
	        'From:Sender:Reply-To:Subject:Date:Message-ID:To:' +
	        'Cc:MIME-Version:Content-Type:Content-Transfer-Encoding:Content-ID:' +
	        'Content-Description:Resent-Date:Resent-From:Resent-Sender:' +
	        'Resent-To:Resent-Cc:Resent-Message-ID:In-Reply-To:References:' +
	        'List-Id:List-Help:List-Unsubscribe:List-Subscribe:List-Post:' +
	        'List-Owner:List-Archive';

	    let fieldNames = options.headerFieldNames || defaultFieldNames;

	    let canonicalizedHeaderData = relaxedHeaders(headers, fieldNames, options.skipFields);
	    let dkimHeader = generateDKIMHeader(options.domainName, options.keySelector, canonicalizedHeaderData.fieldNames, hashAlgo, bodyHash);

	    let signer, signature;

	    canonicalizedHeaderData.headers += 'dkim-signature:' + relaxedHeaderLine(dkimHeader);

	    signer = crypto.createSign(('rsa-' + hashAlgo).toUpperCase());
	    signer.update(canonicalizedHeaderData.headers);
	    try {
	        signature = signer.sign(options.privateKey, 'base64');
	    } catch (_E) {
	        return false;
	    }

	    return dkimHeader + signature.replace(/(^.{73}|.{75}(?!\r?\n|\r))/g, '$&\r\n ').trim();
	};

	sign.exports.relaxedHeaders = relaxedHeaders;

	function generateDKIMHeader(domainName, keySelector, fieldNames, hashAlgo, bodyHash) {
	    let dkim = [
	        'v=1',
	        'a=rsa-' + hashAlgo,
	        'c=relaxed/relaxed',
	        'd=' + punycode.toASCII(domainName),
	        'q=dns/txt',
	        's=' + keySelector,
	        'bh=' + bodyHash,
	        'h=' + fieldNames
	    ].join('; ');

	    return mimeFuncs.foldLines('DKIM-Signature: ' + dkim, 76) + ';\r\n b=';
	}

	function relaxedHeaders(headers, fieldNames, skipFields) {
	    let includedFields = new Set();
	    let skip = new Set();
	    let headerFields = new Map();

	    (skipFields || '')
	        .toLowerCase()
	        .split(':')
	        .forEach(field => {
	            skip.add(field.trim());
	        });

	    (fieldNames || '')
	        .toLowerCase()
	        .split(':')
	        .filter(field => !skip.has(field.trim()))
	        .forEach(field => {
	            includedFields.add(field.trim());
	        });

	    for (let i = headers.length - 1; i >= 0; i--) {
	        let line = headers[i];
	        // only include the first value from bottom to top
	        if (includedFields.has(line.key) && !headerFields.has(line.key)) {
	            headerFields.set(line.key, relaxedHeaderLine(line.line));
	        }
	    }

	    let headersList = [];
	    let fields = [];
	    includedFields.forEach(field => {
	        if (headerFields.has(field)) {
	            fields.push(field);
	            headersList.push(field + ':' + headerFields.get(field));
	        }
	    });

	    return {
	        headers: headersList.join('\r\n') + '\r\n',
	        fieldNames: fields.join(':')
	    };
	}

	function relaxedHeaderLine(line) {
	    return line
	        .substr(line.indexOf(':') + 1)
	        .replace(/\r?\n/g, '')
	        .replace(/\s+/g, ' ')
	        .trim();
	}
	return sign.exports;
}

var dkim;
var hasRequiredDkim;

function requireDkim () {
	if (hasRequiredDkim) return dkim;
	hasRequiredDkim = 1;

	// FIXME:
	// replace this Transform mess with a method that pipes input argument to output argument

	const MessageParser = requireMessageParser();
	const RelaxedBody = requireRelaxedBody();
	const sign = requireSign();
	const PassThrough = require$$0$2.PassThrough;
	const fs = fs$1;
	const path = path$1;
	const crypto = crypto$1;

	const DKIM_ALGO = 'sha256';
	const MAX_MESSAGE_SIZE = 2 * 1024 * 1024; // buffer messages larger than this to disk

	/*
	// Usage:

	let dkim = new DKIM({
	    domainName: 'example.com',
	    keySelector: 'key-selector',
	    privateKey,
	    cacheDir: '/tmp'
	});
	dkim.sign(input).pipe(process.stdout);

	// Where inputStream is a rfc822 message (either a stream, string or Buffer)
	// and outputStream is a DKIM signed rfc822 message
	*/

	class DKIMSigner {
	    constructor(options, keys, input, output) {
	        this.options = options || {};
	        this.keys = keys;

	        this.cacheTreshold = Number(this.options.cacheTreshold) || MAX_MESSAGE_SIZE;
	        this.hashAlgo = this.options.hashAlgo || DKIM_ALGO;

	        this.cacheDir = this.options.cacheDir || false;

	        this.chunks = [];
	        this.chunklen = 0;
	        this.readPos = 0;
	        this.cachePath = this.cacheDir
	            ? path.join(this.cacheDir, 'message.' + Date.now() + '-' + crypto.randomBytes(14).toString('hex'))
	            : false;
	        this.cache = false;

	        this.headers = false;
	        this.bodyHash = false;
	        this.parser = false;
	        this.relaxedBody = false;

	        this.input = input;
	        this.output = output;
	        this.output.usingCache = false;

	        this.hasErrored = false;

	        this.input.on('error', err => {
	            this.hasErrored = true;
	            this.cleanup();
	            output.emit('error', err);
	        });
	    }

	    cleanup() {
	        if (!this.cache || !this.cachePath) {
	            return;
	        }
	        fs.unlink(this.cachePath, () => false);
	    }

	    createReadCache() {
	        // pipe remainings to cache file
	        this.cache = fs.createReadStream(this.cachePath);
	        this.cache.once('error', err => {
	            this.cleanup();
	            this.output.emit('error', err);
	        });
	        this.cache.once('close', () => {
	            this.cleanup();
	        });
	        this.cache.pipe(this.output);
	    }

	    sendNextChunk() {
	        if (this.hasErrored) {
	            return;
	        }

	        if (this.readPos >= this.chunks.length) {
	            if (!this.cache) {
	                return this.output.end();
	            }
	            return this.createReadCache();
	        }
	        let chunk = this.chunks[this.readPos++];
	        if (this.output.write(chunk) === false) {
	            return this.output.once('drain', () => {
	                this.sendNextChunk();
	            });
	        }
	        setImmediate(() => this.sendNextChunk());
	    }

	    sendSignedOutput() {
	        let keyPos = 0;
	        let signNextKey = () => {
	            if (keyPos >= this.keys.length) {
	                this.output.write(this.parser.rawHeaders);
	                return setImmediate(() => this.sendNextChunk());
	            }
	            let key = this.keys[keyPos++];
	            let dkimField = sign(this.headers, this.hashAlgo, this.bodyHash, {
	                domainName: key.domainName,
	                keySelector: key.keySelector,
	                privateKey: key.privateKey,
	                headerFieldNames: this.options.headerFieldNames,
	                skipFields: this.options.skipFields
	            });
	            if (dkimField) {
	                this.output.write(Buffer.from(dkimField + '\r\n'));
	            }
	            return setImmediate(signNextKey);
	        };

	        if (this.bodyHash && this.headers) {
	            return signNextKey();
	        }

	        this.output.write(this.parser.rawHeaders);
	        this.sendNextChunk();
	    }

	    createWriteCache() {
	        this.output.usingCache = true;
	        // pipe remainings to cache file
	        this.cache = fs.createWriteStream(this.cachePath);
	        this.cache.once('error', err => {
	            this.cleanup();
	            // drain input
	            this.relaxedBody.unpipe(this.cache);
	            this.relaxedBody.on('readable', () => {
	                while (this.relaxedBody.read() !== null) {
	                    // do nothing
	                }
	            });
	            this.hasErrored = true;
	            // emit error
	            this.output.emit('error', err);
	        });
	        this.cache.once('close', () => {
	            this.sendSignedOutput();
	        });
	        this.relaxedBody.removeAllListeners('readable');
	        this.relaxedBody.pipe(this.cache);
	    }

	    signStream() {
	        this.parser = new MessageParser();
	        this.relaxedBody = new RelaxedBody({
	            hashAlgo: this.hashAlgo
	        });

	        this.parser.on('headers', value => {
	            this.headers = value;
	        });

	        this.relaxedBody.on('hash', value => {
	            this.bodyHash = value;
	        });

	        this.relaxedBody.on('readable', () => {
	            let chunk;
	            if (this.cache) {
	                return;
	            }
	            while ((chunk = this.relaxedBody.read()) !== null) {
	                this.chunks.push(chunk);
	                this.chunklen += chunk.length;
	                if (this.chunklen >= this.cacheTreshold && this.cachePath) {
	                    return this.createWriteCache();
	                }
	            }
	        });

	        this.relaxedBody.on('end', () => {
	            if (this.cache) {
	                return;
	            }
	            this.sendSignedOutput();
	        });

	        this.parser.pipe(this.relaxedBody);
	        setImmediate(() => this.input.pipe(this.parser));
	    }
	}

	class DKIM {
	    constructor(options) {
	        this.options = options || {};
	        this.keys = [].concat(
	            this.options.keys || {
	                domainName: options.domainName,
	                keySelector: options.keySelector,
	                privateKey: options.privateKey
	            }
	        );
	    }

	    sign(input, extraOptions) {
	        let output = new PassThrough();
	        let inputStream = input;
	        let writeValue = false;

	        if (Buffer.isBuffer(input)) {
	            writeValue = input;
	            inputStream = new PassThrough();
	        } else if (typeof input === 'string') {
	            writeValue = Buffer.from(input);
	            inputStream = new PassThrough();
	        }

	        let options = this.options;
	        if (extraOptions && Object.keys(extraOptions).length) {
	            options = {};
	            Object.keys(this.options || {}).forEach(key => {
	                options[key] = this.options[key];
	            });
	            Object.keys(extraOptions || {}).forEach(key => {
	                if (!(key in options)) {
	                    options[key] = extraOptions[key];
	                }
	            });
	        }

	        let signer = new DKIMSigner(options, this.keys, inputStream, output);
	        setImmediate(() => {
	            signer.signStream();
	            if (writeValue) {
	                setImmediate(() => {
	                    inputStream.end(writeValue);
	                });
	            }
	        });

	        return output;
	    }
	}

	dkim = DKIM;
	return dkim;
}

var httpProxyClient_1;
var hasRequiredHttpProxyClient;

function requireHttpProxyClient () {
	if (hasRequiredHttpProxyClient) return httpProxyClient_1;
	hasRequiredHttpProxyClient = 1;

	/**
	 * Minimal HTTP/S proxy client
	 */

	const net = require$$7;
	const tls = require$$1$2;
	const urllib = require$$0$1;

	/**
	 * Establishes proxied connection to destinationPort
	 *
	 * httpProxyClient("http://localhost:3128/", 80, "google.com", function(err, socket){
	 *     socket.write("GET / HTTP/1.0\r\n\r\n");
	 * });
	 *
	 * @param {String} proxyUrl proxy configuration, etg "http://proxy.host:3128/"
	 * @param {Number} destinationPort Port to open in destination host
	 * @param {String} destinationHost Destination hostname
	 * @param {Function} callback Callback to run with the rocket object once connection is established
	 */
	function httpProxyClient(proxyUrl, destinationPort, destinationHost, callback) {
	    let proxy = urllib.parse(proxyUrl);

	    // create a socket connection to the proxy server
	    let options;
	    let connect;
	    let socket;

	    options = {
	        host: proxy.hostname,
	        port: Number(proxy.port) ? Number(proxy.port) : proxy.protocol === 'https:' ? 443 : 80
	    };

	    if (proxy.protocol === 'https:') {
	        // we can use untrusted proxies as long as we verify actual SMTP certificates
	        options.rejectUnauthorized = false;
	        connect = tls.connect.bind(tls);
	    } else {
	        connect = net.connect.bind(net);
	    }

	    // Error harness for initial connection. Once connection is established, the responsibility
	    // to handle errors is passed to whoever uses this socket
	    let finished = false;
	    let tempSocketErr = err => {
	        if (finished) {
	            return;
	        }
	        finished = true;
	        try {
	            socket.destroy();
	        } catch (_E) {
	            // ignore
	        }
	        callback(err);
	    };

	    let timeoutErr = () => {
	        let err = new Error('Proxy socket timed out');
	        err.code = 'ETIMEDOUT';
	        tempSocketErr(err);
	    };

	    socket = connect(options, () => {
	        if (finished) {
	            return;
	        }

	        let reqHeaders = {
	            Host: destinationHost + ':' + destinationPort,
	            Connection: 'close'
	        };
	        if (proxy.auth) {
	            reqHeaders['Proxy-Authorization'] = 'Basic ' + Buffer.from(proxy.auth).toString('base64');
	        }

	        socket.write(
	            // HTTP method
	            'CONNECT ' +
	                destinationHost +
	                ':' +
	                destinationPort +
	                ' HTTP/1.1\r\n' +
	                // HTTP request headers
	                Object.keys(reqHeaders)
	                    .map(key => key + ': ' + reqHeaders[key])
	                    .join('\r\n') +
	                // End request
	                '\r\n\r\n'
	        );

	        let headers = '';
	        let onSocketData = chunk => {
	            let match;
	            let remainder;

	            if (finished) {
	                return;
	            }

	            headers += chunk.toString('binary');
	            if ((match = headers.match(/\r\n\r\n/))) {
	                socket.removeListener('data', onSocketData);

	                remainder = headers.substr(match.index + match[0].length);
	                headers = headers.substr(0, match.index);
	                if (remainder) {
	                    socket.unshift(Buffer.from(remainder, 'binary'));
	                }

	                // proxy connection is now established
	                finished = true;

	                // check response code
	                match = headers.match(/^HTTP\/\d+\.\d+ (\d+)/i);
	                if (!match || (match[1] || '').charAt(0) !== '2') {
	                    try {
	                        socket.destroy();
	                    } catch (_E) {
	                        // ignore
	                    }
	                    return callback(new Error('Invalid response from proxy' + ((match && ': ' + match[1]) || '')));
	                }

	                socket.removeListener('error', tempSocketErr);
	                socket.removeListener('timeout', timeoutErr);
	                socket.setTimeout(0);

	                return callback(null, socket);
	            }
	        };
	        socket.on('data', onSocketData);
	    });

	    socket.setTimeout(httpProxyClient.timeout || 30 * 1000);
	    socket.on('timeout', timeoutErr);

	    socket.once('error', tempSocketErr);
	}

	httpProxyClient_1 = httpProxyClient;
	return httpProxyClient_1;
}

var mailMessage;
var hasRequiredMailMessage;

function requireMailMessage () {
	if (hasRequiredMailMessage) return mailMessage;
	hasRequiredMailMessage = 1;

	const shared = requireShared();
	const MimeNode = requireMimeNode();
	const mimeFuncs = requireMimeFuncs();

	class MailMessage {
	    constructor(mailer, data) {
	        this.mailer = mailer;
	        this.data = {};
	        this.message = null;

	        data = data || {};
	        let options = mailer.options || {};
	        let defaults = mailer._defaults || {};

	        Object.keys(data).forEach(key => {
	            this.data[key] = data[key];
	        });

	        this.data.headers = this.data.headers || {};

	        // apply defaults
	        Object.keys(defaults).forEach(key => {
	            if (!(key in this.data)) {
	                this.data[key] = defaults[key];
	            } else if (key === 'headers') {
	                // headers is a special case. Allow setting individual default headers
	                Object.keys(defaults.headers).forEach(key => {
	                    if (!(key in this.data.headers)) {
	                        this.data.headers[key] = defaults.headers[key];
	                    }
	                });
	            }
	        });

	        // force specific keys from transporter options
	        ['disableFileAccess', 'disableUrlAccess', 'normalizeHeaderKey'].forEach(key => {
	            if (key in options) {
	                this.data[key] = options[key];
	            }
	        });
	    }

	    resolveContent(...args) {
	        return shared.resolveContent(...args);
	    }

	    resolveAll(callback) {
	        let keys = [
	            [this.data, 'html'],
	            [this.data, 'text'],
	            [this.data, 'watchHtml'],
	            [this.data, 'amp'],
	            [this.data, 'icalEvent']
	        ];

	        if (this.data.alternatives && this.data.alternatives.length) {
	            this.data.alternatives.forEach((alternative, i) => {
	                keys.push([this.data.alternatives, i]);
	            });
	        }

	        if (this.data.attachments && this.data.attachments.length) {
	            this.data.attachments.forEach((attachment, i) => {
	                if (!attachment.filename) {
	                    attachment.filename =
	                        (attachment.path || attachment.href || '').split('/').pop().split('?').shift() || 'attachment-' + (i + 1);
	                    if (attachment.filename.indexOf('.') < 0) {
	                        attachment.filename += '.' + mimeFuncs.detectExtension(attachment.contentType);
	                    }
	                }

	                if (!attachment.contentType) {
	                    attachment.contentType = mimeFuncs.detectMimeType(attachment.filename || attachment.path || attachment.href || 'bin');
	                }

	                keys.push([this.data.attachments, i]);
	            });
	        }

	        let mimeNode = new MimeNode();

	        let addressKeys = ['from', 'to', 'cc', 'bcc', 'sender', 'replyTo'];

	        addressKeys.forEach(address => {
	            let value;
	            if (this.message) {
	                value = [].concat(mimeNode._parseAddresses(this.message.getHeader(address === 'replyTo' ? 'reply-to' : address)) || []);
	            } else if (this.data[address]) {
	                value = [].concat(mimeNode._parseAddresses(this.data[address]) || []);
	            }
	            if (value && value.length) {
	                this.data[address] = value;
	            } else if (address in this.data) {
	                this.data[address] = null;
	            }
	        });

	        let singleKeys = ['from', 'sender'];
	        singleKeys.forEach(address => {
	            if (this.data[address]) {
	                this.data[address] = this.data[address].shift();
	            }
	        });

	        let pos = 0;
	        let resolveNext = () => {
	            if (pos >= keys.length) {
	                return callback(null, this.data);
	            }
	            let args = keys[pos++];
	            if (!args[0] || !args[0][args[1]]) {
	                return resolveNext();
	            }
	            shared.resolveContent(...args, (err, value) => {
	                if (err) {
	                    return callback(err);
	                }

	                let node = {
	                    content: value
	                };
	                if (args[0][args[1]] && typeof args[0][args[1]] === 'object' && !Buffer.isBuffer(args[0][args[1]])) {
	                    Object.keys(args[0][args[1]]).forEach(key => {
	                        if (!(key in node) && !['content', 'path', 'href', 'raw'].includes(key)) {
	                            node[key] = args[0][args[1]][key];
	                        }
	                    });
	                }

	                args[0][args[1]] = node;
	                resolveNext();
	            });
	        };

	        setImmediate(() => resolveNext());
	    }

	    normalize(callback) {
	        let envelope = this.data.envelope || this.message.getEnvelope();
	        let messageId = this.message.messageId();

	        this.resolveAll((err, data) => {
	            if (err) {
	                return callback(err);
	            }

	            data.envelope = envelope;
	            data.messageId = messageId;

	            ['html', 'text', 'watchHtml', 'amp'].forEach(key => {
	                if (data[key] && data[key].content) {
	                    if (typeof data[key].content === 'string') {
	                        data[key] = data[key].content;
	                    } else if (Buffer.isBuffer(data[key].content)) {
	                        data[key] = data[key].content.toString();
	                    }
	                }
	            });

	            if (data.icalEvent && Buffer.isBuffer(data.icalEvent.content)) {
	                data.icalEvent.content = data.icalEvent.content.toString('base64');
	                data.icalEvent.encoding = 'base64';
	            }

	            if (data.alternatives && data.alternatives.length) {
	                data.alternatives.forEach(alternative => {
	                    if (alternative && alternative.content && Buffer.isBuffer(alternative.content)) {
	                        alternative.content = alternative.content.toString('base64');
	                        alternative.encoding = 'base64';
	                    }
	                });
	            }

	            if (data.attachments && data.attachments.length) {
	                data.attachments.forEach(attachment => {
	                    if (attachment && attachment.content && Buffer.isBuffer(attachment.content)) {
	                        attachment.content = attachment.content.toString('base64');
	                        attachment.encoding = 'base64';
	                    }
	                });
	            }

	            data.normalizedHeaders = {};
	            Object.keys(data.headers || {}).forEach(key => {
	                let value = [].concat(data.headers[key] || []).shift();
	                value = (value && value.value) || value;
	                if (value) {
	                    if (['references', 'in-reply-to', 'message-id', 'content-id'].includes(key)) {
	                        value = this.message._encodeHeaderValue(key, value);
	                    }
	                    data.normalizedHeaders[key] = value;
	                }
	            });

	            if (data.list && typeof data.list === 'object') {
	                let listHeaders = this._getListHeaders(data.list);
	                listHeaders.forEach(entry => {
	                    data.normalizedHeaders[entry.key] = entry.value.map(val => (val && val.value) || val).join(', ');
	                });
	            }

	            if (data.references) {
	                data.normalizedHeaders.references = this.message._encodeHeaderValue('references', data.references);
	            }

	            if (data.inReplyTo) {
	                data.normalizedHeaders['in-reply-to'] = this.message._encodeHeaderValue('in-reply-to', data.inReplyTo);
	            }

	            return callback(null, data);
	        });
	    }

	    setMailerHeader() {
	        if (!this.message || !this.data.xMailer) {
	            return;
	        }
	        this.message.setHeader('X-Mailer', this.data.xMailer);
	    }

	    setPriorityHeaders() {
	        if (!this.message || !this.data.priority) {
	            return;
	        }
	        switch ((this.data.priority || '').toString().toLowerCase()) {
	            case 'high':
	                this.message.setHeader('X-Priority', '1 (Highest)');
	                this.message.setHeader('X-MSMail-Priority', 'High');
	                this.message.setHeader('Importance', 'High');
	                break;
	            case 'low':
	                this.message.setHeader('X-Priority', '5 (Lowest)');
	                this.message.setHeader('X-MSMail-Priority', 'Low');
	                this.message.setHeader('Importance', 'Low');
	                break;
	            // do not add anything, since all messages are 'Normal' by default
	        }
	    }

	    setListHeaders() {
	        if (!this.message || !this.data.list || typeof this.data.list !== 'object') {
	            return;
	        }
	        // add optional List-* headers
	        if (this.data.list && typeof this.data.list === 'object') {
	            this._getListHeaders(this.data.list).forEach(listHeader => {
	                listHeader.value.forEach(value => {
	                    this.message.addHeader(listHeader.key, value);
	                });
	            });
	        }
	    }

	    _getListHeaders(listData) {
	        // make sure an url looks like <protocol:url>
	        return Object.keys(listData).map(key => ({
	            key: 'list-' + key.toLowerCase().trim(),
	            value: [].concat(listData[key] || []).map(value => ({
	                prepared: true,
	                foldLines: true,
	                value: []
	                    .concat(value || [])
	                    .map(value => {
	                        if (typeof value === 'string') {
	                            value = {
	                                url: value
	                            };
	                        }

	                        if (value && value.url) {
	                            if (key.toLowerCase().trim() === 'id') {
	                                // List-ID: "comment" <domain>
	                                let comment = value.comment || '';
	                                if (mimeFuncs.isPlainText(comment)) {
	                                    comment = '"' + comment + '"';
	                                } else {
	                                    comment = mimeFuncs.encodeWord(comment);
	                                }

	                                return (value.comment ? comment + ' ' : '') + this._formatListUrl(value.url).replace(/^<[^:]+\/{,2}/, '');
	                            }

	                            // List-*: <http://domain> (comment)
	                            let comment = value.comment || '';
	                            if (!mimeFuncs.isPlainText(comment)) {
	                                comment = mimeFuncs.encodeWord(comment);
	                            }

	                            return this._formatListUrl(value.url) + (value.comment ? ' (' + comment + ')' : '');
	                        }

	                        return '';
	                    })
	                    .filter(value => value)
	                    .join(', ')
	            }))
	        }));
	    }

	    _formatListUrl(url) {
	        url = url.replace(/[\s<]+|[\s>]+/g, '');
	        if (/^(https?|mailto|ftp):/.test(url)) {
	            return '<' + url + '>';
	        }
	        if (/^[^@]+@[^@]+$/.test(url)) {
	            return '<mailto:' + url + '>';
	        }

	        return '<http://' + url + '>';
	    }
	}

	mailMessage = MailMessage;
	return mailMessage;
}

var mailer;
var hasRequiredMailer;

function requireMailer () {
	if (hasRequiredMailer) return mailer;
	hasRequiredMailer = 1;

	const EventEmitter$1 = EventEmitter;
	const shared = requireShared();
	const mimeTypes = requireMimeTypes();
	const MailComposer = requireMailComposer();
	const DKIM = requireDkim();
	const httpProxyClient = requireHttpProxyClient();
	const util = require$$1$1;
	const urllib = require$$0$1;
	const packageData = require$$9;
	const MailMessage = requireMailMessage();
	const net = require$$7;
	const dns = require$$4;
	const crypto = crypto$1;

	/**
	 * Creates an object for exposing the Mail API
	 *
	 * @constructor
	 * @param {Object} transporter Transport object instance to pass the mails to
	 */
	class Mail extends EventEmitter$1 {
	    constructor(transporter, options, defaults) {
	        super();

	        this.options = options || {};
	        this._defaults = defaults || {};

	        this._defaultPlugins = {
	            compile: [(...args) => this._convertDataImages(...args)],
	            stream: []
	        };

	        this._userPlugins = {
	            compile: [],
	            stream: []
	        };

	        this.meta = new Map();

	        this.dkim = this.options.dkim ? new DKIM(this.options.dkim) : false;

	        this.transporter = transporter;
	        this.transporter.mailer = this;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'mail'
	        });

	        this.logger.debug(
	            {
	                tnx: 'create'
	            },
	            'Creating transport: %s',
	            this.getVersionString()
	        );

	        // setup emit handlers for the transporter
	        if (typeof this.transporter.on === 'function') {
	            // deprecated log interface
	            this.transporter.on('log', log => {
	                this.logger.debug(
	                    {
	                        tnx: 'transport'
	                    },
	                    '%s: %s',
	                    log.type,
	                    log.message
	                );
	            });

	            // transporter errors
	            this.transporter.on('error', err => {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'transport'
	                    },
	                    'Transport Error: %s',
	                    err.message
	                );
	                this.emit('error', err);
	            });

	            // indicates if the sender has became idle
	            this.transporter.on('idle', (...args) => {
	                this.emit('idle', ...args);
	            });

	            // indicates if the sender has became idle and all connections are terminated
	            this.transporter.on('clear', (...args) => {
	                this.emit('clear', ...args);
	            });
	        }

	        /**
	         * Optional methods passed to the underlying transport object
	         */
	        ['close', 'isIdle', 'verify'].forEach(method => {
	            this[method] = (...args) => {
	                if (typeof this.transporter[method] === 'function') {
	                    if (method === 'verify' && typeof this.getSocket === 'function') {
	                        this.transporter.getSocket = this.getSocket;
	                        this.getSocket = false;
	                    }
	                    return this.transporter[method](...args);
	                } else {
	                    this.logger.warn(
	                        {
	                            tnx: 'transport',
	                            methodName: method
	                        },
	                        'Non existing method %s called for transport',
	                        method
	                    );
	                    return false;
	                }
	            };
	        });

	        // setup proxy handling
	        if (this.options.proxy && typeof this.options.proxy === 'string') {
	            this.setupProxy(this.options.proxy);
	        }
	    }

	    use(step, plugin) {
	        step = (step || '').toString();
	        if (!this._userPlugins.hasOwnProperty(step)) {
	            this._userPlugins[step] = [plugin];
	        } else {
	            this._userPlugins[step].push(plugin);
	        }

	        return this;
	    }

	    /**
	     * Sends an email using the preselected transport object
	     *
	     * @param {Object} data E-data description
	     * @param {Function?} callback Callback to run once the sending succeeded or failed
	     */
	    sendMail(data, callback = null) {
	        let promise;

	        if (!callback) {
	            promise = new Promise((resolve, reject) => {
	                callback = shared.callbackPromise(resolve, reject);
	            });
	        }

	        if (typeof this.getSocket === 'function') {
	            this.transporter.getSocket = this.getSocket;
	            this.getSocket = false;
	        }

	        let mail = new MailMessage(this, data);

	        this.logger.debug(
	            {
	                tnx: 'transport',
	                name: this.transporter.name,
	                version: this.transporter.version,
	                action: 'send'
	            },
	            'Sending mail using %s/%s',
	            this.transporter.name,
	            this.transporter.version
	        );

	        this._processPlugins('compile', mail, err => {
	            if (err) {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'plugin',
	                        action: 'compile'
	                    },
	                    'PluginCompile Error: %s',
	                    err.message
	                );
	                return callback(err);
	            }

	            mail.message = new MailComposer(mail.data).compile();

	            mail.setMailerHeader();
	            mail.setPriorityHeaders();
	            mail.setListHeaders();

	            this._processPlugins('stream', mail, err => {
	                if (err) {
	                    this.logger.error(
	                        {
	                            err,
	                            tnx: 'plugin',
	                            action: 'stream'
	                        },
	                        'PluginStream Error: %s',
	                        err.message
	                    );
	                    return callback(err);
	                }

	                if (mail.data.dkim || this.dkim) {
	                    mail.message.processFunc(input => {
	                        let dkim = mail.data.dkim ? new DKIM(mail.data.dkim) : this.dkim;
	                        this.logger.debug(
	                            {
	                                tnx: 'DKIM',
	                                messageId: mail.message.messageId(),
	                                dkimDomains: dkim.keys.map(key => key.keySelector + '.' + key.domainName).join(', ')
	                            },
	                            'Signing outgoing message with %s keys',
	                            dkim.keys.length
	                        );
	                        return dkim.sign(input, mail.data._dkim);
	                    });
	                }

	                this.transporter.send(mail, (...args) => {
	                    if (args[0]) {
	                        this.logger.error(
	                            {
	                                err: args[0],
	                                tnx: 'transport',
	                                action: 'send'
	                            },
	                            'Send Error: %s',
	                            args[0].message
	                        );
	                    }
	                    callback(...args);
	                });
	            });
	        });

	        return promise;
	    }

	    getVersionString() {
	        return util.format(
	            '%s (%s; +%s; %s/%s)',
	            packageData.name,
	            packageData.version,
	            packageData.homepage,
	            this.transporter.name,
	            this.transporter.version
	        );
	    }

	    _processPlugins(step, mail, callback) {
	        step = (step || '').toString();

	        if (!this._userPlugins.hasOwnProperty(step)) {
	            return callback();
	        }

	        let userPlugins = this._userPlugins[step] || [];
	        let defaultPlugins = this._defaultPlugins[step] || [];

	        if (userPlugins.length) {
	            this.logger.debug(
	                {
	                    tnx: 'transaction',
	                    pluginCount: userPlugins.length,
	                    step
	                },
	                'Using %s plugins for %s',
	                userPlugins.length,
	                step
	            );
	        }

	        if (userPlugins.length + defaultPlugins.length === 0) {
	            return callback();
	        }

	        let pos = 0;
	        let block = 'default';
	        let processPlugins = () => {
	            let curplugins = block === 'default' ? defaultPlugins : userPlugins;
	            if (pos >= curplugins.length) {
	                if (block === 'default' && userPlugins.length) {
	                    block = 'user';
	                    pos = 0;
	                    curplugins = userPlugins;
	                } else {
	                    return callback();
	                }
	            }
	            let plugin = curplugins[pos++];
	            plugin(mail, err => {
	                if (err) {
	                    return callback(err);
	                }
	                processPlugins();
	            });
	        };

	        processPlugins();
	    }

	    /**
	     * Sets up proxy handler for a Nodemailer object
	     *
	     * @param {String} proxyUrl Proxy configuration url
	     */
	    setupProxy(proxyUrl) {
	        let proxy = urllib.parse(proxyUrl);

	        // setup socket handler for the mailer object
	        this.getSocket = (options, callback) => {
	            let protocol = proxy.protocol.replace(/:$/, '').toLowerCase();

	            if (this.meta.has('proxy_handler_' + protocol)) {
	                return this.meta.get('proxy_handler_' + protocol)(proxy, options, callback);
	            }

	            switch (protocol) {
	                // Connect using a HTTP CONNECT method
	                case 'http':
	                case 'https':
	                    httpProxyClient(proxy.href, options.port, options.host, (err, socket) => {
	                        if (err) {
	                            return callback(err);
	                        }
	                        return callback(null, {
	                            connection: socket
	                        });
	                    });
	                    return;
	                case 'socks':
	                case 'socks5':
	                case 'socks4':
	                case 'socks4a': {
	                    if (!this.meta.has('proxy_socks_module')) {
	                        return callback(new Error('Socks module not loaded'));
	                    }
	                    let connect = ipaddress => {
	                        let proxyV2 = !!this.meta.get('proxy_socks_module').SocksClient;
	                        let socksClient = proxyV2 ? this.meta.get('proxy_socks_module').SocksClient : this.meta.get('proxy_socks_module');
	                        let proxyType = Number(proxy.protocol.replace(/\D/g, '')) || 5;
	                        let connectionOpts = {
	                            proxy: {
	                                ipaddress,
	                                port: Number(proxy.port),
	                                type: proxyType
	                            },
	                            [proxyV2 ? 'destination' : 'target']: {
	                                host: options.host,
	                                port: options.port
	                            },
	                            command: 'connect'
	                        };

	                        if (proxy.auth) {
	                            let username = decodeURIComponent(proxy.auth.split(':').shift());
	                            let password = decodeURIComponent(proxy.auth.split(':').pop());
	                            if (proxyV2) {
	                                connectionOpts.proxy.userId = username;
	                                connectionOpts.proxy.password = password;
	                            } else if (proxyType === 4) {
	                                connectionOpts.userid = username;
	                            } else {
	                                connectionOpts.authentication = {
	                                    username,
	                                    password
	                                };
	                            }
	                        }

	                        socksClient.createConnection(connectionOpts, (err, info) => {
	                            if (err) {
	                                return callback(err);
	                            }
	                            return callback(null, {
	                                connection: info.socket || info
	                            });
	                        });
	                    };

	                    if (net.isIP(proxy.hostname)) {
	                        return connect(proxy.hostname);
	                    }

	                    return dns.resolve(proxy.hostname, (err, address) => {
	                        if (err) {
	                            return callback(err);
	                        }
	                        connect(Array.isArray(address) ? address[0] : address);
	                    });
	                }
	            }
	            callback(new Error('Unknown proxy configuration'));
	        };
	    }

	    _convertDataImages(mail, callback) {
	        if ((!this.options.attachDataUrls && !mail.data.attachDataUrls) || !mail.data.html) {
	            return callback();
	        }
	        mail.resolveContent(mail.data, 'html', (err, html) => {
	            if (err) {
	                return callback(err);
	            }
	            let cidCounter = 0;
	            html = (html || '')
	                .toString()
	                .replace(/(<img\b[^<>]{0,1024} src\s{0,20}=[\s"']{0,20})(data:([^;]+);[^"'>\s]+)/gi, (match, prefix, dataUri, mimeType) => {
	                    let cid = crypto.randomBytes(10).toString('hex') + '@localhost';
	                    if (!mail.data.attachments) {
	                        mail.data.attachments = [];
	                    }
	                    if (!Array.isArray(mail.data.attachments)) {
	                        mail.data.attachments = [].concat(mail.data.attachments || []);
	                    }
	                    mail.data.attachments.push({
	                        path: dataUri,
	                        cid,
	                        filename: 'image-' + ++cidCounter + '.' + mimeTypes.detectExtension(mimeType)
	                    });
	                    return prefix + 'cid:' + cid;
	                });
	            mail.data.html = html;
	            callback();
	        });
	    }

	    set(key, value) {
	        return this.meta.set(key, value);
	    }

	    get(key) {
	        return this.meta.get(key);
	    }
	}

	mailer = Mail;
	return mailer;
}

var dataStream;
var hasRequiredDataStream;

function requireDataStream () {
	if (hasRequiredDataStream) return dataStream;
	hasRequiredDataStream = 1;

	const stream = require$$0$2;
	const Transform = stream.Transform;

	/**
	 * Escapes dots in the beginning of lines. Ends the stream with <CR><LF>.<CR><LF>
	 * Also makes sure that only <CR><LF> sequences are used for linebreaks
	 *
	 * @param {Object} options Stream options
	 */
	class DataStream extends Transform {
	    constructor(options) {
	        super(options);
	        // init Transform
	        this.options = options || {};
	        this._curLine = '';

	        this.inByteCount = 0;
	        this.outByteCount = 0;
	        this.lastByte = false;
	    }

	    /**
	     * Escapes dots
	     */
	    _transform(chunk, encoding, done) {
	        let chunks = [];
	        let chunklen = 0;
	        let i,
	            len,
	            lastPos = 0;
	        let buf;

	        if (!chunk || !chunk.length) {
	            return done();
	        }

	        if (typeof chunk === 'string') {
	            chunk = Buffer.from(chunk);
	        }

	        this.inByteCount += chunk.length;

	        for (i = 0, len = chunk.length; i < len; i++) {
	            if (chunk[i] === 0x2e) {
	                // .
	                if ((i && chunk[i - 1] === 0x0a) || (!i && (!this.lastByte || this.lastByte === 0x0a))) {
	                    buf = chunk.slice(lastPos, i + 1);
	                    chunks.push(buf);
	                    chunks.push(Buffer.from('.'));
	                    chunklen += buf.length + 1;
	                    lastPos = i + 1;
	                }
	            } else if (chunk[i] === 0x0a) {
	                // .
	                if ((i && chunk[i - 1] !== 0x0d) || (!i && this.lastByte !== 0x0d)) {
	                    if (i > lastPos) {
	                        buf = chunk.slice(lastPos, i);
	                        chunks.push(buf);
	                        chunklen += buf.length + 2;
	                    } else {
	                        chunklen += 2;
	                    }
	                    chunks.push(Buffer.from('\r\n'));
	                    lastPos = i + 1;
	                }
	            }
	        }

	        if (chunklen) {
	            // add last piece
	            if (lastPos < chunk.length) {
	                buf = chunk.slice(lastPos);
	                chunks.push(buf);
	                chunklen += buf.length;
	            }

	            this.outByteCount += chunklen;
	            this.push(Buffer.concat(chunks, chunklen));
	        } else {
	            this.outByteCount += chunk.length;
	            this.push(chunk);
	        }

	        this.lastByte = chunk[chunk.length - 1];
	        done();
	    }

	    /**
	     * Finalizes the stream with a dot on a single line
	     */
	    _flush(done) {
	        let buf;
	        if (this.lastByte === 0x0a) {
	            buf = Buffer.from('.\r\n');
	        } else if (this.lastByte === 0x0d) {
	            buf = Buffer.from('\n.\r\n');
	        } else {
	            buf = Buffer.from('\r\n.\r\n');
	        }
	        this.outByteCount += buf.length;
	        this.push(buf);
	        done();
	    }
	}

	dataStream = DataStream;
	return dataStream;
}

var smtpConnection;
var hasRequiredSmtpConnection;

function requireSmtpConnection () {
	if (hasRequiredSmtpConnection) return smtpConnection;
	hasRequiredSmtpConnection = 1;

	const packageInfo = require$$9;
	const EventEmitter$1 = EventEmitter.EventEmitter;
	const net = require$$7;
	const tls = require$$1$2;
	const os$1 = os;
	const crypto = crypto$1;
	const DataStream = requireDataStream();
	const PassThrough = require$$0$2.PassThrough;
	const shared = requireShared();

	// default timeout values in ms
	const CONNECTION_TIMEOUT = 2 * 60 * 1000; // how much to wait for the connection to be established
	const SOCKET_TIMEOUT = 10 * 60 * 1000; // how much to wait for socket inactivity before disconnecting the client
	const GREETING_TIMEOUT = 30 * 1000; // how much to wait after connection is established but SMTP greeting is not receieved
	const DNS_TIMEOUT = 30 * 1000; // how much to wait for resolveHostname

	/**
	 * Generates a SMTP connection object
	 *
	 * Optional options object takes the following possible properties:
	 *
	 *  * **port** - is the port to connect to (defaults to 587 or 465)
	 *  * **host** - is the hostname or IP address to connect to (defaults to 'localhost')
	 *  * **secure** - use SSL
	 *  * **ignoreTLS** - ignore server support for STARTTLS
	 *  * **requireTLS** - forces the client to use STARTTLS
	 *  * **name** - the name of the client server
	 *  * **localAddress** - outbound address to bind to (see: http://nodejs.org/api/net.html#net_net_connect_options_connectionlistener)
	 *  * **greetingTimeout** - Time to wait in ms until greeting message is received from the server (defaults to 10000)
	 *  * **connectionTimeout** - how many milliseconds to wait for the connection to establish
	 *  * **socketTimeout** - Time of inactivity until the connection is closed (defaults to 1 hour)
	 *  * **dnsTimeout** - Time to wait in ms for the DNS requests to be resolved (defaults to 30 seconds)
	 *  * **lmtp** - if true, uses LMTP instead of SMTP protocol
	 *  * **logger** - bunyan compatible logger interface
	 *  * **debug** - if true pass SMTP traffic to the logger
	 *  * **tls** - options for createCredentials
	 *  * **socket** - existing socket to use instead of creating a new one (see: http://nodejs.org/api/net.html#net_class_net_socket)
	 *  * **secured** - boolean indicates that the provided socket has already been upgraded to tls
	 *
	 * @constructor
	 * @namespace SMTP Client module
	 * @param {Object} [options] Option properties
	 */
	class SMTPConnection extends EventEmitter$1 {
	    constructor(options) {
	        super(options);

	        this.id = crypto.randomBytes(8).toString('base64').replace(/\W/g, '');
	        this.stage = 'init';

	        this.options = options || {};

	        this.secureConnection = !!this.options.secure;
	        this.alreadySecured = !!this.options.secured;

	        this.port = Number(this.options.port) || (this.secureConnection ? 465 : 587);
	        this.host = this.options.host || 'localhost';

	        this.servername = this.options.servername ? this.options.servername : !net.isIP(this.host) ? this.host : false;

	        this.allowInternalNetworkInterfaces = this.options.allowInternalNetworkInterfaces || false;

	        if (typeof this.options.secure === 'undefined' && this.port === 465) {
	            // if secure option is not set but port is 465, then default to secure
	            this.secureConnection = true;
	        }

	        this.name = this.options.name || this._getHostname();

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'smtp-connection',
	            sid: this.id
	        });

	        this.customAuth = new Map();
	        Object.keys(this.options.customAuth || {}).forEach(key => {
	            let mapKey = (key || '').toString().trim().toUpperCase();
	            if (!mapKey) {
	                return;
	            }
	            this.customAuth.set(mapKey, this.options.customAuth[key]);
	        });

	        /**
	         * Expose version nr, just for the reference
	         * @type {String}
	         */
	        this.version = packageInfo.version;

	        /**
	         * If true, then the user is authenticated
	         * @type {Boolean}
	         */
	        this.authenticated = false;

	        /**
	         * If set to true, this instance is no longer active
	         * @private
	         */
	        this.destroyed = false;

	        /**
	         * Defines if the current connection is secure or not. If not,
	         * STARTTLS can be used if available
	         * @private
	         */
	        this.secure = !!this.secureConnection;

	        /**
	         * Store incomplete messages coming from the server
	         * @private
	         */
	        this._remainder = '';

	        /**
	         * Unprocessed responses from the server
	         * @type {Array}
	         */
	        this._responseQueue = [];

	        this.lastServerResponse = false;

	        /**
	         * The socket connecting to the server
	         * @public
	         */
	        this._socket = false;

	        /**
	         * Lists supported auth mechanisms
	         * @private
	         */
	        this._supportedAuth = [];

	        /**
	         * Set to true, if EHLO response includes "AUTH".
	         * If false then authentication is not tried
	         */
	        this.allowsAuth = false;

	        /**
	         * Includes current envelope (from, to)
	         * @private
	         */
	        this._envelope = false;

	        /**
	         * Lists supported extensions
	         * @private
	         */
	        this._supportedExtensions = [];

	        /**
	         * Defines the maximum allowed size for a single message
	         * @private
	         */
	        this._maxAllowedSize = 0;

	        /**
	         * Function queue to run if a data chunk comes from the server
	         * @private
	         */
	        this._responseActions = [];
	        this._recipientQueue = [];

	        /**
	         * Timeout variable for waiting the greeting
	         * @private
	         */
	        this._greetingTimeout = false;

	        /**
	         * Timeout variable for waiting the connection to start
	         * @private
	         */
	        this._connectionTimeout = false;

	        /**
	         * If the socket is deemed already closed
	         * @private
	         */
	        this._destroyed = false;

	        /**
	         * If the socket is already being closed
	         * @private
	         */
	        this._closing = false;

	        /**
	         * Callbacks for socket's listeners
	         */
	        this._onSocketData = chunk => this._onData(chunk);
	        this._onSocketError = error => this._onError(error, 'ESOCKET', false, 'CONN');
	        this._onSocketClose = () => this._onClose();
	        this._onSocketEnd = () => this._onEnd();
	        this._onSocketTimeout = () => this._onTimeout();
	    }

	    /**
	     * Creates a connection to a SMTP server and sets up connection
	     * listener
	     */
	    connect(connectCallback) {
	        if (typeof connectCallback === 'function') {
	            this.once('connect', () => {
	                this.logger.debug(
	                    {
	                        tnx: 'smtp'
	                    },
	                    'SMTP handshake finished'
	                );
	                connectCallback();
	            });

	            const isDestroyedMessage = this._isDestroyedMessage('connect');
	            if (isDestroyedMessage) {
	                return connectCallback(this._formatError(isDestroyedMessage, 'ECONNECTION', false, 'CONN'));
	            }
	        }

	        let opts = {
	            port: this.port,
	            host: this.host,
	            allowInternalNetworkInterfaces: this.allowInternalNetworkInterfaces,
	            timeout: this.options.dnsTimeout || DNS_TIMEOUT
	        };

	        if (this.options.localAddress) {
	            opts.localAddress = this.options.localAddress;
	        }

	        let setupConnectionHandlers = () => {
	            this._connectionTimeout = setTimeout(() => {
	                this._onError('Connection timeout', 'ETIMEDOUT', false, 'CONN');
	            }, this.options.connectionTimeout || CONNECTION_TIMEOUT);

	            this._socket.on('error', this._onSocketError);
	        };

	        if (this.options.connection) {
	            // connection is already opened
	            this._socket = this.options.connection;
	            setupConnectionHandlers();

	            if (this.secureConnection && !this.alreadySecured) {
	                setImmediate(() =>
	                    this._upgradeConnection(err => {
	                        if (err) {
	                            this._onError(new Error('Error initiating TLS - ' + (err.message || err)), 'ETLS', false, 'CONN');
	                            return;
	                        }
	                        this._onConnect();
	                    })
	                );
	            } else {
	                setImmediate(() => this._onConnect());
	            }
	            return;
	        } else if (this.options.socket) {
	            // socket object is set up but not yet connected
	            this._socket = this.options.socket;
	            return shared.resolveHostname(opts, (err, resolved) => {
	                if (err) {
	                    return setImmediate(() => this._onError(err, 'EDNS', false, 'CONN'));
	                }
	                this.logger.debug(
	                    {
	                        tnx: 'dns',
	                        source: opts.host,
	                        resolved: resolved.host,
	                        cached: !!resolved.cached
	                    },
	                    'Resolved %s as %s [cache %s]',
	                    opts.host,
	                    resolved.host,
	                    resolved.cached ? 'hit' : 'miss'
	                );
	                Object.keys(resolved).forEach(key => {
	                    if (key.charAt(0) !== '_' && resolved[key]) {
	                        opts[key] = resolved[key];
	                    }
	                });
	                try {
	                    this._socket.connect(this.port, this.host, () => {
	                        this._socket.setKeepAlive(true);
	                        this._onConnect();
	                    });
	                    setupConnectionHandlers();
	                } catch (E) {
	                    return setImmediate(() => this._onError(E, 'ECONNECTION', false, 'CONN'));
	                }
	            });
	        } else if (this.secureConnection) {
	            // connect using tls
	            if (this.options.tls) {
	                Object.keys(this.options.tls).forEach(key => {
	                    opts[key] = this.options.tls[key];
	                });
	            }

	            // ensure servername for SNI
	            if (this.servername && !opts.servername) {
	                opts.servername = this.servername;
	            }

	            return shared.resolveHostname(opts, (err, resolved) => {
	                if (err) {
	                    return setImmediate(() => this._onError(err, 'EDNS', false, 'CONN'));
	                }
	                this.logger.debug(
	                    {
	                        tnx: 'dns',
	                        source: opts.host,
	                        resolved: resolved.host,
	                        cached: !!resolved.cached
	                    },
	                    'Resolved %s as %s [cache %s]',
	                    opts.host,
	                    resolved.host,
	                    resolved.cached ? 'hit' : 'miss'
	                );
	                Object.keys(resolved).forEach(key => {
	                    if (key.charAt(0) !== '_' && resolved[key]) {
	                        opts[key] = resolved[key];
	                    }
	                });
	                try {
	                    this._socket = tls.connect(opts, () => {
	                        this._socket.setKeepAlive(true);
	                        this._onConnect();
	                    });
	                    setupConnectionHandlers();
	                } catch (E) {
	                    return setImmediate(() => this._onError(E, 'ECONNECTION', false, 'CONN'));
	                }
	            });
	        } else {
	            // connect using plaintext
	            return shared.resolveHostname(opts, (err, resolved) => {
	                if (err) {
	                    return setImmediate(() => this._onError(err, 'EDNS', false, 'CONN'));
	                }
	                this.logger.debug(
	                    {
	                        tnx: 'dns',
	                        source: opts.host,
	                        resolved: resolved.host,
	                        cached: !!resolved.cached
	                    },
	                    'Resolved %s as %s [cache %s]',
	                    opts.host,
	                    resolved.host,
	                    resolved.cached ? 'hit' : 'miss'
	                );
	                Object.keys(resolved).forEach(key => {
	                    if (key.charAt(0) !== '_' && resolved[key]) {
	                        opts[key] = resolved[key];
	                    }
	                });
	                try {
	                    this._socket = net.connect(opts, () => {
	                        this._socket.setKeepAlive(true);
	                        this._onConnect();
	                    });
	                    setupConnectionHandlers();
	                } catch (E) {
	                    return setImmediate(() => this._onError(E, 'ECONNECTION', false, 'CONN'));
	                }
	            });
	        }
	    }

	    /**
	     * Sends QUIT
	     */
	    quit() {
	        this._sendCommand('QUIT');
	        this._responseActions.push(this.close);
	    }

	    /**
	     * Closes the connection to the server
	     */
	    close() {
	        clearTimeout(this._connectionTimeout);
	        clearTimeout(this._greetingTimeout);
	        this._responseActions = [];

	        // allow to run this function only once
	        if (this._closing) {
	            return;
	        }
	        this._closing = true;

	        let closeMethod = 'end';

	        if (this.stage === 'init') {
	            // Close the socket immediately when connection timed out
	            closeMethod = 'destroy';
	        }

	        this.logger.debug(
	            {
	                tnx: 'smtp'
	            },
	            'Closing connection to the server using "%s"',
	            closeMethod
	        );

	        let socket = (this._socket && this._socket.socket) || this._socket;

	        if (socket && !socket.destroyed) {
	            try {
	                socket[closeMethod]();
	            } catch (_E) {
	                // just ignore
	            }
	        }

	        this._destroy();
	    }

	    /**
	     * Authenticate user
	     */
	    login(authData, callback) {
	        const isDestroyedMessage = this._isDestroyedMessage('login');
	        if (isDestroyedMessage) {
	            return callback(this._formatError(isDestroyedMessage, 'ECONNECTION', false, 'API'));
	        }

	        this._auth = authData || {};
	        // Select SASL authentication method
	        this._authMethod = (this._auth.method || '').toString().trim().toUpperCase() || false;

	        if (!this._authMethod && this._auth.oauth2 && !this._auth.credentials) {
	            this._authMethod = 'XOAUTH2';
	        } else if (!this._authMethod || (this._authMethod === 'XOAUTH2' && !this._auth.oauth2)) {
	            // use first supported
	            this._authMethod = (this._supportedAuth[0] || 'PLAIN').toUpperCase().trim();
	        }

	        if (this._authMethod !== 'XOAUTH2' && (!this._auth.credentials || !this._auth.credentials.user || !this._auth.credentials.pass)) {
	            if ((this._auth.user && this._auth.pass) || this.customAuth.has(this._authMethod)) {
	                this._auth.credentials = {
	                    user: this._auth.user,
	                    pass: this._auth.pass,
	                    options: this._auth.options
	                };
	            } else {
	                return callback(this._formatError('Missing credentials for "' + this._authMethod + '"', 'EAUTH', false, 'API'));
	            }
	        }

	        if (this.customAuth.has(this._authMethod)) {
	            let handler = this.customAuth.get(this._authMethod);
	            let lastResponse;
	            let returned = false;

	            let resolve = () => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                this.logger.info(
	                    {
	                        tnx: 'smtp',
	                        username: this._auth.user,
	                        action: 'authenticated',
	                        method: this._authMethod
	                    },
	                    'User %s authenticated',
	                    JSON.stringify(this._auth.user)
	                );
	                this.authenticated = true;
	                callback(null, true);
	            };

	            let reject = err => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                callback(this._formatError(err, 'EAUTH', lastResponse, 'AUTH ' + this._authMethod));
	            };

	            let handlerResponse = handler({
	                auth: this._auth,
	                method: this._authMethod,

	                extensions: [].concat(this._supportedExtensions),
	                authMethods: [].concat(this._supportedAuth),
	                maxAllowedSize: this._maxAllowedSize || false,

	                sendCommand: (cmd, done) => {
	                    let promise;

	                    if (!done) {
	                        promise = new Promise((resolve, reject) => {
	                            done = shared.callbackPromise(resolve, reject);
	                        });
	                    }

	                    this._responseActions.push(str => {
	                        lastResponse = str;

	                        let codes = str.match(/^(\d+)(?:\s(\d+\.\d+\.\d+))?\s/);
	                        let data = {
	                            command: cmd,
	                            response: str
	                        };
	                        if (codes) {
	                            data.status = Number(codes[1]) || 0;
	                            if (codes[2]) {
	                                data.code = codes[2];
	                            }
	                            data.text = str.substr(codes[0].length);
	                        } else {
	                            data.text = str;
	                            data.status = 0; // just in case we need to perform numeric comparisons
	                        }
	                        done(null, data);
	                    });
	                    setImmediate(() => this._sendCommand(cmd));

	                    return promise;
	                },

	                resolve,
	                reject
	            });

	            if (handlerResponse && typeof handlerResponse.catch === 'function') {
	                // a promise was returned
	                handlerResponse.then(resolve).catch(reject);
	            }

	            return;
	        }

	        switch (this._authMethod) {
	            case 'XOAUTH2':
	                this._handleXOauth2Token(false, callback);
	                return;
	            case 'LOGIN':
	                this._responseActions.push(str => {
	                    this._actionAUTH_LOGIN_USER(str, callback);
	                });
	                this._sendCommand('AUTH LOGIN');
	                return;
	            case 'PLAIN':
	                this._responseActions.push(str => {
	                    this._actionAUTHComplete(str, callback);
	                });
	                this._sendCommand(
	                    'AUTH PLAIN ' +
	                        Buffer.from(
	                            //this._auth.user+'\u0000'+
	                            '\u0000' + // skip authorization identity as it causes problems with some servers
	                                this._auth.credentials.user +
	                                '\u0000' +
	                                this._auth.credentials.pass,
	                            'utf-8'
	                        ).toString('base64'),
	                    // log entry without passwords
	                    'AUTH PLAIN ' +
	                        Buffer.from(
	                            //this._auth.user+'\u0000'+
	                            '\u0000' + // skip authorization identity as it causes problems with some servers
	                                this._auth.credentials.user +
	                                '\u0000' +
	                                '/* secret */',
	                            'utf-8'
	                        ).toString('base64')
	                );
	                return;
	            case 'CRAM-MD5':
	                this._responseActions.push(str => {
	                    this._actionAUTH_CRAM_MD5(str, callback);
	                });
	                this._sendCommand('AUTH CRAM-MD5');
	                return;
	        }

	        return callback(this._formatError('Unknown authentication method "' + this._authMethod + '"', 'EAUTH', false, 'API'));
	    }

	    /**
	     * Sends a message
	     *
	     * @param {Object} envelope Envelope object, {from: addr, to: [addr]}
	     * @param {Object} message String, Buffer or a Stream
	     * @param {Function} callback Callback to return once sending is completed
	     */
	    send(envelope, message, done) {
	        if (!message) {
	            return done(this._formatError('Empty message', 'EMESSAGE', false, 'API'));
	        }

	        const isDestroyedMessage = this._isDestroyedMessage('send message');
	        if (isDestroyedMessage) {
	            return done(this._formatError(isDestroyedMessage, 'ECONNECTION', false, 'API'));
	        }

	        // reject larger messages than allowed
	        if (this._maxAllowedSize && envelope.size > this._maxAllowedSize) {
	            return setImmediate(() => {
	                done(this._formatError('Message size larger than allowed ' + this._maxAllowedSize, 'EMESSAGE', false, 'MAIL FROM'));
	            });
	        }

	        // ensure that callback is only called once
	        let returned = false;
	        let callback = function () {
	            if (returned) {
	                return;
	            }
	            returned = true;

	            done(...arguments);
	        };

	        if (typeof message.on === 'function') {
	            message.on('error', err => callback(this._formatError(err, 'ESTREAM', false, 'API')));
	        }

	        let startTime = Date.now();
	        this._setEnvelope(envelope, (err, info) => {
	            if (err) {
	                // create passthrough stream to consume to prevent OOM
	                let stream = new PassThrough();
	                if (typeof message.pipe === 'function') {
	                    message.pipe(stream);
	                } else {
	                    stream.write(message);
	                    stream.end();
	                }

	                return callback(err);
	            }
	            let envelopeTime = Date.now();
	            let stream = this._createSendStream((err, str) => {
	                if (err) {
	                    return callback(err);
	                }

	                info.envelopeTime = envelopeTime - startTime;
	                info.messageTime = Date.now() - envelopeTime;
	                info.messageSize = stream.outByteCount;
	                info.response = str;

	                return callback(null, info);
	            });
	            if (typeof message.pipe === 'function') {
	                message.pipe(stream);
	            } else {
	                stream.write(message);
	                stream.end();
	            }
	        });
	    }

	    /**
	     * Resets connection state
	     *
	     * @param {Function} callback Callback to return once connection is reset
	     */
	    reset(callback) {
	        this._sendCommand('RSET');
	        this._responseActions.push(str => {
	            if (str.charAt(0) !== '2') {
	                return callback(this._formatError('Could not reset session state. response=' + str, 'EPROTOCOL', str, 'RSET'));
	            }
	            this._envelope = false;
	            return callback(null, true);
	        });
	    }

	    /**
	     * Connection listener that is run when the connection to
	     * the server is opened
	     *
	     * @event
	     */
	    _onConnect() {
	        clearTimeout(this._connectionTimeout);

	        this.logger.info(
	            {
	                tnx: 'network',
	                localAddress: this._socket.localAddress,
	                localPort: this._socket.localPort,
	                remoteAddress: this._socket.remoteAddress,
	                remotePort: this._socket.remotePort
	            },
	            '%s established to %s:%s',
	            this.secure ? 'Secure connection' : 'Connection',
	            this._socket.remoteAddress,
	            this._socket.remotePort
	        );

	        if (this._destroyed) {
	            // Connection was established after we already had canceled it
	            this.close();
	            return;
	        }

	        this.stage = 'connected';

	        // clear existing listeners for the socket
	        this._socket.removeListener('data', this._onSocketData);
	        this._socket.removeListener('timeout', this._onSocketTimeout);
	        this._socket.removeListener('close', this._onSocketClose);
	        this._socket.removeListener('end', this._onSocketEnd);

	        this._socket.on('data', this._onSocketData);
	        this._socket.once('close', this._onSocketClose);
	        this._socket.once('end', this._onSocketEnd);

	        this._socket.setTimeout(this.options.socketTimeout || SOCKET_TIMEOUT);
	        this._socket.on('timeout', this._onSocketTimeout);

	        this._greetingTimeout = setTimeout(() => {
	            // if still waiting for greeting, give up
	            if (this._socket && !this._destroyed && this._responseActions[0] === this._actionGreeting) {
	                this._onError('Greeting never received', 'ETIMEDOUT', false, 'CONN');
	            }
	        }, this.options.greetingTimeout || GREETING_TIMEOUT);

	        this._responseActions.push(this._actionGreeting);

	        // we have a 'data' listener set up so resume socket if it was paused
	        this._socket.resume();
	    }

	    /**
	     * 'data' listener for data coming from the server
	     *
	     * @event
	     * @param {Buffer} chunk Data chunk coming from the server
	     */
	    _onData(chunk) {
	        if (this._destroyed || !chunk || !chunk.length) {
	            return;
	        }

	        let data = (chunk || '').toString('binary');
	        let lines = (this._remainder + data).split(/\r?\n/);
	        let lastline;

	        this._remainder = lines.pop();

	        for (let i = 0, len = lines.length; i < len; i++) {
	            if (this._responseQueue.length) {
	                lastline = this._responseQueue[this._responseQueue.length - 1];
	                if (/^\d+-/.test(lastline.split('\n').pop())) {
	                    this._responseQueue[this._responseQueue.length - 1] += '\n' + lines[i];
	                    continue;
	                }
	            }
	            this._responseQueue.push(lines[i]);
	        }

	        if (this._responseQueue.length) {
	            lastline = this._responseQueue[this._responseQueue.length - 1];
	            if (/^\d+-/.test(lastline.split('\n').pop())) {
	                return;
	            }
	        }

	        this._processResponse();
	    }

	    /**
	     * 'error' listener for the socket
	     *
	     * @event
	     * @param {Error} err Error object
	     * @param {String} type Error name
	     */
	    _onError(err, type, data, command) {
	        clearTimeout(this._connectionTimeout);
	        clearTimeout(this._greetingTimeout);

	        if (this._destroyed) {
	            // just ignore, already closed
	            // this might happen when a socket is canceled because of reached timeout
	            // but the socket timeout error itself receives only after
	            return;
	        }

	        err = this._formatError(err, type, data, command);

	        this.logger.error(data, err.message);

	        this.emit('error', err);
	        this.close();
	    }

	    _formatError(message, type, response, command) {
	        let err;

	        if (/Error\]$/i.test(Object.prototype.toString.call(message))) {
	            err = message;
	        } else {
	            err = new Error(message);
	        }

	        if (type && type !== 'Error') {
	            err.code = type;
	        }

	        if (response) {
	            err.response = response;
	            err.message += ': ' + response;
	        }

	        let responseCode = (typeof response === 'string' && Number((response.match(/^\d+/) || [])[0])) || false;
	        if (responseCode) {
	            err.responseCode = responseCode;
	        }

	        if (command) {
	            err.command = command;
	        }

	        return err;
	    }

	    /**
	     * 'close' listener for the socket
	     *
	     * @event
	     */
	    _onClose() {
	        let serverResponse = false;

	        if (this._remainder && this._remainder.trim()) {
	            if (this.options.debug || this.options.transactionLog) {
	                this.logger.debug(
	                    {
	                        tnx: 'server'
	                    },
	                    this._remainder.replace(/\r?\n$/, '')
	                );
	            }
	            this.lastServerResponse = serverResponse = this._remainder.trim();
	        }

	        this.logger.info(
	            {
	                tnx: 'network'
	            },
	            'Connection closed'
	        );

	        if (this.upgrading && !this._destroyed) {
	            return this._onError(new Error('Connection closed unexpectedly'), 'ETLS', serverResponse, 'CONN');
	        } else if (![this._actionGreeting, this.close].includes(this._responseActions[0]) && !this._destroyed) {
	            return this._onError(new Error('Connection closed unexpectedly'), 'ECONNECTION', serverResponse, 'CONN');
	        } else if (/^[45]\d{2}\b/.test(serverResponse)) {
	            return this._onError(new Error('Connection closed unexpectedly'), 'ECONNECTION', serverResponse, 'CONN');
	        }

	        this._destroy();
	    }

	    /**
	     * 'end' listener for the socket
	     *
	     * @event
	     */
	    _onEnd() {
	        if (this._socket && !this._socket.destroyed) {
	            this._socket.destroy();
	        }
	    }

	    /**
	     * 'timeout' listener for the socket
	     *
	     * @event
	     */
	    _onTimeout() {
	        return this._onError(new Error('Timeout'), 'ETIMEDOUT', false, 'CONN');
	    }

	    /**
	     * Destroys the client, emits 'end'
	     */
	    _destroy() {
	        if (this._destroyed) {
	            return;
	        }
	        this._destroyed = true;
	        this.emit('end');
	    }

	    /**
	     * Upgrades the connection to TLS
	     *
	     * @param {Function} callback Callback function to run when the connection
	     *        has been secured
	     */
	    _upgradeConnection(callback) {
	        // do not remove all listeners or it breaks node v0.10 as there's
	        // apparently a 'finish' event set that would be cleared as well

	        // we can safely keep 'error', 'end', 'close' etc. events
	        this._socket.removeListener('data', this._onSocketData); // incoming data is going to be gibberish from this point onwards
	        this._socket.removeListener('timeout', this._onSocketTimeout); // timeout will be re-set for the new socket object

	        let socketPlain = this._socket;
	        let opts = {
	            socket: this._socket,
	            host: this.host
	        };

	        Object.keys(this.options.tls || {}).forEach(key => {
	            opts[key] = this.options.tls[key];
	        });

	        // ensure servername for SNI
	        if (this.servername && !opts.servername) {
	            opts.servername = this.servername;
	        }

	        this.upgrading = true;
	        // tls.connect is not an asynchronous function however it may still throw errors and requires to be wrapped with try/catch
	        try {
	            this._socket = tls.connect(opts, () => {
	                this.secure = true;
	                this.upgrading = false;
	                this._socket.on('data', this._onSocketData);

	                socketPlain.removeListener('close', this._onSocketClose);
	                socketPlain.removeListener('end', this._onSocketEnd);

	                return callback(null, true);
	            });
	        } catch (err) {
	            return callback(err);
	        }

	        this._socket.on('error', this._onSocketError);
	        this._socket.once('close', this._onSocketClose);
	        this._socket.once('end', this._onSocketEnd);

	        this._socket.setTimeout(this.options.socketTimeout || SOCKET_TIMEOUT); // 10 min.
	        this._socket.on('timeout', this._onSocketTimeout);

	        // resume in case the socket was paused
	        socketPlain.resume();
	    }

	    /**
	     * Processes queued responses from the server
	     *
	     * @param {Boolean} force If true, ignores _processing flag
	     */
	    _processResponse() {
	        if (!this._responseQueue.length) {
	            return false;
	        }

	        let str = (this.lastServerResponse = (this._responseQueue.shift() || '').toString());

	        if (/^\d+-/.test(str.split('\n').pop())) {
	            // keep waiting for the final part of multiline response
	            return;
	        }

	        if (this.options.debug || this.options.transactionLog) {
	            this.logger.debug(
	                {
	                    tnx: 'server'
	                },
	                str.replace(/\r?\n$/, '')
	            );
	        }

	        if (!str.trim()) {
	            // skip unexpected empty lines
	            setImmediate(() => this._processResponse());
	        }

	        let action = this._responseActions.shift();

	        if (typeof action === 'function') {
	            action.call(this, str);
	            setImmediate(() => this._processResponse());
	        } else {
	            return this._onError(new Error('Unexpected Response'), 'EPROTOCOL', str, 'CONN');
	        }
	    }

	    /**
	     * Send a command to the server, append \r\n
	     *
	     * @param {String} str String to be sent to the server
	     * @param {String} logStr Optional string to be used for logging instead of the actual string
	     */
	    _sendCommand(str, logStr) {
	        if (this._destroyed) {
	            // Connection already closed, can't send any more data
	            return;
	        }

	        if (this._socket.destroyed) {
	            return this.close();
	        }

	        if (this.options.debug || this.options.transactionLog) {
	            this.logger.debug(
	                {
	                    tnx: 'client'
	                },
	                (logStr || str || '').toString().replace(/\r?\n$/, '')
	            );
	        }

	        this._socket.write(Buffer.from(str + '\r\n', 'utf-8'));
	    }

	    /**
	     * Initiates a new message by submitting envelope data, starting with
	     * MAIL FROM: command
	     *
	     * @param {Object} envelope Envelope object in the form of
	     *        {from:'...', to:['...']}
	     *        or
	     *        {from:{address:'...',name:'...'}, to:[address:'...',name:'...']}
	     */
	    _setEnvelope(envelope, callback) {
	        let args = [];
	        let useSmtpUtf8 = false;

	        this._envelope = envelope || {};
	        this._envelope.from = ((this._envelope.from && this._envelope.from.address) || this._envelope.from || '').toString().trim();

	        this._envelope.to = [].concat(this._envelope.to || []).map(to => ((to && to.address) || to || '').toString().trim());

	        if (!this._envelope.to.length) {
	            return callback(this._formatError('No recipients defined', 'EENVELOPE', false, 'API'));
	        }

	        if (this._envelope.from && /[\r\n<>]/.test(this._envelope.from)) {
	            return callback(this._formatError('Invalid sender ' + JSON.stringify(this._envelope.from), 'EENVELOPE', false, 'API'));
	        }

	        // check if the sender address uses only ASCII characters,
	        // otherwise require usage of SMTPUTF8 extension
	        if (/[\x80-\uFFFF]/.test(this._envelope.from)) {
	            useSmtpUtf8 = true;
	        }

	        for (let i = 0, len = this._envelope.to.length; i < len; i++) {
	            if (!this._envelope.to[i] || /[\r\n<>]/.test(this._envelope.to[i])) {
	                return callback(this._formatError('Invalid recipient ' + JSON.stringify(this._envelope.to[i]), 'EENVELOPE', false, 'API'));
	            }

	            // check if the recipients addresses use only ASCII characters,
	            // otherwise require usage of SMTPUTF8 extension
	            if (/[\x80-\uFFFF]/.test(this._envelope.to[i])) {
	                useSmtpUtf8 = true;
	            }
	        }

	        // clone the recipients array for latter manipulation
	        this._envelope.rcptQueue = JSON.parse(JSON.stringify(this._envelope.to || []));
	        this._envelope.rejected = [];
	        this._envelope.rejectedErrors = [];
	        this._envelope.accepted = [];

	        if (this._envelope.dsn) {
	            try {
	                this._envelope.dsn = this._setDsnEnvelope(this._envelope.dsn);
	            } catch (err) {
	                return callback(this._formatError('Invalid DSN ' + err.message, 'EENVELOPE', false, 'API'));
	            }
	        }

	        this._responseActions.push(str => {
	            this._actionMAIL(str, callback);
	        });

	        // If the server supports SMTPUTF8 and the envelope includes an internationalized
	        // email address then append SMTPUTF8 keyword to the MAIL FROM command
	        if (useSmtpUtf8 && this._supportedExtensions.includes('SMTPUTF8')) {
	            args.push('SMTPUTF8');
	            this._usingSmtpUtf8 = true;
	        }

	        // If the server supports 8BITMIME and the message might contain non-ascii bytes
	        // then append the 8BITMIME keyword to the MAIL FROM command
	        if (this._envelope.use8BitMime && this._supportedExtensions.includes('8BITMIME')) {
	            args.push('BODY=8BITMIME');
	            this._using8BitMime = true;
	        }

	        if (this._envelope.size && this._supportedExtensions.includes('SIZE')) {
	            args.push('SIZE=' + this._envelope.size);
	        }

	        // If the server supports DSN and the envelope includes an DSN prop
	        // then append DSN params to the MAIL FROM command
	        if (this._envelope.dsn && this._supportedExtensions.includes('DSN')) {
	            if (this._envelope.dsn.ret) {
	                args.push('RET=' + shared.encodeXText(this._envelope.dsn.ret));
	            }
	            if (this._envelope.dsn.envid) {
	                args.push('ENVID=' + shared.encodeXText(this._envelope.dsn.envid));
	            }
	        }

	        this._sendCommand('MAIL FROM:<' + this._envelope.from + '>' + (args.length ? ' ' + args.join(' ') : ''));
	    }

	    _setDsnEnvelope(params) {
	        let ret = (params.ret || params.return || '').toString().toUpperCase() || null;
	        if (ret) {
	            switch (ret) {
	                case 'HDRS':
	                case 'HEADERS':
	                    ret = 'HDRS';
	                    break;
	                case 'FULL':
	                case 'BODY':
	                    ret = 'FULL';
	                    break;
	            }
	        }

	        if (ret && !['FULL', 'HDRS'].includes(ret)) {
	            throw new Error('ret: ' + JSON.stringify(ret));
	        }

	        let envid = (params.envid || params.id || '').toString() || null;

	        let notify = params.notify || null;
	        if (notify) {
	            if (typeof notify === 'string') {
	                notify = notify.split(',');
	            }
	            notify = notify.map(n => n.trim().toUpperCase());
	            let validNotify = ['NEVER', 'SUCCESS', 'FAILURE', 'DELAY'];
	            let invalidNotify = notify.filter(n => !validNotify.includes(n));
	            if (invalidNotify.length || (notify.length > 1 && notify.includes('NEVER'))) {
	                throw new Error('notify: ' + JSON.stringify(notify.join(',')));
	            }
	            notify = notify.join(',');
	        }

	        let orcpt = (params.recipient || params.orcpt || '').toString() || null;
	        if (orcpt && orcpt.indexOf(';') < 0) {
	            orcpt = 'rfc822;' + orcpt;
	        }

	        return {
	            ret,
	            envid,
	            notify,
	            orcpt
	        };
	    }

	    _getDsnRcptToArgs() {
	        let args = [];
	        // If the server supports DSN and the envelope includes an DSN prop
	        // then append DSN params to the RCPT TO command
	        if (this._envelope.dsn && this._supportedExtensions.includes('DSN')) {
	            if (this._envelope.dsn.notify) {
	                args.push('NOTIFY=' + shared.encodeXText(this._envelope.dsn.notify));
	            }
	            if (this._envelope.dsn.orcpt) {
	                args.push('ORCPT=' + shared.encodeXText(this._envelope.dsn.orcpt));
	            }
	        }
	        return args.length ? ' ' + args.join(' ') : '';
	    }

	    _createSendStream(callback) {
	        let dataStream = new DataStream();
	        let logStream;

	        if (this.options.lmtp) {
	            this._envelope.accepted.forEach((recipient, i) => {
	                let final = i === this._envelope.accepted.length - 1;
	                this._responseActions.push(str => {
	                    this._actionLMTPStream(recipient, final, str, callback);
	                });
	            });
	        } else {
	            this._responseActions.push(str => {
	                this._actionSMTPStream(str, callback);
	            });
	        }

	        dataStream.pipe(this._socket, {
	            end: false
	        });

	        if (this.options.debug) {
	            logStream = new PassThrough();
	            logStream.on('readable', () => {
	                let chunk;
	                while ((chunk = logStream.read())) {
	                    this.logger.debug(
	                        {
	                            tnx: 'message'
	                        },
	                        chunk.toString('binary').replace(/\r?\n$/, '')
	                    );
	                }
	            });
	            dataStream.pipe(logStream);
	        }

	        dataStream.once('end', () => {
	            this.logger.info(
	                {
	                    tnx: 'message',
	                    inByteCount: dataStream.inByteCount,
	                    outByteCount: dataStream.outByteCount
	                },
	                '<%s bytes encoded mime message (source size %s bytes)>',
	                dataStream.outByteCount,
	                dataStream.inByteCount
	            );
	        });

	        return dataStream;
	    }

	    /** ACTIONS **/

	    /**
	     * Will be run after the connection is created and the server sends
	     * a greeting. If the incoming message starts with 220 initiate
	     * SMTP session by sending EHLO command
	     *
	     * @param {String} str Message from the server
	     */
	    _actionGreeting(str) {
	        clearTimeout(this._greetingTimeout);

	        if (str.substr(0, 3) !== '220') {
	            this._onError(new Error('Invalid greeting. response=' + str), 'EPROTOCOL', str, 'CONN');
	            return;
	        }

	        if (this.options.lmtp) {
	            this._responseActions.push(this._actionLHLO);
	            this._sendCommand('LHLO ' + this.name);
	        } else {
	            this._responseActions.push(this._actionEHLO);
	            this._sendCommand('EHLO ' + this.name);
	        }
	    }

	    /**
	     * Handles server response for LHLO command. If it yielded in
	     * error, emit 'error', otherwise treat this as an EHLO response
	     *
	     * @param {String} str Message from the server
	     */
	    _actionLHLO(str) {
	        if (str.charAt(0) !== '2') {
	            this._onError(new Error('Invalid LHLO. response=' + str), 'EPROTOCOL', str, 'LHLO');
	            return;
	        }

	        this._actionEHLO(str);
	    }

	    /**
	     * Handles server response for EHLO command. If it yielded in
	     * error, try HELO instead, otherwise initiate TLS negotiation
	     * if STARTTLS is supported by the server or move into the
	     * authentication phase.
	     *
	     * @param {String} str Message from the server
	     */
	    _actionEHLO(str) {
	        let match;

	        if (str.substr(0, 3) === '421') {
	            this._onError(new Error('Server terminates connection. response=' + str), 'ECONNECTION', str, 'EHLO');
	            return;
	        }

	        if (str.charAt(0) !== '2') {
	            if (this.options.requireTLS) {
	                this._onError(
	                    new Error('EHLO failed but HELO does not support required STARTTLS. response=' + str),
	                    'ECONNECTION',
	                    str,
	                    'EHLO'
	                );
	                return;
	            }

	            // Try HELO instead
	            this._responseActions.push(this._actionHELO);
	            this._sendCommand('HELO ' + this.name);
	            return;
	        }

	        this._ehloLines = str
	            .split(/\r?\n/)
	            .map(line => line.replace(/^\d+[ -]/, '').trim())
	            .filter(line => line)
	            .slice(1);

	        // Detect if the server supports STARTTLS
	        if (!this.secure && !this.options.ignoreTLS && (/[ -]STARTTLS\b/im.test(str) || this.options.requireTLS)) {
	            this._sendCommand('STARTTLS');
	            this._responseActions.push(this._actionSTARTTLS);
	            return;
	        }

	        // Detect if the server supports SMTPUTF8
	        if (/[ -]SMTPUTF8\b/im.test(str)) {
	            this._supportedExtensions.push('SMTPUTF8');
	        }

	        // Detect if the server supports DSN
	        if (/[ -]DSN\b/im.test(str)) {
	            this._supportedExtensions.push('DSN');
	        }

	        // Detect if the server supports 8BITMIME
	        if (/[ -]8BITMIME\b/im.test(str)) {
	            this._supportedExtensions.push('8BITMIME');
	        }

	        // Detect if the server supports PIPELINING
	        if (/[ -]PIPELINING\b/im.test(str)) {
	            this._supportedExtensions.push('PIPELINING');
	        }

	        // Detect if the server supports AUTH
	        if (/[ -]AUTH\b/i.test(str)) {
	            this.allowsAuth = true;
	        }

	        // Detect if the server supports PLAIN auth
	        if (/[ -]AUTH(?:(\s+|=)[^\n]*\s+|\s+|=)PLAIN/i.test(str)) {
	            this._supportedAuth.push('PLAIN');
	        }

	        // Detect if the server supports LOGIN auth
	        if (/[ -]AUTH(?:(\s+|=)[^\n]*\s+|\s+|=)LOGIN/i.test(str)) {
	            this._supportedAuth.push('LOGIN');
	        }

	        // Detect if the server supports CRAM-MD5 auth
	        if (/[ -]AUTH(?:(\s+|=)[^\n]*\s+|\s+|=)CRAM-MD5/i.test(str)) {
	            this._supportedAuth.push('CRAM-MD5');
	        }

	        // Detect if the server supports XOAUTH2 auth
	        if (/[ -]AUTH(?:(\s+|=)[^\n]*\s+|\s+|=)XOAUTH2/i.test(str)) {
	            this._supportedAuth.push('XOAUTH2');
	        }

	        // Detect if the server supports SIZE extensions (and the max allowed size)
	        if ((match = str.match(/[ -]SIZE(?:[ \t]+(\d+))?/im))) {
	            this._supportedExtensions.push('SIZE');
	            this._maxAllowedSize = Number(match[1]) || 0;
	        }

	        this.emit('connect');
	    }

	    /**
	     * Handles server response for HELO command. If it yielded in
	     * error, emit 'error', otherwise move into the authentication phase.
	     *
	     * @param {String} str Message from the server
	     */
	    _actionHELO(str) {
	        if (str.charAt(0) !== '2') {
	            this._onError(new Error('Invalid HELO. response=' + str), 'EPROTOCOL', str, 'HELO');
	            return;
	        }

	        // assume that authentication is enabled (most probably is not though)
	        this.allowsAuth = true;

	        this.emit('connect');
	    }

	    /**
	     * Handles server response for STARTTLS command. If there's an error
	     * try HELO instead, otherwise initiate TLS upgrade. If the upgrade
	     * succeedes restart the EHLO
	     *
	     * @param {String} str Message from the server
	     */
	    _actionSTARTTLS(str) {
	        if (str.charAt(0) !== '2') {
	            if (this.options.opportunisticTLS) {
	                this.logger.info(
	                    {
	                        tnx: 'smtp'
	                    },
	                    'Failed STARTTLS upgrade, continuing unencrypted'
	                );
	                return this.emit('connect');
	            }
	            this._onError(new Error('Error upgrading connection with STARTTLS'), 'ETLS', str, 'STARTTLS');
	            return;
	        }

	        this._upgradeConnection((err, secured) => {
	            if (err) {
	                this._onError(new Error('Error initiating TLS - ' + (err.message || err)), 'ETLS', false, 'STARTTLS');
	                return;
	            }

	            this.logger.info(
	                {
	                    tnx: 'smtp'
	                },
	                'Connection upgraded with STARTTLS'
	            );

	            if (secured) {
	                // restart session
	                if (this.options.lmtp) {
	                    this._responseActions.push(this._actionLHLO);
	                    this._sendCommand('LHLO ' + this.name);
	                } else {
	                    this._responseActions.push(this._actionEHLO);
	                    this._sendCommand('EHLO ' + this.name);
	                }
	            } else {
	                this.emit('connect');
	            }
	        });
	    }

	    /**
	     * Handle the response for AUTH LOGIN command. We are expecting
	     * '334 VXNlcm5hbWU6' (base64 for 'Username:'). Data to be sent as
	     * response needs to be base64 encoded username. We do not need
	     * exact match but settle with 334 response in general as some
	     * hosts invalidly use a longer message than VXNlcm5hbWU6
	     *
	     * @param {String} str Message from the server
	     */
	    _actionAUTH_LOGIN_USER(str, callback) {
	        if (!/^334[ -]/.test(str)) {
	            // expecting '334 VXNlcm5hbWU6'
	            callback(this._formatError('Invalid login sequence while waiting for "334 VXNlcm5hbWU6"', 'EAUTH', str, 'AUTH LOGIN'));
	            return;
	        }

	        this._responseActions.push(str => {
	            this._actionAUTH_LOGIN_PASS(str, callback);
	        });

	        this._sendCommand(Buffer.from(this._auth.credentials.user + '', 'utf-8').toString('base64'));
	    }

	    /**
	     * Handle the response for AUTH CRAM-MD5 command. We are expecting
	     * '334 <challenge string>'. Data to be sent as response needs to be
	     * base64 decoded challenge string, MD5 hashed using the password as
	     * a HMAC key, prefixed by the username and a space, and finally all
	     * base64 encoded again.
	     *
	     * @param {String} str Message from the server
	     */
	    _actionAUTH_CRAM_MD5(str, callback) {
	        let challengeMatch = str.match(/^334\s+(.+)$/);
	        let challengeString = '';

	        if (!challengeMatch) {
	            return callback(
	                this._formatError('Invalid login sequence while waiting for server challenge string', 'EAUTH', str, 'AUTH CRAM-MD5')
	            );
	        } else {
	            challengeString = challengeMatch[1];
	        }

	        // Decode from base64
	        let base64decoded = Buffer.from(challengeString, 'base64').toString('ascii'),
	            hmacMD5 = crypto.createHmac('md5', this._auth.credentials.pass);

	        hmacMD5.update(base64decoded);

	        let prepended = this._auth.credentials.user + ' ' + hmacMD5.digest('hex');

	        this._responseActions.push(str => {
	            this._actionAUTH_CRAM_MD5_PASS(str, callback);
	        });

	        this._sendCommand(
	            Buffer.from(prepended).toString('base64'),
	            // hidden hash for logs
	            Buffer.from(this._auth.credentials.user + ' /* secret */').toString('base64')
	        );
	    }

	    /**
	     * Handles the response to CRAM-MD5 authentication, if there's no error,
	     * the user can be considered logged in. Start waiting for a message to send
	     *
	     * @param {String} str Message from the server
	     */
	    _actionAUTH_CRAM_MD5_PASS(str, callback) {
	        if (!str.match(/^235\s+/)) {
	            return callback(this._formatError('Invalid login sequence while waiting for "235"', 'EAUTH', str, 'AUTH CRAM-MD5'));
	        }

	        this.logger.info(
	            {
	                tnx: 'smtp',
	                username: this._auth.user,
	                action: 'authenticated',
	                method: this._authMethod
	            },
	            'User %s authenticated',
	            JSON.stringify(this._auth.user)
	        );
	        this.authenticated = true;
	        callback(null, true);
	    }

	    /**
	     * Handle the response for AUTH LOGIN command. We are expecting
	     * '334 UGFzc3dvcmQ6' (base64 for 'Password:'). Data to be sent as
	     * response needs to be base64 encoded password.
	     *
	     * @param {String} str Message from the server
	     */
	    _actionAUTH_LOGIN_PASS(str, callback) {
	        if (!/^334[ -]/.test(str)) {
	            // expecting '334 UGFzc3dvcmQ6'
	            return callback(this._formatError('Invalid login sequence while waiting for "334 UGFzc3dvcmQ6"', 'EAUTH', str, 'AUTH LOGIN'));
	        }

	        this._responseActions.push(str => {
	            this._actionAUTHComplete(str, callback);
	        });

	        this._sendCommand(
	            Buffer.from((this._auth.credentials.pass || '').toString(), 'utf-8').toString('base64'),
	            // Hidden pass for logs
	            Buffer.from('/* secret */', 'utf-8').toString('base64')
	        );
	    }

	    /**
	     * Handles the response for authentication, if there's no error,
	     * the user can be considered logged in. Start waiting for a message to send
	     *
	     * @param {String} str Message from the server
	     */
	    _actionAUTHComplete(str, isRetry, callback) {
	        if (!callback && typeof isRetry === 'function') {
	            callback = isRetry;
	            isRetry = false;
	        }

	        if (str.substr(0, 3) === '334') {
	            this._responseActions.push(str => {
	                if (isRetry || this._authMethod !== 'XOAUTH2') {
	                    this._actionAUTHComplete(str, true, callback);
	                } else {
	                    // fetch a new OAuth2 access token
	                    setImmediate(() => this._handleXOauth2Token(true, callback));
	                }
	            });
	            this._sendCommand('');
	            return;
	        }

	        if (str.charAt(0) !== '2') {
	            this.logger.info(
	                {
	                    tnx: 'smtp',
	                    username: this._auth.user,
	                    action: 'authfail',
	                    method: this._authMethod
	                },
	                'User %s failed to authenticate',
	                JSON.stringify(this._auth.user)
	            );
	            return callback(this._formatError('Invalid login', 'EAUTH', str, 'AUTH ' + this._authMethod));
	        }

	        this.logger.info(
	            {
	                tnx: 'smtp',
	                username: this._auth.user,
	                action: 'authenticated',
	                method: this._authMethod
	            },
	            'User %s authenticated',
	            JSON.stringify(this._auth.user)
	        );
	        this.authenticated = true;
	        callback(null, true);
	    }

	    /**
	     * Handle response for a MAIL FROM: command
	     *
	     * @param {String} str Message from the server
	     */
	    _actionMAIL(str, callback) {
	        let message, curRecipient;
	        if (Number(str.charAt(0)) !== 2) {
	            if (this._usingSmtpUtf8 && /^550 /.test(str) && /[\x80-\uFFFF]/.test(this._envelope.from)) {
	                message = 'Internationalized mailbox name not allowed';
	            } else {
	                message = 'Mail command failed';
	            }
	            return callback(this._formatError(message, 'EENVELOPE', str, 'MAIL FROM'));
	        }

	        if (!this._envelope.rcptQueue.length) {
	            return callback(this._formatError("Can't send mail - no recipients defined", 'EENVELOPE', false, 'API'));
	        } else {
	            this._recipientQueue = [];

	            if (this._supportedExtensions.includes('PIPELINING')) {
	                while (this._envelope.rcptQueue.length) {
	                    curRecipient = this._envelope.rcptQueue.shift();
	                    this._recipientQueue.push(curRecipient);
	                    this._responseActions.push(str => {
	                        this._actionRCPT(str, callback);
	                    });
	                    this._sendCommand('RCPT TO:<' + curRecipient + '>' + this._getDsnRcptToArgs());
	                }
	            } else {
	                curRecipient = this._envelope.rcptQueue.shift();
	                this._recipientQueue.push(curRecipient);
	                this._responseActions.push(str => {
	                    this._actionRCPT(str, callback);
	                });
	                this._sendCommand('RCPT TO:<' + curRecipient + '>' + this._getDsnRcptToArgs());
	            }
	        }
	    }

	    /**
	     * Handle response for a RCPT TO: command
	     *
	     * @param {String} str Message from the server
	     */
	    _actionRCPT(str, callback) {
	        let message,
	            err,
	            curRecipient = this._recipientQueue.shift();
	        if (Number(str.charAt(0)) !== 2) {
	            // this is a soft error
	            if (this._usingSmtpUtf8 && /^553 /.test(str) && /[\x80-\uFFFF]/.test(curRecipient)) {
	                message = 'Internationalized mailbox name not allowed';
	            } else {
	                message = 'Recipient command failed';
	            }
	            this._envelope.rejected.push(curRecipient);
	            // store error for the failed recipient
	            err = this._formatError(message, 'EENVELOPE', str, 'RCPT TO');
	            err.recipient = curRecipient;
	            this._envelope.rejectedErrors.push(err);
	        } else {
	            this._envelope.accepted.push(curRecipient);
	        }

	        if (!this._envelope.rcptQueue.length && !this._recipientQueue.length) {
	            if (this._envelope.rejected.length < this._envelope.to.length) {
	                this._responseActions.push(str => {
	                    this._actionDATA(str, callback);
	                });
	                this._sendCommand('DATA');
	            } else {
	                err = this._formatError("Can't send mail - all recipients were rejected", 'EENVELOPE', str, 'RCPT TO');
	                err.rejected = this._envelope.rejected;
	                err.rejectedErrors = this._envelope.rejectedErrors;
	                return callback(err);
	            }
	        } else if (this._envelope.rcptQueue.length) {
	            curRecipient = this._envelope.rcptQueue.shift();
	            this._recipientQueue.push(curRecipient);
	            this._responseActions.push(str => {
	                this._actionRCPT(str, callback);
	            });
	            this._sendCommand('RCPT TO:<' + curRecipient + '>' + this._getDsnRcptToArgs());
	        }
	    }

	    /**
	     * Handle response for a DATA command
	     *
	     * @param {String} str Message from the server
	     */
	    _actionDATA(str, callback) {
	        // response should be 354 but according to this issue https://github.com/eleith/emailjs/issues/24
	        // some servers might use 250 instead, so lets check for 2 or 3 as the first digit
	        if (!/^[23]/.test(str)) {
	            return callback(this._formatError('Data command failed', 'EENVELOPE', str, 'DATA'));
	        }

	        let response = {
	            accepted: this._envelope.accepted,
	            rejected: this._envelope.rejected
	        };

	        if (this._ehloLines && this._ehloLines.length) {
	            response.ehlo = this._ehloLines;
	        }

	        if (this._envelope.rejectedErrors.length) {
	            response.rejectedErrors = this._envelope.rejectedErrors;
	        }

	        callback(null, response);
	    }

	    /**
	     * Handle response for a DATA stream when using SMTP
	     * We expect a single response that defines if the sending succeeded or failed
	     *
	     * @param {String} str Message from the server
	     */
	    _actionSMTPStream(str, callback) {
	        if (Number(str.charAt(0)) !== 2) {
	            // Message failed
	            return callback(this._formatError('Message failed', 'EMESSAGE', str, 'DATA'));
	        } else {
	            // Message sent succesfully
	            return callback(null, str);
	        }
	    }

	    /**
	     * Handle response for a DATA stream
	     * We expect a separate response for every recipient. All recipients can either
	     * succeed or fail separately
	     *
	     * @param {String} recipient The recipient this response applies to
	     * @param {Boolean} final Is this the final recipient?
	     * @param {String} str Message from the server
	     */
	    _actionLMTPStream(recipient, final, str, callback) {
	        let err;
	        if (Number(str.charAt(0)) !== 2) {
	            // Message failed
	            err = this._formatError('Message failed for recipient ' + recipient, 'EMESSAGE', str, 'DATA');
	            err.recipient = recipient;
	            this._envelope.rejected.push(recipient);
	            this._envelope.rejectedErrors.push(err);
	            for (let i = 0, len = this._envelope.accepted.length; i < len; i++) {
	                if (this._envelope.accepted[i] === recipient) {
	                    this._envelope.accepted.splice(i, 1);
	                }
	            }
	        }
	        if (final) {
	            return callback(null, str);
	        }
	    }

	    _handleXOauth2Token(isRetry, callback) {
	        this._auth.oauth2.getToken(isRetry, (err, accessToken) => {
	            if (err) {
	                this.logger.info(
	                    {
	                        tnx: 'smtp',
	                        username: this._auth.user,
	                        action: 'authfail',
	                        method: this._authMethod
	                    },
	                    'User %s failed to authenticate',
	                    JSON.stringify(this._auth.user)
	                );
	                return callback(this._formatError(err, 'EAUTH', false, 'AUTH XOAUTH2'));
	            }
	            this._responseActions.push(str => {
	                this._actionAUTHComplete(str, isRetry, callback);
	            });
	            this._sendCommand(
	                'AUTH XOAUTH2 ' + this._auth.oauth2.buildXOAuth2Token(accessToken),
	                //  Hidden for logs
	                'AUTH XOAUTH2 ' + this._auth.oauth2.buildXOAuth2Token('/* secret */')
	            );
	        });
	    }

	    /**
	     *
	     * @param {string} command
	     * @private
	     */
	    _isDestroyedMessage(command) {
	        if (this._destroyed) {
	            return 'Cannot ' + command + ' - smtp connection is already destroyed.';
	        }

	        if (this._socket) {
	            if (this._socket.destroyed) {
	                return 'Cannot ' + command + ' - smtp connection socket is already destroyed.';
	            }

	            if (!this._socket.writable) {
	                return 'Cannot ' + command + ' - smtp connection socket is already half-closed.';
	            }
	        }
	    }

	    _getHostname() {
	        // defaul hostname is machine hostname or [IP]
	        let defaultHostname;
	        try {
	            defaultHostname = os$1.hostname() || '';
	        } catch (_err) {
	            // fails on windows 7
	            defaultHostname = 'localhost';
	        }

	        // ignore if not FQDN
	        if (!defaultHostname || defaultHostname.indexOf('.') < 0) {
	            defaultHostname = '[127.0.0.1]';
	        }

	        // IP should be enclosed in []
	        if (defaultHostname.match(/^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$/)) {
	            defaultHostname = '[' + defaultHostname + ']';
	        }

	        return defaultHostname;
	    }
	}

	smtpConnection = SMTPConnection;
	return smtpConnection;
}

var xoauth2;
var hasRequiredXoauth2;

function requireXoauth2 () {
	if (hasRequiredXoauth2) return xoauth2;
	hasRequiredXoauth2 = 1;

	const Stream = require$$0$2.Stream;
	const nmfetch = requireFetch();
	const crypto = crypto$1;
	const shared = requireShared();

	/**
	 * XOAUTH2 access_token generator for Gmail.
	 * Create client ID for web applications in Google API console to use it.
	 * See Offline Access for receiving the needed refreshToken for an user
	 * https://developers.google.com/accounts/docs/OAuth2WebServer#offline
	 *
	 * Usage for generating access tokens with a custom method using provisionCallback:
	 * provisionCallback(user, renew, callback)
	 *   * user is the username to get the token for
	 *   * renew is a boolean that if true indicates that existing token failed and needs to be renewed
	 *   * callback is the callback to run with (error, accessToken [, expires])
	 *     * accessToken is a string
	 *     * expires is an optional expire time in milliseconds
	 * If provisionCallback is used, then Nodemailer does not try to attempt generating the token by itself
	 *
	 * @constructor
	 * @param {Object} options Client information for token generation
	 * @param {String} options.user User e-mail address
	 * @param {String} options.clientId Client ID value
	 * @param {String} options.clientSecret Client secret value
	 * @param {String} options.refreshToken Refresh token for an user
	 * @param {String} options.accessUrl Endpoint for token generation, defaults to 'https://accounts.google.com/o/oauth2/token'
	 * @param {String} options.accessToken An existing valid accessToken
	 * @param {String} options.privateKey Private key for JSW
	 * @param {Number} options.expires Optional Access Token expire time in ms
	 * @param {Number} options.timeout Optional TTL for Access Token in seconds
	 * @param {Function} options.provisionCallback Function to run when a new access token is required
	 */
	class XOAuth2 extends Stream {
	    constructor(options, logger) {
	        super();

	        this.options = options || {};

	        if (options && options.serviceClient) {
	            if (!options.privateKey || !options.user) {
	                setImmediate(() => this.emit('error', new Error('Options "privateKey" and "user" are required for service account!')));
	                return;
	            }

	            let serviceRequestTimeout = Math.min(Math.max(Number(this.options.serviceRequestTimeout) || 0, 0), 3600);
	            this.options.serviceRequestTimeout = serviceRequestTimeout || 5 * 60;
	        }

	        this.logger = shared.getLogger(
	            {
	                logger
	            },
	            {
	                component: this.options.component || 'OAuth2'
	            }
	        );

	        this.provisionCallback = typeof this.options.provisionCallback === 'function' ? this.options.provisionCallback : false;

	        this.options.accessUrl = this.options.accessUrl || 'https://accounts.google.com/o/oauth2/token';
	        this.options.customHeaders = this.options.customHeaders || {};
	        this.options.customParams = this.options.customParams || {};

	        this.accessToken = this.options.accessToken || false;

	        if (this.options.expires && Number(this.options.expires)) {
	            this.expires = this.options.expires;
	        } else {
	            let timeout = Math.max(Number(this.options.timeout) || 0, 0);
	            this.expires = (timeout && Date.now() + timeout * 1000) || 0;
	        }

	        this.renewing = false; // Track if renewal is in progress
	        this.renewalQueue = []; // Queue for pending requests during renewal
	    }

	    /**
	     * Returns or generates (if previous has expired) a XOAuth2 token
	     *
	     * @param {Boolean} renew If false then use cached access token (if available)
	     * @param {Function} callback Callback function with error object and token string
	     */
	    getToken(renew, callback) {
	        if (!renew && this.accessToken && (!this.expires || this.expires > Date.now())) {
	            this.logger.debug(
	                {
	                    tnx: 'OAUTH2',
	                    user: this.options.user,
	                    action: 'reuse'
	                },
	                'Reusing existing access token for %s',
	                this.options.user
	            );
	            return callback(null, this.accessToken);
	        }

	        // check if it is possible to renew, if not, return the current token or error
	        if (!this.provisionCallback && !this.options.refreshToken && !this.options.serviceClient) {
	            if (this.accessToken) {
	                this.logger.debug(
	                    {
	                        tnx: 'OAUTH2',
	                        user: this.options.user,
	                        action: 'reuse'
	                    },
	                    'Reusing existing access token (no refresh capability) for %s',
	                    this.options.user
	                );
	                return callback(null, this.accessToken);
	            }
	            this.logger.error(
	                {
	                    tnx: 'OAUTH2',
	                    user: this.options.user,
	                    action: 'renew'
	                },
	                'Cannot renew access token for %s: No refresh mechanism available',
	                this.options.user
	            );
	            return callback(new Error("Can't create new access token for user"));
	        }

	        // If renewal already in progress, queue this request instead of starting another
	        if (this.renewing) {
	            return this.renewalQueue.push({ renew, callback });
	        }

	        this.renewing = true;

	        // Handles token renewal completion - processes queued requests and cleans up
	        const generateCallback = (err, accessToken) => {
	            this.renewalQueue.forEach(item => item.callback(err, accessToken));
	            this.renewalQueue = [];
	            this.renewing = false;

	            if (err) {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'OAUTH2',
	                        user: this.options.user,
	                        action: 'renew'
	                    },
	                    'Failed generating new Access Token for %s',
	                    this.options.user
	                );
	            } else {
	                this.logger.info(
	                    {
	                        tnx: 'OAUTH2',
	                        user: this.options.user,
	                        action: 'renew'
	                    },
	                    'Generated new Access Token for %s',
	                    this.options.user
	                );
	            }
	            // Complete original request
	            callback(err, accessToken);
	        };

	        if (this.provisionCallback) {
	            this.provisionCallback(this.options.user, !!renew, (err, accessToken, expires) => {
	                if (!err && accessToken) {
	                    this.accessToken = accessToken;
	                    this.expires = expires || 0;
	                }
	                generateCallback(err, accessToken);
	            });
	        } else {
	            this.generateToken(generateCallback);
	        }
	    }

	    /**
	     * Updates token values
	     *
	     * @param {String} accessToken New access token
	     * @param {Number} timeout Access token lifetime in seconds
	     *
	     * Emits 'token': { user: User email-address, accessToken: the new accessToken, timeout: TTL in seconds}
	     */
	    updateToken(accessToken, timeout) {
	        this.accessToken = accessToken;
	        timeout = Math.max(Number(timeout) || 0, 0);
	        this.expires = (timeout && Date.now() + timeout * 1000) || 0;

	        this.emit('token', {
	            user: this.options.user,
	            accessToken: accessToken || '',
	            expires: this.expires
	        });
	    }

	    /**
	     * Generates a new XOAuth2 token with the credentials provided at initialization
	     *
	     * @param {Function} callback Callback function with error object and token string
	     */
	    generateToken(callback) {
	        let urlOptions;
	        let loggedUrlOptions;
	        if (this.options.serviceClient) {
	            // service account - https://developers.google.com/identity/protocols/OAuth2ServiceAccount
	            let iat = Math.floor(Date.now() / 1000); // unix time
	            let tokenData = {
	                iss: this.options.serviceClient,
	                scope: this.options.scope || 'https://mail.google.com/',
	                sub: this.options.user,
	                aud: this.options.accessUrl,
	                iat,
	                exp: iat + this.options.serviceRequestTimeout
	            };
	            let token;
	            try {
	                token = this.jwtSignRS256(tokenData);
	            } catch (_err) {
	                return callback(new Error("Can't generate token. Check your auth options"));
	            }

	            urlOptions = {
	                grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',
	                assertion: token
	            };

	            loggedUrlOptions = {
	                grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',
	                assertion: tokenData
	            };
	        } else {
	            if (!this.options.refreshToken) {
	                return callback(new Error("Can't create new access token for user"));
	            }

	            // web app - https://developers.google.com/identity/protocols/OAuth2WebServer
	            urlOptions = {
	                client_id: this.options.clientId || '',
	                client_secret: this.options.clientSecret || '',
	                refresh_token: this.options.refreshToken,
	                grant_type: 'refresh_token'
	            };

	            loggedUrlOptions = {
	                client_id: this.options.clientId || '',
	                client_secret: (this.options.clientSecret || '').substr(0, 6) + '...',
	                refresh_token: (this.options.refreshToken || '').substr(0, 6) + '...',
	                grant_type: 'refresh_token'
	            };
	        }

	        Object.keys(this.options.customParams).forEach(key => {
	            urlOptions[key] = this.options.customParams[key];
	            loggedUrlOptions[key] = this.options.customParams[key];
	        });

	        this.logger.debug(
	            {
	                tnx: 'OAUTH2',
	                user: this.options.user,
	                action: 'generate'
	            },
	            'Requesting token using: %s',
	            JSON.stringify(loggedUrlOptions)
	        );

	        this.postRequest(this.options.accessUrl, urlOptions, this.options, (error, body) => {
	            let data;

	            if (error) {
	                return callback(error);
	            }

	            try {
	                data = JSON.parse(body.toString());
	            } catch (E) {
	                return callback(E);
	            }

	            if (!data || typeof data !== 'object') {
	                this.logger.debug(
	                    {
	                        tnx: 'OAUTH2',
	                        user: this.options.user,
	                        action: 'post'
	                    },
	                    'Response: %s',
	                    (body || '').toString()
	                );
	                return callback(new Error('Invalid authentication response'));
	            }

	            let logData = {};
	            Object.keys(data).forEach(key => {
	                if (key !== 'access_token') {
	                    logData[key] = data[key];
	                } else {
	                    logData[key] = (data[key] || '').toString().substr(0, 6) + '...';
	                }
	            });

	            this.logger.debug(
	                {
	                    tnx: 'OAUTH2',
	                    user: this.options.user,
	                    action: 'post'
	                },
	                'Response: %s',
	                JSON.stringify(logData)
	            );

	            if (data.error) {
	                // Error Response : https://tools.ietf.org/html/rfc6749#section-5.2
	                let errorMessage = data.error;
	                if (data.error_description) {
	                    errorMessage += ': ' + data.error_description;
	                }
	                if (data.error_uri) {
	                    errorMessage += ' (' + data.error_uri + ')';
	                }
	                return callback(new Error(errorMessage));
	            }

	            if (data.access_token) {
	                this.updateToken(data.access_token, data.expires_in);
	                return callback(null, this.accessToken);
	            }

	            return callback(new Error('No access token'));
	        });
	    }

	    /**
	     * Converts an access_token and user id into a base64 encoded XOAuth2 token
	     *
	     * @param {String} [accessToken] Access token string
	     * @return {String} Base64 encoded token for IMAP or SMTP login
	     */
	    buildXOAuth2Token(accessToken) {
	        let authData = ['user=' + (this.options.user || ''), 'auth=Bearer ' + (accessToken || this.accessToken), '', ''];
	        return Buffer.from(authData.join('\x01'), 'utf-8').toString('base64');
	    }

	    /**
	     * Custom POST request handler.
	     * This is only needed to keep paths short in Windows – usually this module
	     * is a dependency of a dependency and if it tries to require something
	     * like the request module the paths get way too long to handle for Windows.
	     * As we do only a simple POST request we do not actually require complicated
	     * logic support (no redirects, no nothing) anyway.
	     *
	     * @param {String} url Url to POST to
	     * @param {String|Buffer} payload Payload to POST
	     * @param {Function} callback Callback function with (err, buff)
	     */
	    postRequest(url, payload, params, callback) {
	        let returned = false;

	        let chunks = [];
	        let chunklen = 0;

	        let req = nmfetch(url, {
	            method: 'post',
	            headers: params.customHeaders,
	            body: payload,
	            allowErrorResponse: true
	        });

	        req.on('readable', () => {
	            let chunk;
	            while ((chunk = req.read()) !== null) {
	                chunks.push(chunk);
	                chunklen += chunk.length;
	            }
	        });

	        req.once('error', err => {
	            if (returned) {
	                return;
	            }
	            returned = true;
	            return callback(err);
	        });

	        req.once('end', () => {
	            if (returned) {
	                return;
	            }
	            returned = true;
	            return callback(null, Buffer.concat(chunks, chunklen));
	        });
	    }

	    /**
	     * Encodes a buffer or a string into Base64url format
	     *
	     * @param {Buffer|String} data The data to convert
	     * @return {String} The encoded string
	     */
	    toBase64URL(data) {
	        if (typeof data === 'string') {
	            data = Buffer.from(data);
	        }

	        return data
	            .toString('base64')
	            .replace(/[=]+/g, '') // remove '='s
	            .replace(/\+/g, '-') // '+' → '-'
	            .replace(/\//g, '_'); // '/' → '_'
	    }

	    /**
	     * Creates a JSON Web Token signed with RS256 (SHA256 + RSA)
	     *
	     * @param {Object} payload The payload to include in the generated token
	     * @return {String} The generated and signed token
	     */
	    jwtSignRS256(payload) {
	        payload = ['{"alg":"RS256","typ":"JWT"}', JSON.stringify(payload)].map(val => this.toBase64URL(val)).join('.');
	        let signature = crypto.createSign('RSA-SHA256').update(payload).sign(this.options.privateKey);
	        return payload + '.' + this.toBase64URL(signature);
	    }
	}

	xoauth2 = XOAuth2;
	return xoauth2;
}

var poolResource;
var hasRequiredPoolResource;

function requirePoolResource () {
	if (hasRequiredPoolResource) return poolResource;
	hasRequiredPoolResource = 1;

	const SMTPConnection = requireSmtpConnection();
	const assign = requireShared().assign;
	const XOAuth2 = requireXoauth2();
	const EventEmitter$1 = EventEmitter;

	/**
	 * Creates an element for the pool
	 *
	 * @constructor
	 * @param {Object} options SMTPPool instance
	 */
	class PoolResource extends EventEmitter$1 {
	    constructor(pool) {
	        super();

	        this.pool = pool;
	        this.options = pool.options;
	        this.logger = this.pool.logger;

	        if (this.options.auth) {
	            switch ((this.options.auth.type || '').toString().toUpperCase()) {
	                case 'OAUTH2': {
	                    let oauth2 = new XOAuth2(this.options.auth, this.logger);
	                    oauth2.provisionCallback =
	                        (this.pool.mailer && this.pool.mailer.get('oauth2_provision_cb')) || oauth2.provisionCallback;
	                    this.auth = {
	                        type: 'OAUTH2',
	                        user: this.options.auth.user,
	                        oauth2,
	                        method: 'XOAUTH2'
	                    };
	                    oauth2.on('token', token => this.pool.mailer.emit('token', token));
	                    oauth2.on('error', err => this.emit('error', err));
	                    break;
	                }
	                default:
	                    if (!this.options.auth.user && !this.options.auth.pass) {
	                        break;
	                    }
	                    this.auth = {
	                        type: (this.options.auth.type || '').toString().toUpperCase() || 'LOGIN',
	                        user: this.options.auth.user,
	                        credentials: {
	                            user: this.options.auth.user || '',
	                            pass: this.options.auth.pass,
	                            options: this.options.auth.options
	                        },
	                        method: (this.options.auth.method || '').trim().toUpperCase() || this.options.authMethod || false
	                    };
	            }
	        }

	        this._connection = false;
	        this._connected = false;

	        this.messages = 0;
	        this.available = true;
	    }

	    /**
	     * Initiates a connection to the SMTP server
	     *
	     * @param {Function} callback Callback function to run once the connection is established or failed
	     */
	    connect(callback) {
	        this.pool.getSocket(this.options, (err, socketOptions) => {
	            if (err) {
	                return callback(err);
	            }

	            let returned = false;
	            let options = this.options;
	            if (socketOptions && socketOptions.connection) {
	                this.logger.info(
	                    {
	                        tnx: 'proxy',
	                        remoteAddress: socketOptions.connection.remoteAddress,
	                        remotePort: socketOptions.connection.remotePort,
	                        destHost: options.host || '',
	                        destPort: options.port || '',
	                        action: 'connected'
	                    },
	                    'Using proxied socket from %s:%s to %s:%s',
	                    socketOptions.connection.remoteAddress,
	                    socketOptions.connection.remotePort,
	                    options.host || '',
	                    options.port || ''
	                );

	                options = assign(false, options);
	                Object.keys(socketOptions).forEach(key => {
	                    options[key] = socketOptions[key];
	                });
	            }

	            this.connection = new SMTPConnection(options);

	            this.connection.once('error', err => {
	                this.emit('error', err);
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                return callback(err);
	            });

	            this.connection.once('end', () => {
	                this.close();
	                if (returned) {
	                    return;
	                }
	                returned = true;

	                let timer = setTimeout(() => {
	                    if (returned) {
	                        return;
	                    }
	                    // still have not returned, this means we have an unexpected connection close
	                    let err = new Error('Unexpected socket close');
	                    if (this.connection && this.connection._socket && this.connection._socket.upgrading) {
	                        // starttls connection errors
	                        err.code = 'ETLS';
	                    }
	                    callback(err);
	                }, 1000);

	                try {
	                    timer.unref();
	                } catch (_E) {
	                    // Ignore. Happens on envs with non-node timer implementation
	                }
	            });

	            this.connection.connect(() => {
	                if (returned) {
	                    return;
	                }

	                if (this.auth && (this.connection.allowsAuth || options.forceAuth)) {
	                    this.connection.login(this.auth, err => {
	                        if (returned) {
	                            return;
	                        }
	                        returned = true;

	                        if (err) {
	                            this.connection.close();
	                            this.emit('error', err);
	                            return callback(err);
	                        }

	                        this._connected = true;
	                        callback(null, true);
	                    });
	                } else {
	                    returned = true;
	                    this._connected = true;
	                    return callback(null, true);
	                }
	            });
	        });
	    }

	    /**
	     * Sends an e-mail to be sent using the selected settings
	     *
	     * @param {Object} mail Mail object
	     * @param {Function} callback Callback function
	     */
	    send(mail, callback) {
	        if (!this._connected) {
	            return this.connect(err => {
	                if (err) {
	                    return callback(err);
	                }
	                return this.send(mail, callback);
	            });
	        }

	        let envelope = mail.message.getEnvelope();
	        let messageId = mail.message.messageId();

	        let recipients = [].concat(envelope.to || []);
	        if (recipients.length > 3) {
	            recipients.push('...and ' + recipients.splice(2).length + ' more');
	        }
	        this.logger.info(
	            {
	                tnx: 'send',
	                messageId,
	                cid: this.id
	            },
	            'Sending message %s using #%s to <%s>',
	            messageId,
	            this.id,
	            recipients.join(', ')
	        );

	        if (mail.data.dsn) {
	            envelope.dsn = mail.data.dsn;
	        }

	        this.connection.send(envelope, mail.message.createReadStream(), (err, info) => {
	            this.messages++;

	            if (err) {
	                this.connection.close();
	                this.emit('error', err);
	                return callback(err);
	            }

	            info.envelope = {
	                from: envelope.from,
	                to: envelope.to
	            };
	            info.messageId = messageId;

	            setImmediate(() => {
	                let err;
	                if (this.messages >= this.options.maxMessages) {
	                    err = new Error('Resource exhausted');
	                    err.code = 'EMAXLIMIT';
	                    this.connection.close();
	                    this.emit('error', err);
	                } else {
	                    this.pool._checkRateLimit(() => {
	                        this.available = true;
	                        this.emit('available');
	                    });
	                }
	            });

	            callback(null, info);
	        });
	    }

	    /**
	     * Closes the connection
	     */
	    close() {
	        this._connected = false;
	        if (this.auth && this.auth.oauth2) {
	            this.auth.oauth2.removeAllListeners();
	        }
	        if (this.connection) {
	            this.connection.close();
	        }
	        this.emit('close');
	    }
	}

	poolResource = PoolResource;
	return poolResource;
}

var Aliyun = {
	description: "Alibaba Cloud Mail",
	domains: [
		"aliyun.com"
	],
	host: "smtp.aliyun.com",
	port: 465,
	secure: true
};
var AliyunQiye = {
	description: "Alibaba Cloud Enterprise Mail",
	host: "smtp.qiye.aliyun.com",
	port: 465,
	secure: true
};
var AOL = {
	description: "AOL Mail",
	domains: [
		"aol.com"
	],
	host: "smtp.aol.com",
	port: 587
};
var Aruba = {
	description: "Aruba PEC (Italian email provider)",
	domains: [
		"aruba.it",
		"pec.aruba.it"
	],
	aliases: [
		"Aruba PEC"
	],
	host: "smtps.aruba.it",
	port: 465,
	secure: true,
	authMethod: "LOGIN"
};
var Bluewin = {
	description: "Bluewin (Swiss email provider)",
	host: "smtpauths.bluewin.ch",
	domains: [
		"bluewin.ch"
	],
	port: 465
};
var BOL = {
	description: "BOL Mail (Brazilian provider)",
	domains: [
		"bol.com.br"
	],
	host: "smtp.bol.com.br",
	port: 587,
	requireTLS: true
};
var DebugMail = {
	description: "DebugMail (email testing service)",
	host: "debugmail.io",
	port: 25
};
var Disroot = {
	description: "Disroot (privacy-focused provider)",
	domains: [
		"disroot.org"
	],
	host: "disroot.org",
	port: 587,
	secure: false,
	authMethod: "LOGIN"
};
var DynectEmail = {
	description: "Dyn Email Delivery",
	aliases: [
		"Dynect"
	],
	host: "smtp.dynect.net",
	port: 25
};
var ElasticEmail = {
	description: "Elastic Email",
	aliases: [
		"Elastic Email"
	],
	host: "smtp.elasticemail.com",
	port: 465,
	secure: true
};
var Ethereal = {
	description: "Ethereal Email (email testing service)",
	aliases: [
		"ethereal.email"
	],
	host: "smtp.ethereal.email",
	port: 587
};
var FastMail = {
	description: "FastMail",
	domains: [
		"fastmail.fm"
	],
	host: "smtp.fastmail.com",
	port: 465,
	secure: true
};
var GandiMail = {
	description: "Gandi Mail",
	aliases: [
		"Gandi",
		"Gandi Mail"
	],
	host: "mail.gandi.net",
	port: 587
};
var Gmail = {
	description: "Gmail",
	aliases: [
		"Google Mail"
	],
	domains: [
		"gmail.com",
		"googlemail.com"
	],
	host: "smtp.gmail.com",
	port: 465,
	secure: true
};
var GMX = {
	description: "GMX Mail",
	domains: [
		"gmx.com",
		"gmx.net",
		"gmx.de"
	],
	host: "mail.gmx.com",
	port: 587
};
var Godaddy = {
	description: "GoDaddy Email (US)",
	host: "smtpout.secureserver.net",
	port: 25
};
var GodaddyAsia = {
	description: "GoDaddy Email (Asia)",
	host: "smtp.asia.secureserver.net",
	port: 25
};
var GodaddyEurope = {
	description: "GoDaddy Email (Europe)",
	host: "smtp.europe.secureserver.net",
	port: 25
};
var Hotmail = {
	description: "Outlook.com / Hotmail",
	aliases: [
		"Outlook",
		"Outlook.com",
		"Hotmail.com"
	],
	domains: [
		"hotmail.com",
		"outlook.com"
	],
	host: "smtp-mail.outlook.com",
	port: 587
};
var iCloud = {
	description: "iCloud Mail",
	aliases: [
		"Me",
		"Mac"
	],
	domains: [
		"me.com",
		"mac.com"
	],
	host: "smtp.mail.me.com",
	port: 587
};
var Infomaniak = {
	description: "Infomaniak Mail (Swiss hosting provider)",
	host: "mail.infomaniak.com",
	domains: [
		"ik.me",
		"ikmail.com",
		"etik.com"
	],
	port: 587
};
var KolabNow = {
	description: "KolabNow (secure email service)",
	domains: [
		"kolabnow.com"
	],
	aliases: [
		"Kolab"
	],
	host: "smtp.kolabnow.com",
	port: 465,
	secure: true,
	authMethod: "LOGIN"
};
var Loopia = {
	description: "Loopia (Swedish hosting provider)",
	host: "mailcluster.loopia.se",
	port: 465
};
var Loops = {
	description: "Loops",
	host: "smtp.loops.so",
	port: 587
};
var Maildev = {
	description: "MailDev (local email testing)",
	port: 1025,
	ignoreTLS: true
};
var MailerSend = {
	description: "MailerSend",
	host: "smtp.mailersend.net",
	port: 587
};
var Mailgun = {
	description: "Mailgun",
	host: "smtp.mailgun.org",
	port: 465,
	secure: true
};
var Mailjet = {
	description: "Mailjet",
	host: "in.mailjet.com",
	port: 587
};
var Mailosaur = {
	description: "Mailosaur (email testing service)",
	host: "mailosaur.io",
	port: 25
};
var Mailtrap = {
	description: "Mailtrap",
	host: "live.smtp.mailtrap.io",
	port: 587
};
var Mandrill = {
	description: "Mandrill (by Mailchimp)",
	host: "smtp.mandrillapp.com",
	port: 587
};
var Naver = {
	description: "Naver Mail (Korean email provider)",
	host: "smtp.naver.com",
	port: 587
};
var OhMySMTP = {
	description: "OhMySMTP (email delivery service)",
	host: "smtp.ohmysmtp.com",
	port: 587,
	secure: false
};
var One = {
	description: "One.com Email",
	host: "send.one.com",
	port: 465,
	secure: true
};
var OpenMailBox = {
	description: "OpenMailBox",
	aliases: [
		"OMB",
		"openmailbox.org"
	],
	host: "smtp.openmailbox.org",
	port: 465,
	secure: true
};
var Outlook365 = {
	description: "Microsoft 365 / Office 365",
	host: "smtp.office365.com",
	port: 587,
	secure: false
};
var Postmark = {
	description: "Postmark",
	aliases: [
		"PostmarkApp"
	],
	host: "smtp.postmarkapp.com",
	port: 2525
};
var Proton = {
	description: "Proton Mail",
	aliases: [
		"ProtonMail",
		"Proton.me",
		"Protonmail.com",
		"Protonmail.ch"
	],
	domains: [
		"proton.me",
		"protonmail.com",
		"pm.me",
		"protonmail.ch"
	],
	host: "smtp.protonmail.ch",
	port: 587,
	requireTLS: true
};
var QQ = {
	description: "QQ Mail",
	domains: [
		"qq.com"
	],
	host: "smtp.qq.com",
	port: 465,
	secure: true
};
var QQex = {
	description: "QQ Enterprise Mail",
	aliases: [
		"QQ Enterprise"
	],
	domains: [
		"exmail.qq.com"
	],
	host: "smtp.exmail.qq.com",
	port: 465,
	secure: true
};
var Resend = {
	description: "Resend",
	host: "smtp.resend.com",
	port: 465,
	secure: true
};
var Runbox = {
	description: "Runbox (Norwegian email provider)",
	domains: [
		"runbox.com"
	],
	host: "smtp.runbox.com",
	port: 465,
	secure: true
};
var SendCloud = {
	description: "SendCloud (Chinese email delivery)",
	host: "smtp.sendcloud.net",
	port: 2525
};
var SendGrid = {
	description: "SendGrid",
	host: "smtp.sendgrid.net",
	port: 587
};
var SendinBlue = {
	description: "Brevo (formerly Sendinblue)",
	aliases: [
		"Brevo"
	],
	host: "smtp-relay.brevo.com",
	port: 587
};
var SendPulse = {
	description: "SendPulse",
	host: "smtp-pulse.com",
	port: 465,
	secure: true
};
var SES = {
	description: "AWS SES US East (N. Virginia)",
	host: "email-smtp.us-east-1.amazonaws.com",
	port: 465,
	secure: true
};
var Seznam = {
	description: "Seznam Email (Czech email provider)",
	aliases: [
		"Seznam Email"
	],
	domains: [
		"seznam.cz",
		"email.cz",
		"post.cz",
		"spoluzaci.cz"
	],
	host: "smtp.seznam.cz",
	port: 465,
	secure: true
};
var SMTP2GO = {
	description: "SMTP2GO",
	host: "mail.smtp2go.com",
	port: 2525
};
var Sparkpost = {
	description: "SparkPost",
	aliases: [
		"SparkPost",
		"SparkPost Mail"
	],
	domains: [
		"sparkpost.com"
	],
	host: "smtp.sparkpostmail.com",
	port: 587,
	secure: false
};
var Tipimail = {
	description: "Tipimail (email delivery service)",
	host: "smtp.tipimail.com",
	port: 587
};
var Tutanota = {
	description: "Tutanota (Tuta Mail)",
	domains: [
		"tutanota.com",
		"tuta.com",
		"tutanota.de",
		"tuta.io"
	],
	host: "smtp.tutanota.com",
	port: 465,
	secure: true
};
var Yahoo = {
	description: "Yahoo Mail",
	domains: [
		"yahoo.com"
	],
	host: "smtp.mail.yahoo.com",
	port: 465,
	secure: true
};
var Yandex = {
	description: "Yandex Mail",
	domains: [
		"yandex.ru"
	],
	host: "smtp.yandex.ru",
	port: 465,
	secure: true
};
var Zimbra = {
	description: "Zimbra Mail Server",
	aliases: [
		"Zimbra Collaboration"
	],
	host: "smtp.zimbra.com",
	port: 587,
	requireTLS: true
};
var Zoho = {
	description: "Zoho Mail",
	host: "smtp.zoho.com",
	port: 465,
	secure: true,
	authMethod: "LOGIN"
};
var require$$0 = {
	"126": {
	description: "126 Mail (NetEase)",
	host: "smtp.126.com",
	port: 465,
	secure: true
},
	"163": {
	description: "163 Mail (NetEase)",
	host: "smtp.163.com",
	port: 465,
	secure: true
},
	"1und1": {
	description: "1&1 Mail (German hosting provider)",
	host: "smtp.1und1.de",
	port: 465,
	secure: true,
	authMethod: "LOGIN"
},
	Aliyun: Aliyun,
	AliyunQiye: AliyunQiye,
	AOL: AOL,
	Aruba: Aruba,
	Bluewin: Bluewin,
	BOL: BOL,
	DebugMail: DebugMail,
	Disroot: Disroot,
	DynectEmail: DynectEmail,
	ElasticEmail: ElasticEmail,
	Ethereal: Ethereal,
	FastMail: FastMail,
	"Feishu Mail": {
	description: "Feishu Mail (Lark)",
	aliases: [
		"Feishu",
		"FeishuMail"
	],
	domains: [
		"www.feishu.cn"
	],
	host: "smtp.feishu.cn",
	port: 465,
	secure: true
},
	"Forward Email": {
	description: "Forward Email (email forwarding service)",
	aliases: [
		"FE",
		"ForwardEmail"
	],
	domains: [
		"forwardemail.net"
	],
	host: "smtp.forwardemail.net",
	port: 465,
	secure: true
},
	GandiMail: GandiMail,
	Gmail: Gmail,
	GMX: GMX,
	Godaddy: Godaddy,
	GodaddyAsia: GodaddyAsia,
	GodaddyEurope: GodaddyEurope,
	"hot.ee": {
	description: "Hot.ee (Estonian email provider)",
	host: "mail.hot.ee"
},
	Hotmail: Hotmail,
	iCloud: iCloud,
	Infomaniak: Infomaniak,
	KolabNow: KolabNow,
	Loopia: Loopia,
	Loops: Loops,
	"mail.ee": {
	description: "Mail.ee (Estonian email provider)",
	host: "smtp.mail.ee"
},
	"Mail.ru": {
	description: "Mail.ru",
	host: "smtp.mail.ru",
	port: 465,
	secure: true
},
	"Mailcatch.app": {
	description: "Mailcatch (email testing service)",
	host: "sandbox-smtp.mailcatch.app",
	port: 2525
},
	Maildev: Maildev,
	MailerSend: MailerSend,
	Mailgun: Mailgun,
	Mailjet: Mailjet,
	Mailosaur: Mailosaur,
	Mailtrap: Mailtrap,
	Mandrill: Mandrill,
	Naver: Naver,
	OhMySMTP: OhMySMTP,
	One: One,
	OpenMailBox: OpenMailBox,
	Outlook365: Outlook365,
	Postmark: Postmark,
	Proton: Proton,
	"qiye.aliyun": {
	description: "Alibaba Mail Enterprise Edition",
	host: "smtp.mxhichina.com",
	port: "465",
	secure: true
},
	QQ: QQ,
	QQex: QQex,
	Resend: Resend,
	Runbox: Runbox,
	SendCloud: SendCloud,
	SendGrid: SendGrid,
	SendinBlue: SendinBlue,
	SendPulse: SendPulse,
	SES: SES,
	"SES-AP-NORTHEAST-1": {
	description: "AWS SES Asia Pacific (Tokyo)",
	host: "email-smtp.ap-northeast-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-AP-NORTHEAST-2": {
	description: "AWS SES Asia Pacific (Seoul)",
	host: "email-smtp.ap-northeast-2.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-AP-NORTHEAST-3": {
	description: "AWS SES Asia Pacific (Osaka)",
	host: "email-smtp.ap-northeast-3.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-AP-SOUTH-1": {
	description: "AWS SES Asia Pacific (Mumbai)",
	host: "email-smtp.ap-south-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-AP-SOUTHEAST-1": {
	description: "AWS SES Asia Pacific (Singapore)",
	host: "email-smtp.ap-southeast-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-AP-SOUTHEAST-2": {
	description: "AWS SES Asia Pacific (Sydney)",
	host: "email-smtp.ap-southeast-2.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-CA-CENTRAL-1": {
	description: "AWS SES Canada (Central)",
	host: "email-smtp.ca-central-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-EU-CENTRAL-1": {
	description: "AWS SES Europe (Frankfurt)",
	host: "email-smtp.eu-central-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-EU-NORTH-1": {
	description: "AWS SES Europe (Stockholm)",
	host: "email-smtp.eu-north-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-EU-WEST-1": {
	description: "AWS SES Europe (Ireland)",
	host: "email-smtp.eu-west-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-EU-WEST-2": {
	description: "AWS SES Europe (London)",
	host: "email-smtp.eu-west-2.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-EU-WEST-3": {
	description: "AWS SES Europe (Paris)",
	host: "email-smtp.eu-west-3.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-SA-EAST-1": {
	description: "AWS SES South America (São Paulo)",
	host: "email-smtp.sa-east-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-EAST-1": {
	description: "AWS SES US East (N. Virginia)",
	host: "email-smtp.us-east-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-EAST-2": {
	description: "AWS SES US East (Ohio)",
	host: "email-smtp.us-east-2.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-GOV-EAST-1": {
	description: "AWS SES GovCloud (US-East)",
	host: "email-smtp.us-gov-east-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-GOV-WEST-1": {
	description: "AWS SES GovCloud (US-West)",
	host: "email-smtp.us-gov-west-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-WEST-1": {
	description: "AWS SES US West (N. California)",
	host: "email-smtp.us-west-1.amazonaws.com",
	port: 465,
	secure: true
},
	"SES-US-WEST-2": {
	description: "AWS SES US West (Oregon)",
	host: "email-smtp.us-west-2.amazonaws.com",
	port: 465,
	secure: true
},
	Seznam: Seznam,
	SMTP2GO: SMTP2GO,
	Sparkpost: Sparkpost,
	Tipimail: Tipimail,
	Tutanota: Tutanota,
	Yahoo: Yahoo,
	Yandex: Yandex,
	Zimbra: Zimbra,
	Zoho: Zoho
};

var wellKnown;
var hasRequiredWellKnown;

function requireWellKnown () {
	if (hasRequiredWellKnown) return wellKnown;
	hasRequiredWellKnown = 1;

	const services = require$$0;
	const normalized = {};

	Object.keys(services).forEach(key => {
	    let service = services[key];

	    normalized[normalizeKey(key)] = normalizeService(service);

	    [].concat(service.aliases || []).forEach(alias => {
	        normalized[normalizeKey(alias)] = normalizeService(service);
	    });

	    [].concat(service.domains || []).forEach(domain => {
	        normalized[normalizeKey(domain)] = normalizeService(service);
	    });
	});

	function normalizeKey(key) {
	    return key.replace(/[^a-zA-Z0-9.-]/g, '').toLowerCase();
	}

	function normalizeService(service) {
	    let filter = ['domains', 'aliases'];
	    let response = {};

	    Object.keys(service).forEach(key => {
	        if (filter.indexOf(key) < 0) {
	            response[key] = service[key];
	        }
	    });

	    return response;
	}

	/**
	 * Resolves SMTP config for given key. Key can be a name (like 'Gmail'), alias (like 'Google Mail') or
	 * an email address (like 'test@googlemail.com').
	 *
	 * @param {String} key [description]
	 * @returns {Object} SMTP config or false if not found
	 */
	wellKnown = function (key) {
	    key = normalizeKey(key.split('@').pop());
	    return normalized[key] || false;
	};
	return wellKnown;
}

var smtpPool;
var hasRequiredSmtpPool;

function requireSmtpPool () {
	if (hasRequiredSmtpPool) return smtpPool;
	hasRequiredSmtpPool = 1;

	const EventEmitter$1 = EventEmitter;
	const PoolResource = requirePoolResource();
	const SMTPConnection = requireSmtpConnection();
	const wellKnown = requireWellKnown();
	const shared = requireShared();
	const packageData = require$$9;

	/**
	 * Creates a SMTP pool transport object for Nodemailer
	 *
	 * @constructor
	 * @param {Object} options SMTP Connection options
	 */
	class SMTPPool extends EventEmitter$1 {
	    constructor(options) {
	        super();

	        options = options || {};
	        if (typeof options === 'string') {
	            options = {
	                url: options
	            };
	        }

	        let urlData;
	        let service = options.service;

	        if (typeof options.getSocket === 'function') {
	            this.getSocket = options.getSocket;
	        }

	        if (options.url) {
	            urlData = shared.parseConnectionUrl(options.url);
	            service = service || urlData.service;
	        }

	        this.options = shared.assign(
	            false, // create new object
	            options, // regular options
	            urlData, // url options
	            service && wellKnown(service) // wellknown options
	        );

	        this.options.maxConnections = this.options.maxConnections || 5;
	        this.options.maxMessages = this.options.maxMessages || 100;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'smtp-pool'
	        });

	        // temporary object
	        let connection = new SMTPConnection(this.options);

	        this.name = 'SMTP (pool)';
	        this.version = packageData.version + '[client:' + connection.version + ']';

	        this._rateLimit = {
	            counter: 0,
	            timeout: null,
	            waiting: [],
	            checkpoint: false,
	            delta: Number(this.options.rateDelta) || 1000,
	            limit: Number(this.options.rateLimit) || 0
	        };
	        this._closed = false;
	        this._queue = [];
	        this._connections = [];
	        this._connectionCounter = 0;

	        this.idling = true;

	        setImmediate(() => {
	            if (this.idling) {
	                this.emit('idle');
	            }
	        });
	    }

	    /**
	     * Placeholder function for creating proxy sockets. This method immediatelly returns
	     * without a socket
	     *
	     * @param {Object} options Connection options
	     * @param {Function} callback Callback function to run with the socket keys
	     */
	    getSocket(options, callback) {
	        // return immediatelly
	        return setImmediate(() => callback(null, false));
	    }

	    /**
	     * Queues an e-mail to be sent using the selected settings
	     *
	     * @param {Object} mail Mail object
	     * @param {Function} callback Callback function
	     */
	    send(mail, callback) {
	        if (this._closed) {
	            return false;
	        }

	        this._queue.push({
	            mail,
	            requeueAttempts: 0,
	            callback
	        });

	        if (this.idling && this._queue.length >= this.options.maxConnections) {
	            this.idling = false;
	        }

	        setImmediate(() => this._processMessages());

	        return true;
	    }

	    /**
	     * Closes all connections in the pool. If there is a message being sent, the connection
	     * is closed later
	     */
	    close() {
	        let connection;
	        let len = this._connections.length;
	        this._closed = true;

	        // clear rate limit timer if it exists
	        clearTimeout(this._rateLimit.timeout);

	        if (!len && !this._queue.length) {
	            return;
	        }

	        // remove all available connections
	        for (let i = len - 1; i >= 0; i--) {
	            if (this._connections[i] && this._connections[i].available) {
	                connection = this._connections[i];
	                connection.close();
	                this.logger.info(
	                    {
	                        tnx: 'connection',
	                        cid: connection.id,
	                        action: 'removed'
	                    },
	                    'Connection #%s removed',
	                    connection.id
	                );
	            }
	        }

	        if (len && !this._connections.length) {
	            this.logger.debug(
	                {
	                    tnx: 'connection'
	                },
	                'All connections removed'
	            );
	        }

	        if (!this._queue.length) {
	            return;
	        }

	        // make sure that entire queue would be cleaned
	        let invokeCallbacks = () => {
	            if (!this._queue.length) {
	                this.logger.debug(
	                    {
	                        tnx: 'connection'
	                    },
	                    'Pending queue entries cleared'
	                );
	                return;
	            }
	            let entry = this._queue.shift();
	            if (entry && typeof entry.callback === 'function') {
	                try {
	                    entry.callback(new Error('Connection pool was closed'));
	                } catch (E) {
	                    this.logger.error(
	                        {
	                            err: E,
	                            tnx: 'callback',
	                            cid: connection.id
	                        },
	                        'Callback error for #%s: %s',
	                        connection.id,
	                        E.message
	                    );
	                }
	            }
	            setImmediate(invokeCallbacks);
	        };
	        setImmediate(invokeCallbacks);
	    }

	    /**
	     * Check the queue and available connections. If there is a message to be sent and there is
	     * an available connection, then use this connection to send the mail
	     */
	    _processMessages() {
	        let connection;
	        let i, len;

	        // do nothing if already closed
	        if (this._closed) {
	            return;
	        }

	        // do nothing if queue is empty
	        if (!this._queue.length) {
	            if (!this.idling) {
	                // no pending jobs
	                this.idling = true;
	                this.emit('idle');
	            }
	            return;
	        }

	        // find first available connection
	        for (i = 0, len = this._connections.length; i < len; i++) {
	            if (this._connections[i].available) {
	                connection = this._connections[i];
	                break;
	            }
	        }

	        if (!connection && this._connections.length < this.options.maxConnections) {
	            connection = this._createConnection();
	        }

	        if (!connection) {
	            // no more free connection slots available
	            this.idling = false;
	            return;
	        }

	        // check if there is free space in the processing queue
	        if (!this.idling && this._queue.length < this.options.maxConnections) {
	            this.idling = true;
	            this.emit('idle');
	        }

	        let entry = (connection.queueEntry = this._queue.shift());
	        entry.messageId = (connection.queueEntry.mail.message.getHeader('message-id') || '').replace(/[<>\s]/g, '');

	        connection.available = false;

	        this.logger.debug(
	            {
	                tnx: 'pool',
	                cid: connection.id,
	                messageId: entry.messageId,
	                action: 'assign'
	            },
	            'Assigned message <%s> to #%s (%s)',
	            entry.messageId,
	            connection.id,
	            connection.messages + 1
	        );

	        if (this._rateLimit.limit) {
	            this._rateLimit.counter++;
	            if (!this._rateLimit.checkpoint) {
	                this._rateLimit.checkpoint = Date.now();
	            }
	        }

	        connection.send(entry.mail, (err, info) => {
	            // only process callback if current handler is not changed
	            if (entry === connection.queueEntry) {
	                try {
	                    entry.callback(err, info);
	                } catch (E) {
	                    this.logger.error(
	                        {
	                            err: E,
	                            tnx: 'callback',
	                            cid: connection.id
	                        },
	                        'Callback error for #%s: %s',
	                        connection.id,
	                        E.message
	                    );
	                }
	                connection.queueEntry = false;
	            }
	        });
	    }

	    /**
	     * Creates a new pool resource
	     */
	    _createConnection() {
	        let connection = new PoolResource(this);

	        connection.id = ++this._connectionCounter;

	        this.logger.info(
	            {
	                tnx: 'pool',
	                cid: connection.id,
	                action: 'conection'
	            },
	            'Created new pool resource #%s',
	            connection.id
	        );

	        // resource comes available
	        connection.on('available', () => {
	            this.logger.debug(
	                {
	                    tnx: 'connection',
	                    cid: connection.id,
	                    action: 'available'
	                },
	                'Connection #%s became available',
	                connection.id
	            );

	            if (this._closed) {
	                // if already closed run close() that will remove this connections from connections list
	                this.close();
	            } else {
	                // check if there's anything else to send
	                this._processMessages();
	            }
	        });

	        // resource is terminated with an error
	        connection.once('error', err => {
	            if (err.code !== 'EMAXLIMIT') {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'pool',
	                        cid: connection.id
	                    },
	                    'Pool Error for #%s: %s',
	                    connection.id,
	                    err.message
	                );
	            } else {
	                this.logger.debug(
	                    {
	                        tnx: 'pool',
	                        cid: connection.id,
	                        action: 'maxlimit'
	                    },
	                    'Max messages limit exchausted for #%s',
	                    connection.id
	                );
	            }

	            if (connection.queueEntry) {
	                try {
	                    connection.queueEntry.callback(err);
	                } catch (E) {
	                    this.logger.error(
	                        {
	                            err: E,
	                            tnx: 'callback',
	                            cid: connection.id
	                        },
	                        'Callback error for #%s: %s',
	                        connection.id,
	                        E.message
	                    );
	                }
	                connection.queueEntry = false;
	            }

	            // remove the erroneus connection from connections list
	            this._removeConnection(connection);

	            this._continueProcessing();
	        });

	        connection.once('close', () => {
	            this.logger.info(
	                {
	                    tnx: 'connection',
	                    cid: connection.id,
	                    action: 'closed'
	                },
	                'Connection #%s was closed',
	                connection.id
	            );

	            this._removeConnection(connection);

	            if (connection.queueEntry) {
	                // If the connection closed when sending, add the message to the queue again
	                // if max number of requeues is not reached yet
	                // Note that we must wait a bit.. because the callback of the 'error' handler might be called
	                // in the next event loop
	                setTimeout(() => {
	                    if (connection.queueEntry) {
	                        if (this._shouldRequeuOnConnectionClose(connection.queueEntry)) {
	                            this._requeueEntryOnConnectionClose(connection);
	                        } else {
	                            this._failDeliveryOnConnectionClose(connection);
	                        }
	                    }
	                    this._continueProcessing();
	                }, 50);
	            } else {
	                if (!this._closed && this.idling && !this._connections.length) {
	                    this.emit('clear');
	                }

	                this._continueProcessing();
	            }
	        });

	        this._connections.push(connection);

	        return connection;
	    }

	    _shouldRequeuOnConnectionClose(queueEntry) {
	        if (this.options.maxRequeues === undefined || this.options.maxRequeues < 0) {
	            return true;
	        }

	        return queueEntry.requeueAttempts < this.options.maxRequeues;
	    }

	    _failDeliveryOnConnectionClose(connection) {
	        if (connection.queueEntry && connection.queueEntry.callback) {
	            try {
	                connection.queueEntry.callback(new Error('Reached maximum number of retries after connection was closed'));
	            } catch (E) {
	                this.logger.error(
	                    {
	                        err: E,
	                        tnx: 'callback',
	                        messageId: connection.queueEntry.messageId,
	                        cid: connection.id
	                    },
	                    'Callback error for #%s: %s',
	                    connection.id,
	                    E.message
	                );
	            }
	            connection.queueEntry = false;
	        }
	    }

	    _requeueEntryOnConnectionClose(connection) {
	        connection.queueEntry.requeueAttempts = connection.queueEntry.requeueAttempts + 1;
	        this.logger.debug(
	            {
	                tnx: 'pool',
	                cid: connection.id,
	                messageId: connection.queueEntry.messageId,
	                action: 'requeue'
	            },
	            'Re-queued message <%s> for #%s. Attempt: #%s',
	            connection.queueEntry.messageId,
	            connection.id,
	            connection.queueEntry.requeueAttempts
	        );
	        this._queue.unshift(connection.queueEntry);
	        connection.queueEntry = false;
	    }

	    /**
	     * Continue to process message if the pool hasn't closed
	     */
	    _continueProcessing() {
	        if (this._closed) {
	            this.close();
	        } else {
	            setTimeout(() => this._processMessages(), 100);
	        }
	    }

	    /**
	     * Remove resource from pool
	     *
	     * @param {Object} connection The PoolResource to remove
	     */
	    _removeConnection(connection) {
	        let index = this._connections.indexOf(connection);

	        if (index !== -1) {
	            this._connections.splice(index, 1);
	        }
	    }

	    /**
	     * Checks if connections have hit current rate limit and if so, queues the availability callback
	     *
	     * @param {Function} callback Callback function to run once rate limiter has been cleared
	     */
	    _checkRateLimit(callback) {
	        if (!this._rateLimit.limit) {
	            return callback();
	        }

	        let now = Date.now();

	        if (this._rateLimit.counter < this._rateLimit.limit) {
	            return callback();
	        }

	        this._rateLimit.waiting.push(callback);

	        if (this._rateLimit.checkpoint <= now - this._rateLimit.delta) {
	            return this._clearRateLimit();
	        } else if (!this._rateLimit.timeout) {
	            this._rateLimit.timeout = setTimeout(() => this._clearRateLimit(), this._rateLimit.delta - (now - this._rateLimit.checkpoint));
	            this._rateLimit.checkpoint = now;
	        }
	    }

	    /**
	     * Clears current rate limit limitation and runs paused callback
	     */
	    _clearRateLimit() {
	        clearTimeout(this._rateLimit.timeout);
	        this._rateLimit.timeout = null;
	        this._rateLimit.counter = 0;
	        this._rateLimit.checkpoint = false;

	        // resume all paused connections
	        while (this._rateLimit.waiting.length) {
	            let cb = this._rateLimit.waiting.shift();
	            setImmediate(cb);
	        }
	    }

	    /**
	     * Returns true if there are free slots in the queue
	     */
	    isIdle() {
	        return this.idling;
	    }

	    /**
	     * Verifies SMTP configuration
	     *
	     * @param {Function} callback Callback function
	     */
	    verify(callback) {
	        let promise;

	        if (!callback) {
	            promise = new Promise((resolve, reject) => {
	                callback = shared.callbackPromise(resolve, reject);
	            });
	        }

	        let auth = new PoolResource(this).auth;

	        this.getSocket(this.options, (err, socketOptions) => {
	            if (err) {
	                return callback(err);
	            }

	            let options = this.options;
	            if (socketOptions && socketOptions.connection) {
	                this.logger.info(
	                    {
	                        tnx: 'proxy',
	                        remoteAddress: socketOptions.connection.remoteAddress,
	                        remotePort: socketOptions.connection.remotePort,
	                        destHost: options.host || '',
	                        destPort: options.port || '',
	                        action: 'connected'
	                    },
	                    'Using proxied socket from %s:%s to %s:%s',
	                    socketOptions.connection.remoteAddress,
	                    socketOptions.connection.remotePort,
	                    options.host || '',
	                    options.port || ''
	                );
	                options = shared.assign(false, options);
	                Object.keys(socketOptions).forEach(key => {
	                    options[key] = socketOptions[key];
	                });
	            }

	            let connection = new SMTPConnection(options);
	            let returned = false;

	            connection.once('error', err => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                connection.close();
	                return callback(err);
	            });

	            connection.once('end', () => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                return callback(new Error('Connection closed'));
	            });

	            let finalize = () => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                connection.quit();
	                return callback(null, true);
	            };

	            connection.connect(() => {
	                if (returned) {
	                    return;
	                }

	                if (auth && (connection.allowsAuth || options.forceAuth)) {
	                    connection.login(auth, err => {
	                        if (returned) {
	                            return;
	                        }

	                        if (err) {
	                            returned = true;
	                            connection.close();
	                            return callback(err);
	                        }

	                        finalize();
	                    });
	                } else if (!auth && connection.allowsAuth && options.forceAuth) {
	                    let err = new Error('Authentication info was not provided');
	                    err.code = 'NoAuth';

	                    returned = true;
	                    connection.close();
	                    return callback(err);
	                } else {
	                    finalize();
	                }
	            });
	        });

	        return promise;
	    }
	}

	// expose to the world
	smtpPool = SMTPPool;
	return smtpPool;
}

var smtpTransport;
var hasRequiredSmtpTransport;

function requireSmtpTransport () {
	if (hasRequiredSmtpTransport) return smtpTransport;
	hasRequiredSmtpTransport = 1;

	const EventEmitter$1 = EventEmitter;
	const SMTPConnection = requireSmtpConnection();
	const wellKnown = requireWellKnown();
	const shared = requireShared();
	const XOAuth2 = requireXoauth2();
	const packageData = require$$9;

	/**
	 * Creates a SMTP transport object for Nodemailer
	 *
	 * @constructor
	 * @param {Object} options Connection options
	 */
	class SMTPTransport extends EventEmitter$1 {
	    constructor(options) {
	        super();

	        options = options || {};

	        if (typeof options === 'string') {
	            options = {
	                url: options
	            };
	        }

	        let urlData;
	        let service = options.service;

	        if (typeof options.getSocket === 'function') {
	            this.getSocket = options.getSocket;
	        }

	        if (options.url) {
	            urlData = shared.parseConnectionUrl(options.url);
	            service = service || urlData.service;
	        }

	        this.options = shared.assign(
	            false, // create new object
	            options, // regular options
	            urlData, // url options
	            service && wellKnown(service) // wellknown options
	        );

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'smtp-transport'
	        });

	        // temporary object
	        let connection = new SMTPConnection(this.options);

	        this.name = 'SMTP';
	        this.version = packageData.version + '[client:' + connection.version + ']';

	        if (this.options.auth) {
	            this.auth = this.getAuth({});
	        }
	    }

	    /**
	     * Placeholder function for creating proxy sockets. This method immediatelly returns
	     * without a socket
	     *
	     * @param {Object} options Connection options
	     * @param {Function} callback Callback function to run with the socket keys
	     */
	    getSocket(options, callback) {
	        // return immediatelly
	        return setImmediate(() => callback(null, false));
	    }

	    getAuth(authOpts) {
	        if (!authOpts) {
	            return this.auth;
	        }

	        let hasAuth = false;
	        let authData = {};

	        if (this.options.auth && typeof this.options.auth === 'object') {
	            Object.keys(this.options.auth).forEach(key => {
	                hasAuth = true;
	                authData[key] = this.options.auth[key];
	            });
	        }

	        if (authOpts && typeof authOpts === 'object') {
	            Object.keys(authOpts).forEach(key => {
	                hasAuth = true;
	                authData[key] = authOpts[key];
	            });
	        }

	        if (!hasAuth) {
	            return false;
	        }

	        switch ((authData.type || '').toString().toUpperCase()) {
	            case 'OAUTH2': {
	                if (!authData.service && !authData.user) {
	                    return false;
	                }
	                let oauth2 = new XOAuth2(authData, this.logger);
	                oauth2.provisionCallback = (this.mailer && this.mailer.get('oauth2_provision_cb')) || oauth2.provisionCallback;
	                oauth2.on('token', token => this.mailer.emit('token', token));
	                oauth2.on('error', err => this.emit('error', err));
	                return {
	                    type: 'OAUTH2',
	                    user: authData.user,
	                    oauth2,
	                    method: 'XOAUTH2'
	                };
	            }
	            default:
	                return {
	                    type: (authData.type || '').toString().toUpperCase() || 'LOGIN',
	                    user: authData.user,
	                    credentials: {
	                        user: authData.user || '',
	                        pass: authData.pass,
	                        options: authData.options
	                    },
	                    method: (authData.method || '').trim().toUpperCase() || this.options.authMethod || false
	                };
	        }
	    }

	    /**
	     * Sends an e-mail using the selected settings
	     *
	     * @param {Object} mail Mail object
	     * @param {Function} callback Callback function
	     */
	    send(mail, callback) {
	        this.getSocket(this.options, (err, socketOptions) => {
	            if (err) {
	                return callback(err);
	            }

	            let returned = false;
	            let options = this.options;
	            if (socketOptions && socketOptions.connection) {
	                this.logger.info(
	                    {
	                        tnx: 'proxy',
	                        remoteAddress: socketOptions.connection.remoteAddress,
	                        remotePort: socketOptions.connection.remotePort,
	                        destHost: options.host || '',
	                        destPort: options.port || '',
	                        action: 'connected'
	                    },
	                    'Using proxied socket from %s:%s to %s:%s',
	                    socketOptions.connection.remoteAddress,
	                    socketOptions.connection.remotePort,
	                    options.host || '',
	                    options.port || ''
	                );

	                // only copy options if we need to modify it
	                options = shared.assign(false, options);
	                Object.keys(socketOptions).forEach(key => {
	                    options[key] = socketOptions[key];
	                });
	            }

	            let connection = new SMTPConnection(options);

	            connection.once('error', err => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                connection.close();
	                return callback(err);
	            });

	            connection.once('end', () => {
	                if (returned) {
	                    return;
	                }

	                let timer = setTimeout(() => {
	                    if (returned) {
	                        return;
	                    }
	                    returned = true;
	                    // still have not returned, this means we have an unexpected connection close
	                    let err = new Error('Unexpected socket close');
	                    if (connection && connection._socket && connection._socket.upgrading) {
	                        // starttls connection errors
	                        err.code = 'ETLS';
	                    }
	                    callback(err);
	                }, 1000);

	                try {
	                    timer.unref();
	                } catch (_E) {
	                    // Ignore. Happens on envs with non-node timer implementation
	                }
	            });

	            let sendMessage = () => {
	                let envelope = mail.message.getEnvelope();
	                let messageId = mail.message.messageId();

	                let recipients = [].concat(envelope.to || []);
	                if (recipients.length > 3) {
	                    recipients.push('...and ' + recipients.splice(2).length + ' more');
	                }

	                if (mail.data.dsn) {
	                    envelope.dsn = mail.data.dsn;
	                }

	                this.logger.info(
	                    {
	                        tnx: 'send',
	                        messageId
	                    },
	                    'Sending message %s to <%s>',
	                    messageId,
	                    recipients.join(', ')
	                );

	                connection.send(envelope, mail.message.createReadStream(), (err, info) => {
	                    returned = true;
	                    connection.close();
	                    if (err) {
	                        this.logger.error(
	                            {
	                                err,
	                                tnx: 'send'
	                            },
	                            'Send error for %s: %s',
	                            messageId,
	                            err.message
	                        );
	                        return callback(err);
	                    }
	                    info.envelope = {
	                        from: envelope.from,
	                        to: envelope.to
	                    };
	                    info.messageId = messageId;
	                    try {
	                        return callback(null, info);
	                    } catch (E) {
	                        this.logger.error(
	                            {
	                                err: E,
	                                tnx: 'callback'
	                            },
	                            'Callback error for %s: %s',
	                            messageId,
	                            E.message
	                        );
	                    }
	                });
	            };

	            connection.connect(() => {
	                if (returned) {
	                    return;
	                }

	                let auth = this.getAuth(mail.data.auth);

	                if (auth && (connection.allowsAuth || options.forceAuth)) {
	                    connection.login(auth, err => {
	                        if (auth && auth !== this.auth && auth.oauth2) {
	                            auth.oauth2.removeAllListeners();
	                        }
	                        if (returned) {
	                            return;
	                        }

	                        if (err) {
	                            returned = true;
	                            connection.close();
	                            return callback(err);
	                        }

	                        sendMessage();
	                    });
	                } else {
	                    sendMessage();
	                }
	            });
	        });
	    }

	    /**
	     * Verifies SMTP configuration
	     *
	     * @param {Function} callback Callback function
	     */
	    verify(callback) {
	        let promise;

	        if (!callback) {
	            promise = new Promise((resolve, reject) => {
	                callback = shared.callbackPromise(resolve, reject);
	            });
	        }

	        this.getSocket(this.options, (err, socketOptions) => {
	            if (err) {
	                return callback(err);
	            }

	            let options = this.options;
	            if (socketOptions && socketOptions.connection) {
	                this.logger.info(
	                    {
	                        tnx: 'proxy',
	                        remoteAddress: socketOptions.connection.remoteAddress,
	                        remotePort: socketOptions.connection.remotePort,
	                        destHost: options.host || '',
	                        destPort: options.port || '',
	                        action: 'connected'
	                    },
	                    'Using proxied socket from %s:%s to %s:%s',
	                    socketOptions.connection.remoteAddress,
	                    socketOptions.connection.remotePort,
	                    options.host || '',
	                    options.port || ''
	                );

	                options = shared.assign(false, options);
	                Object.keys(socketOptions).forEach(key => {
	                    options[key] = socketOptions[key];
	                });
	            }

	            let connection = new SMTPConnection(options);
	            let returned = false;

	            connection.once('error', err => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                connection.close();
	                return callback(err);
	            });

	            connection.once('end', () => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                return callback(new Error('Connection closed'));
	            });

	            let finalize = () => {
	                if (returned) {
	                    return;
	                }
	                returned = true;
	                connection.quit();
	                return callback(null, true);
	            };

	            connection.connect(() => {
	                if (returned) {
	                    return;
	                }

	                let authData = this.getAuth({});

	                if (authData && (connection.allowsAuth || options.forceAuth)) {
	                    connection.login(authData, err => {
	                        if (returned) {
	                            return;
	                        }

	                        if (err) {
	                            returned = true;
	                            connection.close();
	                            return callback(err);
	                        }

	                        finalize();
	                    });
	                } else if (!authData && connection.allowsAuth && options.forceAuth) {
	                    let err = new Error('Authentication info was not provided');
	                    err.code = 'NoAuth';

	                    returned = true;
	                    connection.close();
	                    return callback(err);
	                } else {
	                    finalize();
	                }
	            });
	        });

	        return promise;
	    }

	    /**
	     * Releases resources
	     */
	    close() {
	        if (this.auth && this.auth.oauth2) {
	            this.auth.oauth2.removeAllListeners();
	        }
	        this.emit('close');
	    }
	}

	// expose to the world
	smtpTransport = SMTPTransport;
	return smtpTransport;
}

var sendmailTransport;
var hasRequiredSendmailTransport;

function requireSendmailTransport () {
	if (hasRequiredSendmailTransport) return sendmailTransport;
	hasRequiredSendmailTransport = 1;

	const spawn = require$$0$4.spawn;
	const packageData = require$$9;
	const shared = requireShared();

	/**
	 * Generates a Transport object for Sendmail
	 *
	 * Possible options can be the following:
	 *
	 *  * **path** optional path to sendmail binary
	 *  * **newline** either 'windows' or 'unix'
	 *  * **args** an array of arguments for the sendmail binary
	 *
	 * @constructor
	 * @param {Object} optional config parameter for Sendmail
	 */
	class SendmailTransport {
	    constructor(options) {
	        options = options || {};

	        // use a reference to spawn for mocking purposes
	        this._spawn = spawn;

	        this.options = options || {};

	        this.name = 'Sendmail';
	        this.version = packageData.version;

	        this.path = 'sendmail';
	        this.args = false;
	        this.winbreak = false;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'sendmail'
	        });

	        if (options) {
	            if (typeof options === 'string') {
	                this.path = options;
	            } else if (typeof options === 'object') {
	                if (options.path) {
	                    this.path = options.path;
	                }
	                if (Array.isArray(options.args)) {
	                    this.args = options.args;
	                }
	                this.winbreak = ['win', 'windows', 'dos', '\r\n'].includes((options.newline || '').toString().toLowerCase());
	            }
	        }
	    }

	    /**
	     * <p>Compiles a mailcomposer message and forwards it to handler that sends it.</p>
	     *
	     * @param {Object} emailMessage MailComposer object
	     * @param {Function} callback Callback function to run when the sending is completed
	     */
	    send(mail, done) {
	        // Sendmail strips this header line by itself
	        mail.message.keepBcc = true;

	        let envelope = mail.data.envelope || mail.message.getEnvelope();
	        let messageId = mail.message.messageId();
	        let args;
	        let sendmail;
	        let returned;

	        const hasInvalidAddresses = []
	            .concat(envelope.from || [])
	            .concat(envelope.to || [])
	            .some(addr => /^-/.test(addr));
	        if (hasInvalidAddresses) {
	            return done(new Error('Can not send mail. Invalid envelope addresses.'));
	        }

	        if (this.args) {
	            // force -i to keep single dots
	            args = ['-i'].concat(this.args).concat(envelope.to);
	        } else {
	            args = ['-i'].concat(envelope.from ? ['-f', envelope.from] : []).concat(envelope.to);
	        }

	        let callback = err => {
	            if (returned) {
	                // ignore any additional responses, already done
	                return;
	            }
	            returned = true;
	            if (typeof done === 'function') {
	                if (err) {
	                    return done(err);
	                } else {
	                    return done(null, {
	                        envelope: mail.data.envelope || mail.message.getEnvelope(),
	                        messageId,
	                        response: 'Messages queued for delivery'
	                    });
	                }
	            }
	        };

	        try {
	            sendmail = this._spawn(this.path, args);
	        } catch (E) {
	            this.logger.error(
	                {
	                    err: E,
	                    tnx: 'spawn',
	                    messageId
	                },
	                'Error occurred while spawning sendmail. %s',
	                E.message
	            );
	            return callback(E);
	        }

	        if (sendmail) {
	            sendmail.on('error', err => {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'spawn',
	                        messageId
	                    },
	                    'Error occurred when sending message %s. %s',
	                    messageId,
	                    err.message
	                );
	                callback(err);
	            });

	            sendmail.once('exit', code => {
	                if (!code) {
	                    return callback();
	                }
	                let err;
	                if (code === 127) {
	                    err = new Error('Sendmail command not found, process exited with code ' + code);
	                } else {
	                    err = new Error('Sendmail exited with code ' + code);
	                }

	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'stdin',
	                        messageId
	                    },
	                    'Error sending message %s to sendmail. %s',
	                    messageId,
	                    err.message
	                );
	                callback(err);
	            });
	            sendmail.once('close', callback);

	            sendmail.stdin.on('error', err => {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'stdin',
	                        messageId
	                    },
	                    'Error occurred when piping message %s to sendmail. %s',
	                    messageId,
	                    err.message
	                );
	                callback(err);
	            });

	            let recipients = [].concat(envelope.to || []);
	            if (recipients.length > 3) {
	                recipients.push('...and ' + recipients.splice(2).length + ' more');
	            }
	            this.logger.info(
	                {
	                    tnx: 'send',
	                    messageId
	                },
	                'Sending message %s to <%s>',
	                messageId,
	                recipients.join(', ')
	            );

	            let sourceStream = mail.message.createReadStream();
	            sourceStream.once('error', err => {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'stdin',
	                        messageId
	                    },
	                    'Error occurred when generating message %s. %s',
	                    messageId,
	                    err.message
	                );
	                sendmail.kill('SIGINT'); // do not deliver the message
	                callback(err);
	            });

	            sourceStream.pipe(sendmail.stdin);
	        } else {
	            return callback(new Error('sendmail was not found'));
	        }
	    }
	}

	sendmailTransport = SendmailTransport;
	return sendmailTransport;
}

var streamTransport;
var hasRequiredStreamTransport;

function requireStreamTransport () {
	if (hasRequiredStreamTransport) return streamTransport;
	hasRequiredStreamTransport = 1;

	const packageData = require$$9;
	const shared = requireShared();

	/**
	 * Generates a Transport object for streaming
	 *
	 * Possible options can be the following:
	 *
	 *  * **buffer** if true, then returns the message as a Buffer object instead of a stream
	 *  * **newline** either 'windows' or 'unix'
	 *
	 * @constructor
	 * @param {Object} optional config parameter
	 */
	class StreamTransport {
	    constructor(options) {
	        options = options || {};

	        this.options = options || {};

	        this.name = 'StreamTransport';
	        this.version = packageData.version;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'stream-transport'
	        });

	        this.winbreak = ['win', 'windows', 'dos', '\r\n'].includes((options.newline || '').toString().toLowerCase());
	    }

	    /**
	     * Compiles a mailcomposer message and forwards it to handler that sends it
	     *
	     * @param {Object} emailMessage MailComposer object
	     * @param {Function} callback Callback function to run when the sending is completed
	     */
	    send(mail, done) {
	        // We probably need this in the output
	        mail.message.keepBcc = true;

	        let envelope = mail.data.envelope || mail.message.getEnvelope();
	        let messageId = mail.message.messageId();

	        let recipients = [].concat(envelope.to || []);
	        if (recipients.length > 3) {
	            recipients.push('...and ' + recipients.splice(2).length + ' more');
	        }
	        this.logger.info(
	            {
	                tnx: 'send',
	                messageId
	            },
	            'Sending message %s to <%s> using %s line breaks',
	            messageId,
	            recipients.join(', '),
	            this.winbreak ? '<CR><LF>' : '<LF>'
	        );

	        setImmediate(() => {
	            let stream;

	            try {
	                stream = mail.message.createReadStream();
	            } catch (E) {
	                this.logger.error(
	                    {
	                        err: E,
	                        tnx: 'send',
	                        messageId
	                    },
	                    'Creating send stream failed for %s. %s',
	                    messageId,
	                    E.message
	                );
	                return done(E);
	            }

	            if (!this.options.buffer) {
	                stream.once('error', err => {
	                    this.logger.error(
	                        {
	                            err,
	                            tnx: 'send',
	                            messageId
	                        },
	                        'Failed creating message for %s. %s',
	                        messageId,
	                        err.message
	                    );
	                });
	                return done(null, {
	                    envelope: mail.data.envelope || mail.message.getEnvelope(),
	                    messageId,
	                    message: stream
	                });
	            }

	            let chunks = [];
	            let chunklen = 0;
	            stream.on('readable', () => {
	                let chunk;
	                while ((chunk = stream.read()) !== null) {
	                    chunks.push(chunk);
	                    chunklen += chunk.length;
	                }
	            });

	            stream.once('error', err => {
	                this.logger.error(
	                    {
	                        err,
	                        tnx: 'send',
	                        messageId
	                    },
	                    'Failed creating message for %s. %s',
	                    messageId,
	                    err.message
	                );
	                return done(err);
	            });

	            stream.on('end', () =>
	                done(null, {
	                    envelope: mail.data.envelope || mail.message.getEnvelope(),
	                    messageId,
	                    message: Buffer.concat(chunks, chunklen)
	                })
	            );
	        });
	    }
	}

	streamTransport = StreamTransport;
	return streamTransport;
}

var jsonTransport;
var hasRequiredJsonTransport;

function requireJsonTransport () {
	if (hasRequiredJsonTransport) return jsonTransport;
	hasRequiredJsonTransport = 1;

	const packageData = require$$9;
	const shared = requireShared();

	/**
	 * Generates a Transport object to generate JSON output
	 *
	 * @constructor
	 * @param {Object} optional config parameter
	 */
	class JSONTransport {
	    constructor(options) {
	        options = options || {};

	        this.options = options || {};

	        this.name = 'JSONTransport';
	        this.version = packageData.version;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'json-transport'
	        });
	    }

	    /**
	     * <p>Compiles a mailcomposer message and forwards it to handler that sends it.</p>
	     *
	     * @param {Object} emailMessage MailComposer object
	     * @param {Function} callback Callback function to run when the sending is completed
	     */
	    send(mail, done) {
	        // Sendmail strips this header line by itself
	        mail.message.keepBcc = true;

	        let envelope = mail.data.envelope || mail.message.getEnvelope();
	        let messageId = mail.message.messageId();

	        let recipients = [].concat(envelope.to || []);
	        if (recipients.length > 3) {
	            recipients.push('...and ' + recipients.splice(2).length + ' more');
	        }
	        this.logger.info(
	            {
	                tnx: 'send',
	                messageId
	            },
	            'Composing JSON structure of %s to <%s>',
	            messageId,
	            recipients.join(', ')
	        );

	        setImmediate(() => {
	            mail.normalize((err, data) => {
	                if (err) {
	                    this.logger.error(
	                        {
	                            err,
	                            tnx: 'send',
	                            messageId
	                        },
	                        'Failed building JSON structure for %s. %s',
	                        messageId,
	                        err.message
	                    );
	                    return done(err);
	                }

	                delete data.envelope;
	                delete data.normalizedHeaders;

	                return done(null, {
	                    envelope,
	                    messageId,
	                    message: this.options.skipEncoding ? data : JSON.stringify(data)
	                });
	            });
	        });
	    }
	}

	jsonTransport = JSONTransport;
	return jsonTransport;
}

var sesTransport;
var hasRequiredSesTransport;

function requireSesTransport () {
	if (hasRequiredSesTransport) return sesTransport;
	hasRequiredSesTransport = 1;

	const EventEmitter$1 = EventEmitter;
	const packageData = require$$9;
	const shared = requireShared();
	const LeWindows = requireLeWindows();
	const MimeNode = requireMimeNode();

	/**
	 * Generates a Transport object for AWS SES
	 *
	 * @constructor
	 * @param {Object} optional config parameter
	 */
	class SESTransport extends EventEmitter$1 {
	    constructor(options) {
	        super();
	        options = options || {};

	        this.options = options || {};
	        this.ses = this.options.SES;

	        this.name = 'SESTransport';
	        this.version = packageData.version;

	        this.logger = shared.getLogger(this.options, {
	            component: this.options.component || 'ses-transport'
	        });
	    }

	    getRegion(cb) {
	        if (this.ses.sesClient.config && typeof this.ses.sesClient.config.region === 'function') {
	            // promise
	            return this.ses.sesClient.config
	                .region()
	                .then(region => cb(null, region))
	                .catch(err => cb(err));
	        }
	        return cb(null, false);
	    }

	    /**
	     * Compiles a mailcomposer message and forwards it to SES
	     *
	     * @param {Object} emailMessage MailComposer object
	     * @param {Function} callback Callback function to run when the sending is completed
	     */
	    send(mail, callback) {

	        let fromHeader = mail.message._headers.find(header => /^from$/i.test(header.key));
	        if (fromHeader) {
	            let mimeNode = new MimeNode('text/plain');
	            fromHeader = mimeNode._convertAddresses(mimeNode._parseAddresses(fromHeader.value));
	        }

	        let envelope = mail.data.envelope || mail.message.getEnvelope();
	        let messageId = mail.message.messageId();

	        let recipients = [].concat(envelope.to || []);
	        if (recipients.length > 3) {
	            recipients.push('...and ' + recipients.splice(2).length + ' more');
	        }
	        this.logger.info(
	            {
	                tnx: 'send',
	                messageId
	            },
	            'Sending message %s to <%s>',
	            messageId,
	            recipients.join(', ')
	        );

	        let getRawMessage = next => {
	            // do not use Message-ID and Date in DKIM signature
	            if (!mail.data._dkim) {
	                mail.data._dkim = {};
	            }
	            if (mail.data._dkim.skipFields && typeof mail.data._dkim.skipFields === 'string') {
	                mail.data._dkim.skipFields += ':date:message-id';
	            } else {
	                mail.data._dkim.skipFields = 'date:message-id';
	            }

	            let sourceStream = mail.message.createReadStream();
	            let stream = sourceStream.pipe(new LeWindows());
	            let chunks = [];
	            let chunklen = 0;

	            stream.on('readable', () => {
	                let chunk;
	                while ((chunk = stream.read()) !== null) {
	                    chunks.push(chunk);
	                    chunklen += chunk.length;
	                }
	            });

	            sourceStream.once('error', err => stream.emit('error', err));

	            stream.once('error', err => {
	                next(err);
	            });

	            stream.once('end', () => next(null, Buffer.concat(chunks, chunklen)));
	        };

	        setImmediate(() =>
	            getRawMessage((err, raw) => {
	                if (err) {
	                    this.logger.error(
	                        {
	                            err,
	                            tnx: 'send',
	                            messageId
	                        },
	                        'Failed creating message for %s. %s',
	                        messageId,
	                        err.message
	                    );
	                    return callback(err);
	                }

	                let sesMessage = {
	                    Content: {
	                        Raw: {
	                            // required
	                            Data: raw // required
	                        }
	                    },
	                    FromEmailAddress: fromHeader ? fromHeader : envelope.from,
	                    Destination: {
	                        ToAddresses: envelope.to
	                    }
	                };

	                Object.keys(mail.data.ses || {}).forEach(key => {
	                    sesMessage[key] = mail.data.ses[key];
	                });

	                this.getRegion((err, region) => {
	                    if (err || !region) {
	                        region = 'us-east-1';
	                    }

	                    const command = new this.ses.SendEmailCommand(sesMessage);
	                    const sendPromise = this.ses.sesClient.send(command);

	                    sendPromise
	                        .then(data => {
	                            if (region === 'us-east-1') {
	                                region = 'email';
	                            }
	                            callback(null, {
	                                envelope: {
	                                    from: envelope.from,
	                                    to: envelope.to
	                                },
	                                messageId: '<' + data.MessageId + (!/@/.test(data.MessageId) ? '@' + region + '.amazonses.com' : '') + '>',
	                                response: data.MessageId,
	                                raw
	                            });
	                        })
	                        .catch(err => {
	                            this.logger.error(
	                                {
	                                    err,
	                                    tnx: 'send'
	                                },
	                                'Send error for %s: %s',
	                                messageId,
	                                err.message
	                            );
	                            callback(err);
	                        });
	                });
	            })
	        );
	    }

	    /**
	     * Verifies SES configuration
	     *
	     * @param {Function} callback Callback function
	     */
	    verify(callback) {
	        let promise;
	        if (!callback) {
	            promise = new Promise((resolve, reject) => {
	                callback = shared.callbackPromise(resolve, reject);
	            });
	        }

	        const cb = err => {
	            if (err && !['InvalidParameterValue', 'MessageRejected'].includes(err.code || err.Code || err.name)) {
	                return callback(err);
	            }
	            return callback(null, true);
	        };

	        const sesMessage = {
	            Content: {
	                Raw: {
	                    Data: Buffer.from('From: <invalid@invalid>\r\nTo: <invalid@invalid>\r\n Subject: Invalid\r\n\r\nInvalid')
	                }
	            },
	            FromEmailAddress: 'invalid@invalid',
	            Destination: {
	                ToAddresses: ['invalid@invalid']
	            }
	        };

	        this.getRegion((err, region) => {

	            const command = new this.ses.SendEmailCommand(sesMessage);
	            const sendPromise = this.ses.sesClient.send(command);

	            sendPromise.then(data => cb(null)).catch(err => cb(err));
	        });

	        return promise;
	    }
	}

	sesTransport = SESTransport;
	return sesTransport;
}

var hasRequiredNodemailer;

function requireNodemailer () {
	if (hasRequiredNodemailer) return nodemailer$2;
	hasRequiredNodemailer = 1;

	const Mailer = requireMailer();
	const shared = requireShared();
	const SMTPPool = requireSmtpPool();
	const SMTPTransport = requireSmtpTransport();
	const SendmailTransport = requireSendmailTransport();
	const StreamTransport = requireStreamTransport();
	const JSONTransport = requireJsonTransport();
	const SESTransport = requireSesTransport();
	const nmfetch = requireFetch();
	const packageData = require$$9;

	const ETHEREAL_API = (process.env.ETHEREAL_API || 'https://api.nodemailer.com').replace(/\/+$/, '');
	const ETHEREAL_WEB = (process.env.ETHEREAL_WEB || 'https://ethereal.email').replace(/\/+$/, '');
	const ETHEREAL_API_KEY = (process.env.ETHEREAL_API_KEY || '').replace(/\s*/g, '') || null;
	const ETHEREAL_CACHE = ['true', 'yes', 'y', '1'].includes((process.env.ETHEREAL_CACHE || 'yes').toString().trim().toLowerCase());

	let testAccount = false;

	nodemailer$2.createTransport = function (transporter, defaults) {
	    let urlConfig;
	    let options;
	    let mailer;

	    if (
	        // provided transporter is a configuration object, not transporter plugin
	        (typeof transporter === 'object' && typeof transporter.send !== 'function') ||
	        // provided transporter looks like a connection url
	        (typeof transporter === 'string' && /^(smtps?|direct):/i.test(transporter))
	    ) {
	        if ((urlConfig = typeof transporter === 'string' ? transporter : transporter.url)) {
	            // parse a configuration URL into configuration options
	            options = shared.parseConnectionUrl(urlConfig);
	        } else {
	            options = transporter;
	        }

	        if (options.pool) {
	            transporter = new SMTPPool(options);
	        } else if (options.sendmail) {
	            transporter = new SendmailTransport(options);
	        } else if (options.streamTransport) {
	            transporter = new StreamTransport(options);
	        } else if (options.jsonTransport) {
	            transporter = new JSONTransport(options);
	        } else if (options.SES) {
	            if (options.SES.ses && options.SES.aws) {
	                let error = new Error(
	                    'Using legacy SES configuration, expecting @aws-sdk/client-sesv2, see https://nodemailer.com/transports/ses/'
	                );
	                error.code = 'LegacyConfig';
	                throw error;
	            }
	            transporter = new SESTransport(options);
	        } else {
	            transporter = new SMTPTransport(options);
	        }
	    }

	    mailer = new Mailer(transporter, options, defaults);

	    return mailer;
	};

	nodemailer$2.createTestAccount = function (apiUrl, callback) {
	    let promise;

	    if (!callback && typeof apiUrl === 'function') {
	        callback = apiUrl;
	        apiUrl = false;
	    }

	    if (!callback) {
	        promise = new Promise((resolve, reject) => {
	            callback = shared.callbackPromise(resolve, reject);
	        });
	    }

	    if (ETHEREAL_CACHE && testAccount) {
	        setImmediate(() => callback(null, testAccount));
	        return promise;
	    }

	    apiUrl = apiUrl || ETHEREAL_API;

	    let chunks = [];
	    let chunklen = 0;

	    let requestHeaders = {};
	    let requestBody = {
	        requestor: packageData.name,
	        version: packageData.version
	    };

	    if (ETHEREAL_API_KEY) {
	        requestHeaders.Authorization = 'Bearer ' + ETHEREAL_API_KEY;
	    }

	    let req = nmfetch(apiUrl + '/user', {
	        contentType: 'application/json',
	        method: 'POST',
	        headers: requestHeaders,
	        body: Buffer.from(JSON.stringify(requestBody))
	    });

	    req.on('readable', () => {
	        let chunk;
	        while ((chunk = req.read()) !== null) {
	            chunks.push(chunk);
	            chunklen += chunk.length;
	        }
	    });

	    req.once('error', err => callback(err));

	    req.once('end', () => {
	        let res = Buffer.concat(chunks, chunklen);
	        let data;
	        let err;
	        try {
	            data = JSON.parse(res.toString());
	        } catch (E) {
	            err = E;
	        }
	        if (err) {
	            return callback(err);
	        }
	        if (data.status !== 'success' || data.error) {
	            return callback(new Error(data.error || 'Request failed'));
	        }
	        delete data.status;
	        testAccount = data;
	        callback(null, testAccount);
	    });

	    return promise;
	};

	nodemailer$2.getTestMessageUrl = function (info) {
	    if (!info || !info.response) {
	        return false;
	    }

	    let infoProps = new Map();
	    info.response.replace(/\[([^\]]+)\]$/, (m, props) => {
	        props.replace(/\b([A-Z0-9]+)=([^\s]+)/g, (m, key, value) => {
	            infoProps.set(key, value);
	        });
	    });

	    if (infoProps.has('STATUS') && infoProps.has('MSGID')) {
	        return (testAccount.web || ETHEREAL_WEB) + '/message/' + infoProps.get('MSGID');
	    }

	    return false;
	};
	return nodemailer$2;
}

var nodemailerExports = requireNodemailer();
var nodemailer = /*@__PURE__*/getDefaultExportFromCjs(nodemailerExports);

var nodemailer$1 = /*#__PURE__*/_mergeNamespaces({
  __proto__: null,
  default: nodemailer
}, [nodemailerExports]);

// src/utils/html.ts
var HtmlEscapedCallbackPhase = {
  Stringify: 1};
var raw = (value, callbacks) => {
  const escapedString = new String(value);
  escapedString.isEscaped = true;
  escapedString.callbacks = callbacks;
  return escapedString;
};
var escapeRe = /[&<>'"]/;
var stringBufferToString = async (buffer, callbacks) => {
  let str = "";
  callbacks ||= [];
  const resolvedBuffer = await Promise.all(buffer);
  for (let i = resolvedBuffer.length - 1; ; i--) {
    str += resolvedBuffer[i];
    i--;
    if (i < 0) {
      break;
    }
    let r = resolvedBuffer[i];
    if (typeof r === "object") {
      callbacks.push(...r.callbacks || []);
    }
    const isEscaped = r.isEscaped;
    r = await (typeof r === "object" ? r.toString() : r);
    if (typeof r === "object") {
      callbacks.push(...r.callbacks || []);
    }
    if (r.isEscaped ?? isEscaped) {
      str += r;
    } else {
      const buf = [str];
      escapeToBuffer(r, buf);
      str = buf[0];
    }
  }
  return raw(str, callbacks);
};
var escapeToBuffer = (str, buffer) => {
  const match = str.search(escapeRe);
  if (match === -1) {
    buffer[0] += str;
    return;
  }
  let escape;
  let index;
  let lastIndex = 0;
  for (index = match; index < str.length; index++) {
    switch (str.charCodeAt(index)) {
      case 34:
        escape = "&quot;";
        break;
      case 39:
        escape = "&#39;";
        break;
      case 38:
        escape = "&amp;";
        break;
      case 60:
        escape = "&lt;";
        break;
      case 62:
        escape = "&gt;";
        break;
      default:
        continue;
    }
    buffer[0] += str.substring(lastIndex, index) + escape;
    lastIndex = index + 1;
  }
  buffer[0] += str.substring(lastIndex, index);
};
var resolveCallbackSync = (str) => {
  const callbacks = str.callbacks;
  if (!callbacks?.length) {
    return str;
  }
  const buffer = [str];
  const context = {};
  callbacks.forEach((c) => c({ phase: HtmlEscapedCallbackPhase.Stringify, buffer, context }));
  return buffer[0];
};

// src/helper/html/index.ts
var html = (strings, ...values) => {
  const buffer = [""];
  for (let i = 0, len = strings.length - 1; i < len; i++) {
    buffer[0] += strings[i];
    const children = Array.isArray(values[i]) ? values[i].flat(Infinity) : [values[i]];
    for (let i2 = 0, len2 = children.length; i2 < len2; i2++) {
      const child = children[i2];
      if (typeof child === "string") {
        escapeToBuffer(child, buffer);
      } else if (typeof child === "number") {
        buffer[0] += child;
      } else if (typeof child === "boolean" || child === null || child === void 0) {
        continue;
      } else if (typeof child === "object" && child.isEscaped) {
        if (child.callbacks) {
          buffer.unshift("", child);
        } else {
          const tmp = child.toString();
          if (tmp instanceof Promise) {
            buffer.unshift("", tmp);
          } else {
            buffer[0] += tmp;
          }
        }
      } else if (child instanceof Promise) {
        buffer.unshift("", child);
      } else {
        escapeToBuffer(child.toString(), buffer);
      }
    }
  }
  buffer[0] += strings.at(-1);
  return buffer.length === 1 ? "callbacks" in buffer ? raw(resolveCallbackSync(raw(buffer[0], buffer.callbacks))) : raw(buffer[0]) : stringBufferToString(buffer, buffer.callbacks);
};

const __filename = fileURLToPath$1(import.meta.url);
const __dirname$1 = dirname(__filename);
const cssPath = join(__dirname$1, "../styles/main.css");
let cachedCSS = null;
function getCSS() {
  if (!cachedCSS) {
    cachedCSS = readFileSync(cssPath, "utf-8");
  }
  return cachedCSS;
}
function BaseLayout(props) {
  const {
    title = "Identity Provider",
    content = "",
    user = null,
    config = {},
    error = null,
    success = null
  } = props;
  const theme = {
    title: config.title || "S3DB Identity",
    logo: config.logo || null,
    logoUrl: config.logoUrl || null,
    favicon: config.favicon || null,
    registrationEnabled: config.registrationEnabled !== false,
    // Show register link
    // Colors
    primaryColor: config.primaryColor || "#007bff",
    secondaryColor: config.secondaryColor || "#6c757d",
    successColor: config.successColor || "#28a745",
    dangerColor: config.dangerColor || "#dc3545",
    warningColor: config.warningColor || "#ffc107",
    infoColor: config.infoColor || "#17a2b8",
    // Text colors
    textColor: config.textColor || "#212529",
    textMuted: config.textMuted || "#6c757d",
    // Background colors
    backgroundColor: config.backgroundColor || "#ffffff",
    backgroundLight: config.backgroundLight || "#f8f9fa",
    borderColor: config.borderColor || "#dee2e6",
    // Typography
    fontFamily: config.fontFamily || '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif',
    fontSize: config.fontSize || "16px",
    // Layout
    borderRadius: config.borderRadius || "0.375rem",
    boxShadow: config.boxShadow || "0 0.125rem 0.25rem rgba(0, 0, 0, 0.075)",
    // Company info
    companyName: config.companyName || "S3DB",
    tagline: config.tagline || "Secure Identity & Access Management",
    footerText: config.footerText || null,
    supportEmail: config.supportEmail || null,
    privacyUrl: config.privacyUrl || "/privacy",
    termsUrl: config.termsUrl || "/terms",
    // Social links
    socialLinks: config.socialLinks || null,
    // Custom CSS
    customCSS: config.customCSS || null
  };
  const themeCSS = `
    :root {
      --color-primary: ${theme.primaryColor};
      --color-secondary: ${theme.secondaryColor};
      --color-success: ${theme.successColor};
      --color-danger: ${theme.dangerColor};
      --color-warning: ${theme.warningColor};
      --color-info: ${theme.infoColor};

      --color-text: ${theme.textColor};
      --color-text-muted: ${theme.textMuted};

      --color-bg: ${theme.backgroundColor};
      --color-light: ${theme.backgroundLight};
      --color-border: ${theme.borderColor};

      --font-family: ${theme.fontFamily};
      --font-size-base: ${theme.fontSize};

      --border-radius: ${theme.borderRadius};
      --box-shadow: ${theme.boxShadow};
    }
  `;
  return html`<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="${theme.tagline}">
  <title>${title} - ${theme.title}</title>

  ${theme.favicon ? html`<link rel="icon" type="image/x-icon" href="${theme.favicon}">` : ""}

  <style>${getCSS()}</style>
  <style>${themeCSS}</style>
  ${theme.customCSS ? html`<style>${theme.customCSS}</style>` : ""}
</head>
<body>
  <header class="header">
    <div class="container">
      <div class="header-content">
        <a href="/" class="logo" style="display: flex; align-items: center; gap: 0.75rem; text-decoration: none; color: inherit;">
          ${theme.logoUrl ? html`<img src="${theme.logoUrl}" alt="${theme.title}" height="32" style="display: block;" />` : ""}
          <div style="display: flex; flex-direction: column;">
            <strong style="font-size: 1.125rem;">${theme.companyName}</strong>
            <small style="font-size: 0.75rem; color: var(--color-text-muted); margin-top: -0.125rem;">${theme.tagline}</small>
          </div>
        </a>
        <nav>
          <ul class="nav">
            ${user ? html`
              <li><a href="/profile">Profile</a></li>
              ${user.isAdmin || user.role === "admin" ? html`<li><a href="/admin">Admin</a></li>` : ""}
              <li>
                <form method="POST" action="/logout" style="display: inline;">
                  <button type="submit" class="btn-link" style="cursor: pointer;">Logout</button>
                </form>
              </li>
            ` : html`
              <li><a href="/login">Login</a></li>
              ${theme.registrationEnabled ? html`<li><a href="/register">Register</a></li>` : ""}
            `}
          </ul>
        </nav>
      </div>
    </div>
  </header>

  <main>
    ${error ? html`
      <div class="container">
        <div class="alert alert-danger" role="alert">
          ${error}
        </div>
      </div>
    ` : ""}

    ${success ? html`
      <div class="container">
        <div class="alert alert-success" role="alert">
          ${success}
        </div>
      </div>
    ` : ""}

    ${content}
  </main>

  <footer class="footer">
    <div class="container">
      <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 2rem; margin-bottom: 2rem;">
        <!-- Company Info -->
        <div>
          <h3 style="font-size: 1rem; margin-bottom: 0.75rem; color: var(--color-text);">${theme.companyName}</h3>
          <p style="font-size: 0.875rem; color: var(--color-text-muted); margin-bottom: 0.5rem;">
            ${theme.tagline}
          </p>
          ${theme.supportEmail ? html`
            <p style="font-size: 0.875rem; margin: 0;">
              <a href="mailto:${theme.supportEmail}" style="color: var(--color-primary);">
                ${theme.supportEmail}
              </a>
            </p>
          ` : ""}
        </div>

        <!-- Quick Links -->
        <div>
          <h3 style="font-size: 1rem; margin-bottom: 0.75rem; color: var(--color-text);">Quick Links</h3>
          <ul style="list-style: none; padding: 0; margin: 0; font-size: 0.875rem;">
            ${user ? html`
              <li style="margin-bottom: 0.5rem;"><a href="/profile" style="color: var(--color-text-muted);">Profile</a></li>
              ${user.isAdmin || user.role === "admin" ? html`
                <li style="margin-bottom: 0.5rem;"><a href="/admin" style="color: var(--color-text-muted);">Admin Dashboard</a></li>
              ` : ""}
            ` : html`
              <li style="margin-bottom: 0.5rem;"><a href="/login" style="color: var(--color-text-muted);">Sign In</a></li>
              <li style="margin-bottom: 0.5rem;"><a href="/register" style="color: var(--color-text-muted);">Create Account</a></li>
            `}
            <li style="margin-bottom: 0.5rem;"><a href="${theme.privacyUrl}" style="color: var(--color-text-muted);">Privacy Policy</a></li>
            <li style="margin-bottom: 0.5rem;"><a href="${theme.termsUrl}" style="color: var(--color-text-muted);">Terms of Service</a></li>
          </ul>
        </div>

        <!-- Social Links -->
        ${theme.socialLinks ? html`
          <div>
            <h3 style="font-size: 1rem; margin-bottom: 0.75rem; color: var(--color-text);">Connect</h3>
            <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
              ${theme.socialLinks.github ? html`
                <a href="${theme.socialLinks.github}" target="_blank" rel="noopener" style="color: var(--color-text-muted); font-size: 1.5rem;" title="GitHub">
                  <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                </a>
              ` : ""}
              ${theme.socialLinks.twitter ? html`
                <a href="${theme.socialLinks.twitter}" target="_blank" rel="noopener" style="color: var(--color-text-muted); font-size: 1.5rem;" title="Twitter">
                  <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"/></svg>
                </a>
              ` : ""}
              ${theme.socialLinks.linkedin ? html`
                <a href="${theme.socialLinks.linkedin}" target="_blank" rel="noopener" style="color: var(--color-text-muted); font-size: 1.5rem;" title="LinkedIn">
                  <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                </a>
              ` : ""}
            </div>
          </div>
        ` : ""}
      </div>

      <div style="border-top: 1px solid var(--color-border); padding-top: 1.5rem; text-align: center;">
        ${theme.footerText ? html`
          <p style="font-size: 0.875rem; color: var(--color-text-muted); margin-bottom: 0.5rem;">
            ${theme.footerText}
          </p>
        ` : ""}
        <p style="font-size: 0.875rem; color: var(--color-text-muted); margin: 0;">
          © ${(/* @__PURE__ */ new Date()).getFullYear()} ${theme.companyName}. All rights reserved.
          <span style="margin: 0 0.5rem;">•</span>
          Powered by <a href="https://github.com/forattini-dev/s3db.js" target="_blank" style="color: var(--color-primary);">S3DB Identity</a>
        </p>
      </div>
    </div>
  </footer>
</body>
</html>`;
}

function LoginPage(props = {}) {
  const { error = null, success = null, email = "", config = {} } = props;
  const content = html`
    <div class="auth-container">
      <div class="auth-card">
        <div class="card">
          <div class="card-header">
            Sign In
          </div>

          <form method="POST" action="/login">
            <div class="form-group">
              <label for="email" class="form-label form-label-required">Email address</label>
              <input
                type="email"
                class="form-control ${error ? "is-invalid" : ""}"
                id="email"
                name="email"
                value="${email}"
                required
                autofocus
                autocomplete="email"
              />
            </div>

            <div class="form-group">
              <label for="password" class="form-label form-label-required">Password</label>
              <input
                type="password"
                class="form-control ${error ? "is-invalid" : ""}"
                id="password"
                name="password"
                required
                autocomplete="current-password"
              />
              ${error ? html`<div class="invalid-feedback">${error}</div>` : ""}
            </div>

            <div class="form-group">
              <div class="form-check">
                <input
                  type="checkbox"
                  class="form-check-input"
                  id="remember"
                  name="remember"
                  value="1"
                />
                <label class="form-check-label" for="remember">
                  Remember me
                </label>
              </div>
            </div>

            <button type="submit" class="btn btn-primary btn-block">
              Sign In
            </button>
          </form>

          <div class="auth-links">
            <p class="text-muted">
              <a href="/forgot-password" class="btn-link">Forgot your password?</a>
            </p>
            ${config.registrationEnabled !== false ? html`
              <p class="mt-3">
                Don't have an account? <a href="/register" class="btn-link">Sign up</a>
              </p>
            ` : ""}
          </div>
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "Sign In",
    content,
    config,
    error: null,
    // Error shown in form
    success
    // Success shown at top
  });
}

function RegisterPage(props = {}) {
  const { error = null, email = "", name = "", passwordPolicy = {}, config = {} } = props;
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const content = html`
    <div class="auth-container">
      <div class="auth-card">
        <div class="card">
          <div class="card-header">
            Create Account
          </div>

          <form method="POST" action="/register">
            <div class="form-group">
              <label for="name" class="form-label form-label-required">Full Name</label>
              <input
                type="text"
                class="form-control ${error ? "is-invalid" : ""}"
                id="name"
                name="name"
                value="${name}"
                required
                autofocus
                autocomplete="name"
                minlength="2"
                maxlength="100"
              />
            </div>

            <div class="form-group">
              <label for="email" class="form-label form-label-required">Email address</label>
              <input
                type="email"
                class="form-control ${error ? "is-invalid" : ""}"
                id="email"
                name="email"
                value="${email}"
                required
                autocomplete="email"
              />
              <small class="form-text">We'll send you a verification email</small>
            </div>

            <div class="form-group">
              <label for="password" class="form-label form-label-required">Password</label>
              <input
                type="password"
                class="form-control ${error ? "is-invalid" : ""}"
                id="password"
                name="password"
                required
                autocomplete="new-password"
                minlength="${minLength}"
                maxlength="${maxLength}"
              />
              <small class="form-text">
                Must contain: ${requirements.join(", ")}
              </small>
            </div>

            <div class="form-group">
              <label for="confirm_password" class="form-label form-label-required">Confirm Password</label>
              <input
                type="password"
                class="form-control ${error ? "is-invalid" : ""}"
                id="confirm_password"
                name="confirm_password"
                required
                autocomplete="new-password"
              />
              ${error ? html`<div class="invalid-feedback">${error}</div>` : ""}
            </div>

            <div class="form-group">
              <div class="form-check">
                <input
                  type="checkbox"
                  class="form-check-input"
                  id="agree_terms"
                  name="agree_terms"
                  value="1"
                  required
                />
                <label class="form-check-label" for="agree_terms">
                  I agree to the <a href="/terms" class="btn-link" target="_blank">Terms of Service</a> and <a href="/privacy" class="btn-link" target="_blank">Privacy Policy</a>
                </label>
              </div>
            </div>

            <button type="submit" class="btn btn-primary btn-block">
              Create Account
            </button>
          </form>

          <div class="auth-links">
            <p class="mt-3">
              Already have an account? <a href="/login" class="btn-link">Sign in</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "Create Account",
    content,
    config,
    error: null
    // Error shown in form
  });
}

function ForgotPasswordPage(props = {}) {
  const { error = null, success = null, email = "", config = {} } = props;
  const content = html`
    <div class="auth-container">
      <div class="auth-card">
        <div class="card">
          <div class="card-header">
            Reset Password
          </div>

          ${success ? html`
            <div class="alert alert-success" role="alert">
              ${success}
            </div>
            <div class="auth-links">
              <p class="mt-3">
                <a href="/login" class="btn-link">Back to Sign In</a>
              </p>
            </div>
          ` : html`
            <p class="text-muted mb-3">
              Enter your email address and we'll send you a link to reset your password.
            </p>

            <form method="POST" action="/forgot-password">
              <div class="form-group">
                <label for="email" class="form-label form-label-required">Email address</label>
                <input
                  type="email"
                  class="form-control ${error ? "is-invalid" : ""}"
                  id="email"
                  name="email"
                  value="${email}"
                  required
                  autofocus
                  autocomplete="email"
                />
                ${error ? html`<div class="invalid-feedback">${error}</div>` : ""}
              </div>

              <button type="submit" class="btn btn-primary btn-block">
                Send Reset Link
              </button>
            </form>

            <div class="auth-links">
              <p class="mt-3">
                Remember your password? <a href="/login" class="btn-link">Sign in</a>
              </p>
            </div>
          `}
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "Reset Password",
    content,
    config,
    error: null,
    // Error shown in form
    success: null
    // Success shown in form
  });
}

function ResetPasswordPage(props = {}) {
  const { error = null, token = "", passwordPolicy = {}, config = {} } = props;
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const content = html`
    <div class="auth-container">
      <div class="auth-card">
        <div class="card">
          <div class="card-header">
            Set New Password
          </div>

          <p class="text-muted mb-3">
            Choose a strong password for your account.
          </p>

          <form method="POST" action="/reset-password">
            <input type="hidden" name="token" value="${token}" />

            <div class="form-group">
              <label for="password" class="form-label form-label-required">New Password</label>
              <input
                type="password"
                class="form-control ${error ? "is-invalid" : ""}"
                id="password"
                name="password"
                required
                autofocus
                autocomplete="new-password"
                minlength="${minLength}"
                maxlength="${maxLength}"
              />
              <small class="form-text">
                Must contain: ${requirements.join(", ")}
              </small>
            </div>

            <div class="form-group">
              <label for="confirm_password" class="form-label form-label-required">Confirm New Password</label>
              <input
                type="password"
                class="form-control ${error ? "is-invalid" : ""}"
                id="confirm_password"
                name="confirm_password"
                required
                autocomplete="new-password"
              />
              ${error ? html`<div class="invalid-feedback">${error}</div>` : ""}
            </div>

            <button type="submit" class="btn btn-primary btn-block">
              Reset Password
            </button>
          </form>

          <div class="auth-links">
            <p class="mt-3">
              Remember your password? <a href="/login" class="btn-link">Sign in</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "Set New Password",
    content,
    config,
    error: null,
    // Error shown in form
    success: null
  });
}

function ProfilePage(props = {}) {
  const { user = {}, sessions = [], error = null, success = null, passwordPolicy = {}, config = {} } = props;
  const minLength = passwordPolicy.minLength || 8;
  const maxLength = passwordPolicy.maxLength || 128;
  const requireUppercase = passwordPolicy.requireUppercase !== false;
  const requireLowercase = passwordPolicy.requireLowercase !== false;
  const requireNumbers = passwordPolicy.requireNumbers !== false;
  const requireSymbols = passwordPolicy.requireSymbols || false;
  const requirements = [];
  requirements.push(`${minLength}-${maxLength} characters`);
  if (requireUppercase) requirements.push("uppercase letter");
  if (requireLowercase) requirements.push("lowercase letter");
  if (requireNumbers) requirements.push("number");
  if (requireSymbols) requirements.push("symbol");
  const content = html`
    <div class="container">
      <h1 class="mb-4">My Profile</h1>

      <!-- Profile Information Card -->
      <div class="card mb-4">
        <div class="card-header">
          Profile Information
        </div>
        <form method="POST" action="/profile/update">
          <div class="p-3">
            <div class="form-group">
              <label for="name" class="form-label form-label-required">Full Name</label>
              <input
                type="text"
                class="form-control"
                id="name"
                name="name"
                value="${user.name || ""}"
                required
                minlength="2"
                maxlength="100"
              />
            </div>

            <div class="form-group">
              <label for="email" class="form-label form-label-required">Email Address</label>
              <input
                type="email"
                class="form-control"
                id="email"
                name="email"
                value="${user.email || ""}"
                required
                autocomplete="email"
              />
              ${user.emailVerified ? html`<small class="form-text text-success">✓ Verified</small>` : html`<small class="form-text text-danger">⚠ Not verified - <a href="/verify-email/resend" class="btn-link">Resend verification email</a></small>`}
            </div>

            <div class="form-group mb-0">
              <button type="submit" class="btn btn-primary">
                Save Changes
              </button>
            </div>
          </div>
        </form>
      </div>

      <!-- Change Password Card -->
      <div class="card mb-4">
        <div class="card-header">
          Change Password
        </div>
        <form method="POST" action="/profile/change-password">
          <div class="p-3">
            <div class="form-group">
              <label for="current_password" class="form-label form-label-required">Current Password</label>
              <input
                type="password"
                class="form-control"
                id="current_password"
                name="current_password"
                required
                autocomplete="current-password"
              />
            </div>

            <div class="form-group">
              <label for="new_password" class="form-label form-label-required">New Password</label>
              <input
                type="password"
                class="form-control"
                id="new_password"
                name="new_password"
                required
                autocomplete="new-password"
                minlength="${minLength}"
                maxlength="${maxLength}"
              />
              <small class="form-text">
                Must contain: ${requirements.join(", ")}
              </small>
            </div>

            <div class="form-group">
              <label for="confirm_new_password" class="form-label form-label-required">Confirm New Password</label>
              <input
                type="password"
                class="form-control"
                id="confirm_new_password"
                name="confirm_new_password"
                required
                autocomplete="new-password"
              />
            </div>

            <div class="form-group mb-0">
              <button type="submit" class="btn btn-primary">
                Change Password
              </button>
            </div>
          </div>
        </form>
      </div>

      <!-- Active Sessions Card -->
      <div class="card mb-4">
        <div class="card-header">
          Active Sessions
          <span class="badge" style="background-color: var(--color-primary); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem; margin-left: 0.5rem;">
            ${sessions.length}
          </span>
        </div>
        <div class="p-3">
          ${sessions.length === 0 ? html`
            <p class="text-muted">No active sessions</p>
          ` : html`
            <p class="text-muted mb-3">
              You are currently logged in on these devices. If you see a session you don't recognize, log it out immediately.
            </p>

            ${sessions.map((session, index) => {
    const isCurrentSession = session.isCurrent;
    const createdAt = new Date(session.createdAt);
    const expiresAt = new Date(session.expiresAt);
    return html`
                <div class="session-item" style="border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: 1rem; margin-bottom: 1rem; ${isCurrentSession ? "background-color: #f0f9ff;" : ""}">
                  <div style="display: flex; justify-content: space-between; align-items: start;">
                    <div style="flex: 1;">
                      <div style="font-weight: 500; margin-bottom: 0.5rem;">
                        ${session.userAgent || "Unknown device"}
                        ${isCurrentSession ? html`<span class="badge" style="background-color: var(--color-success); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem; margin-left: 0.5rem;">Current</span>` : ""}
                      </div>
                      <div style="font-size: 0.875rem; color: var(--color-text-muted);">
                        <div>IP: ${session.ipAddress || "Unknown"}</div>
                        <div>Created: ${createdAt.toLocaleString()}</div>
                        <div>Expires: ${expiresAt.toLocaleString()}</div>
                      </div>
                    </div>
                    ${!isCurrentSession ? html`
                      <form method="POST" action="/profile/logout-session" style="margin: 0;">
                        <input type="hidden" name="session_id" value="${session.id}" />
                        <button type="submit" class="btn btn-danger" style="font-size: 0.875rem; padding: 0.5rem 1rem;">
                          Logout
                        </button>
                      </form>
                    ` : ""}
                  </div>
                </div>
              `;
  })}

            ${sessions.length > 1 ? html`
              <form method="POST" action="/profile/logout-all-sessions" style="margin-top: 1rem;">
                <button type="submit" class="btn btn-danger">
                  Logout All Other Sessions
                </button>
              </form>
            ` : ""}
          `}
        </div>
      </div>

      <!-- Account Information Card -->
      <div class="card mb-4">
        <div class="card-header">
          Account Information
        </div>
        <div class="p-3">
          <div class="info-row" style="display: flex; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
            <div style="font-weight: 500; width: 200px;">Account Status:</div>
            <div>
              ${user.status === "active" ? html`<span style="color: var(--color-success);">✓ Active</span>` : ""}
              ${user.status === "pending_verification" ? html`<span style="color: var(--color-warning);">⏳ Pending Verification</span>` : ""}
              ${user.status === "suspended" ? html`<span style="color: var(--color-danger);">⚠ Suspended</span>` : ""}
            </div>
          </div>
          ${user.isAdmin ? html`
            <div class="info-row" style="display: flex; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <div style="font-weight: 500; width: 200px;">Role:</div>
              <div><span style="color: var(--color-primary);">👑 Administrator</span></div>
            </div>
          ` : ""}
          ${user.lastLoginAt ? html`
            <div class="info-row" style="display: flex; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <div style="font-weight: 500; width: 200px;">Last Login:</div>
              <div>${new Date(user.lastLoginAt).toLocaleString()}</div>
            </div>
          ` : ""}
          ${user.lastLoginIp ? html`
            <div class="info-row" style="display: flex; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <div style="font-weight: 500; width: 200px;">Last Login IP:</div>
              <div>${user.lastLoginIp}</div>
            </div>
          ` : ""}
          ${user.createdAt ? html`
            <div class="info-row" style="display: flex; padding: 0.5rem 0;">
              <div style="font-weight: 500; width: 200px;">Member Since:</div>
              <div>${new Date(user.createdAt).toLocaleDateString()}</div>
            </div>
          ` : ""}
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "My Profile",
    content,
    config,
    user,
    error,
    success
  });
}

function AdminDashboardPage(props = {}) {
  const { stats = {}, user = {}, config = {} } = props;
  const content = html`
    <div class="container">
      <h1 class="mb-4">Admin Dashboard</h1>

      <!-- Statistics Cards -->
      <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin-bottom: 2rem;">
        <!-- Users Card -->
        <div class="card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
          <div class="p-3">
            <div style="font-size: 0.875rem; opacity: 0.9; margin-bottom: 0.5rem;">Total Users</div>
            <div style="font-size: 2rem; font-weight: bold;">${stats.totalUsers || 0}</div>
            <div style="font-size: 0.875rem; opacity: 0.9; margin-top: 0.5rem;">
              ${stats.activeUsers || 0} active · ${stats.pendingUsers || 0} pending
            </div>
          </div>
        </div>

        <!-- OAuth2 Clients Card -->
        <div class="card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white;">
          <div class="p-3">
            <div style="font-size: 0.875rem; opacity: 0.9; margin-bottom: 0.5rem;">OAuth2 Clients</div>
            <div style="font-size: 2rem; font-weight: bold;">${stats.totalClients || 0}</div>
            <div style="font-size: 0.875rem; opacity: 0.9; margin-top: 0.5rem;">
              ${stats.activeClients || 0} active
            </div>
          </div>
        </div>

        <!-- Sessions Card -->
        <div class="card" style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white;">
          <div class="p-3">
            <div style="font-size: 0.875rem; opacity: 0.9; margin-bottom: 0.5rem;">Active Sessions</div>
            <div style="font-size: 2rem; font-weight: bold;">${stats.activeSessions || 0}</div>
            <div style="font-size: 0.875rem; opacity: 0.9; margin-top: 0.5rem;">
              ${stats.uniqueUsers || 0} unique users
            </div>
          </div>
        </div>

        <!-- Auth Codes Card -->
        <div class="card" style="background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); color: white;">
          <div class="p-3">
            <div style="font-size: 0.875rem; opacity: 0.9; margin-bottom: 0.5rem;">Auth Codes</div>
            <div style="font-size: 2rem; font-weight: bold;">${stats.totalAuthCodes || 0}</div>
            <div style="font-size: 0.875rem; opacity: 0.9; margin-top: 0.5rem;">
              ${stats.unusedAuthCodes || 0} unused
            </div>
          </div>
        </div>
      </div>

      <!-- Quick Actions -->
      <div class="card mb-4">
        <div class="card-header">
          Quick Actions
        </div>
        <div class="p-3">
          <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem;">
            <a href="/admin/clients" class="btn btn-primary" style="text-decoration: none; text-align: center;">
              📱 Manage Clients
            </a>
            <a href="/admin/users" class="btn btn-primary" style="text-decoration: none; text-align: center;">
              👥 Manage Users
            </a>
            <a href="/admin/sessions" class="btn btn-primary" style="text-decoration: none; text-align: center;">
              🔐 View Sessions
            </a>
            <a href="/admin/auth-codes" class="btn btn-primary" style="text-decoration: none; text-align: center;">
              🎫 Auth Codes
            </a>
          </div>
        </div>
      </div>

      <!-- Recent Activity -->
      ${stats.recentUsers && stats.recentUsers.length > 0 ? html`
        <div class="card mb-4">
          <div class="card-header">
            Recent Users
          </div>
          <div class="p-3">
            <table style="width: 100%; border-collapse: collapse;">
              <thead>
                <tr style="border-bottom: 2px solid var(--color-border);">
                  <th style="text-align: left; padding: 0.75rem; font-weight: 500;">Email</th>
                  <th style="text-align: left; padding: 0.75rem; font-weight: 500;">Name</th>
                  <th style="text-align: left; padding: 0.75rem; font-weight: 500;">Status</th>
                  <th style="text-align: left; padding: 0.75rem; font-weight: 500;">Created</th>
                </tr>
              </thead>
              <tbody>
                ${stats.recentUsers.map((user2) => html`
                  <tr style="border-bottom: 1px solid var(--color-border);">
                    <td style="padding: 0.75rem;">${user2.email}</td>
                    <td style="padding: 0.75rem;">${user2.name}</td>
                    <td style="padding: 0.75rem;">
                      <span class="badge" style="background-color: ${user2.status === "active" ? "var(--color-success)" : user2.status === "suspended" ? "var(--color-danger)" : "var(--color-warning)"}; color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem;">
                        ${user2.status}
                      </span>
                    </td>
                    <td style="padding: 0.75rem; color: var(--color-text-muted); font-size: 0.875rem;">
                      ${new Date(user2.createdAt).toLocaleDateString()}
                    </td>
                  </tr>
                `)}
              </tbody>
            </table>
          </div>
        </div>
      ` : ""}

      <!-- System Information -->
      <div class="card">
        <div class="card-header">
          System Information
        </div>
        <div class="p-3">
          <div style="display: grid; gap: 0.5rem;">
            <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <span style="font-weight: 500;">Identity Provider:</span>
              <span>${config.title || "S3DB Identity"}</span>
            </div>
            <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <span style="font-weight: 500;">Your Role:</span>
              <span style="color: var(--color-primary);">Administrator</span>
            </div>
            ${stats.serverUptime ? html`
              <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
                <span style="font-weight: 500;">Server Uptime:</span>
                <span>${stats.serverUptime}</span>
              </div>
            ` : ""}
            <div style="display: flex; justify-content: space-between; padding: 0.5rem 0;">
              <span style="font-weight: 500;">Database Type:</span>
              <span>S3DB (S3-based Document Database)</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "Admin Dashboard",
    content,
    config,
    user
  });
}

function AdminClientsPage(props = {}) {
  const { clients = [], user = {}, error = null, success = null, config = {} } = props;
  const content = html`
    <div class="container">
      <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 2rem;">
        <h1>OAuth2 Clients</h1>
        <a href="/admin/clients/new" class="btn btn-primary">
          + New Client
        </a>
      </div>

      ${clients.length === 0 ? html`
        <div class="card">
          <div class="p-3 text-center">
            <p class="text-muted">No OAuth2 clients registered yet.</p>
            <a href="/admin/clients/new" class="btn btn-primary mt-3">
              Create Your First Client
            </a>
          </div>
        </div>
      ` : html`
        <div style="display: grid; gap: 1.5rem;">
          ${clients.map((client) => {
    const grantTypes = Array.isArray(client.grantTypes) ? client.grantTypes : [];
    const allowedScopes = Array.isArray(client.allowedScopes) ? client.allowedScopes : [];
    const redirectUris = Array.isArray(client.redirectUris) ? client.redirectUris : [];
    return html`
              <div class="card">
                <div class="card-header" style="display: flex; justify-content: space-between; align-items: center;">
                  <div>
                    <strong>${client.name}</strong>
                    ${!client.active ? html`
                      <span class="badge" style="background-color: var(--color-danger); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem; margin-left: 0.5rem;">
                        Inactive
                      </span>
                    ` : ""}
                  </div>
                  <div style="display: flex; gap: 0.5rem;">
                    <a href="/admin/clients/${client.id}/edit" class="btn btn-secondary" style="font-size: 0.875rem; padding: 0.5rem 1rem;">
                      Edit
                    </a>
                    <form method="POST" action="/admin/clients/${client.id}/delete" style="margin: 0; display: inline;">
                      <button
                        type="submit"
                        class="btn btn-danger"
                        style="font-size: 0.875rem; padding: 0.5rem 1rem;"
                        onclick="return confirm('Are you sure you want to delete this client? This action cannot be undone.')"
                      >
                        Delete
                      </button>
                    </form>
                  </div>
                </div>
                <div class="p-3">
                  <div style="display: grid; gap: 1rem;">
                    <!-- Client ID -->
                    <div>
                      <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                        Client ID
                      </div>
                      <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem; word-break: break-all;">
                        ${client.clientId}
                      </code>
                    </div>

                    <!-- Redirect URIs -->
                    ${redirectUris.length > 0 ? html`
                      <div>
                        <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                          Redirect URIs (${redirectUris.length})
                        </div>
                        <div style="display: flex; flex-wrap: wrap; gap: 0.5rem;">
                          ${redirectUris.map((uri) => html`
                            <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem;">
                              ${uri}
                            </code>
                          `)}
                        </div>
                      </div>
                    ` : ""}

                    <!-- Grant Types -->
                    ${grantTypes.length > 0 ? html`
                      <div>
                        <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                          Grant Types
                        </div>
                        <div style="display: flex; flex-wrap: wrap; gap: 0.5rem;">
                          ${grantTypes.map((type) => html`
                            <span class="badge" style="background-color: var(--color-primary); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem;">
                              ${type}
                            </span>
                          `)}
                        </div>
                      </div>
                    ` : ""}

                    <!-- Allowed Scopes -->
                    ${allowedScopes.length > 0 ? html`
                      <div>
                        <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                          Allowed Scopes
                        </div>
                        <div style="display: flex; flex-wrap: wrap; gap: 0.5rem;">
                          ${allowedScopes.map((scope) => html`
                            <span class="badge" style="background-color: var(--color-success); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem;">
                              ${scope}
                            </span>
                          `)}
                        </div>
                      </div>
                    ` : ""}

                    <!-- Created Date -->
                    ${client.createdAt ? html`
                      <div style="color: var(--color-text-muted); font-size: 0.875rem;">
                        Created: ${new Date(client.createdAt).toLocaleString()}
                      </div>
                    ` : ""}
                  </div>

                  <!-- Actions -->
                  <div style="margin-top: 1.5rem; padding-top: 1.5rem; border-top: 1px solid var(--color-border); display: flex; gap: 1rem;">
                    <form method="POST" action="/admin/clients/${client.id}/rotate-secret" style="margin: 0;">
                      <button type="submit" class="btn btn-secondary" style="font-size: 0.875rem;">
                        🔄 Rotate Secret
                      </button>
                    </form>
                    <form method="POST" action="/admin/clients/${client.id}/toggle-active" style="margin: 0;">
                      <button type="submit" class="btn ${client.active ? "btn-danger" : "btn-success"}" style="font-size: 0.875rem;">
                        ${client.active ? "\u{1F534} Deactivate" : "\u{1F7E2} Activate"}
                      </button>
                    </form>
                  </div>
                </div>
              </div>
            `;
  })}
        </div>
      `}
    </div>
  `;
  return BaseLayout({
    title: "OAuth2 Clients - Admin",
    content,
    config,
    user,
    error,
    success
  });
}

var __freeze = Object.freeze;
var __defProp = Object.defineProperty;
var __template = (cooked, raw) => __freeze(__defProp(cooked, "raw", { value: __freeze(raw || cooked.slice()) }));
var _a;
function AdminClientFormPage(props = {}) {
  const { client = null, user = {}, error = null, availableScopes = [], availableGrantTypes = [], config = {} } = props;
  const isEditMode = !!client;
  const clientData = client || {
    name: "",
    redirectUris: [""],
    grantTypes: ["authorization_code", "refresh_token"],
    allowedScopes: ["openid", "profile", "email"],
    active: true
  };
  const content = html(_a || (_a = __template(['\n    <div class="container-sm">\n      <div style="margin-bottom: 2rem;">\n        <a href="/admin/clients" class="btn-link" style="font-size: 0.875rem;">\u2190 Back to Clients</a>\n        <h1 class="mt-3">', ' OAuth2 Client</h1>\n      </div>\n\n      <div class="card">\n        <form method="POST" action="', '">\n          <div class="p-3">\n            <!-- Client Name -->\n            <div class="form-group">\n              <label for="name" class="form-label form-label-required">Client Name</label>\n              <input\n                type="text"\n                class="form-control ', '"\n                id="name"\n                name="name"\n                value="', '"\n                required\n                autofocus\n                placeholder="My Application"\n              />\n              <small class="form-text">A friendly name for this OAuth2 client</small>\n              ', '\n            </div>\n\n            <!-- Redirect URIs -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Redirect URIs</label>\n              <div id="redirect-uris-container">\n                ', '\n              </div>\n              <button type="button" class="btn btn-secondary mt-2" onclick="addRedirectUri()">\n                + Add Another URI\n              </button>\n              <small class="form-text">Where users will be redirected after authorization</small>\n            </div>\n\n            <!-- Grant Types -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Grant Types</label>\n              ', '\n              <small class="form-text">OAuth2 grant types this client can use</small>\n            </div>\n\n            <!-- Allowed Scopes -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Allowed Scopes</label>\n              ', '\n              <small class="form-text">Scopes this client is allowed to request</small>\n            </div>\n\n            <!-- Active Status -->\n            <div class="form-group">\n              <div class="form-check">\n                <input\n                  type="checkbox"\n                  class="form-check-input"\n                  id="active"\n                  name="active"\n                  value="1"\n                  ', '\n                />\n                <label class="form-check-label" for="active">\n                  <strong>Active</strong> - Client can authenticate and receive tokens\n                </label>\n              </div>\n            </div>\n\n            <!-- Submit Buttons -->\n            <div class="form-group mb-0" style="display: flex; gap: 1rem;">\n              <button type="submit" class="btn btn-primary">\n                ', '\n              </button>\n              <a href="/admin/clients" class="btn btn-secondary">\n                Cancel\n              </a>\n            </div>\n          </div>\n        </form>\n      </div>\n\n      ', `
    </div>

    <script>
      function addRedirectUri() {
        const container = document.getElementById('redirect-uris-container');
        const div = document.createElement('div');
        div.className = 'redirect-uri-row';
        div.style.cssText = 'display: flex; gap: 0.5rem; margin-bottom: 0.5rem;';
        div.innerHTML = \`
          <input
            type="url"
            class="form-control"
            name="redirectUris[]"
            required
            placeholder="https://example.com/callback"
          />
          <button type="button" class="btn btn-danger" onclick="this.parentElement.remove()" style="padding: 0.75rem 1rem;">
            \u2715
          </button>
        \`;
        container.appendChild(div);
      }
    <\/script>
  `], ['\n    <div class="container-sm">\n      <div style="margin-bottom: 2rem;">\n        <a href="/admin/clients" class="btn-link" style="font-size: 0.875rem;">\u2190 Back to Clients</a>\n        <h1 class="mt-3">', ' OAuth2 Client</h1>\n      </div>\n\n      <div class="card">\n        <form method="POST" action="', '">\n          <div class="p-3">\n            <!-- Client Name -->\n            <div class="form-group">\n              <label for="name" class="form-label form-label-required">Client Name</label>\n              <input\n                type="text"\n                class="form-control ', '"\n                id="name"\n                name="name"\n                value="', '"\n                required\n                autofocus\n                placeholder="My Application"\n              />\n              <small class="form-text">A friendly name for this OAuth2 client</small>\n              ', '\n            </div>\n\n            <!-- Redirect URIs -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Redirect URIs</label>\n              <div id="redirect-uris-container">\n                ', '\n              </div>\n              <button type="button" class="btn btn-secondary mt-2" onclick="addRedirectUri()">\n                + Add Another URI\n              </button>\n              <small class="form-text">Where users will be redirected after authorization</small>\n            </div>\n\n            <!-- Grant Types -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Grant Types</label>\n              ', '\n              <small class="form-text">OAuth2 grant types this client can use</small>\n            </div>\n\n            <!-- Allowed Scopes -->\n            <div class="form-group">\n              <label class="form-label form-label-required">Allowed Scopes</label>\n              ', '\n              <small class="form-text">Scopes this client is allowed to request</small>\n            </div>\n\n            <!-- Active Status -->\n            <div class="form-group">\n              <div class="form-check">\n                <input\n                  type="checkbox"\n                  class="form-check-input"\n                  id="active"\n                  name="active"\n                  value="1"\n                  ', '\n                />\n                <label class="form-check-label" for="active">\n                  <strong>Active</strong> - Client can authenticate and receive tokens\n                </label>\n              </div>\n            </div>\n\n            <!-- Submit Buttons -->\n            <div class="form-group mb-0" style="display: flex; gap: 1rem;">\n              <button type="submit" class="btn btn-primary">\n                ', '\n              </button>\n              <a href="/admin/clients" class="btn btn-secondary">\n                Cancel\n              </a>\n            </div>\n          </div>\n        </form>\n      </div>\n\n      ', `
    </div>

    <script>
      function addRedirectUri() {
        const container = document.getElementById('redirect-uris-container');
        const div = document.createElement('div');
        div.className = 'redirect-uri-row';
        div.style.cssText = 'display: flex; gap: 0.5rem; margin-bottom: 0.5rem;';
        div.innerHTML = \\\`
          <input
            type="url"
            class="form-control"
            name="redirectUris[]"
            required
            placeholder="https://example.com/callback"
          />
          <button type="button" class="btn btn-danger" onclick="this.parentElement.remove()" style="padding: 0.75rem 1rem;">
            \u2715
          </button>
        \\\`;
        container.appendChild(div);
      }
    <\/script>
  `])), isEditMode ? "Edit" : "Create", isEditMode ? `/admin/clients/${client.id}/update` : "/admin/clients/create", error ? "is-invalid" : "", clientData.name, error ? html`<div class="invalid-feedback">${error}</div>` : "", (Array.isArray(clientData.redirectUris) ? clientData.redirectUris : [""]).map((uri, index) => html`
                  <div class="redirect-uri-row" style="display: flex; gap: 0.5rem; margin-bottom: 0.5rem;">
                    <input
                      type="url"
                      class="form-control"
                      name="redirectUris[]"
                      value="${uri}"
                      required
                      placeholder="https://example.com/callback"
                    />
                    ${index > 0 ? html`
                      <button type="button" class="btn btn-danger" onclick="this.parentElement.remove()" style="padding: 0.75rem 1rem;">
                        ✕
                      </button>
                    ` : ""}
                  </div>
                `), (availableGrantTypes.length > 0 ? availableGrantTypes : ["authorization_code", "refresh_token", "client_credentials"]).map((type) => {
    const isChecked = Array.isArray(clientData.grantTypes) && clientData.grantTypes.includes(type);
    return html`
                  <div class="form-check">
                    <input
                      type="checkbox"
                      class="form-check-input"
                      id="grant_${type}"
                      name="grantTypes[]"
                      value="${type}"
                      ${isChecked ? "checked" : ""}
                    />
                    <label class="form-check-label" for="grant_${type}">
                      <code>${type}</code>
                    </label>
                  </div>
                `;
  }), (availableScopes.length > 0 ? availableScopes : ["openid", "profile", "email", "offline_access"]).map((scope) => {
    const isChecked = Array.isArray(clientData.allowedScopes) && clientData.allowedScopes.includes(scope);
    return html`
                  <div class="form-check">
                    <input
                      type="checkbox"
                      class="form-check-input"
                      id="scope_${scope}"
                      name="allowedScopes[]"
                      value="${scope}"
                      ${isChecked ? "checked" : ""}
                    />
                    <label class="form-check-label" for="scope_${scope}">
                      <code>${scope}</code>
                    </label>
                  </div>
                `;
  }), clientData.active !== false ? "checked" : "", isEditMode ? "Update Client" : "Create Client", isEditMode ? html`
        <div class="alert alert-info mt-4">
          <strong>Note:</strong> The client secret cannot be displayed again after creation. If you need a new secret, use the "Rotate Secret" button on the clients list page.
        </div>
      ` : "");
  return BaseLayout({
    title: `${isEditMode ? "Edit" : "Create"} OAuth2 Client - Admin`,
    content,
    config,
    user,
    error: null
    // Error shown in form
  });
}

function AdminUsersPage(props = {}) {
  const { users = [], user = {}, error = null, success = null, config = {} } = props;
  const statusColors = {
    active: "var(--color-success)",
    suspended: "var(--color-danger)",
    pending_verification: "var(--color-warning)"
  };
  const content = html`
    <div class="container">
      <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 2rem;">
        <h1>User Management</h1>
        <a href="/admin" class="btn btn-secondary">
          ← Back to Dashboard
        </a>
      </div>

      ${users.length === 0 ? html`
        <div class="card">
          <div class="p-3 text-center">
            <p class="text-muted">No users found.</p>
          </div>
        </div>
      ` : html`
        <div class="card">
          <table style="width: 100%; border-collapse: collapse;">
            <thead>
              <tr style="border-bottom: 2px solid var(--color-border); background-color: var(--color-light);">
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Name</th>
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Email</th>
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Status</th>
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Role</th>
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Verified</th>
                <th style="text-align: left; padding: 1rem; font-weight: 500;">Joined</th>
                <th style="text-align: right; padding: 1rem; font-weight: 500;">Actions</th>
              </tr>
            </thead>
            <tbody>
              ${users.map((u) => {
    const statusColor = statusColors[u.status] || "var(--color-text-muted)";
    const isCurrentUser = u.id === user.id;
    return html`
                  <tr style="border-bottom: 1px solid var(--color-border);">
                    <td style="padding: 1rem;">
                      <strong>${u.name}</strong>
                      ${isCurrentUser ? html`
                        <span class="badge" style="background-color: var(--color-primary); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem; margin-left: 0.5rem;">
                          You
                        </span>
                      ` : ""}
                    </td>
                    <td style="padding: 1rem;">
                      <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem;">
                        ${u.email}
                      </code>
                    </td>
                    <td style="padding: 1rem;">
                      <span class="badge" style="background-color: ${statusColor}; color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem;">
                        ${u.status.replace("_", " ")}
                      </span>
                    </td>
                    <td style="padding: 1rem;">
                      ${u.role === "admin" ? html`
                        <span class="badge" style="background-color: var(--color-danger); color: white; padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.75rem;">
                          Admin
                        </span>
                      ` : html`
                        <span style="color: var(--color-text-muted); font-size: 0.875rem;">User</span>
                      `}
                    </td>
                    <td style="padding: 1rem;">
                      ${u.emailVerified ? html`
                        <span style="color: var(--color-success);">✓</span>
                      ` : html`
                        <span style="color: var(--color-text-muted);">✗</span>
                      `}
                    </td>
                    <td style="padding: 1rem; color: var(--color-text-muted); font-size: 0.875rem;">
                      ${u.createdAt ? new Date(u.createdAt).toLocaleDateString() : "Unknown"}
                    </td>
                    <td style="padding: 1rem; text-align: right;">
                      <div style="display: flex; gap: 0.5rem; justify-content: flex-end;">
                        <a href="/admin/users/${u.id}/edit" class="btn btn-secondary" style="font-size: 0.875rem; padding: 0.5rem 0.75rem;">
                          Edit
                        </a>
                        ${!isCurrentUser ? html`
                          <form method="POST" action="/admin/users/${u.id}/delete" style="margin: 0; display: inline;">
                            <button
                              type="submit"
                              class="btn btn-danger"
                              style="font-size: 0.875rem; padding: 0.5rem 0.75rem;"
                              onclick="return confirm('Are you sure you want to delete this user? This action cannot be undone.')"
                            >
                              Delete
                            </button>
                          </form>
                        ` : ""}
                      </div>
                    </td>
                  </tr>

                  <!-- Expandable Actions Row -->
                  <tr style="border-bottom: 1px solid var(--color-border); background-color: var(--color-light);">
                    <td colspan="7" style="padding: 0.75rem 1rem;">
                      <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
                        <!-- Status Management -->
                        ${!isCurrentUser ? html`
                          <form method="POST" action="/admin/users/${u.id}/change-status" style="margin: 0;">
                            <input type="hidden" name="status" value="${u.status === "active" ? "suspended" : "active"}" />
                            <button type="submit" class="btn ${u.status === "active" ? "btn-danger" : "btn-success"}" style="font-size: 0.875rem; padding: 0.5rem 1rem;">
                              ${u.status === "active" ? "\u{1F534} Suspend" : "\u{1F7E2} Activate"}
                            </button>
                          </form>
                        ` : ""}

                        <!-- Mark as Verified -->
                        ${!u.emailVerified && !isCurrentUser ? html`
                          <form method="POST" action="/admin/users/${u.id}/verify-email" style="margin: 0;">
                            <button type="submit" class="btn btn-secondary" style="font-size: 0.875rem; padding: 0.5rem 1rem;">
                              ✓ Mark Email Verified
                            </button>
                          </form>
                        ` : ""}

                        <!-- Reset Password -->
                        ${!isCurrentUser ? html`
                          <form method="POST" action="/admin/users/${u.id}/reset-password" style="margin: 0;">
                            <button
                              type="submit"
                              class="btn btn-secondary"
                              style="font-size: 0.875rem; padding: 0.5rem 1rem;"
                              onclick="return confirm('Send password reset email to ${u.email}?')"
                            >
                              🔑 Send Password Reset
                            </button>
                          </form>
                        ` : ""}

                        <!-- Toggle Admin -->
                        ${!isCurrentUser ? html`
                          <form method="POST" action="/admin/users/${u.id}/toggle-admin" style="margin: 0;">
                            <button
                              type="submit"
                              class="btn ${u.role === "admin" ? "btn-danger" : "btn-primary"}"
                              style="font-size: 0.875rem; padding: 0.5rem 1rem;"
                              onclick="return confirm('${u.role === "admin" ? "Remove admin privileges from" : "Grant admin privileges to"} ${u.name}?')"
                            >
                              ${u.role === "admin" ? "\u{1F464} Remove Admin" : "\u26A1 Make Admin"}
                            </button>
                          </form>
                        ` : ""}
                      </div>
                    </td>
                  </tr>
                `;
  })}
            </tbody>
          </table>
        </div>
      `}

      <!-- Statistics Summary -->
      <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin-top: 2rem;">
        <div class="card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
          <div class="p-3 text-center">
            <div style="font-size: 0.875rem; opacity: 0.9;">Total Users</div>
            <div style="font-size: 2rem; font-weight: bold; margin-top: 0.5rem;">${users.length}</div>
          </div>
        </div>

        <div class="card" style="background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); color: white;">
          <div class="p-3 text-center">
            <div style="font-size: 0.875rem; opacity: 0.9;">Active</div>
            <div style="font-size: 2rem; font-weight: bold; margin-top: 0.5rem;">
              ${users.filter((u) => u.status === "active").length}
            </div>
          </div>
        </div>

        <div class="card" style="background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); color: white;">
          <div class="p-3 text-center">
            <div style="font-size: 0.875rem; opacity: 0.9;">Pending</div>
            <div style="font-size: 2rem; font-weight: bold; margin-top: 0.5rem;">
              ${users.filter((u) => u.status === "pending_verification").length}
            </div>
          </div>
        </div>

        <div class="card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white;">
          <div class="p-3 text-center">
            <div style="font-size: 0.875rem; opacity: 0.9;">Verified Emails</div>
            <div style="font-size: 2rem; font-weight: bold; margin-top: 0.5rem;">
              ${users.filter((u) => u.emailVerified).length}
            </div>
          </div>
        </div>
      </div>
    </div>
  `;
  return BaseLayout({
    title: "User Management - Admin",
    content,
    config,
    user,
    error,
    success
  });
}

function AdminUserFormPage(props = {}) {
  const { editUser = {}, user = {}, error = null, config = {} } = props;
  const isCurrentUser = editUser.id === user.id;
  const content = html`
    <div class="container-sm">
      <div style="margin-bottom: 2rem;">
        <a href="/admin/users" class="btn-link" style="font-size: 0.875rem;">← Back to Users</a>
        <h1 class="mt-3">Edit User: ${editUser.name}</h1>
      </div>

      <div class="card">
        <form method="POST" action="/admin/users/${editUser.id}/update">
          <div class="p-3">
            <!-- Name -->
            <div class="form-group">
              <label for="name" class="form-label form-label-required">Full Name</label>
              <input
                type="text"
                class="form-control ${error ? "is-invalid" : ""}"
                id="name"
                name="name"
                value="${editUser.name}"
                required
                autofocus
                placeholder="John Doe"
              />
              <small class="form-text">User's display name</small>
              ${error ? html`<div class="invalid-feedback">${error}</div>` : ""}
            </div>

            <!-- Email -->
            <div class="form-group">
              <label for="email" class="form-label form-label-required">Email Address</label>
              <input
                type="email"
                class="form-control"
                id="email"
                name="email"
                value="${editUser.email}"
                required
                placeholder="user@example.com"
              />
              <small class="form-text">Email address for login and notifications</small>
            </div>

            <!-- Status -->
            <div class="form-group">
              <label class="form-label form-label-required">Account Status</label>
              <div style="display: grid; gap: 0.75rem;">
                <div class="form-check">
                  <input
                    type="radio"
                    class="form-check-input"
                    id="status_active"
                    name="status"
                    value="active"
                    ${editUser.status === "active" ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <label class="form-check-label" for="status_active">
                    <strong>Active</strong> - User can log in and access services
                  </label>
                </div>
                <div class="form-check">
                  <input
                    type="radio"
                    class="form-check-input"
                    id="status_suspended"
                    name="status"
                    value="suspended"
                    ${editUser.status === "suspended" ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <label class="form-check-label" for="status_suspended">
                    <strong>Suspended</strong> - User cannot log in
                  </label>
                </div>
                <div class="form-check">
                  <input
                    type="radio"
                    class="form-check-input"
                    id="status_pending"
                    name="status"
                    value="pending_verification"
                    ${editUser.status === "pending_verification" ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <label class="form-check-label" for="status_pending">
                    <strong>Pending Verification</strong> - Awaiting email verification
                  </label>
                </div>
              </div>
              ${isCurrentUser ? html`
                <small class="form-text" style="color: var(--color-warning);">You cannot change your own status</small>
              ` : ""}
            </div>

            <!-- Role -->
            <div class="form-group">
              <label class="form-label form-label-required">Role</label>
              <div style="display: grid; gap: 0.75rem;">
                <div class="form-check">
                  <input
                    type="radio"
                    class="form-check-input"
                    id="role_user"
                    name="role"
                    value="user"
                    ${editUser.role !== "admin" ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <label class="form-check-label" for="role_user">
                    <strong>User</strong> - Standard user access
                  </label>
                </div>
                <div class="form-check">
                  <input
                    type="radio"
                    class="form-check-input"
                    id="role_admin"
                    name="role"
                    value="admin"
                    ${editUser.role === "admin" ? "checked" : ""}
                    ${isCurrentUser ? "disabled" : ""}
                  />
                  <label class="form-check-label" for="role_admin">
                    <strong>Admin</strong> - Full administrative access
                  </label>
                </div>
              </div>
              ${isCurrentUser ? html`
                <small class="form-text" style="color: var(--color-warning);">You cannot change your own role</small>
              ` : ""}
            </div>

            <!-- Email Verification -->
            <div class="form-group">
              <div class="form-check">
                <input
                  type="checkbox"
                  class="form-check-input"
                  id="emailVerified"
                  name="emailVerified"
                  value="1"
                  ${editUser.emailVerified ? "checked" : ""}
                />
                <label class="form-check-label" for="emailVerified">
                  <strong>Email Verified</strong> - User has confirmed their email address
                </label>
              </div>
            </div>

            <!-- Submit Buttons -->
            <div class="form-group mb-0" style="display: flex; gap: 1rem;">
              <button type="submit" class="btn btn-primary">
                Update User
              </button>
              <a href="/admin/users" class="btn btn-secondary">
                Cancel
              </a>
            </div>
          </div>
        </form>
      </div>

      <!-- User Information -->
      <div class="card mt-4">
        <div class="card-header">
          User Information
        </div>
        <div class="p-3">
          <div style="display: grid; gap: 0.5rem;">
            <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
              <span style="font-weight: 500;">User ID:</span>
              <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem;">
                ${editUser.id}
              </code>
            </div>
            ${editUser.createdAt ? html`
              <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
                <span style="font-weight: 500;">Joined:</span>
                <span>${new Date(editUser.createdAt).toLocaleString()}</span>
              </div>
            ` : ""}
            ${editUser.updatedAt ? html`
              <div style="display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--color-border);">
                <span style="font-weight: 500;">Last Updated:</span>
                <span>${new Date(editUser.updatedAt).toLocaleString()}</span>
              </div>
            ` : ""}
            ${editUser.lastLoginAt ? html`
              <div style="display: flex; justify-content: space-between; padding: 0.5rem 0;">
                <span style="font-weight: 500;">Last Login:</span>
                <span>${new Date(editUser.lastLoginAt).toLocaleString()}</span>
              </div>
            ` : html`
              <div style="display: flex; justify-content: space-between; padding: 0.5rem 0;">
                <span style="font-weight: 500;">Last Login:</span>
                <span style="color: var(--color-text-muted);">Never</span>
              </div>
            `}
          </div>
        </div>
      </div>

      <!-- Danger Zone -->
      ${!isCurrentUser ? html`
        <div class="card mt-4" style="border-color: var(--color-danger);">
          <div class="card-header" style="background-color: var(--color-danger); color: white;">
            Danger Zone
          </div>
          <div class="p-3">
            <div style="display: flex; flex-direction: column; gap: 1rem;">
              <!-- Send Password Reset -->
              <div>
                <h3 style="font-size: 1rem; margin-bottom: 0.5rem;">Send Password Reset Email</h3>
                <p style="color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.75rem;">
                  Send a password reset link to ${editUser.email}
                </p>
                <form method="POST" action="/admin/users/${editUser.id}/reset-password" style="margin: 0;">
                  <button
                    type="submit"
                    class="btn btn-secondary"
                    onclick="return confirm('Send password reset email to ${editUser.email}?')"
                  >
                    🔑 Send Password Reset
                  </button>
                </form>
              </div>

              <!-- Delete User -->
              <div style="padding-top: 1rem; border-top: 1px solid var(--color-border);">
                <h3 style="font-size: 1rem; margin-bottom: 0.5rem;">Delete User Account</h3>
                <p style="color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.75rem;">
                  Permanently delete this user account. This action cannot be undone.
                </p>
                <form method="POST" action="/admin/users/${editUser.id}/delete" style="margin: 0;">
                  <button
                    type="submit"
                    class="btn btn-danger"
                    onclick="return confirm('Are you sure you want to delete ${editUser.name}? This action cannot be undone.')"
                  >
                    🗑️ Delete User
                  </button>
                </form>
              </div>
            </div>
          </div>
        </div>
      ` : ""}
    </div>
  `;
  return BaseLayout({
    title: `Edit User: ${editUser.name} - Admin`,
    content,
    config,
    user,
    error: null
    // Error shown in form
  });
}

const SCOPE_DESCRIPTIONS = {
  openid: {
    name: "OpenID Connect",
    description: "Sign in using your identity",
    icon: "\u{1F510}"
  },
  profile: {
    name: "Profile Information",
    description: "Access your basic profile information (name, picture)",
    icon: "\u{1F464}"
  },
  email: {
    name: "Email Address",
    description: "Access your email address",
    icon: "\u{1F4E7}"
  },
  offline_access: {
    name: "Offline Access",
    description: "Maintain access when you are not using the app",
    icon: "\u{1F504}"
  },
  phone: {
    name: "Phone Number",
    description: "Access your phone number",
    icon: "\u{1F4F1}"
  },
  address: {
    name: "Address",
    description: "Access your address information",
    icon: "\u{1F3E0}"
  }
};
function ConsentPage(props = {}) {
  const {
    client = {},
    scopes = [],
    user = {},
    responseType,
    redirectUri,
    state = "",
    codeChallenge = "",
    codeChallengeMethod = "plain",
    error = null,
    config = {}
  } = props;
  const scopeDetails = scopes.map((scope) => ({
    scope,
    ...SCOPE_DESCRIPTIONS[scope],
    unknown: !SCOPE_DESCRIPTIONS[scope]
  })).filter((s) => !s.unknown);
  const content = html`
    <div class="container-sm">
      ${error ? html`
        <div class="alert alert-danger mb-4">
          ${error}
        </div>
      ` : ""}

      <div style="text-align: center; margin-bottom: 2rem;">
        ${config.logoUrl ? html`
          <img src="${config.logoUrl}" alt="Logo" style="max-width: 80px; margin-bottom: 1rem;" />
        ` : ""}
        <h1 style="font-size: 1.75rem; margin-bottom: 0.5rem;">Authorize Application</h1>
        <p style="color: var(--color-text-muted);">
          <strong>${client.name || "Application"}</strong> is requesting access to your account
        </p>
      </div>

      <div class="card mb-3">
        <div class="card-header">
          Application Information
        </div>
        <div class="p-3">
          <div style="display: grid; gap: 1rem;">
            <div>
              <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                Application Name
              </div>
              <div style="font-size: 1.125rem; font-weight: 600;">
                ${client.name || "Unknown Application"}
              </div>
            </div>

            ${client.description ? html`
              <div>
                <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                  Description
                </div>
                <div>${client.description}</div>
              </div>
            ` : ""}

            <div>
              <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                Client ID
              </div>
              <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem; word-break: break-all;">
                ${client.clientId}
              </code>
            </div>

            <div>
              <div style="font-weight: 500; color: var(--color-text-muted); font-size: 0.875rem; margin-bottom: 0.25rem;">
                Will Redirect To
              </div>
              <code style="background: var(--color-light); padding: 0.25rem 0.5rem; border-radius: 3px; font-size: 0.875rem; word-break: break-all;">
                ${redirectUri}
              </code>
            </div>
          </div>
        </div>
      </div>

      <div class="card mb-3">
        <div class="card-header">
          Requested Permissions
        </div>
        <div class="p-3">
          ${scopeDetails.length === 0 ? html`
            <p style="color: var(--color-text-muted); font-style: italic;">
              This application is not requesting any specific permissions.
            </p>
          ` : html`
            <div style="display: grid; gap: 1rem;">
              ${scopeDetails.map((s) => html`
                <div style="display: flex; gap: 1rem; align-items: flex-start;">
                  <div style="font-size: 2rem; line-height: 1;">
                    ${s.icon}
                  </div>
                  <div style="flex: 1;">
                    <div style="font-weight: 600; margin-bottom: 0.25rem;">
                      ${s.name}
                    </div>
                    <div style="color: var(--color-text-muted); font-size: 0.875rem;">
                      ${s.description}
                    </div>
                  </div>
                </div>
              `)}
            </div>
          `}
        </div>
      </div>

      <div class="card mb-3" style="background-color: var(--color-light);">
        <div class="p-3">
          <div style="display: flex; gap: 0.75rem; align-items: flex-start;">
            <div style="font-size: 1.5rem;">ℹ️</div>
            <div style="flex: 1;">
              <div style="font-weight: 600; margin-bottom: 0.5rem;">
                Signed in as ${user.name}
              </div>
              <div style="font-size: 0.875rem; color: var(--color-text-muted); margin-bottom: 0.75rem;">
                By clicking "Allow", you authorize <strong>${client.name}</strong> to access your information as described above.
              </div>
              <div style="font-size: 0.875rem; color: var(--color-text-muted);">
                You can revoke this access at any time from your <a href="/profile" style="color: var(--color-primary);">profile settings</a>.
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Authorization Form -->
      <form method="POST" action="/oauth/consent">
        <!-- OAuth2 Parameters -->
        <input type="hidden" name="response_type" value="${responseType}" />
        <input type="hidden" name="client_id" value="${client.clientId}" />
        <input type="hidden" name="redirect_uri" value="${redirectUri}" />
        <input type="hidden" name="scope" value="${scopes.join(" ")}" />
        ${state ? html`<input type="hidden" name="state" value="${state}" />` : ""}
        ${codeChallenge ? html`<input type="hidden" name="code_challenge" value="${codeChallenge}" />` : ""}
        ${codeChallengeMethod ? html`<input type="hidden" name="code_challenge_method" value="${codeChallengeMethod}" />` : ""}

        <!-- Trust Option -->
        <div class="form-group">
          <div class="form-check">
            <input
              type="checkbox"
              class="form-check-input"
              id="trust_application"
              name="trust_application"
              value="1"
            />
            <label class="form-check-label" for="trust_application">
              Trust this application (don't ask again)
            </label>
          </div>
          <small class="form-text">
            You won't be asked for permission next time this application requests access with the same permissions.
          </small>
        </div>

        <!-- Action Buttons -->
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem;">
          <button
            type="submit"
            name="decision"
            value="deny"
            class="btn btn-secondary"
            style="order: 1;"
          >
            Deny
          </button>
          <button
            type="submit"
            name="decision"
            value="allow"
            class="btn btn-primary"
            style="order: 2;"
          >
            Allow
          </button>
        </div>
      </form>

      <div style="text-align: center; margin-top: 2rem;">
        <a href="/logout" style="color: var(--color-text-muted); font-size: 0.875rem;">
          Not ${user.name}? Sign out
        </a>
      </div>
    </div>
  `;
  return BaseLayout({
    title: `Authorize ${client.name || "Application"}`,
    content,
    config,
    user,
    error: null
    // Error shown in page
  });
}

function VerifyEmailPage(props = {}) {
  const { status = "pending", email = "", message = "", config = {} } = props;
  const statusConfig = {
    success: {
      icon: "\u2705",
      title: "Email Verified!",
      color: "var(--color-success)",
      defaultMessage: "Your email address has been successfully verified."
    },
    error: {
      icon: "\u274C",
      title: "Verification Failed",
      color: "var(--color-danger)",
      defaultMessage: "The verification link is invalid or has already been used."
    },
    expired: {
      icon: "\u23F0",
      title: "Link Expired",
      color: "var(--color-warning)",
      defaultMessage: "This verification link has expired. Please request a new one."
    },
    pending: {
      icon: "\u{1F4E7}",
      title: "Verify Your Email",
      color: "var(--color-primary)",
      defaultMessage: "Please check your email for a verification link."
    }
  };
  const currentStatus = statusConfig[status] || statusConfig.pending;
  const displayMessage = message || currentStatus.defaultMessage;
  const content = html`
    <div class="container-sm">
      <div style="text-align: center; margin-bottom: 2rem;">
        ${config.logoUrl ? html`
          <img src="${config.logoUrl}" alt="Logo" style="max-width: 80px; margin-bottom: 1rem;" />
        ` : ""}
        <h1 style="font-size: 1.75rem; margin-bottom: 0.5rem;">${currentStatus.title}</h1>
      </div>

      <div class="card">
        <div class="p-3" style="text-align: center;">
          <div style="font-size: 4rem; margin-bottom: 1.5rem;">
            ${currentStatus.icon}
          </div>

          <div style="font-size: 1.125rem; color: var(--color-text); margin-bottom: 2rem;">
            ${displayMessage}
          </div>

          ${status === "success" ? html`
            <div style="margin-bottom: 1.5rem;">
              <a href="/login" class="btn btn-primary">
                Sign In
              </a>
            </div>
            <div>
              <a href="/profile" style="color: var(--color-text-muted); font-size: 0.875rem;">
                Go to your profile
              </a>
            </div>
          ` : status === "error" || status === "expired" ? html`
            ${email ? html`
              <form method="POST" action="/verify-email/resend" style="margin-bottom: 1.5rem;">
                <input type="hidden" name="email" value="${email}" />
                <button type="submit" class="btn btn-primary">
                  Send New Verification Email
                </button>
              </form>
            ` : html`
              <div style="margin-bottom: 1.5rem;">
                <a href="/login" class="btn btn-primary">
                  Sign In to Resend
                </a>
              </div>
            `}
            <div>
              <a href="/login" style="color: var(--color-text-muted); font-size: 0.875rem;">
                Sign in
              </a>
            </div>
          ` : html`
            <!-- Pending status -->
            <div style="background-color: var(--color-light); border-radius: 8px; padding: 1.5rem; margin-bottom: 1.5rem;">
              <div style="font-weight: 600; margin-bottom: 0.5rem;">
                Didn't receive the email?
              </div>
              <ul style="text-align: left; color: var(--color-text-muted); font-size: 0.875rem; margin: 0; padding-left: 1.5rem;">
                <li>Check your spam or junk folder</li>
                <li>Make sure the email address is correct</li>
                <li>Wait a few minutes and check again</li>
              </ul>
            </div>

            ${email ? html`
              <form method="POST" action="/verify-email/resend" style="margin-bottom: 1.5rem;">
                <input type="hidden" name="email" value="${email}" />
                <button type="submit" class="btn btn-secondary">
                  Resend Verification Email
                </button>
              </form>
            ` : html`
              <div style="margin-bottom: 1.5rem;">
                <a href="/login" class="btn btn-secondary">
                  Sign In to Resend
                </a>
              </div>
            `}

            <div>
              <a href="/login" style="color: var(--color-text-muted); font-size: 0.875rem;">
                Back to sign in
              </a>
            </div>
          `}
        </div>
      </div>

      ${status === "success" ? html`
        <div class="alert alert-success mt-4" style="text-align: center;">
          <strong>Your account is now fully activated!</strong><br>
          You can now access all features and services.
        </div>
      ` : ""}
    </div>
  `;
  return BaseLayout({
    title: currentStatus.title,
    content,
    config,
    user: null,
    error: null,
    success: null
  });
}

var bcrypt$1 = {exports: {}};

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var nodeGypBuild$1 = {exports: {}};

var nodeGypBuild;
var hasRequiredNodeGypBuild$1;

function requireNodeGypBuild$1 () {
	if (hasRequiredNodeGypBuild$1) return nodeGypBuild;
	hasRequiredNodeGypBuild$1 = 1;
	var fs = fs$1;
	var path = path$1;
	var os$1 = os;

	// Workaround to fix webpack's build warnings: 'the request of a dependency is an expression'
	var runtimeRequire = typeof __webpack_require__ === 'function' ? __non_webpack_require__ : commonjsRequire; // eslint-disable-line

	var vars = (process.config && process.config.variables) || {};
	var prebuildsOnly = !!process.env.PREBUILDS_ONLY;
	var abi = process.versions.modules; // TODO: support old node where this is undef
	var runtime = isElectron() ? 'electron' : (isNwjs() ? 'node-webkit' : 'node');

	var arch = process.env.npm_config_arch || os$1.arch();
	var platform = process.env.npm_config_platform || os$1.platform();
	var libc = process.env.LIBC || (isAlpine(platform) ? 'musl' : 'glibc');
	var armv = process.env.ARM_VERSION || (arch === 'arm64' ? '8' : vars.arm_version) || '';
	var uv = (process.versions.uv || '').split('.')[0];

	nodeGypBuild = load;

	function load (dir) {
	  return runtimeRequire(load.resolve(dir))
	}

	load.resolve = load.path = function (dir) {
	  dir = path.resolve(dir || '.');

	  try {
	    var name = runtimeRequire(path.join(dir, 'package.json')).name.toUpperCase().replace(/-/g, '_');
	    if (process.env[name + '_PREBUILD']) dir = process.env[name + '_PREBUILD'];
	  } catch (err) {}

	  if (!prebuildsOnly) {
	    var release = getFirst(path.join(dir, 'build/Release'), matchBuild);
	    if (release) return release

	    var debug = getFirst(path.join(dir, 'build/Debug'), matchBuild);
	    if (debug) return debug
	  }

	  var prebuild = resolve(dir);
	  if (prebuild) return prebuild

	  var nearby = resolve(path.dirname(process.execPath));
	  if (nearby) return nearby

	  var target = [
	    'platform=' + platform,
	    'arch=' + arch,
	    'runtime=' + runtime,
	    'abi=' + abi,
	    'uv=' + uv,
	    armv ? 'armv=' + armv : '',
	    'libc=' + libc,
	    'node=' + process.versions.node,
	    process.versions.electron ? 'electron=' + process.versions.electron : '',
	    typeof __webpack_require__ === 'function' ? 'webpack=true' : '' // eslint-disable-line
	  ].filter(Boolean).join(' ');

	  throw new Error('No native build was found for ' + target + '\n    loaded from: ' + dir + '\n')

	  function resolve (dir) {
	    // Find matching "prebuilds/<platform>-<arch>" directory
	    var tuples = readdirSync(path.join(dir, 'prebuilds')).map(parseTuple);
	    var tuple = tuples.filter(matchTuple(platform, arch)).sort(compareTuples)[0];
	    if (!tuple) return

	    // Find most specific flavor first
	    var prebuilds = path.join(dir, 'prebuilds', tuple.name);
	    var parsed = readdirSync(prebuilds).map(parseTags);
	    var candidates = parsed.filter(matchTags(runtime, abi));
	    var winner = candidates.sort(compareTags(runtime))[0];
	    if (winner) return path.join(prebuilds, winner.file)
	  }
	};

	function readdirSync (dir) {
	  try {
	    return fs.readdirSync(dir)
	  } catch (err) {
	    return []
	  }
	}

	function getFirst (dir, filter) {
	  var files = readdirSync(dir).filter(filter);
	  return files[0] && path.join(dir, files[0])
	}

	function matchBuild (name) {
	  return /\.node$/.test(name)
	}

	function parseTuple (name) {
	  // Example: darwin-x64+arm64
	  var arr = name.split('-');
	  if (arr.length !== 2) return

	  var platform = arr[0];
	  var architectures = arr[1].split('+');

	  if (!platform) return
	  if (!architectures.length) return
	  if (!architectures.every(Boolean)) return

	  return { name, platform, architectures }
	}

	function matchTuple (platform, arch) {
	  return function (tuple) {
	    if (tuple == null) return false
	    if (tuple.platform !== platform) return false
	    return tuple.architectures.includes(arch)
	  }
	}

	function compareTuples (a, b) {
	  // Prefer single-arch prebuilds over multi-arch
	  return a.architectures.length - b.architectures.length
	}

	function parseTags (file) {
	  var arr = file.split('.');
	  var extension = arr.pop();
	  var tags = { file: file, specificity: 0 };

	  if (extension !== 'node') return

	  for (var i = 0; i < arr.length; i++) {
	    var tag = arr[i];

	    if (tag === 'node' || tag === 'electron' || tag === 'node-webkit') {
	      tags.runtime = tag;
	    } else if (tag === 'napi') {
	      tags.napi = true;
	    } else if (tag.slice(0, 3) === 'abi') {
	      tags.abi = tag.slice(3);
	    } else if (tag.slice(0, 2) === 'uv') {
	      tags.uv = tag.slice(2);
	    } else if (tag.slice(0, 4) === 'armv') {
	      tags.armv = tag.slice(4);
	    } else if (tag === 'glibc' || tag === 'musl') {
	      tags.libc = tag;
	    } else {
	      continue
	    }

	    tags.specificity++;
	  }

	  return tags
	}

	function matchTags (runtime, abi) {
	  return function (tags) {
	    if (tags == null) return false
	    if (tags.runtime && tags.runtime !== runtime && !runtimeAgnostic(tags)) return false
	    if (tags.abi && tags.abi !== abi && !tags.napi) return false
	    if (tags.uv && tags.uv !== uv) return false
	    if (tags.armv && tags.armv !== armv) return false
	    if (tags.libc && tags.libc !== libc) return false

	    return true
	  }
	}

	function runtimeAgnostic (tags) {
	  return tags.runtime === 'node' && tags.napi
	}

	function compareTags (runtime) {
	  // Precedence: non-agnostic runtime, abi over napi, then by specificity.
	  return function (a, b) {
	    if (a.runtime !== b.runtime) {
	      return a.runtime === runtime ? -1 : 1
	    } else if (a.abi !== b.abi) {
	      return a.abi ? -1 : 1
	    } else if (a.specificity !== b.specificity) {
	      return a.specificity > b.specificity ? -1 : 1
	    } else {
	      return 0
	    }
	  }
	}

	function isNwjs () {
	  return !!(process.versions && process.versions.nw)
	}

	function isElectron () {
	  if (process.versions && process.versions.electron) return true
	  if (process.env.ELECTRON_RUN_AS_NODE) return true
	  return typeof window !== 'undefined' && window.process && window.process.type === 'renderer'
	}

	function isAlpine (platform) {
	  return platform === 'linux' && fs.existsSync('/etc/alpine-release')
	}

	// Exposed for unit tests
	// TODO: move to lib
	load.parseTags = parseTags;
	load.matchTags = matchTags;
	load.compareTags = compareTags;
	load.parseTuple = parseTuple;
	load.matchTuple = matchTuple;
	load.compareTuples = compareTuples;
	return nodeGypBuild;
}

var hasRequiredNodeGypBuild;

function requireNodeGypBuild () {
	if (hasRequiredNodeGypBuild) return nodeGypBuild$1.exports;
	hasRequiredNodeGypBuild = 1;
	const runtimeRequire = typeof __webpack_require__ === 'function' ? __non_webpack_require__ : commonjsRequire; // eslint-disable-line
	if (typeof runtimeRequire.addon === 'function') { // if the platform supports native resolving prefer that
	  nodeGypBuild$1.exports = runtimeRequire.addon.bind(runtimeRequire);
	} else { // else use the runtime version here
	  nodeGypBuild$1.exports = requireNodeGypBuild$1();
	}
	return nodeGypBuild$1.exports;
}

var promises;
var hasRequiredPromises;

function requirePromises () {
	if (hasRequiredPromises) return promises;
	hasRequiredPromises = 1;
	let Promise = commonjsGlobal.Promise;

	/// encapsulate a method with a node-style callback in a Promise
	/// @param {object} 'this' of the encapsulated function
	/// @param {function} function to be encapsulated
	/// @param {Array-like} args to be passed to the called function
	/// @return {Promise} a Promise encapsulating the function
	function promise(fn, context, args) {
	    if (!Array.isArray(args)) {
	        args = Array.prototype.slice.call(args);
	    }

	    if (typeof fn !== 'function') {
	        return Promise.reject(new Error('fn must be a function'));
	    }

	    return new Promise((resolve, reject) => {
	        args.push((err, data) => {
	            if (err) {
	                reject(err);
	            } else {
	                resolve(data);
	            }
	        });

	        fn.apply(context, args);
	    });
	}

	/// @param {err} the error to be thrown
	function reject(err) {
	    return Promise.reject(err);
	}

	/// changes the promise implementation that bcrypt uses
	/// @param {Promise} the implementation to use
	function use(promise) {
	    Promise = promise;
	}

	promises = {
	    promise,
	    reject,
	    use
	};
	return promises;
}

var hasRequiredBcrypt;

function requireBcrypt () {
	if (hasRequiredBcrypt) return bcrypt$1.exports;
	hasRequiredBcrypt = 1;
	(function (module) {
		const path = path$1;
		const bindings = requireNodeGypBuild()(path.resolve(__dirname));

		const crypto = crypto$1;

		const promises = requirePromises();

		/// generate a salt (sync)
		/// @param {Number} [rounds] number of rounds (default 10)
		/// @return {String} salt
		function genSaltSync(rounds, minor) {
		    // default 10 rounds
		    if (!rounds) {
		        rounds = 10;
		    } else if (typeof rounds !== 'number') {
		        throw new Error('rounds must be a number');
		    }

		    if (!minor) {
		        minor = 'b';
		    } else if (minor !== 'b' && minor !== 'a') {
		        throw new Error('minor must be either "a" or "b"');
		    }

		    return bindings.gen_salt_sync(minor, rounds, crypto.randomBytes(16));
		}

		/// generate a salt
		/// @param {Number} [rounds] number of rounds (default 10)
		/// @param {Function} cb callback(err, salt)
		function genSalt(rounds, minor, cb) {
		    let error;

		    // if callback is first argument, then use defaults for others
		    if (typeof arguments[0] === 'function') {
		        // have to set callback first otherwise arguments are overridden
		        cb = arguments[0];
		        rounds = 10;
		        minor = 'b';
		        // callback is second argument
		    } else if (typeof arguments[1] === 'function') {
		        // have to set callback first otherwise arguments are overridden
		        cb = arguments[1];
		        minor = 'b';
		    }

		    if (!cb) {
		        return promises.promise(genSalt, this, [rounds, minor]);
		    }

		    // default 10 rounds
		    if (!rounds) {
		        rounds = 10;
		    } else if (typeof rounds !== 'number') {
		        // callback error asynchronously
		        error = new Error('rounds must be a number');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }

		    if (!minor) {
		        minor = 'b';
		    } else if (minor !== 'b' && minor !== 'a') {
		        error = new Error('minor must be either "a" or "b"');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }

		    crypto.randomBytes(16, function (error, randomBytes) {
		        if (error) {
		            cb(error);
		            return;
		        }

		        bindings.gen_salt(minor, rounds, randomBytes, cb);
		    });
		}

		/// hash data using a salt
		/// @param {String|Buffer} data the data to encrypt
		/// @param {String} salt the salt to use when hashing
		/// @return {String} hash
		function hashSync(data, salt) {
		    if (data == null || salt == null) {
		        throw new Error('data and salt arguments required');
		    }

		    if (!(typeof data === 'string' || data instanceof Buffer) || (typeof salt !== 'string' && typeof salt !== 'number')) {
		        throw new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');
		    }

		    if (typeof salt === 'number') {
		        salt = module.exports.genSaltSync(salt);
		    }

		    return bindings.encrypt_sync(data, salt);
		}

		/// hash data using a salt
		/// @param {String|Buffer} data the data to encrypt
		/// @param {String} salt the salt to use when hashing
		/// @param {Function} cb callback(err, hash)
		function hash(data, salt, cb) {
		    let error;

		    if (typeof data === 'function') {
		        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');
		        return process.nextTick(function () {
		            data(error);
		        });
		    }

		    if (typeof salt === 'function') {
		        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');
		        return process.nextTick(function () {
		            salt(error);
		        });
		    }

		    // cb exists but is not a function
		    // return a rejecting promise
		    if (cb && typeof cb !== 'function') {
		        return promises.reject(new Error('cb must be a function or null to return a Promise'));
		    }

		    if (!cb) {
		        return promises.promise(hash, this, [data, salt]);
		    }

		    if (data == null || salt == null) {
		        error = new Error('data and salt arguments required');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }

		    if (!(typeof data === 'string' || data instanceof Buffer) || (typeof salt !== 'string' && typeof salt !== 'number')) {
		        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }


		    if (typeof salt === 'number') {
		        return module.exports.genSalt(salt, function (err, salt) {
		            return bindings.encrypt(data, salt, cb);
		        });
		    }

		    return bindings.encrypt(data, salt, cb);
		}

		/// compare raw data to hash
		/// @param {String|Buffer} data the data to hash and compare
		/// @param {String} hash expected hash
		/// @return {bool} true if hashed data matches hash
		function compareSync(data, hash) {
		    if (data == null || hash == null) {
		        throw new Error('data and hash arguments required');
		    }

		    if (!(typeof data === 'string' || data instanceof Buffer) || typeof hash !== 'string') {
		        throw new Error('data must be a string or Buffer and hash must be a string');
		    }

		    return bindings.compare_sync(data, hash);
		}

		/// compare raw data to hash
		/// @param {String|Buffer} data the data to hash and compare
		/// @param {String} hash expected hash
		/// @param {Function} cb callback(err, matched) - matched is true if hashed data matches hash
		function compare(data, hash, cb) {
		    let error;

		    if (typeof data === 'function') {
		        error = new Error('data and hash arguments required');
		        return process.nextTick(function () {
		            data(error);
		        });
		    }

		    if (typeof hash === 'function') {
		        error = new Error('data and hash arguments required');
		        return process.nextTick(function () {
		            hash(error);
		        });
		    }

		    // cb exists but is not a function
		    // return a rejecting promise
		    if (cb && typeof cb !== 'function') {
		        return promises.reject(new Error('cb must be a function or null to return a Promise'));
		    }

		    if (!cb) {
		        return promises.promise(compare, this, [data, hash]);
		    }

		    if (data == null || hash == null) {
		        error = new Error('data and hash arguments required');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }

		    if (!(typeof data === 'string' || data instanceof Buffer) || typeof hash !== 'string') {
		        error = new Error('data and hash must be strings');
		        return process.nextTick(function () {
		            cb(error);
		        });
		    }

		    return bindings.compare(data, hash, cb);
		}

		/// @param {String} hash extract rounds from this hash
		/// @return {Number} the number of rounds used to encrypt a given hash
		function getRounds(hash) {
		    if (hash == null) {
		        throw new Error('hash argument required');
		    }

		    if (typeof hash !== 'string') {
		        throw new Error('hash must be a string');
		    }

		    return bindings.get_rounds(hash);
		}

		module.exports = {
		    genSaltSync,
		    genSalt,
		    hashSync,
		    hash,
		    compareSync,
		    compare,
		    getRounds,
		}; 
	} (bcrypt$1));
	return bcrypt$1.exports;
}

var bcryptExports = requireBcrypt();
var bcrypt = /*@__PURE__*/getDefaultExportFromCjs(bcryptExports);

const DEFAULT_PASSWORD_POLICY = {
  minLength: 8,
  maxLength: 128,
  requireUppercase: true,
  requireLowercase: true,
  requireNumbers: true,
  requireSymbols: false,
  bcryptRounds: 10
};
async function hashPassword(password, rounds = 10) {
  if (!password || typeof password !== "string") {
    throw new Error("Password must be a non-empty string");
  }
  if (password.length > 72) {
    throw new Error("Password too long (max 72 characters)");
  }
  return await bcrypt.hash(password, rounds);
}
async function verifyPassword(plaintext, hash) {
  if (!plaintext || typeof plaintext !== "string") {
    return false;
  }
  if (!hash || typeof hash !== "string") {
    return false;
  }
  try {
    return await bcrypt.compare(plaintext, hash);
  } catch (error) {
    return false;
  }
}
function validatePassword(password, policy = DEFAULT_PASSWORD_POLICY) {
  const errors = [];
  if (!password || typeof password !== "string") {
    return { valid: false, errors: ["Password must be a string"] };
  }
  const rules = { ...DEFAULT_PASSWORD_POLICY, ...policy };
  if (password.length < rules.minLength) {
    errors.push(`Password must be at least ${rules.minLength} characters long`);
  }
  if (password.length > rules.maxLength) {
    errors.push(`Password must not exceed ${rules.maxLength} characters`);
  }
  if (rules.requireUppercase && !/[A-Z]/.test(password)) {
    errors.push("Password must contain at least one uppercase letter");
  }
  if (rules.requireLowercase && !/[a-z]/.test(password)) {
    errors.push("Password must contain at least one lowercase letter");
  }
  if (rules.requireNumbers && !/[0-9]/.test(password)) {
    errors.push("Password must contain at least one number");
  }
  if (rules.requireSymbols && !/[!@#$%^&*()_+\-=\[\]{};':"\\|,.<>\/?]/.test(password)) {
    errors.push("Password must contain at least one symbol");
  }
  return {
    valid: errors.length === 0,
    errors
  };
}

function sessionAuth(sessionManager, options = {}) {
  const {
    required = false,
    requireAdmin = false,
    redirectTo = "/login"
  } = options;
  return async (c, next) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    let user = null;
    let session = null;
    if (sessionId) {
      const { valid, session: validSession, reason } = await sessionManager.validateSession(sessionId);
      if (valid) {
        session = validSession;
        user = validSession.metadata || null;
      } else {
        sessionManager.clearSessionCookie(c);
        if (required) {
          const currentUrl = c.req.url;
          return c.redirect(`${redirectTo}?redirect=${encodeURIComponent(currentUrl)}&error=${encodeURIComponent("Your session has expired. Please log in again.")}`);
        }
      }
    }
    if (required && !user) {
      const currentUrl = c.req.url;
      return c.redirect(`${redirectTo}?redirect=${encodeURIComponent(currentUrl)}`);
    }
    if (requireAdmin && (!user || !user.isAdmin)) {
      return c.html("<h1>403 Forbidden</h1><p>You do not have permission to access this page.</p>", 403);
    }
    c.set("user", user);
    c.set("session", session);
    c.set("isAuthenticated", !!user);
    c.set("isAdmin", user?.isAdmin || false);
    await next();
  };
}
function adminOnly(sessionManager) {
  return sessionAuth(sessionManager, {
    required: true,
    requireAdmin: true
  });
}

function getPageComponent(customPages, pageName, defaultPage) {
  return customPages[pageName] || defaultPage;
}
function registerUIRoutes(app, plugin) {
  const { sessionManager, usersResource, config } = plugin;
  const customPages = config.ui.customPages || {};
  const uiConfig = {
    ...config.ui,
    registrationEnabled: config.registration.enabled
  };
  app.get("/login", async (c) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      const { valid } = await sessionManager.validateSession(sessionId);
      if (valid) {
        return c.redirect("/profile");
      }
    }
    const error = c.req.query("error");
    const success = c.req.query("success");
    const email = c.req.query("email") || "";
    const PageComponent = getPageComponent(customPages, "login", LoginPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      success: success ? decodeURIComponent(success) : null,
      email,
      config: uiConfig
    }));
  });
  app.post("/login", async (c) => {
    try {
      const body = await c.req.parseBody();
      const { email, password, remember } = body;
      if (!email || !password) {
        return c.redirect(`/login?error=${encodeURIComponent("Email and password are required")}&email=${encodeURIComponent(email || "")}`);
      }
      const [okQuery, errQuery, users] = await tryFn(
        () => usersResource.query({ email: email.toLowerCase().trim() })
      );
      if (!okQuery || users.length === 0) {
        await new Promise((resolve) => setTimeout(resolve, 100));
        return c.redirect(`/login?error=${encodeURIComponent("Invalid email or password")}&email=${encodeURIComponent(email)}`);
      }
      const user = users[0];
      const [okVerify, errVerify, isValid] = await tryFn(
        () => verifyPassword(password, user.passwordHash)
      );
      if (!okVerify || !isValid) {
        return c.redirect(`/login?error=${encodeURIComponent("Invalid email or password")}&email=${encodeURIComponent(email)}`);
      }
      if (user.status !== "active") {
        const message = user.status === "suspended" ? "Your account has been suspended. Please contact support." : "Your account is inactive. Please verify your email or contact support.";
        return c.redirect(`/login?error=${encodeURIComponent(message)}&email=${encodeURIComponent(email)}`);
      }
      const ipAddress = c.req.header("x-forwarded-for")?.split(",")[0].trim() || c.req.header("x-real-ip") || "unknown";
      const userAgent = c.req.header("user-agent") || "unknown";
      const sessionExpiry = remember === "1" ? "30d" : config.session.sessionExpiry;
      const [okSession, errSession, session] = await tryFn(
        () => sessionManager.createSession({
          userId: user.id,
          metadata: {
            email: user.email,
            name: user.name,
            isAdmin: user.isAdmin || false
          },
          ipAddress,
          userAgent,
          expiresIn: sessionExpiry
        })
      );
      if (!okSession) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create session:", errSession);
        }
        return c.redirect(`/login?error=${encodeURIComponent("Failed to create session. Please try again.")}&email=${encodeURIComponent(email)}`);
      }
      sessionManager.setSessionCookie(c, session.id, session.expiresAt);
      await tryFn(
        () => usersResource.patch(user.id, {
          lastLoginAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastLoginIp: ipAddress
        })
      );
      const redirectTo = c.req.query("redirect") || "/profile";
      return c.redirect(redirectTo);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Login error:", error);
      }
      return c.redirect(`/login?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/register", async (c) => {
    if (!config.registration.enabled) {
      const message = config.registration.customMessage || "Registration is currently disabled. Please contact an administrator for access.";
      return c.redirect(`/login?error=${encodeURIComponent(message)}`);
    }
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      const { valid } = await sessionManager.validateSession(sessionId);
      if (valid) {
        return c.redirect("/profile");
      }
    }
    const error = c.req.query("error");
    const email = c.req.query("email") || "";
    const name = c.req.query("name") || "";
    const PageComponent = getPageComponent(customPages, "register", RegisterPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      email,
      name,
      passwordPolicy: config.passwordPolicy,
      config: uiConfig
    }));
  });
  app.post("/register", async (c) => {
    if (!config.registration.enabled) {
      const message = config.registration.customMessage || "Registration is currently disabled. Please contact an administrator for access.";
      return c.redirect(`/login?error=${encodeURIComponent(message)}`);
    }
    try {
      const body = await c.req.parseBody();
      const { name, email, password, confirm_password, agree_terms } = body;
      if (!name || !email || !password || !confirm_password) {
        return c.redirect(`/register?error=${encodeURIComponent("All fields are required")}&email=${encodeURIComponent(email || "")}&name=${encodeURIComponent(name || "")}`);
      }
      if (!agree_terms || agree_terms !== "1") {
        return c.redirect(`/register?error=${encodeURIComponent("You must agree to the Terms of Service and Privacy Policy")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      if (password !== confirm_password) {
        return c.redirect(`/register?error=${encodeURIComponent("Passwords do not match")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const passwordValidation = validatePassword(password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/register?error=${encodeURIComponent(errorMsg)}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const emailDomain = normalizedEmail.split("@")[1];
      if (config.registration.blockedDomains && config.registration.blockedDomains.length > 0) {
        if (config.registration.blockedDomains.includes(emailDomain)) {
          return c.redirect(`/register?error=${encodeURIComponent("Registration with this email domain is not allowed")}&name=${encodeURIComponent(name)}`);
        }
      }
      if (config.registration.allowedDomains && config.registration.allowedDomains.length > 0) {
        if (!config.registration.allowedDomains.includes(emailDomain)) {
          return c.redirect(`/register?error=${encodeURIComponent("Registration is restricted to specific email domains")}&name=${encodeURIComponent(name)}`);
        }
      }
      const [okCheck, errCheck, existingUsers] = await tryFn(
        () => usersResource.query({ email: normalizedEmail })
      );
      if (okCheck && existingUsers && existingUsers.length > 0) {
        return c.redirect(`/register?error=${encodeURIComponent("An account with this email already exists")}&name=${encodeURIComponent(name)}`);
      }
      const [okHash, errHash, passwordHash] = await tryFn(
        () => hashPassword(password, config.passwordPolicy.bcryptRounds)
      );
      if (!okHash) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password hashing failed:", errHash);
        }
        return c.redirect(`/register?error=${encodeURIComponent("Failed to process password. Please try again.")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const ipAddress = c.req.header("x-forwarded-for")?.split(",")[0].trim() || c.req.header("x-real-ip") || "unknown";
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.insert({
          email: normalizedEmail,
          name: name.trim(),
          passwordHash,
          status: "pending_verification",
          // Requires email verification
          isAdmin: false,
          emailVerified: false,
          registrationIp: ipAddress,
          lastLoginAt: null,
          lastLoginIp: null
        })
      );
      if (!okUser) {
        if (config.verbose) {
          console.error("[Identity Plugin] User creation failed:", errUser);
        }
        return c.redirect(`/register?error=${encodeURIComponent("Failed to create account. Please try again.")}&email=${encodeURIComponent(email)}&name=${encodeURIComponent(name)}`);
      }
      const verificationToken = generatePasswordResetToken();
      const verificationExpiry = calculateExpiration(24);
      await usersResource.update(user.id, {
        emailVerificationToken: verificationToken,
        emailVerificationExpiry: verificationExpiry
      });
      if (plugin.emailService) {
        try {
          await plugin.emailService.sendEmailVerificationEmail({
            to: normalizedEmail,
            name: name.trim(),
            verificationToken
          });
        } catch (emailError) {
          if (config.verbose) {
            console.error("[Identity Plugin] Failed to send verification email:", emailError);
          }
        }
      }
      return c.redirect(`/login?success=${encodeURIComponent("Account created successfully! Please check your email to verify your account.")}&email=${encodeURIComponent(normalizedEmail)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Registration error:", error);
      }
      return c.redirect(`/register?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/logout", async (c) => {
    try {
      const sessionId = sessionManager.getSessionIdFromRequest(c.req);
      if (sessionId) {
        await sessionManager.destroySession(sessionId);
      }
      sessionManager.clearSessionCookie(c);
      return c.redirect("/login?success=You have been logged out successfully");
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout error:", error);
      }
      sessionManager.clearSessionCookie(c);
      return c.redirect("/login");
    }
  });
  app.get("/logout", async (c) => {
    const sessionId = sessionManager.getSessionIdFromRequest(c.req);
    if (sessionId) {
      await sessionManager.destroySession(sessionId);
    }
    sessionManager.clearSessionCookie(c);
    return c.redirect("/login?success=You have been logged out successfully");
  });
  app.get("/forgot-password", async (c) => {
    const error = c.req.query("error");
    const success = c.req.query("success");
    const email = c.req.query("email") || "";
    const PageComponent = getPageComponent(customPages, "forgotPassword", ForgotPasswordPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      success: success ? decodeURIComponent(success) : null,
      email,
      config: uiConfig
    }));
  });
  app.post("/forgot-password", async (c) => {
    try {
      const body = await c.req.parseBody();
      const { email } = body;
      if (!email) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Email is required")}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const [okQuery, errQuery, users] = await tryFn(
        () => usersResource.query({ email: normalizedEmail })
      );
      const successMessage = "If an account exists with this email, you will receive password reset instructions.";
      if (!okQuery || users.length === 0) {
        await new Promise((resolve) => setTimeout(resolve, 500));
        return c.redirect(`/forgot-password?success=${encodeURIComponent(successMessage)}`);
      }
      const user = users[0];
      const resetToken = generatePasswordResetToken();
      const expiresAt = calculateExpiration("1h");
      const [okToken, errToken] = await tryFn(
        () => plugin.passwordResetTokensResource.insert({
          userId: user.id,
          token: resetToken,
          expiresAt,
          used: false
        })
      );
      if (!okToken) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create reset token:", errToken);
        }
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Failed to process request. Please try again.")}&email=${encodeURIComponent(email)}`);
      }
      if (plugin.emailService && plugin.emailService.config.enabled) {
        await plugin.emailService.sendPasswordResetEmail({
          to: user.email,
          name: user.name,
          resetToken,
          expiresIn: 60
          // minutes
        });
      } else if (config.verbose) {
        console.log("[Identity Plugin] Email service disabled. Reset token:", resetToken);
        console.log("[Identity Plugin] Reset URL:", `${config.ui.baseUrl || "http://localhost:4000"}/reset-password?token=${resetToken}`);
      }
      return c.redirect(`/forgot-password?success=${encodeURIComponent(successMessage)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Forgot password error:", error);
      }
      return c.redirect(`/forgot-password?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/reset-password", async (c) => {
    const token = c.req.query("token");
    const error = c.req.query("error");
    if (!token) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid or missing reset token")}`);
    }
    const [okQuery, errQuery, tokens] = await tryFn(
      () => plugin.passwordResetTokensResource.query({ token })
    );
    if (!okQuery || tokens.length === 0) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid reset token")}`);
    }
    const resetToken = tokens[0];
    if (isExpired(resetToken.expiresAt)) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has expired. Please request a new one.")}`);
    }
    if (resetToken.used) {
      return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has already been used. Please request a new one.")}`);
    }
    const PageComponent = getPageComponent(customPages, "resetPassword", ResetPasswordPage);
    return c.html(PageComponent({
      error: error ? decodeURIComponent(error) : null,
      token,
      passwordPolicy: config.passwordPolicy,
      config: uiConfig
    }));
  });
  app.post("/reset-password", async (c) => {
    try {
      const body = await c.req.parseBody();
      const { token, password, confirm_password } = body;
      if (!token || !password || !confirm_password) {
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("All fields are required")}`);
      }
      if (password !== confirm_password) {
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("Passwords do not match")}`);
      }
      const passwordValidation = validatePassword(password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent(errorMsg)}`);
      }
      const [okQuery, errQuery, tokens] = await tryFn(
        () => plugin.passwordResetTokensResource.query({ token })
      );
      if (!okQuery || tokens.length === 0) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Invalid reset token")}`);
      }
      const resetToken = tokens[0];
      if (isExpired(resetToken.expiresAt)) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has expired. Please request a new one.")}`);
      }
      if (resetToken.used) {
        return c.redirect(`/forgot-password?error=${encodeURIComponent("Reset link has already been used.")}`);
      }
      const [okHash, errHash, passwordHash] = await tryFn(
        () => hashPassword(password, config.passwordPolicy.bcryptRounds)
      );
      if (!okHash) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password hashing failed:", errHash);
        }
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("Failed to process password. Please try again.")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(resetToken.userId, {
          passwordHash
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password update failed:", errUpdate);
        }
        return c.redirect(`/reset-password?token=${token}&error=${encodeURIComponent("Failed to reset password. Please try again.")}`);
      }
      await tryFn(
        () => plugin.passwordResetTokensResource.patch(resetToken.id, { used: true })
      );
      await sessionManager.destroyUserSessions(resetToken.userId);
      return c.redirect(`/login?success=${encodeURIComponent("Your password has been reset successfully. Please log in with your new password.")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Reset password error:", error);
      }
      return c.redirect(`/forgot-password?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/profile", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to load user:", errUser);
        }
        return c.redirect(`/login?error=${encodeURIComponent("Failed to load profile. Please try again.")}`);
      }
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(userData.id)
      );
      const sessions = okSessions ? allSessions.map((session) => ({
        ...session,
        isCurrent: session.id === currentSessionId
      })) : [];
      const error = c.req.query("error");
      const success = c.req.query("success");
      const PageComponent = getPageComponent(customPages, "profile", ProfilePage);
      return c.html(PageComponent({
        user: userData,
        sessions,
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        passwordPolicy: config.passwordPolicy,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Profile page error:", error);
      }
      return c.redirect(`/login?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/update", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { name, email } = body;
      const user = c.get("user");
      if (!name || !email) {
        return c.redirect(`/profile?error=${encodeURIComponent("Name and email are required")}`);
      }
      const normalizedEmail = email.toLowerCase().trim();
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      if (normalizedEmail !== userData.email) {
        const [okCheck, errCheck, existingUsers] = await tryFn(
          () => usersResource.query({ email: normalizedEmail })
        );
        if (okCheck && existingUsers.length > 0) {
          return c.redirect(`/profile?error=${encodeURIComponent("Email address is already in use")}`);
        }
        const [okUpdate, errUpdate] = await tryFn(
          () => usersResource.patch(userData.id, {
            name: name.trim(),
            email: normalizedEmail,
            emailVerified: false
          })
        );
        if (!okUpdate) {
          if (config.verbose) {
            console.error("[Identity Plugin] Profile update failed:", errUpdate);
          }
          return c.redirect(`/profile?error=${encodeURIComponent("Failed to update profile. Please try again.")}`);
        }
        return c.redirect(`/profile?success=${encodeURIComponent("Profile updated successfully. Please verify your new email address.")}`);
      } else {
        const [okUpdate, errUpdate] = await tryFn(
          () => usersResource.patch(userData.id, {
            name: name.trim()
          })
        );
        if (!okUpdate) {
          if (config.verbose) {
            console.error("[Identity Plugin] Profile update failed:", errUpdate);
          }
          return c.redirect(`/profile?error=${encodeURIComponent("Failed to update profile. Please try again.")}`);
        }
        return c.redirect(`/profile?success=${encodeURIComponent("Profile updated successfully")}`);
      }
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Profile update error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/change-password", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { current_password, new_password, confirm_new_password } = body;
      const user = c.get("user");
      if (!current_password || !new_password || !confirm_new_password) {
        return c.redirect(`/profile?error=${encodeURIComponent("All password fields are required")}`);
      }
      if (new_password !== confirm_new_password) {
        return c.redirect(`/profile?error=${encodeURIComponent("New passwords do not match")}`);
      }
      const [okUser, errUser, userData] = await tryFn(
        () => usersResource.get(user.userId || user.id)
      );
      if (!okUser) {
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to load profile")}`);
      }
      const [okVerify, errVerify, isValid] = await tryFn(
        () => verifyPassword(current_password, userData.passwordHash)
      );
      if (!okVerify || !isValid) {
        return c.redirect(`/profile?error=${encodeURIComponent("Current password is incorrect")}`);
      }
      const passwordValidation = validatePassword(new_password, config.passwordPolicy);
      if (!passwordValidation.valid) {
        const errorMsg = passwordValidation.errors.join(", ");
        return c.redirect(`/profile?error=${encodeURIComponent(errorMsg)}`);
      }
      const [okHash, errHash, passwordHash] = await tryFn(
        () => hashPassword(new_password, config.passwordPolicy.bcryptRounds)
      );
      if (!okHash) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password hashing failed:", errHash);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to process password. Please try again.")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userData.id, {
          passwordHash
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Password update failed:", errUpdate);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to change password. Please try again.")}`);
      }
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(userData.id)
      );
      if (okSessions) {
        for (const session of allSessions) {
          if (session.id !== currentSessionId) {
            await sessionManager.destroySession(session.id);
          }
        }
      }
      return c.redirect(`/profile?success=${encodeURIComponent("Password changed successfully. All other sessions have been logged out.")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Change password error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/logout-session", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { session_id } = body;
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      if (!session_id) {
        return c.redirect(`/profile?error=${encodeURIComponent("Session ID is required")}`);
      }
      if (session_id === currentSessionId) {
        return c.redirect(`/profile?error=${encodeURIComponent("Cannot logout current session. Use logout button instead.")}`);
      }
      const [okSession, errSession, session] = await tryFn(
        () => sessionManager.getSession(session_id)
      );
      if (!okSession || !session) {
        return c.redirect(`/profile?error=${encodeURIComponent("Session not found")}`);
      }
      if (session.userId !== (user.userId || user.id)) {
        return c.redirect(`/profile?error=${encodeURIComponent("Access denied")}`);
      }
      await sessionManager.destroySession(session_id);
      return c.redirect(`/profile?success=${encodeURIComponent("Session logged out successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout session error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/profile/logout-all-sessions", sessionAuth(sessionManager, { required: true }), async (c) => {
    try {
      const user = c.get("user");
      const currentSessionId = sessionManager.getSessionIdFromRequest(c.req);
      const [okSessions, errSessions, allSessions] = await tryFn(
        () => sessionManager.getUserSessions(user.userId || user.id)
      );
      if (!okSessions) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to get sessions:", errSessions);
        }
        return c.redirect(`/profile?error=${encodeURIComponent("Failed to logout sessions. Please try again.")}`);
      }
      let loggedOutCount = 0;
      for (const session of allSessions) {
        if (session.id !== currentSessionId) {
          await sessionManager.destroySession(session.id);
          loggedOutCount++;
        }
      }
      return c.redirect(`/profile?success=${encodeURIComponent(`${loggedOutCount} session(s) logged out successfully`)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Logout all sessions error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const [okUsers, errUsers, allUsers] = await tryFn(() => usersResource.list({ limit: 1e3 }));
      const [okClients, errClients, allClients] = await tryFn(() => plugin.oauth2ClientsResource.list({ limit: 100 }));
      const [okSessions, errSessions, allSessions] = await tryFn(() => plugin.sessionsResource.list({ limit: 1e3 }));
      const [okCodes, errCodes, allCodes] = await tryFn(() => plugin.oauth2AuthCodesResource.list({ limit: 1e3 }));
      const users = okUsers ? allUsers : [];
      const clients = okClients ? allClients : [];
      const sessions = okSessions ? allSessions : [];
      const codes = okCodes ? allCodes : [];
      const now = /* @__PURE__ */ new Date();
      const stats = {
        totalUsers: users.length,
        activeUsers: users.filter((u) => u.status === "active").length,
        pendingUsers: users.filter((u) => u.status === "pending_verification").length,
        totalClients: clients.length,
        activeClients: clients.filter((c2) => c2.active !== false).length,
        activeSessions: sessions.filter((s) => new Date(s.expiresAt) > now).length,
        uniqueUsers: new Set(sessions.filter((s) => new Date(s.expiresAt) > now).map((s) => s.userId)).size,
        totalAuthCodes: codes.length,
        unusedAuthCodes: codes.filter((c2) => !c2.used).length,
        recentUsers: users.slice(-5).reverse(),
        serverUptime: formatUptime(process.uptime())
      };
      return c.html(AdminDashboardPage({
        stats,
        user,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Admin dashboard error:", error);
      }
      return c.redirect(`/profile?error=${encodeURIComponent("Failed to load admin dashboard")}`);
    }
  });
  app.get("/admin/clients", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const error = c.req.query("error");
      const success = c.req.query("success");
      const [okClients, errClients, clients] = await tryFn(
        () => plugin.oauth2ClientsResource.list({ limit: 100 })
      );
      if (!okClients) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to load clients:", errClients);
        }
        return c.redirect(`/admin?error=${encodeURIComponent("Failed to load clients")}`);
      }
      return c.html(AdminClientsPage({
        clients,
        user,
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Admin clients error:", error);
      }
      return c.redirect(`/admin?error=${encodeURIComponent("Failed to load clients")}`);
    }
  });
  app.get("/admin/clients/new", adminOnly(sessionManager), async (c) => {
    const user = c.get("user");
    const error = c.req.query("error");
    return c.html(AdminClientFormPage({
      user,
      error: error ? decodeURIComponent(error) : null,
      availableScopes: config.supportedScopes || ["openid", "profile", "email", "offline_access"],
      availableGrantTypes: config.supportedGrantTypes || ["authorization_code", "refresh_token", "client_credentials"],
      config: uiConfig
    }));
  });
  app.post("/admin/clients/create", adminOnly(sessionManager), async (c) => {
    try {
      const body = await c.req.parseBody();
      const { name, redirectUris, grantTypes, allowedScopes, active } = body;
      if (!name) {
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("Client name is required")}`);
      }
      const redirectUrisArray = Array.isArray(redirectUris) ? redirectUris : [redirectUris];
      const grantTypesArray = Array.isArray(grantTypes) ? grantTypes : grantTypes ? [grantTypes] : [];
      const allowedScopesArray = Array.isArray(allowedScopes) ? allowedScopes : allowedScopes ? [allowedScopes] : [];
      if (redirectUrisArray.length === 0 || redirectUrisArray[0] === "") {
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("At least one redirect URI is required")}`);
      }
      const clientId = idGenerator();
      const clientSecret = idGenerator() + idGenerator();
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.insert({
          clientId,
          clientSecret,
          name: name.trim(),
          redirectUris: redirectUrisArray.filter((uri) => uri && uri.trim() !== ""),
          grantTypes: grantTypesArray,
          allowedScopes: allowedScopesArray,
          active: active === "1"
        })
      );
      if (!okClient) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to create client:", errClient);
        }
        return c.redirect(`/admin/clients/new?error=${encodeURIComponent("Failed to create client. Please try again.")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client created successfully. Client ID: " + clientId + " | Client Secret: " + clientSecret + " (Save this secret now - it cannot be displayed again!)")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Create client error:", error);
      }
      return c.redirect(`/admin/clients/new?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin/clients/:id/edit", adminOnly(sessionManager), async (c) => {
    try {
      const user = c.get("user");
      const clientId = c.req.param("id");
      const error = c.req.query("error");
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.get(clientId)
      );
      if (!okClient) {
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Client not found")}`);
      }
      return c.html(AdminClientFormPage({
        client,
        user,
        error: error ? decodeURIComponent(error) : null,
        availableScopes: config.supportedScopes || ["openid", "profile", "email", "offline_access"],
        availableGrantTypes: config.supportedGrantTypes || ["authorization_code", "refresh_token", "client_credentials"],
        config: uiConfig
      }));
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Edit client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to load client")}`);
    }
  });
  app.post("/admin/clients/:id/update", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const body = await c.req.parseBody();
      const { name, redirectUris, grantTypes, allowedScopes, active } = body;
      if (!name) {
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("Client name is required")}`);
      }
      const redirectUrisArray = Array.isArray(redirectUris) ? redirectUris : [redirectUris];
      const grantTypesArray = Array.isArray(grantTypes) ? grantTypes : grantTypes ? [grantTypes] : [];
      const allowedScopesArray = Array.isArray(allowedScopes) ? allowedScopes : allowedScopes ? [allowedScopes] : [];
      if (redirectUrisArray.length === 0 || redirectUrisArray[0] === "") {
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("At least one redirect URI is required")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          name: name.trim(),
          redirectUris: redirectUrisArray.filter((uri) => uri && uri.trim() !== ""),
          grantTypes: grantTypesArray,
          allowedScopes: allowedScopesArray,
          active: active === "1"
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to update client:", errUpdate);
        }
        return c.redirect(`/admin/clients/${clientId}/edit?error=${encodeURIComponent("Failed to update client. Please try again.")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client updated successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Update client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/delete", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const [okDelete, errDelete] = await tryFn(
        () => plugin.oauth2ClientsResource.delete(clientId)
      );
      if (!okDelete) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to delete client:", errDelete);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to delete client")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Client deleted successfully")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Delete client error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/rotate-secret", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const newSecret = idGenerator() + idGenerator();
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          clientSecret: newSecret
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to rotate secret:", errUpdate);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to rotate secret")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent("Secret rotated successfully. New secret: " + newSecret + " (Save this now - it cannot be displayed again!)")}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Rotate secret error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/clients/:id/toggle-active", adminOnly(sessionManager), async (c) => {
    try {
      const clientId = c.req.param("id");
      const [okClient, errClient, client] = await tryFn(
        () => plugin.oauth2ClientsResource.get(clientId)
      );
      if (!okClient) {
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Client not found")}`);
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => plugin.oauth2ClientsResource.patch(clientId, {
          active: !client.active
        })
      );
      if (!okUpdate) {
        if (config.verbose) {
          console.error("[Identity Plugin] Failed to toggle active:", errUpdate);
        }
        return c.redirect(`/admin/clients?error=${encodeURIComponent("Failed to update client")}`);
      }
      return c.redirect(`/admin/clients?success=${encodeURIComponent(`Client ${client.active ? "deactivated" : "activated"} successfully`)}`);
    } catch (error) {
      if (config.verbose) {
        console.error("[Identity Plugin] Toggle active error:", error);
      }
      return c.redirect(`/admin/clients?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/admin/users", adminOnly(sessionManager), async (c) => {
    const error = c.req.query("error");
    const success = c.req.query("success");
    try {
      const [okUsers, errUsers, allUsers] = await tryFn(
        () => usersResource.list({ limit: 1e3 })
      );
      if (!okUsers) {
        console.error("[Identity Plugin] List users error:", errUsers);
        return c.html(AdminUsersPage({
          users: [],
          user: c.get("user"),
          error: "Failed to load users",
          success: success ? decodeURIComponent(success) : null,
          config: uiConfig
        }));
      }
      const users = allUsers || [];
      return c.html(AdminUsersPage({
        users,
        user: c.get("user"),
        error: error ? decodeURIComponent(error) : null,
        success: success ? decodeURIComponent(success) : null,
        config: uiConfig
      }));
    } catch (error2) {
      console.error("[Identity Plugin] List users error:", error2);
      return c.html(AdminUsersPage({
        users: [],
        user: c.get("user"),
        error: "An error occurred. Please try again.",
        config: uiConfig
      }));
    }
  });
  app.get("/admin/users/:id/edit", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const error = c.req.query("error");
    try {
      const [okUser, errUser, editUser] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !editUser) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      return c.html(AdminUserFormPage({
        editUser,
        user: c.get("user"),
        error: error ? decodeURIComponent(error) : null,
        config: uiConfig
      }));
    } catch (error2) {
      console.error("[Identity Plugin] Get user error:", error2);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/update", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const body = await c.req.parseBody();
    const { name, email, status, role, emailVerified } = body;
    const currentUser = c.get("user");
    try {
      const [okUser, errUser, editUser] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !editUser) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const isSelfEdit = userId === currentUser.id;
      if (email !== editUser.email) {
        const [okExists, errExists, existingUsers] = await tryFn(
          () => usersResource.query({ email: email.toLowerCase().trim() })
        );
        if (okExists && existingUsers && existingUsers.length > 0) {
          return c.html(AdminUserFormPage({
            editUser: { ...editUser, name, email },
            user: currentUser,
            error: "Email already in use",
            config: uiConfig
          }));
        }
      }
      const updates = {
        name: name.trim(),
        email: email.toLowerCase().trim()
      };
      if (!isSelfEdit) {
        if (status) {
          updates.status = status;
        }
        if (role) {
          updates.role = role;
        }
      }
      updates.emailVerified = emailVerified === "1";
      if (email !== editUser.email) {
        updates.emailVerified = false;
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(userId, updates)
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Update user error:", errUpdate);
        return c.html(AdminUserFormPage({
          editUser: { ...editUser, ...updates },
          user: currentUser,
          error: "Failed to update user",
          config: uiConfig
        }));
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User ${name} updated successfully`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Update user error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/delete", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot delete your own account")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const userName = user.name;
      const [okDelete, errDelete] = await tryFn(
        () => usersResource.delete(userId)
      );
      if (!okDelete) {
        console.error("[Identity Plugin] Delete user error:", errDelete);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to delete user")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User ${userName} deleted successfully`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Delete user error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/change-status", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const body = await c.req.parseBody();
    const { status } = body;
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot change your own status")}`);
    }
    try {
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { status })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Change status error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to change user status")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`User status changed to ${status}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Change status error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/verify-email", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    try {
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { emailVerified: true })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Verify email error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to verify email")}`);
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent("Email marked as verified")}`);
    } catch (error) {
      console.error("[Identity Plugin] Verify email error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/reset-password", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("Use the profile page to change your own password")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const resetToken = generatePasswordResetToken();
      const resetExpiry = calculateExpiration(1);
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, {
          passwordResetToken: resetToken,
          passwordResetExpiry: resetExpiry
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Password reset update error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to generate reset token")}`);
      }
      if (plugin.emailService) {
        const resetUrl = `${config.issuer}/reset-password?token=${resetToken}`;
        await plugin.emailService.sendPasswordResetEmail(user.email, {
          name: user.name,
          resetUrl
        });
      }
      return c.redirect(`/admin/users?success=${encodeURIComponent(`Password reset email sent to ${user.email}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Reset password error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.post("/admin/users/:id/toggle-admin", adminOnly(sessionManager), async (c) => {
    const userId = c.req.param("id");
    const currentUser = c.get("user");
    if (userId === currentUser.id) {
      return c.redirect(`/admin/users?error=${encodeURIComponent("You cannot change your own role")}`);
    }
    try {
      const [okUser, errUser, user] = await tryFn(
        () => usersResource.get(userId)
      );
      if (!okUser || !user) {
        return c.redirect(`/admin/users?error=${encodeURIComponent("User not found")}`);
      }
      const newRole = user.role === "admin" ? "user" : "admin";
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.patch(userId, { role: newRole })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Toggle admin error:", errUpdate);
        return c.redirect(`/admin/users?error=${encodeURIComponent("Failed to change user role")}`);
      }
      const action = newRole === "admin" ? "granted admin privileges to" : "removed admin privileges from";
      return c.redirect(`/admin/users?success=${encodeURIComponent(`Successfully ${action} ${user.name}`)}`);
    } catch (error) {
      console.error("[Identity Plugin] Toggle admin error:", error);
      return c.redirect(`/admin/users?error=${encodeURIComponent("An error occurred. Please try again.")}`);
    }
  });
  app.get("/oauth/authorize", sessionAuth(sessionManager, { required: false }), async (c) => {
    const query = c.req.query();
    const {
      response_type,
      client_id,
      redirect_uri,
      scope,
      state,
      code_challenge,
      code_challenge_method = "plain"
    } = query;
    try {
      if (!response_type || !client_id || !redirect_uri) {
        return c.html(`
          <html>
            <body>
              <h1>Invalid Request</h1>
              <p>response_type, client_id, and redirect_uri are required</p>
            </body>
          </html>
        `, 400);
      }
      const user = c.get("user");
      if (!user) {
        const returnUrl = `/oauth/authorize?${new URLSearchParams(query).toString()}`;
        return c.redirect(`/login?returnUrl=${encodeURIComponent(returnUrl)}`);
      }
      const [okClient, errClient, clients] = await tryFn(
        () => plugin.oauth2ClientsResource.query({ clientId: client_id })
      );
      if (!okClient || !clients || clients.length === 0) {
        return c.html(`
          <html>
            <body>
              <h1>Invalid Client</h1>
              <p>Client not found</p>
            </body>
          </html>
        `, 400);
      }
      const client = clients[0];
      if (client.active === false) {
        return c.html(`
          <html>
            <body>
              <h1>Client Inactive</h1>
              <p>This client is not currently active</p>
            </body>
          </html>
        `, 400);
      }
      if (!client.redirectUris || !client.redirectUris.includes(redirect_uri)) {
        return c.html(`
          <html>
            <body>
              <h1>Invalid Redirect URI</h1>
              <p>The redirect_uri does not match any registered URIs for this client</p>
            </body>
          </html>
        `, 400);
      }
      const requestedScopes = scope ? scope.split(" ") : [];
      if (requestedScopes.length > 0) {
        const invalidScopes = requestedScopes.filter(
          (s) => !client.allowedScopes || !client.allowedScopes.includes(s)
        );
        if (invalidScopes.length > 0) {
          return c.html(`
            <html>
              <body>
                <h1>Invalid Scopes</h1>
                <p>Invalid scopes: ${invalidScopes.join(", ")}</p>
              </body>
            </html>
          `, 400);
        }
      }
      const PageComponent = getPageComponent(customPages, "consent", ConsentPage);
      return c.html(PageComponent({
        client,
        scopes: requestedScopes,
        user,
        responseType: response_type,
        redirectUri: redirect_uri,
        state,
        codeChallenge: code_challenge,
        codeChallengeMethod: code_challenge_method,
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] OAuth authorize error:", error);
      return c.html(`
        <html>
          <body>
            <h1>Server Error</h1>
            <p>An error occurred while processing your request</p>
          </body>
        </html>
      `, 500);
    }
  });
  app.post("/oauth/consent", sessionAuth(sessionManager, { required: true }), async (c) => {
    const body = await c.req.parseBody();
    const {
      decision,
      trust_application,
      response_type,
      client_id,
      redirect_uri,
      scope,
      state,
      code_challenge,
      code_challenge_method = "plain"
    } = body;
    const user = c.get("user");
    try {
      if (decision === "deny") {
        const errorParams = new URLSearchParams({
          error: "access_denied",
          error_description: "User denied authorization"
        });
        if (state) {
          errorParams.set("state", state);
        }
        return c.redirect(`${redirect_uri}?${errorParams.toString()}`);
      }
      const authCode = generateAuthCode();
      const requestedScopes = scope ? scope.split(" ") : [];
      const expiresAt = new Date(Date.now() + 10 * 60 * 1e3).toISOString();
      const [okCode, errCode] = await tryFn(
        () => plugin.oauth2AuthCodesResource.insert({
          code: authCode,
          clientId: client_id,
          userId: user.id,
          redirectUri: redirect_uri,
          scope: requestedScopes,
          codeChallenge: code_challenge || null,
          codeChallengeMethod: code_challenge_method || "plain",
          expiresAt,
          used: false,
          trusted: trust_application === "1"
        })
      );
      if (!okCode) {
        console.error("[Identity Plugin] Failed to store auth code:", errCode);
        return c.html(`
          <html>
            <body>
              <h1>Server Error</h1>
              <p>Failed to generate authorization code</p>
            </body>
          </html>
        `, 500);
      }
      if (trust_application === "1") {
      }
      const successParams = new URLSearchParams({
        code: authCode
      });
      if (state) {
        successParams.set("state", state);
      }
      return c.redirect(`${redirect_uri}?${successParams.toString()}`);
    } catch (error) {
      console.error("[Identity Plugin] OAuth consent error:", error);
      return c.html(`
        <html>
          <body>
            <h1>Server Error</h1>
            <p>An error occurred while processing your consent</p>
          </body>
        </html>
      `, 500);
    }
  });
  app.get("/verify-email", async (c) => {
    const token = c.req.query("token");
    const PageComponent = getPageComponent(customPages, "verifyEmail", VerifyEmailPage);
    if (!token) {
      return c.html(PageComponent({
        status: "pending",
        config: uiConfig
      }));
    }
    try {
      const [okUsers, errUsers, users] = await tryFn(
        () => usersResource.query({ emailVerificationToken: token })
      );
      if (!okUsers || !users || users.length === 0) {
        return c.html(PageComponent({
          status: "error",
          message: "Invalid verification link. It may have already been used or expired.",
          config: uiConfig
        }));
      }
      const user = users[0];
      if (user.emailVerified) {
        return c.html(PageComponent({
          status: "success",
          message: "Your email is already verified! You can sign in now.",
          config: uiConfig
        }));
      }
      if (user.emailVerificationExpiry) {
        if (isExpired(user.emailVerificationExpiry)) {
          return c.html(PageComponent({
            status: "expired",
            email: user.email,
            message: "This verification link has expired. Please request a new one.",
            config: uiConfig
          }));
        }
      }
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(user.id, {
          emailVerified: true,
          emailVerificationToken: null,
          emailVerificationExpiry: null,
          status: "active"
          // Activate account on email verification
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Email verification update error:", errUpdate);
        return c.html(PageComponent({
          status: "error",
          message: "Failed to verify email. Please try again later.",
          config: uiConfig
        }));
      }
      return c.html(PageComponent({
        status: "success",
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] Email verification error:", error);
      return c.html(PageComponent({
        status: "error",
        message: "An error occurred while verifying your email.",
        config: uiConfig
      }));
    }
  });
  app.post("/verify-email/resend", async (c) => {
    const body = await c.req.parseBody();
    const { email } = body;
    const PageComponent = getPageComponent(customPages, "verifyEmail", VerifyEmailPage);
    if (!email) {
      return c.html(PageComponent({
        status: "error",
        message: "Email address is required.",
        config: uiConfig
      }));
    }
    try {
      const [okUsers, errUsers, users] = await tryFn(
        () => usersResource.query({ email: email.toLowerCase().trim() })
      );
      if (!okUsers || !users || users.length === 0) {
        return c.html(PageComponent({
          status: "pending",
          message: "If an account exists with this email, a verification link has been sent.",
          config: uiConfig
        }));
      }
      const user = users[0];
      if (user.emailVerified) {
        return c.html(PageComponent({
          status: "success",
          message: "Your email is already verified! You can sign in now.",
          config: uiConfig
        }));
      }
      const verificationToken = generatePasswordResetToken();
      const verificationExpiry = calculateExpiration(24);
      const [okUpdate, errUpdate] = await tryFn(
        () => usersResource.update(user.id, {
          emailVerificationToken: verificationToken,
          emailVerificationExpiry: verificationExpiry
        })
      );
      if (!okUpdate) {
        console.error("[Identity Plugin] Verification token update error:", errUpdate);
        return c.html(PageComponent({
          status: "error",
          message: "Failed to send verification email. Please try again later.",
          config: uiConfig
        }));
      }
      if (plugin.emailService) {
        await plugin.emailService.sendEmailVerificationEmail({
          to: user.email,
          name: user.name,
          verificationToken
        });
      }
      return c.html(PageComponent({
        status: "pending",
        email: user.email,
        message: "A new verification link has been sent to your email address.",
        config: uiConfig
      }));
    } catch (error) {
      console.error("[Identity Plugin] Resend verification error:", error);
      return c.html(PageComponent({
        status: "error",
        message: "An error occurred. Please try again later.",
        config: uiConfig
      }));
    }
  });
}
function formatUptime(seconds) {
  const days = Math.floor(seconds / 86400);
  const hours = Math.floor(seconds % 86400 / 3600);
  const minutes = Math.floor(seconds % 3600 / 60);
  const parts = [];
  if (days > 0) parts.push(`${days}d`);
  if (hours > 0) parts.push(`${hours}h`);
  if (minutes > 0) parts.push(`${minutes}m`);
  return parts.length > 0 ? parts.join(" ") : "< 1m";
}

var routes = /*#__PURE__*/Object.freeze({
  __proto__: null,
  registerUIRoutes: registerUIRoutes
});

export { AVAILABLE_BEHAVIORS, AnalyticsNotEnabledError, ApiPlugin, AuditPlugin, AuthenticationError, BACKUP_DRIVERS, BackupPlugin, BaseBackupDriver, BaseError, BaseReplicator, BehaviorError, BigqueryReplicator, CONSUMER_DRIVERS, Cache, CachePlugin, S3Client as Client, ConnectionString, ConnectionStringError, CostsPlugin, CryptoError, DEFAULT_BEHAVIOR, Database, DatabaseError, DynamoDBReplicator, EncryptionError, ErrorMap, EventualConsistencyPlugin, Factory, FilesystemBackupDriver, FilesystemCache, FullTextPlugin, GeoPlugin, IdentityPlugin, InvalidResourceItem, MLPlugin, MemoryCache, MemoryClient, MemoryStorage, MetadataLimitError, MetricsPlugin, MissingMetadata, MongoDBReplicator, MultiBackupDriver, MySQLReplicator, NoSuchBucket, NoSuchKey, NotFound, PartitionAwareFilesystemCache, PartitionDriverError, PartitionError, PermissionError, PlanetScaleReplicator, Plugin, PluginError, PluginObject, PluginStorageError, PostgresReplicator, QueueConsumerPlugin, REPLICATOR_DRIVERS, RabbitMqConsumer, RelationPlugin, ReplicatorPlugin, Resource, ResourceError, ResourceIdsPageReader, ResourceIdsReader, ResourceNotFound, ResourceReader, ResourceWriter, S3BackupDriver, S3Cache, S3Client, S3QueuePlugin, Database as S3db, S3dbError, S3dbReplicator, SchedulerPlugin, Schema, SchemaError, Seeder, SqsConsumer, SqsReplicator, StateMachinePlugin, StreamError, TTLPlugin, TfStatePlugin, TursoReplicator, UnknownError, ValidationError, Validator, VectorPlugin, WebhookReplicator, behaviors, calculateAttributeNamesSize, calculateAttributeSizes, calculateEffectiveLimit, calculateSystemOverhead, calculateTotalSize, calculateUTF8Bytes, clearUTF8Memory, createBackupDriver, createConsumer, createReplicator, decode$1 as decode, decodeDecimal, decodeFixedPoint, decodeFixedPointBatch, decrypt, S3db as default, encode$1 as encode, encodeDecimal, encodeFixedPoint, encodeFixedPointBatch, encrypt, generateTypes, getBehavior, getSizeBreakdown, idGenerator, mapAwsError, md5, passwordGenerator, printTypes, sha256, streamToString, transformValue, tryFn, tryFnSync, validateBackupConfig, validateReplicatorConfig };
//# sourceMappingURL=s3db.es.js.map
